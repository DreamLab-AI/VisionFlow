use log::{error, info, warn, Level};
use serde_json::{json, Value};
use std::{
    collections::HashMap,
    fs,
    path::PathBuf,
    sync::{Arc, Mutex},
    thread,
    time::{Duration, Instant},
};
use tempfile::tempdir;

use super::super::src::utils::advanced_logging::{
    get_performance_summary, init_advanced_logging, log_gpu_error, log_gpu_kernel,
    log_memory_event, log_performance, log_structured, AdvancedLogger, GPULogMetrics, LogComponent,
    LogEntry,
};

/// Test suite for telemetry integration
#[cfg(test)]
mod telemetry_tests {
    use super::*;

    #[test]
    fn test_full_agent_lifecycle_logging() {
        let temp_dir = tempdir().expect("Failed to create temp dir");
        let log_dir = temp_dir.path().to_path_buf();

        let logger = AdvancedLogger::new(&log_dir).expect("Failed to create logger");

        // Simulate complete agent lifecycle
        test_agent_startup_logging(&logger);
        test_agent_execution_logging(&logger);
        test_agent_error_handling(&logger);
        test_agent_shutdown_logging(&logger);

        // Verify all log files were created
        let expected_files = vec![
            "server.log",
            "client.log",
            "gpu.log",
            "analytics.log",
            "memory.log",
            "network.log",
            "performance.log",
            "error.log",
        ];

        for file in expected_files {
            let log_file_path = log_dir.join(file);
            assert!(log_file_path.exists(), "Log file {} should exist", file);

            let content =
                fs::read_to_string(&log_file_path).expect("Should be able to read log file");
            assert!(!content.is_empty(), "Log file {} should not be empty", file);
        }
    }

    #[test]
    fn test_docker_volume_logging() {
        // Test logging to Docker-mounted volumes
        let docker_log_dir = PathBuf::from("/tmp/test_docker_logs");
        fs::create_dir_all(&docker_log_dir).expect("Failed to create docker log dir");

        let logger = AdvancedLogger::new(&docker_log_dir).expect("Failed to create logger");

        // Test writing to volume-mounted directory
        logger.log_structured(
            LogComponent::Server,
            Level::Info,
            "Docker volume test",
            Some(HashMap::from([
                ("container_id".to_string(), json!("test-container-123")),
                ("volume_mount".to_string(), json!("/app/logs")),
            ])),
        );

        // Verify file persistence across container restarts
        let log_file = docker_log_dir.join("server.log");
        assert!(log_file.exists());

        let content = fs::read_to_string(&log_file).expect("Should read log file");
        assert!(content.contains("Docker volume test"));
        assert!(content.contains("test-container-123"));

        // Cleanup
        fs::remove_dir_all(&docker_log_dir).ok();
    }

    #[test]
    fn test_log_correlation_across_services() {
        let temp_dir = tempdir().expect("Failed to create temp dir");
        let log_dir = temp_dir.path().to_path_buf();

        let logger = AdvancedLogger::new(&log_dir).expect("Failed to create logger");

        let correlation_id = "req-123-456-789";
        let session_id = "session-abc-def";

        // Simulate distributed request across multiple services
        let services = vec![
            LogComponent::Server,
            LogComponent::Analytics,
            LogComponent::GPU,
            LogComponent::Memory,
        ];

        for (i, component) in services.iter().enumerate() {
            let metadata = HashMap::from([
                ("correlation_id".to_string(), json!(correlation_id)),
                ("session_id".to_string(), json!(session_id)),
                ("step".to_string(), json!(i + 1)),
                ("service".to_string(), json!(component.as_str())),
            ]);

            logger.log_structured(
                *component,
                Level::Info,
                &format!("Processing step {} for request", i + 1),
                Some(metadata),
            );
        }

        // Verify correlation across all log files
        for component in &services {
            let log_file = log_dir.join(component.log_file_name());
            let content = fs::read_to_string(&log_file).expect("Should read log file");

            assert!(
                content.contains(correlation_id),
                "Log file {} should contain correlation ID",
                component.as_str()
            );
            assert!(
                content.contains(session_id),
                "Log file {} should contain session ID",
                component.as_str()
            );
        }
    }

    #[test]
    fn test_telemetry_data_completeness() {
        let temp_dir = tempdir().expect("Failed to create temp dir");
        let log_dir = temp_dir.path().to_path_buf();

        let logger = AdvancedLogger::new(&log_dir).expect("Failed to create logger");

        // Test GPU telemetry completeness
        logger.log_gpu_kernel("vector_add", 1250.5, 256.0, 512.0);
        logger.log_gpu_kernel("matrix_multiply", 3400.2, 1024.0, 2048.0);

        // Test memory telemetry completeness
        logger.log_memory_event("allocation", 128.5, 256.0);
        logger.log_memory_event("deallocation", 64.2, 192.0);

        // Test performance telemetry completeness
        logger.log_performance("agent_spawn", 45.8, Some(120.5));
        logger.log_performance("task_execution", 892.3, Some(89.2));

        // Test error telemetry completeness
        logger.log_gpu_error("CUDA out of memory", true);
        logger.log_structured(
            LogComponent::Error,
            Level::Error,
            "Agent coordination failed",
            Some(HashMap::from([
                ("agent_id".to_string(), json!("agent-123")),
                ("error_type".to_string(), json!("coordination_timeout")),
                ("recovery_action".to_string(), json!("restart_agent")),
            ])),
        );

        // Verify data completeness in each log file
        verify_gpu_log_completeness(&log_dir);
        verify_memory_log_completeness(&log_dir);
        verify_performance_log_completeness(&log_dir);
        verify_error_log_completeness(&log_dir);
    }

    #[test]
    fn test_position_fix_origin_clustering() {
        let temp_dir = tempdir().expect("Failed to create temp dir");
        let log_dir = temp_dir.path().to_path_buf();

        let logger = AdvancedLogger::new(&log_dir).expect("Failed to create logger");

        // Simulate position clustering issue and resolution
        let cluster_positions = vec![
            (0.0, 0.0, 0.0),      // Origin cluster issue
            (0.1, 0.1, 0.1),      // Near origin
            (100.0, 200.0, 50.0), // Properly dispersed
            (150.0, 180.0, 75.0), // Properly dispersed
        ];

        for (i, (x, y, z)) in cluster_positions.iter().enumerate() {
            let is_origin_cluster = *x < 1.0 && *y < 1.0 && *z < 1.0;

            let metadata = HashMap::from([
                ("agent_id".to_string(), json!(format!("agent-{}", i))),
                ("position_x".to_string(), json!(x)),
                ("position_y".to_string(), json!(y)),
                ("position_z".to_string(), json!(z)),
                (
                    "origin_cluster_detected".to_string(),
                    json!(is_origin_cluster),
                ),
                (
                    "clustering_fix_applied".to_string(),
                    json!(is_origin_cluster),
                ),
            ]);

            if is_origin_cluster {
                logger.log_structured(
                    LogComponent::Analytics,
                    Level::Warn,
                    "Origin clustering detected, applying position fix",
                    Some(metadata),
                );

                // Log the fix application
                let fix_metadata = HashMap::from([
                    ("agent_id".to_string(), json!(format!("agent-{}", i))),
                    (
                        "original_position".to_string(),
                        json!(format!("({}, {}, {})", x, y, z)),
                    ),
                    (
                        "corrected_position".to_string(),
                        json!(format!(
                            "({}, {}, {})",
                            x + 10.0 + (i as f64) * 5.0,
                            y + 15.0 + (i as f64) * 7.0,
                            z + 8.0 + (i as f64) * 3.0
                        )),
                    ),
                ]);

                logger.log_structured(
                    LogComponent::Analytics,
                    Level::Info,
                    "Position fix applied successfully",
                    Some(fix_metadata),
                );
            } else {
                logger.log_structured(
                    LogComponent::Analytics,
                    Level::Info,
                    "Agent position validated, no clustering issues",
                    Some(metadata),
                );
            }
        }

        // Verify position fix logging
        let analytics_log = log_dir.join("analytics.log");
        let content = fs::read_to_string(&analytics_log).expect("Should read analytics log");

        assert!(content.contains("Origin clustering detected"));
        assert!(content.contains("Position fix applied successfully"));
        assert!(content.contains("corrected_position"));
        assert!(content.contains("origin_cluster_detected"));
    }

    #[test]
    fn test_error_scenarios_and_recovery() {
        let temp_dir = tempdir().expect("Failed to create temp dir");
        let log_dir = temp_dir.path().to_path_buf();

        let logger = AdvancedLogger::new(&log_dir).expect("Failed to create logger");

        // Test various error scenarios
        test_gpu_memory_exhaustion_recovery(&logger);
        test_network_partition_recovery(&logger);
        test_agent_crash_recovery(&logger);
        test_log_file_corruption_recovery(&logger);

        // Verify error recovery logging
        let error_log = log_dir.join("error.log");
        let content = fs::read_to_string(&error_log).expect("Should read error log");

        assert!(content.contains("gpu_memory_exhausted"));
        assert!(content.contains("network_partition_detected"));
        assert!(content.contains("agent_crash_detected"));
        assert!(content.contains("recovery_successful"));
    }

    #[test]
    fn test_performance_impact_of_logging() {
        let temp_dir = tempdir().expect("Failed to create temp dir");
        let log_dir = temp_dir.path().to_path_buf();

        let logger = AdvancedLogger::new(&log_dir).expect("Failed to create logger");

        const NUM_OPERATIONS: usize = 1000;
        const MAX_ACCEPTABLE_OVERHEAD_MS: u128 = 50;

        // Measure baseline performance (without logging)
        let baseline_start = Instant::now();
        for i in 0..NUM_OPERATIONS {
            // Simulate computational work
            let _ = (i as f64).sqrt().sin().cos();
        }
        let baseline_duration = baseline_start.elapsed();

        // Measure performance with intensive logging
        let logging_start = Instant::now();
        for i in 0..NUM_OPERATIONS {
            // Same computational work
            let _ = (i as f64).sqrt().sin().cos();

            // Add logging
            if i % 10 == 0 {
                logger.log_performance(&format!("operation_{}", i), i as f64 * 0.1, Some(10.0));
            }
            if i % 50 == 0 {
                logger.log_gpu_kernel("test_kernel", i as f64 * 2.0, 64.0, 128.0);
            }
            if i % 100 == 0 {
                logger.log_memory_event("test_allocation", i as f64 * 0.5, i as f64 * 0.8);
            }
        }
        let logging_duration = logging_start.elapsed();

        let overhead = logging_duration.as_millis() - baseline_duration.as_millis();

        info!("Baseline duration: {:?}", baseline_duration);
        info!("Logging duration: {:?}", logging_duration);
        info!("Overhead: {} ms", overhead);

        assert!(
            overhead <= MAX_ACCEPTABLE_OVERHEAD_MS,
            "Logging overhead {} ms exceeds maximum acceptable {} ms",
            overhead,
            MAX_ACCEPTABLE_OVERHEAD_MS
        );
    }

    #[test]
    fn test_log_rotation_and_cleanup() {
        let temp_dir = tempdir().expect("Failed to create temp dir");
        let log_dir = temp_dir.path().to_path_buf();

        let logger = AdvancedLogger::new(&log_dir).expect("Failed to create logger");

        // Generate enough logs to trigger rotation
        let large_message = "A".repeat(1024 * 1024); // 1MB message

        for i in 0..60 {
            logger.log_structured(
                LogComponent::Server,
                Level::Info,
                &format!("{} - iteration {}", large_message, i),
                Some(HashMap::from([
                    ("iteration".to_string(), json!(i)),
                    ("size_mb".to_string(), json!(1.0)),
                ])),
            );

            // Small delay to ensure different timestamps
            thread::sleep(Duration::from_millis(10));
        }

        // Check if rotation occurred
        let archived_dir = log_dir.join("archived");
        assert!(archived_dir.exists(), "Archived directory should exist");

        let archived_files: Vec<_> = fs::read_dir(&archived_dir)
            .expect("Should read archived dir")
            .filter_map(|entry| entry.ok())
            .filter(|entry| entry.file_name().to_string_lossy().starts_with("server_"))
            .collect();

        assert!(!archived_files.is_empty(), "Should have archived log files");

        // Verify current log file still exists and is not too large
        let current_log = log_dir.join("server.log");
        assert!(current_log.exists(), "Current server.log should exist");

        let metadata = fs::metadata(&current_log).expect("Should get file metadata");
        let size_mb = metadata.len() / (1024 * 1024);
        assert!(
            size_mb < 50,
            "Current log file should be under rotation limit"
        );
    }

    // Helper functions for specific test scenarios
    fn test_agent_startup_logging(logger: &AdvancedLogger) {
        logger.log_structured(
            LogComponent::Server,
            Level::Info,
            "Agent system initializing",
            Some(HashMap::from([
                ("startup_phase".to_string(), json!("initialization")),
                ("agent_count".to_string(), json!(5)),
            ])),
        );
    }

    fn test_agent_execution_logging(logger: &AdvancedLogger) {
        logger.log_performance("agent_task_execution", 123.4, Some(89.5));
        logger.log_gpu_kernel("clustering_kernel", 2345.6, 512.0, 768.0);
        logger.log_memory_event("agent_memory_allocation", 256.0, 384.0);
    }

    fn test_agent_error_handling(logger: &AdvancedLogger) {
        logger.log_gpu_error("Agent GPU computation failed", true);
        logger.log_structured(
            LogComponent::Error,
            Level::Error,
            "Agent coordination timeout",
            Some(HashMap::from([
                ("agent_id".to_string(), json!("agent-456")),
                ("timeout_duration_ms".to_string(), json!(5000)),
            ])),
        );
    }

    fn test_agent_shutdown_logging(logger: &AdvancedLogger) {
        logger.log_structured(
            LogComponent::Server,
            Level::Info,
            "Agent system shutting down gracefully",
            Some(HashMap::from([
                ("shutdown_reason".to_string(), json!("user_requested")),
                ("cleanup_completed".to_string(), json!(true)),
            ])),
        );
    }

    fn test_gpu_memory_exhaustion_recovery(logger: &AdvancedLogger) {
        logger.log_gpu_error("GPU memory exhausted during kernel execution", false);
        logger.log_structured(
            LogComponent::Error,
            Level::Error,
            "GPU memory exhaustion detected",
            Some(HashMap::from([
                ("error_type".to_string(), json!("gpu_memory_exhausted")),
                ("recovery_strategy".to_string(), json!("reduce_batch_size")),
            ])),
        );
        logger.log_structured(
            LogComponent::GPU,
            Level::Info,
            "GPU recovery completed successfully",
            Some(HashMap::from([
                ("recovery_successful".to_string(), json!(true)),
                ("new_batch_size".to_string(), json!(512)),
            ])),
        );
    }

    fn test_network_partition_recovery(logger: &AdvancedLogger) {
        logger.log_structured(
            LogComponent::Network,
            Level::Error,
            "Network partition detected between agents",
            Some(HashMap::from([
                (
                    "error_type".to_string(),
                    json!("network_partition_detected"),
                ),
                (
                    "affected_agents".to_string(),
                    json!(["agent-1", "agent-2", "agent-3"]),
                ),
            ])),
        );
        logger.log_structured(
            LogComponent::Network,
            Level::Info,
            "Network partition recovered",
            Some(HashMap::from([
                ("recovery_successful".to_string(), json!(true)),
                ("reconnected_agents".to_string(), json!(3)),
            ])),
        );
    }

    fn test_agent_crash_recovery(logger: &AdvancedLogger) {
        logger.log_structured(
            LogComponent::Error,
            Level::Error,
            "Agent process crashed unexpectedly",
            Some(HashMap::from([
                ("error_type".to_string(), json!("agent_crash_detected")),
                ("agent_id".to_string(), json!("agent-789")),
                ("crash_reason".to_string(), json!("segmentation_fault")),
            ])),
        );
        logger.log_structured(
            LogComponent::Server,
            Level::Info,
            "Agent restarted successfully",
            Some(HashMap::from([
                ("recovery_successful".to_string(), json!(true)),
                ("restart_time_ms".to_string(), json!(1250)),
            ])),
        );
    }

    fn test_log_file_corruption_recovery(logger: &AdvancedLogger) {
        logger.log_structured(
            LogComponent::Error,
            Level::Error,
            "Log file corruption detected",
            Some(HashMap::from([
                ("error_type".to_string(), json!("log_file_corrupted")),
                ("affected_file".to_string(), json!("gpu.log")),
            ])),
        );
        logger.log_structured(
            LogComponent::Server,
            Level::Info,
            "New log file created after corruption",
            Some(HashMap::from([
                ("recovery_successful".to_string(), json!(true)),
                ("backup_created".to_string(), json!(true)),
            ])),
        );
    }

    fn verify_gpu_log_completeness(log_dir: &PathBuf) {
        let gpu_log = log_dir.join("gpu.log");
        let content = fs::read_to_string(&gpu_log).expect("Should read GPU log");

        // Verify required fields are present
        assert!(content.contains("vector_add"));
        assert!(content.contains("matrix_multiply"));
        assert!(content.contains("execution_time_us"));
        assert!(content.contains("memory_allocated_mb"));
        assert!(content.contains("memory_peak_mb"));
        assert!(content.contains("CUDA out of memory"));
    }

    fn verify_memory_log_completeness(log_dir: &PathBuf) {
        let memory_log = log_dir.join("memory.log");
        let content = fs::read_to_string(&memory_log).expect("Should read memory log");

        assert!(content.contains("allocation"));
        assert!(content.contains("deallocation"));
        assert!(content.contains("allocated_mb"));
        assert!(content.contains("peak_mb"));
    }

    fn verify_performance_log_completeness(log_dir: &PathBuf) {
        let perf_log = log_dir.join("performance.log");
        let content = fs::read_to_string(&perf_log).expect("Should read performance log");

        assert!(content.contains("agent_spawn"));
        assert!(content.contains("task_execution"));
        assert!(content.contains("duration_ms"));
        assert!(content.contains("throughput"));
    }

    fn verify_error_log_completeness(log_dir: &PathBuf) {
        let error_log = log_dir.join("error.log");
        let content = fs::read_to_string(&error_log).expect("Should read error log");

        assert!(content.contains("CUDA out of memory"));
        assert!(content.contains("Agent coordination failed"));
        assert!(content.contains("coordination_timeout"));
        assert!(content.contains("restart_agent"));
    }
}
