//! Configuration management for the retriever module
//!
//! Provides comprehensive configuration options for all retrieval components

use serde::{Deserialize, Serialize};\nuse std::time::Duration;\nuse crate::error::Result;\n\n/// Main configuration for the retriever system\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RetrieverConfig {\n    /// Vector index configuration\n    pub vector: VectorConfig,\n    \n    /// Graph traversal configuration\n    pub graph: GraphConfig,\n    \n    /// Query processing configuration\n    pub query: QueryConfig,\n    \n    /// Search configuration\n    pub search: SearchConfig,\n    \n    /// Ranking configuration\n    pub ranking: RankingConfig,\n    \n    /// Cache configuration\n    pub cache: CacheConfig,\n    \n    /// Context management configuration\n    pub context: ContextConfig,\n    \n    /// Performance configuration\n    pub performance: PerformanceConfig,\n    \n    /// Metrics configuration\n    pub metrics: MetricsConfig,\n}\n\n/// Vector index and embedding configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct VectorConfig {\n    /// Model path or identifier\n    pub model_path: String,\n    \n    /// Embedding dimension\n    pub dimension: usize,\n    \n    /// HNSW index parameters\n    pub hnsw: HnswConfig,\n    \n    /// Whether to use GPU acceleration\n    pub use_gpu: bool,\n    \n    /// Batch size for embedding generation\n    pub batch_size: usize,\n    \n    /// Maximum text length for embeddings\n    pub max_text_length: usize,\n    \n    /// Similarity threshold\n    pub similarity_threshold: f32,\n}\n\n/// HNSW index configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct HnswConfig {\n    /// Maximum connections per layer\n    pub m: usize,\n    \n    /// Size of dynamic candidate list\n    pub ef_construction: usize,\n    \n    /// Size of search dynamic list\n    pub ef_search: usize,\n    \n    /// Maximum number of layers\n    pub max_layers: usize,\n    \n    /// Level generation factor\n    pub ml: f64,\n}\n\n/// Graph traversal configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GraphConfig {\n    /// Maximum number of hops\n    pub max_hops: usize,\n    \n    /// Maximum nodes to explore per hop\n    pub max_nodes_per_hop: usize,\n    \n    /// Traversal strategy\n    pub strategy: TraversalStrategyConfig,\n    \n    /// Weight decay per hop\n    pub hop_decay: f32,\n    \n    /// Minimum relevance score to continue\n    pub min_relevance: f32,\n    \n    /// Whether to use bidirectional traversal\n    pub bidirectional: bool,\n    \n    /// Cycle detection enabled\n    pub cycle_detection: bool,\n}\n\n/// Traversal strategy configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum TraversalStrategyConfig {\n    BreadthFirst,\n    DepthFirst,\n    BestFirst { beam_width: usize },\n    Dijkstra,\n    AStar { heuristic_weight: f32 },\n    Hybrid { strategies: Vec<TraversalStrategyConfig> },\n}\n\n/// Query processing configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct QueryConfig {\n    /// Query expansion settings\n    pub expansion: ExpansionConfig,\n    \n    /// Query rewriting settings\n    pub rewriting: RewritingConfig,\n    \n    /// Maximum query length\n    pub max_length: usize,\n    \n    /// Preprocessing options\n    pub preprocessing: PreprocessingConfig,\n}\n\n/// Query expansion configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ExpansionConfig {\n    /// Enable expansion\n    pub enabled: bool,\n    \n    /// Number of expansion terms\n    pub num_terms: usize,\n    \n    /// Expansion strategies\n    pub strategies: Vec<ExpansionStrategy>,\n    \n    /// Minimum term frequency\n    pub min_frequency: f32,\n    \n    /// Maximum expansion ratio\n    pub max_expansion_ratio: f32,\n}\n\n/// Query expansion strategies\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum ExpansionStrategy {\n    Synonym,\n    WordNet,\n    Embedding { similarity_threshold: f32 },\n    CoOccurrence { window_size: usize },\n    Ngram { n: usize },\n}\n\n/// Query rewriting configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RewritingConfig {\n    /// Enable rewriting\n    pub enabled: bool,\n    \n    /// Rewriting strategies\n    pub strategies: Vec<RewritingStrategy>,\n    \n    /// Maximum rewrites per query\n    pub max_rewrites: usize,\n}\n\n/// Query rewriting strategies\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum RewritingStrategy {\n    Paraphrase,\n    Simplification,\n    TermSubstitution,\n    GrammarCorrection,\n    ConceptualExpansion,\n}\n\n/// Text preprocessing configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PreprocessingConfig {\n    /// Enable lowercasing\n    pub lowercase: bool,\n    \n    /// Enable stemming\n    pub stemming: bool,\n    \n    /// Remove stop words\n    pub remove_stopwords: bool,\n    \n    /// Unicode normalization\n    pub unicode_normalization: bool,\n    \n    /// Remove punctuation\n    pub remove_punctuation: bool,\n}\n\n/// Search configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SearchConfig {\n    /// Search strategies to use\n    pub strategies: Vec<SearchStrategy>,\n    \n    /// Maximum results per strategy\n    pub max_results_per_strategy: usize,\n    \n    /// Search timeout\n    pub timeout: Duration,\n    \n    /// Hybrid search configuration\n    pub hybrid: HybridSearchConfig,\n}\n\n/// Search strategies\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum SearchStrategy {\n    Vector { weight: f32 },\n    Keyword { weight: f32 },\n    Semantic { weight: f32 },\n    Graph { weight: f32 },\n}\n\n/// Hybrid search configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct HybridSearchConfig {\n    /// Fusion strategy\n    pub fusion_strategy: FusionStrategy,\n    \n    /// Normalization method\n    pub normalization: NormalizationMethod,\n    \n    /// Minimum score threshold\n    pub min_score: f32,\n}\n\n/// Result fusion strategies\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum FusionStrategy {\n    RankFusion,\n    ScoreFusion,\n    WeightedFusion { weights: Vec<f32> },\n    AdaptiveFusion,\n}\n\n/// Score normalization methods\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum NormalizationMethod {\n    MinMax,\n    ZScore,\n    Sigmoid,\n    Softmax,\n}\n\n/// Ranking configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RankingConfig {\n    /// Ranking model configuration\n    pub model: RankingModelConfig,\n    \n    /// Features to use for ranking\n    pub features: Vec<RankingFeature>,\n    \n    /// Re-ranking configuration\n    pub reranking: RerankingConfig,\n}\n\n/// Ranking model configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum RankingModelConfig {\n    BM25 { k1: f32, b: f32 },\n    TfIdf { normalization: bool },\n    LearnedRanking { model_path: String },\n    Ensemble { models: Vec<RankingModelConfig> },\n}\n\n/// Ranking features\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum RankingFeature {\n    TextSimilarity,\n    GraphDistance,\n    Popularity,\n    Recency,\n    Length,\n    QueryTermCoverage,\n    EntityDensity,\n}\n\n/// Re-ranking configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RerankingConfig {\n    /// Enable re-ranking\n    pub enabled: bool,\n    \n    /// Number of documents to re-rank\n    pub top_k: usize,\n    \n    /// Re-ranking model\n    pub model: String,\n    \n    /// Context-aware re-ranking\n    pub context_aware: bool,\n}\n\n/// Cache configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CacheConfig {\n    /// Enable caching\n    pub enabled: bool,\n    \n    /// Maximum cache size\n    pub max_size: usize,\n    \n    /// TTL for cache entries\n    pub ttl: Duration,\n    \n    /// Cache eviction policy\n    pub eviction_policy: EvictionPolicy,\n    \n    /// Cache warming settings\n    pub warming: CacheWarmingConfig,\n}\n\n/// Cache eviction policies\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum EvictionPolicy {\n    LRU,\n    LFU,\n    FIFO,\n    TTL,\n    Adaptive,\n}\n\n/// Cache warming configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CacheWarmingConfig {\n    /// Enable cache warming\n    pub enabled: bool,\n    \n    /// Warmup strategies\n    pub strategies: Vec<WarmupStrategy>,\n    \n    /// Warmup on startup\n    pub on_startup: bool,\n    \n    /// Background warmup\n    pub background: bool,\n}\n\n/// Cache warmup strategies\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum WarmupStrategy {\n    PopularQueries,\n    RecentQueries,\n    PredictedQueries,\n    RandomSampling,\n}\n\n/// Context management configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ContextConfig {\n    /// Maximum context window size\n    pub max_window_size: usize,\n    \n    /// Context assembly strategy\n    pub assembly_strategy: ContextAssemblyStrategy,\n    \n    /// Context overlap handling\n    pub overlap_handling: OverlapHandling,\n    \n    /// Context compression\n    pub compression: ContextCompressionConfig,\n}\n\n/// Context assembly strategies\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum ContextAssemblyStrategy {\n    Concatenation,\n    Hierarchical,\n    GraphBased,\n    Summarization,\n    Adaptive,\n}\n\n/// Context overlap handling\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum OverlapHandling {\n    Remove,\n    Merge,\n    Preserve,\n    Deduplicate,\n}\n\n/// Context compression configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ContextCompressionConfig {\n    /// Enable compression\n    pub enabled: bool,\n    \n    /// Compression strategy\n    pub strategy: CompressionStrategy,\n    \n    /// Compression ratio\n    pub ratio: f32,\n}\n\n/// Context compression strategies\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum CompressionStrategy {\n    Summarization,\n    KeySentences,\n    Clustering,\n    Abstractive,\n    Extractive,\n}\n\n/// Performance configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PerformanceConfig {\n    /// Number of parallel threads\n    pub num_threads: usize,\n    \n    /// Batch processing settings\n    pub batch: BatchConfig,\n    \n    /// Memory management\n    pub memory: MemoryConfig,\n    \n    /// Timeouts\n    pub timeouts: TimeoutConfig,\n}\n\n/// Batch processing configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct BatchConfig {\n    /// Default batch size\n    pub default_size: usize,\n    \n    /// Maximum batch size\n    pub max_size: usize,\n    \n    /// Adaptive batching\n    pub adaptive: bool,\n    \n    /// Batch timeout\n    pub timeout: Duration,\n}\n\n/// Memory management configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MemoryConfig {\n    /// Maximum memory usage (MB)\n    pub max_usage_mb: usize,\n    \n    /// Memory pool size\n    pub pool_size: usize,\n    \n    /// Garbage collection threshold\n    pub gc_threshold: f32,\n}\n\n/// Timeout configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TimeoutConfig {\n    /// Query processing timeout\n    pub query_processing: Duration,\n    \n    /// Search timeout\n    pub search: Duration,\n    \n    /// Graph traversal timeout\n    pub graph_traversal: Duration,\n    \n    /// Ranking timeout\n    pub ranking: Duration,\n    \n    /// Overall retrieval timeout\n    pub total: Duration,\n}\n\n/// Metrics configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MetricsConfig {\n    /// Enable metrics collection\n    pub enabled: bool,\n    \n    /// Metrics to collect\n    pub metrics: Vec<MetricType>,\n    \n    /// Reporting interval\n    pub reporting_interval: Duration,\n    \n    /// Metrics export configuration\n    pub export: MetricsExportConfig,\n}\n\n/// Types of metrics to collect\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum MetricType {\n    Latency,\n    Throughput,\n    Accuracy,\n    Memory,\n    CacheHitRate,\n    ErrorRate,\n    QualityScores,\n}\n\n/// Metrics export configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MetricsExportConfig {\n    /// Export format\n    pub format: ExportFormat,\n    \n    /// Export destination\n    pub destination: String,\n    \n    /// Export interval\n    pub interval: Duration,\n}\n\n/// Metrics export formats\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum ExportFormat {\n    Json,\n    Prometheus,\n    Csv,\n    Custom { format: String },\n}\n\nimpl Default for RetrieverConfig {\n    fn default() -> Self {\n        Self {\n            vector: VectorConfig::default(),\n            graph: GraphConfig::default(),\n            query: QueryConfig::default(),\n            search: SearchConfig::default(),\n            ranking: RankingConfig::default(),\n            cache: CacheConfig::default(),\n            context: ContextConfig::default(),\n            performance: PerformanceConfig::default(),\n            metrics: MetricsConfig::default(),\n        }\n    }\n}\n\nimpl Default for VectorConfig {\n    fn default() -> Self {\n        Self {\n            model_path: \"sentence-transformers/all-MiniLM-L6-v2\".to_string(),\n            dimension: 384,\n            hnsw: HnswConfig::default(),\n            use_gpu: false,\n            batch_size: 32,\n            max_text_length: 512,\n            similarity_threshold: 0.7,\n        }\n    }\n}\n\nimpl Default for HnswConfig {\n    fn default() -> Self {\n        Self {\n            m: 16,\n            ef_construction: 200,\n            ef_search: 50,\n            max_layers: 16,\n            ml: 1.0 / (2.0_f64).ln(),\n        }\n    }\n}\n\nimpl Default for GraphConfig {\n    fn default() -> Self {\n        Self {\n            max_hops: 3,\n            max_nodes_per_hop: 50,\n            strategy: TraversalStrategyConfig::BestFirst { beam_width: 10 },\n            hop_decay: 0.8,\n            min_relevance: 0.1,\n            bidirectional: true,\n            cycle_detection: true,\n        }\n    }\n}\n\nimpl Default for QueryConfig {\n    fn default() -> Self {\n        Self {\n            expansion: ExpansionConfig::default(),\n            rewriting: RewritingConfig::default(),\n            max_length: 1000,\n            preprocessing: PreprocessingConfig::default(),\n        }\n    }\n}\n\nimpl Default for ExpansionConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            num_terms: 5,\n            strategies: vec![\n                ExpansionStrategy::Synonym,\n                ExpansionStrategy::Embedding { similarity_threshold: 0.8 },\n            ],\n            min_frequency: 0.01,\n            max_expansion_ratio: 2.0,\n        }\n    }\n}\n\nimpl Default for RewritingConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            strategies: vec![\n                RewritingStrategy::Paraphrase,\n                RewritingStrategy::TermSubstitution,\n            ],\n            max_rewrites: 3,\n        }\n    }\n}\n\nimpl Default for PreprocessingConfig {\n    fn default() -> Self {\n        Self {\n            lowercase: true,\n            stemming: true,\n            remove_stopwords: true,\n            unicode_normalization: true,\n            remove_punctuation: false,\n        }\n    }\n}\n\nimpl Default for SearchConfig {\n    fn default() -> Self {\n        Self {\n            strategies: vec![\n                SearchStrategy::Vector { weight: 0.4 },\n                SearchStrategy::Keyword { weight: 0.3 },\n                SearchStrategy::Semantic { weight: 0.3 },\n            ],\n            max_results_per_strategy: 100,\n            timeout: Duration::from_secs(30),\n            hybrid: HybridSearchConfig::default(),\n        }\n    }\n}\n\nimpl Default for HybridSearchConfig {\n    fn default() -> Self {\n        Self {\n            fusion_strategy: FusionStrategy::RankFusion,\n            normalization: NormalizationMethod::MinMax,\n            min_score: 0.1,\n        }\n    }\n}\n\nimpl Default for RankingConfig {\n    fn default() -> Self {\n        Self {\n            model: RankingModelConfig::BM25 { k1: 1.2, b: 0.75 },\n            features: vec![\n                RankingFeature::TextSimilarity,\n                RankingFeature::GraphDistance,\n                RankingFeature::QueryTermCoverage,\n            ],\n            reranking: RerankingConfig::default(),\n        }\n    }\n}\n\nimpl Default for RerankingConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            top_k: 20,\n            model: \"cross-encoder/ms-marco-MiniLM-L-6-v2\".to_string(),\n            context_aware: true,\n        }\n    }\n}\n\nimpl Default for CacheConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            max_size: 10000,\n            ttl: Duration::from_secs(3600),\n            eviction_policy: EvictionPolicy::LRU,\n            warming: CacheWarmingConfig::default(),\n        }\n    }\n}\n\nimpl Default for CacheWarmingConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            strategies: vec![WarmupStrategy::PopularQueries],\n            on_startup: true,\n            background: true,\n        }\n    }\n}\n\nimpl Default for ContextConfig {\n    fn default() -> Self {\n        Self {\n            max_window_size: 4096,\n            assembly_strategy: ContextAssemblyStrategy::Hierarchical,\n            overlap_handling: OverlapHandling::Deduplicate,\n            compression: ContextCompressionConfig::default(),\n        }\n    }\n}\n\nimpl Default for ContextCompressionConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            strategy: CompressionStrategy::KeySentences,\n            ratio: 0.7,\n        }\n    }\n}\n\nimpl Default for PerformanceConfig {\n    fn default() -> Self {\n        Self {\n            num_threads: num_cpus::get(),\n            batch: BatchConfig::default(),\n            memory: MemoryConfig::default(),\n            timeouts: TimeoutConfig::default(),\n        }\n    }\n}\n\nimpl Default for BatchConfig {\n    fn default() -> Self {\n        Self {\n            default_size: 16,\n            max_size: 128,\n            adaptive: true,\n            timeout: Duration::from_millis(100),\n        }\n    }\n}\n\nimpl Default for MemoryConfig {\n    fn default() -> Self {\n        Self {\n            max_usage_mb: 2048,\n            pool_size: 1024,\n            gc_threshold: 0.8,\n        }\n    }\n}\n\nimpl Default for TimeoutConfig {\n    fn default() -> Self {\n        Self {\n            query_processing: Duration::from_secs(5),\n            search: Duration::from_secs(10),\n            graph_traversal: Duration::from_secs(15),\n            ranking: Duration::from_secs(5),\n            total: Duration::from_secs(30),\n        }\n    }\n}\n\nimpl Default for MetricsConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            metrics: vec![\n                MetricType::Latency,\n                MetricType::Throughput,\n                MetricType::CacheHitRate,\n                MetricType::ErrorRate,\n            ],\n            reporting_interval: Duration::from_secs(60),\n            export: MetricsExportConfig::default(),\n        }\n    }\n}\n\nimpl Default for MetricsExportConfig {\n    fn default() -> Self {\n        Self {\n            format: ExportFormat::Json,\n            destination: \"./metrics\".to_string(),\n            interval: Duration::from_secs(300),\n        }\n    }\n}\n\nimpl RetrieverConfig {\n    /// Load configuration from file\n    pub fn from_file<P: AsRef<std::path::Path>>(path: P) -> Result<Self> {\n        let content = std::fs::read_to_string(path)\n            .map_err(|e| crate::error::RetrieverError::config(format!(\"Failed to read config file: {}\", e)))?;\n        \n        let config: Self = serde_json::from_str(&content)\n            .map_err(|e| crate::error::RetrieverError::config(format!(\"Failed to parse config: {}\", e)))?;\n        \n        config.validate()?;\n        Ok(config)\n    }\n    \n    /// Save configuration to file\n    pub fn to_file<P: AsRef<std::path::Path>>(&self, path: P) -> Result<()> {\n        let content = serde_json::to_string_pretty(self)\n            .map_err(|e| crate::error::RetrieverError::config(format!(\"Failed to serialize config: {}\", e)))?;\n        \n        std::fs::write(path, content)\n            .map_err(|e| crate::error::RetrieverError::config(format!(\"Failed to write config file: {}\", e)))?;\n        \n        Ok(())\n    }\n    \n    /// Validate configuration\n    pub fn validate(&self) -> Result<()> {\n        // Validate vector config\n        if self.vector.dimension == 0 {\n            return Err(crate::error::RetrieverError::config(\"Vector dimension must be greater than 0\"));\n        }\n        \n        if self.vector.batch_size == 0 {\n            return Err(crate::error::RetrieverError::config(\"Batch size must be greater than 0\"));\n        }\n        \n        // Validate graph config\n        if self.graph.max_hops == 0 {\n            return Err(crate::error::RetrieverError::config(\"Max hops must be greater than 0\"));\n        }\n        \n        if self.graph.hop_decay <= 0.0 || self.graph.hop_decay > 1.0 {\n            return Err(crate::error::RetrieverError::config(\"Hop decay must be between 0 and 1\"));\n        }\n        \n        // Validate performance config\n        if self.performance.num_threads == 0 {\n            return Err(crate::error::RetrieverError::config(\"Number of threads must be greater than 0\"));\n        }\n        \n        if self.performance.batch.default_size > self.performance.batch.max_size {\n            return Err(crate::error::RetrieverError::config(\"Default batch size cannot exceed max batch size\"));\n        }\n        \n        // Validate context config\n        if self.context.max_window_size == 0 {\n            return Err(crate::error::RetrieverError::config(\"Context window size must be greater than 0\"));\n        }\n        \n        Ok(())\n    }\n    \n    /// Get configuration summary\n    pub fn summary(&self) -> String {\n        format!(\n            \"RetrieverConfig {{ vector_dim: {}, max_hops: {}, cache_enabled: {}, threads: {} }}\",\n            self.vector.dimension,\n            self.graph.max_hops,\n            self.cache.enabled,\n            self.performance.num_threads\n        )\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::Duration;\n    \n    #[test]\n    fn test_default_config() {\n        let config = RetrieverConfig::default();\n        assert!(config.validate().is_ok());\n        assert_eq!(config.vector.dimension, 384);\n        assert_eq!(config.graph.max_hops, 3);\n        assert!(config.cache.enabled);\n    }\n    \n    #[test]\n    fn test_config_validation() {\n        let mut config = RetrieverConfig::default();\n        \n        // Test invalid vector dimension\n        config.vector.dimension = 0;\n        assert!(config.validate().is_err());\n        \n        // Test invalid hop decay\n        config.vector.dimension = 384;\n        config.graph.hop_decay = 1.5;\n        assert!(config.validate().is_err());\n        \n        // Test valid config\n        config.graph.hop_decay = 0.8;\n        assert!(config.validate().is_ok());\n    }\n    \n    #[test]\n    fn test_config_serialization() {\n        let config = RetrieverConfig::default();\n        let json = serde_json::to_string(&config).unwrap();\n        let deserialized: RetrieverConfig = serde_json::from_str(&json).unwrap();\n        assert!(deserialized.validate().is_ok());\n    }\n}\n"