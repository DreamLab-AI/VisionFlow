diff --git a/.env_template b/.env_template
index 2deb6750..790fcda4 100755
--- a/.env_template
+++ b/.env_template
@@ -26,6 +26,7 @@ GITHUB_RATE_LIMIT=
 # RAGFlow Configuration
 RAGFLOW_API_KEY=
 RAGFLOW_API_BASE_URL=http://ragflowe-server/v1/
+RAGFLOW_AGENT_ID=
 RAGFLOW_TIMEOUT=30
 RAGFLOW_MAX_RETRIES=3
 
@@ -60,3 +61,13 @@ PERPLEXITY_ENABLED_PUBKEYS=         # Public keys with access to Perplexity API
 OPENAI_ENABLED_PUBKEYS=             # Public keys with access to OpenAI features
 RAGFLOW_ENABLED_PUBKEYS=            # Public keys with access to RAGFlow features
 
+# Kokoro TTS Configuration
+KOKORO_API_URL=http://pedantic_morse:8880
+KOKORO_DEFAULT_VOICE=af_heart
+KOKORO_DEFAULT_FORMAT=mp3
+KOKORO_DEFAULT_SPEED=1.0
+KOKORO_TIMEOUT=30
+KOKORO_STREAM=true
+KOKORO_RETURN_TIMESTAMPS=true
+KOKORO_SAMPLE_RATE=24000
+
diff --git a/Cargo.lock b/Cargo.lock
index fc3debc9..f14c21ba 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -3630,12 +3630,14 @@ dependencies = [
  "base64 0.22.1",
  "bytemuck",
  "byteorder",
+ "bytes",
  "chrono",
  "config",
  "cudarc",
  "dotenvy",
  "flate2",
  "futures",
+ "futures-util",
  "glam",
  "lazy_static",
  "log",
diff --git a/Cargo.toml b/Cargo.toml
index 332c5b1e..a22e4619 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -18,6 +18,7 @@ tokio-tungstenite = { version = "0.22" }
 # Async runtime
 tokio = { version = "1.43", features = ["full"] }
 futures = "0.3"
+futures-util = "0.3"
 async-trait = "0.1.86"
 
 # Serialization
@@ -63,6 +64,7 @@ sha1 = "0.10.6"
 scopeguard = "1.2"
 url = "2.5.0"
 flate2 = "1.0"
+bytes = "1.5"
 byteorder = "1.5"
 urlencoding = "2.1"
 
diff --git a/client/examples/speech-demo.html b/client/examples/speech-demo.html
new file mode 100644
index 00000000..2c67929e
--- /dev/null
+++ b/client/examples/speech-demo.html
@@ -0,0 +1,214 @@
+<!DOCTYPE html>
+<html lang="en">
+<head>
+    <meta charset="UTF-8">
+    <meta name="viewport" content="width=device-width, initial-scale=1.0">
+    <title>Speech Integration Demo</title>
+    <style>
+        body {
+            font-family: Arial, sans-serif;
+            max-width: 800px;
+            margin: 0 auto;
+            padding: 20px;
+        }
+        .demo-section {
+            margin-bottom: 30px;
+            padding: 20px;
+            border: 1px solid #ddd;
+            border-radius: 8px;
+        }
+        h1, h2 {
+            color: #333;
+        }
+        button {
+            background-color: #4CAF50;
+            border: none;
+            color: white;
+            padding: 10px 15px;
+            text-align: center;
+            text-decoration: none;
+            display: inline-block;
+            font-size: 16px;
+            margin: 10px 5px;
+            cursor: pointer;
+            border-radius: 4px;
+        }
+        button:disabled {
+            background-color: #cccccc;
+            cursor: not-allowed;
+        }
+        textarea {
+            width: 100%;
+            padding: 12px 20px;
+            margin: 8px 0;
+            box-sizing: border-box;
+            border: 2px solid #ccc;
+            border-radius: 4px;
+            resize: vertical;
+        }
+        .status {
+            padding: 10px;
+            margin-top: 10px;
+            border-radius: 4px;
+        }
+        .status.connected {
+            background-color: #dff0d8;
+            color: #3c763d;
+        }
+        .status.disconnected {
+            background-color: #f2dede;
+            color: #a94442;
+        }
+        .status.connecting {
+            background-color: #fcf8e3;
+            color: #8a6d3b;
+        }
+        .log-container {
+            margin-top: 20px;
+            height: 200px;
+            overflow-y: auto;
+            padding: 10px;
+            background-color: #f5f5f5;
+            border: 1px solid #ddd;
+            border-radius: 4px;
+        }
+        .log-entry {
+            margin: 5px 0;
+            font-family: monospace;
+        }
+    </style>
+</head>
+<body>
+    <h1>Speech Integration Demo</h1>
+    
+    <div class="demo-section">
+        <h2>Step 1: Initialize Audio</h2>
+        <p>Audio playback requires user interaction to start. Click the button below to initialize the audio player.</p>
+        <button id="initAudioBtn">Initialize Audio</button>
+        <div id="audioStatus" class="status disconnected">Audio not initialized</div>
+    </div>
+    
+    <div class="demo-section">
+        <h2>Step 2: Connect to Speech Service</h2>
+        <p>Connect to the WebSocket speech service to receive audio streams.</p>
+        <button id="connectBtn" disabled>Connect</button>
+        <div id="connectionStatus" class="status disconnected">Not connected</div>
+    </div>
+    
+    <div class="demo-section">
+        <h2>Step 3: Test TTS Directly</h2>
+        <p>Send text directly to the TTS service.</p>
+        <textarea id="directTtsText" rows="3" placeholder="Enter text to speak" disabled>Hello, I am the Kokoro text to speech service. How may I help you today?</textarea>
+        <button id="directTtsBtn" disabled>Speak Text</button>
+    </div>
+    
+    <div class="demo-section">
+        <h2>Step 4: Test RAGFlow with TTS</h2>
+        <p>Send a question to RAGFlow and receive both text and speech responses.</p>
+        <textarea id="ragflowText" rows="3" placeholder="Enter a question for RAGFlow" disabled>Tell me about the features of this graph visualization system.</textarea>
+        <button id="ragflowBtn" disabled>Ask RAGFlow</button>
+        <div id="ragflowResponse" class="status" style="display: none;"></div>
+    </div>
+    
+    <div class="log-container">
+        <h3>Log</h3>
+        <div id="logEntries"></div>
+    </div>
+
+    <script type="module">
+        // This is a placeholder for the actual implementation
+        // In a real application, you would import and use the actual speech-demo.ts module
+        import { 
+            initializeAudio, 
+            connectSpeechService,
+            sendDirectTTS,
+            sendRagflowWithTTS
+        } from './speech-demo.ts';
+
+        // Log function
+        function log(message) {
+            const logContainer = document.getElementById('logEntries');
+            const entry = document.createElement('div');
+            entry.className = 'log-entry';
+            entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
+            logContainer.appendChild(entry);
+            logContainer.scrollTop = logContainer.scrollHeight;
+        }
+
+        // Audio initialization
+        document.getElementById('initAudioBtn').addEventListener('click', function() {
+            try {
+                initializeAudio();
+                document.getElementById('audioStatus').textContent = 'Audio initialized';
+                document.getElementById('audioStatus').className = 'status connected';
+                document.getElementById('connectBtn').disabled = false;
+                log('Audio player initialized');
+            } catch (error) {
+                document.getElementById('audioStatus').textContent = 'Error initializing audio: ' + error.message;
+                log('Error initializing audio: ' + error.message);
+            }
+        });
+
+        // Connect to speech service
+        document.getElementById('connectBtn').addEventListener('click', function() {
+            try {
+                connectSpeechService();
+                document.getElementById('connectionStatus').textContent = 'Connecting...';
+                document.getElementById('connectionStatus').className = 'status connecting';
+                log('Connecting to speech service...');
+                
+                // For demo purposes, simulate connection success after 1 second
+                setTimeout(() => {
+                    document.getElementById('connectionStatus').textContent = 'Connected';
+                    document.getElementById('connectionStatus').className = 'status connected';
+                    document.getElementById('directTtsText').disabled = false;
+                    document.getElementById('directTtsBtn').disabled = false;
+                    document.getElementById('ragflowText').disabled = false;
+                    document.getElementById('ragflowBtn').disabled = false;
+                    log('Connected to speech service');
+                }, 1000);
+            } catch (error) {
+                document.getElementById('connectionStatus').textContent = 'Error connecting: ' + error.message;
+                log('Error connecting: ' + error.message);
+            }
+        });
+
+        // Direct TTS
+        document.getElementById('directTtsBtn').addEventListener('click', function() {
+            const text = document.getElementById('directTtsText').value;
+            if (text) {
+                log(`Sending TTS request: "${text}"`);
+                sendDirectTTS(text);
+            } else {
+                log('Please enter text to speak');
+            }
+        });
+
+        // RAGFlow with TTS
+        document.getElementById('ragflowBtn').addEventListener('click', async function() {
+            const question = document.getElementById('ragflowText').value;
+            if (question) {
+                log(`Sending RAGFlow question with TTS: "${question}"`);
+                document.getElementById('ragflowResponse').style.display = 'block';
+                document.getElementById('ragflowResponse').textContent = 'Processing...';
+                
+                try {
+                    // For demo purposes, simulate a RAGFlow response
+                    setTimeout(() => {
+                        document.getElementById('ragflowResponse').textContent = 
+                            'This graph visualization system features 3D rendering, physics-based layouts, and real-time collaboration. It supports VR/AR modes and can handle large datasets efficiently.';
+                        log('Received RAGFlow response and streaming audio');
+                    }, 1000);
+                    
+                    sendRagflowWithTTS(question);
+                } catch (error) {
+                    document.getElementById('ragflowResponse').textContent = 'Error: ' + error.message;
+                    log('Error with RAGFlow request: ' + error.message);
+                }
+            } else {
+                log('Please enter a question');
+            }
+        });
+    </script>
+</body>
+</html>
\ No newline at end of file
diff --git a/client/examples/speech-demo.ts b/client/examples/speech-demo.ts
new file mode 100644
index 00000000..504b5661
--- /dev/null
+++ b/client/examples/speech-demo.ts
@@ -0,0 +1,114 @@
+import { getSpeechWebSocketService, SpeechConnectionStatus } from '../services/SpeechWebSocketService';
+import { getAudioPlayer } from '../audio/AudioPlayer';
+
+/**
+ * This is a simple demo of the speech service integration with RAGFlow
+ * It demonstrates two approaches:
+ * 1. Using direct WebSocket communication with the speech service
+ * 2. Using the RAGFlow API with TTS enabled
+ */
+
+// Initialize the audio player
+const audioPlayer = getAudioPlayer();
+
+// First, ensure audio context is active (requires user interaction)
+function initializeAudio() {
+  audioPlayer.resume().catch(console.error);
+  console.log('Audio player initialized', audioPlayer.getState());
+}
+
+// Get the speech WebSocket service
+const speechService = getSpeechWebSocketService({
+  onStatusChange: (status) => {
+    console.log('Speech service status changed:', status);
+    
+    if (status === SpeechConnectionStatus.CONNECTED) {
+      console.log('Speech service connected, ready to use!');
+    }
+  }
+});
+
+// Connect to the speech service
+function connectSpeechService() {
+  speechService.connect();
+}
+
+// Send a direct TTS request through the WebSocket
+function sendDirectTTS(text: string) {
+  if (!speechService.isConnected()) {
+    console.error('Speech service not connected');
+    return;
+  }
+  
+  console.log('Sending direct TTS request:', text);
+  speechService.sendTTS(text);
+}
+
+// Use RAGFlow with TTS enabled
+async function sendRagflowWithTTS(question: string) {
+  const response = await fetch('/api/ragflow/message', {
+    method: 'POST',
+    headers: {
+      'Content-Type': 'application/json',
+    },
+    body: JSON.stringify({
+      question,
+      enable_tts: true,
+      stream: true
+    }),
+  });
+
+  console.log('RAGFlow request sent with TTS enabled');
+  
+  if (!response.ok) {
+    throw new Error(`RAGFlow request failed: ${response.statusText}`);
+  }
+  
+  // If streaming response, handle the stream
+  if (response.headers.get('content-type')?.includes('text/event-stream')) {
+    const reader = response.body!.getReader();
+    
+    while (true) {
+      const { done, value } = await reader.read();
+      if (done) break;
+      
+      // Process the chunk (text response)
+      const text = new TextDecoder().decode(value);
+      console.log('Received text chunk:', text);
+      
+      // Note: Audio will come through the speech WebSocket separately
+    }
+  } else {
+    // Handle non-streaming response
+    const data = await response.json();
+    console.log('Received complete response:', data);
+  }
+}
+
+// Usage example (to be called after user interaction):
+// 1. Initialize audio (requires user interaction)
+// document.getElementById('initButton')?.addEventListener('click', () => {
+//   initializeAudio();
+// });
+//
+// 2. Connect to speech service
+// document.getElementById('connectButton')?.addEventListener('click', () => {
+//   connectSpeechService();
+// });
+//
+// 3. Send a direct TTS request
+// document.getElementById('directTtsButton')?.addEventListener('click', () => {
+//   sendDirectTTS('This is a test of the direct TTS service.');
+// });
+//
+// 4. Send a RAGFlow request with TTS enabled
+// document.getElementById('ragflowTtsButton')?.addEventListener('click', () => {
+//   sendRagflowWithTTS('Tell me about the features of this graph visualization system.');
+// });
+
+export {
+  initializeAudio,
+  connectSpeechService,
+  sendDirectTTS,
+  sendRagflowWithTTS
+};
\ No newline at end of file
diff --git a/client/services/SpeechWebSocketService.ts b/client/services/SpeechWebSocketService.ts
new file mode 100644
index 00000000..cc12ebd9
--- /dev/null
+++ b/client/services/SpeechWebSocketService.ts
@@ -0,0 +1,203 @@
+import { getAudioPlayer } from '../audio/AudioPlayer';
+
+export interface SpeechWebSocketOptions {
+    url?: string;
+    autoReconnect?: boolean;
+    reconnectDelay?: number;
+    maxReconnectAttempts?: number;
+    onStatusChange?: (status: SpeechConnectionStatus) => void;
+}
+
+export enum SpeechConnectionStatus {
+    CONNECTING = 'connecting',
+    CONNECTED = 'connected',
+    DISCONNECTED = 'disconnected',
+    ERROR = 'error',
+}
+
+export interface TTSRequest {
+    type: 'tts';
+    text: string;
+    voice?: string;
+    speed?: number;
+    stream?: boolean;
+}
+
+export class SpeechWebSocketService {
+    private ws: WebSocket | null = null;
+    private status: SpeechConnectionStatus = SpeechConnectionStatus.DISCONNECTED;
+    private reconnectAttempts = 0;
+    private audioPlayer = getAudioPlayer();
+    
+    private options: Required<SpeechWebSocketOptions> = {
+        url: (location.protocol === 'https:' ? 'wss://' : 'ws://') + location.host + '/speech',
+        autoReconnect: true,
+        reconnectDelay: 3000,
+        maxReconnectAttempts: 5,
+        onStatusChange: () => {},
+    };
+
+    constructor(options: SpeechWebSocketOptions = {}) {
+        this.options = { ...this.options, ...options };
+    }
+
+    /**
+     * Connect to the speech WebSocket server
+     */
+    public connect(): void {
+        if (this.ws?.readyState === WebSocket.OPEN) {
+            console.log('WebSocket is already connected');
+            return;
+        }
+
+        this.setStatus(SpeechConnectionStatus.CONNECTING);
+        
+        try {
+            this.ws = new WebSocket(this.options.url);
+            
+            this.ws.onopen = this.handleOpen.bind(this);
+            this.ws.onclose = this.handleClose.bind(this);
+            this.ws.onerror = this.handleError.bind(this);
+            this.ws.onmessage = this.handleMessage.bind(this);
+            
+            console.log('Connecting to speech WebSocket at', this.options.url);
+        } catch (error) {
+            console.error('Failed to create WebSocket connection:', error);
+            this.setStatus(SpeechConnectionStatus.ERROR);
+            this.attemptReconnect();
+        }
+    }
+
+    /**
+     * Disconnect from the WebSocket server
+     */
+    public disconnect(): void {
+        if (this.ws) {
+            this.ws.close();
+            this.ws = null;
+        }
+    }
+
+    /**
+     * Send a text-to-speech request
+     */
+    public sendTTS(text: string, voice?: string, speed?: number, stream?: boolean): void {
+        if (!this.isConnected()) {
+            console.warn('Cannot send TTS request: WebSocket is not connected');
+            return;
+        }
+
+        const request: TTSRequest = {
+            type: 'tts',
+            text,
+            voice,
+            speed,
+            stream,
+        };
+
+        this.ws!.send(JSON.stringify(request));
+        console.log('Sent TTS request:', request);
+    }
+
+    /**
+     * Check if the WebSocket is connected
+     */
+    public isConnected(): boolean {
+        return this.ws !== null && this.ws.readyState === WebSocket.OPEN;
+    }
+
+    /**
+     * Get the current connection status
+     */
+    public getStatus(): SpeechConnectionStatus {
+        return this.status;
+    }
+
+    private handleOpen(_event: Event): void {
+        console.log('Speech WebSocket connection established');
+        this.setStatus(SpeechConnectionStatus.CONNECTED);
+        this.reconnectAttempts = 0;
+    }
+
+    private handleClose(event: CloseEvent): void {
+        console.log('Speech WebSocket connection closed:', event.code, event.reason);
+        this.setStatus(SpeechConnectionStatus.DISCONNECTED);
+        this.attemptReconnect();
+    }
+
+    private handleError(event: Event): void {
+        console.error('Speech WebSocket error:', event);
+        this.setStatus(SpeechConnectionStatus.ERROR);
+    }
+
+    private handleMessage(event: MessageEvent): void {
+        // Handle binary audio data
+        if (event.data instanceof ArrayBuffer) {
+            this.handleAudioData(event.data);
+            return;
+        }
+
+        // Handle JSON messages
+        try {
+            const message = JSON.parse(event.data);
+            console.log('Received speech message:', message);
+            
+            if (message.type === 'error') {
+                console.error('Speech service error:', message.message);
+            }
+        } catch (error) {
+            console.error('Failed to parse WebSocket message:', error);
+        }
+    }
+
+    private handleAudioData(data: ArrayBuffer): void {
+        console.log(`Received audio chunk: ${data.byteLength} bytes`);
+        
+        // Process the audio data through the AudioPlayer
+        this.audioPlayer.handleAudioChunk(data, false);
+    }
+
+    private attemptReconnect(): void {
+        if (!this.options.autoReconnect) {
+            return;
+        }
+
+        if (this.reconnectAttempts >= this.options.maxReconnectAttempts) {
+            console.log('Max reconnect attempts reached, giving up');
+            return;
+        }
+
+        this.reconnectAttempts++;
+        console.log(`Attempting to reconnect (${this.reconnectAttempts}/${this.options.maxReconnectAttempts}) in ${this.options.reconnectDelay}ms`);
+        
+        setTimeout(() => {
+            console.log('Reconnecting...');
+            this.connect();
+        }, this.options.reconnectDelay);
+    }
+
+    private setStatus(status: SpeechConnectionStatus): void {
+        if (this.status !== status) {
+            this.status = status;
+            this.options.onStatusChange(status);
+        }
+    }
+}
+
+// Create a singleton instance
+let instance: SpeechWebSocketService | null = null;
+
+export function getSpeechWebSocketService(options: SpeechWebSocketOptions = {}): SpeechWebSocketService {
+    if (!instance) {
+        instance = new SpeechWebSocketService(options);
+    }
+    return instance;
+}
+
+// Helper to clean up the service
+export function disposeSpeechWebSocketService(): void {
+    if (instance) {
+        instance.disconnect();
+        instance = null;
+    }
+}
\ No newline at end of file
diff --git a/docs/overview/architecture.md b/docs/overview/architecture.md
index 7fdd91e9..e4d0ed51 100644
--- a/docs/overview/architecture.md
+++ b/docs/overview/architecture.md
@@ -27,6 +27,7 @@ graph TB
     end
 
     subgraph Backend
+        PhysicsEngine[Continuous Physics Engine]
         Server[Actix Web Server]
         FileH[File Handler]
         GraphH[Graph Handler]
@@ -43,6 +44,7 @@ graph TB
         SpeechS[Speech Service]
         NostrS[Nostr Service]
         WSManager[WebSocket Manager]
+        ClientManager[Client Manager]
         GPUCompute[GPU Compute]
         Compression[Compression Utils]
         AudioProc[Audio Processor]
@@ -82,10 +84,13 @@ graph TB
 
     FileH --> FileS
     GraphH --> GraphS
-    WSH --> WSManager
+    WSH --> ClientManager
+    ClientManager --> WSManager
     PerplexityH --> PerplexityS
     RagFlowH --> RagFlowS
     NostrH --> NostrS
+    
+    GraphS --> PhysicsEngine --> ClientManager
 
     FileS --> GitHub
     PerplexityS --> Perplexity
@@ -123,7 +128,9 @@ graph TB
 - **PerplexityH (Perplexity Handler)**: Interfaces with the Perplexity AI service.
 - **RagFlowH (RagFlow Handler)**: Interfaces with the RAGFlow service.
 - **VisualizationH (Visualization Handler)**: Handles visualization-related requests.
+- **ClientManager**: Manages all connected WebSocket clients and broadcasts updates.
 - **NostrH (Nostr Handler)**: Manages Nostr authentication and user sessions.
+- **PhysicsEngine**: Continuously calculates force-directed layout independent of client connections.
 - **FileS (File Service)**: Provides file-related services.
 - **GraphS (Graph Service)**: Provides graph-related services.
 - **GPUS (GPU Compute Service)**: Manages GPU-accelerated computations.
@@ -143,7 +150,12 @@ graph TB
 
 For more detailed technical information, please refer to:
 - [Binary Protocol](../technical/binary-protocol.md)
+- [Decoupled Graph Architecture](../technical/decoupled-graph-architecture.md)
 - [Performance Optimizations](../technical/performance.md)
 - [Class Diagrams](../technical/class-diagrams.md)
-- [WebSockets Implementation](../technical/websockets.md)
-- [Graph Node Stacking Fix](../technical/graph-node-stacking-fix.md)
\ No newline at end of file
+- [WebSockets Implementation](../api/websocket-updated.md)
+- [Graph Node Stacking Fix](../technical/graph-node-stacking-fix.md)
+
+## Server Architecture
+
+The server now uses a continuous physics simulation system that pre-computes node positions independent of client connections. When clients connect, they receive the complete graph state and any ongoing updates. This architecture enables bidirectional synchronization of graph state between all connected clients.
\ No newline at end of file
diff --git a/settings.yaml b/settings.yaml
index 8f76d58a..aaa7c957 100644
--- a/settings.yaml
+++ b/settings.yaml
@@ -186,6 +186,7 @@ xr:
   portal_edge_width: 0.02
 ragflow:
   api_key: ''
+  agent_id: '302e58df9d4411ef929c0242ac120006'
   api_base_url: ''
   timeout: 30
   max_retries: 3
@@ -206,3 +207,12 @@ openai:
   base_url: ''
   timeout: 30
   rate_limit: 100
+kokoro:
+  api_url: 'http://pedantic_morse:8880'
+  default_voice: 'af_heart'
+  default_format: 'mp3'
+  default_speed: 1.0
+  timeout: 30
+  stream: true
+  return_timestamps: true
+  sample_rate: 24000
diff --git a/src/app_state.rs b/src/app_state.rs
index 33009f3c..8d1fad89 100755
--- a/src/app_state.rs
+++ b/src/app_state.rs
@@ -3,7 +3,9 @@ use tokio::sync::RwLock;
 use actix_web::web;
 use log::info;
 
+use crate::handlers::socket_flow_handler::ClientManager;
 use crate::config::Settings;
+use once_cell::sync::Lazy;
 use tokio::time::Duration;
 use crate::config::feature_access::FeatureAccess;
 use crate::models::metadata::MetadataStore;
@@ -11,6 +13,7 @@ use crate::models::protected_settings::{ProtectedSettings, ApiKeys, NostrUser};
 use crate::services::graph_service::GraphService;
 use crate::services::github::{GitHubClient, ContentAPI};
 use crate::services::perplexity_service::PerplexityService;
+use crate::services::speech_service::SpeechService;
 use crate::services::ragflow_service::RAGFlowService;
 use crate::services::nostr_service::NostrService;
 use crate::utils::gpu_compute::GPUCompute;
@@ -26,12 +29,18 @@ pub struct AppState {
     pub content_api: Arc<ContentAPI>,
     pub perplexity_service: Option<Arc<PerplexityService>>,
     pub ragflow_service: Option<Arc<RAGFlowService>>,
+    pub speech_service: Option<Arc<SpeechService>>,
     pub nostr_service: Option<web::Data<NostrService>>,
     pub feature_access: web::Data<FeatureAccess>,
-    pub ragflow_conversation_id: String,
+    pub ragflow_session_id: String,
     pub active_connections: Arc<AtomicUsize>,
+    // Client manager for tracking WebSocket connections
+    pub client_manager: Option<Arc<ClientManager>>,
 }
 
+// Static ClientManager for the app
+static APP_CLIENT_MANAGER: Lazy<Arc<ClientManager>> = Lazy::new(|| Arc::new(ClientManager::new()));
+
 impl AppState {
     pub async fn new(
         settings: Arc<RwLock<Settings>>,
@@ -39,8 +48,9 @@ impl AppState {
         content_api: Arc<ContentAPI>,
         perplexity_service: Option<Arc<PerplexityService>>,
         ragflow_service: Option<Arc<RAGFlowService>>,
+        speech_service: Option<Arc<SpeechService>>,
         gpu_compute: Option<Arc<RwLock<GPUCompute>>>,
-        ragflow_conversation_id: String,
+        ragflow_session_id: String,
     ) -> Result<Self, Box<dyn std::error::Error + Send + Sync>> {
         // Initialize GraphService with settings - log this as a major step
         info!("[AppState::new] Initializing GraphService");
@@ -48,7 +58,7 @@ impl AppState {
         // Add a short delay to ensure any previous physics loops have time to detect shutdown flags
         tokio::time::sleep(Duration::from_millis(50)).await;
         
-        let graph_service = GraphService::new(settings.clone(), gpu_compute.clone()).await;
+        let graph_service = GraphService::new(settings.clone(), gpu_compute.clone(), Some(APP_CLIENT_MANAGER.clone())).await;
         info!("[AppState::new] GraphService initialization complete");
         
         Ok(Self {
@@ -61,10 +71,12 @@ impl AppState {
             content_api,
             perplexity_service,
             ragflow_service,
+            speech_service,
             nostr_service: None,
             feature_access: web::Data::new(FeatureAccess::from_env()),
-            ragflow_conversation_id,
+            ragflow_session_id,
             active_connections: Arc::new(AtomicUsize::new(0)),
+            client_manager: Some(APP_CLIENT_MANAGER.clone()),
         })
     }
 
@@ -127,4 +139,11 @@ impl AppState {
     pub fn get_available_features(&self, pubkey: &str) -> Vec<String> {
         self.feature_access.get_available_features(pubkey)
     }
+    
+    // Ensure that a ClientManager exists, creating one if it doesn't
+    pub async fn ensure_client_manager(&self) -> Arc<ClientManager> {
+        // Always return the static client manager
+        // This avoids mutability issues since the App struct is often behind an immutable reference
+        APP_CLIENT_MANAGER.clone()
+    }
 }
diff --git a/src/config/mod.rs b/src/config/mod.rs
index 6c0c7d8c..fe56aea9 100644
--- a/src/config/mod.rs
+++ b/src/config/mod.rs
@@ -69,6 +69,7 @@ pub struct Settings {
     pub ragflow: RagFlowSettings,
     pub perplexity: PerplexitySettings,
     pub openai: OpenAISettings,
+    pub kokoro: KokoroSettings,
 }
 
 #[derive(Debug, Serialize, Deserialize, Clone, Default)]
@@ -287,9 +288,9 @@ pub struct XRSettings {
 pub struct RagFlowSettings {
     pub api_key: String,
     pub api_base_url: String,
+    pub agent_id: String,
     pub timeout: u64,
     pub max_retries: u32,
-    pub chat_id: String,
 }
 
 #[derive(Debug, Serialize, Deserialize, Clone)]
@@ -314,6 +315,18 @@ pub struct OpenAISettings {
     pub rate_limit: u32,
 }
 
+#[derive(Debug, Serialize, Deserialize, Clone)]
+pub struct KokoroSettings {
+    pub api_url: String,
+    pub default_voice: String,
+    pub default_format: String,
+    pub default_speed: f32,
+    pub timeout: u64,
+    pub stream: bool,
+    pub return_timestamps: bool,
+    pub sample_rate: u32,
+}
+
 impl Settings {
     pub fn new() -> Result<Self, ConfigError> {
         debug!("Initializing settings");
@@ -622,9 +635,9 @@ impl Default for Settings {
             ragflow: RagFlowSettings {
                 api_key: String::new(),
                 api_base_url: String::new(),
+                agent_id: String::new(),
                 timeout: 30,
                 max_retries: 3,
-                chat_id: String::new(),
             },
             perplexity: PerplexitySettings {
                 api_key: String::new(),
@@ -644,6 +657,16 @@ impl Default for Settings {
                 timeout: 30,
                 rate_limit: 100,
             },
+            kokoro: KokoroSettings {
+                api_url: "http://pedantic_morse:8880".to_string(), // Default URL based on Docker network
+                default_voice: "af_heart".to_string(),
+                default_format: "mp3".to_string(),
+                default_speed: 1.0,
+                timeout: 30,
+                stream: true,
+                return_timestamps: true,
+                sample_rate: 24000,
+            },
         }
     }
 }
diff --git a/src/handlers/mod.rs b/src/handlers/mod.rs
index 5663ec64..d1ed9bbd 100755
--- a/src/handlers/mod.rs
+++ b/src/handlers/mod.rs
@@ -5,4 +5,5 @@ pub mod perplexity_handler;
 pub mod ragflow_handler;
 pub mod settings_handler;
 pub mod socket_flow_handler;
+pub mod speech_socket_handler;
 pub mod nostr_handler;
diff --git a/src/handlers/perplexity_handler.rs b/src/handlers/perplexity_handler.rs
index 0e4ffcf6..2b272f9f 100755
--- a/src/handlers/perplexity_handler.rs
+++ b/src/handlers/perplexity_handler.rs
@@ -32,7 +32,7 @@ pub async fn handle_perplexity(
         }))
     };
 
-    let conversation_id = state.ragflow_conversation_id.clone();
+    let conversation_id = state.ragflow_session_id.clone();
     match perplexity_service.query(&request.query, &conversation_id).await {
         Ok(answer) => {
             let response = PerplexityResponse {
diff --git a/src/handlers/ragflow_handler.rs b/src/handlers/ragflow_handler.rs
index 06723155..10a9804b 100755
--- a/src/handlers/ragflow_handler.rs
+++ b/src/handlers/ragflow_handler.rs
@@ -1,33 +1,35 @@
 use actix_web::{web, HttpResponse, ResponseError, Responder};
 use crate::AppState;
 use serde::{Serialize, Deserialize};
-use log::error;
+use log::{error, info};
 use serde_json::json;
 use futures::StreamExt;
 use actix_web::web::Bytes;
 use crate::services::ragflow_service::RAGFlowError;
+use actix_web::web::ServiceConfig;
+use crate::types::speech::SpeechOptions;
 
 #[derive(Debug, Deserialize)]
 #[serde(rename_all = "camelCase")]
-pub struct InitChatRequest {
+pub struct CreateSessionRequest {
     pub user_id: String,
 }
 
 #[derive(Debug, Serialize)]
 #[serde(rename_all = "camelCase")]
-pub struct InitChatResponse {
+pub struct CreateSessionResponse {
     pub success: bool,
-    pub conversation_id: String,
+    pub session_id: String,
     pub message: Option<String>,
 }
 
 #[derive(Serialize, Deserialize)]
 #[serde(rename_all = "camelCase")]
 pub struct SendMessageRequest {
-    pub message: String,
-    pub quote: Option<bool>,
-    pub doc_ids: Option<Vec<String>>,
+    pub question: String,
     pub stream: Option<bool>,
+    pub session_id: Option<String>,
+    pub enable_tts: Option<bool>,
 }
 
 // Implement ResponseError for RAGFlowError
@@ -50,17 +52,62 @@ pub async fn send_message(
         }))
     };
 
-    let conversation_id = state.ragflow_conversation_id.clone();
+    // Get session ID from request or use the default one from app state if not provided
+    let session_id = match &request.session_id {
+        Some(id) => id.clone(),
+        None => state.ragflow_session_id.clone(),
+    };
+
+    let enable_tts = request.enable_tts.unwrap_or(false);
+    // The quote and doc_ids parameters are not used in the new API
     match ragflow_service.send_message(
-        conversation_id,
-        request.message.clone(),
-        request.quote.unwrap_or(false),
-        request.doc_ids.clone(),
-        request.stream.unwrap_or(false),
+        session_id,
+        request.question.clone(),
+        false, // quote parameter (unused)
+        None,  // doc_ids parameter (unused)
+        request.stream.unwrap_or(true),
     ).await {
         Ok(response_stream) => {
-            let mapped_stream = response_stream.map(|result| {
+            // Check if TTS is enabled and speech service exists
+            if enable_tts {
+                if let Some(speech_service) = &state.speech_service {
+                    let speech_service = speech_service.clone();
+                    // Clone the question to pass to TTS
+                    let question = request.question.clone();
+                    // Spawn a task to process TTS in the background
+                    actix_web::rt::spawn(async move {
+                        let speech_options = SpeechOptions::default();
+                        // The exact question will be sent to TTS
+                        if let Err(e) = speech_service.text_to_speech(question, speech_options).await {
+                            error!("Error processing TTS: {:?}", e);
+                        }
+                    });
+                }
+            }
+            
+            // Continue with normal text response handling
+            let enable_tts = enable_tts; // Clone for capture in closure
+            let mapped_stream = response_stream.map(move |result| {
                 result.map(|answer| {
+                    // Skip empty messages (like the end marker)
+                    if answer.is_empty() {
+                        return Bytes::new();
+                    }
+                    
+                    // If TTS is enabled, send answer to speech service
+                    if enable_tts {
+                        if let Some(speech_service) = &state.speech_service {
+                            let speech_service = speech_service.clone();
+                            let speech_options = SpeechOptions::default();
+                            let answer_clone = answer.clone();
+                            actix_web::rt::spawn(async move {
+                                if let Err(e) = speech_service.text_to_speech(answer_clone, speech_options).await {
+                                    error!("Error processing TTS for answer: {:?}", e);
+                                }
+                            });
+                        }
+                    }
+                    
                     let json_response = json!({
                         "answer": answer,
                         "success": true
@@ -80,10 +127,10 @@ pub async fn send_message(
     }
 }
 
-/// Handler for initiating a new chat conversation.
-pub async fn init_chat(
+/// Handler for initiating a new session with RAGFlow agent.
+pub async fn create_session(
     state: web::Data<AppState>,
-    request: web::Json<InitChatRequest>,
+    request: web::Json<CreateSessionRequest>,
 ) -> impl Responder {
     let user_id = request.user_id.clone();
     let ragflow_service = match &state.ragflow_service {
@@ -93,12 +140,24 @@ pub async fn init_chat(
         }))
     };
 
-    match ragflow_service.create_conversation(user_id.clone()).await {
-        Ok(conversation_id) => HttpResponse::Ok().json(InitChatResponse {
-            success: true,
-            conversation_id,
-            message: None,
-        }),
+    match ragflow_service.create_session(user_id.clone()).await {
+        Ok(session_id) => {
+            // Store the session ID in the AppState for future use
+            // We can't directly modify AppState through an Arc, but we can clone it and create a new state
+            // For now, we'll log this situation but not update the shared state
+            // In a production environment, you'd want a better solution like using RwLock for the session_id
+            info!(
+                "Created new RAGFlow session: {}. Note: session ID cannot be stored in shared AppState.",
+                session_id
+            );
+            // Use the session_id directly from the request in subsequent calls
+            
+            HttpResponse::Ok().json(CreateSessionResponse {
+                success: true,
+                session_id,
+                message: None,
+            })
+        },
         Err(e) => {
             error!("Failed to initialize chat: {}", e);
             HttpResponse::InternalServerError().json(json!({
@@ -108,12 +167,35 @@ pub async fn init_chat(
     }
 }
 
-/// Handler for retrieving chat history.
-pub async fn get_chat_history(
-    _state: web::Data<AppState>,
-    _conversation_id: web::Path<String>,
+/// Handler for retrieving session history.
+pub async fn get_session_history(
+    state: web::Data<AppState>,
+    session_id: web::Path<String>,
 ) -> impl Responder {
-    HttpResponse::NotImplemented().json(json!({
-        "message": "Chat history retrieval is not implemented"
-    }))
+    let ragflow_service = match &state.ragflow_service {
+        Some(service) => service,
+        None => return HttpResponse::ServiceUnavailable().json(json!({
+            "error": "RAGFlow service is not available"
+        }))
+    };
+
+    match ragflow_service.get_session_history(session_id.to_string()).await {
+        Ok(history) => HttpResponse::Ok().json(history),
+        Err(e) => {
+            error!("Failed to get session history: {}", e);
+            HttpResponse::InternalServerError().json(json!({
+                "error": format!("Failed to get chat history: {}", e)
+            }))
+        }
+    }
+}
+
+/// Configure RAGFlow API routes
+pub fn config(cfg: &mut ServiceConfig) {
+    cfg.service(
+        web::scope("/ragflow")
+            .route("/session", web::post().to(create_session))
+            .route("/message", web::post().to(send_message))
+            .route("/history/{session_id}", web::get().to(get_session_history))
+    );
 }
diff --git a/src/handlers/socket_flow_handler.rs b/src/handlers/socket_flow_handler.rs
index 2f28b871..92b26ba2 100644
--- a/src/handlers/socket_flow_handler.rs
+++ b/src/handlers/socket_flow_handler.rs
@@ -1,11 +1,12 @@
-use actix::prelude::*;
+use actix::{prelude::*, Actor, Handler, Message};
 use actix_web::{web, Error, HttpRequest, HttpResponse};
 use actix_web_actors::ws;
 use flate2::{write::ZlibEncoder, Compression};
 use log::{debug, error, info, warn};
 use std::io::Write;
-use std::sync::Arc;
 use std::collections::HashMap;
+use std::sync::Arc;
+use std::sync::atomic::{AtomicUsize, Ordering};
 use tokio::sync::RwLock;
 use std::time::Instant;
 
@@ -32,6 +33,79 @@ const DEFAULT_MOTION_DAMPING: f32 = 0.9;  // Smooth transitions in rate
 // Maximum value for u16 node IDs
 const MAX_U16_VALUE: u32 = 65535;
 
+/// ClientManager keeps track of all connected WebSocket clients
+/// and provides methods for broadcasting data to all clients
+#[derive(Debug)]
+pub struct ClientManager {
+    /// Map of client IDs to associated actor addresses
+    clients: RwLock<HashMap<usize, actix::Addr<SocketFlowServer>>>,
+    /// Counter for generating unique client IDs
+    next_id: AtomicUsize,
+}
+
+impl ClientManager {
+    /// Create a new ClientManager
+    pub fn new() -> Self {
+        Self {
+            clients: RwLock::new(HashMap::new()),
+            next_id: AtomicUsize::new(1),
+        }
+    }
+
+    /// Register a new client with the manager
+    pub async fn register(&self, addr: actix::Addr<SocketFlowServer>) -> usize {
+        let id = self.next_id.fetch_add(1, Ordering::SeqCst);
+        let mut clients = self.clients.write().await;
+        clients.insert(id, addr);
+        info!("[ClientManager] Registered new client: {} (total: {})", id, clients.len());
+        id
+    }
+
+    /// Unregister a client from the manager
+    pub async fn unregister(&self, id: usize) {
+        let mut clients = self.clients.write().await;
+        clients.remove(&id);
+        info!("[ClientManager] Unregistered client: {} (remaining: {})", id, clients.len());
+    }
+
+    /// Broadcast node positions to all connected clients
+    pub async fn broadcast_node_positions(&self, nodes: Vec<crate::utils::socket_flow_messages::Node>) {
+        if nodes.is_empty() {
+            return;
+        }
+
+        let clients = self.clients.read().await;
+        if clients.is_empty() {
+            return;
+        }
+
+        // Convert nodes to binary format
+        let binary_data = nodes.into_iter()
+            .filter_map(|node| {
+                // Parse node ID as u16 for binary protocol
+                node.id.parse::<u16>().ok().map(|id| (id, BinaryNodeData {
+                    position: node.data.position,
+                    velocity: node.data.velocity,
+                    mass: node.data.mass,
+                    flags: node.data.flags,
+                    padding: node.data.padding,
+                }))
+            })
+            .collect::<Vec<_>>();
+
+        // Send the update to all clients
+        for (id, addr) in clients.iter() {
+            addr.do_send(BroadcastPositionUpdate(binary_data.clone()));
+            debug!("[ClientManager] Sent position update to client {}", id);
+        }
+    }
+}
+
+/// Message type for broadcasting position updates to clients
+#[derive(Message, Clone)]
+#[rtype(result = "()")]
+pub struct BroadcastPositionUpdate(pub Vec<(u16, BinaryNodeData)>);
+
 pub struct SocketFlowServer {
     app_state: Arc<AppState>,
     settings: Arc<RwLock<crate::config::Settings>>,
@@ -61,11 +135,15 @@ pub struct SocketFlowServer {
     motion_damping: f32,       // Smoothing factor for rate changes
     nodes_in_motion: usize,    // Counter for nodes currently in motion
     total_node_count: usize,   // Total node count for percentage calculation
-    last_motion_check: Instant, // Last time we checked motion percentage
+    last_motion_check: Instant, // Last time we checked motion percentage,
+    // Client ID assigned by the ClientManager
+    client_id: Option<usize>,
+    // Reference to the ClientManager
+    client_manager: Option<Arc<ClientManager>>,
 }
 
 impl SocketFlowServer {
-    pub fn new(app_state: Arc<AppState>, settings: Arc<RwLock<crate::config::Settings>>) -> Self {
+    pub fn new(app_state: Arc<AppState>, settings: Arc<RwLock<crate::config::Settings>>, client_manager: Option<Arc<ClientManager>>) -> Self {
         // Get dynamic rate settings from config
         let min_update_rate = settings
             .try_read()
@@ -120,6 +198,8 @@ impl SocketFlowServer {
             nodes_in_motion: 0,
             total_node_count: 0,
             last_motion_check: Instant::now(),
+            client_id: None,
+            client_manager,
         }
     }
 
@@ -264,9 +344,26 @@ impl Actor for SocketFlowServer {
     type Context = ws::WebsocketContext<Self>;
 
     fn started(&mut self, ctx: &mut Self::Context) {
-        info!("[WebSocket] Client connected successfully");
+        // Register this client with the client manager
+        if let Some(client_manager) = &self.client_manager {
+            let addr = ctx.address();
+            let addr_clone = addr.clone(); // Clone the address before moving it
+            
+            // Use actix's runtime to avoid blocking in the actor's started method
+            let cm_clone = client_manager.clone();
+            actix::spawn(async move {
+                let client_id = cm_clone.register(addr_clone).await;
+                // Send a message back to the actor with its client ID
+                addr.do_send(SetClientId(client_id)); // This uses the original addr which is still valid
+            });
+        }
+    
+        info!("[WebSocket] New client connected");
         self.last_activity = std::time::Instant::now();
         
+        // We'll retrieve client ID asynchronously via message
+        self.client_id = None;
+        
         // Set up server-side heartbeat ping to keep connection alive
         if !self.heartbeat_timer_set {
             ctx.run_interval(std::time::Duration::from_secs(5), |act, ctx| {
@@ -299,12 +396,63 @@ impl Actor for SocketFlowServer {
         self.last_activity = std::time::Instant::now();
     }
 
-    fn stopped(&mut self, _: &mut Self::Context) {
-        info!("[WebSocket] Client disconnected");
+    fn stopped(&mut self, _ctx: &mut Self::Context) {
+        // Unregister this client when it disconnects
+        if let Some(client_id) = self.client_id {
+            if let Some(client_manager) = &self.client_manager {
+                let client_manager_clone = client_manager.clone();
+                actix::spawn(async move {
+                    client_manager_clone.unregister(client_id).await;
+                });
+            }
+            info!("[WebSocket] Client {} disconnected", client_id);
+        } else {
+            info!("[WebSocket] Unidentified client disconnected");
+        }
     }
 }
 
+// Message to set client ID after registration
+#[derive(Message)]
+#[rtype(result = "()")]
+struct SetClientId(usize);
+
+// Helper function to fetch nodes without borrowing from the actor
 // Helper function to fetch nodes without borrowing from the actor
+
+// Implement handler for BroadcastPositionUpdate message
+impl Handler<BroadcastPositionUpdate> for SocketFlowServer {
+    type Result = ();
+
+    fn handle(&mut self, msg: BroadcastPositionUpdate, ctx: &mut Self::Context) -> Self::Result {
+        if !msg.0.is_empty() {
+            // Encode the binary message
+            let binary_data = binary_protocol::encode_node_data(&msg.0);
+            
+            // Apply compression if needed
+            let compressed_data = self.maybe_compress(binary_data);
+            let final_data_size = compressed_data.len(); // Store the size before moving
+            
+            // Send to client
+            ctx.binary(compressed_data);
+            
+            // Debug logging - limit to avoid spamming logs
+            if self.should_log_update() {
+                debug!("[WebSocket] Broadcast update sent: {} nodes, {} bytes", msg.0.len(), final_data_size);
+            }
+        }
+    }
+}
+
+// Implement handler for SetClientId message
+impl Handler<SetClientId> for SocketFlowServer {
+    type Result = ();
+
+    fn handle(&mut self, msg: SetClientId, _ctx: &mut Self::Context) -> Self::Result {
+        self.client_id = Some(msg.0);
+        info!("[WebSocket] Client assigned ID: {}", msg.0);
+    }
+}
 async fn fetch_nodes(
     app_state: Arc<AppState>,
     settings: Arc<RwLock<crate::config::Settings>>
@@ -515,7 +663,7 @@ impl StreamHandler<Result<ws::Message, ws::ProtocolError>> for SocketFlowServer
                     let _settings_clone = act.settings.clone();
                                                 ctx.run_later(next_interval, move |act, ctx| {
                                                     // Recursively call the handler to restart the cycle
-                                                    act.handle(Ok(ws::Message::Text("{\"type\":\"requestInitialData\"}".to_string().into())), ctx);
+                                                    <SocketFlowServer as StreamHandler<Result<ws::Message, ws::ProtocolError>>>::handle(act, Ok(ws::Message::Text("{\"type\":\"requestInitialData\"}".to_string().into())), ctx);
                                                 });
                                                 
                                                 // Log performance metrics periodically
@@ -734,8 +882,11 @@ pub async fn socket_flow_handler(
     req: HttpRequest,
     stream: web::Payload,
     app_state: web::Data<AppState>,
-    settings: web::Data<Arc<RwLock<crate::config::Settings>>>,
+    settings: web::Data<Arc<RwLock<crate::config::Settings>>>
 ) -> Result<HttpResponse, Error> {
+    // Ensure ClientManager exists in app_state or create it if not present
+    let client_manager = app_state.ensure_client_manager().await;
+
     let should_debug = settings.try_read().map(|s| {
         s.system.debug.enabled && s.system.debug.enable_websocket_debug
     }).unwrap_or(false);
@@ -749,7 +900,7 @@ pub async fn socket_flow_handler(
         return Ok(HttpResponse::BadRequest().body("WebSocket upgrade required"));
     }
 
-    let ws = SocketFlowServer::new(app_state.into_inner(), settings.get_ref().clone());
+    let ws = SocketFlowServer::new(app_state.into_inner(), settings.get_ref().clone(), Some(client_manager));
 
     match ws::start(ws, &req, stream) {
         Ok(response) => {
diff --git a/src/handlers/speech_socket_handler.rs b/src/handlers/speech_socket_handler.rs
new file mode 100644
index 00000000..863eb439
--- /dev/null
+++ b/src/handlers/speech_socket_handler.rs
@@ -0,0 +1,228 @@
+use actix::prelude::*;
+use actix_web::{web, Error, HttpRequest, HttpResponse};
+use actix_web_actors::ws;
+use log::{debug, error, info};
+use std::sync::Arc;
+use std::time::{Duration, Instant};
+use serde::{Deserialize, Serialize};
+use serde_json::json;
+use crate::app_state::AppState;
+use crate::types::speech::SpeechOptions;
+use tokio::sync::broadcast;
+use futures::FutureExt;
+
+// Constants for heartbeat
+const HEARTBEAT_INTERVAL: Duration = Duration::from_secs(5);
+const CLIENT_TIMEOUT: Duration = Duration::from_secs(10);
+
+// Define message types
+#[derive(Debug, Serialize, Deserialize)]
+#[serde(rename_all = "camelCase")]
+struct TextToSpeechRequest {
+    text: String,
+    voice: Option<String>,
+    speed: Option<f32>,
+    stream: Option<bool>,
+}
+
+#[derive(Debug, Serialize, Deserialize)]
+#[serde(rename_all = "camelCase")]
+struct SetProviderRequest {
+    provider: String,
+}
+
+pub struct SpeechSocket {
+    id: String,
+    app_state: Arc<AppState>,
+    heartbeat: Instant,
+    audio_rx: Option<broadcast::Receiver<Vec<u8>>>,
+}
+
+impl SpeechSocket {
+    pub fn new(id: String, app_state: Arc<AppState>) -> Self {
+        let audio_rx = if let Some(speech_service) = &app_state.speech_service {
+            Some(speech_service.subscribe_to_audio())
+        } else {
+            None
+        };
+
+        Self {
+            id,
+            app_state,
+            heartbeat: Instant::now(),
+            audio_rx,
+        }
+    }
+    
+    // Helper method to handle heartbeat
+    fn start_heartbeat(&self, ctx: &mut ws::WebsocketContext<Self>) {
+        ctx.run_interval(HEARTBEAT_INTERVAL, |act, ctx| {
+            if Instant::now().duration_since(act.heartbeat) > CLIENT_TIMEOUT {
+                info!("SpeechSocket client heartbeat failed, disconnecting!");
+                ctx.stop();
+                return;
+            }
+            ctx.ping(b"");
+        });
+    }
+    
+    // Process text-to-speech request
+    async fn process_tts_request(app_state: Arc<AppState>, req: TextToSpeechRequest) -> Result<(), String> {
+        if let Some(speech_service) = &app_state.speech_service {
+            // Get default settings from app state
+            let settings = app_state.settings.read().await;
+            let default_voice = settings.kokoro.default_voice.clone();
+            let default_speed = settings.kokoro.default_speed;
+            let default_stream = settings.kokoro.stream;
+            drop(settings);
+            
+            // Create options with defaults or provided values
+            let options = SpeechOptions {
+                voice: req.voice.unwrap_or(default_voice),
+                speed: req.speed.unwrap_or(default_speed),
+                stream: req.stream.unwrap_or(default_stream),
+            };
+            
+            // Send request to TTS service
+            match speech_service.text_to_speech(req.text, options).await {
+                Ok(_) => Ok(()),
+                Err(e) => Err(format!("Failed to process TTS request: {}", e)),
+            }
+        } else {
+            Err("Speech service is not available".to_string())
+        }
+    }
+}
+
+impl Actor for SpeechSocket {
+    type Context = ws::WebsocketContext<Self>;
+
+    fn started(&mut self, ctx: &mut Self::Context) {
+        info!("[SpeechSocket] Client connected: {}", self.id);
+        
+        // Start heartbeat
+        self.start_heartbeat(ctx);
+        
+        // Send welcome message
+        let welcome = json!({
+            "type": "connected",
+            "message": "Connected to speech service"
+        });
+        
+        ctx.text(welcome.to_string());
+        
+        // Start listening for audio data
+        if let Some(mut rx) = self.audio_rx.take() {
+            let addr = ctx.address();
+            
+            ctx.spawn(Box::pin(async move {
+                while let Ok(audio_data) = rx.recv().await {
+                    // Send audio data to the client
+                    if addr.try_send(AudioChunkMessage(audio_data)).is_err() {
+                        break;
+                    }
+                }
+            }.into_actor(self)));
+        }
+    }
+}
+
+// Message type for audio data
+struct AudioChunkMessage(Vec<u8>);
+
+impl Message for AudioChunkMessage {
+    type Result = ();
+}
+
+impl Handler<AudioChunkMessage> for SpeechSocket {
+    type Result = ();
+
+    fn handle(&mut self, msg: AudioChunkMessage, ctx: &mut Self::Context) -> Self::Result {
+        // Send binary audio data to the client
+        ctx.binary(msg.0);
+    }
+}
+
+impl StreamHandler<Result<ws::Message, ws::ProtocolError>> for SpeechSocket {
+    fn handle(&mut self, msg: Result<ws::Message, ws::ProtocolError>, ctx: &mut Self::Context) {
+        match msg {
+            Ok(ws::Message::Ping(msg)) => {
+                self.heartbeat = Instant::now();
+                ctx.pong(&msg);
+            }
+            Ok(ws::Message::Pong(_)) => {
+                self.heartbeat = Instant::now();
+            }
+            Ok(ws::Message::Text(text)) => {
+                debug!("[SpeechSocket] Received text: {}", text);
+                self.heartbeat = Instant::now();
+                
+                // Parse the message
+                match serde_json::from_str::<serde_json::Value>(&text) {
+                    Ok(msg) => {
+                        // Process based on message type
+                        let msg_type = msg.get("type").and_then(|t| t.as_str());
+                        match msg_type {
+                            Some("tts") => {
+                                // Parse as TextToSpeechRequest
+                                if let Ok(tts_req) = serde_json::from_value::<TextToSpeechRequest>(msg) {
+                                    // Process TTS request
+                                    let app_state = self.app_state.clone();
+                                    let fut = Self::process_tts_request(app_state, tts_req).boxed().into_actor(self);
+                                    ctx.spawn(fut.map(|result, _, ctx| {
+                                        if let Err(e) = result {
+                                            let error_msg = json!({
+                                                "type": "error",
+                                                "message": e
+                                            });
+                                            ctx.text(error_msg.to_string());
+                                        }
+                                    }));
+                                } else {
+                                    ctx.text(json!({"type": "error", "message": "Invalid TTS request format"}).to_string());
+                                }
+                            }
+                            _ => {
+                                ctx.text(json!({"type": "error", "message": "Unknown message type"}).to_string());
+                            }
+                        }
+                    }
+                    Err(e) => {
+                        ctx.text(json!({"type": "error", "message": format!("Invalid JSON: {}", e)}).to_string());
+                    }
+                }
+            }
+            Ok(ws::Message::Binary(_)) => {
+                // Binary data from client not supported in this handler
+                ctx.text(json!({"type": "error", "message": "Binary data not supported"}).to_string());
+            }
+            Ok(ws::Message::Close(reason)) => {
+                info!("[SpeechSocket] Client disconnected: {}", self.id);
+                ctx.close(reason);
+                ctx.stop();
+            }
+            _ => (),
+        }
+    }
+}
+
+// Handler for the WebSocket route
+pub async fn speech_socket_handler(
+    req: HttpRequest,
+    stream: web::Payload,
+    app_state: web::Data<AppState>,
+) -> Result<HttpResponse, Error> {
+    let socket_id = format!("speech_{}", uuid::Uuid::new_v4());
+    let socket = SpeechSocket::new(socket_id, app_state.into_inner());
+    
+    match ws::start(socket, &req, stream) {
+        Ok(response) => {
+            info!("[SpeechSocket] WebSocket connection established");
+            Ok(response)
+        }
+        Err(e) => {
+            error!("[SpeechSocket] Failed to start WebSocket: {}", e);
+            Err(e)
+        }
+    }
+}
\ No newline at end of file
diff --git a/src/main.rs b/src/main.rs
index 30bdd1c1..0e9d98f4 100755
--- a/src/main.rs
+++ b/src/main.rs
@@ -6,6 +6,7 @@ use webxr::{
         health_handler,
         pages_handler,
         socket_flow_handler::socket_flow_handler,
+        speech_socket_handler::speech_socket_handler,
         nostr_handler,
     },
     services::{
@@ -13,7 +14,8 @@ use webxr::{
         graph_service::GraphService,
         github::{GitHubClient, ContentAPI, GitHubConfig},
     },
-    utils::gpu_compute::GPUCompute
+    utils::gpu_compute::GPUCompute,
+    services::speech_service::SpeechService,
 };
 
 use actix_web::{web, App, HttpServer, middleware};
@@ -79,14 +81,20 @@ async fn main() -> std::io::Result<()> {
     let content_api = Arc::new(ContentAPI::new(github_client.clone()));
 
     // Initialize app state asynchronously
+    // Initialize speech service
+    let speech_service = {
+        let service = SpeechService::new(settings.clone());
+        Some(Arc::new(service))
+    };
+    
     let mut app_state = match AppState::new(
             settings.clone(),
             github_client.clone(),
             content_api.clone(),
             None,
             None,
-            None,
-            "default_conversation".to_string(),
+            speech_service,
+            None, "default_session".to_string()
         ).await {
             Ok(state) => state,
             Err(e) => return Err(std::io::Error::new(std::io::ErrorKind::Other, format!("Failed to initialize app state: {}", e)))
@@ -127,6 +135,10 @@ async fn main() -> std::io::Result<()> {
 
     // Build initial graph from metadata and initialize GPU compute
     info!("Building initial graph from existing metadata for physics simulation");
+    
+    // Create the ClientManager that will be shared between GraphService and WebSocket handlers
+    let client_manager = app_state.ensure_client_manager().await;
+    
     match GraphService::build_graph_from_metadata(&metadata_store).await {
         Ok(graph_data) => {            
             // Initialize GPU compute if not already done
@@ -151,7 +163,8 @@ async fn main() -> std::io::Result<()> {
                         info!("Reinitializing graph service with GPU compute");
                         app_state.graph_service = GraphService::new(
                             settings.clone(), 
-                            app_state.gpu_compute.clone()
+                            app_state.gpu_compute.clone(),
+                            Some(client_manager.clone())
                         ).await;
                         
                         info!("Graph service successfully reinitialized with GPU compute");
@@ -164,7 +177,8 @@ async fn main() -> std::io::Result<()> {
         // Initialize graph service with None as GPU compute (will use CPU fallback)
                         app_state.graph_service = GraphService::new(
                             settings.clone(), 
-                            None
+                            None,
+                            Some(client_manager.clone())
                         ).await;
                         
                         info!("Graph service initialized with CPU fallback");
@@ -199,6 +213,11 @@ async fn main() -> std::io::Result<()> {
     info!("Waiting for initial physics layout calculation to complete...");
     tokio::time::sleep(Duration::from_millis(500)).await;
     info!("Initial delay complete. Starting HTTP server...");
+    
+    // Start the broadcast loop to share position updates with all clients
+    info!("Starting position broadcast loop for client synchronization...");
+    app_state.graph_service.start_broadcast_loop();
+    info!("Position broadcast loop started");
 
     // Create web::Data after all initialization is complete
     let app_state_data = web::Data::new(app_state);
@@ -231,6 +250,7 @@ async fn main() -> std::io::Result<()> {
             .app_data(app_state_data.nostr_service.clone().unwrap())
             .app_data(app_state_data.feature_access.clone())
             .route("/wss", web::get().to(socket_flow_handler))
+            .route("/speech", web::get().to(speech_socket_handler))
             .service(
                 web::scope("")
                     .configure(api_handler::config)
diff --git a/src/services/graph_service.rs b/src/services/graph_service.rs
index 41082b88..d81f1da1 100755
--- a/src/services/graph_service.rs
+++ b/src/services/graph_service.rs
@@ -5,6 +5,7 @@ use std::collections::{HashMap, HashSet};
 use actix_web::web;
 use rand::distributions::{Alphanumeric, DistString};
 use rand::Rng;
+use rand::seq::SliceRandom;
 use std::io::{Error, ErrorKind};
 use serde_json;
 use std::pin::Pin;
@@ -22,7 +23,9 @@ use crate::app_state::AppState;
 use crate::config::Settings;
 use crate::utils::gpu_compute::GPUCompute;
 use crate::models::simulation_params::{SimulationParams, SimulationPhase, SimulationMode};
+use crate::handlers::socket_flow_handler::ClientManager;
 use crate::models::pagination::PaginatedGraphData;
+use crate::types::vec3::Vec3Data;
 use tokio::sync::Mutex;
 use once_cell::sync::Lazy;
 
@@ -37,6 +40,11 @@ static SIMULATION_LOOP_RUNNING: AtomicBool = AtomicBool::new(false);
 // while an old one is being shut down
 static SIMULATION_MUTEX: Lazy<Mutex<String>> = Lazy::new(|| Mutex::new(String::new()));
 
+
+// Physics simulation constants for independent processing
+const CONTINUOUS_SIMULATION_INTERVAL_MS: u64 = 16; // ~60fps
+const STABLE_THRESHOLD_ITERATIONS: usize = 100; // Number of iterations with minimal movement to consider graph stable
+
 // Cache configuration
 const NODE_POSITION_CACHE_TTL_MS: u64 = 50; // 50ms cache time
 const METADATA_FILE_WAIT_TIMEOUT_MS: u64 = 5000; // 5 second wait timeout
@@ -53,17 +61,20 @@ pub struct GraphService {
     node_positions_cache: Arc<RwLock<Option<(Vec<Node>, Instant)>>>,
     cache_enabled: bool,
     simulation_id: String,
+    client_manager: Option<Arc<ClientManager>>,
+    is_initialized: Arc<AtomicBool>,
+    is_physics_stable: Arc<AtomicBool>,
     shutdown_requested: Arc<AtomicBool>,
 }
 
 impl GraphService {
-    pub async fn new(settings: Arc<RwLock<Settings>>, gpu_compute: Option<Arc<RwLock<GPUCompute>>>) -> Self {
+    pub async fn new(settings: Arc<RwLock<Settings>>, gpu_compute: Option<Arc<RwLock<GPUCompute>>>, client_manager: Option<Arc<ClientManager>>) -> Self {
         // Get physics settings
         let physics_settings = settings.read().await.visualization.physics.clone();
 
         // Generate a unique ID for this GraphService instance
         let simulation_id = Alphanumeric.sample_string(&mut rand::thread_rng(), 8);
-        info!("[GraphService::new] Creating new GraphService instance with ID: {}", simulation_id);
+        info!("[GraphService::new] Creating independent GraphService instance with ID: {}", simulation_id);
         
         // Acquire the mutex to ensure exclusive access during initialization
         let mut guard = SIMULATION_MUTEX.lock().await;
@@ -79,7 +90,7 @@ impl GraphService {
         let node_map = Arc::new(RwLock::new(HashMap::new()));
 
         if gpu_compute.is_some() {
-            info!("[GraphService] GPU compute is enabled - physics simulation will run");
+            info!("[GraphService] GPU compute is enabled - continuous physics simulation will run");
             info!("[GraphService] Testing GPU compute functionality at startup");
             tokio::spawn(Self::test_gpu_at_startup(gpu_compute.clone()));
         } else {
@@ -90,15 +101,36 @@ impl GraphService {
         let shutdown_requested = Arc::new(AtomicBool::new(false));
         // Create the GraphService with caching enabled 
         let _cache = Arc::new(RwLock::new(Option::<(Vec<Node>, Instant)>::None));
+        
+        // Create atomic flags for graph status tracking
+        let is_initialized = Arc::new(AtomicBool::new(false));
+        let is_physics_stable = Arc::new(AtomicBool::new(false));
+        
         let graph_service = Self {
             graph_data: Arc::new(RwLock::new(GraphData::default())),
             node_map: node_map.clone(),
             gpu_compute,
             node_positions_cache: Arc::new(RwLock::new(None)),
             cache_enabled: true,
+            client_manager,
+            is_initialized: is_initialized.clone(),
+            is_physics_stable: is_physics_stable.clone(),
             simulation_id: simulation_id.clone(),
             shutdown_requested: shutdown_requested.clone(),
         };
+
+        // Initialize the graph data from metadata if available
+        // This runs immediately on startup, before any clients connect
+        let graph_service_clone = graph_service.clone();
+        tokio::spawn(async move {
+            // Allow a small delay for other systems to initialize
+            tokio::time::sleep(Duration::from_millis(500)).await;
+            info!("[GraphService] Starting initial graph initialization");
+            
+            if let Err(e) = graph_service_clone.initialize_graph().await {
+                error!("[GraphService] Failed to initialize graph data: {}", e);
+            }
+        });
         
         // Prepare for simulation loop
         let graph_data = Arc::clone(&graph_service.graph_data);
@@ -135,10 +167,11 @@ impl GraphService {
         // Release the mutex before spawning the task
         drop(guard);
         
-        info!("[GraphService] Starting physics simulation loop (ID: {})", loop_simulation_id);
+        info!("[GraphService] Starting continuous physics simulation loop (ID: {})", loop_simulation_id);
         tokio::spawn(async move {
+            // Configure simulation parameters
             let params = SimulationParams {
-                iterations: physics_settings.iterations,
+                iterations: physics_settings.iterations, 
                 spring_strength: physics_settings.spring_strength,
                 repulsion: physics_settings.repulsion_strength,
                 damping: physics_settings.damping,
@@ -158,6 +191,10 @@ impl GraphService {
                 SIMULATION_LOOP_RUNNING.store(false, Ordering::SeqCst); 
             });
             
+            // Track stability by monitoring consecutive frames with minimal position changes
+            let mut consecutive_stable_iterations = 0;
+            let mut previous_positions: HashMap<String, Vec3Data> = HashMap::new();
+            
             loop {
                 // Check if shutdown was requested
                 if shutdown_requested.load(Ordering::SeqCst) {
@@ -165,7 +202,7 @@ impl GraphService {
                     break;
                 }
                 
-                // Update positions - using loop ID in logs to track which loop is running
+                // Continuously update positions - using loop ID in logs to track which loop is running
                 debug!("[Graph:{}] Starting physics calculation iteration", loop_simulation_id);
                 let mut graph = graph_data.write().await;
                 let mut node_map = node_map.write().await;
@@ -175,26 +212,78 @@ impl GraphService {
                        loop_simulation_id, gpu_status, physics_settings.enabled);
                        
                 if physics_settings.enabled {
+                    let mut positions_stable = true;
+                    
                     if let Some(gpu) = &gpu_compute {
                         if let Err(e) = Self::calculate_layout_with_retry(gpu, &mut graph, &mut node_map, &params).await {
                             error!("[Graph:{}] Error updating positions: {}", loop_simulation_id, e);
+                            positions_stable = false;
                         } else {
                             debug!("[Graph:{}] GPU calculation completed successfully", loop_simulation_id);
                             debug!("[Graph:{}] Successfully calculated layout for {} nodes", loop_simulation_id, graph.nodes.len());
+                            
+                            // Check if positions have stabilized
+                            if !graph.nodes.is_empty() {
+                                // Compare current positions with previous positions
+                                let mut max_movement = 0.0f32;
+                                
+                                for node in &graph.nodes {
+                                    let curr_pos = &node.data.position;
+                                    if let Some(prev_pos) = previous_positions.get(&node.id) {
+                                        let dx = curr_pos.x - prev_pos.x;
+                                        let dy = curr_pos.y - prev_pos.y;
+                                        let dz = curr_pos.z - prev_pos.z;
+                                        let movement = (dx*dx + dy*dy + dz*dz).sqrt();
+                                        if movement > max_movement {
+                                            max_movement = movement;
+                                        }
+                                        
+                                        if movement > 0.001 { // Consider stable if movement < 1mm
+                                            positions_stable = false;
+                                        }
+                                    }
+                                    
+                                    // Update previous positions for next iteration
+                                    previous_positions.insert(node.id.clone(), curr_pos.clone());
+                                }
+                                
+                                if positions_stable {
+                                    consecutive_stable_iterations += 1;
+                                    if consecutive_stable_iterations >= STABLE_THRESHOLD_ITERATIONS && 
+                                       !is_physics_stable.load(Ordering::SeqCst) {
+                                        info!("[Graph:{}] Physics simulation STABILIZED after {} iterations", 
+                                              loop_simulation_id, consecutive_stable_iterations);
+                                        is_physics_stable.store(true, Ordering::SeqCst);
+                                    }
+                                } else {
+                                    consecutive_stable_iterations = 0;
+                                    if is_physics_stable.load(Ordering::SeqCst) {
+                                        info!("[Graph:{}] Physics simulation destabilized, max movement: {:.6}", 
+                                              loop_simulation_id, max_movement);
+                                        is_physics_stable.store(false, Ordering::SeqCst);
+                                    }
+                                }
+                            }
                         }
                     } else {
                         // Use CPU fallback when GPU is not available
                         debug!("[Graph:{}] GPU compute not available - using CPU fallback for physics calculation", loop_simulation_id);
                         if let Err(e) = Self::calculate_layout_cpu(&mut graph, &mut node_map, &params) {
                             error!("[Graph:{}] Error updating positions with CPU fallback: {}", loop_simulation_id, e);
+                            positions_stable = false;
                         } else {
                             debug!("[Graph:{}] CPU calculation completed successfully", loop_simulation_id);
                             debug!("[Graph:{}] Successfully calculated layout with CPU fallback for {} nodes", loop_simulation_id, graph.nodes.len());
+                            // Similar stability check could be implemented for CPU calculation
                         }
                     }
                 } else {
                     debug!("[Graph:{}] Physics disabled in settings - skipping physics calculation", loop_simulation_id);
                 }
+                
+                // Mark graph as initialized after first layout calculation
+                is_initialized.store(true, Ordering::SeqCst);
+                
                 drop(graph); // Release locks before sleep
                 drop(node_map);
                 tokio::time::sleep(tokio::time::Duration::from_millis(16)).await;
@@ -202,11 +291,139 @@ impl GraphService {
                 *cache = None;
             }
             drop(loop_guard); // Explicitly drop the guard to trigger the cleanup
+            info!("[Graph:{}] Physics simulation loop terminated", loop_simulation_id);
         }); 
 
+        // Add a periodic duplicate node cleanup job
+        info!("[GraphService] Starting periodic duplicate node cleanup job");
+        let graph_service_clone = graph_service.clone();
+        let cleanup_simulation_id = simulation_id.clone();
+        tokio::spawn(async move {
+            // Wait for graph to initialize before starting cleanup
+            tokio::time::sleep(Duration::from_secs(10)).await;
+            
+            // Run cleanup every minute to prevent node proliferation
+            let mut interval = tokio::time::interval(Duration::from_secs(60));
+            
+            loop {
+                interval.tick().await;
+                
+                // Check if shutdown was requested
+                if graph_service_clone.shutdown_requested.load(Ordering::SeqCst) {
+                    info!("[GraphService:{}] Cleanup job shutting down", cleanup_simulation_id);
+                    break;
+                }
+                
+                // Clean any duplicate nodes that might have appeared
+                if let Ok(removed) = graph_service_clone.clean_duplicate_nodes().await {
+                    if removed > 0 {
+                        info!("[GraphService:{}] Removed {} duplicate nodes during cleanup", cleanup_simulation_id, removed);
+                    }
+                    
+                    // Also fix any node 0 instances that might be causing the axis-aligned issues
+                    if let Ok(fixed) = graph_service_clone.fix_node_zero_issue().await {
+                        if fixed > 0 {
+                            info!("[GraphService:{}] Fixed {} instances of problematic node 0", cleanup_simulation_id, fixed);
+                        }
+                    }
+                }
+            }
+        });
+
         graph_service
     }
     
+    // Initialize the graph from metadata on startup
+    pub async fn initialize_graph(&self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
+        info!("[GraphService] Initializing graph from metadata");
+        
+        // Wait for metadata file if in docker environment
+        if Self::is_running_in_docker() {
+            if !Self::wait_for_metadata_file().await {
+                return Err("Timed out waiting for metadata file".into());
+            }
+        }
+        
+        // Load metadata and build graph
+        let metadata = match crate::services::file_service::FileService::load_or_create_metadata() {
+            Ok(metadata) => metadata,
+            Err(e) => return Err(format!("Failed to load metadata: {}", e).into()),
+        };
+        
+        // Build graph from metadata
+        let graph = Self::build_graph_from_metadata(&metadata).await?;
+        *self.graph_data.write().await = graph;
+        
+        // Also initialize node_map
+        {
+            let graph = self.graph_data.read().await;
+            let mut node_map = self.node_map.write().await;
+            node_map.clear();
+            for node in &graph.nodes {
+                node_map.insert(node.id.clone(), node.clone());
+            }
+        }
+        
+        info!("[GraphService] Graph successfully initialized from metadata");
+        self.is_initialized.store(true, Ordering::SeqCst);
+        Ok(())
+    }
+    
+    // Helper to check if running in docker
+    fn is_running_in_docker() -> bool {
+        std::path::Path::new("/.dockerenv").exists()
+    }
+    
+    // Broadcast node position updates to all connected clients
+    pub async fn broadcast_node_positions(&self) {
+        if let Some(client_manager) = &self.client_manager {
+            // Only broadcast if graph is initialized
+            if !self.is_initialized.load(Ordering::SeqCst) {
+                return;
+            }
+            
+            // Get current node positions
+            let nodes = self.get_node_positions().await;
+            if nodes.is_empty() {
+                return;
+            }
+            
+            // Broadcast to all clients
+            client_manager.broadcast_node_positions(nodes).await;
+        }
+    }
+    
+    // Check if physics simulation has stabilized
+    pub fn is_physics_stable(&self) -> bool {
+        self.is_physics_stable.load(Ordering::SeqCst)
+    }
+    
+    // Start broadcasting loop to send position updates to all connected clients
+    pub fn start_broadcast_loop(&self) {
+        if self.client_manager.is_none() {
+            return;
+        }
+        
+        let graph_service = self.clone();
+        let simulation_id = self.simulation_id.clone();
+        tokio::spawn(async move {
+            info!("[GraphService:{}] Starting position broadcast loop", simulation_id);
+            let mut interval = tokio::time::interval(tokio::time::Duration::from_millis(100)); // 10 Hz broadcasts
+            
+            loop {
+                interval.tick().await;
+                
+                // Check if shutdown was requested
+                if graph_service.shutdown_requested.load(Ordering::SeqCst) {
+                    info!("[GraphService:{}] Broadcast loop shutting down", simulation_id);
+                    break;
+                }
+                
+                graph_service.broadcast_node_positions().await;
+            }
+        }); 
+    }
+    
     /// Shutdown the simulation loop to allow creating a new instance
     pub async fn shutdown(&self) {
         info!("[GraphService] Shutting down simulation loop (ID: {})", self.simulation_id);
@@ -361,12 +578,16 @@ impl GraphService {
             }
         }
         // This guard will reset the flag when it goes out of scope
+        debug!("Starting graph rebuild from metadata");
         let _guard = RebuildGuard;
         
         let mut graph = GraphData::new();
         let mut edge_map = HashMap::new();
         let mut node_map = HashMap::new();
 
+        // Track used numeric IDs to prevent duplicates
+        let mut used_numeric_ids = HashSet::new();
+        let mut next_id_counter = 1; // Start at 1 to avoid node 0 issues
         // First pass: Create nodes from files in metadata
         let mut valid_nodes = HashSet::new();
         debug!("Creating nodes from {} metadata entries", metadata.len());
@@ -378,12 +599,55 @@ impl GraphService {
 
         // Create nodes for all valid node IDs
         for node_id in &valid_nodes {
+            // Skip if this node ID already has a numeric ID to prevent duplicates
+            if graph.id_to_metadata.values().any(|id| id == node_id) {
+                debug!("Skipping duplicate node for metadata ID: {}", node_id); 
+                continue;
+            }
             // Get metadata for this node, including the node_id if available
             let metadata_entry = graph.metadata.get(&format!("{}.md", node_id));
             let stored_node_id = metadata_entry.map(|m| m.node_id.clone());
+
+            // Validate the stored node ID or generate a new one to guarantee uniqueness
+            let final_node_id = if let Some(id_str) = stored_node_id {
+                if let Ok(id_num) = id_str.parse::<u16>() {
+                    if id_num == 0 || used_numeric_ids.contains(&id_str) {
+                        // Don't use 0 or already used IDs
+                        let new_id = next_id_counter.to_string();
+                        next_id_counter += 1;
+                        new_id
+                    } else {
+                        id_str
+                    }
+                } else {
+                    let new_id = next_id_counter.to_string();
+                    next_id_counter += 1;
+                    new_id
+                }
+            } else {
+                // No stored ID, generate a new unique one
+                let new_id = next_id_counter.to_string();
+                next_id_counter += 1;
+                new_id
+            };
+            used_numeric_ids.insert(final_node_id.clone());
             
-            // Create node with stored ID or generate a new one if not available
-            let mut node = Node::new_with_id(node_id.clone(), stored_node_id);
+            // Create node with guaranteed unique ID
+            let mut node = Node::new_with_id(node_id.clone(), Some(final_node_id));
+            debug!("Created node {} with numeric ID {}", node_id, node.id);
+            
+            // CRITICAL: Double-check to ensure no node 0
+            if node.id == "0" {
+                debug!("Found node with ID 0 after creation, assigning new ID");
+                // Generate a new unique ID
+                let new_id = next_id_counter.to_string();
+                next_id_counter += 1;
+                
+                // Create a new node with the same metadata but different ID
+                let mut replacement_node = node.clone();
+                replacement_node.id = new_id;
+                node = replacement_node;
+            }
             graph.id_to_metadata.insert(node.id.clone(), node_id.clone());
 
             // Get metadata for this node
@@ -436,6 +700,7 @@ impl GraphService {
             let node_clone = node.clone();
             graph.nodes.push(node_clone);
             // Store nodes in map by numeric ID for efficient lookups
+            debug!("Added node with numeric ID: {}, metadata ID: {}", node.id, node.metadata_id);
             node_map.insert(node.id.clone(), node);
         }
 
@@ -443,6 +708,15 @@ impl GraphService {
         debug!("Storing {} metadata entries in graph", metadata.len());
         graph.metadata = metadata.clone();
         debug!("Created {} nodes in graph", graph.nodes.len());
+        
+        // Final check for any duplicate node IDs that might have slipped through
+        let mut unique_ids = HashSet::new();
+        let original_count = graph.nodes.len();
+        graph.nodes.retain(|node| unique_ids.insert(node.id.clone()));
+        if original_count != graph.nodes.len() {
+            debug!("Removed {} duplicate nodes in final validation", original_count - graph.nodes.len());
+        }
+        
         // Second pass: Create edges from topic counts
         for (source_file, metadata) in metadata.iter() {
             let source_id = source_file.trim_end_matches(".md").to_string();
@@ -523,14 +797,26 @@ impl GraphService {
         let mut graph = GraphData::new();
         let mut node_map = HashMap::new();
         debug!("Starting graph build process");
+        
+        // Track used numeric IDs to prevent duplicates
+        let mut used_numeric_ids: HashSet<String> = HashSet::new();
+        let mut next_id_counter = 1; // Start at 1 to avoid node 0 issues
+        
+        // Track all existing node IDs to prevent duplicates
+        let mut existing_numeric_ids = HashSet::new();
 
         // Copy metadata from current graph
         graph.metadata = current_graph.metadata.clone();
         debug!("Copied {} metadata entries from current graph", graph.metadata.len());
         
         let mut edge_map = HashMap::new();
+        
+        // Copy id_to_metadata mapping to prevent duplicate node creation
+        graph.id_to_metadata = current_graph.id_to_metadata.clone();
 
-        // Create nodes from metadata entries
+        // Create nodes from metadata entries - first build a set of valid nodes
+        // to avoid creating duplicate nodes or nodes not tied to metadata
+        debug!("Building node set from metadata entries");
         let mut valid_nodes = HashSet::new();
         for file_name in graph.metadata.keys() {
             let node_id = file_name.trim_end_matches(".md").to_string();
@@ -540,6 +826,12 @@ impl GraphService {
 
         // Create nodes for all valid node IDs
         for node_id in &valid_nodes {
+            // Skip if this node ID already has a numeric ID to prevent duplicates
+            if graph.id_to_metadata.values().any(|id| id == node_id) {
+                debug!("Skipping duplicate node for metadata ID: {}", node_id);
+                continue;
+            }
+            
             // Get metadata for this node, including the node_id if available
             let metadata_entry = graph.metadata.get(&format!("{}.md", node_id));
             let stored_node_id = metadata_entry.map(|m| m.node_id.clone());
@@ -548,6 +840,25 @@ impl GraphService {
             let mut node = Node::new_with_id(node_id.clone(), stored_node_id);
             graph.id_to_metadata.insert(node.id.clone(), node_id.clone());
 
+            // CRITICAL: Check for node 0 and assign a new ID if found
+            if node.id == "0" {
+                debug!("Found node with ID 0, assigning new ID");
+                // Generate a new unique ID
+                let new_id = next_id_counter.to_string();
+                next_id_counter += 1;
+                
+                // Create a new node with the same metadata but different ID
+                let mut replacement_node = node.clone();
+                replacement_node.id = new_id;
+                node = replacement_node;
+            }
+
+            // Track numeric ID to avoid duplicates
+            if !existing_numeric_ids.insert(node.id.clone()) {
+                debug!("Detected duplicate numeric ID: {} for node: {}", node.id, node_id);
+                continue;  // Skip this node as it has a duplicate ID
+            }
+
             // Get metadata for this node
             if let Some(metadata) = graph.metadata.get(&format!("{}.md", node_id)) {
                 // Set file size which also calculates mass
@@ -653,7 +964,15 @@ impl GraphService {
             .map(|((source, target), weight)| {
                 Edge::new(source, target, weight)
             })
-            .collect();
+            .collect(); 
+        
+        // Final check for any duplicate node IDs that might have slipped through
+        let mut unique_ids = HashSet::new();
+        let original_count = graph.nodes.len();
+        graph.nodes.retain(|node| unique_ids.insert(node.id.clone()));
+        if original_count != graph.nodes.len() {
+            debug!("Removed {} duplicate nodes in final validation", original_count - graph.nodes.len());
+        }
 
         // Initialize random positions for all nodes
         Self::initialize_random_positions(&mut graph);
@@ -667,7 +986,8 @@ impl GraphService {
         let mut rng = rand::thread_rng();
         let node_count = graph.nodes.len() as f32;
         let initial_radius = 3.0; // Increasing radius for better visibility
-        let golden_ratio = (1.0 + 5.0_f32.sqrt()) / 2.0;
+        // Slightly vary the golden ratio to avoid perfect symmetry
+        let golden_ratio = (1.0 + 5.0_f32.sqrt()) / 2.0 + rng.gen_range(-0.01..0.01);
         
         // Log the initialization process
         info!("Initializing random positions for {} nodes with radius {}", 
@@ -680,15 +1000,25 @@ impl GraphService {
             let i_float: f32 = i as f32;
             
             // Calculate Fibonacci sphere coordinates
+            // Add randomness to prevent perfect alignment
+            let _i_perturbed = i_float + rng.gen_range(-0.2..0.2);
+            let _golden_angle = 2.0 * std::f32::consts::PI / golden_ratio + rng.gen_range(-0.01..0.01);
             let theta = 2.0 * std::f32::consts::PI * i_float / golden_ratio;
             let phi = (1.0 - 2.0 * (i_float + 0.5) / node_count).acos();
-            
+
             // Add slight randomness to prevent exact overlaps
-            let r = initial_radius * (0.9 + rng.gen_range(0.0..0.2));
+            // CRITICAL FIX: Use different random values for each coordinate component
+            // This prevents nodes from aligning along axis lines which was causing
+            // node proliferation issues. By using independent randomization factors
+            // for each coordinate, we ensure better 3D distribution and prevent
+            // nodes from clustering along specific axes.
+            let r_x = initial_radius * (0.85 + rng.gen_range(0.0..0.3));
+            let r_y = initial_radius * (0.85 + rng.gen_range(0.0..0.3));
+            let r_z = initial_radius * (0.85 + rng.gen_range(0.0..0.3));
             
-            node.set_x(r * phi.sin() * theta.cos());
-            node.set_y(r * phi.sin() * theta.sin());
-            node.set_z(r * phi.cos());
+            node.set_x(r_x * phi.sin() * theta.cos());
+            node.set_y(r_y * phi.sin() * theta.sin());
+            node.set_z(r_z * phi.cos());
             
             // Initialize with zero velocity
             node.set_vx(0.0);
@@ -1148,6 +1478,51 @@ impl GraphService {
     pub async fn get_node_map_mut(&self) -> tokio::sync::RwLockWriteGuard<'_, HashMap<String, Node>> {
         self.node_map.write().await
     }
+
+    /// Fix any instances of node ID 0 throughout the graph
+    pub async fn fix_node_zero_issue(&self) -> Result<usize, Error> {
+        debug!("Checking for problematic node 0 instances");
+        let mut graph = self.graph_data.write().await;
+        let mut node_map = self.node_map.write().await;
+        
+        let mut counter = 0;
+        let mut next_id = 100; // Start at higher number to avoid conflicts
+        
+        // Fix any node with ID 0
+        for node in &mut graph.nodes {
+            if node.id == "0" {
+                debug!("Found node with ID 0, replacing with ID {}", next_id);
+                let old_id = node.id.clone();
+                node.id = next_id.to_string();
+                next_id += 1;
+                counter += 1;
+                node_map.remove(&old_id);
+                node_map.insert(node.id.clone(), node.clone());
+            }
+        }
+        
+        Ok(counter)
+    }
+    
+    // Add a method to check for duplicate nodes and clean them
+    pub async fn clean_duplicate_nodes(&self) -> Result<usize, Error> {
+        debug!("Checking for duplicate nodes in the graph");
+        let mut graph = self.graph_data.write().await;
+        let mut node_map = self.node_map.write().await;
+        
+        // Create a set to track unique node IDs
+        let mut unique_ids = HashSet::new();
+        let original_count = graph.nodes.len();
+        
+        // Remove duplicate nodes (keeping the first instance)
+        graph.nodes.retain(|node| unique_ids.insert(node.id.clone()));
+        
+        // Update node map to match
+        *node_map = graph.nodes.iter().map(|n| (n.id.clone(), n.clone())).collect();
+        let nodes_removed = original_count - graph.nodes.len();
+        debug!("Removed {} duplicate nodes from graph", nodes_removed);
+        Ok(nodes_removed)
+    }
     
     // Add method to get GPU compute instance
     pub async fn get_gpu_compute(&self) -> Option<Arc<RwLock<GPUCompute>>> {
diff --git a/src/services/ragflow_service.rs b/src/services/ragflow_service.rs
index fe25167c..a43f98f7 100755
--- a/src/services/ragflow_service.rs
+++ b/src/services/ragflow_service.rs
@@ -4,9 +4,9 @@ use crate::config::Settings;
 use std::fmt;
 use futures::stream::{Stream, StreamExt};
 use std::pin::Pin;
-use serde_json::json;
 use std::sync::Arc;
 use tokio::sync::RwLock;
+use serde::{Deserialize, Serialize};
 
 #[derive(Debug)]
 pub enum RAGFlowError {
@@ -41,10 +41,52 @@ impl From<std::io::Error> for RAGFlowError {
     }
 }
 
+#[derive(Debug, Deserialize)]
+struct SessionResponse {
+    code: i32,
+    data: SessionData,
+}
+
+#[derive(Debug, Deserialize)]
+struct SessionData {
+    id: String,
+    message: Option<Vec<Message>>,
+}
+
+#[derive(Debug, Deserialize)]
+struct Message {
+    role: String,
+    content: String,
+}
+
+#[derive(Debug, Deserialize)]
+struct CompletionResponse {
+    code: i32,
+    data: CompletionData,
+}
+
+#[derive(Debug, Deserialize)]
+struct CompletionData {
+    answer: Option<String>,
+    reference: Option<serde_json::Value>,
+    id: Option<String>,
+    session_id: Option<String>,
+}
+
+#[derive(Debug, Serialize)]
+struct CompletionRequest {
+    question: String,
+    stream: bool,
+    session_id: Option<String>,
+    user_id: Option<String>,
+    sync_dsl: Option<bool>,
+}
+
 pub struct RAGFlowService {
     client: Client,
     api_key: String,
     base_url: String,
+    agent_id: String,
 }
 
 impl RAGFlowService {
@@ -56,17 +98,24 @@ impl RAGFlowService {
             client,
             api_key: settings.ragflow.api_key.clone(),
             base_url: settings.ragflow.api_base_url.clone(),
+            agent_id: settings.ragflow.agent_id.clone(),
         })
     }
 
-    pub async fn create_conversation(&self, user_id: String) -> Result<String, RAGFlowError> {
-        info!("Creating conversation for user: {}", user_id);
-        let url = format!("{}/api/new_conversation", self.base_url.trim_end_matches('/'));
-        info!("Full URL for create_conversation: {}", url);
+    pub async fn create_session(&self, user_id: String) -> Result<String, RAGFlowError> {
+        info!("Creating session for user: {}", user_id);
+        let url = format!(
+            "{}/api/v1/agents/{}/sessions?user_id={}", 
+            self.base_url.trim_end_matches('/'), 
+            self.agent_id,
+            user_id
+        );
+        info!("Full URL for create_session: {}", url);
         
-        let response = self.client.get(&url)
+        let response = self.client.post(&url)
             .header("Authorization", format!("Bearer {}", self.api_key))
-            .query(&[("user_id", user_id)])
+            .header("Content-Type", "application/json")
+            .body("{}")  // Empty JSON body as we don't have any Begin parameters
             .send()
             .await?;
 
@@ -76,38 +125,47 @@ impl RAGFlowService {
         if status.is_success() {
             let result: serde_json::Value = response.json().await?;
             info!("Successful response: {:?}", result);
-            Ok(result["data"]["id"].as_str().unwrap_or("").to_string())
+            
+            // Extract session ID from the response
+            match result["data"]["id"].as_str() {
+                Some(id) => Ok(id.to_string()),
+                None => {
+                    error!("Failed to parse session ID from response: {:?}", result);
+                    Err(RAGFlowError::ParseError("Failed to parse session ID".to_string()))
+                }
+            }
         } else {
             let error_message = response.text().await?;
-            error!("Failed to create conversation. Status: {}, Error: {}", status, error_message);
+            error!("Failed to create session. Status: {}, Error: {}", status, error_message);
             Err(RAGFlowError::StatusError(status, error_message))
         }
     }
 
     pub async fn send_message(
         &self,
-        conversation_id: String,
+        session_id: String,
         message: String,
-        quote: bool,
-        doc_ids: Option<Vec<String>>,
+        _quote: bool,  // Not used in new API
+        _doc_ids: Option<Vec<String>>,  // Not used in new API
         stream: bool,
     ) -> Result<Pin<Box<dyn Stream<Item = Result<String, RAGFlowError>> + Send + 'static>>, RAGFlowError> {
-        info!("Sending message to conversation: {}", conversation_id);
-        let url = format!("{}/api/completion", self.base_url.trim_end_matches('/'));
+        info!("Sending message to session: {}", session_id);
+        let url = format!(
+            "{}/api/v1/agents/{}/completions", 
+            self.base_url.trim_end_matches('/'),
+            self.agent_id
+        );
         info!("Full URL for send_message: {}", url);
         
-        let mut request_body = json!({
-            "conversation_id": conversation_id,
-            "messages": [{"role": "user", "content": message}],
-            "quote": quote,
-            "stream": stream
-        });
-
-        if let Some(ids) = doc_ids {
-            request_body["doc_ids"] = serde_json::json!(ids.join(","));
-        }
+        let request_body = CompletionRequest {
+            question: message,
+            stream,
+            session_id: Some(session_id),
+            user_id: None,
+            sync_dsl: Some(false),
+        };
 
-        info!("Request body: {:?}", request_body);
+        info!("Request body: {:?}", serde_json::to_string(&request_body).unwrap_or_default());
 
         let response = self.client.post(&url)
             .header("Authorization", format!("Bearer {}", self.api_key))
@@ -120,26 +178,50 @@ impl RAGFlowService {
         info!("Response status: {}", status);
        
         if status.is_success() {
-            let stream = response.bytes_stream().map(move |chunk_result| {
-                match chunk_result {
-                    Ok(chunk) => {
-                        match serde_json::from_slice::<serde_json::Value>(&chunk) {
-                            Ok(json_response) => {
-                                // Extract text answer from the response
-                                match json_response["data"]["answer"].as_str()
-                                    .or_else(|| json_response["answer"].as_str()) {
-                                    Some(answer) => Ok(answer.to_string()),
-                                    None => Err(RAGFlowError::ParseError("No answer found in response".to_string()))
+            if stream {
+                let stream = response.bytes_stream().map(move |chunk_result| {
+                    match chunk_result {
+                        Ok(chunk) => {
+                            let chunk_str = String::from_utf8_lossy(&chunk);
+                            // Handle SSE format (data: {...})
+                            let chunk_str = chunk_str.trim();
+                            
+                            if chunk_str.starts_with("data:") {
+                                let json_str = chunk_str.trim_start_matches("data:").trim();
+                                match serde_json::from_str::<serde_json::Value>(json_str) {
+                                    Ok(json_response) => {
+                                        if let Some(true) = json_response["data"].as_bool() {
+                                            // This is the end marker
+                                            Ok("".to_string())
+                                        } else if let Some(answer) = json_response["data"]["answer"].as_str() {
+                                            Ok(answer.to_string())
+                                        } else {
+                                            Err(RAGFlowError::ParseError("No answer found in response".to_string()))
+                                        }
+                                    },
+                                    Err(e) => Err(RAGFlowError::ParseError(format!("Failed to parse JSON: {}, content: {}", e, json_str))),
                                 }
-                            },
-                            Err(e) => Err(RAGFlowError::ParseError(format!("Failed to parse JSON response: {}", e))),
-                        }
-                    },
-                    Err(e) => Err(RAGFlowError::ReqwestError(e)),
-                }
-            });
+                            } else {
+                                Err(RAGFlowError::ParseError(format!("Invalid SSE format: {}", chunk_str)))
+                            }
+                        },
+                        Err(e) => Err(RAGFlowError::ReqwestError(e)),
+                    }
+                });
 
-            Ok(Box::pin(stream))
+                Ok(Box::pin(stream))
+            } else {
+                // Non-streaming response handling
+                let result: serde_json::Value = response.json().await?;
+                
+                if let Some(answer) = result["data"]["answer"].as_str() {
+                    // Create a one-item stream with the answer
+                    let stream = futures::stream::once(futures::future::ok(answer.to_string()));
+                    Ok(Box::pin(stream))
+                } else {
+                    Err(RAGFlowError::ParseError("No answer found in response".to_string()))
+                }
+            }
         } else {
             let error_message = response.text().await?;
             error!("Failed to send message. Status: {}, Error: {}", status, error_message);
@@ -147,8 +229,14 @@ impl RAGFlowService {
         }
     }
 
-    pub async fn get_conversation_history(&self, conversation_id: String) -> Result<serde_json::Value, RAGFlowError> {
-        let url = format!("{}/api/conversation/{}", self.base_url.trim_end_matches('/'), conversation_id);
+    pub async fn get_session_history(&self, session_id: String) -> Result<serde_json::Value, RAGFlowError> {
+        let url = format!(
+            "{}/api/v1/agents/{}/sessions?id={}", 
+            self.base_url.trim_end_matches('/'), 
+            self.agent_id,
+            session_id
+        );
+        
         let response = self.client.get(&url)
             .header("Authorization", format!("Bearer {}", self.api_key))
             .send()
@@ -160,7 +248,7 @@ impl RAGFlowService {
             Ok(history)
         } else {
             let error_message = response.text().await?;
-            error!("Failed to get conversation history. Status: {}, Error: {}", status, error_message);
+            error!("Failed to get session history. Status: {}, Error: {}", status, error_message);
             Err(RAGFlowError::StatusError(status, error_message))
         }
     }
@@ -172,6 +260,7 @@ impl Clone for RAGFlowService {
             client: self.client.clone(),
             api_key: self.api_key.clone(),
             base_url: self.base_url.clone(),
+            agent_id: self.agent_id.clone(),
         }
     }
 }
diff --git a/src/services/speech_service.rs b/src/services/speech_service.rs
index 3880ae4c..3f0de2af 100755
--- a/src/services/speech_service.rs
+++ b/src/services/speech_service.rs
@@ -1,10 +1,10 @@
 use tokio::sync::{mpsc, Mutex, RwLock};
 use tokio_tungstenite::{connect_async, WebSocketStream, MaybeTlsStream, tungstenite};
-use tokio_tungstenite::tungstenite::Message;
 use tungstenite::http::Request;
 use serde_json::json;
 use std::sync::Arc;
 use tokio::task;
+use tokio::sync::broadcast;
 use crate::config::Settings;
 use log::{info, error, debug};
 use futures::{SinkExt, StreamExt};
@@ -12,13 +12,18 @@ use std::error::Error;
 use tokio::net::TcpStream;
 use url::Url;
 use base64::Engine as _;
-use base64::engine::general_purpose::STANDARD as BASE64;
-use crate::types::speech::{SpeechError, SpeechCommand, TTSProvider};
+use base64::engine::general_purpose::{STANDARD as BASE64};
+use crate::types::speech::{SpeechError, SpeechCommand, TTSProvider, SpeechOptions};
+use reqwest::Client;
+
 
 pub struct SpeechService {
     sender: Arc<Mutex<mpsc::Sender<SpeechCommand>>>,
     settings: Arc<RwLock<Settings>>,
     tts_provider: Arc<RwLock<TTSProvider>>,
+    // Audio broadcast channel for distributing TTS audio to all connected clients
+    audio_tx: broadcast::Sender<Vec<u8>>,
+    http_client: Arc<Client>,
 }
 
 impl SpeechService {
@@ -26,10 +31,18 @@ impl SpeechService {
         let (tx, rx) = mpsc::channel(100);
         let sender = Arc::new(Mutex::new(tx));
 
+        // Create a broadcast channel for audio data with buffer size of 100
+        let (audio_tx, _) = broadcast::channel(100);
+        
+        // Create HTTP client for Kokoro TTS API
+        let http_client = Arc::new(Client::new());
+
         let service = SpeechService {
             sender,
             settings,
-            tts_provider: Arc::new(RwLock::new(TTSProvider::OpenAI)),
+            tts_provider: Arc::new(RwLock::new(TTSProvider::Kokoro)), // Updated default to Kokoro
+            audio_tx,
+            http_client,
         };
 
         service.start(rx);
@@ -38,6 +51,9 @@ impl SpeechService {
 
     fn start(&self, mut receiver: mpsc::Receiver<SpeechCommand>) {
         let settings = Arc::clone(&self.settings);
+        let http_client = Arc::clone(&self.http_client);
+        let tts_provider = Arc::clone(&self.tts_provider);
+        let audio_tx = self.audio_tx.clone();
 
         task::spawn(async move {
             let mut ws_stream: Option<WebSocketStream<MaybeTlsStream<TcpStream>>> = None;
@@ -183,9 +199,109 @@ impl SpeechService {
                         }
                         break;
                     },
-                    SpeechCommand::SetTTSProvider(_) => {
-                        // OpenAI is now the only provider, so we ignore provider changes
-                        info!("TTS provider is fixed to OpenAI");
+                    SpeechCommand::SetTTSProvider(provider) => {
+                        // Update the provider
+                        let mut current_provider = tts_provider.write().await;
+                        *current_provider = provider.clone();
+                        info!("TTS provider updated to: {:?}", provider);
+                    },
+                    SpeechCommand::TextToSpeech(text, options) => {
+                        // Check which provider to use
+                        let provider = {
+                            let p = tts_provider.read().await;
+                            p.clone()
+                        };
+                        
+                        match provider {
+                            TTSProvider::OpenAI => {
+                                // Ignore OpenAI for now and just log
+                                info!("TextToSpeech command with OpenAI provider not implemented");
+                            },
+                            TTSProvider::Kokoro => {
+                                info!("Processing TextToSpeech command with Kokoro provider");
+                                let kokoro_settings = {
+                                    let s = settings.read().await;
+                                    s.kokoro.clone()
+                                };
+                                
+                                // Prepare Kokoro API request
+                                let api_url = format!("{}/v1/audio/speech", kokoro_settings.api_url);
+                                info!("Sending TTS request to Kokoro API: {}", api_url);
+                                
+                                let request_body = json!({
+                                    "model": "kokoro",
+                                    "input": text,
+                                    "voice": options.voice.clone(),
+                                    "response_format": kokoro_settings.default_format,
+                                    "speed": options.speed,
+                                    "stream": options.stream
+                                });
+                                
+                                let response = match http_client
+                                    .post(&api_url)
+                                    .header("Content-Type", "application/json")
+                                    .body(request_body.to_string())
+                                    .send()
+                                    .await
+                                {
+                                    Ok(response) => {
+                                        if !response.status().is_success() {
+                                            let status = response.status();
+                                            let error_text = response.text().await.unwrap_or_default();
+                                            error!("Kokoro API error {}: {}", status, error_text);
+                                            continue;
+                                        }
+                                        response
+                                    }
+                                    Err(e) => {
+                                        error!("Failed to connect to Kokoro API: {}", e);
+                                        continue;
+                                    }
+                                };
+                                
+                                // Handle the response (streaming or not)
+                                if options.stream {
+                                    let stream = response.bytes_stream();
+                                    let audio_broadcaster = audio_tx.clone();
+                                    
+                                    // Process the streaming response
+                                    tokio::spawn(async move {
+                                        let mut stream = Box::pin(stream);
+                                        
+                                        while let Some(item) = stream.next().await {
+                                            match item {
+                                                Ok(bytes) => {
+                                                    // Send audio chunk to all connected clients
+                                                    if let Err(e) = audio_broadcaster.send(bytes.to_vec()) {
+                                                        error!("Failed to broadcast audio chunk: {}", e);
+                                                    }
+                                                }
+                                                Err(e) => {
+                                                    error!("Error receiving audio stream: {}", e);
+                                                    break;
+                                                }
+                                            }
+                                        }
+                                        debug!("Finished streaming audio from Kokoro");
+                                    });
+                                } else {
+                                    // Handle non-streaming response
+                                    match response.bytes().await {
+                                        Ok(bytes) => {
+                                            // Send the complete audio file in one chunk
+                                            if let Err(e) = audio_tx.send(bytes.to_vec()) {
+                                                error!("Failed to send audio data: {}", e);
+                                            } else {
+                                                debug!("Sent {} bytes of audio data", bytes.len());
+                                            }
+                                        }
+                                        Err(e) => {
+                                            error!("Failed to get audio bytes: {}", e);
+                                        }
+                                    }
+                                }
+                            }
+                        }
                     }
                 }
             }
@@ -203,17 +319,32 @@ impl SpeechService {
         self.sender.lock().await.send(command).await.map_err(|e| Box::new(SpeechError::from(e)))?;
         Ok(())
     }
+    
+    pub async fn text_to_speech(&self, text: String, options: SpeechOptions) -> Result<(), Box<dyn Error>> {
+        let command = SpeechCommand::TextToSpeech(text, options);
+        self.sender.lock().await.send(command).await.map_err(|e| Box::new(SpeechError::from(e)))?;
+        Ok(())
+    }
 
     pub async fn close(&self) -> Result<(), Box<dyn Error>> {
         let command = SpeechCommand::Close;
         self.sender.lock().await.send(command).await.map_err(|e| Box::new(SpeechError::from(e)))?;
         Ok(())
     }
-
-    pub async fn set_tts_provider(&self, _use_openai: bool) -> Result<(), Box<dyn Error>> {
-        // OpenAI is now the only provider, so we ignore the parameter
-        let command = SpeechCommand::SetTTSProvider(TTSProvider::OpenAI);
+    
+    pub async fn set_tts_provider(&self, provider: TTSProvider) -> Result<(), Box<dyn Error>> {
+        let command = SpeechCommand::SetTTSProvider(provider);
         self.sender.lock().await.send(command).await.map_err(|e| Box::new(SpeechError::from(e)))?;
         Ok(())
     }
+
+    // Get a subscriber to the audio broadcast channel
+    pub fn subscribe_to_audio(&self) -> broadcast::Receiver<Vec<u8>> {
+        self.audio_tx.subscribe()
+    }
+    
+    // Current provider
+    pub async fn get_tts_provider(&self) -> TTSProvider {
+        self.tts_provider.read().await.clone()
+    }
 }
diff --git a/src/types/speech.rs b/src/types/speech.rs
index 447263f9..148a9b3a 100644
--- a/src/types/speech.rs
+++ b/src/types/speech.rs
@@ -63,13 +63,32 @@ impl From<base64::DecodeError> for SpeechError {
 
 #[derive(Debug, Clone)]
 pub enum TTSProvider {
-    OpenAI,  // OpenAI is now the only supported provider
+    OpenAI,
+    Kokoro,
 }
 
 #[derive(Debug)]
 pub enum SpeechCommand {
     Initialize,
     SendMessage(String),
+    TextToSpeech(String, SpeechOptions),
     Close,
     SetTTSProvider(TTSProvider),
 }
+
+#[derive(Debug, Clone)]
+pub struct SpeechOptions {
+    pub voice: String,
+    pub speed: f32,
+    pub stream: bool,
+}
+
+impl Default for SpeechOptions {
+    fn default() -> Self {
+        Self {
+            voice: "af_heart".to_string(), // Default Kokoro voice
+            speed: 1.0,
+            stream: true,
+        }
+    }
+}
