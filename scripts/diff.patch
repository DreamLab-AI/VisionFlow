diff --git a/scripts/diff.patch b/scripts/diff.patch
index 1f950e47..e69de29b 100644
--- a/scripts/diff.patch
+++ b/scripts/diff.patch
@@ -1,2519 +0,0 @@
-diff --git a/src/app_state.rs b/src/app_state.rs
-index cb38c406..36268b9e 100755
---- a/src/app_state.rs
-+++ b/src/app_state.rs
-@@ -1,13 +1,14 @@
- use std::sync::{Arc, atomic::{AtomicUsize, Ordering}};
- use tokio::sync::RwLock;
- use actix_web::web;
--use log::{info, warn, error};
-+use log::info;
- 
- use crate::config::Settings;
- use tokio::time::Duration;
- use crate::config::feature_access::FeatureAccess;
- use crate::models::metadata::MetadataStore;
- use crate::models::protected_settings::{ProtectedSettings, ApiKeys, NostrUser};
-+use crate::models::graph::GraphUpdateStatus;
- use crate::services::graph_service::GraphService;
- use crate::services::github::{GitHubClient, ContentAPI};
- use crate::services::perplexity_service::PerplexityService;
-@@ -30,6 +31,8 @@ pub struct AppState {
-     pub feature_access: web::Data<FeatureAccess>,
-     pub ragflow_conversation_id: String,
-     pub active_connections: Arc<AtomicUsize>,
-+    // Track graph updates for websocket clients
-+    pub graph_update_status: Arc<RwLock<GraphUpdateStatus>>,
- }
- 
- impl AppState {
-@@ -65,6 +68,7 @@ impl AppState {
-             feature_access: web::Data::new(FeatureAccess::from_env()),
-             ragflow_conversation_id,
-             active_connections: Arc::new(AtomicUsize::new(0)),
-+            graph_update_status: Arc::new(RwLock::new(GraphUpdateStatus::default())),
-         })
-     }
- 
-diff --git a/src/config/feature_access.rs b/src/config/feature_access.rs
-index 31e1949e..b661d270 100644
---- a/src/config/feature_access.rs
-+++ b/src/config/feature_access.rs
-@@ -1,7 +1,7 @@
- use std::env;
- use std::fs;
- use std::path::PathBuf;
--use log::{info, warn};
-+use log::{info, warn, debug};
- 
- /// Represents the access control configuration for various features and user roles
- pub struct FeatureAccess {
-@@ -41,7 +41,11 @@ impl FeatureAccess {
-         env::var(var_name)
-             .unwrap_or_default()
-             .split(',')
--            .map(|s| s.trim().to_string())
-+            .map(|s| {
-+                let trimmed = s.trim().to_string();
-+                debug!("Loaded pubkey from env {}: '{}'", var_name, trimmed);
-+                trimmed
-+            })
-             .filter(|s| !s.is_empty())
-             .collect()
-     }
-@@ -102,33 +106,48 @@ impl FeatureAccess {
- 
-     /// Checks if a pubkey has basic access
-     pub fn has_access(&self, pubkey: &str) -> bool {
--        self.approved_pubkeys.contains(&pubkey.to_string())
-+        let pubkey_str = pubkey.trim();
-+        debug!("Checking access for pubkey: '{}'", pubkey_str);
-+        debug!("Approved pubkeys: {:?}", self.approved_pubkeys);
-+        self.approved_pubkeys.iter().any(|p| p.trim() == pubkey_str)
-     }
- 
-     /// Checks if a pubkey has access to Perplexity features
-     pub fn has_perplexity_access(&self, pubkey: &str) -> bool {
--        self.perplexity_enabled.contains(&pubkey.to_string())
-+        let pubkey_str = pubkey.trim();
-+        debug!("Checking Perplexity access for pubkey: '{}'", pubkey_str);
-+        self.perplexity_enabled.iter().any(|p| p.trim() == pubkey_str)
-     }
- 
-     /// Checks if a pubkey has access to OpenAI features
-     pub fn has_openai_access(&self, pubkey: &str) -> bool {
--        self.openai_enabled.contains(&pubkey.to_string())
-+        let pubkey_str = pubkey.trim();
-+        debug!("Checking OpenAI access for pubkey: '{}'", pubkey_str);
-+        self.openai_enabled.iter().any(|p| p.trim() == pubkey_str)
-     }
- 
-     /// Checks if a pubkey has access to RagFlow features
-     pub fn has_ragflow_access(&self, pubkey: &str) -> bool {
--        self.ragflow_enabled.contains(&pubkey.to_string())
-+        let pubkey_str = pubkey.trim();
-+        debug!("Checking RagFlow access for pubkey: '{}'", pubkey_str);
-+        self.ragflow_enabled.iter().any(|p| p.trim() == pubkey_str)
-     }
- 
-     /// Checks if a pubkey has power user status
--    pub fn is_power_user(&self, pubkey: &str) -> bool {
--        self.power_users.contains(&pubkey.to_string())
-+    pub fn is_power_user(&self, pubkey: &str) -> bool {       
-+        let pubkey_str = pubkey.trim();
-+        debug!("Checking power user status for pubkey: '{}'", pubkey_str);
-+        debug!("Power users: {:?}", self.power_users);
-+        self.power_users.iter().any(|p| p.trim() == pubkey_str)
-     }
- 
-     /// Checks if a pubkey has settings sync access
-     pub fn can_sync_settings(&self, pubkey: &str) -> bool {
-         // Power users automatically get settings sync access
--        self.is_power_user(pubkey) || self.settings_sync_enabled.contains(&pubkey.to_string())
-+        if self.is_power_user(pubkey) {
-+            return true;
-+        }
-+        self.settings_sync_enabled.iter().any(|p| p.trim() == pubkey.trim())
-     }
- 
-     /// Checks if a pubkey has access to a specific feature
-diff --git a/src/handlers/api_handler/files/mod.rs b/src/handlers/api_handler/files/mod.rs
-index ef3cd1ef..44ff8c90 100644
---- a/src/handlers/api_handler/files/mod.rs
-+++ b/src/handlers/api_handler/files/mod.rs
-@@ -22,7 +22,7 @@ pub async fn fetch_and_process_files(state: web::Data<AppState>) -> HttpResponse
-     
-     let file_service = FileService::new(state.settings.clone());
-     
--    match file_service.fetch_and_process_files(state.content_api.clone(), state.settings.clone(), &mut metadata_store).await {
-+    match file_service.fetch_and_process_files(&state.content_api, state.settings.clone(), &mut metadata_store).await {
-         Ok(processed_files) => {
-             let file_names: Vec<String> = processed_files.iter()
-                 .map(|pf| pf.file_name.clone())
-diff --git a/src/handlers/api_handler/graph/mod.rs b/src/handlers/api_handler/graph/mod.rs
-index 1d9da939..3f63a8c0 100644
---- a/src/handlers/api_handler/graph/mod.rs
-+++ b/src/handlers/api_handler/graph/mod.rs
-@@ -198,7 +198,7 @@ pub async fn update_graph(state: web::Data<AppState>) -> impl Responder {
-     };
-     
-     let file_service = FileService::new(Arc::clone(&state.settings));
--    match file_service.fetch_and_process_files(state.content_api.clone(), Arc::clone(&state.settings), &mut metadata).await {
-+    match file_service.fetch_and_process_files(&state.content_api, Arc::clone(&state.settings), &mut metadata).await {
-         Ok(processed_files) => {
-             if processed_files.is_empty() {
-                 debug!("No new files to process");
-diff --git a/src/handlers/file_handler.rs b/src/handlers/file_handler.rs
-index 7f5e33d3..24bcbf41 100755
---- a/src/handlers/file_handler.rs
-+++ b/src/handlers/file_handler.rs
-@@ -28,7 +28,7 @@ pub async fn fetch_and_process_files(state: web::Data<AppState>) -> HttpResponse
-     match file_service.fetch_and_process_files(&state.content_api, state.settings.clone(), &mut metadata_store).await {
-         Ok(processed_files) => {
-             let file_names: Vec<String> = processed_files.iter()
--                .map(|pf| pf.file_name.clone())
-+                .map(|pf| pf.file_name.clone()) 
-                 .collect();
- 
-             info!("Successfully processed {} public markdown files", processed_files.len());
-diff --git a/src/handlers/graph_handler.rs b/src/handlers/graph_handler.rs
-index d761ff2e..d939cd2b 100755
---- a/src/handlers/graph_handler.rs
-+++ b/src/handlers/graph_handler.rs
-@@ -6,8 +6,12 @@ use std::collections::HashMap;
- use std::sync::Arc;
- use crate::models::metadata::Metadata;
- use crate::utils::socket_flow_messages::Node;
-+use tokio::fs::{create_dir_all, File, metadata};
- use crate::services::file_service::FileService;
- use crate::services::graph_service::GraphService;
-+use std::io::Error;
-+use std::path::Path;
-+use crate::services::file_service::{GRAPH_CACHE_PATH, LAYOUT_CACHE_PATH};
- 
- #[derive(Serialize)]
- #[serde(rename_all = "camelCase")]
-@@ -39,8 +43,158 @@ pub struct GraphQuery {
-     pub filter: Option<String>,
- }
- 
-+/// Explicitly verify and report on cache file status
-+pub async fn verify_cache_files() -> (bool, bool) {
-+    info!("Verifying cache files existence and permissions");
-+    let graph_exists = Path::new(GRAPH_CACHE_PATH).exists();
-+    let layout_exists = Path::new(LAYOUT_CACHE_PATH).exists();
-+    
-+    if graph_exists {
-+        match metadata(GRAPH_CACHE_PATH).await {
-+            Ok(md) => {
-+                info!("Graph cache file exists: {} bytes, is_file={}", 
-+                      md.len(), md.is_file());
-+                
-+                // Try opening the file to verify permissions
-+                match File::open(GRAPH_CACHE_PATH).await {
-+                    Ok(_) => info!("Graph cache file is readable"),
-+                    Err(e) => error!("Graph cache file exists but can't be opened: {}", e)
-+                }
-+            },
-+            Err(e) => error!("Failed to get metadata for graph cache: {}", e)
-+        }
-+    } else {
-+        error!("Graph cache file does not exist at {}", GRAPH_CACHE_PATH);
-+    }
-+    
-+    if layout_exists {
-+        match metadata(LAYOUT_CACHE_PATH).await {
-+            Ok(md) => {
-+                info!("Layout cache file exists: {} bytes, is_file={}", 
-+                      md.len(), md.is_file());
-+                match File::open(LAYOUT_CACHE_PATH).await {
-+                    Ok(_) => info!("Layout cache file is readable"),
-+                    Err(e) => error!("Layout cache file exists but can't be opened: {}", e)
-+                }
-+            },
-+            Err(e) => error!("Failed to get metadata for layout cache: {}", e)
-+        }
-+    } else {
-+        error!("Layout cache file does not exist at {}", LAYOUT_CACHE_PATH);
-+    }
-+    (graph_exists, layout_exists)
-+}
-+
- pub async fn get_graph_data(state: web::Data<AppState>) -> impl Responder {
-     info!("Received request for graph data");
-+
-+    // Check if metadata directory exists and create if necessary
-+    if let Err(e) = create_dir_all("/app/data/metadata").await {
-+        error!("Failed to create metadata directory: {}", e);
-+    } else {
-+        info!("Metadata directory exists or was created successfully");
-+    }
-+    
-+    // Get metadata from the app state
-+    let metadata = state.metadata.read().await.clone();
-+    if metadata.is_empty() {
-+        error!("Metadata store is empty - no files to process");
-+        return HttpResponse::ServiceUnavailable().json(serde_json::json!({
-+            "error": "No metadata available to build graph"
-+        }));
-+    }
-+    
-+    // Check if the graph_service already has graph data
-+    let graph_size = {
-+        let graph = state.graph_service.get_graph_data_mut().await;
-+        graph.nodes.len()
-+        // Don't drop graph lock here to avoid race conditions with validation
-+    };
-+    
-+    // If the graph is empty, we need to build it first
-+    if graph_size == 0 {
-+        info!("Graph data is empty, building graph from {} metadata entries", metadata.len());
-+        match GraphService::build_graph_from_metadata(&metadata).await {
-+            Ok(built_graph) => {
-+                // Update the app state's graph data
-+                let mut app_graph = state.graph_service.get_graph_data_mut().await;
-+                *app_graph = built_graph.clone();
-+                drop(app_graph);
-+                
-+                // Update node map
-+                let mut node_map = state.graph_service.get_node_map_mut().await;
-+                node_map.clear();
-+                for node in &built_graph.nodes {
-+                    node_map.insert(node.id.clone(), node.clone());
-+                }
-+                drop(node_map);
-+                
-+                info!("Successfully built and updated graph with {} nodes, {} edges",
-+                      built_graph.nodes.len(), built_graph.edges.len());
-+            },
-+            Err(e) => error!("Failed to build graph: {}", e)
-+        }
-+    } else {
-+        info!("Graph already contains {} nodes, using existing data for hot start", graph_size);
-+        
-+        // Clone what we need for the background task
-+        let app_state = state.clone();
-+        let metadata_clone = metadata.clone();
-+        
-+        // Spawn background validation and update task
-+        tokio::spawn(async move {
-+            info!("Starting background validation of cached graph data against metadata");
-+            
-+            // Try to validate and update the graph
-+            match GraphService::build_graph_from_metadata(&metadata_clone).await {
-+                Ok(validated_graph) => {
-+                    // Check if the validated graph is different from what we have
-+                    let current_size = {
-+                        let graph = app_state.graph_service.get_graph_data_mut().await;
-+                        graph.nodes.len()
-+                    };
-+                    
-+                    let validated_size = validated_graph.nodes.len();
-+                    
-+                    if current_size != validated_size {
-+                        info!("Background validation found graph size difference: {} vs {}. Updating...", 
-+                              current_size, validated_size);
-+                        
-+                        // Update app state with the validated graph
-+                        let mut app_graph = app_state.graph_service.get_graph_data_mut().await;
-+                        *app_graph = validated_graph.clone();
-+                        drop(app_graph);
-+                        
-+                        // Update node map
-+                        let mut node_map = app_state.graph_service.get_node_map_mut().await;
-+                        node_map.clear();
-+                        for node in &validated_graph.nodes {
-+                            node_map.insert(node.id.clone(), node.clone());
-+                        }
-+
-+                        // Update the graph update status so WebSocket clients can check for changes
-+                        let update_diff = validated_graph.nodes.len() as i32 - current_size as i32;
-+                        let mut update_status = app_state.graph_update_status.write().await;
-+                        
-+                        // Only mark as updated if there were actual changes
-+                        if update_diff != 0 {
-+                            info!("Background validation completed - found {} node changes", update_diff);
-+                            update_status.last_update = chrono::Utc::now();
-+                            update_status.update_available = true;
-+                            update_status.nodes_changed = update_diff;
-+                        } else {
-+                            // Still update check time even if no changes
-+                            info!("Background validation completed - graph is already up to date");
-+                            update_status.last_check = chrono::Utc::now();
-+                            update_status.update_available = false;
-+                        }
-+                        
-+                    }
-+                },
-+                Err(e) => error!("Background graph validation failed: {}", e)
-+            }
-+        });
-+    }
-     
-     // Make sure the GPU layout is calculated before sending data
-     if let Some(gpu_compute) = &state.graph_service.get_gpu_compute().await {
-@@ -82,17 +236,39 @@ pub async fn get_graph_data(state: web::Data<AppState>) -> impl Responder {
-         info!("GPU compute not available, sending graph without GPU processing");
-     }
-     
-+    // Take a single layout snapshot for client to load at init
-+    info!("Taking layout snapshot for client initialization");
-+    if let Err(e) = state.graph_service.take_layout_snapshot().await {
-+        warn!("Failed to take layout snapshot: {}", e);
-+    } else {
-+        info!("Layout snapshot saved successfully");
-+    }
-+
-+    // Verify if cache files were created and provide details
-+    let (graph_cached, layout_cached) = verify_cache_files().await;
-+    info!("Cache file verification complete: graph={}, layout={}", graph_cached, layout_cached);
-+    
-     let graph = state.graph_service.get_graph_data_mut().await;
-     
-     // Log position data to debug zero positions
--    if !graph.nodes.is_empty() {
-+    if graph.nodes.is_empty() {
-+        error!("Graph is still empty after build attempt. This should not happen if there is valid metadata.");
-+        
-+        // Return an empty response with an error indicator
-+        return HttpResponse::Ok().json(serde_json::json!({
-+            "nodes": [],
-+            "edges": [],
-+            "metadata": {},
-+            "error": "Failed to build graph data"
-+        }));
-+    } else {
-         // Log a few nodes for debugging
-         for (i, node) in graph.nodes.iter().take(5).enumerate() {
-             debug!("Node {}: id={}, label={}, pos=[{:.3},{:.3},{:.3}]", 
-                 i, node.id, node.label, node.data.position[0], node.data.position[1], node.data.position[2]);
-         }
-     }
--    
-+
-     // Log edge data
-     if !graph.edges.is_empty() {
-         for (i, edge) in graph.edges.iter().take(5).enumerate() {
-@@ -118,7 +294,35 @@ pub async fn get_graph_data(state: web::Data<AppState>) -> impl Responder {
- pub async fn get_paginated_graph_data(
-     state: web::Data<AppState>,
-     query: web::Query<GraphQuery>,
--) -> impl Responder {
-+) -> impl Responder {    
-+    // Ensure metadata directory exists
-+    if let Err(e) = create_dir_all("/app/data/metadata").await {
-+        error!("Failed to create metadata directory: {}", e);
-+    }
-+    
-+    // Get metadata and explicitly build graph with caching if this is the first page
-+    if query.page.unwrap_or(1) == 1 {
-+        info!("First page requested - verifying cache files");
-+        // Verify cache files when first page is requested
-+        let (graph_cached, layout_cached) = verify_cache_files().await;
-+        
-+        // Get the current graph size
-+        let graph_size = {
-+            let graph = state.graph_service.get_graph_data_mut().await;
-+            graph.nodes.len()
-+        };
-+        
-+        // If the graph is empty, rebuild it
-+        if graph_size == 0 {
-+            info!("Graph data is empty when paginated view requested, rebuilding graph");
-+            let metadata = state.metadata.read().await.clone();
-+            if !metadata.is_empty() {
-+                let _ = get_graph_data(state.clone()).await;
-+            }
-+        }
-+        
-+        info!("Cache status for first page: graph={}, layout={}", graph_cached, layout_cached);
-+    }
-     info!("Received request for paginated graph data with params: {:?}", query);
-     
-     // Ensure GPU layout is calculated before sending first page of data
-@@ -236,9 +440,10 @@ pub async fn get_paginated_graph_data(
- 
- // Rebuild graph from existing metadata
- pub async fn refresh_graph(state: web::Data<AppState>) -> impl Responder {
--    info!("Received request to refresh graph");
-+    info!("Received request to refresh graph and rebuild caches");
-     
-     let metadata = state.metadata.read().await.clone();
-+    info!("Building graph from {} metadata entries", metadata.len());
-     debug!("Building graph from {} metadata entries", metadata.len());
-     
-     match GraphService::build_graph_from_metadata(&metadata).await {
-@@ -271,11 +476,23 @@ pub async fn refresh_graph(state: web::Data<AppState>) -> impl Responder {
-             for node in &graph.nodes {
-                 node_map.insert(node.id.clone(), node.clone());
-             }
-+
-+            // Take a layout snapshot after refreshing the graph
-+            info!("Taking layout snapshot after graph refresh");
-+            if let Err(e) = state.graph_service.take_layout_snapshot().await {
-+                warn!("Failed to take layout snapshot: {}", e);
-+            } else {
-+                info!("Layout snapshot saved successfully after refresh");
-+            }
-+
-+            // Verify the cache files after rebuilding the graph
-+            let (graph_cached, layout_cached) = verify_cache_files().await;
-             
-             info!("Graph refreshed successfully with {} nodes and {} edges", 
-                 graph.nodes.len(), 
-                 graph.edges.len()
-             );
-+            info!("Cache files after refresh: graph={}, layout={}", graph_cached, layout_cached);
-             
-             HttpResponse::Ok().json(serde_json::json!({
-                 "success": true,
-@@ -359,6 +576,14 @@ pub async fn update_graph(state: web::Data<AppState>) -> impl Responder {
-                     for node in &graph.nodes {
-                         node_map.insert(node.id.clone(), node.clone());
-                     }
-+
-+                    // Take a layout snapshot after updating the graph
-+                    info!("Taking layout snapshot after graph update");
-+                    if let Err(e) = state.graph_service.take_layout_snapshot().await {
-+                        warn!("Failed to take layout snapshot: {}", e);
-+                    } else {
-+                        info!("Layout snapshot saved successfully after update");
-+                    }
-                     
-                     debug!("Graph updated successfully");
-                     
-diff --git a/src/handlers/nostr_handler.rs b/src/handlers/nostr_handler.rs
-index 11bbf037..506c1b15 100644
---- a/src/handlers/nostr_handler.rs
-+++ b/src/handlers/nostr_handler.rs
-@@ -4,6 +4,7 @@ use crate::services::nostr_service::{NostrService, AuthEvent, NostrError};
- use crate::config::feature_access::FeatureAccess;
- use actix_web::{web, Error, HttpRequest, HttpResponse};
- use serde::{Deserialize, Serialize};
-+use log::{debug, error, info};
- use serde_json::json;
- 
- #[derive(Debug, Serialize)]
-@@ -66,12 +67,15 @@ async fn check_power_user_status(
-     req: HttpRequest,
-     feature_access: web::Data<FeatureAccess>,
- ) -> Result<HttpResponse, Error> {
--    let pubkey = req.headers()
-+    let pubkey_raw = req.headers()
-         .get("X-Nostr-Pubkey")
-         .and_then(|h| h.to_str().ok())
-         .unwrap_or("");
-+        
-+    let pubkey = pubkey_raw.trim();
-+    debug!("Checking power user status for pubkey: '{}'", pubkey);
- 
--    if pubkey.is_empty() {
-+    if pubkey.is_empty() { 
-         return Ok(HttpResponse::BadRequest().json(json!({
-             "error": "Missing Nostr pubkey"
-         })));
-@@ -86,12 +90,15 @@ async fn get_available_features(
-     req: HttpRequest,
-     feature_access: web::Data<FeatureAccess>,
- ) -> Result<HttpResponse, Error> {
--    let pubkey = req.headers()
-+    let pubkey_raw = req.headers()
-         .get("X-Nostr-Pubkey")
-         .and_then(|h| h.to_str().ok())
-         .unwrap_or("");
-+        
-+    let pubkey = pubkey_raw.trim();
-+    debug!("Getting available features for pubkey: '{}'", pubkey);
- 
--    if pubkey.is_empty() {
-+    if pubkey.is_empty() { 
-         return Ok(HttpResponse::BadRequest().json(json!({
-             "error": "Missing Nostr pubkey"
-         })));
-@@ -108,12 +115,15 @@ async fn check_feature_access(
-     feature_access: web::Data<FeatureAccess>,
-     feature: web::Path<String>,
- ) -> Result<HttpResponse, Error> {
--    let pubkey = req.headers()
-+    let pubkey_raw = req.headers()
-         .get("X-Nostr-Pubkey")
-         .and_then(|h| h.to_str().ok())
-         .unwrap_or("");
-+        
-+    let pubkey = pubkey_raw.trim();
-+    debug!("Checking access to feature '{}' for pubkey: '{}'", feature, pubkey);
- 
--    if pubkey.is_empty() {
-+    if pubkey.is_empty() { 
-         return Ok(HttpResponse::BadRequest().json(json!({
-             "error": "Missing Nostr pubkey"
-         })));
-@@ -129,7 +139,9 @@ async fn login(
-     nostr_service: web::Data<NostrService>,
-     feature_access: web::Data<FeatureAccess>,
- ) -> Result<HttpResponse, Error> {
-+    info!("Handling login request for pubkey: {}", event.pubkey.trim());
-     match nostr_service.verify_auth_event(event.into_inner()).await {
-+        
-         Ok(user) => {
-             let token = user.session_token.clone().unwrap_or_default();
-             let expires_at = user.last_seen + std::env::var("AUTH_TOKEN_EXPIRY")
-@@ -146,6 +158,9 @@ async fn login(
-                 npub: Some(user.npub.clone()),
-                 is_power_user: user.is_power_user,
-             };
-+            
-+            debug!("Login successful for pubkey: {}, is_power_user: {}, features: {:?}", 
-+                user.pubkey.trim(), user.is_power_user, features);
- 
-             Ok(HttpResponse::Ok().json(AuthResponse {
-                 user: user_dto,
-@@ -160,7 +175,8 @@ async fn login(
-             })))
-         }
-         Err(e) => {
--            Ok(HttpResponse::InternalServerError().json(json!({
-+            error!("Authentication error: {}", e);
-+            Ok(HttpResponse::InternalServerError().json(json!({ 
-                 "error": format!("Authentication error: {}", e)
-             })))
-         }
-@@ -171,14 +187,17 @@ async fn logout(
-     req: web::Json<ValidateRequest>,
-     nostr_service: web::Data<NostrService>,
- ) -> Result<HttpResponse, Error> {
-+    let pubkey = req.pubkey.trim();
-+    debug!("Handling logout request for pubkey: '{}'", pubkey);
-+    
-     // Validate session before logout
--    if !nostr_service.validate_session(&req.pubkey, &req.token).await {
-+    if !nostr_service.validate_session(pubkey, &req.token).await {
-         return Ok(HttpResponse::Unauthorized().json(json!({
-             "error": "Invalid session"
-         })));
-     }
- 
--    match nostr_service.logout(&req.pubkey).await {
-+    match nostr_service.logout(pubkey).await {
-         Ok(_) => Ok(HttpResponse::Ok().json(json!({
-             "message": "Logged out successfully"
-         }))),
-@@ -193,13 +212,18 @@ async fn verify(
-     nostr_service: web::Data<NostrService>,
-     feature_access: web::Data<FeatureAccess>,
- ) -> Result<HttpResponse, Error> {
--    let is_valid = nostr_service.validate_session(&req.pubkey, &req.token).await;
-+    let pubkey = req.pubkey.trim();
-+    debug!("Verifying session for pubkey: '{}'", pubkey);
-+    
-+    let is_valid = nostr_service.validate_session(pubkey, &req.token).await;
-     let user = if is_valid {
--        nostr_service.get_user(&req.pubkey).await
-+        debug!("Session is valid, getting user info");
-+        nostr_service.get_user(pubkey).await
-                 .map(|u| UserResponseDTO {
-                     pubkey: u.pubkey,
-                     npub: Some(u.npub),
-                     is_power_user: u.is_power_user,
-+                    
-                 })
-     } else {
-         None
-@@ -207,7 +231,7 @@ async fn verify(
- 
-     // Get available features if session is valid
-     let features = if is_valid {
--        feature_access.get_available_features(&req.pubkey)
-+        feature_access.get_available_features(pubkey)
-     } else {
-         Vec::new()
-     };
-@@ -224,22 +248,24 @@ async fn refresh(
-     nostr_service: web::Data<NostrService>,
-     feature_access: web::Data<FeatureAccess>,
- ) -> Result<HttpResponse, Error> {
-+    let pubkey = req.pubkey.trim();
-+    debug!("Refreshing session for pubkey: '{}'", pubkey);
-     // First validate the current session
--    if !nostr_service.validate_session(&req.pubkey, &req.token).await {
-+    if !nostr_service.validate_session(pubkey, &req.token).await {
-         return Ok(HttpResponse::Unauthorized().json(json!({
-             "error": "Invalid session"
-         })));
-     }
- 
--    match nostr_service.refresh_session(&req.pubkey).await {
-+    match nostr_service.refresh_session(pubkey).await {
-         Ok(new_token) => {
--            if let Some(user) = nostr_service.get_user(&req.pubkey).await {
-+            if let Some(user) = nostr_service.get_user(pubkey).await {
-                 let expires_at = user.last_seen + std::env::var("AUTH_TOKEN_EXPIRY")
-                     .unwrap_or_else(|_| "3600".to_string())
-                     .parse::<i64>()
-                     .unwrap_or(3600);
- // Get available features for the refreshed session
--let features = feature_access.get_available_features(&req.pubkey);
-+let features = feature_access.get_available_features(pubkey);
- 
- Ok(HttpResponse::Ok().json(AuthResponse {
-     user: UserResponseDTO {
-@@ -268,13 +294,16 @@ async fn update_api_keys(
-     nostr_service: web::Data<NostrService>,
-     pubkey: web::Path<String>,
- ) -> Result<HttpResponse, Error> {
-+    let trimmed_pubkey = pubkey.trim().to_string();
-     let api_keys = ApiKeys {
-         perplexity: req.perplexity.clone(),
-         openai: req.openai.clone(),
-         ragflow: req.ragflow.clone(),
-     };
-+    
-+    debug!("Updating API keys for pubkey: '{}'", trimmed_pubkey);
- 
--    match nostr_service.update_user_api_keys(&pubkey, api_keys).await {
-+    match nostr_service.update_user_api_keys(&trimmed_pubkey, api_keys).await {
-         Ok(user) => {
-             let user_dto = UserResponseDTO {
-                 pubkey: user.pubkey.clone(),
-@@ -303,9 +332,12 @@ async fn update_api_keys(
- 
- async fn get_api_keys(
-     state: web::Data<AppState>,
--    pubkey: web::Path<String>,
-+    pubkey_param: web::Path<String>,
- ) -> Result<HttpResponse, Error> {
-+    let pubkey = pubkey_param.trim();
-+    debug!("Getting API keys for pubkey: '{}'", pubkey);
-     let protected_settings = state.protected_settings.read().await;
-+    
-     let api_keys = protected_settings.get_api_keys(&pubkey);
-     
-     Ok(HttpResponse::Ok().json(api_keys))
-diff --git a/src/handlers/perplexity_handler.rs b/src/handlers/perplexity_handler.rs
-index 0e4ffcf6..7838d616 100755
---- a/src/handlers/perplexity_handler.rs
-+++ b/src/handlers/perplexity_handler.rs
-@@ -1,8 +1,8 @@
- use crate::AppState;
- use actix_web::{post, web, HttpResponse, Responder};
- use serde::{Deserialize, Serialize};
--use serde_json::json;
--use log::{error, info};
-+use serde_json::json; 
-+use log::info;
- 
- #[derive(Debug, Deserialize)]
- #[serde(rename_all = "camelCase")]
-@@ -25,7 +25,7 @@ pub async fn handle_perplexity(
- ) -> impl Responder {
-     info!("Received perplexity request: {:?}", request);
- 
--    let perplexity_service = match &state.perplexity_service {
-+    let _perplexity_service = match &state.perplexity_service {
-         Some(service) => service,
-         None => return HttpResponse::ServiceUnavailable().json(json!({
-             "error": "Perplexity service is not available"
-@@ -33,17 +33,26 @@ pub async fn handle_perplexity(
-     };
- 
-     let conversation_id = state.ragflow_conversation_id.clone();
--    match perplexity_service.query(&request.query, &conversation_id).await {
--        Ok(answer) => {
--            let response = PerplexityResponse {
--                answer,
--                conversation_id,
--            };
--            HttpResponse::Ok().json(response)
--        }
--        Err(e) => {
--            error!("Error processing perplexity request: {}", e);
--            HttpResponse::InternalServerError().json(format!("Error: {}", e))
--        }
--    }
-+    
-+    // TEMPORARILY COMMENTED OUT: Perplexity API call as per optimization requirements
-+    // match perplexity_service.query(&request.query, &conversation_id).await {
-+    //     Ok(answer) => {
-+    //         let response = PerplexityResponse {
-+    //             answer,
-+    //             conversation_id,
-+    //         };
-+    //         HttpResponse::Ok().json(response)
-+    //     }
-+    //     Err(e) => {
-+    //         error!("Error processing perplexity request: {}", e);
-+    //         HttpResponse::InternalServerError().json(format!("Error: {}", e))
-+    //     }
-+    // }
-+    
-+    // Return a default response while the perplexity service is disabled
-+    let response = PerplexityResponse {
-+        answer: "The Perplexity service is temporarily disabled for performance optimization.".to_string(),
-+        conversation_id,
-+    };
-+    HttpResponse::Ok().json(response)
- }
-diff --git a/src/handlers/socket_flow_handler.rs b/src/handlers/socket_flow_handler.rs
-index 2f28b871..cf145919 100644
---- a/src/handlers/socket_flow_handler.rs
-+++ b/src/handlers/socket_flow_handler.rs
-@@ -1,6 +1,7 @@
- use actix::prelude::*;
- use actix_web::{web, Error, HttpRequest, HttpResponse};
- use actix_web_actors::ws;
-+use futures::future::{self, Future};
- use flate2::{write::ZlibEncoder, Compression};
- use log::{debug, error, info, warn};
- use std::io::Write;
-@@ -14,6 +15,9 @@ use crate::utils::binary_protocol;
- use crate::types::vec3::Vec3Data;
- use crate::utils::socket_flow_messages::{BinaryNodeData, PingMessage, PongMessage};
- 
-+// Initialize node ID counter when module is loaded
-+use crate::models::node::Node;
-+
- // Constants for throttling debug logs
- const DEBUG_LOG_SAMPLE_RATE: usize = 10; // Only log 1 in 10 updates
- 
-@@ -27,6 +31,10 @@ const DEFAULT_MIN_UPDATE_RATE: u32 = 5;   // Min 5 updates per second when stabl
- const BATCH_UPDATE_WINDOW_MS: u64 = 200;  // Check motion every 200ms
- const DEFAULT_MAX_UPDATE_RATE: u32 = 60;  // Max 60 updates per second when active
- const DEFAULT_MOTION_THRESHOLD: f32 = 0.05;  // 5% of nodes need to be moving
-+
-+// Graph update check interval (check every 10 seconds)
-+const GRAPH_UPDATE_CHECK_INTERVAL: std::time::Duration = std::time::Duration::from_secs(10);
-+
- const DEFAULT_MOTION_DAMPING: f32 = 0.9;  // Smooth transitions in rate
- 
- // Maximum value for u16 node IDs
-@@ -62,6 +70,9 @@ pub struct SocketFlowServer {
-     nodes_in_motion: usize,    // Counter for nodes currently in motion
-     total_node_count: usize,   // Total node count for percentage calculation
-     last_motion_check: Instant, // Last time we checked motion percentage
-+    
-+    // Graph update check
-+    last_graph_update_check: Instant, // Last time we checked for graph updates
- }
- 
- impl SocketFlowServer {
-@@ -120,6 +131,7 @@ impl SocketFlowServer {
-             nodes_in_motion: 0,
-             total_node_count: 0,
-             last_motion_check: Instant::now(),
-+            last_graph_update_check: Instant::now(),
-         }
-     }
- 
-@@ -245,7 +257,7 @@ impl SocketFlowServer {
- 
-     // New method to mark a batch as sent
-     fn mark_batch_sent(&mut self) { self.last_batch_time = Instant::now(); }
--    
-+
-     // New method to collect nodes that have changed position
-     fn collect_changed_nodes(&mut self) -> Vec<(u16, BinaryNodeData)> {
-         let mut changed_nodes = Vec::new();
-@@ -278,6 +290,48 @@ impl Actor for SocketFlowServer {
-                 act.last_activity = std::time::Instant::now();
-             });
-         }
-+        
-+        // Set up periodic graph update check
-+        ctx.run_interval(GRAPH_UPDATE_CHECK_INTERVAL, |act, ctx| {
-+            // Get current time and check if we should perform an update check
-+            let now = Instant::now();
-+            let elapsed = now.duration_since(act.last_graph_update_check);
-+            
-+            // Only check periodically to reduce overhead
-+            if elapsed < GRAPH_UPDATE_CHECK_INTERVAL {
-+                return;
-+            }
-+            
-+            // Update timestamp first to prevent repeated checks
-+            act.last_graph_update_check = now;
-+            
-+            // Clone what we need to avoid borrowing issues
-+            let app_state_clone = act.app_state.clone();
-+            
-+            // Use a separate future for the async work, properly wrapped
-+            let fut = async move { 
-+                let status = app_state_clone.graph_update_status.read().await;
-+                (status.update_available, status.nodes_changed)
-+            };
-+            
-+            // Wrap the future and handle the result with proper actor context
-+            let wrapped_fut = actix::fut::wrap_future::<_, Self>(fut);
-+            ctx.spawn(wrapped_fut.map(|(update_available, nodes_changed), _act, ctx| {
-+                // If an update is available, send notification to client
-+                if update_available {
-+                    let message = serde_json::json!({
-+                        "type": "graphUpdateAvailable",
-+                        "timestamp": chrono::Utc::now().timestamp_millis(),
-+                        "nodesChanged": nodes_changed
-+                    });
-+                    
-+                    if let Ok(msg_str) = serde_json::to_string(&message) {
-+                        ctx.text(msg_str);
-+                        info!("Notified client of available graph update with {} node changes", nodes_changed);
-+                    }
-+                }
-+            }));
-+        });
- 
-         // Send simple connection established message
-         let response = serde_json::json!({
-@@ -512,7 +566,7 @@ impl StreamHandler<Result<ws::Message, ws::ProtocolError>> for SocketFlowServer
-                                                 
-                                                 // Use a simple recursive approach to restart the cycle
-                                                 let _app_state = act.app_state.clone();
--                    let _settings_clone = act.settings.clone();
-+                                                let _settings_clone = act.settings.clone();
-                                                 ctx.run_later(next_interval, move |act, ctx| {
-                                                     // Recursively call the handler to restart the cycle
-                                                     act.handle(Ok(ws::Message::Text("{\"type\":\"requestInitialData\"}".to_string().into())), ctx);
-@@ -546,6 +600,22 @@ impl StreamHandler<Result<ws::Message, ws::ProtocolError>> for SocketFlowServer
-                                     ctx.text(msg_str);
-                                 }
-                             }
-+                            
-+                            Some("fetchUpdatedGraph") => {
-+                                // Client is requesting to fetch updated graph data
-+                                info!("Client requesting to fetch updated graph data");
-+                                
-+                                // Reset the update flag in AppState
-+                                let app_state = self.app_state.clone();
-+                                let fut = async move {
-+                                    let mut update_status = app_state.graph_update_status.write().await;
-+                                    update_status.update_available = false;
-+                                };
-+                                
-+                                // Run as actor future
-+                                let fut = fut.into_actor(self);
-+                                ctx.spawn(fut.map(|_, _, _| ()));
-+                            }
-                             Some("enableRandomization") => {
-                                 if let Ok(enable_msg) = serde_json::from_value::<serde_json::Value>(msg.clone()) {
-                                     let enabled = enable_msg.get("enabled").and_then(|e| e.as_bool()).unwrap_or(false);
-@@ -736,6 +806,9 @@ pub async fn socket_flow_handler(
-     app_state: web::Data<AppState>,
-     settings: web::Data<Arc<RwLock<crate::config::Settings>>>,
- ) -> Result<HttpResponse, Error> {
-+    // Initialize node ID counter from persistent storage
-+    Node::initialize_id_counter();
-+    
-     let should_debug = settings.try_read().map(|s| {
-         s.system.debug.enabled && s.system.debug.enable_websocket_debug
-     }).unwrap_or(false);
-diff --git a/src/main.rs b/src/main.rs
-index 30bdd1c1..f1a71416 100755
---- a/src/main.rs
-+++ b/src/main.rs
-@@ -1,6 +1,7 @@
- use webxr::{
-     AppState,
-     config::Settings,
-+    models::graph::GraphData,
-     handlers::{
-         api_handler,
-         health_handler,
-@@ -10,8 +11,9 @@ use webxr::{
-     },
-     services::{
-         file_service::FileService,
--        graph_service::GraphService,
-+        file_service::{GRAPH_CACHE_PATH, LAYOUT_CACHE_PATH}, // Added import for cache paths
-         github::{GitHubClient, ContentAPI, GitHubConfig},
-+        graph_service::GraphService,
-     },
-     utils::gpu_compute::GPUCompute
- };
-@@ -21,7 +23,6 @@ use actix_cors::Cors;
- use actix_files::Files;
- use std::sync::Arc;
- use tokio::sync::RwLock;
--use tokio::time::Duration;
- use dotenvy::dotenv;
- use log::{error, info, debug, warn};
- use webxr::utils::logging::{init_logging_with_config, LogConfig};
-@@ -117,6 +118,23 @@ async fn main() -> std::io::Result<()> {
-     }
- 
-     info!("Loaded {} items from metadata store", metadata_store.len());
-+    
-+    // Ensure metadata directories are properly set up
-+    if let Err(e) = tokio::fs::create_dir_all("/app/data/metadata/files").await {
-+        warn!("Failed to create metadata directory: {}", e);
-+    }
-+    
-+    // Ensure parent directories for cache files exist
-+    if let Err(e) = tokio::fs::create_dir_all(std::path::Path::new(GRAPH_CACHE_PATH).parent().unwrap()).await {
-+        warn!("Failed to create directory for graph cache: {}", e);
-+    }
-+    if let Err(e) = tokio::fs::create_dir_all(std::path::Path::new(LAYOUT_CACHE_PATH).parent().unwrap()).await {
-+        warn!("Failed to create directory for layout cache: {}", e);
-+    }
-+    
-+    if tokio::fs::metadata("/app/data/metadata").await.is_ok() {
-+        info!("Verified metadata directory exists");
-+    }
- 
-     // Update metadata in app state
-     {
-@@ -125,84 +143,70 @@ async fn main() -> std::io::Result<()> {
-         info!("Loaded metadata into app state");
-     }
- 
-+    // Build initial graph from metadata and initialize GPU compute
-+    // LAZY INITIALIZATION: We don't build the graph on startup anymore
-+    // Instead, we'll build it when the first client request comes in
-+    info!("LAZY INITIALIZATION ENABLED: Deferring graph building until first client request");
-+
-     // Build initial graph from metadata and initialize GPU compute
-     info!("Building initial graph from existing metadata for physics simulation");
-     match GraphService::build_graph_from_metadata(&metadata_store).await {
--        Ok(graph_data) => {            
--            // Initialize GPU compute if not already done
--            if app_state.gpu_compute.is_none() {
--                info!("No GPU compute instance found, initializing one now");
--                match GPUCompute::new(&graph_data).await {
--                    Ok(gpu_instance) => {
--                        info!("GPU compute initialized successfully");
--                        // Update app_state with new GPU compute instance
--                        app_state.gpu_compute = Some(gpu_instance);
--                        
--                        // Shut down the existing GraphService before creating a new one
--                        info!("Shutting down existing graph service before reinitializing with GPU");
--                        let shutdown_start = std::time::Instant::now();
--                        app_state.graph_service.shutdown().await;
--                        info!("Graph service shutdown completed in {:?}", shutdown_start.elapsed());
--                        
--                        // Add a small delay to ensure clean shutdown
--                        tokio::time::sleep(Duration::from_millis(100)).await;
--                        
--                        // Reinitialize graph service with GPU compute
--                        info!("Reinitializing graph service with GPU compute");
--                        app_state.graph_service = GraphService::new(
--                            settings.clone(), 
--                            app_state.gpu_compute.clone()
--                        ).await;
--                        
--                        info!("Graph service successfully reinitialized with GPU compute");
--                    },
--                    Err(e) => {
--                        warn!("Failed to initialize GPU compute: {}. Continuing with CPU fallback.", e);
--                                        // Shut down the existing GraphService before creating a new one
--                        app_state.graph_service.shutdown().await;
--                        
--        // Initialize graph service with None as GPU compute (will use CPU fallback)
--                        app_state.graph_service = GraphService::new(
--                            settings.clone(), 
--                            None
--                        ).await;
--                        
--                        info!("Graph service initialized with CPU fallback");
--                    }
--                }
--            }
--
--            // Update graph data after GPU is initialized
-+        Ok(new_graph) => {
-+            // Update app state with the new graph
-             let mut graph = app_state.graph_service.get_graph_data_mut().await;
--            let mut node_map = app_state.graph_service.get_node_map_mut().await;
--            *graph = graph_data;
-+            *graph = new_graph;
-             
--            // Update node_map with new graph nodes
--            node_map.clear();
--            for node in &graph.nodes {
--                node_map.insert(node.id.clone(), node.clone());
-+            // Now initialize GPU with the populated graph
-+            info!("Initializing GPU compute with populated graph data");
-+            match GPUCompute::new(&*graph).await {
-+                Ok(gpu_instance) => {
-+                    info!("GPU compute initialized successfully");
-+                    app_state.gpu_compute = Some(gpu_instance);
-+                },
-+                Err(e) => warn!("Failed to initialize GPU compute: {}. Will use CPU fallback.", e)
-             }
--            
--            drop(graph);
--            drop(node_map);
--
--            info!("Built initial graph from metadata");
--            
-         },
--        Err(e) => {
--            error!("Failed to build initial graph: {}", e);
--            return Err(std::io::Error::new(std::io::ErrorKind::Other, format!("Failed to build initial graph: {}", e)));
--        }
-+        Err(e) => error!("Failed to build initial graph: {}", e)
-     }
--
--    // Add a delay to allow GPU computation to run before accepting client connections
--    info!("Waiting for initial physics layout calculation to complete...");
--    tokio::time::sleep(Duration::from_millis(500)).await;
--    info!("Initial delay complete. Starting HTTP server...");
-+    
-+    info!("Starting HTTP server with lazy graph initialization...");
- 
-     // Create web::Data after all initialization is complete
-     let app_state_data = web::Data::new(app_state);
- 
-+    // Pre-build graph to ensure cache files are created on startup
-+    if metadata_store.len() > 0 {
-+        info!("Pre-building graph to ensure cache files are created on startup");
-+        match GraphService::build_graph_from_metadata(&metadata_store).await {
-+            Ok(graph) => {
-+                info!("Successfully pre-built graph with {} nodes, {} edges", graph.nodes.len(), graph.edges.len());
-+                
-+                // Update the app state's graph service with the built graph
-+                let mut app_graph = app_state_data.graph_service.get_graph_data_mut().await;
-+                *app_graph = graph.clone();
-+                drop(app_graph);
-+                
-+                // Update the node map too
-+                let mut node_map = app_state_data.graph_service.get_node_map_mut().await;
-+                node_map.clear();
-+                for node in &graph.nodes {
-+                    node_map.insert(node.id.clone(), node.clone());
-+                }
-+                drop(node_map);
-+                
-+                // Explicitly verify the cache files were created
-+                if let Err(e) = tokio::fs::metadata(GRAPH_CACHE_PATH).await {
-+                    warn!("Graph cache file was not created: {}", e);
-+                }
-+                if let Err(e) = tokio::fs::metadata(LAYOUT_CACHE_PATH).await {
-+                    warn!("Layout cache file was not created: {}", e);
-+                }
-+            },
-+            Err(e) => warn!("Failed to pre-build graph: {}. Cache files may not be created until first request", e)
-+        }
-+        info!("Pre-build process completed");
-+    }
-+
-     // Start the server
-     let bind_address = {
-         let settings_read = settings.read().await;
-diff --git a/src/models/graph.rs b/src/models/graph.rs
-index e393442e..bb648b17 100755
---- a/src/models/graph.rs
-+++ b/src/models/graph.rs
-@@ -3,6 +3,7 @@ use super::edge::Edge;
- use super::metadata::MetadataStore;
- use serde::{Deserialize, Serialize};
- use std::collections::HashMap;
-+use chrono::{DateTime, Utc, Duration};
- 
- /// Represents the graph data structure containing nodes, edges, and metadata.
- /// All fields use camelCase serialization for client compatibility.
-@@ -15,18 +16,52 @@ pub struct GraphData {
-     pub edges: Vec<Edge>,
-     /// Metadata associated with the graph, using camelCase keys.
-     pub metadata: MetadataStore,
-+    /// Timestamp when the graph was last validated against metadata
-+    pub last_validated: DateTime<Utc>,
-     /// Mapping from numeric ID to metadata ID (filename) for lookup
-     #[serde(skip)]
-     pub id_to_metadata: HashMap<String, String>,
-+    /// Flag to indicate if the graph has been hot-started from cache
-+    #[serde(skip)]
-+    pub hot_started: bool,
-+}
-+
-+/// Status of background graph updates for WebSocket clients to check
-+#[derive(Clone, Debug)]
-+pub struct GraphUpdateStatus {
-+    /// Timestamp of the last update check
-+    pub last_check: DateTime<Utc>,
-+    /// Timestamp of the most recent update
-+    pub last_update: DateTime<Utc>,
-+    /// Whether an update is available that clients should fetch
-+    pub update_available: bool,
-+    /// Count of nodes changed in the last update
-+    pub nodes_changed: i32,
-+}
-+
-+impl Default for GraphUpdateStatus {
-+    fn default() -> Self {
-+        let now = Utc::now();
-+        Self {
-+            last_check: now,
-+            last_update: now - Duration::hours(1), // Initial offset to ensure first check is considered new
-+            update_available: false,
-+            nodes_changed: 0,
-+        }
-+    }
- }
- 
-+/// Implementation of GraphData for creating and manipulating graph data
-+/// All fields use camelCase serialization for client compatibility
- impl GraphData {
-     pub fn new() -> Self {
-         Self {
-             nodes: Vec::new(),
-             edges: Vec::new(),
-             metadata: MetadataStore::new(),
-+            last_validated: Utc::now(),
-             id_to_metadata: HashMap::new(),
-+            hot_started: false,
-         }
-     }
- }
-diff --git a/src/models/node.rs b/src/models/node.rs
-index 43c1ab3d..dffbdd5c 100755
---- a/src/models/node.rs
-+++ b/src/models/node.rs
-@@ -1,11 +1,19 @@
- use serde::{Deserialize, Serialize};
- use std::collections::HashMap;
--use std::sync::atomic::{AtomicU32, Ordering};
-+use std::sync::atomic::{AtomicU32, Ordering, AtomicBool};
- use crate::utils::socket_flow_messages::BinaryNodeData;
- use crate::types::vec3::Vec3Data;
-+use std::path::Path;
-+use std::fs;
-+use log::{info, warn};
- 
- // Static counter for generating unique numeric IDs
- static NEXT_NODE_ID: AtomicU32 = AtomicU32::new(1);  // Start from 1 (0 could be reserved)
-+static ID_INITIALIZED: AtomicBool = AtomicBool::new(false);
-+
-+// Constants for ID management
-+const MAX_NODE_ID_FILE: &str = "data/metadata/max_node_id.txt";
-+const MAX_U16_VALUE: u32 = 65535; // Maximum value for u16 to ensure compatibility with binary protocol
- 
- #[derive(Debug, Serialize, Deserialize, Clone)]
- #[serde(rename_all = "camelCase")]
-@@ -39,20 +47,122 @@ pub struct Node {
- }
- 
- impl Node {
-+    /// Initialize the NEXT_NODE_ID counter from stored max ID
-+    pub fn initialize_id_counter() {
-+        // Only initialize once to prevent race conditions
-+        if ID_INITIALIZED.swap(true, Ordering::SeqCst) {
-+            return;
-+        }
-+
-+        let max_id = Node::load_max_id_from_storage();
-+        
-+        // Update the counter if we found a valid ID
-+        if max_id > 0 {
-+            // Add 1 to ensure next ID is unique
-+            let next_id = max_id + 1;
-+            
-+            // Ensure we don't exceed u16 limit for binary protocol compatibility
-+            if next_id > MAX_U16_VALUE {
-+                warn!("Loaded max node ID {} exceeds u16 limit. Resetting to 1.", max_id);
-+                NEXT_NODE_ID.store(1, Ordering::SeqCst);
-+            } else {
-+                info!("Initialized node ID counter with value {} (loaded max ID: {})", next_id, max_id);
-+                NEXT_NODE_ID.store(next_id, Ordering::SeqCst);
-+            }
-+        } else {
-+            info!("No valid max node ID found, starting from 1");
-+            NEXT_NODE_ID.store(1, Ordering::SeqCst);
-+        }
-+    }
-+    
-+    /// Load the maximum node ID from storage
-+    fn load_max_id_from_storage() -> u32 {
-+        // Check if the file exists
-+        if !Path::new(MAX_NODE_ID_FILE).exists() {
-+            return 0;
-+        }
-+        
-+        // Try to read the file
-+        match fs::read_to_string(MAX_NODE_ID_FILE) {
-+            Ok(content) => {
-+                // Try to parse the content as u32
-+                match content.trim().parse::<u32>() {
-+                    Ok(id) => {
-+                        if id > 0 && id <= MAX_U16_VALUE {
-+                            return id;
-+                        } else {
-+                            warn!("Invalid node ID in storage: {}, must be between 1 and {}", id, MAX_U16_VALUE);
-+                        }
-+                    },
-+                    Err(e) => warn!("Failed to parse node ID from storage: {}", e)
-+                }
-+            },
-+            Err(e) => warn!("Failed to read max node ID file: {}", e)
-+        }
-+        
-+        0 // Return 0 if loading failed
-+    }
-+    
-+    /// Save the current maximum node ID to storage
-+    fn save_max_id_to_storage(id: u32) {
-+        // Create parent directory if it doesn't exist
-+        if let Some(parent) = Path::new(MAX_NODE_ID_FILE).parent() {
-+            if !parent.exists() {
-+                if let Err(e) = fs::create_dir_all(parent) {
-+                    warn!("Failed to create directory for max node ID: {}", e);
-+                    return;
-+                }
-+            }
-+        }
-+        
-+        // Write the ID to the file
-+        if let Err(e) = fs::write(MAX_NODE_ID_FILE, id.to_string()) {
-+            warn!("Failed to save max node ID to storage: {}", e);
-+        }
-+    }
-+    
-     pub fn new(metadata_id: String) -> Self {
-+        // Ensure ID counter is initialized
-+        if !ID_INITIALIZED.load(Ordering::SeqCst) {
-+            Node::initialize_id_counter();
-+        }
-+        
-         Self::new_with_id(metadata_id, None)
-     }
- 
-     pub fn new_with_id(metadata_id: String, provided_id: Option<String>) -> Self {
-+        // Ensure ID counter is initialized
-+        if !ID_INITIALIZED.load(Ordering::SeqCst) {
-+            Node::initialize_id_counter();
-+        }
-+        
-         // Always generate a new ID on the server side
-         // Use provided ID only if it's a valid numeric string (from a previous session)
-         let id = match provided_id {
-             Some(id) if !id.is_empty() && id != "0" && id.parse::<u32>().is_ok() => {
--                // Use the provided ID only if it's a valid numeric ID
--                id
-+                let parsed_id = id.parse::<u32>().unwrap();
-+                
-+                // Ensure we update our counter if this ID is higher
-+                if parsed_id > NEXT_NODE_ID.load(Ordering::SeqCst) {
-+                    NEXT_NODE_ID.store(parsed_id + 1, Ordering::SeqCst);
-+                    // Save the new maximum ID
-+                    Node::save_max_id_to_storage(parsed_id);
-+                }
-+                
-+                // Return the provided ID
-+                id.clone()
-             },
-             _ => {
--                NEXT_NODE_ID.fetch_add(1, Ordering::SeqCst).to_string()
-+                // Generate a new unique ID and save it
-+                let new_id = NEXT_NODE_ID.fetch_add(1, Ordering::SeqCst);
-+                
-+                // Save the new maximum ID periodically (every 10 IDs)
-+                if new_id % 10 == 0 {
-+                    Node::save_max_id_to_storage(new_id);
-+                }
-+                
-+                // Return the new ID as string
-+                new_id.to_string()
-             }
-         };
-         
-diff --git a/src/services/empty_graph_check.rs b/src/services/empty_graph_check.rs
-new file mode 100644
-index 00000000..a17ddb28
---- /dev/null
-+++ b/src/services/empty_graph_check.rs
-@@ -0,0 +1,21 @@
-+use crate::models::graph::GraphData;
-+use std::io::{Error, ErrorKind};
-+use log::warn;
-+
-+/// This function checks if a graph is empty or contains too few nodes
-+/// It is used before GPU operations to prevent errors
-+pub fn check_empty_graph(graph: &GraphData, min_nodes: usize) -> Result<(), Error> {
-+    // Check for completely empty graph
-+    if graph.nodes.is_empty() {
-+        return Err(Error::new(ErrorKind::InvalidData, 
-+            "Graph contains no nodes, cannot perform GPU computation on empty graph"));
-+    }
-+    
-+    // Check if graph is below recommended threshold
-+    if graph.nodes.len() < min_nodes {
-+        warn!("[Empty Graph Check] Graph contains only {} nodes, which is below the recommended minimum of {}. 
-+              This may cause instability in GPU computation.", graph.nodes.len(), min_nodes);
-+    }
-+    
-+    Ok(())
-+}
-\ No newline at end of file
-diff --git a/src/services/file_service.rs b/src/services/file_service.rs
-index 519ae9ae..bc0ef94f 100755
---- a/src/services/file_service.rs
-+++ b/src/services/file_service.rs
-@@ -2,7 +2,7 @@ use crate::models::metadata::{Metadata, MetadataStore, MetadataOps};
- use crate::models::graph::GraphData;
- use crate::config::Settings;
- use serde::{Deserialize, Serialize};
--use log::{info, debug, error};
-+use log::{info, debug, error, warn};
- use std::sync::atomic::{AtomicU32, Ordering};
- use regex::Regex;
- use std::fs;
-@@ -20,7 +20,11 @@ use std::io::Error;
- use super::github::{GitHubClient, ContentAPI, GitHubConfig};
- 
- // Constants
--const METADATA_PATH: &str = "/app/data/metadata/metadata.json";
-+pub const METADATA_PATH: &str = "/app/data/metadata/metadata.json"; // Legacy combined metadata path
-+pub const METADATA_DIR: &str = "/app/data/metadata";
-+pub const FILE_METADATA_DIR: &str = "/app/data/metadata/files"; // Directory for individual file metadata
-+pub const GRAPH_CACHE_PATH: &str = "/app/data/metadata/graph.json"; // Path for cached graph data
-+pub const LAYOUT_CACHE_PATH: &str = "/app/data/metadata/layout.json"; // Path for cached layout data
- pub const MARKDOWN_DIR: &str = "/app/data/markdown";
- const GITHUB_API_DELAY: Duration = Duration::from_millis(500);
- 
-@@ -184,8 +188,31 @@ impl FileService {
-     /// Load metadata from file or create new if not exists
-     pub fn load_or_create_metadata() -> Result<MetadataStore, String> {
-         // Ensure metadata directory exists
--        std::fs::create_dir_all("/app/data/metadata")
-+        std::fs::create_dir_all(METADATA_DIR)
-             .map_err(|e| format!("Failed to create metadata directory: {}", e))?;
-+            
-+        // Explicitly set permissions on metadata directory to ensure it's writable
-+        #[cfg(unix)]
-+        {
-+            use std::os::unix::fs::PermissionsExt;
-+            if let Err(e) = std::fs::set_permissions(METADATA_DIR, std::fs::Permissions::from_mode(0o777)) {
-+                warn!("Could not set permissions on metadata directory: {}", e);
-+                // Continue anyway, as this is not critical
-+            } else {
-+                info!("Successfully set permissions on metadata directory");
-+            }
-+        }
-+            
-+        // Ensure file metadata directory exists
-+        std::fs::create_dir_all(FILE_METADATA_DIR)
-+            .map_err(|e| format!("Failed to create file metadata directory: {}", e))?;
-+
-+        // Also set permissions on the file metadata directory
-+        #[cfg(unix)]
-+        {
-+            use std::os::unix::fs::PermissionsExt;
-+            let _ = std::fs::set_permissions(FILE_METADATA_DIR, std::fs::Permissions::from_mode(0o777));
-+        }
-         
-         let metadata_path = "/app/data/metadata/metadata.json";
-         
-@@ -264,6 +291,10 @@ impl FileService {
-     pub async fn initialize_local_storage(
-         settings: Arc<RwLock<Settings>>,
-     ) -> Result<(), Box<dyn StdError + Send + Sync>> {
-+        // First ensure directories exist with proper permissions
-+        info!("Ensuring metadata directories exist with proper permissions");
-+        Self::ensure_directories()?;
-+        
-         // Create GitHub client using environment variables
-         let github_config = GitHubConfig::from_env()
-             .map_err(|e| Box::new(e) as Box<dyn StdError + Send + Sync>)?;
-@@ -279,9 +310,6 @@ impl FileService {
- 
-         info!("Initializing local storage with files from GitHub");
- 
--        // Ensure directories exist and have proper permissions
--        Self::ensure_directories()?;
--
-         // Get all markdown files from GitHub
-         let github_files = content_api.list_markdown_files("").await?;
-         info!("Found {} markdown files in GitHub", github_files.len());
-@@ -467,13 +495,97 @@ impl FileService {
-             }
-         }
-     }
-+    
-+    /// Load metadata for a single file
-+    pub fn load_file_metadata(file_name: &str) -> Result<Option<Metadata>, Error> {
-+        let file_path = format!("{}/{}.json", FILE_METADATA_DIR, file_name);
-+        let metadata_path = Path::new(&file_path);
-+        
-+        if !metadata_path.exists() {
-+            return Ok(None);
-+        }
-+        
-+        match fs::read_to_string(metadata_path) {
-+            Ok(content) => {
-+                match serde_json::from_str::<Metadata>(&content) {
-+                    Ok(metadata) => Ok(Some(metadata)),
-+                    Err(e) => Err(Error::new(std::io::ErrorKind::InvalidData, 
-+                        format!("Failed to parse metadata for {}: {}", file_name, e)))
-+                }
-+            },
-+            Err(e) => Err(Error::new(std::io::ErrorKind::Other, 
-+                format!("Failed to read metadata file for {}: {}", file_name, e)))
-+        }
-+    }
-+    
-+    /// Save metadata for a single file
-+    pub fn save_file_metadata(file_name: &str, metadata: &Metadata) -> Result<(), Error> {
-+        let file_path = format!("{}/{}.json", FILE_METADATA_DIR, file_name);
-+        
-+        // Serialize the metadata to JSON
-+        let json = serde_json::to_string_pretty(metadata)
-+            .map_err(|e| Error::new(std::io::ErrorKind::Other, e.to_string()))?;
-+            
-+        // Write to file
-+        fs::write(&file_path, json)
-+            .map_err(|e| Error::new(std::io::ErrorKind::Other, 
-+                format!("Failed to write metadata for {}: {}", file_name, e)))
-+    }
-+    
-+    /// Check if a file has changed by comparing SHA1 hashes
-+    pub fn has_file_changed(file_name: &str, content: &str) -> Result<bool, Error> {
-+        // Calculate the SHA1 hash of the current content
-+        let current_hash = Self::calculate_sha1(content);
-+        
-+        // Try to load the existing metadata
-+        match Self::load_file_metadata(file_name)? {
-+            Some(metadata) => {
-+                // If we have metadata, compare the SHA1 hashes
-+                Ok(metadata.sha1 != current_hash)
-+            },
-+            None => {
-+                // If we don't have metadata, the file is considered changed
-+                Ok(true)
-+            }
-+        }
-+    }
-+    
-+    /// Load metadata from individual files
-+    pub fn load_all_file_metadata() -> Result<MetadataStore, Error> {
-+        let mut metadata_store = MetadataStore::new();
-+        
-+        // Read all .json files in the file metadata directory
-+        if let Ok(entries) = fs::read_dir(FILE_METADATA_DIR) {
-+            for entry in entries.filter_map(Result::ok) {
-+                if let Some(file_name) = entry.file_name().to_str().map(|s| s.to_owned()) {
-+                    if file_name.ends_with(".json") {
-+                        let base_name = file_name.trim_end_matches(".json");
-+                        if let Ok(Some(metadata)) = Self::load_file_metadata(base_name) {
-+                            metadata_store.insert(base_name.to_owned(), metadata);
-+                        }
-+                    }
-+                }
-+            }
-+        }
-+        
-+        Ok(metadata_store)
-+    }
- 
-     /// Save metadata to file
-     pub fn save_metadata(metadata: &MetadataStore) -> Result<(), Error> {
-+        // Save combined metadata for backward compatibility
-         let json = serde_json::to_string_pretty(metadata)
-             .map_err(|e| Error::new(std::io::ErrorKind::Other, e.to_string()))?;
-         fs::write(METADATA_PATH, json)
-             .map_err(|e| Error::new(std::io::ErrorKind::Other, e.to_string()))?;
-+        
-+        // Save individual file metadata
-+        for (file_name, metadata) in metadata {
-+            if let Err(e) = Self::save_file_metadata(file_name, metadata) {
-+                error!("Failed to save individual metadata for {}: {}", file_name, e);
-+            }
-+        }
-+        
-         Ok(())
-     }
- 
-@@ -494,12 +606,14 @@ impl FileService {
-     /// Fetch and process files from GitHub
-     pub async fn fetch_and_process_files(
-         &self,
--        content_api: Arc<ContentAPI>,
-+        content_api: &Arc<ContentAPI>,
-         _settings: Arc<RwLock<Settings>>,
-         metadata_store: &mut MetadataStore,
-     ) -> Result<Vec<ProcessedFile>, Box<dyn StdError + Send + Sync>> {
-         let mut processed_files = Vec::new();
--
-+        
-+        info!("Starting optimized file processing with hash-based invalidation");
-+        
-         // Get all markdown files from GitHub
-         let github_files = content_api.list_markdown_files("").await?;
-         info!("Found {} markdown files in GitHub", github_files.len());
-@@ -524,35 +638,67 @@ impl FileService {
- 
-                             // Only fetch full content for public files
-                             match content_api.fetch_file_content(&file_meta.download_url).await {
--                                Ok(content) => {
-+                                Ok(content) => {                                
-                                     let file_path = format!("{}/{}", MARKDOWN_DIR, file_meta.name);
--                                    if let Err(e) = fs::write(&file_path, &content) {
--                                        error!("Failed to write file {}: {}", file_path, e);
--                                        return Err(e.into());
--                                    }
--
--                                    let file_size = content.len();
--                                    let node_size = Self::calculate_node_size(file_size);
--
--                                    let metadata = Metadata {
--                                        file_name: file_meta.name.clone(),
--                                        file_size,
--                                        node_size,
--                                        node_id: "0".to_string(), // Will be assigned properly later
--                                        hyperlink_count: Self::count_hyperlinks(&content),
--                                        sha1: Self::calculate_sha1(&content),
--                                        last_modified: file_meta.last_modified.unwrap_or_else(|| Utc::now()),
--                                        perplexity_link: String::new(),
--                                        last_perplexity_process: None,
--                                        topic_counts: HashMap::new(), // Will be updated later
-+                                    // Calculate the SHA1 hash of the content
-+                                    let new_sha1 = Self::calculate_sha1(&content);
-+                                    
-+                                    // Check if the file has changed by comparing SHA1 hashes
-+                                    let file_changed = match Self::load_file_metadata(&file_meta.name) {
-+                                        Ok(Some(existing_metadata)) => {
-+                                            let changed = existing_metadata.sha1 != new_sha1;
-+                                            if !changed {
-+                                                debug!("File {} unchanged (SHA1 match), skipping processing", file_meta.name);
-+                                            } else {
-+                                                debug!("File {} has changed, reprocessing", file_meta.name);
-+                                            }
-+                                            changed
-+                                        },
-+                                        _ => {
-+                                            debug!("No existing metadata for {}, processing as new file", file_meta.name);
-+                                            true
-+                                        }
-                                     };
--
--                                    Ok(Some(ProcessedFile {
--                                        file_name: file_meta.name.clone(),
--                                        content,
--                                        is_public: true,
--                                        metadata,
--                                    }))
-+                                    
-+                                    // Only process the file if it has changed or if we don't have metadata for it
-+                                    if file_changed {
-+                                        // Write the content to the file
-+                                        if let Err(e) = fs::write(&file_path, &content) {
-+                                            error!("Failed to write file {}: {}", file_path, e);
-+                                            return Err(e.into());
-+                                        }
-+
-+                                        let file_size = content.len();
-+                                        let node_size = Self::calculate_node_size(file_size);
-+
-+                                        // Create new metadata or update existing
-+                                        let mut metadata = Self::load_file_metadata(&file_meta.name)
-+                                            .unwrap_or_default()
-+                                            .unwrap_or_default();
-+                                            
-+                                        // Update metadata fields
-+                                        metadata.file_name = file_meta.name.clone();
-+                                        metadata.file_size = file_size;
-+                                        metadata.node_size = node_size;
-+                                        metadata.hyperlink_count = Self::count_hyperlinks(&content);
-+                                        metadata.sha1 = new_sha1;
-+                                        metadata.last_modified = file_meta.last_modified.unwrap_or_else(|| Utc::now());
-+                                        
-+                                        // Keep existing values for these fields if present
-+                                        if metadata.node_id == "0" || metadata.node_id.is_empty() {
-+                                            metadata.node_id = "0".to_string(); // Will be assigned properly later
-+                                        }
-+
-+                                        Ok(Some(ProcessedFile {
-+                                            file_name: file_meta.name.clone(),
-+                                            content,
-+                                            is_public: true,
-+                                            metadata,
-+                                        }))
-+                                    } else {
-+                                        // If the file hasn't changed, return None so we don't process it again
-+                                        Ok(None)
-+                                    }
-                                 }
-                                 Err(e) => {
-                                     error!("Failed to fetch content for {}: {}", file_meta.name, e);
-@@ -574,7 +720,17 @@ impl FileService {
-             for result in results {
-                 match result {
-                     Ok(Some(processed_file)) => {
-+                        // Save individual file metadata
-+                        if let Err(e) = Self::save_file_metadata(
-+                            &processed_file.file_name, 
-+                            &processed_file.metadata
-+                        ) {
-+                            error!("Failed to save metadata for {}: {}", 
-+                                processed_file.file_name, e);
-+                        }
-+                        
-                         processed_files.push(processed_file);
-+                        info!("Processed file: {}", processed_files.last().unwrap().file_name);
-                     }
-                     Ok(None) => continue, // Skipped non-public file
-                     Err(e) => {
-diff --git a/src/services/graph_service.rs b/src/services/graph_service.rs
-index 41082b88..a7d7a381 100755
---- a/src/services/graph_service.rs
-+++ b/src/services/graph_service.rs
-@@ -11,7 +11,7 @@ use std::pin::Pin;
- use std::time::{Duration, Instant};
- use futures::Future;
- use log::{info, warn, error, debug};
--use scopeguard;
-+use scopeguard; 
- 
- use tokio::fs::File as TokioFile;
- use crate::models::graph::GraphData;
-@@ -23,8 +23,11 @@ use crate::config::Settings;
- use crate::utils::gpu_compute::GPUCompute;
- use crate::models::simulation_params::{SimulationParams, SimulationPhase, SimulationMode};
- use crate::models::pagination::PaginatedGraphData;
-+use tokio::io::AsyncReadExt;
- use tokio::sync::Mutex;
- use once_cell::sync::Lazy;
-+use crate::services::file_service::GRAPH_CACHE_PATH;
-+use crate::services::file_service::LAYOUT_CACHE_PATH;
- 
- // Static flag to prevent multiple simultaneous graph rebuilds
- static GRAPH_REBUILD_IN_PROGRESS: AtomicBool = AtomicBool::new(false);
-@@ -44,6 +47,7 @@ const METADATA_FILE_CHECK_INTERVAL_MS: u64 = 100; // Check every 100ms
- // Constants for GPU retry mechanism
- const MAX_GPU_CALCULATION_RETRIES: u32 = 3;
- const GPU_RETRY_DELAY_MS: u64 = 500; // 500ms delay between retries
-+const GPU_INIT_WAIT_MS: u64 = 1000; // 1 second wait before GPU test
- 
- #[derive(Clone)]
- pub struct GraphService {
-@@ -81,7 +85,7 @@ impl GraphService {
-         if gpu_compute.is_some() {
-             info!("[GraphService] GPU compute is enabled - physics simulation will run");
-             info!("[GraphService] Testing GPU compute functionality at startup");
--            tokio::spawn(Self::test_gpu_at_startup(gpu_compute.clone()));
-+            tokio::spawn(Self::test_gpu_at_startup(gpu_compute.clone(), simulation_id.clone()));
-         } else {
-             error!("[GraphService] GPU compute is NOT enabled - physics simulation will use CPU fallback");
-         }
-@@ -135,6 +139,9 @@ impl GraphService {
-         // Release the mutex before spawning the task
-         drop(guard);
-         
-+        // Try to load cached graph data
-+        let _ = Self::try_load_cached_graph_data(Arc::clone(&graph_service.graph_data)).await;
-+        
-         info!("[GraphService] Starting physics simulation loop (ID: {})", loop_simulation_id);
-         tokio::spawn(async move {
-             let params = SimulationParams {
-@@ -269,28 +276,28 @@ impl GraphService {
-     }
-     
-     /// Test GPU compute at startup to verify it's working
--    async fn test_gpu_at_startup(gpu_compute: Option<Arc<RwLock<GPUCompute>>>) {
-+    async fn test_gpu_at_startup(gpu_compute: Option<Arc<RwLock<GPUCompute>>>, instance_id: String) {
-         // Add a small delay to let other initialization complete
--        tokio::time::sleep(Duration::from_millis(1000)).await;
-+        tokio::time::sleep(Duration::from_millis(GPU_INIT_WAIT_MS)).await;
-         
--        info!("[GraphService] Running GPU startup test");
-+        info!("[GraphService:{}] Running GPU startup test", instance_id);
-         
-         if let Some(gpu) = &gpu_compute {
-             match gpu.read().await.test_compute() {
-                 Ok(_) => {
--                    info!("[GraphService] ✅ GPU test computation succeeded - GPU physics is working");
-+                    info!("[GraphService:{}] ✅ GPU test computation succeeded - GPU physics is working", instance_id);
-                 },
-                 Err(e) => {
--                    error!("[GraphService] ❌ GPU test computation failed: {}", e);
--                    error!("[GraphService] The system will fall back to CPU physics which may be slower");
-+                    error!("[GraphService:{}] ❌ GPU test computation failed: {}", instance_id, e);
-+                    error!("[GraphService:{}] The system will fall back to CPU physics which may be slower", instance_id);
-                     
-                     // Try initializing a new GPU instance
--                    info!("[GraphService] Attempting to reinitialize GPU...");
-+                    info!("[GraphService:{}] Attempting to reinitialize GPU...", instance_id);
-                     let _new_gpu = GPUCompute::new(&GraphData::default()).await; // Using _ to avoid unused warning
-                 }
-             }
-         } else {
--            error!("[GraphService] ❌ No GPU compute instance available for testing");
-+            error!("[GraphService:{}] ❌ No GPU compute instance available for testing", instance_id);
-         }
-     }
-     
-@@ -346,6 +353,35 @@ impl GraphService {
-     pub async fn build_graph_from_metadata(metadata: &MetadataStore) -> Result<GraphData, Box<dyn std::error::Error + Send + Sync>> {
-         // Check if a rebuild is already in progress
-         info!("Building graph from {} metadata entries", metadata.len());
-+        
-+        // Try to load from cache first if metadata has not changed
-+        if let Ok(cached_graph) = Self::load_graph_cache().await {
-+            // Check if cached graph matches current metadata
-+            info!("Checking if cached graph is valid: {} cache entries vs {} metadata entries", cached_graph.metadata.len(), metadata.len());
-+            if cached_graph.metadata.len() == metadata.len() {
-+                // Simple check: count metadata items
-+                let mut needs_rebuild = false;
-+                
-+                // More detailed check: compare sha1 hashes
-+                for (file_name, meta) in metadata.iter() {
-+                    if !cached_graph.metadata.contains_key(file_name) || 
-+                       cached_graph.metadata[file_name].sha1 != meta.sha1 {
-+                        needs_rebuild = true;
-+                        break;
-+                    }
-+                }
-+
-+                if !needs_rebuild {
-+                    info!("Cached graph is valid (all SHA1 hashes match), using it");
-+                    let mut cloned_graph = cached_graph.clone();
-+                    
-+                    // Ensure timestamp is updated to show it was validated
-+                    cloned_graph.last_validated = chrono::Utc::now();
-+                    
-+                    return Ok(cloned_graph);
-+                }
-+            }
-+        }
-         debug!("Building graph from {} metadata entries", metadata.len());
-         
-         if GRAPH_REBUILD_IN_PROGRESS.compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst).is_err() {
-@@ -494,10 +530,29 @@ impl GraphService {
-             .collect();
- 
-         // Initialize random positions
--        Self::initialize_random_positions(&mut graph);
-+        // Try to use cached layout positions first, fall back to random if not available
-+        if let Err(e) = Self::initialize_positions(&mut graph).await {
-+            warn!("Failed to initialize positions from cache: {}, using random positions", e);
-+            Self::initialize_random_positions(&mut graph);
-+        }
- 
--        info!("Built graph with {} nodes and {} edges", graph.nodes.len(), graph.edges.len());
-+        // Record validation timestamp
-+        graph.last_validated = chrono::Utc::now();
-+        
-+        // Take a layout snapshot to provide for client initialization
-+        info!("Taking layout snapshot after graph build");
-+        if let Err(e) = Self::save_layout_cache(graph.clone()).await {
-+            warn!("Failed to take layout snapshot: {}", e);
-+        }
-+        
-+        info!("Built graph with {} nodes and {} edges (validated at {})",
-+              graph.nodes.len(), graph.edges.len(), graph.last_validated);
-         debug!("Completed graph build: {} nodes, {} edges", graph.nodes.len(), graph.edges.len());
-+        
-+        // Cache the graph data to disk
-+        if let Err(e) = Self::save_graph_cache(&graph).await {
-+            warn!("Failed to cache graph data: {}", e);
-+        }
-         Ok(graph)
-     }
- 
-@@ -656,10 +711,25 @@ impl GraphService {
-             .collect();
- 
-         // Initialize random positions for all nodes
--        Self::initialize_random_positions(&mut graph);
-+        // Try to use cached layout positions first, fall back to random if not available
-+        if let Err(e) = Self::initialize_positions(&mut graph).await {
-+            warn!("Failed to initialize positions from cache: {}", e);
-+            Self::initialize_random_positions(&mut graph);
-+        }
- 
-         info!("Built graph with {} nodes and {} edges", graph.nodes.len(), graph.edges.len());
-         debug!("Completed graph build: {} nodes, {} edges", graph.nodes.len(), graph.edges.len());
-+        
-+        // Take a layout snapshot to provide for client initialization
-+        info!("Taking layout snapshot after graph build");
-+        if let Err(e) = Self::save_layout_cache(graph.clone()).await {
-+            warn!("Failed to take layout snapshot: {}", e);
-+        }
-+        
-+        // Cache the graph data to disk
-+        if let Err(e) = Self::save_graph_cache(&graph).await {
-+            warn!("Failed to cache graph data: {}", e);
-+        }
-         Ok(graph)
-     }
- 
-@@ -706,6 +776,34 @@ impl GraphService {
-             }
-         }
-     }
-+    
-+    // Initialize positions using cached values or random positions as fallback
-+    pub async fn initialize_positions(graph: &mut GraphData) -> Result<(), std::io::Error> {
-+        // Try to load positions from cache first
-+        match Self::load_layout_cache().await {
-+            Ok(position_map) => {
-+                debug!("Applying cached positions to {} nodes", position_map.len());
-+                let mut applied_count = 0;
-+                
-+                for node in &mut graph.nodes {
-+                    if let Some(&(x, y, z)) = position_map.get(&node.id) {
-+                        node.set_x(x);
-+                        node.set_y(y);
-+                        node.set_z(z);
-+                        applied_count += 1;
-+                    }
-+                }
-+                
-+                info!("Applied cached positions to {}/{} nodes", applied_count, graph.nodes.len());
-+                Ok(())
-+            },
-+            Err(e) => {
-+                info!("No cached positions available, using random initialization: {}", e);
-+                Self::initialize_random_positions(graph);
-+                Ok(())
-+            }
-+        }
-+    }
- 
-     /// Helper function to retry GPU layout calculation with exponential backoff
-     pub async fn calculate_layout_with_retry(
-@@ -714,6 +812,17 @@ impl GraphService {
-         node_map: &mut HashMap<String, Node>, 
-         params: &SimulationParams,
-     ) -> std::io::Result<()> {
-+        // First validate the graph data to avoid potential GPU issues
-+        if graph.nodes.is_empty() {
-+            warn!("[calculate_layout_with_retry] Empty graph received, cannot perform GPU calculation");
-+            return Err(Error::new(ErrorKind::InvalidData, "Cannot perform GPU calculation on empty graph"));
-+        }
-+        
-+        if let Err(e) = crate::services::empty_graph_check::check_empty_graph(graph, 5) {
-+            warn!("[calculate_layout_with_retry] Graph data validation failed: {}. Falling back to CPU.", e);
-+            return Self::calculate_layout_cpu(graph, node_map, params);
-+        }
-+        
-         debug!("[calculate_layout_with_retry] Starting GPU calculation with retry mechanism");
-         let mut last_error: Option<Error> = None;
-         
-@@ -766,7 +875,7 @@ impl GraphService {
-     ) -> std::io::Result<()> {
-         {
-             info!("[calculate_layout] Starting GPU physics calculation for {} nodes, {} edges with mode {:?}", 
--                  graph.nodes.len(), graph.edges.len(), params.mode);
-+                graph.nodes.len(), graph.edges.len(), params.mode);
-             
-             // Get current timestamp for performance tracking
-             let start_time = std::time::Instant::now();
-@@ -774,7 +883,7 @@ impl GraphService {
-             let mut gpu_compute = gpu_compute.write().await;
- 
-             info!("[calculate_layout] params: iterations={}, spring_strength={:.3}, repulsion={:.3}, damping={:.3}",
--                 params.iterations, params.spring_strength, params.repulsion, params.damping);
-+                params.iterations, params.spring_strength, params.repulsion, params.damping);
-             
-             // Update data and parameters
-             if let Err(e) = gpu_compute.update_graph_data(graph) {
-@@ -843,11 +952,15 @@ impl GraphService {
-                     format!("[{:.2},{:.2},{:.2}]", graph.nodes[0].data.position.x, graph.nodes[0].data.position.y, graph.nodes[0].data.position.z)
-                 } else { "no nodes".to_string() };
-             
--                info!("[calculate_layout] Updated positions for {}/{} nodes in {:?}. Sample positions: {}", nodes_updated, graph.nodes.len(), elapsed, sample_positions);
-+            info!("[calculate_layout] Updated positions for {}/{} nodes in {:?}. Sample positions: {}", nodes_updated, graph.nodes.len(), elapsed, sample_positions);
-             
--            Ok(())
-+            // Return success
-+            ()
-         }
--    }
-+        
-+        // Return success
-+        Ok(())
-+   }
- 
-     /// CPU fallback implementation of force-directed graph layout
-     pub fn calculate_layout_cpu(
-@@ -1041,7 +1154,9 @@ impl GraphService {
-         let elapsed = start_time.elapsed();
-         info!("[calculate_layout_cpu] Updated positions for {} nodes in {:?}", 
-              graph.nodes.len(), elapsed);
-+             
-         
-+        // Return success
-         Ok(())
-     }
- 
-@@ -1095,6 +1210,13 @@ impl GraphService {
-         *cache = None;
-     }
- 
-+    /// Take a layout snapshot and save it to disk (only called explicitly, not after every physics update)
-+    pub async fn take_layout_snapshot(&self) -> Result<(), std::io::Error> {
-+        let graph = self.graph_data.read().await;
-+        info!("Taking layout snapshot to {}", LAYOUT_CACHE_PATH);
-+        Self::save_layout_cache((*graph).clone()).await
-+    }
-+
-     pub async fn get_node_positions(&self) -> Vec<Node> {
-         let start_time = Instant::now();
- 
-@@ -1154,6 +1276,241 @@ impl GraphService {
-         self.gpu_compute.clone()
-     }
- 
-+    /// Save graph data to cache file
-+    pub async fn save_graph_cache(graph: &GraphData) -> Result<(), std::io::Error> {
-+        info!("Attempting to cache graph data to {}", GRAPH_CACHE_PATH);
-+        let start_time = std::time::Instant::now();
-+        info!("Graph contains {} nodes and {} edges", graph.nodes.len(), graph.edges.len());
-+        
-+        // Ensure the directory exists
-+        if let Some(dir) = std::path::Path::new(GRAPH_CACHE_PATH).parent() {
-+            if !dir.exists() {
-+                info!("Creating directory: {:?}", dir);
-+                match std::fs::create_dir_all(dir) {
-+                    Ok(_) => {
-+                        info!("Successfully created directory: {:?}", dir);
-+                        
-+                        // Set directory permissions explicitly on Unix systems
-+                        #[cfg(unix)]
-+                        {
-+                            use std::os::unix::fs::PermissionsExt;
-+                            if let Err(e) = std::fs::set_permissions(dir, std::fs::Permissions::from_mode(0o777)) {
-+                                warn!("Could not set permissions on cache directory: {}", e);
-+                            }
-+                        }
-+                    },
-+                    Err(e) => {
-+                        error!("Failed to create directory {:?}: {}", dir, e);
-+                        // Continue anyway since the directory might already exist with different permissions
-+                    }
-+                }
-+            }
-+        }
-+        
-+        // Serialize graph to JSON with pretty formatting for easier debugging
-+        let json = match serde_json::to_string_pretty(graph) {
-+            Ok(json) => json,
-+            Err(e) => {
-+                error!("Failed to serialize graph data: {}", e);
-+                return Err(std::io::Error::new(std::io::ErrorKind::Other, e.to_string()));
-+            }
-+        };
-+
-+        // First try using standard file system functions, which might be more reliable
-+        info!("Writing {} bytes to file {} using std::fs", json.len(), GRAPH_CACHE_PATH);
-+        match std::fs::write(GRAPH_CACHE_PATH, json.as_bytes()) {
-+            Ok(_) => {
-+                let elapsed = start_time.elapsed();
-+                info!("Successfully cached graph data ({} bytes) to {} in {:?} using std::fs", 
-+                      json.len(), GRAPH_CACHE_PATH, elapsed);
-+                return Ok(());
-+            }
-+            Err(e) => {
-+                warn!("Failed to write graph cache using std::fs, falling back to tokio::fs: {}", e);
-+                // Fall through to tokio version below
-+            }
-+        }
-+        
-+        // Fall back to tokio's async fs
-+        info!("Writing {} bytes to file {} using tokio::fs", json.len(), GRAPH_CACHE_PATH);
-+        match tokio::fs::write(GRAPH_CACHE_PATH, json.as_bytes()).await {
-+            Ok(_) => {
-+                info!("Successfully cached graph data ({} bytes) to {}", json.len(), GRAPH_CACHE_PATH);
-+                Ok(())
-+            },
-+            Err(e) => {
-+                error!("Failed to write graph cache file {}: {}", GRAPH_CACHE_PATH, e);
-+                Err(e)
-+            }
-+        }
-+    }
-+    
-+    /// Load graph data from cache file
-+    pub async fn load_graph_cache() -> Result<GraphData, std::io::Error> {
-+        info!("Attempting to load graph data from cache: {}", GRAPH_CACHE_PATH);
-+        debug!("GRAPH_CACHE_PATH = {}", GRAPH_CACHE_PATH);
-+        
-+        // Check if cache file exists
-+        if !tokio::fs::metadata(GRAPH_CACHE_PATH).await.is_ok() {
-+            return Err(std::io::Error::new(
-+                std::io::ErrorKind::NotFound, 
-+                "Graph cache file not found"
-+            ));
-+        }
-+        
-+        // Read file content
-+        let mut file = tokio::fs::File::open(GRAPH_CACHE_PATH).await?;
-+        let mut content = String::new();
-+        
-+        // Read the file content
-+        file.read_to_string(&mut content).await?;
-+        
-+        // Deserialize JSON
-+        let graph = serde_json::from_str::<GraphData>(&content)
-+            .map_err(|e| std::io::Error::new(
-+                std::io::ErrorKind::InvalidData, 
-+                format!("Failed to parse graph cache: {}", e)
-+            ))?;
-+        
-+        info!("Successfully loaded graph data from cache ({} nodes, {} edges), last validated: {}", 
-+              graph.nodes.len(), graph.edges.len(), graph.last_validated);
-+              
-+        // Return the loaded graph
-+        Ok(graph) 
-+    }
-+    
-+    /// Try to load cached graph data into the provided graph_data RwLock
-+    pub async fn try_load_cached_graph_data(graph_data: Arc<RwLock<GraphData>>) -> Result<(), std::io::Error> {
-+        match Self::load_graph_cache().await {
-+            Ok(cached_graph) => {
-+                info!("Initializing graph service with cached graph data");
-+                let mut graph = graph_data.write().await;
-+                *graph = cached_graph;
-+                info!("Graph service initialized with {} nodes and {} edges from cache",
-+                     graph.nodes.len(), graph.edges.len());
-+                Ok(())
-+            },
-+            Err(e) => {
-+                info!("No valid graph cache found: {}", e);
-+                Err(e)
-+            }
-+        }
-+    }
-+    
-+    /// Save layout positions to cache file
-+    pub async fn save_layout_cache(graph: GraphData) -> Result<(), std::io::Error> {
-+        info!("Attempting to cache node layout positions to {}", LAYOUT_CACHE_PATH);
-+        let start_time = std::time::Instant::now();
-+        
-+        // Ensure the directory exists
-+        if let Some(dir) = std::path::Path::new(LAYOUT_CACHE_PATH).parent() {
-+            if !dir.exists() {
-+                info!("Creating directory: {:?}", dir);
-+                match std::fs::create_dir_all(dir) {
-+                    Ok(_) => {
-+                        info!("Successfully created directory: {:?}", dir);
-+                        
-+                        // Set directory permissions explicitly on Unix systems
-+                        #[cfg(unix)]
-+                        {
-+                            use std::os::unix::fs::PermissionsExt;
-+                            if let Err(e) = std::fs::set_permissions(dir, std::fs::Permissions::from_mode(0o777)) {
-+                                warn!("Could not set permissions on cache directory: {}", e);
-+                            }
-+                        }
-+                    },
-+                    Err(e) => {
-+                        error!("Failed to create directory {:?}: {}", dir, e);
-+                        // Continue anyway since the directory might already exist with different permissions
-+                    }
-+                }
-+            }
-+        }
-+        
-+        // Create a serializable structure with just the necessary position information
-+        info!("Building position data array for {} nodes", graph.nodes.len());
-+        let positions: Vec<(String, f32, f32, f32)> = graph.nodes.iter()
-+            .map(|node| (
-+                node.id.clone(),
-+                node.data.position.x,
-+                node.data.position.y,
-+                node.data.position.z
-+            ))
-+            .collect();
-+        
-+        // Serialize positions to JSON with pretty formatting for easier debugging
-+        let json = match serde_json::to_string_pretty(&positions) {
-+            Ok(json) => json,
-+            Err(e) => {
-+                error!("Failed to serialize layout positions: {}", e);
-+                return Err(std::io::Error::new(std::io::ErrorKind::Other, e.to_string()));
-+            }
-+        };
-+
-+        // First try using standard file system functions, which might be more reliable
-+        info!("Writing {} bytes to file {} using std::fs", json.len(), LAYOUT_CACHE_PATH);
-+        match std::fs::write(LAYOUT_CACHE_PATH, json.as_bytes()) {
-+            Ok(_) => {
-+                let elapsed = start_time.elapsed();
-+                info!("Successfully cached layout data for {} nodes to {} in {:?} using std::fs", 
-+                      positions.len(), LAYOUT_CACHE_PATH, elapsed);
-+                return Ok(());
-+            }
-+            Err(e) => {
-+                warn!("Failed to write layout cache using std::fs, falling back to tokio::fs: {}", e);
-+                // Fall through to tokio version below
-+            }
-+        }
-+        
-+        // Fall back to tokio's async fs 
-+        info!("Writing {} bytes to file {} using tokio::fs", json.len(), LAYOUT_CACHE_PATH);
-+        match tokio::fs::write(LAYOUT_CACHE_PATH, json.as_bytes()).await {
-+            Ok(_) => {
-+                info!("Successfully cached layout data for {} nodes to {}", positions.len(), LAYOUT_CACHE_PATH);
-+                Ok(())
-+            },
-+            Err(e) => {
-+                error!("Failed to write layout cache file {}: {}", LAYOUT_CACHE_PATH, e);
-+                Err(e)
-+            }
-+        }
-+    }
-+    
-+    /// Load layout positions from cache file
-+    pub async fn load_layout_cache() -> Result<HashMap<String, (f32, f32, f32)>, std::io::Error> {
-+        info!("Attempting to load layout from cache: {}", LAYOUT_CACHE_PATH);
-+        
-+        // Check if cache file exists
-+        if !tokio::fs::metadata(LAYOUT_CACHE_PATH).await.is_ok() {
-+            return Err(std::io::Error::new(
-+                std::io::ErrorKind::NotFound, 
-+                "Layout cache file not found"
-+            ));
-+        }
-+        
-+        // Read file content
-+        let mut file = tokio::fs::File::open(LAYOUT_CACHE_PATH).await?;
-+        let mut content = String::new();
-+        file.read_to_string(&mut content).await?;
-+        
-+        // Deserialize JSON
-+        let positions = serde_json::from_str::<Vec<(String, f32, f32, f32)>>(&content)
-+            .map_err(|e| std::io::Error::new(
-+                std::io::ErrorKind::InvalidData, 
-+                format!("Failed to parse layout cache: {}", e)
-+            ))?;
-+        
-+        // Convert to HashMap
-+        let position_map: HashMap<String, (f32, f32, f32)> = positions.into_iter()
-+            .map(|(id, x, y, z)| (id, (x, y, z)))
-+            .collect();
-+        
-+        info!("Successfully loaded layout positions for {} nodes from cache", 
-+              position_map.len());
-+        Ok(position_map)
-+    }
-+
-+
-     pub async fn update_node_positions(&self, updates: Vec<(u16, Node)>) -> Result<(), Error> {
-         let mut graph = self.graph_data.write().await;
-         let mut node_map = self.node_map.write().await;
-diff --git a/src/services/mod.rs b/src/services/mod.rs
-index 81bebaf9..93a34ac6 100755
---- a/src/services/mod.rs
-+++ b/src/services/mod.rs
-@@ -1,6 +1,7 @@
- pub mod github;
- pub mod file_service;
- pub mod graph_service;
-+pub mod empty_graph_check;
- pub mod nostr_service;
- pub mod perplexity_service;
- pub mod ragflow_service;
-diff --git a/src/services/nostr_service.rs b/src/services/nostr_service.rs
-index a8c46855..faa36be0 100644
---- a/src/services/nostr_service.rs
-+++ b/src/services/nostr_service.rs
-@@ -10,7 +10,7 @@ use std::sync::Arc;
- use tokio::sync::RwLock;
- use chrono::Utc;
- use thiserror::Error;
--use log::{debug, error, info};
-+use log::{debug, error, info, warn};
- use uuid::Uuid;
- 
- #[derive(Debug, Error)]
-@@ -57,7 +57,11 @@ impl NostrService {
-         let power_users = std::env::var("POWER_USER_PUBKEYS")
-             .unwrap_or_default()
-             .split(',')
--            .map(|s| s.trim().to_string())
-+            .map(|s| {
-+                let trimmed = s.trim().to_string();
-+                debug!("Loaded power user pubkey: '{}'", trimmed);
-+                trimmed
-+            })
-             .collect();
- 
-         let token_expiry = std::env::var("AUTH_TOKEN_EXPIRY")
-@@ -110,7 +114,12 @@ impl NostrService {
-         }
- 
-         let now = Utc::now();
--        let is_power_user = self.power_user_pubkeys.contains(&event.pubkey);
-+        let trimmed_pubkey = event.pubkey.trim().to_string();
-+        let is_power_user = self.power_user_pubkeys.iter().any(|p| p.trim() == trimmed_pubkey);
-+        
-+        debug!("Checking power user status for pubkey '{}', result: {}", trimmed_pubkey, is_power_user);
-+        debug!("Power users list: {:?}", self.power_user_pubkeys);
-+        debug!("Is pubkey in list with exact match: {}", self.power_user_pubkeys.contains(&trimmed_pubkey));
- 
-         // Generate session token
-         let session_token = Uuid::new_v4().to_string();
-@@ -136,14 +145,16 @@ impl NostrService {
-     }
- 
-     pub async fn get_user(&self, pubkey: &str) -> Option<NostrUser> {
-+        let trimmed_pubkey = pubkey.trim();
-         let users = self.users.read().await;
--        users.get(pubkey).cloned()
-+        users.get(trimmed_pubkey).cloned()
-     }
- 
-     pub async fn update_user_api_keys(&self, pubkey: &str, api_keys: ApiKeys) -> Result<NostrUser, NostrError> {
-+        let trimmed_pubkey = pubkey.trim();
-         let mut users = self.users.write().await;
--        
--        if let Some(user) = users.get_mut(pubkey) {
-+        debug!("Updating API keys for pubkey: '{}'", trimmed_pubkey);
-+        if let Some(user) = users.get_mut(trimmed_pubkey) {
-             if user.is_power_user {
-                 return Err(NostrError::PowerUserOperation);
-             }
-@@ -156,7 +167,9 @@ impl NostrService {
-     }
- 
-     pub async fn validate_session(&self, pubkey: &str, token: &str) -> bool {
--        if let Some(user) = self.get_user(pubkey).await {
-+        let trimmed_pubkey = pubkey.trim();
-+        debug!("Validating session for pubkey: '{}'", trimmed_pubkey);
-+        if let Some(user) = self.get_user(trimmed_pubkey).await {
-             if let Some(session_token) = user.session_token {
-                 let now = Utc::now().timestamp();
-                 if now - user.last_seen <= self.token_expiry {
-@@ -168,9 +181,10 @@ impl NostrService {
-     }
- 
-     pub async fn refresh_session(&self, pubkey: &str) -> Result<String, NostrError> {
-+        let trimmed_pubkey = pubkey.trim();
-         let mut users = self.users.write().await;
--        
--        if let Some(user) = users.get_mut(pubkey) {
-+        debug!("Refreshing session for pubkey: '{}'", trimmed_pubkey);
-+        if let Some(user) = users.get_mut(trimmed_pubkey) {
-             let now = Utc::now().timestamp();
-             let new_token = Uuid::new_v4().to_string();
-             user.session_token = Some(new_token.clone());
-@@ -182,9 +196,10 @@ impl NostrService {
-     }
- 
-     pub async fn logout(&self, pubkey: &str) -> Result<(), NostrError> {
-+        let trimmed_pubkey = pubkey.trim();
-         let mut users = self.users.write().await;
--        
--        if let Some(user) = users.get_mut(pubkey) {
-+        debug!("Logging out pubkey: '{}'", trimmed_pubkey);
-+        if let Some(user) = users.get_mut(trimmed_pubkey) {
-             user.session_token = None;
-             user.last_seen = Utc::now().timestamp();
-             Ok(())
-@@ -204,7 +219,9 @@ impl NostrService {
-     }
- 
-     pub async fn is_power_user(&self, pubkey: &str) -> bool {
--        if let Some(user) = self.get_user(pubkey).await {
-+        let trimmed_pubkey = pubkey.trim();
-+        debug!("Checking service-level power user status for: '{}'", trimmed_pubkey);
-+        if let Some(user) = self.get_user(trimmed_pubkey).await {
-             user.is_power_user
-         } else {
-             false
-diff --git a/src/services/speech_service.rs b/src/services/speech_service.rs
-index c5311bc7..52ca9efc 100755
---- a/src/services/speech_service.rs
-+++ b/src/services/speech_service.rs
-@@ -1,6 +1,5 @@
- use tokio::sync::{mpsc, Mutex, RwLock};
--use tokio_tungstenite::{connect_async, WebSocketStream, MaybeTlsStream};
--use tungstenite::protocol::Message;
-+use tokio_tungstenite::{connect_async, WebSocketStream, MaybeTlsStream, tungstenite::Message};
- use tungstenite::http::Request;
- use serde_json::json;
- use std::sync::Arc;
-@@ -18,6 +17,7 @@ use crate::types::speech::{SpeechError, SpeechCommand, TTSProvider};
- pub struct SpeechService {
-     sender: Arc<Mutex<mpsc::Sender<SpeechCommand>>>,
-     settings: Arc<RwLock<Settings>>,
-+    #[allow(dead_code)]
-     tts_provider: Arc<RwLock<TTSProvider>>,
- }
- 
-diff --git a/src/utils/gpu_compute.rs b/src/utils/gpu_compute.rs
-index 65b5ae13..50669faa 100755
---- a/src/utils/gpu_compute.rs
-+++ b/src/utils/gpu_compute.rs
-@@ -23,6 +23,9 @@ const SHARED_MEM_SIZE: u32 = BLOCK_SIZE * NODE_SIZE;
- // Constants for retry mechanism
- const MAX_GPU_INIT_RETRIES: u32 = 3;
- const RETRY_DELAY_MS: u64 = 500; // 500ms delay between retries
-+const MIN_VALID_NODES: u32 = 5;  // Minimum number of nodes for valid initialization
-+const DIAGNOSTIC_INTERVAL: i32 = 100;  // Log diagnostic info every N iterations
-+const PTX_PATHS: [&str; 2] = ["/app/src/utils/compute_forces.ptx", "./src/utils/compute_forces.ptx"];
- 
- // Note: CPU fallback code has been removed as we're always using GPU now
- 
-@@ -37,6 +40,29 @@ pub struct GPUCompute {
-     pub iteration_count: i32,
- }
- 
-+// Health status of the GPU compute system
-+#[derive(Debug, Clone, Copy, PartialEq)]
-+pub enum GpuHealth {
-+    Healthy,
-+    Warning,
-+    Critical,
-+    Unknown
-+}
-+
-+// Additional info about GPU state
-+#[derive(Debug, Clone)]
-+pub struct GpuDiagnostics {
-+    pub health: GpuHealth,
-+    pub node_count: u32,
-+    pub gpu_memory_used: u64,
-+    pub iterations_completed: i32,
-+    pub device_properties: String,
-+    pub last_error: Option<String>,
-+    pub last_operation_time_ms: u64,
-+    pub timestamp: std::time::SystemTime,
-+}
-+
-+
- impl GPUCompute {
-     pub fn test_gpu() -> Result<(), Error> {
-         info!("Running GPU test");
-@@ -91,7 +117,16 @@ impl GPUCompute {
-         let num_nodes = graph.nodes.len() as u32;
-         info!("Initializing GPU compute with {} nodes (with retry mechanism)", num_nodes);
- 
--        // Check node count limit
-+        // Validate graph has enough nodes to avoid empty/near-empty graph issues
-+        if num_nodes == 0 {
-+            return Err(Error::new(
-+                ErrorKind::InvalidInput,
-+                "Cannot initialize GPU with empty graph (no nodes)"
-+            ));
-+        } else if num_nodes < MIN_VALID_NODES {
-+            warn!("Initializing GPU with only {} nodes, which is below the recommended minimum of {}. This may cause instability.", num_nodes, MIN_VALID_NODES);
-+        }
-+        
-         if num_nodes > MAX_NODES {
-             return Err(Error::new(
-                 std::io::ErrorKind::Other,
-@@ -259,24 +294,51 @@ impl GPUCompute {
-         device: Arc<CudaDevice>, 
-         num_nodes: u32, 
-         graph: &GraphData
--    ) -> Result<Arc<RwLock<Self>>, Error> {
--        let ptx_path = "/app/src/utils/compute_forces.ptx";
-+    ) -> Result<Arc<RwLock<Self>>, Error> {        
-+        let primary_ptx_path = "/app/src/utils/compute_forces.ptx";
-+        let primary_path_exists = Path::new(primary_ptx_path).exists();
-         
--        // Validate PTX file
--        let ptx_path_obj = Path::new(ptx_path);
--
--        if !ptx_path_obj.exists() {
--            error!("PTX file does not exist at {} - this file is required for GPU physics", ptx_path);
--            return Err(Error::new(ErrorKind::NotFound, 
--                format!("PTX file not found at {}", ptx_path)));
-+        // Variable to hold our PTX data once loaded
-+        let ptx_data;
-+        
-+        if primary_path_exists {
-+            // Primary path exists, use it
-+            info!("PTX file found at primary path: {}", primary_ptx_path);
-+            ptx_data = Ptx::from_file(primary_ptx_path);
-+            info!("Successfully loaded PTX file from primary path");
-+        } else {
-+            // Primary path doesn't exist, try alternatives
-+            error!("PTX file does not exist at primary path: {} - trying alternatives", primary_ptx_path);
-+            
-+            let mut found = false;
-+            let mut alternative_ptx = None;
-+            
-+            // Try each alternative path
-+            for alt_path in &PTX_PATHS {
-+                if Path::new(alt_path).exists() {
-+                    info!("Found PTX file at alternative path: {}", alt_path);
-+                    alternative_ptx = Some(Ptx::from_file(alt_path));
-+                    found = true;
-+                    break;
-+                }
-+            }
-+            
-+            if !found {
-+                // No valid PTX file found anywhere
-+                error!("PTX file not found at any known location. GPU physics will not work.");
-+                return Err(Error::new(ErrorKind::NotFound, 
-+                    format!("PTX file not found at any known location. Tried: {} and alternatives", primary_ptx_path)));
-+            }
-+            
-+            ptx_data = alternative_ptx.unwrap();
-+            info!("Successfully loaded PTX file from alternative path");
-         }
- 
--        let ptx = Ptx::from_file(ptx_path);
--
-         info!("Successfully loaded PTX file");
--            
--        device.load_ptx(ptx, "compute_forces_kernel", &["compute_forces_kernel"])
-+
-+        device.load_ptx(ptx_data, "compute_forces_kernel", &["compute_forces_kernel"])
-             .map_err(|e| Error::new(std::io::ErrorKind::Other, e.to_string()))?;
-+
-             
-         let force_kernel = device.get_func("compute_forces_kernel", "compute_forces_kernel")
-             .ok_or_else(|| Error::new(std::io::ErrorKind::Other, "Function compute_forces_kernel not found"))?;
-@@ -311,7 +373,20 @@ impl GPUCompute {
- 
-     pub fn update_graph_data(&mut self, graph: &GraphData) -> Result<(), Error> {
-         info!("Updating graph data for {} nodes", graph.nodes.len());
--
-+        
-+        // Early validation for empty graph
-+        if graph.nodes.is_empty() {
-+            return Err(Error::new(ErrorKind::InvalidData, 
-+                "Cannot update GPU with empty graph data. The graph contains no nodes."));
-+        }
-+        
-+        // Validate node positions to avoid NaN issues
-+        for (i, node) in graph.nodes.iter().enumerate() {
-+            if node.data.position.x.is_nan() || node.data.position.y.is_nan() || node.data.position.z.is_nan() {
-+                warn!("Node at index {} (id: {}) has NaN coordinates - fixing with zero values", 
-+                    i, node.id);
-+            }
-+        }
-         // Update node index mapping
-         self.node_indices.clear();
-         for (idx, node) in graph.nodes.iter().enumerate() {
-@@ -367,6 +442,12 @@ impl GPUCompute {
-     pub fn compute_forces(&mut self) -> Result<(), Error> {
-         info!("Starting force computation on GPU");
-         
-+        // Safety check: Make sure we have nodes to process
-+        if self.num_nodes == 0 {
-+            return Err(Error::new(ErrorKind::InvalidData, 
-+                "Cannot compute forces with zero nodes"));
-+        }
-+        
-         let blocks = ((self.num_nodes + BLOCK_SIZE - 1) / BLOCK_SIZE).max(1);
-         let cfg = LaunchConfig {
-             grid_dim: (blocks, 1, 1),
-@@ -374,9 +455,17 @@ impl GPUCompute {
-             shared_mem_bytes: SHARED_MEM_SIZE,
-         };
- 
--        info!("Launch config: blocks={}, threads={}, shared_mem={}",
--            blocks, BLOCK_SIZE, SHARED_MEM_SIZE);
--
-+        // Log detailed information periodically rather than every call
-+        if self.iteration_count % DIAGNOSTIC_INTERVAL == 0 {
-+            info!("GPU kernel parameters: spring_strength={}, damping={}, repulsion={}, time_step={}",
-+                self.simulation_params.spring_strength,
-+                self.simulation_params.damping,
-+                self.simulation_params.repulsion,
-+                self.simulation_params.time_step);
-+        } else {
-+            info!("GPU kernel launching: blocks={}, nodes={}, iteration={}",
-+                blocks, self.num_nodes, self.iteration_count);
-+        }
-         unsafe {
-             self.force_kernel.clone().launch(cfg, (
-                 &self.node_data,
-@@ -472,6 +561,25 @@ impl GPUCompute {
-         info!("GPU test computation successful");
-         Ok(())
-     }
-+    
-+    pub fn get_diagnostics(&self) -> GpuDiagnostics {
-+        // Simplified diagnostics without using unsupported methods
-+        let device_props = "CUDA GPU".to_string();
-+
-+        // Use simpler diagnostics without unsupported memory methods
-+        let memory_used = 0; // Cannot get actual memory usage
-+
-+        GpuDiagnostics {
-+            health: if self.iteration_count > 0 { GpuHealth::Healthy } else { GpuHealth::Unknown },
-+            node_count: self.num_nodes,
-+            gpu_memory_used: memory_used,
-+            iterations_completed: self.iteration_count,
-+            device_properties: device_props,
-+            last_error: None,
-+            last_operation_time_ms: 0,
-+            timestamp: std::time::SystemTime::now(),
-+        }
-+    }
- }
- 
- #[cfg(test)]
diff --git a/src/app_state.rs b/src/app_state.rs
index fa9fb42e..33009f3c 100755
--- a/src/app_state.rs
+++ b/src/app_state.rs
@@ -1,14 +1,13 @@
 use std::sync::{Arc, atomic::{AtomicUsize, Ordering}};
 use tokio::sync::RwLock;
 use actix_web::web;
-use log::{info, warn};
+use log::info;
 
 use crate::config::Settings;
 use tokio::time::Duration;
 use crate::config::feature_access::FeatureAccess;
 use crate::models::metadata::MetadataStore;
 use crate::models::protected_settings::{ProtectedSettings, ApiKeys, NostrUser};
-use crate::models::graph::GraphUpdateStatus;
 use crate::services::graph_service::GraphService;
 use crate::services::github::{GitHubClient, ContentAPI};
 use crate::services::perplexity_service::PerplexityService;
@@ -31,10 +30,6 @@ pub struct AppState {
     pub feature_access: web::Data<FeatureAccess>,
     pub ragflow_conversation_id: String,
     pub active_connections: Arc<AtomicUsize>,
-    // Track graph updates for websocket clients
-    // Track GPU availability for diagnostics
-    pub gpu_available: Arc<RwLock<bool>>,
-    pub graph_update_status: Arc<RwLock<GraphUpdateStatus>>,
 }
 
 impl AppState {
@@ -70,8 +65,6 @@ impl AppState {
             feature_access: web::Data::new(FeatureAccess::from_env()),
             ragflow_conversation_id,
             active_connections: Arc::new(AtomicUsize::new(0)),
-            gpu_available: Arc::new(RwLock::new(false)),
-            graph_update_status: Arc::new(RwLock::new(GraphUpdateStatus::default())),
         })
     }
 
@@ -134,36 +127,4 @@ impl AppState {
     pub fn get_available_features(&self, pubkey: &str) -> Vec<String> {
         self.feature_access.get_available_features(pubkey)
     }
-    
-    /// Check GPU availability and update status
-    pub async fn check_gpu_status(&self) -> bool {
-        let status = if let Some(gpu) = &self.gpu_compute {
-            // Try to get a read lock on the GPU compute
-            match gpu.try_read() {
-                Ok(gpu_lock) => {
-                    // Try to run a simple test computation
-                    match gpu_lock.test_compute() {
-                        Ok(_) => {
-                            info!("GPU compute test successful - GPU is AVAILABLE");
-                            true
-                        },
-                        Err(e) => {
-                            warn!("GPU compute test failed: {} - GPU is NOT AVAILABLE", e);
-                            false
-                        }
-                    }
-                },
-                Err(_) => {
-                    warn!("Could not acquire GPU lock for testing - GPU is NOT AVAILABLE");
-                    false
-                }
-            }
-        } else {
-            warn!("No GPU compute instance found - GPU is NOT AVAILABLE");
-            false
-        };
-        
-        *self.gpu_available.write().await = status;
-        status
-    }
 }
diff --git a/src/config/feature_access.rs b/src/config/feature_access.rs
index b661d270..31e1949e 100644
--- a/src/config/feature_access.rs
+++ b/src/config/feature_access.rs
@@ -1,7 +1,7 @@
 use std::env;
 use std::fs;
 use std::path::PathBuf;
-use log::{info, warn, debug};
+use log::{info, warn};
 
 /// Represents the access control configuration for various features and user roles
 pub struct FeatureAccess {
@@ -41,11 +41,7 @@ impl FeatureAccess {
         env::var(var_name)
             .unwrap_or_default()
             .split(',')
-            .map(|s| {
-                let trimmed = s.trim().to_string();
-                debug!("Loaded pubkey from env {}: '{}'", var_name, trimmed);
-                trimmed
-            })
+            .map(|s| s.trim().to_string())
             .filter(|s| !s.is_empty())
             .collect()
     }
@@ -106,48 +102,33 @@ impl FeatureAccess {
 
     /// Checks if a pubkey has basic access
     pub fn has_access(&self, pubkey: &str) -> bool {
-        let pubkey_str = pubkey.trim();
-        debug!("Checking access for pubkey: '{}'", pubkey_str);
-        debug!("Approved pubkeys: {:?}", self.approved_pubkeys);
-        self.approved_pubkeys.iter().any(|p| p.trim() == pubkey_str)
+        self.approved_pubkeys.contains(&pubkey.to_string())
     }
 
     /// Checks if a pubkey has access to Perplexity features
     pub fn has_perplexity_access(&self, pubkey: &str) -> bool {
-        let pubkey_str = pubkey.trim();
-        debug!("Checking Perplexity access for pubkey: '{}'", pubkey_str);
-        self.perplexity_enabled.iter().any(|p| p.trim() == pubkey_str)
+        self.perplexity_enabled.contains(&pubkey.to_string())
     }
 
     /// Checks if a pubkey has access to OpenAI features
     pub fn has_openai_access(&self, pubkey: &str) -> bool {
-        let pubkey_str = pubkey.trim();
-        debug!("Checking OpenAI access for pubkey: '{}'", pubkey_str);
-        self.openai_enabled.iter().any(|p| p.trim() == pubkey_str)
+        self.openai_enabled.contains(&pubkey.to_string())
     }
 
     /// Checks if a pubkey has access to RagFlow features
     pub fn has_ragflow_access(&self, pubkey: &str) -> bool {
-        let pubkey_str = pubkey.trim();
-        debug!("Checking RagFlow access for pubkey: '{}'", pubkey_str);
-        self.ragflow_enabled.iter().any(|p| p.trim() == pubkey_str)
+        self.ragflow_enabled.contains(&pubkey.to_string())
     }
 
     /// Checks if a pubkey has power user status
-    pub fn is_power_user(&self, pubkey: &str) -> bool {       
-        let pubkey_str = pubkey.trim();
-        debug!("Checking power user status for pubkey: '{}'", pubkey_str);
-        debug!("Power users: {:?}", self.power_users);
-        self.power_users.iter().any(|p| p.trim() == pubkey_str)
+    pub fn is_power_user(&self, pubkey: &str) -> bool {
+        self.power_users.contains(&pubkey.to_string())
     }
 
     /// Checks if a pubkey has settings sync access
     pub fn can_sync_settings(&self, pubkey: &str) -> bool {
         // Power users automatically get settings sync access
-        if self.is_power_user(pubkey) {
-            return true;
-        }
-        self.settings_sync_enabled.iter().any(|p| p.trim() == pubkey.trim())
+        self.is_power_user(pubkey) || self.settings_sync_enabled.contains(&pubkey.to_string())
     }
 
     /// Checks if a pubkey has access to a specific feature
diff --git a/src/handlers/api_handler/files/mod.rs b/src/handlers/api_handler/files/mod.rs
index 44ff8c90..ef3cd1ef 100644
--- a/src/handlers/api_handler/files/mod.rs
+++ b/src/handlers/api_handler/files/mod.rs
@@ -22,7 +22,7 @@ pub async fn fetch_and_process_files(state: web::Data<AppState>) -> HttpResponse
     
     let file_service = FileService::new(state.settings.clone());
     
-    match file_service.fetch_and_process_files(&state.content_api, state.settings.clone(), &mut metadata_store).await {
+    match file_service.fetch_and_process_files(state.content_api.clone(), state.settings.clone(), &mut metadata_store).await {
         Ok(processed_files) => {
             let file_names: Vec<String> = processed_files.iter()
                 .map(|pf| pf.file_name.clone())
diff --git a/src/handlers/api_handler/graph/mod.rs b/src/handlers/api_handler/graph/mod.rs
index 3f63a8c0..1d9da939 100644
--- a/src/handlers/api_handler/graph/mod.rs
+++ b/src/handlers/api_handler/graph/mod.rs
@@ -198,7 +198,7 @@ pub async fn update_graph(state: web::Data<AppState>) -> impl Responder {
     };
     
     let file_service = FileService::new(Arc::clone(&state.settings));
-    match file_service.fetch_and_process_files(&state.content_api, Arc::clone(&state.settings), &mut metadata).await {
+    match file_service.fetch_and_process_files(state.content_api.clone(), Arc::clone(&state.settings), &mut metadata).await {
         Ok(processed_files) => {
             if processed_files.is_empty() {
                 debug!("No new files to process");
diff --git a/src/handlers/file_handler.rs b/src/handlers/file_handler.rs
index 24bcbf41..7f5e33d3 100755
--- a/src/handlers/file_handler.rs
+++ b/src/handlers/file_handler.rs
@@ -28,7 +28,7 @@ pub async fn fetch_and_process_files(state: web::Data<AppState>) -> HttpResponse
     match file_service.fetch_and_process_files(&state.content_api, state.settings.clone(), &mut metadata_store).await {
         Ok(processed_files) => {
             let file_names: Vec<String> = processed_files.iter()
-                .map(|pf| pf.file_name.clone()) 
+                .map(|pf| pf.file_name.clone())
                 .collect();
 
             info!("Successfully processed {} public markdown files", processed_files.len());
diff --git a/src/handlers/graph_handler.rs b/src/handlers/graph_handler.rs
index d939cd2b..d761ff2e 100755
--- a/src/handlers/graph_handler.rs
+++ b/src/handlers/graph_handler.rs
@@ -6,12 +6,8 @@ use std::collections::HashMap;
 use std::sync::Arc;
 use crate::models::metadata::Metadata;
 use crate::utils::socket_flow_messages::Node;
-use tokio::fs::{create_dir_all, File, metadata};
 use crate::services::file_service::FileService;
 use crate::services::graph_service::GraphService;
-use std::io::Error;
-use std::path::Path;
-use crate::services::file_service::{GRAPH_CACHE_PATH, LAYOUT_CACHE_PATH};
 
 #[derive(Serialize)]
 #[serde(rename_all = "camelCase")]
@@ -43,158 +39,8 @@ pub struct GraphQuery {
     pub filter: Option<String>,
 }
 
-/// Explicitly verify and report on cache file status
-pub async fn verify_cache_files() -> (bool, bool) {
-    info!("Verifying cache files existence and permissions");
-    let graph_exists = Path::new(GRAPH_CACHE_PATH).exists();
-    let layout_exists = Path::new(LAYOUT_CACHE_PATH).exists();
-    
-    if graph_exists {
-        match metadata(GRAPH_CACHE_PATH).await {
-            Ok(md) => {
-                info!("Graph cache file exists: {} bytes, is_file={}", 
-                      md.len(), md.is_file());
-                
-                // Try opening the file to verify permissions
-                match File::open(GRAPH_CACHE_PATH).await {
-                    Ok(_) => info!("Graph cache file is readable"),
-                    Err(e) => error!("Graph cache file exists but can't be opened: {}", e)
-                }
-            },
-            Err(e) => error!("Failed to get metadata for graph cache: {}", e)
-        }
-    } else {
-        error!("Graph cache file does not exist at {}", GRAPH_CACHE_PATH);
-    }
-    
-    if layout_exists {
-        match metadata(LAYOUT_CACHE_PATH).await {
-            Ok(md) => {
-                info!("Layout cache file exists: {} bytes, is_file={}", 
-                      md.len(), md.is_file());
-                match File::open(LAYOUT_CACHE_PATH).await {
-                    Ok(_) => info!("Layout cache file is readable"),
-                    Err(e) => error!("Layout cache file exists but can't be opened: {}", e)
-                }
-            },
-            Err(e) => error!("Failed to get metadata for layout cache: {}", e)
-        }
-    } else {
-        error!("Layout cache file does not exist at {}", LAYOUT_CACHE_PATH);
-    }
-    (graph_exists, layout_exists)
-}
-
 pub async fn get_graph_data(state: web::Data<AppState>) -> impl Responder {
     info!("Received request for graph data");
-
-    // Check if metadata directory exists and create if necessary
-    if let Err(e) = create_dir_all("/app/data/metadata").await {
-        error!("Failed to create metadata directory: {}", e);
-    } else {
-        info!("Metadata directory exists or was created successfully");
-    }
-    
-    // Get metadata from the app state
-    let metadata = state.metadata.read().await.clone();
-    if metadata.is_empty() {
-        error!("Metadata store is empty - no files to process");
-        return HttpResponse::ServiceUnavailable().json(serde_json::json!({
-            "error": "No metadata available to build graph"
-        }));
-    }
-    
-    // Check if the graph_service already has graph data
-    let graph_size = {
-        let graph = state.graph_service.get_graph_data_mut().await;
-        graph.nodes.len()
-        // Don't drop graph lock here to avoid race conditions with validation
-    };
-    
-    // If the graph is empty, we need to build it first
-    if graph_size == 0 {
-        info!("Graph data is empty, building graph from {} metadata entries", metadata.len());
-        match GraphService::build_graph_from_metadata(&metadata).await {
-            Ok(built_graph) => {
-                // Update the app state's graph data
-                let mut app_graph = state.graph_service.get_graph_data_mut().await;
-                *app_graph = built_graph.clone();
-                drop(app_graph);
-                
-                // Update node map
-                let mut node_map = state.graph_service.get_node_map_mut().await;
-                node_map.clear();
-                for node in &built_graph.nodes {
-                    node_map.insert(node.id.clone(), node.clone());
-                }
-                drop(node_map);
-                
-                info!("Successfully built and updated graph with {} nodes, {} edges",
-                      built_graph.nodes.len(), built_graph.edges.len());
-            },
-            Err(e) => error!("Failed to build graph: {}", e)
-        }
-    } else {
-        info!("Graph already contains {} nodes, using existing data for hot start", graph_size);
-        
-        // Clone what we need for the background task
-        let app_state = state.clone();
-        let metadata_clone = metadata.clone();
-        
-        // Spawn background validation and update task
-        tokio::spawn(async move {
-            info!("Starting background validation of cached graph data against metadata");
-            
-            // Try to validate and update the graph
-            match GraphService::build_graph_from_metadata(&metadata_clone).await {
-                Ok(validated_graph) => {
-                    // Check if the validated graph is different from what we have
-                    let current_size = {
-                        let graph = app_state.graph_service.get_graph_data_mut().await;
-                        graph.nodes.len()
-                    };
-                    
-                    let validated_size = validated_graph.nodes.len();
-                    
-                    if current_size != validated_size {
-                        info!("Background validation found graph size difference: {} vs {}. Updating...", 
-                              current_size, validated_size);
-                        
-                        // Update app state with the validated graph
-                        let mut app_graph = app_state.graph_service.get_graph_data_mut().await;
-                        *app_graph = validated_graph.clone();
-                        drop(app_graph);
-                        
-                        // Update node map
-                        let mut node_map = app_state.graph_service.get_node_map_mut().await;
-                        node_map.clear();
-                        for node in &validated_graph.nodes {
-                            node_map.insert(node.id.clone(), node.clone());
-                        }
-
-                        // Update the graph update status so WebSocket clients can check for changes
-                        let update_diff = validated_graph.nodes.len() as i32 - current_size as i32;
-                        let mut update_status = app_state.graph_update_status.write().await;
-                        
-                        // Only mark as updated if there were actual changes
-                        if update_diff != 0 {
-                            info!("Background validation completed - found {} node changes", update_diff);
-                            update_status.last_update = chrono::Utc::now();
-                            update_status.update_available = true;
-                            update_status.nodes_changed = update_diff;
-                        } else {
-                            // Still update check time even if no changes
-                            info!("Background validation completed - graph is already up to date");
-                            update_status.last_check = chrono::Utc::now();
-                            update_status.update_available = false;
-                        }
-                        
-                    }
-                },
-                Err(e) => error!("Background graph validation failed: {}", e)
-            }
-        });
-    }
     
     // Make sure the GPU layout is calculated before sending data
     if let Some(gpu_compute) = &state.graph_service.get_gpu_compute().await {
@@ -236,39 +82,17 @@ pub async fn get_graph_data(state: web::Data<AppState>) -> impl Responder {
         info!("GPU compute not available, sending graph without GPU processing");
     }
     
-    // Take a single layout snapshot for client to load at init
-    info!("Taking layout snapshot for client initialization");
-    if let Err(e) = state.graph_service.take_layout_snapshot().await {
-        warn!("Failed to take layout snapshot: {}", e);
-    } else {
-        info!("Layout snapshot saved successfully");
-    }
-
-    // Verify if cache files were created and provide details
-    let (graph_cached, layout_cached) = verify_cache_files().await;
-    info!("Cache file verification complete: graph={}, layout={}", graph_cached, layout_cached);
-    
     let graph = state.graph_service.get_graph_data_mut().await;
     
     // Log position data to debug zero positions
-    if graph.nodes.is_empty() {
-        error!("Graph is still empty after build attempt. This should not happen if there is valid metadata.");
-        
-        // Return an empty response with an error indicator
-        return HttpResponse::Ok().json(serde_json::json!({
-            "nodes": [],
-            "edges": [],
-            "metadata": {},
-            "error": "Failed to build graph data"
-        }));
-    } else {
+    if !graph.nodes.is_empty() {
         // Log a few nodes for debugging
         for (i, node) in graph.nodes.iter().take(5).enumerate() {
             debug!("Node {}: id={}, label={}, pos=[{:.3},{:.3},{:.3}]", 
                 i, node.id, node.label, node.data.position[0], node.data.position[1], node.data.position[2]);
         }
     }
-
+    
     // Log edge data
     if !graph.edges.is_empty() {
         for (i, edge) in graph.edges.iter().take(5).enumerate() {
@@ -294,35 +118,7 @@ pub async fn get_graph_data(state: web::Data<AppState>) -> impl Responder {
 pub async fn get_paginated_graph_data(
     state: web::Data<AppState>,
     query: web::Query<GraphQuery>,
-) -> impl Responder {    
-    // Ensure metadata directory exists
-    if let Err(e) = create_dir_all("/app/data/metadata").await {
-        error!("Failed to create metadata directory: {}", e);
-    }
-    
-    // Get metadata and explicitly build graph with caching if this is the first page
-    if query.page.unwrap_or(1) == 1 {
-        info!("First page requested - verifying cache files");
-        // Verify cache files when first page is requested
-        let (graph_cached, layout_cached) = verify_cache_files().await;
-        
-        // Get the current graph size
-        let graph_size = {
-            let graph = state.graph_service.get_graph_data_mut().await;
-            graph.nodes.len()
-        };
-        
-        // If the graph is empty, rebuild it
-        if graph_size == 0 {
-            info!("Graph data is empty when paginated view requested, rebuilding graph");
-            let metadata = state.metadata.read().await.clone();
-            if !metadata.is_empty() {
-                let _ = get_graph_data(state.clone()).await;
-            }
-        }
-        
-        info!("Cache status for first page: graph={}, layout={}", graph_cached, layout_cached);
-    }
+) -> impl Responder {
     info!("Received request for paginated graph data with params: {:?}", query);
     
     // Ensure GPU layout is calculated before sending first page of data
@@ -440,10 +236,9 @@ pub async fn get_paginated_graph_data(
 
 // Rebuild graph from existing metadata
 pub async fn refresh_graph(state: web::Data<AppState>) -> impl Responder {
-    info!("Received request to refresh graph and rebuild caches");
+    info!("Received request to refresh graph");
     
     let metadata = state.metadata.read().await.clone();
-    info!("Building graph from {} metadata entries", metadata.len());
     debug!("Building graph from {} metadata entries", metadata.len());
     
     match GraphService::build_graph_from_metadata(&metadata).await {
@@ -476,23 +271,11 @@ pub async fn refresh_graph(state: web::Data<AppState>) -> impl Responder {
             for node in &graph.nodes {
                 node_map.insert(node.id.clone(), node.clone());
             }
-
-            // Take a layout snapshot after refreshing the graph
-            info!("Taking layout snapshot after graph refresh");
-            if let Err(e) = state.graph_service.take_layout_snapshot().await {
-                warn!("Failed to take layout snapshot: {}", e);
-            } else {
-                info!("Layout snapshot saved successfully after refresh");
-            }
-
-            // Verify the cache files after rebuilding the graph
-            let (graph_cached, layout_cached) = verify_cache_files().await;
             
             info!("Graph refreshed successfully with {} nodes and {} edges", 
                 graph.nodes.len(), 
                 graph.edges.len()
             );
-            info!("Cache files after refresh: graph={}, layout={}", graph_cached, layout_cached);
             
             HttpResponse::Ok().json(serde_json::json!({
                 "success": true,
@@ -576,14 +359,6 @@ pub async fn update_graph(state: web::Data<AppState>) -> impl Responder {
                     for node in &graph.nodes {
                         node_map.insert(node.id.clone(), node.clone());
                     }
-
-                    // Take a layout snapshot after updating the graph
-                    info!("Taking layout snapshot after graph update");
-                    if let Err(e) = state.graph_service.take_layout_snapshot().await {
-                        warn!("Failed to take layout snapshot: {}", e);
-                    } else {
-                        info!("Layout snapshot saved successfully after update");
-                    }
                     
                     debug!("Graph updated successfully");
                     
diff --git a/src/handlers/nostr_handler.rs b/src/handlers/nostr_handler.rs
index 506c1b15..11bbf037 100644
--- a/src/handlers/nostr_handler.rs
+++ b/src/handlers/nostr_handler.rs
@@ -4,7 +4,6 @@ use crate::services::nostr_service::{NostrService, AuthEvent, NostrError};
 use crate::config::feature_access::FeatureAccess;
 use actix_web::{web, Error, HttpRequest, HttpResponse};
 use serde::{Deserialize, Serialize};
-use log::{debug, error, info};
 use serde_json::json;
 
 #[derive(Debug, Serialize)]
@@ -67,15 +66,12 @@ async fn check_power_user_status(
     req: HttpRequest,
     feature_access: web::Data<FeatureAccess>,
 ) -> Result<HttpResponse, Error> {
-    let pubkey_raw = req.headers()
+    let pubkey = req.headers()
         .get("X-Nostr-Pubkey")
         .and_then(|h| h.to_str().ok())
         .unwrap_or("");
-        
-    let pubkey = pubkey_raw.trim();
-    debug!("Checking power user status for pubkey: '{}'", pubkey);
 
-    if pubkey.is_empty() { 
+    if pubkey.is_empty() {
         return Ok(HttpResponse::BadRequest().json(json!({
             "error": "Missing Nostr pubkey"
         })));
@@ -90,15 +86,12 @@ async fn get_available_features(
     req: HttpRequest,
     feature_access: web::Data<FeatureAccess>,
 ) -> Result<HttpResponse, Error> {
-    let pubkey_raw = req.headers()
+    let pubkey = req.headers()
         .get("X-Nostr-Pubkey")
         .and_then(|h| h.to_str().ok())
         .unwrap_or("");
-        
-    let pubkey = pubkey_raw.trim();
-    debug!("Getting available features for pubkey: '{}'", pubkey);
 
-    if pubkey.is_empty() { 
+    if pubkey.is_empty() {
         return Ok(HttpResponse::BadRequest().json(json!({
             "error": "Missing Nostr pubkey"
         })));
@@ -115,15 +108,12 @@ async fn check_feature_access(
     feature_access: web::Data<FeatureAccess>,
     feature: web::Path<String>,
 ) -> Result<HttpResponse, Error> {
-    let pubkey_raw = req.headers()
+    let pubkey = req.headers()
         .get("X-Nostr-Pubkey")
         .and_then(|h| h.to_str().ok())
         .unwrap_or("");
-        
-    let pubkey = pubkey_raw.trim();
-    debug!("Checking access to feature '{}' for pubkey: '{}'", feature, pubkey);
 
-    if pubkey.is_empty() { 
+    if pubkey.is_empty() {
         return Ok(HttpResponse::BadRequest().json(json!({
             "error": "Missing Nostr pubkey"
         })));
@@ -139,9 +129,7 @@ async fn login(
     nostr_service: web::Data<NostrService>,
     feature_access: web::Data<FeatureAccess>,
 ) -> Result<HttpResponse, Error> {
-    info!("Handling login request for pubkey: {}", event.pubkey.trim());
     match nostr_service.verify_auth_event(event.into_inner()).await {
-        
         Ok(user) => {
             let token = user.session_token.clone().unwrap_or_default();
             let expires_at = user.last_seen + std::env::var("AUTH_TOKEN_EXPIRY")
@@ -158,9 +146,6 @@ async fn login(
                 npub: Some(user.npub.clone()),
                 is_power_user: user.is_power_user,
             };
-            
-            debug!("Login successful for pubkey: {}, is_power_user: {}, features: {:?}", 
-                user.pubkey.trim(), user.is_power_user, features);
 
             Ok(HttpResponse::Ok().json(AuthResponse {
                 user: user_dto,
@@ -175,8 +160,7 @@ async fn login(
             })))
         }
         Err(e) => {
-            error!("Authentication error: {}", e);
-            Ok(HttpResponse::InternalServerError().json(json!({ 
+            Ok(HttpResponse::InternalServerError().json(json!({
                 "error": format!("Authentication error: {}", e)
             })))
         }
@@ -187,17 +171,14 @@ async fn logout(
     req: web::Json<ValidateRequest>,
     nostr_service: web::Data<NostrService>,
 ) -> Result<HttpResponse, Error> {
-    let pubkey = req.pubkey.trim();
-    debug!("Handling logout request for pubkey: '{}'", pubkey);
-    
     // Validate session before logout
-    if !nostr_service.validate_session(pubkey, &req.token).await {
+    if !nostr_service.validate_session(&req.pubkey, &req.token).await {
         return Ok(HttpResponse::Unauthorized().json(json!({
             "error": "Invalid session"
         })));
     }
 
-    match nostr_service.logout(pubkey).await {
+    match nostr_service.logout(&req.pubkey).await {
         Ok(_) => Ok(HttpResponse::Ok().json(json!({
             "message": "Logged out successfully"
         }))),
@@ -212,18 +193,13 @@ async fn verify(
     nostr_service: web::Data<NostrService>,
     feature_access: web::Data<FeatureAccess>,
 ) -> Result<HttpResponse, Error> {
-    let pubkey = req.pubkey.trim();
-    debug!("Verifying session for pubkey: '{}'", pubkey);
-    
-    let is_valid = nostr_service.validate_session(pubkey, &req.token).await;
+    let is_valid = nostr_service.validate_session(&req.pubkey, &req.token).await;
     let user = if is_valid {
-        debug!("Session is valid, getting user info");
-        nostr_service.get_user(pubkey).await
+        nostr_service.get_user(&req.pubkey).await
                 .map(|u| UserResponseDTO {
                     pubkey: u.pubkey,
                     npub: Some(u.npub),
                     is_power_user: u.is_power_user,
-                    
                 })
     } else {
         None
@@ -231,7 +207,7 @@ async fn verify(
 
     // Get available features if session is valid
     let features = if is_valid {
-        feature_access.get_available_features(pubkey)
+        feature_access.get_available_features(&req.pubkey)
     } else {
         Vec::new()
     };
@@ -248,24 +224,22 @@ async fn refresh(
     nostr_service: web::Data<NostrService>,
     feature_access: web::Data<FeatureAccess>,
 ) -> Result<HttpResponse, Error> {
-    let pubkey = req.pubkey.trim();
-    debug!("Refreshing session for pubkey: '{}'", pubkey);
     // First validate the current session
-    if !nostr_service.validate_session(pubkey, &req.token).await {
+    if !nostr_service.validate_session(&req.pubkey, &req.token).await {
         return Ok(HttpResponse::Unauthorized().json(json!({
             "error": "Invalid session"
         })));
     }
 
-    match nostr_service.refresh_session(pubkey).await {
+    match nostr_service.refresh_session(&req.pubkey).await {
         Ok(new_token) => {
-            if let Some(user) = nostr_service.get_user(pubkey).await {
+            if let Some(user) = nostr_service.get_user(&req.pubkey).await {
                 let expires_at = user.last_seen + std::env::var("AUTH_TOKEN_EXPIRY")
                     .unwrap_or_else(|_| "3600".to_string())
                     .parse::<i64>()
                     .unwrap_or(3600);
 // Get available features for the refreshed session
-let features = feature_access.get_available_features(pubkey);
+let features = feature_access.get_available_features(&req.pubkey);
 
 Ok(HttpResponse::Ok().json(AuthResponse {
     user: UserResponseDTO {
@@ -294,16 +268,13 @@ async fn update_api_keys(
     nostr_service: web::Data<NostrService>,
     pubkey: web::Path<String>,
 ) -> Result<HttpResponse, Error> {
-    let trimmed_pubkey = pubkey.trim().to_string();
     let api_keys = ApiKeys {
         perplexity: req.perplexity.clone(),
         openai: req.openai.clone(),
         ragflow: req.ragflow.clone(),
     };
-    
-    debug!("Updating API keys for pubkey: '{}'", trimmed_pubkey);
 
-    match nostr_service.update_user_api_keys(&trimmed_pubkey, api_keys).await {
+    match nostr_service.update_user_api_keys(&pubkey, api_keys).await {
         Ok(user) => {
             let user_dto = UserResponseDTO {
                 pubkey: user.pubkey.clone(),
@@ -332,12 +303,9 @@ async fn update_api_keys(
 
 async fn get_api_keys(
     state: web::Data<AppState>,
-    pubkey_param: web::Path<String>,
+    pubkey: web::Path<String>,
 ) -> Result<HttpResponse, Error> {
-    let pubkey = pubkey_param.trim();
-    debug!("Getting API keys for pubkey: '{}'", pubkey);
     let protected_settings = state.protected_settings.read().await;
-    
     let api_keys = protected_settings.get_api_keys(&pubkey);
     
     Ok(HttpResponse::Ok().json(api_keys))
diff --git a/src/handlers/perplexity_handler.rs b/src/handlers/perplexity_handler.rs
index 7838d616..0e4ffcf6 100755
--- a/src/handlers/perplexity_handler.rs
+++ b/src/handlers/perplexity_handler.rs
@@ -1,8 +1,8 @@
 use crate::AppState;
 use actix_web::{post, web, HttpResponse, Responder};
 use serde::{Deserialize, Serialize};
-use serde_json::json; 
-use log::info;
+use serde_json::json;
+use log::{error, info};
 
 #[derive(Debug, Deserialize)]
 #[serde(rename_all = "camelCase")]
@@ -25,7 +25,7 @@ pub async fn handle_perplexity(
 ) -> impl Responder {
     info!("Received perplexity request: {:?}", request);
 
-    let _perplexity_service = match &state.perplexity_service {
+    let perplexity_service = match &state.perplexity_service {
         Some(service) => service,
         None => return HttpResponse::ServiceUnavailable().json(json!({
             "error": "Perplexity service is not available"
@@ -33,26 +33,17 @@ pub async fn handle_perplexity(
     };
 
     let conversation_id = state.ragflow_conversation_id.clone();
-    
-    // TEMPORARILY COMMENTED OUT: Perplexity API call as per optimization requirements
-    // match perplexity_service.query(&request.query, &conversation_id).await {
-    //     Ok(answer) => {
-    //         let response = PerplexityResponse {
-    //             answer,
-    //             conversation_id,
-    //         };
-    //         HttpResponse::Ok().json(response)
-    //     }
-    //     Err(e) => {
-    //         error!("Error processing perplexity request: {}", e);
-    //         HttpResponse::InternalServerError().json(format!("Error: {}", e))
-    //     }
-    // }
-    
-    // Return a default response while the perplexity service is disabled
-    let response = PerplexityResponse {
-        answer: "The Perplexity service is temporarily disabled for performance optimization.".to_string(),
-        conversation_id,
-    };
-    HttpResponse::Ok().json(response)
+    match perplexity_service.query(&request.query, &conversation_id).await {
+        Ok(answer) => {
+            let response = PerplexityResponse {
+                answer,
+                conversation_id,
+            };
+            HttpResponse::Ok().json(response)
+        }
+        Err(e) => {
+            error!("Error processing perplexity request: {}", e);
+            HttpResponse::InternalServerError().json(format!("Error: {}", e))
+        }
+    }
 }
diff --git a/src/handlers/socket_flow_handler.rs b/src/handlers/socket_flow_handler.rs
index cf145919..2f28b871 100644
--- a/src/handlers/socket_flow_handler.rs
+++ b/src/handlers/socket_flow_handler.rs
@@ -1,7 +1,6 @@
 use actix::prelude::*;
 use actix_web::{web, Error, HttpRequest, HttpResponse};
 use actix_web_actors::ws;
-use futures::future::{self, Future};
 use flate2::{write::ZlibEncoder, Compression};
 use log::{debug, error, info, warn};
 use std::io::Write;
@@ -15,9 +14,6 @@ use crate::utils::binary_protocol;
 use crate::types::vec3::Vec3Data;
 use crate::utils::socket_flow_messages::{BinaryNodeData, PingMessage, PongMessage};
 
-// Initialize node ID counter when module is loaded
-use crate::models::node::Node;
-
 // Constants for throttling debug logs
 const DEBUG_LOG_SAMPLE_RATE: usize = 10; // Only log 1 in 10 updates
 
@@ -31,10 +27,6 @@ const DEFAULT_MIN_UPDATE_RATE: u32 = 5;   // Min 5 updates per second when stabl
 const BATCH_UPDATE_WINDOW_MS: u64 = 200;  // Check motion every 200ms
 const DEFAULT_MAX_UPDATE_RATE: u32 = 60;  // Max 60 updates per second when active
 const DEFAULT_MOTION_THRESHOLD: f32 = 0.05;  // 5% of nodes need to be moving
-
-// Graph update check interval (check every 10 seconds)
-const GRAPH_UPDATE_CHECK_INTERVAL: std::time::Duration = std::time::Duration::from_secs(10);
-
 const DEFAULT_MOTION_DAMPING: f32 = 0.9;  // Smooth transitions in rate
 
 // Maximum value for u16 node IDs
@@ -70,9 +62,6 @@ pub struct SocketFlowServer {
     nodes_in_motion: usize,    // Counter for nodes currently in motion
     total_node_count: usize,   // Total node count for percentage calculation
     last_motion_check: Instant, // Last time we checked motion percentage
-    
-    // Graph update check
-    last_graph_update_check: Instant, // Last time we checked for graph updates
 }
 
 impl SocketFlowServer {
@@ -131,7 +120,6 @@ impl SocketFlowServer {
             nodes_in_motion: 0,
             total_node_count: 0,
             last_motion_check: Instant::now(),
-            last_graph_update_check: Instant::now(),
         }
     }
 
@@ -257,7 +245,7 @@ impl SocketFlowServer {
 
     // New method to mark a batch as sent
     fn mark_batch_sent(&mut self) { self.last_batch_time = Instant::now(); }
-
+    
     // New method to collect nodes that have changed position
     fn collect_changed_nodes(&mut self) -> Vec<(u16, BinaryNodeData)> {
         let mut changed_nodes = Vec::new();
@@ -290,48 +278,6 @@ impl Actor for SocketFlowServer {
                 act.last_activity = std::time::Instant::now();
             });
         }
-        
-        // Set up periodic graph update check
-        ctx.run_interval(GRAPH_UPDATE_CHECK_INTERVAL, |act, ctx| {
-            // Get current time and check if we should perform an update check
-            let now = Instant::now();
-            let elapsed = now.duration_since(act.last_graph_update_check);
-            
-            // Only check periodically to reduce overhead
-            if elapsed < GRAPH_UPDATE_CHECK_INTERVAL {
-                return;
-            }
-            
-            // Update timestamp first to prevent repeated checks
-            act.last_graph_update_check = now;
-            
-            // Clone what we need to avoid borrowing issues
-            let app_state_clone = act.app_state.clone();
-            
-            // Use a separate future for the async work, properly wrapped
-            let fut = async move { 
-                let status = app_state_clone.graph_update_status.read().await;
-                (status.update_available, status.nodes_changed)
-            };
-            
-            // Wrap the future and handle the result with proper actor context
-            let wrapped_fut = actix::fut::wrap_future::<_, Self>(fut);
-            ctx.spawn(wrapped_fut.map(|(update_available, nodes_changed), _act, ctx| {
-                // If an update is available, send notification to client
-                if update_available {
-                    let message = serde_json::json!({
-                        "type": "graphUpdateAvailable",
-                        "timestamp": chrono::Utc::now().timestamp_millis(),
-                        "nodesChanged": nodes_changed
-                    });
-                    
-                    if let Ok(msg_str) = serde_json::to_string(&message) {
-                        ctx.text(msg_str);
-                        info!("Notified client of available graph update with {} node changes", nodes_changed);
-                    }
-                }
-            }));
-        });
 
         // Send simple connection established message
         let response = serde_json::json!({
@@ -566,7 +512,7 @@ impl StreamHandler<Result<ws::Message, ws::ProtocolError>> for SocketFlowServer
                                                 
                                                 // Use a simple recursive approach to restart the cycle
                                                 let _app_state = act.app_state.clone();
-                                                let _settings_clone = act.settings.clone();
+                    let _settings_clone = act.settings.clone();
                                                 ctx.run_later(next_interval, move |act, ctx| {
                                                     // Recursively call the handler to restart the cycle
                                                     act.handle(Ok(ws::Message::Text("{\"type\":\"requestInitialData\"}".to_string().into())), ctx);
@@ -600,22 +546,6 @@ impl StreamHandler<Result<ws::Message, ws::ProtocolError>> for SocketFlowServer
                                     ctx.text(msg_str);
                                 }
                             }
-                            
-                            Some("fetchUpdatedGraph") => {
-                                // Client is requesting to fetch updated graph data
-                                info!("Client requesting to fetch updated graph data");
-                                
-                                // Reset the update flag in AppState
-                                let app_state = self.app_state.clone();
-                                let fut = async move {
-                                    let mut update_status = app_state.graph_update_status.write().await;
-                                    update_status.update_available = false;
-                                };
-                                
-                                // Run as actor future
-                                let fut = fut.into_actor(self);
-                                ctx.spawn(fut.map(|_, _, _| ()));
-                            }
                             Some("enableRandomization") => {
                                 if let Ok(enable_msg) = serde_json::from_value::<serde_json::Value>(msg.clone()) {
                                     let enabled = enable_msg.get("enabled").and_then(|e| e.as_bool()).unwrap_or(false);
@@ -806,9 +736,6 @@ pub async fn socket_flow_handler(
     app_state: web::Data<AppState>,
     settings: web::Data<Arc<RwLock<crate::config::Settings>>>,
 ) -> Result<HttpResponse, Error> {
-    // Initialize node ID counter from persistent storage
-    Node::initialize_id_counter();
-    
     let should_debug = settings.try_read().map(|s| {
         s.system.debug.enabled && s.system.debug.enable_websocket_debug
     }).unwrap_or(false);
diff --git a/src/main.rs b/src/main.rs
index 9881b794..30bdd1c1 100755
--- a/src/main.rs
+++ b/src/main.rs
@@ -10,13 +10,10 @@ use webxr::{
     },
     services::{
         file_service::FileService,
-        file_service::{GRAPH_CACHE_PATH, LAYOUT_CACHE_PATH}, // Added import for cache paths
-        github::{GitHubClient, ContentAPI, GitHubConfig},
         graph_service::GraphService,
+        github::{GitHubClient, ContentAPI, GitHubConfig},
     },
-    utils::gpu_compute::GPUCompute,
-    models::node::Node,
-    utils::gpu_diagnostics
+    utils::gpu_compute::GPUCompute
 };
 
 use actix_web::{web, App, HttpServer, middleware};
@@ -24,8 +21,8 @@ use actix_cors::Cors;
 use actix_files::Files;
 use std::sync::Arc;
 use tokio::sync::RwLock;
-use dotenvy::dotenv;
 use tokio::time::Duration;
+use dotenvy::dotenv;
 use log::{error, info, debug, warn};
 use webxr::utils::logging::{init_logging_with_config, LogConfig};
 
@@ -120,23 +117,6 @@ async fn main() -> std::io::Result<()> {
     }
 
     info!("Loaded {} items from metadata store", metadata_store.len());
-    
-    // Ensure metadata directories are properly set up
-    if let Err(e) = tokio::fs::create_dir_all("/app/data/metadata/files").await {
-        warn!("Failed to create metadata directory: {}", e);
-    }
-    
-    // Ensure parent directories for cache files exist
-    if let Err(e) = tokio::fs::create_dir_all(std::path::Path::new(GRAPH_CACHE_PATH).parent().unwrap()).await {
-        warn!("Failed to create directory for graph cache: {}", e);
-    }
-    if let Err(e) = tokio::fs::create_dir_all(std::path::Path::new(LAYOUT_CACHE_PATH).parent().unwrap()).await {
-        warn!("Failed to create directory for layout cache: {}", e);
-    }
-    
-    if tokio::fs::metadata("/app/data/metadata").await.is_ok() {
-        info!("Verified metadata directory exists");
-    }
 
     // Update metadata in app state
     {
@@ -146,127 +126,82 @@ async fn main() -> std::io::Result<()> {
     }
 
     // Build initial graph from metadata and initialize GPU compute
-    
-    // CRITICAL: Initialize Node ID counter at startup to ensure consistent IDs across all processes
-    // This MUST be done before any graph building or GPU operations 
-    info!("CRITICAL: Initializing Node ID counter for consistent IDs across all worker processes");
-    Node::initialize_id_counter();
-    
-    // LAZY INITIALIZATION: We don't build the graph on startup anymore
-    // Instead, we'll build it when the first client request comes in
-    info!("Initializing graph with cache files and GPU setup");
-
-    // Build graph ONCE and initialize GPU 
-    // This eliminates the redundant second build that was happening before
+    info!("Building initial graph from existing metadata for physics simulation");
     match GraphService::build_graph_from_metadata(&metadata_store).await {
-        Ok(new_graph) => {
-                info!("Successfully built graph with {} nodes, {} edges", new_graph.nodes.len(), new_graph.edges.len());
-                
-                // Update app state with the new graph
-                let mut app_graph = app_state.graph_service.get_graph_data_mut().await;
-                *app_graph = new_graph.clone();
-                drop(app_graph);
-                
-                // Update the node map too
-                let mut node_map = app_state.graph_service.get_node_map_mut().await;
-                node_map.clear();
-                for node in &new_graph.nodes {
-                    node_map.insert(node.id.clone(), node.clone());
-                }
-                drop(node_map);
-                
-                // Explicitly verify the cache files were created
-                if let Err(e) = tokio::fs::metadata(GRAPH_CACHE_PATH).await {
-                    warn!("Graph cache file was not created: {}", e);
-                }
-                if let Err(e) = tokio::fs::metadata(LAYOUT_CACHE_PATH).await {
-                    warn!("Layout cache file was not created: {}", e);
-                }
-                
-                // Run GPU diagnostics before attempting to initialize
-                info!("Running GPU diagnostics before initialization");
-                let gpu_diag_report = gpu_diagnostics::run_gpu_diagnostics();
-                info!("GPU diagnostics complete: \n{}", gpu_diag_report);
-                
-                // Try to fix CUDA environment if there might be issues
-                if let Err(e) = gpu_diagnostics::fix_cuda_environment() {
-                    warn!("Could not fix CUDA environment: {}", e);
-                }
-                
-                // Initialize GPU with the populated graph
-                info!("Attempting to initialize GPU compute with populated graph data");
-                let gpu_init_start = std::time::Instant::now();
-                match GPUCompute::new(&new_graph).await {
+        Ok(graph_data) => {            
+            // Initialize GPU compute if not already done
+            if app_state.gpu_compute.is_none() {
+                info!("No GPU compute instance found, initializing one now");
+                match GPUCompute::new(&graph_data).await {
                     Ok(gpu_instance) => {
-                        info!("✅ GPU compute initialized successfully");
-                        
-                        // CRITICAL FIX: Test GPU and update flag in a separate scope to avoid borrow issues
-                        {
-                            let gpu_lock = gpu_instance.read().await;
-                            if gpu_lock.test_compute().is_ok() {
-                                GraphService::update_global_gpu_status(true);
-                            }
-                        }
+                        info!("GPU compute initialized successfully");
+                        // Update app_state with new GPU compute instance
                         app_state.gpu_compute = Some(gpu_instance);
                         
-                        // CRITICAL: Check GPU status after initialization to verify it's fully operational
-                        tokio::time::sleep(Duration::from_millis(500)).await; // Longer delay for GPU stabilization
+                        // Shut down the existing GraphService before creating a new one
+                        info!("Shutting down existing graph service before reinitializing with GPU");
+                        let shutdown_start = std::time::Instant::now();
+                        app_state.graph_service.shutdown().await;
+                        info!("Graph service shutdown completed in {:?}", shutdown_start.elapsed());
+                        
+                        // Add a small delay to ensure clean shutdown
+                        tokio::time::sleep(Duration::from_millis(100)).await;
                         
-                        // Run a thorough check
-                        // Check GPU status with a longer timeout
-                        tokio::time::timeout(Duration::from_secs(5), app_state.check_gpu_status())
-                            .await
-                            .unwrap_or(false);
-                            
-                        let gpu_status = *app_state.gpu_available.read().await;
-                        if gpu_status {
-                            info!("🎉 GPU COMPUTE IS VERIFIED AND AVAILABLE FOR PHYSICS SIMULATION ({:?})", 
-                                  gpu_init_start.elapsed());
-                            
-                            // Try an actual physics calculation to confirm it's fully working
-                            if let Some(gpu) = &app_state.gpu_compute {
-                                let mut graph_data = app_state.graph_service.get_graph_data_mut().await;
-                                let mut node_map = app_state.graph_service.get_node_map_mut().await;
-                                
-                                match GraphService::calculate_layout_with_retry(
-                                    gpu, 
-                                    Some(&web::Data::new(app_state.clone())), 
-                                    &mut graph_data, 
-                                    &mut node_map, 
-                                    &webxr::models::simulation_params::SimulationParams::default()
-                                ).await {
-                                    Ok(_) => {
-                                        info!("🔥 GPU PHYSICS TEST CALCULATION SUCCESSFUL - SYSTEM READY FOR GPU ACCELERATION");
-                                        GraphService::update_global_gpu_status(true);
-                                        // Force GPU status to true after successful test
-                                        *app_state.gpu_available.write().await = true;
-                                    },
-                                    Err(e) => {
-                                        warn!("⚠️ GPU test calculation failed: {} - will fall back to CPU physics", e);
-                                        *app_state.gpu_available.write().await = false;
-                                    }
-                                }
-                            }
-                        } else {
-                            warn!("⚠️ GPU compute failed verification check after {:?} - falling back to CPU physics", gpu_init_start.elapsed());
-                        }
+                        // Reinitialize graph service with GPU compute
+                        info!("Reinitializing graph service with GPU compute");
+                        app_state.graph_service = GraphService::new(
+                            settings.clone(), 
+                            app_state.gpu_compute.clone()
+                        ).await;
                         
-                        // Run one final diagnostic if we didn't get GPU working
-                        if !(*app_state.gpu_available.read().await) {
-                            error!("Final GPU diagnosis after unsuccessful initialization: \n{}", gpu_diagnostics::run_gpu_diagnostics());
-                        }
+                        info!("Graph service successfully reinitialized with GPU compute");
                     },
-                    Err(e) => error!("❌ Failed to initialize GPU compute: {}. Will use CPU fallback.", e)
+                    Err(e) => {
+                        warn!("Failed to initialize GPU compute: {}. Continuing with CPU fallback.", e);
+                                        // Shut down the existing GraphService before creating a new one
+                        app_state.graph_service.shutdown().await;
+                        
+        // Initialize graph service with None as GPU compute (will use CPU fallback)
+                        app_state.graph_service = GraphService::new(
+                            settings.clone(), 
+                            None
+                        ).await;
+                        
+                        info!("Graph service initialized with CPU fallback");
+                    }
                 }
-            },
-            Err(e) => warn!("Failed to pre-build graph: {}. Cache files may not be created until first request", e)
+            }
+
+            // Update graph data after GPU is initialized
+            let mut graph = app_state.graph_service.get_graph_data_mut().await;
+            let mut node_map = app_state.graph_service.get_node_map_mut().await;
+            *graph = graph_data;
+            
+            // Update node_map with new graph nodes
+            node_map.clear();
+            for node in &graph.nodes {
+                node_map.insert(node.id.clone(), node.clone());
+            }
+            
+            drop(graph);
+            drop(node_map);
+
+            info!("Built initial graph from metadata");
+            
+        },
+        Err(e) => {
+            error!("Failed to build initial graph: {}", e);
+            return Err(std::io::Error::new(std::io::ErrorKind::Other, format!("Failed to build initial graph: {}", e)));
         }
-    
-    info!("Starting HTTP server with graph initialization complete...");
+    }
+
+    // Add a delay to allow GPU computation to run before accepting client connections
+    info!("Waiting for initial physics layout calculation to complete...");
+    tokio::time::sleep(Duration::from_millis(500)).await;
+    info!("Initial delay complete. Starting HTTP server...");
 
     // Create web::Data after all initialization is complete
     let app_state_data = web::Data::new(app_state);
-    info!("Pre-build process completed");
 
     // Start the server
     let bind_address = {
diff --git a/src/models/graph.rs b/src/models/graph.rs
index bb648b17..e393442e 100755
--- a/src/models/graph.rs
+++ b/src/models/graph.rs
@@ -3,7 +3,6 @@ use super::edge::Edge;
 use super::metadata::MetadataStore;
 use serde::{Deserialize, Serialize};
 use std::collections::HashMap;
-use chrono::{DateTime, Utc, Duration};
 
 /// Represents the graph data structure containing nodes, edges, and metadata.
 /// All fields use camelCase serialization for client compatibility.
@@ -16,52 +15,18 @@ pub struct GraphData {
     pub edges: Vec<Edge>,
     /// Metadata associated with the graph, using camelCase keys.
     pub metadata: MetadataStore,
-    /// Timestamp when the graph was last validated against metadata
-    pub last_validated: DateTime<Utc>,
     /// Mapping from numeric ID to metadata ID (filename) for lookup
     #[serde(skip)]
     pub id_to_metadata: HashMap<String, String>,
-    /// Flag to indicate if the graph has been hot-started from cache
-    #[serde(skip)]
-    pub hot_started: bool,
-}
-
-/// Status of background graph updates for WebSocket clients to check
-#[derive(Clone, Debug)]
-pub struct GraphUpdateStatus {
-    /// Timestamp of the last update check
-    pub last_check: DateTime<Utc>,
-    /// Timestamp of the most recent update
-    pub last_update: DateTime<Utc>,
-    /// Whether an update is available that clients should fetch
-    pub update_available: bool,
-    /// Count of nodes changed in the last update
-    pub nodes_changed: i32,
-}
-
-impl Default for GraphUpdateStatus {
-    fn default() -> Self {
-        let now = Utc::now();
-        Self {
-            last_check: now,
-            last_update: now - Duration::hours(1), // Initial offset to ensure first check is considered new
-            update_available: false,
-            nodes_changed: 0,
-        }
-    }
 }
 
-/// Implementation of GraphData for creating and manipulating graph data
-/// All fields use camelCase serialization for client compatibility
 impl GraphData {
     pub fn new() -> Self {
         Self {
             nodes: Vec::new(),
             edges: Vec::new(),
             metadata: MetadataStore::new(),
-            last_validated: Utc::now(),
             id_to_metadata: HashMap::new(),
-            hot_started: false,
         }
     }
 }
diff --git a/src/models/node.rs b/src/models/node.rs
index dffbdd5c..43c1ab3d 100755
--- a/src/models/node.rs
+++ b/src/models/node.rs
@@ -1,19 +1,11 @@
 use serde::{Deserialize, Serialize};
 use std::collections::HashMap;
-use std::sync::atomic::{AtomicU32, Ordering, AtomicBool};
+use std::sync::atomic::{AtomicU32, Ordering};
 use crate::utils::socket_flow_messages::BinaryNodeData;
 use crate::types::vec3::Vec3Data;
-use std::path::Path;
-use std::fs;
-use log::{info, warn};
 
 // Static counter for generating unique numeric IDs
 static NEXT_NODE_ID: AtomicU32 = AtomicU32::new(1);  // Start from 1 (0 could be reserved)
-static ID_INITIALIZED: AtomicBool = AtomicBool::new(false);
-
-// Constants for ID management
-const MAX_NODE_ID_FILE: &str = "data/metadata/max_node_id.txt";
-const MAX_U16_VALUE: u32 = 65535; // Maximum value for u16 to ensure compatibility with binary protocol
 
 #[derive(Debug, Serialize, Deserialize, Clone)]
 #[serde(rename_all = "camelCase")]
@@ -47,122 +39,20 @@ pub struct Node {
 }
 
 impl Node {
-    /// Initialize the NEXT_NODE_ID counter from stored max ID
-    pub fn initialize_id_counter() {
-        // Only initialize once to prevent race conditions
-        if ID_INITIALIZED.swap(true, Ordering::SeqCst) {
-            return;
-        }
-
-        let max_id = Node::load_max_id_from_storage();
-        
-        // Update the counter if we found a valid ID
-        if max_id > 0 {
-            // Add 1 to ensure next ID is unique
-            let next_id = max_id + 1;
-            
-            // Ensure we don't exceed u16 limit for binary protocol compatibility
-            if next_id > MAX_U16_VALUE {
-                warn!("Loaded max node ID {} exceeds u16 limit. Resetting to 1.", max_id);
-                NEXT_NODE_ID.store(1, Ordering::SeqCst);
-            } else {
-                info!("Initialized node ID counter with value {} (loaded max ID: {})", next_id, max_id);
-                NEXT_NODE_ID.store(next_id, Ordering::SeqCst);
-            }
-        } else {
-            info!("No valid max node ID found, starting from 1");
-            NEXT_NODE_ID.store(1, Ordering::SeqCst);
-        }
-    }
-    
-    /// Load the maximum node ID from storage
-    fn load_max_id_from_storage() -> u32 {
-        // Check if the file exists
-        if !Path::new(MAX_NODE_ID_FILE).exists() {
-            return 0;
-        }
-        
-        // Try to read the file
-        match fs::read_to_string(MAX_NODE_ID_FILE) {
-            Ok(content) => {
-                // Try to parse the content as u32
-                match content.trim().parse::<u32>() {
-                    Ok(id) => {
-                        if id > 0 && id <= MAX_U16_VALUE {
-                            return id;
-                        } else {
-                            warn!("Invalid node ID in storage: {}, must be between 1 and {}", id, MAX_U16_VALUE);
-                        }
-                    },
-                    Err(e) => warn!("Failed to parse node ID from storage: {}", e)
-                }
-            },
-            Err(e) => warn!("Failed to read max node ID file: {}", e)
-        }
-        
-        0 // Return 0 if loading failed
-    }
-    
-    /// Save the current maximum node ID to storage
-    fn save_max_id_to_storage(id: u32) {
-        // Create parent directory if it doesn't exist
-        if let Some(parent) = Path::new(MAX_NODE_ID_FILE).parent() {
-            if !parent.exists() {
-                if let Err(e) = fs::create_dir_all(parent) {
-                    warn!("Failed to create directory for max node ID: {}", e);
-                    return;
-                }
-            }
-        }
-        
-        // Write the ID to the file
-        if let Err(e) = fs::write(MAX_NODE_ID_FILE, id.to_string()) {
-            warn!("Failed to save max node ID to storage: {}", e);
-        }
-    }
-    
     pub fn new(metadata_id: String) -> Self {
-        // Ensure ID counter is initialized
-        if !ID_INITIALIZED.load(Ordering::SeqCst) {
-            Node::initialize_id_counter();
-        }
-        
         Self::new_with_id(metadata_id, None)
     }
 
     pub fn new_with_id(metadata_id: String, provided_id: Option<String>) -> Self {
-        // Ensure ID counter is initialized
-        if !ID_INITIALIZED.load(Ordering::SeqCst) {
-            Node::initialize_id_counter();
-        }
-        
         // Always generate a new ID on the server side
         // Use provided ID only if it's a valid numeric string (from a previous session)
         let id = match provided_id {
             Some(id) if !id.is_empty() && id != "0" && id.parse::<u32>().is_ok() => {
-                let parsed_id = id.parse::<u32>().unwrap();
-                
-                // Ensure we update our counter if this ID is higher
-                if parsed_id > NEXT_NODE_ID.load(Ordering::SeqCst) {
-                    NEXT_NODE_ID.store(parsed_id + 1, Ordering::SeqCst);
-                    // Save the new maximum ID
-                    Node::save_max_id_to_storage(parsed_id);
-                }
-                
-                // Return the provided ID
-                id.clone()
+                // Use the provided ID only if it's a valid numeric ID
+                id
             },
             _ => {
-                // Generate a new unique ID and save it
-                let new_id = NEXT_NODE_ID.fetch_add(1, Ordering::SeqCst);
-                
-                // Save the new maximum ID periodically (every 10 IDs)
-                if new_id % 10 == 0 {
-                    Node::save_max_id_to_storage(new_id);
-                }
-                
-                // Return the new ID as string
-                new_id.to_string()
+                NEXT_NODE_ID.fetch_add(1, Ordering::SeqCst).to_string()
             }
         };
         
diff --git a/src/services/file_service.rs b/src/services/file_service.rs
index 068150d9..519ae9ae 100755
--- a/src/services/file_service.rs
+++ b/src/services/file_service.rs
@@ -2,7 +2,7 @@ use crate::models::metadata::{Metadata, MetadataStore, MetadataOps};
 use crate::models::graph::GraphData;
 use crate::config::Settings;
 use serde::{Deserialize, Serialize};
-use log::{info, debug, error, warn};
+use log::{info, debug, error};
 use std::sync::atomic::{AtomicU32, Ordering};
 use regex::Regex;
 use std::fs;
@@ -20,11 +20,7 @@ use std::io::Error;
 use super::github::{GitHubClient, ContentAPI, GitHubConfig};
 
 // Constants
-pub const METADATA_PATH: &str = "/app/data/metadata/metadata.json"; // Legacy combined metadata path
-pub const METADATA_DIR: &str = "/app/data/metadata";
-pub const FILE_METADATA_DIR: &str = "/app/data/metadata/files"; // Directory for individual file metadata
-pub const GRAPH_CACHE_PATH: &str = "/app/data/metadata/graph.json"; // Path for cached graph data
-pub const LAYOUT_CACHE_PATH: &str = "/app/data/metadata/layout.json"; // Path for cached layout data
+const METADATA_PATH: &str = "/app/data/metadata/metadata.json";
 pub const MARKDOWN_DIR: &str = "/app/data/markdown";
 const GITHUB_API_DELAY: Duration = Duration::from_millis(500);
 
@@ -37,7 +33,6 @@ pub struct ProcessedFile {
 }
 
 pub struct FileService {
-    #[allow(dead_code)]
     settings: Arc<RwLock<Settings>>,
     // Counter for assigning node IDs, initialized based on existing metadata
     node_id_counter: AtomicU32,
@@ -189,31 +184,8 @@ impl FileService {
     /// Load metadata from file or create new if not exists
     pub fn load_or_create_metadata() -> Result<MetadataStore, String> {
         // Ensure metadata directory exists
-        std::fs::create_dir_all(METADATA_DIR)
+        std::fs::create_dir_all("/app/data/metadata")
             .map_err(|e| format!("Failed to create metadata directory: {}", e))?;
-            
-        // Explicitly set permissions on metadata directory to ensure it's writable
-        #[cfg(unix)]
-        {
-            use std::os::unix::fs::PermissionsExt;
-            if let Err(e) = std::fs::set_permissions(METADATA_DIR, std::fs::Permissions::from_mode(0o777)) {
-                warn!("Could not set permissions on metadata directory: {}", e);
-                // Continue anyway, as this is not critical
-            } else {
-                info!("Successfully set permissions on metadata directory");
-            }
-        }
-            
-        // Ensure file metadata directory exists
-        std::fs::create_dir_all(FILE_METADATA_DIR)
-            .map_err(|e| format!("Failed to create file metadata directory: {}", e))?;
-
-        // Also set permissions on the file metadata directory
-        #[cfg(unix)]
-        {
-            use std::os::unix::fs::PermissionsExt;
-            let _ = std::fs::set_permissions(FILE_METADATA_DIR, std::fs::Permissions::from_mode(0o777));
-        }
         
         let metadata_path = "/app/data/metadata/metadata.json";
         
@@ -292,10 +264,6 @@ impl FileService {
     pub async fn initialize_local_storage(
         settings: Arc<RwLock<Settings>>,
     ) -> Result<(), Box<dyn StdError + Send + Sync>> {
-        // First ensure directories exist with proper permissions
-        info!("Ensuring metadata directories exist with proper permissions");
-        Self::ensure_directories()?;
-        
         // Create GitHub client using environment variables
         let github_config = GitHubConfig::from_env()
             .map_err(|e| Box::new(e) as Box<dyn StdError + Send + Sync>)?;
@@ -311,6 +279,9 @@ impl FileService {
 
         info!("Initializing local storage with files from GitHub");
 
+        // Ensure directories exist and have proper permissions
+        Self::ensure_directories()?;
+
         // Get all markdown files from GitHub
         let github_files = content_api.list_markdown_files("").await?;
         info!("Found {} markdown files in GitHub", github_files.len());
@@ -496,97 +467,13 @@ impl FileService {
             }
         }
     }
-    
-    /// Load metadata for a single file
-    pub fn load_file_metadata(file_name: &str) -> Result<Option<Metadata>, Error> {
-        let file_path = format!("{}/{}.json", FILE_METADATA_DIR, file_name);
-        let metadata_path = Path::new(&file_path);
-        
-        if !metadata_path.exists() {
-            return Ok(None);
-        }
-        
-        match fs::read_to_string(metadata_path) {
-            Ok(content) => {
-                match serde_json::from_str::<Metadata>(&content) {
-                    Ok(metadata) => Ok(Some(metadata)),
-                    Err(e) => Err(Error::new(std::io::ErrorKind::InvalidData, 
-                        format!("Failed to parse metadata for {}: {}", file_name, e)))
-                }
-            },
-            Err(e) => Err(Error::new(std::io::ErrorKind::Other, 
-                format!("Failed to read metadata file for {}: {}", file_name, e)))
-        }
-    }
-    
-    /// Save metadata for a single file
-    pub fn save_file_metadata(file_name: &str, metadata: &Metadata) -> Result<(), Error> {
-        let file_path = format!("{}/{}.json", FILE_METADATA_DIR, file_name);
-        
-        // Serialize the metadata to JSON
-        let json = serde_json::to_string_pretty(metadata)
-            .map_err(|e| Error::new(std::io::ErrorKind::Other, e.to_string()))?;
-            
-        // Write to file
-        fs::write(&file_path, json)
-            .map_err(|e| Error::new(std::io::ErrorKind::Other, 
-                format!("Failed to write metadata for {}: {}", file_name, e)))
-    }
-    
-    /// Check if a file has changed by comparing SHA1 hashes
-    pub fn has_file_changed(file_name: &str, content: &str) -> Result<bool, Error> {
-        // Calculate the SHA1 hash of the current content
-        let current_hash = Self::calculate_sha1(content);
-        
-        // Try to load the existing metadata
-        match Self::load_file_metadata(file_name)? {
-            Some(metadata) => {
-                // If we have metadata, compare the SHA1 hashes
-                Ok(metadata.sha1 != current_hash)
-            },
-            None => {
-                // If we don't have metadata, the file is considered changed
-                Ok(true)
-            }
-        }
-    }
-    
-    /// Load metadata from individual files
-    pub fn load_all_file_metadata() -> Result<MetadataStore, Error> {
-        let mut metadata_store = MetadataStore::new();
-        
-        // Read all .json files in the file metadata directory
-        if let Ok(entries) = fs::read_dir(FILE_METADATA_DIR) {
-            for entry in entries.filter_map(Result::ok) {
-                if let Some(file_name) = entry.file_name().to_str().map(|s| s.to_owned()) {
-                    if file_name.ends_with(".json") {
-                        let base_name = file_name.trim_end_matches(".json");
-                        if let Ok(Some(metadata)) = Self::load_file_metadata(base_name) {
-                            metadata_store.insert(base_name.to_owned(), metadata);
-                        }
-                    }
-                }
-            }
-        }
-        
-        Ok(metadata_store)
-    }
 
     /// Save metadata to file
     pub fn save_metadata(metadata: &MetadataStore) -> Result<(), Error> {
-        // Save combined metadata for backward compatibility
         let json = serde_json::to_string_pretty(metadata)
             .map_err(|e| Error::new(std::io::ErrorKind::Other, e.to_string()))?;
         fs::write(METADATA_PATH, json)
             .map_err(|e| Error::new(std::io::ErrorKind::Other, e.to_string()))?;
-        
-        // Save individual file metadata
-        for (file_name, metadata) in metadata {
-            if let Err(e) = Self::save_file_metadata(file_name, metadata) {
-                error!("Failed to save individual metadata for {}: {}", file_name, e);
-            }
-        }
-        
         Ok(())
     }
 
@@ -607,14 +494,12 @@ impl FileService {
     /// Fetch and process files from GitHub
     pub async fn fetch_and_process_files(
         &self,
-        content_api: &Arc<ContentAPI>,
+        content_api: Arc<ContentAPI>,
         _settings: Arc<RwLock<Settings>>,
         metadata_store: &mut MetadataStore,
     ) -> Result<Vec<ProcessedFile>, Box<dyn StdError + Send + Sync>> {
         let mut processed_files = Vec::new();
-        
-        info!("Starting optimized file processing with hash-based invalidation");
-        
+
         // Get all markdown files from GitHub
         let github_files = content_api.list_markdown_files("").await?;
         info!("Found {} markdown files in GitHub", github_files.len());
@@ -639,67 +524,35 @@ impl FileService {
 
                             // Only fetch full content for public files
                             match content_api.fetch_file_content(&file_meta.download_url).await {
-                                Ok(content) => {                                
+                                Ok(content) => {
                                     let file_path = format!("{}/{}", MARKDOWN_DIR, file_meta.name);
-                                    // Calculate the SHA1 hash of the content
-                                    let new_sha1 = Self::calculate_sha1(&content);
-                                    
-                                    // Check if the file has changed by comparing SHA1 hashes
-                                    let file_changed = match Self::load_file_metadata(&file_meta.name) {
-                                        Ok(Some(existing_metadata)) => {
-                                            let changed = existing_metadata.sha1 != new_sha1;
-                                            if !changed {
-                                                debug!("File {} unchanged (SHA1 match), skipping processing", file_meta.name);
-                                            } else {
-                                                debug!("File {} has changed, reprocessing", file_meta.name);
-                                            }
-                                            changed
-                                        },
-                                        _ => {
-                                            debug!("No existing metadata for {}, processing as new file", file_meta.name);
-                                            true
-                                        }
-                                    };
-                                    
-                                    // Only process the file if it has changed or if we don't have metadata for it
-                                    if file_changed {
-                                        // Write the content to the file
-                                        if let Err(e) = fs::write(&file_path, &content) {
-                                            error!("Failed to write file {}: {}", file_path, e);
-                                            return Err(e.into());
-                                        }
-
-                                        let file_size = content.len();
-                                        let node_size = Self::calculate_node_size(file_size);
-
-                                        // Create new metadata or update existing
-                                        let mut metadata = Self::load_file_metadata(&file_meta.name)
-                                            .unwrap_or_default()
-                                            .unwrap_or_default();
-                                            
-                                        // Update metadata fields
-                                        metadata.file_name = file_meta.name.clone();
-                                        metadata.file_size = file_size;
-                                        metadata.node_size = node_size;
-                                        metadata.hyperlink_count = Self::count_hyperlinks(&content);
-                                        metadata.sha1 = new_sha1;
-                                        metadata.last_modified = file_meta.last_modified.unwrap_or_else(|| Utc::now());
-                                        
-                                        // Keep existing values for these fields if present
-                                        if metadata.node_id == "0" || metadata.node_id.is_empty() {
-                                            metadata.node_id = "0".to_string(); // Will be assigned properly later
-                                        }
-
-                                        Ok(Some(ProcessedFile {
-                                            file_name: file_meta.name.clone(),
-                                            content,
-                                            is_public: true,
-                                            metadata,
-                                        }))
-                                    } else {
-                                        // If the file hasn't changed, return None so we don't process it again
-                                        Ok(None)
+                                    if let Err(e) = fs::write(&file_path, &content) {
+                                        error!("Failed to write file {}: {}", file_path, e);
+                                        return Err(e.into());
                                     }
+
+                                    let file_size = content.len();
+                                    let node_size = Self::calculate_node_size(file_size);
+
+                                    let metadata = Metadata {
+                                        file_name: file_meta.name.clone(),
+                                        file_size,
+                                        node_size,
+                                        node_id: "0".to_string(), // Will be assigned properly later
+                                        hyperlink_count: Self::count_hyperlinks(&content),
+                                        sha1: Self::calculate_sha1(&content),
+                                        last_modified: file_meta.last_modified.unwrap_or_else(|| Utc::now()),
+                                        perplexity_link: String::new(),
+                                        last_perplexity_process: None,
+                                        topic_counts: HashMap::new(), // Will be updated later
+                                    };
+
+                                    Ok(Some(ProcessedFile {
+                                        file_name: file_meta.name.clone(),
+                                        content,
+                                        is_public: true,
+                                        metadata,
+                                    }))
                                 }
                                 Err(e) => {
                                     error!("Failed to fetch content for {}: {}", file_meta.name, e);
@@ -721,17 +574,7 @@ impl FileService {
             for result in results {
                 match result {
                     Ok(Some(processed_file)) => {
-                        // Save individual file metadata
-                        if let Err(e) = Self::save_file_metadata(
-                            &processed_file.file_name, 
-                            &processed_file.metadata
-                        ) {
-                            error!("Failed to save metadata for {}: {}", 
-                                processed_file.file_name, e);
-                        }
-                        
                         processed_files.push(processed_file);
-                        info!("Processed file: {}", processed_files.last().unwrap().file_name);
                     }
                     Ok(None) => continue, // Skipped non-public file
                     Err(e) => {
diff --git a/src/services/github/content.rs b/src/services/github/content.rs
index 464ee39d..ba2c5243 100644
--- a/src/services/github/content.rs
+++ b/src/services/github/content.rs
@@ -31,7 +31,6 @@ impl ContentAPI {
     }
 
     /// Ensure consistent URL encoding for paths
-    #[allow(dead_code)]
     async fn encode_path(&self, path: &str) -> String {
         let settings = self.client.settings().read().await;
         let debug_enabled = settings.system.debug.enabled;
diff --git a/src/services/graph_service.rs b/src/services/graph_service.rs
index 9574e5ff..41082b88 100755
--- a/src/services/graph_service.rs
+++ b/src/services/graph_service.rs
@@ -11,7 +11,7 @@ use std::pin::Pin;
 use std::time::{Duration, Instant};
 use futures::Future;
 use log::{info, warn, error, debug};
-use scopeguard; 
+use scopeguard;
 
 use tokio::fs::File as TokioFile;
 use crate::models::graph::GraphData;
@@ -23,11 +23,8 @@ use crate::config::Settings;
 use crate::utils::gpu_compute::GPUCompute;
 use crate::models::simulation_params::{SimulationParams, SimulationPhase, SimulationMode};
 use crate::models::pagination::PaginatedGraphData;
-use tokio::io::AsyncReadExt;
 use tokio::sync::Mutex;
 use once_cell::sync::Lazy;
-use crate::services::file_service::GRAPH_CACHE_PATH;
-use crate::services::file_service::LAYOUT_CACHE_PATH;
 
 // Static flag to prevent multiple simultaneous graph rebuilds
 static GRAPH_REBUILD_IN_PROGRESS: AtomicBool = AtomicBool::new(false);
@@ -40,9 +37,6 @@ static SIMULATION_LOOP_RUNNING: AtomicBool = AtomicBool::new(false);
 // while an old one is being shut down
 static SIMULATION_MUTEX: Lazy<Mutex<String>> = Lazy::new(|| Mutex::new(String::new()));
 
-// Static flag to track GPU availability across threads
-static GPU_AVAILABLE: AtomicBool = AtomicBool::new(false);
-
 // Cache configuration
 const NODE_POSITION_CACHE_TTL_MS: u64 = 50; // 50ms cache time
 const METADATA_FILE_WAIT_TIMEOUT_MS: u64 = 5000; // 5 second wait timeout
@@ -50,7 +44,6 @@ const METADATA_FILE_CHECK_INTERVAL_MS: u64 = 100; // Check every 100ms
 // Constants for GPU retry mechanism
 const MAX_GPU_CALCULATION_RETRIES: u32 = 3;
 const GPU_RETRY_DELAY_MS: u64 = 500; // 500ms delay between retries
-const GPU_INIT_WAIT_MS: u64 = 1000; // 1 second wait before GPU test
 
 #[derive(Clone)]
 pub struct GraphService {
@@ -85,18 +78,16 @@ impl GraphService {
         // Create the shared node map
         let node_map = Arc::new(RwLock::new(HashMap::new()));
 
-        // Create shutdown signal
-        let shutdown_requested = Arc::new(AtomicBool::new(false));
-
         if gpu_compute.is_some() {
             info!("[GraphService] GPU compute is enabled - physics simulation will run");
             info!("[GraphService] Testing GPU compute functionality at startup");
-            
-            // CRITICAL FIX: Wait for GPU initialization to complete instead of spawning task
-            Self::test_gpu_at_startup(gpu_compute.clone(), None, simulation_id.clone()).await;
+            tokio::spawn(Self::test_gpu_at_startup(gpu_compute.clone()));
         } else {
             error!("[GraphService] GPU compute is NOT enabled - physics simulation will use CPU fallback");
         }
+
+        // Create shutdown signal
+        let shutdown_requested = Arc::new(AtomicBool::new(false));
         // Create the GraphService with caching enabled 
         let _cache = Arc::new(RwLock::new(Option::<(Vec<Node>, Instant)>::None));
         let graph_service = Self {
@@ -144,9 +135,6 @@ impl GraphService {
         // Release the mutex before spawning the task
         drop(guard);
         
-        // Try to load cached graph data
-        let _ = Self::try_load_cached_graph_data(Arc::clone(&graph_service.graph_data)).await;
-        
         info!("[GraphService] Starting physics simulation loop (ID: {})", loop_simulation_id);
         tokio::spawn(async move {
             let params = SimulationParams {
@@ -182,20 +170,15 @@ impl GraphService {
                 let mut graph = graph_data.write().await;
                 let mut node_map = node_map.write().await;
 
-                // CRITICAL FIX: Check the global GPU availability flag directly
-                // This ensures we use consistent state across components 
-                let is_gpu_available = GPU_AVAILABLE.load(Ordering::SeqCst);
-                
-                let gpu_status = if is_gpu_available { "available" } else { "NOT available" };
-                
-                debug!("[Graph:{}] GPU compute status: {}, is available flag: {}, physics enabled: {}", 
-                       loop_simulation_id, gpu_status, is_gpu_available, physics_settings.enabled);
+                let gpu_status = if gpu_compute.is_some() { "available" } else { "NOT available" };
+                debug!("[Graph:{}] GPU compute status: {}, physics enabled: {}", 
+                       loop_simulation_id, gpu_status, physics_settings.enabled);
                        
                 if physics_settings.enabled {
                     if let Some(gpu) = &gpu_compute {
-                        if let Err(e) = Self::calculate_layout_with_retry(gpu, None, &mut graph, &mut node_map, &params).await {
+                        if let Err(e) = Self::calculate_layout_with_retry(gpu, &mut graph, &mut node_map, &params).await {
                             error!("[Graph:{}] Error updating positions: {}", loop_simulation_id, e);
-                        } else if is_gpu_available {
+                        } else {
                             debug!("[Graph:{}] GPU calculation completed successfully", loop_simulation_id);
                             debug!("[Graph:{}] Successfully calculated layout for {} nodes", loop_simulation_id, graph.nodes.len());
                         }
@@ -286,69 +269,29 @@ impl GraphService {
     }
     
     /// Test GPU compute at startup to verify it's working
-    async fn test_gpu_at_startup(
-        gpu_compute: Option<Arc<RwLock<GPUCompute>>>, 
-        app_state: Option<web::Data<AppState>>,
-        instance_id: String
-    ) {
+    async fn test_gpu_at_startup(gpu_compute: Option<Arc<RwLock<GPUCompute>>>) {
         // Add a small delay to let other initialization complete
-        tokio::time::sleep(Duration::from_millis(GPU_INIT_WAIT_MS)).await;
+        tokio::time::sleep(Duration::from_millis(1000)).await;
         
-        info!("[GraphService:{}] Running GPU startup test", instance_id);
-        let mut is_gpu_available = false;
+        info!("[GraphService] Running GPU startup test");
         
-        if let Some(gpu) = gpu_compute {
+        if let Some(gpu) = &gpu_compute {
             match gpu.read().await.test_compute() {
                 Ok(_) => {
-                    info!("[GraphService:{}] ✅ GPU test computation succeeded - GPU physics is working", instance_id);
-                    is_gpu_available = true;
+                    info!("[GraphService] ✅ GPU test computation succeeded - GPU physics is working");
                 },
                 Err(e) => {
-                    error!("[GraphService:{}] ❌ GPU test computation failed: {}", instance_id, e);
-                    error!("[GraphService:{}] The system will fall back to CPU physics which may be slower", instance_id); 
-                    is_gpu_available = false;
+                    error!("[GraphService] ❌ GPU test computation failed: {}", e);
+                    error!("[GraphService] The system will fall back to CPU physics which may be slower");
                     
                     // Try initializing a new GPU instance
-                    info!("[GraphService:{}] Attempting to reinitialize GPU...", instance_id);
-                    if let Ok(new_gpu) = GPUCompute::new(&GraphData::default()).await {
-                        info!("[GraphService:{}] GPU reinitialization succeeded", instance_id);
-                        match new_gpu.read().await.test_compute() {
-                            Ok(_) => {
-                                info!("[GraphService:{}] Reinitialized GPU passed test", instance_id);
-                                is_gpu_available = true;
-                            },
-                            Err(_) => {}
-                        }
-                    }
+                    info!("[GraphService] Attempting to reinitialize GPU...");
+                    let _new_gpu = GPUCompute::new(&GraphData::default()).await; // Using _ to avoid unused warning
                 }
             }
         } else {
-            error!("[GraphService:{}] ❌ No GPU compute instance available for testing", instance_id);
-            is_gpu_available = false;
-        }
-        
-        // Update app_state if provided
-        if let Some(state) = app_state {
-            match state.gpu_available.try_write() {
-                Ok(mut available) => {
-                    *available = is_gpu_available;
-                    info!("[GraphService:{}] Updated global GPU status to: {}", instance_id, is_gpu_available);
-                },
-                Err(_) => error!("[GraphService:{}] Failed to update GPU status in AppState", instance_id)
-            }
+            error!("[GraphService] ❌ No GPU compute instance available for testing");
         }
-        
-        // CRITICAL FIX: Update the shared GPU availability flag
-        GPU_AVAILABLE.store(is_gpu_available, Ordering::SeqCst);
-        info!("[GraphService:{}] Updated global GPU availability flag to: {}", instance_id, is_gpu_available);
-    }
-
-    /// Update the global GPU availability flag directly (used by external systems)
-    pub fn update_global_gpu_status(available: bool) {
-        let old_status = GPU_AVAILABLE.load(Ordering::SeqCst);
-        GPU_AVAILABLE.store(available, Ordering::SeqCst);
-        info!("[GraphService] Global GPU availability flag updated: {} -> {}", 
-              old_status, available);
     }
     
     /// Wait for metadata file to be available (mounted by Docker)
@@ -403,35 +346,6 @@ impl GraphService {
     pub async fn build_graph_from_metadata(metadata: &MetadataStore) -> Result<GraphData, Box<dyn std::error::Error + Send + Sync>> {
         // Check if a rebuild is already in progress
         info!("Building graph from {} metadata entries", metadata.len());
-        
-        // Try to load from cache first if metadata has not changed
-        if let Ok(cached_graph) = Self::load_graph_cache().await {
-            // Check if cached graph matches current metadata
-            info!("Checking if cached graph is valid: {} cache entries vs {} metadata entries", cached_graph.metadata.len(), metadata.len());
-            if cached_graph.metadata.len() == metadata.len() {
-                // Simple check: count metadata items
-                let mut needs_rebuild = false;
-                
-                // More detailed check: compare sha1 hashes
-                for (file_name, meta) in metadata.iter() {
-                    if !cached_graph.metadata.contains_key(file_name) || 
-                       cached_graph.metadata[file_name].sha1 != meta.sha1 {
-                        needs_rebuild = true;
-                        break;
-                    }
-                }
-
-                if !needs_rebuild {
-                    info!("Cached graph is valid (all SHA1 hashes match), using it");
-                    let mut cloned_graph = cached_graph.clone();
-                    
-                    // Ensure timestamp is updated to show it was validated
-                    cloned_graph.last_validated = chrono::Utc::now();
-                    
-                    return Ok(cloned_graph);
-                }
-            }
-        }
         debug!("Building graph from {} metadata entries", metadata.len());
         
         if GRAPH_REBUILD_IN_PROGRESS.compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst).is_err() {
@@ -580,29 +494,10 @@ impl GraphService {
             .collect();
 
         // Initialize random positions
-        // Try to use cached layout positions first, fall back to random if not available
-        if let Err(e) = Self::initialize_positions(&mut graph).await {
-            warn!("Failed to initialize positions from cache: {}, using random positions", e);
-            Self::initialize_random_positions(&mut graph);
-        }
+        Self::initialize_random_positions(&mut graph);
 
-        // Record validation timestamp
-        graph.last_validated = chrono::Utc::now();
-        
-        // Take a layout snapshot to provide for client initialization
-        info!("Taking layout snapshot after graph build");
-        if let Err(e) = Self::save_layout_cache(graph.clone()).await {
-            warn!("Failed to take layout snapshot: {}", e);
-        }
-        
-        info!("Built graph with {} nodes and {} edges (validated at {})",
-              graph.nodes.len(), graph.edges.len(), graph.last_validated);
+        info!("Built graph with {} nodes and {} edges", graph.nodes.len(), graph.edges.len());
         debug!("Completed graph build: {} nodes, {} edges", graph.nodes.len(), graph.edges.len());
-        
-        // Cache the graph data to disk
-        if let Err(e) = Self::save_graph_cache(&graph).await {
-            warn!("Failed to cache graph data: {}", e);
-        }
         Ok(graph)
     }
 
@@ -761,25 +656,10 @@ impl GraphService {
             .collect();
 
         // Initialize random positions for all nodes
-        // Try to use cached layout positions first, fall back to random if not available
-        if let Err(e) = Self::initialize_positions(&mut graph).await {
-            warn!("Failed to initialize positions from cache: {}", e);
-            Self::initialize_random_positions(&mut graph);
-        }
+        Self::initialize_random_positions(&mut graph);
 
         info!("Built graph with {} nodes and {} edges", graph.nodes.len(), graph.edges.len());
         debug!("Completed graph build: {} nodes, {} edges", graph.nodes.len(), graph.edges.len());
-        
-        // Take a layout snapshot to provide for client initialization
-        info!("Taking layout snapshot after graph build");
-        if let Err(e) = Self::save_layout_cache(graph.clone()).await {
-            warn!("Failed to take layout snapshot: {}", e);
-        }
-        
-        // Cache the graph data to disk
-        if let Err(e) = Self::save_graph_cache(&graph).await {
-            warn!("Failed to cache graph data: {}", e);
-        }
         Ok(graph)
     }
 
@@ -826,69 +706,14 @@ impl GraphService {
             }
         }
     }
-    
-    // Initialize positions using cached values or random positions as fallback
-    pub async fn initialize_positions(graph: &mut GraphData) -> Result<(), std::io::Error> {
-        // Try to load positions from cache first
-        match Self::load_layout_cache().await {
-            Ok(position_map) => {
-                debug!("Applying cached positions to {} nodes", position_map.len());
-                let mut applied_count = 0;
-                
-                for node in &mut graph.nodes {
-                    if let Some(&(x, y, z)) = position_map.get(&node.id) {
-                        node.set_x(x);
-                        node.set_y(y);
-                        node.set_z(z);
-                        applied_count += 1;
-                    }
-                }
-                
-                info!("Applied cached positions to {}/{} nodes", applied_count, graph.nodes.len());
-                Ok(())
-            },
-            Err(e) => {
-                info!("No cached positions available, using random initialization: {}", e);
-                Self::initialize_random_positions(graph);
-                Ok(())
-            }
-        }
-    }
 
     /// Helper function to retry GPU layout calculation with exponential backoff
     pub async fn calculate_layout_with_retry(
         gpu_compute: &Arc<RwLock<GPUCompute>>,
-        app_state: Option<&web::Data<AppState>>,
         graph: &mut GraphData,
         node_map: &mut HashMap<String, Node>, 
-        params: &SimulationParams
+        params: &SimulationParams,
     ) -> std::io::Result<()> {
-        // First validate the graph data to avoid potential GPU issues
-        if graph.nodes.is_empty() {
-            warn!("[calculate_layout_with_retry] Empty graph received, cannot perform GPU calculation");
-            return Err(Error::new(ErrorKind::InvalidData, "Cannot perform GPU calculation on empty graph"));
-        }
-        
-        if let Err(e) = crate::services::empty_graph_check::check_empty_graph(graph, 5) {
-            warn!("[calculate_layout_with_retry] Graph data validation failed: {}. Falling back to CPU.", e);
-            return Self::calculate_layout_cpu(graph, node_map, params);
-        }
-        
-        // Check if GPU is available based on AppState tracking (if provided)
-        if let Some(app_state) = app_state {
-            let gpu_available = *app_state.gpu_available.read().await;
-            if !gpu_available {
-                // AppState knows GPU is not available, fall back to CPU without retry attempts
-                warn!("[calculate_layout_with_retry] GPU is known to be unavailable from AppState, using CPU directly");
-                return Self::calculate_layout_cpu(graph, node_map, params);
-            }
-        } else if !GPU_AVAILABLE.load(Ordering::SeqCst) {
-            // CRITICAL FIX: Check the shared GPU availability flag if AppState isn't provided
-            warn!("[calculate_layout_with_retry] GPU is marked as unavailable in shared state, using CPU directly");
-            return Self::calculate_layout_cpu(graph, node_map, params);
-        }
-
-        // Proceed with GPU calculation with retry mechanism
         debug!("[calculate_layout_with_retry] Starting GPU calculation with retry mechanism");
         let mut last_error: Option<Error> = None;
         
@@ -918,15 +743,6 @@ impl GraphService {
         debug!("[calculate_layout_with_retry] All GPU attempts failed, falling back to CPU");
         error!("[calculate_layout] Failed after {} attempts, falling back to CPU", MAX_GPU_CALCULATION_RETRIES);
         
-        // Update AppState to indicate GPU is unavailable if provided
-        if let Some(app_state) = app_state {
-            *app_state.gpu_available.write().await = false;
-            error!("Marking GPU as unavailable in AppState for future calculations");
-            
-            // CRITICAL FIX: Also update the shared flag
-            GPU_AVAILABLE.store(false, Ordering::SeqCst);
-        }
-        
         // As a fallback, try CPU calculation when GPU fails repeatedly
         match Self::calculate_layout_cpu(graph, node_map, params) {
             Ok(()) => {
@@ -950,7 +766,7 @@ impl GraphService {
     ) -> std::io::Result<()> {
         {
             info!("[calculate_layout] Starting GPU physics calculation for {} nodes, {} edges with mode {:?}", 
-                graph.nodes.len(), graph.edges.len(), params.mode);
+                  graph.nodes.len(), graph.edges.len(), params.mode);
             
             // Get current timestamp for performance tracking
             let start_time = std::time::Instant::now();
@@ -958,7 +774,7 @@ impl GraphService {
             let mut gpu_compute = gpu_compute.write().await;
 
             info!("[calculate_layout] params: iterations={}, spring_strength={:.3}, repulsion={:.3}, damping={:.3}",
-                params.iterations, params.spring_strength, params.repulsion, params.damping);
+                 params.iterations, params.spring_strength, params.repulsion, params.damping);
             
             // Update data and parameters
             if let Err(e) = gpu_compute.update_graph_data(graph) {
@@ -1027,15 +843,11 @@ impl GraphService {
                     format!("[{:.2},{:.2},{:.2}]", graph.nodes[0].data.position.x, graph.nodes[0].data.position.y, graph.nodes[0].data.position.z)
                 } else { "no nodes".to_string() };
             
-            info!("[calculate_layout] Updated positions for {}/{} nodes in {:?}. Sample positions: {}", nodes_updated, graph.nodes.len(), elapsed, sample_positions);
+                info!("[calculate_layout] Updated positions for {}/{} nodes in {:?}. Sample positions: {}", nodes_updated, graph.nodes.len(), elapsed, sample_positions);
             
-            // Return success
-            ()
+            Ok(())
         }
-        
-        // Return success
-        Ok(())
-   }
+    }
 
     /// CPU fallback implementation of force-directed graph layout
     pub fn calculate_layout_cpu(
@@ -1229,9 +1041,7 @@ impl GraphService {
         let elapsed = start_time.elapsed();
         info!("[calculate_layout_cpu] Updated positions for {} nodes in {:?}", 
              graph.nodes.len(), elapsed);
-             
         
-        // Return success
         Ok(())
     }
 
@@ -1285,13 +1095,6 @@ impl GraphService {
         *cache = None;
     }
 
-    /// Take a layout snapshot and save it to disk (only called explicitly, not after every physics update)
-    pub async fn take_layout_snapshot(&self) -> Result<(), std::io::Error> {
-        let graph = self.graph_data.read().await;
-        info!("Taking layout snapshot to {}", LAYOUT_CACHE_PATH);
-        Self::save_layout_cache((*graph).clone()).await
-    }
-
     pub async fn get_node_positions(&self) -> Vec<Node> {
         let start_time = Instant::now();
 
@@ -1351,241 +1154,6 @@ impl GraphService {
         self.gpu_compute.clone()
     }
 
-    /// Save graph data to cache file
-    pub async fn save_graph_cache(graph: &GraphData) -> Result<(), std::io::Error> {
-        info!("Attempting to cache graph data to {}", GRAPH_CACHE_PATH);
-        let start_time = std::time::Instant::now();
-        info!("Graph contains {} nodes and {} edges", graph.nodes.len(), graph.edges.len());
-        
-        // Ensure the directory exists
-        if let Some(dir) = std::path::Path::new(GRAPH_CACHE_PATH).parent() {
-            if !dir.exists() {
-                info!("Creating directory: {:?}", dir);
-                match std::fs::create_dir_all(dir) {
-                    Ok(_) => {
-                        info!("Successfully created directory: {:?}", dir);
-                        
-                        // Set directory permissions explicitly on Unix systems
-                        #[cfg(unix)]
-                        {
-                            use std::os::unix::fs::PermissionsExt;
-                            if let Err(e) = std::fs::set_permissions(dir, std::fs::Permissions::from_mode(0o777)) {
-                                warn!("Could not set permissions on cache directory: {}", e);
-                            }
-                        }
-                    },
-                    Err(e) => {
-                        error!("Failed to create directory {:?}: {}", dir, e);
-                        // Continue anyway since the directory might already exist with different permissions
-                    }
-                }
-            }
-        }
-        
-        // Serialize graph to JSON with pretty formatting for easier debugging
-        let json = match serde_json::to_string_pretty(graph) {
-            Ok(json) => json,
-            Err(e) => {
-                error!("Failed to serialize graph data: {}", e);
-                return Err(std::io::Error::new(std::io::ErrorKind::Other, e.to_string()));
-            }
-        };
-
-        // First try using standard file system functions, which might be more reliable
-        info!("Writing {} bytes to file {} using std::fs", json.len(), GRAPH_CACHE_PATH);
-        match std::fs::write(GRAPH_CACHE_PATH, json.as_bytes()) {
-            Ok(_) => {
-                let elapsed = start_time.elapsed();
-                info!("Successfully cached graph data ({} bytes) to {} in {:?} using std::fs", 
-                      json.len(), GRAPH_CACHE_PATH, elapsed);
-                return Ok(());
-            }
-            Err(e) => {
-                warn!("Failed to write graph cache using std::fs, falling back to tokio::fs: {}", e);
-                // Fall through to tokio version below
-            }
-        }
-        
-        // Fall back to tokio's async fs
-        info!("Writing {} bytes to file {} using tokio::fs", json.len(), GRAPH_CACHE_PATH);
-        match tokio::fs::write(GRAPH_CACHE_PATH, json.as_bytes()).await {
-            Ok(_) => {
-                info!("Successfully cached graph data ({} bytes) to {}", json.len(), GRAPH_CACHE_PATH);
-                Ok(())
-            },
-            Err(e) => {
-                error!("Failed to write graph cache file {}: {}", GRAPH_CACHE_PATH, e);
-                Err(e)
-            }
-        }
-    }
-    
-    /// Load graph data from cache file
-    pub async fn load_graph_cache() -> Result<GraphData, std::io::Error> {
-        info!("Attempting to load graph data from cache: {}", GRAPH_CACHE_PATH);
-        debug!("GRAPH_CACHE_PATH = {}", GRAPH_CACHE_PATH);
-        
-        // Check if cache file exists
-        if !tokio::fs::metadata(GRAPH_CACHE_PATH).await.is_ok() {
-            return Err(std::io::Error::new(
-                std::io::ErrorKind::NotFound, 
-                "Graph cache file not found"
-            ));
-        }
-        
-        // Read file content
-        let mut file = tokio::fs::File::open(GRAPH_CACHE_PATH).await?;
-        let mut content = String::new();
-        
-        // Read the file content
-        file.read_to_string(&mut content).await?;
-        
-        // Deserialize JSON
-        let graph = serde_json::from_str::<GraphData>(&content)
-            .map_err(|e| std::io::Error::new(
-                std::io::ErrorKind::InvalidData, 
-                format!("Failed to parse graph cache: {}", e)
-            ))?;
-        
-        info!("Successfully loaded graph data from cache ({} nodes, {} edges), last validated: {}", 
-              graph.nodes.len(), graph.edges.len(), graph.last_validated);
-              
-        // Return the loaded graph
-        Ok(graph) 
-    }
-    
-    /// Try to load cached graph data into the provided graph_data RwLock
-    pub async fn try_load_cached_graph_data(graph_data: Arc<RwLock<GraphData>>) -> Result<(), std::io::Error> {
-        match Self::load_graph_cache().await {
-            Ok(cached_graph) => {
-                info!("Initializing graph service with cached graph data");
-                let mut graph = graph_data.write().await;
-                *graph = cached_graph;
-                info!("Graph service initialized with {} nodes and {} edges from cache",
-                     graph.nodes.len(), graph.edges.len());
-                Ok(())
-            },
-            Err(e) => {
-                info!("No valid graph cache found: {}", e);
-                Err(e)
-            }
-        }
-    }
-    
-    /// Save layout positions to cache file
-    pub async fn save_layout_cache(graph: GraphData) -> Result<(), std::io::Error> {
-        info!("Attempting to cache node layout positions to {}", LAYOUT_CACHE_PATH);
-        let start_time = std::time::Instant::now();
-        
-        // Ensure the directory exists
-        if let Some(dir) = std::path::Path::new(LAYOUT_CACHE_PATH).parent() {
-            if !dir.exists() {
-                info!("Creating directory: {:?}", dir);
-                match std::fs::create_dir_all(dir) {
-                    Ok(_) => {
-                        info!("Successfully created directory: {:?}", dir);
-                        
-                        // Set directory permissions explicitly on Unix systems
-                        #[cfg(unix)]
-                        {
-                            use std::os::unix::fs::PermissionsExt;
-                            if let Err(e) = std::fs::set_permissions(dir, std::fs::Permissions::from_mode(0o777)) {
-                                warn!("Could not set permissions on cache directory: {}", e);
-                            }
-                        }
-                    },
-                    Err(e) => {
-                        error!("Failed to create directory {:?}: {}", dir, e);
-                        // Continue anyway since the directory might already exist with different permissions
-                    }
-                }
-            }
-        }
-        
-        // Create a serializable structure with just the necessary position information
-        info!("Building position data array for {} nodes", graph.nodes.len());
-        let positions: Vec<(String, f32, f32, f32)> = graph.nodes.iter()
-            .map(|node| (
-                node.id.clone(),
-                node.data.position.x,
-                node.data.position.y,
-                node.data.position.z
-            ))
-            .collect();
-        
-        // Serialize positions to JSON with pretty formatting for easier debugging
-        let json = match serde_json::to_string_pretty(&positions) {
-            Ok(json) => json,
-            Err(e) => {
-                error!("Failed to serialize layout positions: {}", e);
-                return Err(std::io::Error::new(std::io::ErrorKind::Other, e.to_string()));
-            }
-        };
-
-        // First try using standard file system functions, which might be more reliable
-        info!("Writing {} bytes to file {} using std::fs", json.len(), LAYOUT_CACHE_PATH);
-        match std::fs::write(LAYOUT_CACHE_PATH, json.as_bytes()) {
-            Ok(_) => {
-                let elapsed = start_time.elapsed();
-                info!("Successfully cached layout data for {} nodes to {} in {:?} using std::fs", 
-                      positions.len(), LAYOUT_CACHE_PATH, elapsed);
-                return Ok(());
-            }
-            Err(e) => {
-                warn!("Failed to write layout cache using std::fs, falling back to tokio::fs: {}", e);
-                // Fall through to tokio version below
-            }
-        }
-        
-        // Fall back to tokio's async fs 
-        info!("Writing {} bytes to file {} using tokio::fs", json.len(), LAYOUT_CACHE_PATH);
-        match tokio::fs::write(LAYOUT_CACHE_PATH, json.as_bytes()).await {
-            Ok(_) => {
-                info!("Successfully cached layout data for {} nodes to {}", positions.len(), LAYOUT_CACHE_PATH);
-                Ok(())
-            },
-            Err(e) => {
-                error!("Failed to write layout cache file {}: {}", LAYOUT_CACHE_PATH, e);
-                Err(e)
-            }
-        }
-    }
-    
-    /// Load layout positions from cache file
-    pub async fn load_layout_cache() -> Result<HashMap<String, (f32, f32, f32)>, std::io::Error> {
-        info!("Attempting to load layout from cache: {}", LAYOUT_CACHE_PATH);
-        
-        // Check if cache file exists
-        if !tokio::fs::metadata(LAYOUT_CACHE_PATH).await.is_ok() {
-            return Err(std::io::Error::new(
-                std::io::ErrorKind::NotFound, 
-                "Layout cache file not found"
-            ));
-        }
-        
-        // Read file content
-        let mut file = tokio::fs::File::open(LAYOUT_CACHE_PATH).await?;
-        let mut content = String::new();
-        file.read_to_string(&mut content).await?;
-        
-        // Deserialize JSON
-        let positions = serde_json::from_str::<Vec<(String, f32, f32, f32)>>(&content)
-            .map_err(|e| std::io::Error::new(
-                std::io::ErrorKind::InvalidData, 
-                format!("Failed to parse layout cache: {}", e)
-            ))?;
-        
-        // Convert to HashMap
-        let position_map: HashMap<String, (f32, f32, f32)> = positions.into_iter()
-            .map(|(id, x, y, z)| (id, (x, y, z)))
-            .collect();
-        
-        info!("Successfully loaded layout positions for {} nodes from cache", 
-              position_map.len());
-        Ok(position_map)
-    }
-
-
     pub async fn update_node_positions(&self, updates: Vec<(u16, Node)>) -> Result<(), Error> {
         let mut graph = self.graph_data.write().await;
         let mut node_map = self.node_map.write().await;
diff --git a/src/services/mod.rs b/src/services/mod.rs
index 93a34ac6..81bebaf9 100755
--- a/src/services/mod.rs
+++ b/src/services/mod.rs
@@ -1,7 +1,6 @@
 pub mod github;
 pub mod file_service;
 pub mod graph_service;
-pub mod empty_graph_check;
 pub mod nostr_service;
 pub mod perplexity_service;
 pub mod ragflow_service;
diff --git a/src/services/nostr_service.rs b/src/services/nostr_service.rs
index faa36be0..a8c46855 100644
--- a/src/services/nostr_service.rs
+++ b/src/services/nostr_service.rs
@@ -10,7 +10,7 @@ use std::sync::Arc;
 use tokio::sync::RwLock;
 use chrono::Utc;
 use thiserror::Error;
-use log::{debug, error, info, warn};
+use log::{debug, error, info};
 use uuid::Uuid;
 
 #[derive(Debug, Error)]
@@ -57,11 +57,7 @@ impl NostrService {
         let power_users = std::env::var("POWER_USER_PUBKEYS")
             .unwrap_or_default()
             .split(',')
-            .map(|s| {
-                let trimmed = s.trim().to_string();
-                debug!("Loaded power user pubkey: '{}'", trimmed);
-                trimmed
-            })
+            .map(|s| s.trim().to_string())
             .collect();
 
         let token_expiry = std::env::var("AUTH_TOKEN_EXPIRY")
@@ -114,12 +110,7 @@ impl NostrService {
         }
 
         let now = Utc::now();
-        let trimmed_pubkey = event.pubkey.trim().to_string();
-        let is_power_user = self.power_user_pubkeys.iter().any(|p| p.trim() == trimmed_pubkey);
-        
-        debug!("Checking power user status for pubkey '{}', result: {}", trimmed_pubkey, is_power_user);
-        debug!("Power users list: {:?}", self.power_user_pubkeys);
-        debug!("Is pubkey in list with exact match: {}", self.power_user_pubkeys.contains(&trimmed_pubkey));
+        let is_power_user = self.power_user_pubkeys.contains(&event.pubkey);
 
         // Generate session token
         let session_token = Uuid::new_v4().to_string();
@@ -145,16 +136,14 @@ impl NostrService {
     }
 
     pub async fn get_user(&self, pubkey: &str) -> Option<NostrUser> {
-        let trimmed_pubkey = pubkey.trim();
         let users = self.users.read().await;
-        users.get(trimmed_pubkey).cloned()
+        users.get(pubkey).cloned()
     }
 
     pub async fn update_user_api_keys(&self, pubkey: &str, api_keys: ApiKeys) -> Result<NostrUser, NostrError> {
-        let trimmed_pubkey = pubkey.trim();
         let mut users = self.users.write().await;
-        debug!("Updating API keys for pubkey: '{}'", trimmed_pubkey);
-        if let Some(user) = users.get_mut(trimmed_pubkey) {
+        
+        if let Some(user) = users.get_mut(pubkey) {
             if user.is_power_user {
                 return Err(NostrError::PowerUserOperation);
             }
@@ -167,9 +156,7 @@ impl NostrService {
     }
 
     pub async fn validate_session(&self, pubkey: &str, token: &str) -> bool {
-        let trimmed_pubkey = pubkey.trim();
-        debug!("Validating session for pubkey: '{}'", trimmed_pubkey);
-        if let Some(user) = self.get_user(trimmed_pubkey).await {
+        if let Some(user) = self.get_user(pubkey).await {
             if let Some(session_token) = user.session_token {
                 let now = Utc::now().timestamp();
                 if now - user.last_seen <= self.token_expiry {
@@ -181,10 +168,9 @@ impl NostrService {
     }
 
     pub async fn refresh_session(&self, pubkey: &str) -> Result<String, NostrError> {
-        let trimmed_pubkey = pubkey.trim();
         let mut users = self.users.write().await;
-        debug!("Refreshing session for pubkey: '{}'", trimmed_pubkey);
-        if let Some(user) = users.get_mut(trimmed_pubkey) {
+        
+        if let Some(user) = users.get_mut(pubkey) {
             let now = Utc::now().timestamp();
             let new_token = Uuid::new_v4().to_string();
             user.session_token = Some(new_token.clone());
@@ -196,10 +182,9 @@ impl NostrService {
     }
 
     pub async fn logout(&self, pubkey: &str) -> Result<(), NostrError> {
-        let trimmed_pubkey = pubkey.trim();
         let mut users = self.users.write().await;
-        debug!("Logging out pubkey: '{}'", trimmed_pubkey);
-        if let Some(user) = users.get_mut(trimmed_pubkey) {
+        
+        if let Some(user) = users.get_mut(pubkey) {
             user.session_token = None;
             user.last_seen = Utc::now().timestamp();
             Ok(())
@@ -219,9 +204,7 @@ impl NostrService {
     }
 
     pub async fn is_power_user(&self, pubkey: &str) -> bool {
-        let trimmed_pubkey = pubkey.trim();
-        debug!("Checking service-level power user status for: '{}'", trimmed_pubkey);
-        if let Some(user) = self.get_user(trimmed_pubkey).await {
+        if let Some(user) = self.get_user(pubkey).await {
             user.is_power_user
         } else {
             false
diff --git a/src/services/speech_service.rs b/src/services/speech_service.rs
index 52ca9efc..3880ae4c 100755
--- a/src/services/speech_service.rs
+++ b/src/services/speech_service.rs
@@ -1,5 +1,6 @@
 use tokio::sync::{mpsc, Mutex, RwLock};
-use tokio_tungstenite::{connect_async, WebSocketStream, MaybeTlsStream, tungstenite::Message};
+use tokio_tungstenite::{connect_async, WebSocketStream, MaybeTlsStream, tungstenite};
+use tokio_tungstenite::tungstenite::Message;
 use tungstenite::http::Request;
 use serde_json::json;
 use std::sync::Arc;
@@ -17,7 +18,6 @@ use crate::types::speech::{SpeechError, SpeechCommand, TTSProvider};
 pub struct SpeechService {
     sender: Arc<Mutex<mpsc::Sender<SpeechCommand>>>,
     settings: Arc<RwLock<Settings>>,
-    #[allow(dead_code)]
     tts_provider: Arc<RwLock<TTSProvider>>,
 }
 
@@ -88,7 +88,7 @@ impl SpeechService {
                                     }
                                 });
                                 
-                                if let Err(e) = stream.send(Message::Text(init_event.to_string())).await {
+                                if let Err(e) = stream.send(tungstenite::Message::Text(init_event.to_string())).await {
                                     error!("Failed to send initial response.create event: {}", e);
                                     continue;
                                 }
@@ -112,7 +112,7 @@ impl SpeechService {
                                 }
                             });
 
-                            if let Err(e) = stream.send(Message::Text(msg_event.to_string())).await {
+                            if let Err(e) = stream.send(tungstenite::Message::Text(msg_event.to_string())).await {
                                 error!("Failed to send message to OpenAI: {}", e);
                                 continue;
                             }
@@ -121,14 +121,14 @@ impl SpeechService {
                                 "type": "response.create"
                             });
                             
-                            if let Err(e) = stream.send(Message::Text(response_event.to_string())).await {
+                            if let Err(e) = stream.send(tungstenite::Message::Text(response_event.to_string())).await {
                                 error!("Failed to request response from OpenAI: {}", e);
                                 continue;
                             }
                             
                             while let Some(message) = stream.next().await {
                                 match message {
-                                    Ok(Message::Text(text)) => {
+                                    Ok(tungstenite::Message::Text(text)) => {
                                         let event = match serde_json::from_str::<serde_json::Value>(&text) {
                                             Ok(event) => event,
                                             Err(e) => {
@@ -163,7 +163,7 @@ impl SpeechService {
                                             _ => {}
                                         }
                                     },
-                                    Ok(Message::Close(_)) => break,
+                                    Ok(tungstenite::Message::Close(_)) => break,
                                     Err(e) => {
                                         error!("Error receiving from OpenAI: {}", e);
                                         break;
@@ -177,7 +177,7 @@ impl SpeechService {
                     },
                     SpeechCommand::Close => {
                         if let Some(mut stream) = ws_stream.take() {
-                            if let Err(e) = stream.send(Message::Close(None)).await {
+                            if let Err(e) = stream.send(tungstenite::Message::Close(None)).await {
                                 error!("Failed to send close frame: {}", e);
                             }
                         }
diff --git a/src/utils/gpu_compute.rs b/src/utils/gpu_compute.rs
index 9d2b51cb..65b5ae13 100755
--- a/src/utils/gpu_compute.rs
+++ b/src/utils/gpu_compute.rs
@@ -23,9 +23,6 @@ const SHARED_MEM_SIZE: u32 = BLOCK_SIZE * NODE_SIZE;
 // Constants for retry mechanism
 const MAX_GPU_INIT_RETRIES: u32 = 3;
 const RETRY_DELAY_MS: u64 = 500; // 500ms delay between retries
-const MIN_VALID_NODES: u32 = 5;  // Minimum number of nodes for valid initialization
-const DIAGNOSTIC_INTERVAL: i32 = 100;  // Log diagnostic info every N iterations
-const PTX_PATHS: [&str; 2] = ["/app/src/utils/compute_forces.ptx", "./src/utils/compute_forces.ptx"];
 
 // Note: CPU fallback code has been removed as we're always using GPU now
 
@@ -40,38 +37,6 @@ pub struct GPUCompute {
     pub iteration_count: i32,
 }
 
-// Health status of the GPU compute system
-#[derive(Debug, Clone, Copy, PartialEq)]
-pub enum GpuHealth {
-    Healthy,
-    Warning,
-    Critical,
-    Unknown
-}
-
-// Status enum for GPU availability reporting
-#[derive(Debug, Clone, Copy, PartialEq)]
-pub enum GpuStatus {
-    Available,
-    Unavailable,
-    InitializationError,
-    DriverError
-}
-
-// Additional info about GPU state
-#[derive(Debug, Clone)]
-pub struct GpuDiagnostics {
-    pub health: GpuHealth,
-    pub node_count: u32,
-    pub gpu_memory_used: u64,
-    pub iterations_completed: i32,
-    pub device_properties: String,
-    pub last_error: Option<String>,
-    pub last_operation_time_ms: u64,
-    pub timestamp: std::time::SystemTime,
-}
-
-
 impl GPUCompute {
     pub fn test_gpu() -> Result<(), Error> {
         info!("Running GPU test");
@@ -92,11 +57,7 @@ impl GPUCompute {
     }
     
     fn create_cuda_device() -> Result<Arc<CudaDevice>, Error> {
-        // CRITICAL FIX: Run diagnostics first to log all GPU-related environment variables
-        Self::diagnostic_cuda_info()?;
-        info!("CUDA diagnostics complete - proceeding with device creation");
-        
-        // Check the NVIDIA_GPU_UUID environment variable
+        // First try to use the NVIDIA_GPU_UUID environment variable
         if let Ok(uuid) = env::var("NVIDIA_GPU_UUID") {
             info!("Attempting to create CUDA device with UUID: {}", uuid);
             // Note: cudarc doesn't directly support creation by UUID, so we log it
@@ -110,79 +71,27 @@ impl GPUCompute {
         }
         
         // Always use device index 0 within the container
-        info!("CRITICAL: Attempting to create CUDA device with explicit index 0");
-        
-        // FIX: Add error recovery - try multiple approaches to create the device
+        // (NVIDIA_VISIBLE_DEVICES in docker-compose.yml controls which actual GPU this is)
+        info!("Creating CUDA device with index 0");
         match CudaDevice::new(0) {
             Ok(device) => {
-                info!("✅ Successfully created CUDA device with index 0");
+                // Successfully created device
+                info!("Successfully created CUDA device with index 0 (for GPU UUID: {})", env::var("NVIDIA_GPU_UUID").unwrap_or_else(|_| "unknown".to_string()));
                 Ok(device.into()) // Use .into() to convert to Arc
             },
             Err(e) => {
-                error!("❌ Failed initial CUDA device creation attempt: {}", e);
-                
-                // Try to create device using alternative approach
-                info!("Attempting fallback CUDA device creation...");
-                
-                // Try to get the device count
-                match CudaDevice::count() {
-                    Ok(count) => {
-                        if count == 0 {
-                            error!("No CUDA devices found by driver");
-                            return Err(Error::new(ErrorKind::NotFound, 
-                                "No CUDA devices found by driver - GPU compute unavailable"));
-                        }
-                        
-                        info!("Detected {} CUDA devices, trying to create with first available", count);
-                        
-                        // Try using array initialization with first device
-                        match CudaDevice::new(0) {
-                            Ok(device) => {
-                                info!("✅ Successfully created CUDA device using alternative method");
-                                Ok(device.into())
-                            },
-                            Err(alt_err) => {
-                                error!("❌ Alternative device creation also failed: {}", alt_err);
-                                
-                                // One last attempt - try device 1 as fallback
-                                info!("Making final attempt with device 1");
-                                match CudaDevice::new(1) {
-                                    Ok(device) => {
-                                        info!("✅ Successfully created CUDA device using device 1");
-                                        Ok(device.into())
-                                    },
-                                    Err(def_err) => {
-                                        error!("❌ All device creation attempts failed: {}", def_err);
-                                        Err(Error::new(ErrorKind::Other, 
-                                            format!("All CUDA device creation attempts failed. GPU compute unavailable.")))
-                                    }
-                                }
-                            }
-                        }
-                    },
-                    Err(count_err) => {
-                        error!("❌ Failed to get CUDA device count: {}", count_err);
-                        Err(Error::new(ErrorKind::Other, format!("Failed to get CUDA device count: {}", count_err)))
-                    }
-                }
+                error!("Failed to create CUDA device with index 0: {}", e);
+                Err(Error::new(ErrorKind::Other, 
+                    format!("Failed to create CUDA device: {}. Make sure CUDA drivers are installed and working, and GPU is properly detected.", e)))
             }
         }
     }
-    
+
     pub async fn new(graph: &GraphData) -> Result<Arc<RwLock<Self>>, Error> {
         let num_nodes = graph.nodes.len() as u32;
         info!("Initializing GPU compute with {} nodes (with retry mechanism)", num_nodes);
 
-        // Validate graph has enough nodes to avoid empty/near-empty graph issues
-        if num_nodes == 0 {
-            return Err(Error::new(
-                ErrorKind::InvalidInput,
-                "Cannot initialize GPU with empty graph (no nodes)"
-            ));
-        } else if num_nodes < MIN_VALID_NODES {
-            warn!("Initializing GPU with only {} nodes, which is below the recommended minimum of {}. This may cause instability.", num_nodes, MIN_VALID_NODES);
-        }
-        
+        // Check node count limit
         if num_nodes > MAX_NODES {
             return Err(Error::new(
                 std::io::ErrorKind::Other,
@@ -231,7 +140,7 @@ impl GPUCompute {
         info!("Checking CUDA-related environment variables:");
         for var in &["NVIDIA_GPU_UUID", "NVIDIA_VISIBLE_DEVICES", "CUDA_VISIBLE_DEVICES"] {
             match env::var(var) {
-                Ok(val) => info!("  {}={} (FOUND)", var, val),
+                Ok(val) => info!("  {}={}", var, val),
                 Err(_) => info!("  {} is not set", var)
             }
         }
@@ -350,51 +259,24 @@ impl GPUCompute {
         device: Arc<CudaDevice>, 
         num_nodes: u32, 
         graph: &GraphData
-    ) -> Result<Arc<RwLock<Self>>, Error> {        
-        let primary_ptx_path = "/app/src/utils/compute_forces.ptx";
-        let primary_path_exists = Path::new(primary_ptx_path).exists();
-        
-        // Variable to hold our PTX data once loaded
-        let ptx_data;
+    ) -> Result<Arc<RwLock<Self>>, Error> {
+        let ptx_path = "/app/src/utils/compute_forces.ptx";
         
-        if primary_path_exists {
-            // Primary path exists, use it
-            info!("PTX file found at primary path: {}", primary_ptx_path);
-            ptx_data = Ptx::from_file(primary_ptx_path);
-            info!("Successfully loaded PTX file from primary path");
-        } else {
-            // Primary path doesn't exist, try alternatives
-            error!("PTX file does not exist at primary path: {} - trying alternatives", primary_ptx_path);
-            
-            let mut found = false;
-            let mut alternative_ptx = None;
-            
-            // Try each alternative path
-            for alt_path in &PTX_PATHS {
-                if Path::new(alt_path).exists() {
-                    info!("Found PTX file at alternative path: {}", alt_path);
-                    alternative_ptx = Some(Ptx::from_file(alt_path));
-                    found = true;
-                    break;
-                }
-            }
-            
-            if !found {
-                // No valid PTX file found anywhere
-                error!("PTX file not found at any known location. GPU physics will not work.");
-                return Err(Error::new(ErrorKind::NotFound, 
-                    format!("PTX file not found at any known location. Tried: {} and alternatives", primary_ptx_path)));
-            }
-            
-            ptx_data = alternative_ptx.unwrap();
-            info!("Successfully loaded PTX file from alternative path");
+        // Validate PTX file
+        let ptx_path_obj = Path::new(ptx_path);
+
+        if !ptx_path_obj.exists() {
+            error!("PTX file does not exist at {} - this file is required for GPU physics", ptx_path);
+            return Err(Error::new(ErrorKind::NotFound, 
+                format!("PTX file not found at {}", ptx_path)));
         }
 
-        info!("Successfully loaded PTX file");
+        let ptx = Ptx::from_file(ptx_path);
 
-        device.clone().load_ptx(ptx_data, "compute_forces_kernel", &["compute_forces_kernel"])
+        info!("Successfully loaded PTX file");
+            
+        device.load_ptx(ptx, "compute_forces_kernel", &["compute_forces_kernel"])
             .map_err(|e| Error::new(std::io::ErrorKind::Other, e.to_string()))?;
-
             
         let force_kernel = device.get_func("compute_forces_kernel", "compute_forces_kernel")
             .ok_or_else(|| Error::new(std::io::ErrorKind::Other, "Function compute_forces_kernel not found"))?;
@@ -429,20 +311,7 @@ impl GPUCompute {
 
     pub fn update_graph_data(&mut self, graph: &GraphData) -> Result<(), Error> {
         info!("Updating graph data for {} nodes", graph.nodes.len());
-        
-        // Early validation for empty graph
-        if graph.nodes.is_empty() {
-            return Err(Error::new(ErrorKind::InvalidData, 
-                "Cannot update GPU with empty graph data. The graph contains no nodes."));
-        }
-        
-        // Validate node positions to avoid NaN issues
-        for (i, node) in graph.nodes.iter().enumerate() {
-            if node.data.position.x.is_nan() || node.data.position.y.is_nan() || node.data.position.z.is_nan() {
-                warn!("Node at index {} (id: {}) has NaN coordinates - fixing with zero values", 
-                    i, node.id);
-            }
-        }
+
         // Update node index mapping
         self.node_indices.clear();
         for (idx, node) in graph.nodes.iter().enumerate() {
@@ -498,12 +367,6 @@ impl GPUCompute {
     pub fn compute_forces(&mut self) -> Result<(), Error> {
         info!("Starting force computation on GPU");
         
-        // Safety check: Make sure we have nodes to process
-        if self.num_nodes == 0 {
-            return Err(Error::new(ErrorKind::InvalidData, 
-                "Cannot compute forces with zero nodes"));
-        }
-        
         let blocks = ((self.num_nodes + BLOCK_SIZE - 1) / BLOCK_SIZE).max(1);
         let cfg = LaunchConfig {
             grid_dim: (blocks, 1, 1),
@@ -511,17 +374,9 @@ impl GPUCompute {
             shared_mem_bytes: SHARED_MEM_SIZE,
         };
 
-        // Log detailed information periodically rather than every call
-        if self.iteration_count % DIAGNOSTIC_INTERVAL == 0 {
-            info!("GPU kernel parameters: spring_strength={}, damping={}, repulsion={}, time_step={}",
-                self.simulation_params.spring_strength,
-                self.simulation_params.damping,
-                self.simulation_params.repulsion,
-                self.simulation_params.time_step);
-        } else {
-            info!("GPU kernel launching: blocks={}, nodes={}, iteration={}",
-                blocks, self.num_nodes, self.iteration_count);
-        }
+        info!("Launch config: blocks={}, threads={}, shared_mem={}",
+            blocks, BLOCK_SIZE, SHARED_MEM_SIZE);
+
         unsafe {
             self.force_kernel.clone().launch(cfg, (
                 &self.node_data,
@@ -617,34 +472,6 @@ impl GPUCompute {
         info!("GPU test computation successful");
         Ok(())
     }
-    
-    pub fn get_diagnostics(&self) -> GpuDiagnostics {
-        // Simplified diagnostics without using unsupported methods
-        let device_props = "CUDA GPU".to_string();
-
-        // Use simpler diagnostics without unsupported memory methods
-        let memory_used = 0; // Cannot get actual memory usage
-
-        GpuDiagnostics {
-            health: if self.iteration_count > 0 { GpuHealth::Healthy } else { GpuHealth::Unknown },
-            node_count: self.num_nodes,
-            gpu_memory_used: memory_used,
-            iterations_completed: self.iteration_count,
-            device_properties: device_props,
-            last_error: None,
-            last_operation_time_ms: 0,
-            timestamp: std::time::SystemTime::now(),
-        }
-    }
-    
-    /// Get current GPU status
-    pub fn get_status(&self) -> GpuStatus {
-        if self.iteration_count > 0 {
-            GpuStatus::Available
-        } else {
-            GpuStatus::Unavailable
-        }
-    }
 }
 
 #[cfg(test)]
diff --git a/src/utils/mod.rs b/src/utils/mod.rs
index 93dea5a9..615a7f4b 100755
--- a/src/utils/mod.rs
+++ b/src/utils/mod.rs
@@ -2,7 +2,6 @@ pub mod audio_processor;
 pub mod binary_protocol;
 pub mod edge_data;
 pub mod gpu_compute;
-pub mod gpu_diagnostics;
 pub mod logging;
 pub mod socket_flow_constants;
 pub mod socket_flow_messages;
