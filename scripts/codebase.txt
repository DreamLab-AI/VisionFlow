
## Project Structure Tree

```
Root files:
Cargo.lock
Cargo.toml
config.yml
docker-compose.dev.yml
docker-compose.production.yml
docker-compose.yml
Dockerfile
Dockerfile.dev
Dockerfile.production
nginx.conf
nginx.dev.conf
package.json
package-lock.json
README.md

Directories:
../client
├── components
├── data
│   └── settings.yaml
├── index.html
├── index.html.orig
├── package.json
├── package.json.bak
├── package-lock.json
├── src
│   ├── app
│   │   ├── AppInitializer.tsx
│   │   ├── App.tsx
│   │   ├── components
│   │   │   ├── MarkdownDisplayPanel.tsx
│   │   │   ├── NarrativeGoldminePanel.tsx
│   │   │   └── RightPaneControlPanel.tsx
│   │   ├── main.tsx
│   │   └── TwoPaneLayout.tsx
│   ├── components
│   │   └── layout
│   │       ├── ControlPanel.tsx
│   │       └── ViewportContainer.tsx
│   ├── contexts
│   │   ├── ApplicationModeContext.tsx
│   │   └── WindowSizeContext.tsx
│   ├── features
│   │   ├── auth
│   │   │   ├── components
│   │   │   │   ├── AuthUIHandler.tsx
│   │   │   │   └── NostrAuthSection.tsx
│   │   │   ├── hooks
│   │   │   │   └── useAuth.ts
│   │   │   └── initAuth.ts
│   │   ├── graph
│   │   │   ├── components
│   │   │   │   ├── GraphCanvas.tsx
│   │   │   │   ├── GraphManager.tsx
│   │   │   │   └── GraphViewport.tsx
│   │   │   └── managers
│   │   │       └── graphDataManager.ts
│   │   ├── settings
│   │   │   ├── components
│   │   │   │   ├── BackendUrlSetting.tsx
│   │   │   │   ├── control-panel-context.tsx
│   │   │   │   ├── panels
│   │   │   │   │   ├── AIPanel.tsx
│   │   │   │   │   ├── SystemPanel.tsx
│   │   │   │   │   ├── VisualisationPanel.tsx
│   │   │   │   │   └── XRPanel.tsx
│   │   │   │   ├── SettingControlComponent.tsx
│   │   │   │   ├── SettingsSection.tsx
│   │   │   │   └── SettingsSubsection.tsx
│   │   │   ├── config
│   │   │   │   ├── defaultSettings.ts
│   │   │   │   ├── settingsConfig.ts
│   │   │   │   ├── settings.ts
│   │   │   │   └── settingsUIDefinition.ts
│   │   │   └── types
│   │   │       ├── settingsSchema.ts
│   │   │       ├── settingsTypes.ts
│   │   │       └── uiSetting.ts
│   │   ├── visualisation
│   │   │   ├── components
│   │   │   │   ├── ActionButtons.tsx
│   │   │   │   ├── CameraController.tsx
│   │   │   │   ├── HologramVisualisation.tsx
│   │   │   │   └── MetadataVisualizer.tsx
│   │   │   ├── managers
│   │   │   │   └── sceneManager.ts
│   │   │   ├── renderers
│   │   │   │   ├── HologramManager.tsx
│   │   │   │   ├── materials
│   │   │   │   │   ├── HologramMaterial.tsx
│   │   │   │   │   └── HologramShaderMaterial.ts
│   │   │   │   └── TextRenderer.tsx
│   │   │   ├── types
│   │   │   │   └── visualisationTypes.ts
│   │   │   └── utils
│   │   │       └── animations.ts
│   │   └── xr
│   │       ├── components
│   │       │   ├── ui
│   │       │   │   └── XRControlPanel.tsx
│   │       │   ├── XRController.tsx
│   │       │   ├── XRScene.tsx
│   │       │   └── XRVisualisationConnector.tsx
│   │       ├── hooks
│   │       │   ├── useSafeXRHooks.tsx
│   │       │   └── useXRContextCheck.tsx
│   │       ├── managers
│   │       │   ├── xrInitializer.ts
│   │       │   └── xrSessionManager.ts
│   │       ├── providers
│   │       │   ├── SafeXRProvider.tsx
│   │       │   └── XRContextWrapper.tsx
│   │       ├── systems
│   │       │   └── HandInteractionSystem.tsx
│   │       └── types
│   │           ├── webxr-extensions.d.ts
│   │           └── xr.ts
│   ├── hooks
│   │   ├── useContainerSize.ts
│   │   └── useWindowSize.ts
│   ├── pages
│   ├── services
│   │   ├── api.ts
│   │   ├── nostrAuthService.ts
│   │   ├── platformManager.ts
│   │   ├── settingsService.ts
│   │   └── WebSocketService.ts
│   ├── store
│   │   └── settingsStore.ts
│   ├── styles
│   │   ├── globals.css
│   │   └── tokens.css
│   ├── types
│   │   ├── binaryProtocol.ts
│   │   ├── getalby-sdk.d.ts
│   │   ├── lucide-react.d.ts
│   │   ├── nip07.d.ts
│   │   ├── node-env.d.ts
│   │   ├── react-syntax-highlighter.d.ts
│   │   ├── react-three-fiber.d.ts
│   │   ├── react-three-libraries.d.ts
│   │   ├── tailwind-merge.d.ts
│   │   ├── three-extensions.d.ts
│   │   └── webxr-extensions.d.ts
│   ├── ui
│   │   ├── Button.tsx
│   │   ├── Card.tsx
│   │   ├── Collapsible.tsx
│   │   ├── formGroup
│   │   │   └── FormGroup.tsx
│   │   ├── Input.tsx
│   │   ├── Label.tsx
│   │   ├── markdown
│   │   │   └── MarkdownRenderer.tsx
│   │   ├── RadioGroup.tsx
│   │   ├── Select.tsx
│   │   ├── Slider.tsx
│   │   ├── Switch.tsx
│   │   ├── Tabs.tsx
│   │   ├── ThemeProvider.tsx
│   │   ├── ThemeSelector.tsx
│   │   ├── Toaster.tsx
│   │   ├── Toast.tsx
│   │   ├── Tooltip.tsx
│   │   └── useToast.tsx
│   └── utils
│       ├── binaryUtils.ts
│       ├── caseConversion.ts
│       ├── cn.ts
│       ├── debugState.ts
│       ├── deepMerge.ts
│       ├── logger.ts
│       ├── objectPath.ts
│       └── utils.ts
├── tailwind.config.js
├── tsconfig.json
├── vite.config.ts
└── vite-start.js
../src
├── app_state.rs
├── config
│   ├── feature_access.rs
│   ├── feature_access_test.rs
│   └── mod.rs
├── handlers
│   ├── api_handler
│   │   ├── files
│   │   │   └── mod.rs
│   │   ├── graph
│   │   │   └── mod.rs
│   │   ├── mod.rs
│   │   └── visualisation
│   │       └── mod.rs
│   ├── file_handler.rs
│   ├── graph_handler.rs
│   ├── health_handler.rs
│   ├── mod.rs
│   ├── nostr_handler.rs
│   ├── pages_handler.rs
│   ├── perplexity_handler.rs
│   ├── ragflow_handler.rs
│   ├── settings_handler.rs
│   ├── socket_flow_handler.rs
│   ├── speech_socket_handler.rs
│   └── visualization_handler.rs
├── lib.rs
├── main.rs
├── models
│   ├── client_settings_payload.rs
│   ├── edge.rs
│   ├── graph.rs
│   ├── metadata.rs
│   ├── mod.rs
│   ├── node.rs
│   ├── pagination.rs
│   ├── protected_settings.rs
│   ├── simulation_params.rs
│   ├── ui_settings.rs
│   └── user_settings.rs
├── services
│   ├── empty_graph_check.rs
│   ├── file_service.rs
│   ├── github
│   │   ├── api.rs
│   │   ├── config.rs
│   │   ├── content.rs
│   │   ├── mod.rs
│   │   ├── pr.rs
│   │   └── types.rs
│   ├── graph_service.rs
│   ├── mod.rs
│   ├── nostr_service.rs
│   ├── perplexity_service.rs
│   ├── ragflow_service.rs
│   └── speech_service.rs
├── state.rs
├── types
│   ├── mod.rs
│   ├── speech.rs
│   └── vec3.rs
└── utils
    ├── audio_processor.rs
    ├── auth.rs
    ├── binary_protocol.rs
    ├── compute_forces.cu
    ├── compute_forces.ptx
    ├── edge_data.rs
    ├── gpu_compute.rs
    ├── gpu_diagnostics.rs
    ├── logging.rs
    ├── mod.rs
    ├── socket_flow_constants.rs
    ├── socket_flow_messages.rs
    └── tests
        └── socket_flow_tests.rs
../docs
├── api
│   ├── index.md
│   ├── rest.md
│   ├── websocket.md
│   └── websocket-updated.md
├── client
│   ├── architecture.md
│   ├── components.md
│   ├── core.md
│   ├── index.md
│   ├── rendering.md
│   ├── state.md
│   ├── types.md
│   ├── visualization.md
│   ├── websocket.md
│   ├── websocket-readiness.md
│   └── xr.md
├── contributing.md
├── deployment
│   ├── docker.md
│   └── index.md
├── development
│   ├── debugging.md
│   ├── index.md
│   └── setup.md
├── index.md
├── overview
│   └── architecture.md
├── server
│   ├── architecture.md
│   ├── config.md
│   ├── handlers.md
│   ├── index.md
│   ├── models.md
│   ├── services.md
│   ├── types.md
│   └── utils.md
└── technical
    └── decoupled-graph-architecture.md

67 directories, 212 files
```

# Project Codebase

Generated: Tue 13 May 10:24:57 UTC 2025

## Project Structure

- Server: Rust (src directory)
- Client: TypeScript (client directory)


## README.md

# LogseqXR: Immersive WebXR Visualisation for Logseq Knowledge Graphs

![image](https://github.com/user-attachments/assets/269a678d-88a5-42de-9d67-d73b64f4e520)

**Inspired by the innovative work of Prof. Rob Aspin:** [https://github.com/trebornipsa](https://github.com/trebornipsa)

![P1080785_1728030359430_0](https://github.com/user-attachments/assets/3ecac4a3-95d7-4c75-a3b2-e93deee565d6)

## About LogseqXR

LogseqXR transforms your Logseq knowledge base into an immersive 3D visualisation that you can explore in VR/AR. Experience your ideas as tangible objects in space, discover new connections, and interact with your knowledge in ways never before possible.

## Quick Links

- [Project Overview](docs/index.md)
- [Development Setup](docs/development/setup.md)
- [API Documentation](docs/api/index.md)
- [Contributing Guidelines](docs/contributing.md)

## Documentation

Our documentation is organised into several key sections:

### Client Documentation
- [Architecture](docs/client/architecture.md)
- [Components](docs/client/components.md)
- [Core Utilities](docs/client/core.md)
- [Rendering System](docs/client/rendering.md)
- [State Management](docs/client/state.md)
- [Type Definitions](docs/client/types.md)
- [Visualisation](docs/client/visualisation.md)
- [WebSocket Communication](docs/client/websocket.md)
- [WebXR Integration](docs/client/xr.md)

### Server Documentation
- [Architecture](docs/server/architecture.md)
- [Configuration](docs/server/config.md)
- [Request Handlers](docs/server/handlers.md)
- [Data Models](docs/server/models.md)
- [Services](docs/server/services.md)
- [Type Definitions](docs/server/types.md)
- [Utilities](docs/server/utils.md)

### API Documentation
- [REST API](docs/api/rest.md)
- [WebSocket API](docs/api/websocket.md)

### Development and Deployment
- [Development Setup](docs/development/setup.md)
- [Debugging Guide](docs/development/debugging.md)
- [Docker Deployment](docs/deployment/docker.md)
- [Contributing Guidelines](docs/contributing.md)

### System Architecture Diagram

```mermaid
graph TB
    %% Frontend Components
    subgraph Frontend
        UI[User Interface Layer]
        R3FRenderer[React Three Fiber Renderer]
        XR[WebXR Integration]
        WSClient[WebSocket Client]
        GraphDisplay[Graph Display Manager]
        ControlPanel["Modular Control Panel (Nostr Auth)"]
        XRControls[XR Control System]
        WSService[WebSocket Service]
        GraphDataManager[Graph Data Manager]
        PlatformManager[Platform Manager]
        XRSessionManager[XR Session Manager]
        XRInitializer[XR Initializer]
        HologramRenderer[Hologram Renderer]
        TextRenderer[Text Renderer]
        SettingsStore[Settings Store]
        NostrAuthClient[Nostr Auth Client UI]
    end

    %% Backend Components
    subgraph Backend
        ActixServer[Actix Web Server]
        FileHandler[File Handler]
        GraphHandler[Graph Handler]
        WebSocketHandler[WebSocket Handler]
        PerplexityHandler[Perplexity Handler]
        RagFlowHandler[RagFlow Handler]
        VisualisationHandler[Visualisation Handler]
        NostrAuthHandler[Nostr Auth Handler]
        HealthHandler[Health Handler]
        PagesHandler[Pages Handler]
        SettingsHandler[Settings Handler]
        FileService[File Service]
        GraphService[Graph Service]
        GPUComputeService[GPU Compute Service]
        PerplexityService[Perplexity Service]
        RagFlowService[RagFlow Service]
        SpeechService[Speech Service]
        NostrAuthService[Nostr Auth Service Backend]
        ClientManager[WebSocket Client Manager]
        PhysicsEngine[Continuous Physics Engine]
        AudioProcessor[Audio Processor]
        MetadataStoreModel[Metadata Store Model]
        ProtectedSettingsModel[Protected Settings Model]
    end

    %% External Components
    subgraph External
        GitHubAPI[GitHub API]
        PerplexityAI[Perplexity AI]
        RagFlowAPI[RagFlow API]
        OpenAI_API[OpenAI API]
        NostrPlatformAPI[Nostr Platform API]
    end

    %% Connections between Frontend Components
    UI --> GraphDisplay
    UI --> ControlPanel
    UI --> NostrAuthClient
    UI --> XRControls

    XR --> R3FRenderer
    WSClient --> WSService
    WSService --> ActixServer

    %% Connections between Backend Components
    ActixServer --> FileHandler
    ActixServer --> GraphHandler
    ActixServer --> WebSocketHandler
    ActixServer --> PerplexityHandler
    ActixServer --> RagFlowHandler
    ActixServer --> VisualisationHandler
    ActixServer --> NostrAuthHandler
    ActixServer --> HealthHandler
    ActixServer --> PagesHandler
    ActixServer --> SettingsHandler

    FileHandler --> FileService
    GraphHandler --> GraphService
    WebSocketHandler --> ClientManager
    PerplexityHandler --> PerplexityService
    RagFlowHandler --> RagFlowService
    NostrAuthHandler --> NostrAuthService

    GraphService --> PhysicsEngine
    PhysicsEngine --> GPUComputeService
    PhysicsEngine --> ClientManager

    %% Connections to External Components
    FileService --> GitHubAPI
    PerplexityService --> PerplexityAI
    RagFlowService --> RagFlowAPI
    SpeechService --> OpenAI_API
    NostrAuthService --> NostrPlatformAPI

    %% Styling for clarity
    style Frontend fill:#f9f,stroke:#333,stroke-width:2px
    style Backend fill:#bbf,stroke:#333,stroke-width:2px
    style External fill:#bfb,stroke:#333,stroke-width:2px
```

### Class Diagram

```mermaid
classDiagram
    direction LR

    class AppClient {
        <<React Component>>
        +graphDataManager: GraphDataManager
        +webSocketService: WebSocketService
        +settingsStore: SettingsStore
        +platformManager: PlatformManager
        +xrSessionManager: XRSessionManager
        +nostrAuthService: NostrAuthService (Client)
        +initialize()
        +render()
    }

    class GraphManagerComponent {
        <<React Component>>
        +nodes: GraphNode[]
        +edges: Edge[]
        +updateNodePositions(data: ArrayBuffer)
        +renderGraph()
    }

    class WebSocketService_Client {
        <<TypeScript Service>>
        -socket: WebSocket
        +connect()
        +sendMessage(data: object)
        +onBinaryMessage(callback: function)
        +onConnectionStatusChange(callback: function)
        +isReady(): boolean
    }

    class SettingsStore_Client {
        <<Zustand Store>>
        +settings: Settings
        +get(path: string): any
        +set(path: string, value: any)
        +initialize(): Promise<Settings>
    }

    class GraphDataManager_Client {
        <<TypeScript Service>>
        -data: GraphData
        +fetchInitialData(): Promise<GraphData>
        +updateNodePositions(data: ArrayBuffer)
        +sendNodePositions()
        +getGraphData(): GraphData
    }

    class NostrAuthService_Client {
        <<TypeScript Service>>
        +login(): Promise<AuthState>
        +logout(): Promise<void>
        +onAuthStateChanged(listener: function): function
        +isAuthenticated(): boolean
    }

    AppClient --> GraphManagerComponent
    AppClient --> WebSocketService_Client
    AppClient --> SettingsStore_Client
    AppClient --> GraphDataManager_Client
    AppClient --> NostrAuthService_Client
    GraphDataManager_Client --> WebSocketService_Client

    class AppState_Server {
        <<Rust Struct>>
        +graph_service: GraphService_Server
        +gpu_compute: Option<Arc<RwLock<GPUCompute_Util>>>
        +settings: Arc<RwLock<AppFullSettings>>
        +protected_settings: Arc<RwLock<ProtectedSettings_Model>>
        +metadata: Arc<RwLock<MetadataStore_Model>>
        +github_client: Arc<GitHubClient_Service>
        +content_api: Arc<ContentAPI_Service>
        +speech_service: Option<Arc<SpeechService_Server>>
        +nostr_service: Option<web::Data<NostrService_Server>>
        +client_manager: Arc<ClientManager_Server>
        +new(settings, github_client, content_api, speech_service, gpu_compute, client_manager)
    }

    class GraphService_Server {
        <<Rust Struct>>
        +graph_data: Arc<RwLock<GraphData_Model>>
        +node_map: Arc<RwLock<HashMap_String_NodeModel_>>
        +gpu_compute: Option<Arc<RwLock<GPUCompute_Util>>>
        +client_manager: Arc<ClientManager_Server>
        +new(settings, gpu_compute, client_manager)
        +build_graph_from_metadata(metadata: &MetadataStore_Model): Result<GraphData_Model>
        +calculate_layout(gpu_compute, graph, node_map, params): Result<()>
        +start_broadcast_loop(client_manager)
        +get_node_positions(): Vec<Node_Model>
    }

    class SpeechService_Server {
        <<Rust Struct>>
        +settings: Arc<RwLock<AppFullSettings>>
        +tts_provider: Arc<RwLock<TTSProvider_Enum>>
        +audio_tx: broadcast.Sender_Vec_u8_
        +new(settings)
        +text_to_speech(text: String, options: SpeechOptions): Result<()>
    }

    class NostrService_Server {
        <<Rust Struct>>
        +users: Arc<RwLock<HashMap_String_NostrUser_>>
        +verify_auth_event(event: AuthEvent): Result<NostrUser_Model>
        +validate_session(pubkey: str, token: str): bool
        +get_user(pubkey: str): Option<NostrUser_Model>
    }
    
    class GPUCompute_Util {
        <<Rust Struct>>
        +device: Arc<CudaDevice>
        +force_kernel: CudaFunction
        +node_data: CudaSlice_BinaryNodeData_
        +new(graph: &GraphData_Model): Result<Arc<RwLock<Self>>>
        +compute_forces(): Result<()>
        +get_node_data(): Result<Vec<BinaryNodeData>>
    }
    
    class ClientManager_Server {
        <<Rust Struct>>
        +clients: RwLock<HashMap_usize_Addr_SocketFlowServer_>>
        +register(addr): usize
        +unregister(id: usize)
        +broadcast_node_positions(nodes: Vec<Node_Model>)
    }

    AppState_Server --> GraphService_Server
    AppState_Server --> NostrService_Server
    AppState_Server --> SpeechService_Server
    AppState_Server --> GPUCompute_Util
    AppState_Server --> ClientManager_Server
    GraphService_Server --> GPUCompute_Util
    GraphService_Server --> ClientManager_Server
```

### Sequence Diagram

```mermaid
sequenceDiagram
    participant ClientUI as Client UI (React)
    participant GraphMgrClient as GraphDataManager (Client)
    participant WSClient as WebSocketService (Client)
    participant SettingsClient as SettingsStore (Client)
    participant NostrAuthClient as NostrAuthService (Client)
    participant PlatformMgrClient as PlatformManager (Client)
    participant R3FRenderer as ReactThreeFiber (Client)

    participant ActixServer as Actix Web Server (Backend)
    participant AppStateSrv as AppState (Backend)
    participant GraphSrv as GraphService (Backend)
    participant GPUComputeSrv as GPUCompute (Backend)
    participant ClientMgrSrv as ClientManager (Backend)
    participant FileSrv as FileService (Backend)
    participant NostrSrv as NostrService (Backend)
    participant SpeechSrv as SpeechService (Backend)
    participant SettingsHandlerSrv as SettingsHandler (Backend)
    participant NostrHandlerSrv as NostrHandler (Backend)
    participant FileHandlerSrv as FileHandler (Backend)
    participant GraphHandlerSrv as GraphHandler (Backend)
    participant WSHandlerSrv as WebSocketHandler (Backend)
    
    participant GitHubAPI as GitHub API (External)
    participant PerplexityAPI as Perplexity AI (External)
    participant RagFlowAPI as RagFlow API (External)
    participant OpenAI_API as OpenAI API (External)
    participant NostrPlatform as Nostr Platform (External)

    %% === Server Initialisation ===
    activate ActixServer
    ActixServer->>ActixServer: Load AppFullSettings (settings.yaml, env)
    alt Settings Load Error
        ActixServer-->>ClientUI: HTTP 500 (Conceptual)
    else Settings Loaded
        ActixServer->>AppStateSrv: new(AppFullSettings, GitHubClient, ContentAPI, SpeechService, GPUCompute, ClientManager)
        activate AppStateSrv
            Note over AppStateSrv: Initialises services like GitHubClient, ContentAPI
            AppStateSrv->>SpeechSrv: new(AppFullSettings)
            activate SpeechSrv; deactivate SpeechSrv
            AppStateSrv->>NostrSrv: new() (via init_nostr_service)
            activate NostrSrv; deactivate NostrSrv
            AppStateSrv->>FileSrv: load_or_create_metadata()
            activate FileSrv; deactivate FileSrv
            AppStateSrv->>GraphSrv: build_graph_from_metadata()
            activate GraphSrv
                GraphSrv->>GraphSrv: Initialise random positions
            deactivate GraphSrv
            AppStateSrv->>GPUComputeSrv: new(GraphData) (or test_gpu)
            activate GPUComputeSrv; deactivate GPUComputeSrv
            AppStateSrv->>GraphSrv: new(AppFullSettings, GPUCompute, ClientManager)
            activate GraphSrv
                GraphSrv->>GraphSrv: Start physics simulation loop (async)
                GraphSrv->>GraphSrv: Start broadcast loop (async)
            deactivate GraphSrv
        AppStateSrv-->>ActixServer: Initialised AppState
        deactivate AppStateSrv
    end
    deactivate ActixServer

    %% === Client Initialisation ===
    activate ClientUI
    ClientUI->>PlatformMgrClient: initialise()
    activate PlatformMgrClient; deactivate PlatformMgrClient
    ClientUI->>SettingsClient: initialise()
    activate SettingsClient
        SettingsClient->>SettingsClient: Load from localStorage
        SettingsClient->>ActixServer: GET /api/user-settings (fetchSettings)
        activate ActixServer
            ActixServer->>SettingsHandlerSrv: get_public_settings(AppState)
            SettingsHandlerSrv-->>ActixServer: UISettings (JSON)
        deactivate ActixServer
        ActixServer-->>SettingsClient: Settings JSON
        SettingsClient->>SettingsClient: Merge and store settings
    deactivate SettingsClient
    
    ClientUI->>NostrAuthClient: initialise()
    activate NostrAuthClient
        NostrAuthClient->>NostrAuthClient: Check localStorage for session
        alt Stored Session Found
            NostrAuthClient->>ActixServer: POST /api/auth/nostr/verify (token)
            activate ActixServer
                ActixServer->>NostrHandlerSrv: verify(AppState, token_payload)
                NostrHandlerSrv->>NostrSrv: validate_session(pubkey, token)
                NostrSrv-->>NostrHandlerSrv: Validation Result
            deactivate ActixServer
            ActixServer-->>NostrAuthClient: VerificationResponse
            NostrAuthClient->>SettingsClient: Update auth state
        end
    deactivate NostrAuthClient

    ClientUI->>WSClient: connect()
    activate WSClient
        WSClient->>ActixServer: WebSocket Handshake (/wss)
        activate ActixServer
            ActixServer->>WSHandlerSrv: handle_connection(AppState, ClientManager)
            activate WSHandlerSrv
                WSHandlerSrv->>ClientMgrSrv: register(client_addr)
                activate ClientMgrSrv; deactivate ClientMgrSrv
            deactivate WSHandlerSrv
        deactivate ActixServer
        ActixServer-->>WSClient: WebSocket Opened
        WSClient->>WSClient: isConnected = true
        WSClient-->>ActixServer: {"type":"requestInitialData"} (on connection_established from server)
        activate ActixServer
            ActixServer->>WSHandlerSrv: Handle requestInitialData
            WSHandlerSrv->>GraphSrv: get_node_positions()
            GraphSrv-->>WSHandlerSrv: Vec<Node_Model>
            WSHandlerSrv->>WSHandlerSrv: Encode to binary
            WSHandlerSrv-->>WSClient: Binary Position Data (Initial Graph)
        deactivate ActixServer
        WSClient->>GraphMgrClient: updateNodePositions(binary_data)
        activate GraphMgrClient
            GraphMgrClient->>GraphMgrClient: Parse binary, update internal graph
            GraphMgrClient->>R3FRenderer: Trigger re-render
        deactivate GraphMgrClient
    deactivate WSClient
    
    ClientUI->>GraphMgrClient: fetchInitialData() (if WebSocket initial data is not primary)
    activate GraphMgrClient
        GraphMgrClient->>ActixServer: GET /api/graph/data
        activate ActixServer
            ActixServer->>GraphHandlerSrv: get_graph_data(AppState)
            GraphHandlerSrv->>GraphSrv: get_graph_data_mut()
            GraphSrv-->>GraphHandlerSrv: GraphData_Model
        deactivate ActixServer
        ActixServer-->>GraphMgrClient: GraphData JSON
        GraphMgrClient->>GraphMgrClient: Set graph data
        GraphMgrClient->>R3FRenderer: Trigger re-render
    deactivate GraphMgrClient
    deactivate ClientUI

    %% === Continuous Graph Updates (Server to Client) ===
    loop Physics Simulation & Broadcast (Backend)
        GraphSrv->>GPUComputeSrv: compute_forces()
        GPUComputeSrv-->>GraphSrv: Updated Node Data
        GraphSrv->>ClientMgrSrv: broadcast_node_positions(updated_nodes)
        activate ClientMgrSrv
            ClientMgrSrv->>WSHandlerSrv: Send binary to all clients
            WSHandlerSrv-->>WSClient: Binary Position Data
        deactivate ClientMgrSrv
        WSClient->>GraphMgrClient: updateNodePositions(binary_data)
        activate GraphMgrClient
            GraphMgrClient->>GraphMgrClient: Parse binary, update internal graph
            GraphMgrClient->>R3FRenderer: Trigger re-render
        deactivate GraphMgrClient
    end

    %% === User Drags Node (Client to Server) ===
    ClientUI->>R3FRenderer: User interacts with node
    R3FRenderer->>GraphMgrClient: Node position changed by user
    activate GraphMgrClient
        GraphMgrClient->>GraphMgrClient: Update local node position
        GraphMgrClient->>WSClient: sendNodePositions() (sends binary update)
        activate WSClient
            WSClient->>ActixServer: Binary Position Data (Client Update)
            activate ActixServer
                ActixServer->>WSHandlerSrv: Handle binary message
                WSHandlerSrv->>GraphSrv: update_node_positions(client_updates)
                activate GraphSrv
                    GraphSrv->>GraphSrv: Update internal graph, resolve conflicts
                    GraphSrv->>GPUComputeSrv: compute_forces() (recalculate layout)
                    GPUComputeSrv-->>GraphSrv: Updated Node Data
                deactivate GraphSrv
                Note over ActixServer: Server now has authoritative positions.
                Note over ActixServer: Broadcast loop will send these out.
            deactivate ActixServer
        deactivate WSClient
    deactivate GraphMgrClient

    %% === Settings Update Flow ===
    ClientUI->>SettingsClient: User changes a setting
    activate SettingsClient
        SettingsClient->>SettingsClient: Update local settings state
        SettingsClient->>ActixServer: POST /api/user-settings/sync (settings JSON)
        activate ActixServer
            ActixServer->>SettingsHandlerSrv: update_user_settings(AppState, settings_payload)
            activate SettingsHandlerSrv
                SettingsHandlerSrv->>AppStateSrv: settings.write().await (AppFullSettings)
                AppStateSrv->>AppStateSrv: Merge client settings into AppFullSettings
                AppStateSrv->>AppStateSrv: AppFullSettings.save() to settings.yaml
                SettingsHandlerSrv->>ClientMgrSrv: Broadcast settings_updated JSON
                activate ClientMgrSrv
                    ClientMgrSrv->>WSHandlerSrv: Send JSON to all clients
                    WSHandlerSrv-->>WSClient: {"type":"settings_updated", "payload":...}
                deactivate ClientMgrSrv
            deactivate SettingsHandlerSrv
            SettingsHandlerSrv-->>ActixServer: Updated UISettings (JSON)
        deactivate ActixServer
        ActixServer-->>SettingsClient: Confirmation
    deactivate SettingsClient
    WSClient->>SettingsClient: Receive settings_updated message
    activate SettingsClient
        SettingsClient->>SettingsClient: Update local settings store
        SettingsClient->>ClientUI: Notify UI components of change
    deactivate SettingsClient

    %% === Nostr Authentication Flow ===
    ClientUI->>NostrAuthClient: User clicks Login
    activate NostrAuthClient
        NostrAuthClient->>NostrAuthClient: Interact with NIP-07 Provider (e.g., window.nostr)
        NostrAuthClient->>NostrAuthClient: Get pubkey, sign auth event
        NostrAuthClient->>ActixServer: POST /api/auth/nostr (signed_event_payload)
        activate ActixServer
            ActixServer->>NostrHandlerSrv: login(AppState, event_payload)
            activate NostrHandlerSrv
                NostrHandlerSrv->>NostrSrv: verify_auth_event(event)
                activate NostrSrv
                    NostrSrv->>NostrSrv: Verify signature, manage user session
                    NostrSrv-->>NostrHandlerSrv: NostrUser_Model with session_token
                deactivate NostrSrv
            deactivate NostrHandlerSrv
            NostrHandlerSrv-->>ActixServer: AuthResponse (user_dto, token, expires_at, features)
        deactivate ActixServer
        ActixServer-->>NostrAuthClient: AuthResponse JSON
        NostrAuthClient->>NostrAuthClient: Store token, update user state
        NostrAuthClient->>SettingsClient: Update auth state in store
        NostrAuthClient-->>ClientUI: Login successful / UI update
    deactivate NostrAuthClient
```

### AR Features Implementation Status

#### Hand Tracking (Meta Quest 3)
- XR Interaction is primarily managed by `client/src/features/xr/systems/HandInteractionSystem.tsx` and related hooks/providers like `useSafeXRHooks.tsx`.
- Session management is in `client/src/features/xr/managers/xrSessionManager.ts`.
- Initialisation logic is in `client/src/features/xr/managers/xrInitializer.ts`.
- Currently addressing:
  - Performance optimisation for AR passthrough mode.
  - Virtual desktop cleanup during AR activation (conceptual, not explicitly in code).
  - Type compatibility for WebXR hand input APIs (e.g., `XRHand`, `XRJointSpace` as seen in `webxr-extensions.d.ts`).
  - Joint position extraction methods for gesture recognition.

##### Current Challenges
- Ensuring robust type definitions for WebXR extensions across different browsers/devices (see `client/src/features/xr/types/webxr-extensions.d.ts`).
- Extracting and interpreting joint positions from `XRJointSpace` for reliable gesture recognition (conceptual, `HandInteractionSystem.tsx` has stubs).
- Performance optimisation in AR passthrough mode, especially with complex scenes.

##### Next Steps
- Refine `webxr-extensions.d.ts` for better type safety with hand tracking APIs.
- Implement more sophisticated gesture recognition in `HandInteractionSystem.tsx`.
- Optimise AR mode transitions and rendering performance.
- Enhance Meta Quest 3 specific features if possible (e.g., passthrough quality).

### Authentication and Settings Inheritance

#### Unauthenticated Users
- Use browser's localStorage for settings persistence (via Zustand `persist` middleware in `client/src/store/settingsStore.ts`).
- Settings are stored locally and not synced to a user-specific backend store.
- Default to basic settings visibility.
- Limited to local visualisation features; AI and GitHub features requiring API keys will not be available unless default keys are configured on the server.

#### Authenticated Users (Nostr)
- **Regular Users**:
    - Settings are loaded from and saved to user-specific files on the server (e.g., `/app/user_settings/<pubkey>.yaml`), managed by `src/handlers/settings_handler.rs` using `UserSettings` model.
    - These user-specific settings are a subset of the global settings (typically UI/visualisation preferences defined in `UISettings`).
    - Can access features based on their `feature_access.rs` configuration (e.g., RAGFlow, OpenAI by default for new users).
    - Can manage their own API keys for these services via `/api/auth/nostr/api-keys` endpoint, stored in their `NostrUser` profile on the server.
- **Power Users**:
    - Directly load and modify the global server settings from `settings.yaml` (represented by `AppFullSettings` in Rust).
    - Have full access to all settings and advanced API features (Perplexity, RAGFlow, GitHub, OpenAI TTS) which use API keys configured in `settings.yaml` or environment variables.
    - Settings modifications made by power users are persisted to the main `settings.yaml` and broadcast to all connected clients.

### Settings Inheritance Flow

```mermaid
graph TD
    A[Start] --> B{"Authenticated?"}
    B -->|No| C["Load LocalSettings (localStorage via Zustand)"]
    B -->|Yes| D{"Is Power User? (feature_access.rs)"}
    D -->|No| E["Load UserSpecificSettings (user_settings/pubkey.yaml via API)"]
    D -->|Yes| F["Load GlobalServerSettings (settings.yaml via API)"]
    C --> X["Apply Settings to UI"]
    E --> X
    F --> X
```

### Settings Sync Flow

```mermaid
graph TD
    A["Setting Changed in UI"] --> B{"Authenticated?"}
    B -->|No| C["Save Locally (localStorage via Zustand)"]
    B -->|Yes| D{"Is Power User?"}
    D -->|No| E["Save to UserSpecificSettings (user_settings/pubkey.yaml via API)"]
    D -->|Yes| F["Save to GlobalServerSettings (settings.yaml via API)"]
    F --> G["Server Broadcasts GlobalSettingsUpdate to All Clients"]
    G --> H["Other Clients Update Local Store"]
    E --> I["User's Local Store Updated"]
    C --> I
```

### Modular Control Panel Architecture

The client's user interface for settings and controls is primarily managed by the `LowerControlPanel.tsx` component. This panel uses a tabbed interface to organise different categories of settings and tools. Some sections, like those within `SettingsSection.tsx`, support being "detached" into floating draggable windows.

#### Component Structure

The main UI is structured as follows:
- **`LowerControlPanel.tsx`**: A two-pane layout.
    - **Left Pane**: Contains tabs for core settings:
        - Nostr Authentication (`NostrAuthSection.tsx`)
        - System Settings (`SystemPanel.tsx`)
        - Visualisation Settings (`VisualisationPanel.tsx`)
        - XR Settings (`XRPanel.tsx`)
        - AI Services Settings (`AIPanel.tsx`)
    - **Right Pane**: Contains tabs for features/tools:
        - Embedded "Narrative Gold Mine" iframe.
        - Markdown Renderer (`MarkdownRenderer.tsx`) for displaying content.
        - LLM Query interface (basic textarea and button).
- **`SettingsSection.tsx`**: Used within panels (e.g., `VisualisationPanel.tsx`) to group related settings. Supports:
    - Collapsible sections.
    - Detaching into a draggable, floating window using `react-draggable`.
- **`SettingControlComponent.tsx`**: Renders individual UI controls (sliders, toggles, inputs) for each setting, including dynamic tooltips using `Tooltip.tsx`.

The conceptual interfaces for settings provided in the original README are useful for understanding the data structure but are not direct props to a single "ModularControlPanel" component. Instead, settings are managed by `zustand` (`SettingsStore.ts`) and individual panel components consume and update this store.

```typescript
// Conceptual structure of a setting item (managed by SettingsStore)
interface UISetting { // From client/src/features/settings/types/uiSetting.ts
  type: 'slider' | 'toggle' | 'colour' | 'select' | 'number' | 'text'; // Simplified
  id?: string;
  label?: string;
  value?: any;
  min?: number;
  max?: number;
  step?: number;
  options?: Array<{ value: string; label: string }>;
  // ... other properties like description, help, advanced
}

// Conceptual structure for how settings are organised in the store (e.g., settings.visualisation.nodes)
interface SettingsCategory {
  [settingId: string]: UISetting | SettingsCategory;
}
```

#### Layout Management
The overall layout is a fixed two-pane structure within `LowerControlPanel.tsx`.
Individual `SettingsSection` components can be detached, and their position is managed by `react-draggable` locally. There isn't a global `LayoutConfig` prop managing all detachable panel positions in the way the conceptual interface suggested. User preferences for advanced settings visibility are handled by `ControlPanelProvider` and `useControlPanelContext`.

#### Performance Optimisations
- **Debounced Updates**: `SettingControlComponent.tsx` uses `onBlur` or Enter key for text/number inputs, which acts as a form of debouncing for settings changes that might trigger expensive re-renders or API calls.
- **CSS Transforms**: Used by `react-draggable` for smooth movement of detached panels.
- **Memoisation**: `useMemo` is used in components like `GraphManager.tsx` to stabilise expensive calculations or object references.
- **Targeted Re-renders**: Zustand store selectors for primitive values are used in some places (e.g., `App.tsx`) to avoid unnecessary re-renders.

The goal is to maintain responsiveness, especially during interactions with the 3D visualisation and real-time updates.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Acknowledgements

- Prof Rob Aspin: For inspiring the project's vision and providing valuable resources.
- OpenAI: For their advanced AI models powering the question-answering features.
- Perplexity AI and RAGFlow: For their AI services enhancing content processing and interaction.
- Three.js: For the robust 3D rendering capabilities utilised in the frontend.
- Actix: For the high-performance web framework powering the backend server.



## Docker Configuration


### docker-compose.yml

name: logseq-xr

services:
  webxr:
    build: .
    image: logseq-xr-image:latest
    container_name: logseq-xr-webxr
    read_only: false
    networks:
      ragflow:
        aliases:
          - webxr-client # Removed logseq-xr-webxr alias
    deploy:
      resources:
        limits:
          cpus: '16.0'
          memory: 64G
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']  # Explicitly use GPU 0
              capabilities: [compute, utility]
    expose:
      - "4000"
    ports:
      - "4000:4000"  # Map container nginx port 4000 to host port 4000
    environment:
      - RUST_LOG=off                 # Changed from info
      - RUST_BACKTRACE=1
      - BIND_ADDRESS=0.0.0.0
      - PORT=3001  # Explicitly set Rust backend to use port 3001
      - NGINX_PORT=4000  # Set nginx to use port 4000
      - NVIDIA_GPU_UUID=GPU-553dc306-dab3-32e2-c69b-28175a6f4da6  # Direct UUID value for the specific GPU
      - NVIDIA_VISIBLE_DEVICES=GPU-553dc306-dab3-32e2-c69b-28175a6f4da6  # Pass the GPU UUID directly
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - NODE_ENV=production
      - GIT_HASH=${GIT_HASH:-development}  # Pass GIT_HASH from build environment
      - DEBUG_MODE=${DEBUG_MODE:-false}  # Control whether to start webxr or not
    env_file:
      - .env
    volumes:
      - ./data/markdown:/app/data/markdown
      - ./data/metadata:/app/data/metadata  # Added metadata volume mount
      - ./data/user_settings:/app/user_settings  # Added user settings volume mount
      - ./data/settings.yaml:/app/settings.yaml:rw # Simplified syntax, rw for read-write
      - type: tmpfs
        target: /tmp
        tmpfs:
          size: 4G
    user: "${UID:-1000}:${GID:-1000}"  # Use host user's UID/GID or default to 1000
    restart: unless-stopped
    stop_grace_period: 30s
    command: sh -c 'exec /app/start.sh'  # Always start WebXR with GPU enabled (via modified start.sh)
    init: true
    logging:
      driver: "json-file"
      options:
        max-size: "1g"
        max-file: "5"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

# Removed cloudflared service definition - now defined in docker-compose.production.yml
networks:
  ragflow:
    external: true
    name: docker_ragflow  # RAGFlow's network name from docker network ls

### docker-compose.dev.yml

services:
  webxr:
    container_name: logseq_spring_thing_webxr
    build:
      context: .
      dockerfile: Dockerfile.dev
      args:
        CUDA_ARCH: ${CUDA_ARCH:-86}
    volumes:
      - ./client:/app/client
      - ./data/markdown:/app/data/markdown
      - ./data/metadata:/app/data/metadata
      - ./data/user_settings:/app/user_settings
      - ./data/settings.yaml:/app/settings.yaml
      - ./nginx.dev.conf:/etc/nginx/nginx.conf:ro # Mount dev Nginx config (read-only)
      - ./logs/nginx:/var/log/nginx # Mount nginx logs to host
      - ./scripts/logs:/app/logs
      - npm-cache:/root/.npm
      - cargo-cache:/root/.cargo/registry
      - cargo-git-cache:/root/.cargo/git
      - cargo-target-cache:/app/target # Cache Rust build artifacts
    env_file:
      - .env
    environment:
      - NVIDIA_VISIBLE_DEVICES=GPU-553dc306-dab3-32e2-c69b-28175a6f4da6
      - NVIDIA_GPU_UUID=GPU-553dc306-dab3-32e2-c69b-28175a6f4da6
      - RUST_LOG=off
      - NODE_ENV=development
      - VITE_DEV_SERVER_PORT=5173 # Internal Vite port, accessed via Nginx
      - VITE_API_PORT=4000
      - VITE_HMR_PORT=24678 # Internal HMR port, accessed via Nginx
      - RUST_LOG_REDIRECT=true
      # Override the port from settings.yaml for development environment
      # Ensure Rust backend listens on 4000, which Vite proxies to.
      - SYSTEM_NETWORK_PORT=4000
    deploy: # Indentation: 4 spaces
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [compute,utility]
              device_ids: ['0']
    ports: # Indentation: 4 spaces
      # Expose only Nginx port 3001 to the host.
      # Other services (Vite 5173, Rust 4000, HMR 24678) are accessed via Nginx proxy.
      - "3001:3001"  # Nginx entry point
    networks: # Indentation: 4 spaces
      - docker_ragflow

networks: # Indentation: 2 spaces
  docker_ragflow:
    external: true

volumes: # Indentation: 2 spaces
  npm-cache:
  cargo-cache:
  cargo-git-cache:
  cargo-target-cache:

### docker-compose.production.yml

version: '3.8'

services:
  webxr:
    container_name: logseq-spring-thing-webxr
    build:
      context: .
      dockerfile: Dockerfile.production
      args:
        CUDA_ARCH: ${CUDA_ARCH:-89}
        REBUILD_PTX: ${REBUILD_PTX:-false}
    env_file:
      - .env # Load all variables from .env file into the container
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-GPU-553dc306-dab3-32e2-c69b-28175a6f4da6}
      - NVIDIA_GPU_UUID=${NVIDIA_GPU_UUID:-GPU-553dc306-dab3-32e2-c69b-28175a6f4da6}
      - RUST_LOG=${RUST_LOG:-info}
      - NODE_ENV=production
      - GIT_HASH=${GIT_HASH:-production}
    volumes:
      # Only mount data directories, not code
      - ./data/markdown:/app/data/markdown
      - ./data/metadata:/app/data/metadata
      - ./data/user_settings:/app/user_settings
      - ./data/settings.yaml:/app/settings.yaml
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [compute,utility]
              device_ids: ['0']
    ports:
      - "4000:4000"  # Expose API port
    networks:
      - docker_ragflow # Revert to simple network list item
    restart: unless-stopped
    healthcheck:
      # Check root path which Nginx serves, indicating Nginx is up
      test: ["CMD", "curl", "-f", "http://localhost:4000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  cloudflared:
    container_name: cloudflared-tunnel
    image: cloudflare/cloudflared:latest
    command: tunnel --no-autoupdate run
    environment:
      # Use the standard variable name, expecting it from the .env file loaded by Compose
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
    volumes:
      - ./config.yml:/etc/cloudflared/config.yml:ro
    depends_on:
      - webxr
    networks:
      - docker_ragflow
    restart: unless-stopped

networks:
  docker_ragflow:
    external: true

# Removed duplicated cloudflared service definition

### Dockerfile

# Stage 1: Frontend Build
FROM node:20-slim AS frontend-builder

WORKDIR /app/client

# Copy package files
COPY client/package.json client/package-lock.json ./

# Clean install dependencies
RUN npm ci

# Copy source files and config
COPY client/src ./src
COPY client/index.html ./index.html
COPY client/vite.config.ts ./vite.config.ts
COPY client/tsconfig.json ./tsconfig.json

# Create dist directory
RUN mkdir -p ../data/public/dist

# Build frontend
ENV NODE_ENV=production
RUN npm run build

# Move the build output to the expected location
RUN mv dist/* ../data/public/dist/

# Stage 2: Rust Dependencies Cache
FROM nvidia/cuda:12.8.1-devel-ubuntu22.04 AS rust-deps-builder

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    libssl-dev \
    pkg-config \
    libegl1-mesa-dev \
    libasound2-dev \
    ca-certificates \
    jq \
    && rm -rf /var/lib/apt/lists/*

# Install Rust with better error handling
RUN curl --retry 5 --retry-delay 2 --retry-connrefused https://sh.rustup.rs -sSf | sh -s -- -y --default-toolchain 1.82.0
ENV PATH="/root/.cargo/bin:${PATH}"

# Configure cargo for better network resilience
RUN mkdir -p ~/.cargo && \
    echo '[source.crates-io]' >> ~/.cargo/config.toml && \
    echo 'registry = "https://github.com/rust-lang/crates.io-index"' >> ~/.cargo/config.toml && \
    echo 'replace-with = "ustc"' >> ~/.cargo/config.toml && \
    echo '[source.ustc]' >> ~/.cargo/config.toml && \
    echo 'registry = "sparse+https://mirrors.ustc.edu.cn/crates.io-index/"' >> ~/.cargo/config.toml && \
    echo '[net]' >> ~/.cargo/config.toml && \
    echo 'retry = 10' >> ~/.cargo/config.toml && \
    echo 'timeout = 120' >> ~/.cargo/config.toml && \
    echo 'git-fetch-with-cli = true' >> ~/.cargo/config.toml

WORKDIR /usr/src/app

# Copy Cargo files first for better layer caching
COPY Cargo.toml Cargo.lock ./

# Install git and set GIT_HASH
RUN apt-get update && apt-get install -y git && rm -rf /var/lib/apt/lists/*

# Create dummy src directory and build dependencies
RUN mkdir src && \
    echo "fn main() {}" > src/main.rs && \
    GIT_HASH=$(git rev-parse HEAD || echo "development") \
    CARGO_NET_GIT_FETCH_WITH_CLI=true \
    CARGO_HTTP_TIMEOUT=120 \
    CARGO_HTTP_CHECK_REVOKE=false \
    cargo build --release --features gpu --jobs $(nproc) || \
    (sleep 2 && GIT_HASH=$(git rev-parse HEAD || echo "development") CARGO_HTTP_MULTIPLEXING=false cargo build --release --jobs $(nproc)) || \
    (sleep 5 && GIT_HASH=$(git rev-parse HEAD || echo "development") CARGO_HTTP_MULTIPLEXING=false cargo build --release --jobs 1)

# Copy the real source code and build
COPY src ./src

RUN GIT_HASH=$(git rev-parse HEAD || echo "development") \
    cargo build --release --features gpu --jobs $(nproc) || \
    (sleep 2 && GIT_HASH=$(git rev-parse HEAD || echo "development") cargo build --release --jobs $(nproc)) || \
    (sleep 5 && GIT_HASH=$(git rev-parse HEAD || echo "development") cargo build --release --jobs 1)

# Stage 3: Final Runtime Image
FROM nvidia/cuda:12.8.1-devel-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PATH="/app/venv/bin:${PATH}" \
    NVIDIA_DRIVER_CAPABILITIES=all \
    RUST_LOG=off \
    RUST_BACKTRACE=0 \
    PORT=4000 \
    BIND_ADDRESS=0.0.0.0 \
    NODE_ENV=production \
    DOMAIN=localhost

# Install runtime dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    libssl3 \
    nginx \
    libegl1-mesa \
    libasound2 \
    ca-certificates \
    mesa-utils \
    libgl1-mesa-dri \
    libgl1-mesa-glx \
    netcat-openbsd \
    gettext-base \
    net-tools \
    iproute2 \
    procps \
    lsof \
    jq \
    wget \
    && wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/bin/yq \
    && chmod +x /usr/bin/yq \
    && wget https://github.com/vi/websocat/releases/latest/download/websocat.x86_64-unknown-linux-musl -O /usr/bin/websocat \
    && chmod +x /usr/bin/websocat \
    && rm -rf /var/lib/apt/lists/* \
    && rm -rf /usr/share/doc/* \
    && rm -rf /usr/share/man/*

# Create non-root user
RUN groupadd -r webxr && useradd -r -g webxr webxr


# Create Nginx directories and set permissions for the webxr group
RUN mkdir -p /var/log/nginx /var/run/nginx && \
    chown -R root:webxr /var/log/nginx /var/run/nginx && \
    chmod -R 775 /var/log/nginx /var/run/nginx

# Create necessary directories
RUN mkdir -p /app/data/public/dist && \
    mkdir -p /app/src/utils && \
    chown -R webxr:webxr /app

# Switch to non-root user
USER webxr

# Copy built artifacts
COPY --from=rust-deps-builder /usr/src/app/target/release/webxr /app/
COPY src/utils/compute_forces.ptx /app/src/utils/compute_forces.ptx
COPY --from=frontend-builder /app/data/public/dist /app/data/public/dist

# Copy start script
COPY scripts/start.sh /app/start.sh

# Set proper permissions
USER root
RUN chown -R webxr:webxr /app && \
    chmod 755 /app/start.sh && \
    chmod -R g+w /app && \
    chmod 644 /app/src/utils/compute_forces.ptx
# Settings file is mounted via docker-compose, no need to touch/chmod here

USER webxr

EXPOSE 4000

CMD ["/app/start.sh"]

### Dockerfile.dev

FROM nvidia/cuda:12.8.1-devel-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive \
    RUST_LOG=off \
    PATH="/root/.cargo/bin:${PATH}" \
    NVIDIA_DRIVER_CAPABILITIES=all \
    CUDA_HOME=/usr/local/cuda

# Install dependencies including compilation tools
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    git \
    nginx \
    build-essential \
    gcc-11 \
    g++-11 \
    pkg-config \
    libssl-dev \
    netcat-openbsd \
    lsof \
    gzip \
    expect \
    && rm -rf /var/lib/apt/lists/*

# Create Nginx log directory
RUN mkdir -p /var/log/nginx

# Set gcc-11 as default compiler (needed for CUDA compilation)
RUN update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 100 \
    && update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 100

# Install Node.js
RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
    apt-get install -y nodejs

# Install Rust
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y

WORKDIR /app

# Create necessary directories
RUN mkdir -p /app/data/markdown \
    /app/data/metadata \
    /app/data/runtime \
    /app/user_settings \
    /app/client

# Copy Rust files first
COPY Cargo.toml Cargo.lock ./
COPY src ./src

# Copy client directory with all frontend files
COPY client ./client

# Install Node.js dependencies
WORKDIR /app/client
RUN npm install

WORKDIR /app

# Copy Nginx config
COPY nginx.dev.conf /etc/nginx/nginx.conf

# Build Rust with GPU features
RUN cargo build --features gpu && \
    cp target/debug/webxr /app/webxr

# PTX compilation - now happens during container build
COPY scripts/compile_ptx.sh ./scripts/
COPY src/utils/compute_forces.cu ./src/utils/
RUN chmod +x ./scripts/compile_ptx.sh && \
    # Get CUDA_ARCH from build arg or default to 86
    CUDA_ARCH=${CUDA_ARCH:-86} ./scripts/compile_ptx.sh

# Development entrypoint script
COPY scripts/dev-entrypoint.sh ./
RUN chmod +x ./dev-entrypoint.sh

EXPOSE 3001 4000 5173 24678

ENTRYPOINT ["./dev-entrypoint.sh"]

### Dockerfile.production

FROM nvidia/cuda:12.8.1-devel-ubuntu22.04 as builder

ENV DEBIAN_FRONTEND=noninteractive \
    RUST_LOG=info \
    PATH="/root/.cargo/bin:${PATH}" \
    NVIDIA_DRIVER_CAPABILITIES=all \
    CUDA_HOME=/usr/local/cuda \
    NODE_ENV=production

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    git \
    build-essential \
    gcc-11 \
    g++-11 \
    pkg-config \
    libssl-dev \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Set gcc-11 as default compiler (needed for CUDA compilation)
RUN update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 100 \
    && update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 100

# Install Node.js
RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
    apt-get install -y nodejs

# Install Rust
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y

# Create app directory
WORKDIR /build

# Copy Rust files for server build
COPY Cargo.toml Cargo.lock ./
COPY src ./src

# Copy client files for frontend build
COPY client ./client

# Build client (production mode)
WORKDIR /build/client
# Temporarily set NODE_ENV=development for install to ensure devDeps, then run build
RUN NODE_ENV=development npm install && \
    npm run build

# Build Rust server (release mode with GPU features)
WORKDIR /build
RUN cargo build --release --features gpu

# Handle PTX compilation
# First try to copy existing PTX file
COPY src/utils/compute_forces.ptx ./src/utils/compute_forces.ptx

# Compile PTX if needed (if REBUILD_PTX=true or if the copy failed)
ARG REBUILD_PTX=false
ARG CUDA_ARCH=89
RUN if [ "$REBUILD_PTX" = "true" ] || [ ! -f "./src/utils/compute_forces.ptx" ]; then \
        echo "Compiling PTX file for sm_${CUDA_ARCH}..." && \
        nvcc \
            -arch=sm_${CUDA_ARCH} \
            -O3 \
            --use_fast_math \
            -ptx \
            -rdc=true \
            --compiler-options -fPIC \
            ./src/utils/compute_forces.cu \
            -o ./src/utils/compute_forces.ptx && \
        chmod 644 ./src/utils/compute_forces.ptx && \
        echo "PTX compilation successful"; \
    else \
        echo "Using existing PTX file"; \
    fi

# Second stage: runtime image
FROM nvidia/cuda:12.8.1-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive \
    RUST_LOG=info \
    NODE_ENV=production \
    NVIDIA_DRIVER_CAPABILITIES=all

# Install runtime dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    nginx \
    ca-certificates \
    nodejs \
    npm \
    && rm -rf /var/lib/apt/lists/*

# Create app directory
WORKDIR /app

# Create necessary directories
RUN mkdir -p /app/data/markdown \
    /app/data/metadata \
    /app/data/runtime \
    /app/user_settings \
    /app/client/dist \
    /app/src/utils

# Copy built artifacts from builder stage
COPY --from=builder /build/target/release/webxr /app/webxr
COPY --from=builder /build/client/dist /app/client/dist
COPY --from=builder /build/src/utils/compute_forces.ptx /app/src/utils/compute_forces.ptx

# Copy nginx configuration
COPY nginx.conf /etc/nginx/nginx.conf

# Copy startup script
COPY scripts/start.sh /app/start.sh
RUN chmod +x /app/start.sh

# Expose port
EXPOSE 4000

# Set entrypoint
ENTRYPOINT ["/app/start.sh"]

### nginx.conf

# Use a standard, writable path for the PID file
pid /tmp/nginx.pid;
error_log /var/log/nginx/error.log debug;

events {
    worker_connections 1024;
    multi_accept on;
    use epoll;
}

http {
    # Basic settings
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    charset utf-8;

    # Override TypeScript MIME type (overriding video/mp2t from mime.types)
    types {
        application/typescript ts;
    }

    # Logging
    log_format debug_format '$remote_addr - $remote_user [$time_local] '
                          '"$request" $status $body_bytes_sent '
                          '"$http_referer" "$http_user_agent" '
                          'rt=$request_time uct="$upstream_connect_time" uht="$upstream_header_time" urt="$upstream_response_time"'
                          ' ws_status="$upstream_http_upgrade"';  # Added WebSocket status logging

    access_log /var/log/nginx/access.log debug_format;

    # Optimization
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 120;  # Increased to match cloudflared keepAliveTimeout
    keepalive_requests 100;

    # Gzip settings
    gzip on;
    gzip_disable "msie6";
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_buffers 16 8k;
    gzip_http_version 1.1;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

    # WebSocket configuration
    map $http_upgrade $connection_upgrade {
        default upgrade;
        ''      close;
    }

    # Upstream backend definition for the Rust server
    upstream backend {
        server 127.0.0.1:3001;  # Use localhost since both services are in same container
        keepalive 32;  # Keep connections alive
    }

    # Main server configuration
    server {
        listen 4000 default_server;  # Listen on port 4000 for external connections
        server_name _;  # Accept any server name
        root /app/client/dist;  # Set root to built client files directory

        # Security headers
        add_header X-Content-Type-Options nosniff;
        add_header X-Frame-Options SAMEORIGIN;
        add_header X-XSS-Protection "1; mode=block";
        add_header Referrer-Policy "same-origin" always;
        add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline' 'unsafe-eval'; connect-src 'self' ws: wss: http: https: *.visionflow.info; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://getalby.com; frame-src 'self' https://getalby.com" always;
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

        # WebSocket endpoint
        location /wss {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;
            proxy_set_header Host $host;
            
            # Pass through Cloudflare headers
            proxy_set_header CF-Connecting-IP $http_cf_connecting_ip;
            proxy_set_header CF-Ray $http_cf_ray;
            proxy_set_header CF-Visitor $http_cf_visitor;
            
            # Standard proxy headers
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $http_x_forwarded_proto;
            
            # WebSocket timeouts
            proxy_read_timeout 600m;  # Increased from 3600s to 600m (10 hours) to match websocketIdleTimeout
            proxy_send_timeout 3600s;
            proxy_connect_timeout 75s;
            proxy_buffering off;
            proxy_cache off;
            
            # Debug logging
            access_log /var/log/nginx/websocket.log debug_format;
            error_log /var/log/nginx/websocket-error.log debug;
        }

        # API endpoints
        location /api {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # API specific settings
            proxy_read_timeout 120s;  # Increased for larger graph data
            proxy_send_timeout 120s;  # Increased for larger graph data
            proxy_connect_timeout 60s;
            proxy_buffering on;       # Enable buffering for API responses
            proxy_buffer_size 256k;   # Increased for larger responses
            proxy_buffers 8 256k;     # Increased number of buffers
            proxy_busy_buffers_size 512k;  # Increased for larger responses
            proxy_max_temp_file_size 2048m;  # Allow larger temporary files
            add_header Cache-Control "no-store" always;  # Prevent caching of dynamic data
        }

        # Static files
        location / {
            try_files $uri $uri/ /index.html =404;
            expires 1h;
            add_header Cache-Control "public, no-transform";
            # error_page 404 = @backend;  # Remove fallback for root, let try_files handle index.html
        }

        # Static files with proper MIME types
        location /assets/ {
            expires 7d;
            add_header Cache-Control "public, no-transform" always;
            try_files $uri =404;
            access_log off;
        }

        # Fallback location for static files
        location @backend {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Error pages
        error_page 404 /404.html;
        error_page 500 502 503 504 /50x.html;
        location = /50x.html {
            root /usr/share/nginx/html;
        }
    }
}

### nginx.dev.conf

# nginx.dev.conf
# Development-specific Nginx configuration
pid /tmp/nginx.pid;
error_log /var/log/nginx/error.log info; # Use info level for dev

events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    charset utf-8;

    # Override TypeScript MIME type
    types {
        application/typescript ts;
    }

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';
    access_log /var/log/nginx/access.log main;

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;

    # WebSocket header mapping
    map $http_upgrade $connection_upgrade {
        default upgrade;
        ''      close;
    }

    # Upstream definitions
    upstream backend {
        # Rust backend service
        server 127.0.0.1:4000; # Point to the Rust server's actual listening port
    }

    upstream vite_dev_server {
        # Vite development server
        server 127.0.0.1:5173; # New internal port for Vite
    }

    upstream vite_hmr {
        # Vite HMR WebSocket server
        server 127.0.0.1:24678; # Matches VITE_HMR_PORT
    }

    server {
        listen 3001 default_server; # Main exposed port
        server_name localhost;

        # Vite HMR WebSocket (/ws)
        location /ws {
            proxy_pass http://vite_hmr;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_read_timeout 86400; # Keep HMR connection open
        }

        # Backend WebSocket (/wss) - For Application
        location /wss {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_read_timeout 600m;
            proxy_send_timeout 3600s;
            proxy_connect_timeout 75s;
            proxy_buffering off;
        }

        # Backend API (/api)
        location /api {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_read_timeout 120s;
            proxy_send_timeout 120s;
            proxy_connect_timeout 60s;
            proxy_buffering on;
            proxy_buffer_size 128k;
            proxy_buffers 4 256k;
            proxy_busy_buffers_size 256k;
        }

        # Everything else goes to Vite Dev Server
        location / {
            proxy_pass http://vite_dev_server;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade; # Required for Vite's own WS connections if any
            proxy_set_header Connection $connection_upgrade;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_read_timeout 120s;
            proxy_send_timeout 120s;
        }

        # Error pages (optional but good practice)
        error_page 500 502 503 504 /50x.html;
        location = /50x.html {
            root /usr/share/nginx/html; # Default Nginx error page location
        }
    }
}
### settings.yaml

visualisation:
  nodes:
    base_color: '#66d9ef'  # Light Teal
    metalness: 0.2
    opacity: 1.0
    roughness: 0.7
    size_range:
    - 0.1  # Smaller min size
    - 1.5  # Smaller max size
    quality: medium
    enable_instancing: false
    enable_hologram: false
    enable_metadata_shape: false
    enable_metadata_visualisation: true
  edges:
    arrow_size: 0.02
    base_width: 0.1
    color: '#56b6c2'  # Muted Cyan
    enable_arrows: false
    opacity: 0.85
    width_range:
    - 0.1
    - 1.0
    quality: medium
  physics:
    attraction_strength: 0.05      # Lowered for less pull
    bounds_size: 15.0             # Increased for wider spread
    collision_radius: 0.5
    damping: 0.95
    enable_bounds: true
    enabled: true
    iterations: 100
    max_velocity: 0.02
    repulsion_strength: 0.1       # Increased for more push apart
    spring_strength: 0.2
    repulsion_distance: 2.0       # Increased distance for repulsion
    mass_scale: 1.0
    boundary_damping: 0.95
  rendering:
    ambient_light_intensity: 0.8
    background_color: '#181c28'  # Dark Blue/Grey
    directional_light_intensity: 0.7
    enable_ambient_occlusion: false
    enable_antialiasing: false
    enable_shadows: false
    environment_intensity: 0.7
  animations:
    enable_motion_blur: false
    enable_node_animations: false
    motion_blur_strength: 0.2
    selection_wave_enabled: false
    pulse_enabled: false
    pulse_speed: 0.8
    pulse_strength: 0.6
    wave_speed: 0.5
  labels:
    desktop_font_size: 0.15  # Smaller font size
    enable_labels: true
    text_color: '#f8f8f2'  # Off-White
    text_outline_color: '#181c28'  # Dark background for contrast
    text_outline_width: 0.01
    text_resolution: 32
    text_padding: 0.3
    billboard_mode: camera
  bloom:
    edge_bloom_strength: 0.4
    enabled: false
    environment_bloom_strength: 2.0
    node_bloom_strength: 3.0
    radius: 2.0
    strength: 3.0
  hologram:
    ring_count: 1
    ring_color: '#c2a200'
    ring_opacity: 0.001
    sphere_sizes:
    - 4
    - 8
    ring_rotation_speed: 10.0
    enable_buckminster: false
    buckminster_size: 10
    buckminster_opacity: 0.05
    enable_geodesic: false
    geodesic_size: 10
    geodesic_opacity: 0.05
    enable_triangle_sphere: false
    triangle_sphere_size: 10
    triangle_sphere_opacity: 0.05
    global_rotation_speed: 3
system:
  network:
    bind_address: 0.0.0.0
    domain: visionflow.info
    enable_http2: false
    enable_rate_limiting: false
    enable_tls: false
    max_request_size: 10485760
    min_tls_version: ''
    port: 3001 # Changed from 4000 to avoid conflict with Nginx
    rate_limit_requests: 10000
    rate_limit_window: 600
    tunnel_id: dummy
    api_client_timeout: 30
    enable_metrics: false
    max_concurrent_requests: 1
    max_retries: 3
    metrics_port: 9090
    retry_delay: 5
  websocket:
    binary_chunk_size: 2048
    binary_update_rate: 30
    # Dynamic update rate parameters
    min_update_rate: 5
    max_update_rate: 60
    motion_threshold: 0.05
    motion_damping: 0.9
    binary_message_version: 1
    compression_enabled: false
    compression_threshold: 512
    heartbeat_interval: 10000
    heartbeat_timeout: 600000
    max_connections: 100
    max_message_size: 10485760
    reconnect_attempts: 5
    reconnect_delay: 1000
    update_rate: 60
  security:
    allowed_origins:
    - https://www.visionflow.info
    - https://visionflow.info
    audit_log_path: /app/logs/audit.log
    cookie_httponly: true
    cookie_samesite: Strict
    cookie_secure: true
    csrf_token_timeout: 3600
    enable_audit_logging: false
    enable_request_validation: false
    session_timeout: 3600
  debug:
    enabled: false
    enable_data_debug: false
    enable_websocket_debug: false
    log_binary_headers: false
    log_full_json: false
    log_level: warn
    log_format: json
xr:
  mode: inline
  room_scale: 1.0
  space_type: local-floor
  quality: medium
  enable_hand_tracking: true
  hand_mesh_enabled: true
  hand_mesh_color: '#4287f5'
  hand_mesh_opacity: 0.3
  hand_point_size: 0.006
  hand_ray_enabled: true
  hand_ray_color: '#4287f5'
  hand_ray_width: 0.003
  gesture_smoothing: 0.7
  enable_haptics: true
  haptic_intensity: 0.3
  drag_threshold: 0.08
  pinch_threshold: 0.3
  rotation_threshold: 0.08
  interaction_radius: 0.15
  movement_speed: 0.08
  dead_zone: 0.12
  movement_axes:
    horizontal: 2
    vertical: 3
  enable_light_estimation: false
  enable_plane_detection: false
  enable_scene_understanding: false
  plane_color: '#4287f5'
  plane_opacity: 0.001
  plane_detection_distance: 3.0
  show_plane_overlay: false
  snap_to_floor: false
  enable_passthrough_portal: false
  passthrough_opacity: 0.8
  passthrough_brightness: 1.1
  passthrough_contrast: 1.2
  portal_size: 2.5
  portal_edge_color: '#4287f5'
  portal_edge_width: 0.02
auth:
  enabled: false
  provider: ""
  required: false
ragflow:
  api_key: ''
  agent_id: '302e58df9d4411ef929c0242ac120006'
  api_base_url: ''
  timeout: 30
  max_retries: 3
  chat_id: ''
perplexity:
  api_key: ''
  model: llama-3.1-sonar-small-128k-online
  api_url: ''
  max_tokens: 4096
  temperature: 0.5
  top_p: 0.9
  presence_penalty: 0.0
  frequency_penalty: 0.0
  timeout: 30
  rate_limit: 100
openai:
  api_key: ''
  base_url: ''
  timeout: 30
  rate_limit: 100
kokoro:
  api_url: 'http://pedantic_morse:8880'
  default_voice: 'af_heart'
  default_format: 'mp3'
  default_speed: 1.0
  timeout: 30
  stream: true
  return_timestamps: true
  sample_rate: 24000
### .dockerignore

# Git
.git
.gitignore
.pmpm-store

# Rust
target/

# Node.js
node_modules/
npm-debug.log

# IDEs and editors
.vscode/
.idea/
*.swp
*.swo

# OS generated files
.DS_Store
Thumbs.db

# Test files
tests/

# Environment variables
.env

# Cloudflared
config.yml

## Configuration Files


### Cargo.toml

[package]
name = "webxr"
version = "0.1.0"
edition = "2021"
description = "A WebXR graph visualisation server with GPU-accelerated physics"
authors = ["Your Name <your.email@example.com>"]

[dependencies]
# Web framework and WebSocket
actix-web = { version = "=4.5.1", features = ["compress-gzip", "macros"] }
actix-cors = "=0.7.0"
actix-files = "=0.6.5"
actix = "=0.13.1"
actix-web-actors = "=4.3.0"
tungstenite = "0.22"
tokio-tungstenite = { version = "0.22" }

# Async runtime
tokio = { version = "1.43", features = ["full"] }
futures = "0.3"
futures-util = "0.3"
async-trait = "0.1.86"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
serde_yaml = "0.9"

# Configuration
config = { version = "0.13", features = ["toml"] }
dotenvy = "0.15"
toml = "0.8"

# Logging
log = "0.4"
simplelog = "0.12"

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# GPU/Compute
bytemuck = { version = "1.21", features = ["derive"] }
pollster = "0.3"
cudarc = { version = "0.11", features = ["driver", "cuda-12040"] }

# HTTP client and API
reqwest = { version = "0.11", features = ["json", "stream"] }
async-openai = "0.14.3"
# Even though backoff is unmaintained (RUSTSEC-2025-0012), we'll use the latest version
# since it's used transitively by async-openai and our code doesn't directly import it
backoff = { version = "0.4.0", features = ["tokio"] }
nostr-sdk = "0.26"

# Utilities
uuid = { version = "1.12", features = ["v4", "serde"] }
chrono = { version = "0.4", features = ["serde"] }
base64 = "0.22"
rand = "0.8"
regex = "1.11"
lazy_static = "1.5"
once_cell = "1.19"
sha1 = "0.10.6"
scopeguard = "1.2"
url = "2.5.0"
flate2 = "1.0"
bytes = "1.5"
byteorder = "1.5"
urlencoding = "2.1"

# Math/Linear Algebra (needed for GPU compute)
nalgebra = "0.32"

# Added from the code block
glam = "0.24"

[dev-dependencies]
tokio-test = "0.4"
mockall = "0.11"
pretty_assertions = "1.4"

[features]
default = ["gpu"]
gpu = ["cudarc/driver"]  # Enable GPU support with CUDA driver
cpu = []  # CPU-only mode

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
panic = "abort"
strip = true

[profile.dev]
opt-level = 1

[package.metadata.rust-version]
min = "1.70.0"


### package.json

{
  "name": "logseq-spring-thing-client",
  "private": true,
  "version": "0.1.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview",
    "lint": "eslint src --ext ts,tsx --report-unused-disable-directives"
  },
  "dependencies": {
    "@getalby/sdk": "^4.1.1",
    "@radix-ui/react-collapsible": "^1.1.4",
    "@radix-ui/react-dialog": "^1.1.7",
    "@radix-ui/react-dropdown-menu": "^2.1.7",
    "@radix-ui/react-label": "^2.1.3",
    "@radix-ui/react-radio-group": "^1.1.3",
    "@radix-ui/react-select": "^2.2.4",
    "@radix-ui/react-slider": "^1.2.4",
    "@radix-ui/react-slot": "^1.2.0",
    "@radix-ui/react-switch": "^1.1.4",
    "@radix-ui/react-toast": "^1.2.7",
    "@radix-ui/react-tooltip": "^1.2.0",
    "@react-three/drei": "^9.80.0",
    "@react-three/fiber": "^8.15.0",
    "@react-three/postprocessing": "^2.15.0",
    "@react-three/xr": "^6.0.0",
    "@types/node": "^22.14.1",
    "@types/three": "^0.175.0",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "framer-motion": "^12.6.5",
    "hls.js": "^1.6.2",
    "immer": "^10.1.1",
    "lucide-react": "^0.487.0",
    "nostr-tools": "^2.12.0",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-markdown": "^10.1.0",
    "react-rnd": "^10.5.2",
    "react-syntax-highlighter": "^15.6.1",
    "remark-gfm": "^4.0.1",
    "tailwind-merge": "^3.2.0",
    "three": "^0.175.0",
    "uuid": "^11.1.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.0",
    "@types/react-dom": "^18.2.0",
    "@types/uuid": "^10.0.0",
    "@vitejs/plugin-react": "^4.3.4",
    "autoprefixer": "^10.4.21",
    "postcss": "^8.5.3",
    "tailwindcss": "^4.1.3",
    "typescript": "^5.8.3",
    "vite": "^6.2.6"
  }
}

### vite.config.ts


import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';
import path from 'path';

export default defineConfig({
  plugins: [react()],
  optimizeDeps: {
    include: ['@getalby/sdk']
  },
  build: {
    outDir: 'dist',
    emptyOutDir: true,
  },
  server: {
    host: '0.0.0.0',
    // Use the VITE_DEV_SERVER_PORT from env (should be 5173 now)
    port: parseInt(process.env.VITE_DEV_SERVER_PORT || '5173'),
    strictPort: true,
    hmr: {
      // HMR port is internal (24678), client connects via Nginx (3001)
      port: parseInt(process.env.VITE_HMR_PORT || '24678'),
      // Let client infer host from window.location
      protocol: 'ws',
      clientPort: 3001, // Client connects to Nginx port
      path: '/ws' // Explicitly set the path Nginx proxies
    },
    // Proxy is now handled by Nginx, remove proxy config from Vite
  },
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './src'),
    },
  },
});


### .env.template - MISSING


### tsconfig.json - MISSING


### .eslintrc - MISSING


### .gitignore

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*
debug_log.txt

# Dependencies
node_modules
client/node_modules
.pnpm-store/
.npm
.yarn
/featureclient/

# Build output
dist
dist-ssr
*.local
build
out
/codebase.txt

# Data directories
data/markdown/
data/runtime/
data/public/dist/
data/metadata/metadata.json
data/metadata/layout.json
data/metadata/graph.json

# Documentation and assets
docs/*.gif
docs/*.png
*.mp4
*.webm
*.mov
*.wav
*.mp3
*.glb
*.gltf
*.hdr
*.exr

# Editor directories and files
.vscode/*
!.vscode/extensions.json
!.vscode/settings.json
.idea
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?
.DS_Store
*.pem

# Environment and configuration
.env
.env.*
!.env.example
!.env_template
settings.local.toml
certs

# TypeScript
*.tsbuildinfo
auto-imports.d.ts
components.d.ts

# Testing and coverage
coverage
.nyc_output

# Cache and temporary
.cache
.temp
.eslintcache
.stylelintcache
*.tmp
*.temp
.tmp
.temp

# Rust/Cargo
target/
**/*.rs.bk
Cargo.lock

# Platform and deployment
.vercel
.netlify
.cloudflare

# Debug and profiling
chrome-profiler-events*.json
speed-measure-plugin*.json

# Generated files
generated
optimized-output.gif

# Docker
.docker/
docker-compose.override.yml

# AI and tools
.aider*
.hypothesis/
__pycache__/
*.pyc

# Project specific
scripts/local/
client/visualisation/effects/custom/
.qodo

### tsconfig.json

{
  "compilerOptions": {
    "baseUrl": ".",
    "paths": {
      "@/*": ["src/*"],
      "@/components/*": ["src/components/*"],
      "@/features/*": ["src/features/*"],
      "@/ui/*": ["src/ui/*"],
      "@/services/*": ["src/services/*"],
      "@/utils/*": ["src/utils/*"],
      "@/types/*": ["src/types/*"],
      "@/contexts/*": ["src/contexts/*"],
      "@/store/*": ["src/store/*"]
    },
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "lib": ["es2020", "dom", "dom.iterable"],
    "moduleResolution": "node",
    "skipLibCheck": true,
    "target": "es2020",
    "module": "es2020",
    "resolveJsonModule": true,
    "allowSyntheticDefaultImports": true,
    "typeRoots": ["./node_modules/@types"]
  },
  "include": ["src/**/*.ts", "src/**/*.tsx", "src/**/*.js", "src/**/*.jsx", "src/types/react-three-fiber.d.ts"],
  "exclude": ["node_modules"]
}


## Important Scripts


### scripts/dev-entrypoint.sh

#!/bin/bash
set -e # Exit immediately if a command exits with a non-zero status.

# Configure log paths
LOGS_DIR="/app/logs"
RUST_LOG_FILE="${LOGS_DIR}/rust.log"
VITE_LOG_FILE="${LOGS_DIR}/vite.log"
NGINX_ACCESS_LOG="/var/log/nginx/access.log"
NGINX_ERROR_LOG="/var/log/nginx/error.log"
MAX_LOG_SIZE_MB=10 # Increased size for dev logs
MAX_LOG_FILES=3

# Create directories if they don't exist
mkdir -p "${LOGS_DIR}"
mkdir -p /var/log/nginx # Ensure nginx log dir exists (also done in Dockerfile)
touch ${NGINX_ACCESS_LOG} ${NGINX_ERROR_LOG} # Ensure log files exist

# Function to log messages with timestamps
log() {
    echo "[ENTRYPOINT][$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# Function to rotate logs (simplified for entrypoint)
rotate_log_file() {
    local log_file=$1
    if [ -f "${log_file}" ]; then
        local size_bytes=$(stat -c %s "${log_file}" 2>/dev/null || echo 0)
        local size_mb=$((size_bytes / 1024 / 1024))

        if [ "${size_mb}" -ge "${MAX_LOG_SIZE_MB}" ]; then
            log "Rotating log: ${log_file} (current size: ${size_mb}MB)"
            # Simple rotation: just move current to .1 and clear current
            mv "${log_file}" "${log_file}.1" 2>/dev/null || true
            touch "${log_file}"
        fi
    fi
}

# Cleanup function
cleanup() {
    log "Shutting down services..."
    # Send TERM signal to child processes
    if [ -n "${NGINX_PID:-}" ]; then kill -TERM $NGINX_PID 2>/dev/null || true; fi
    if [ -n "${RUST_PID:-}" ]; then kill -TERM $RUST_PID 2>/dev/null || true; fi
    if [ -n "${VITE_PID:-}" ]; then kill -TERM $VITE_PID 2>/dev/null || true; fi
    # Wait briefly for processes to terminate gracefully
    sleep 2
    # Force kill if still running
    if [ -n "${NGINX_PID:-}" ]; then kill -KILL $NGINX_PID 2>/dev/null || true; fi
    if [ -n "${RUST_PID:-}" ]; then kill -KILL $RUST_PID 2>/dev/null || true; fi
    if [ -n "${VITE_PID:-}" ]; then kill -KILL $VITE_PID 2>/dev/null || true; fi
    log "Cleanup complete."
    # exit 0 # Removed to allow script to continue for indefinite running
}

# Set up trap for cleanup on receiving signals
trap cleanup SIGTERM SIGINT SIGQUIT

# Start the Rust server in the background
start_rust_server() {
    log "Starting Rust server (logging to ${RUST_LOG_FILE})..."
    TARGET_PORT=${SYSTEM_NETWORK_PORT:-4000} # Use SYSTEM_NETWORK_PORT, default to 4000 if not set
    log "Attempting to free port ${TARGET_PORT} if in use..."
    log "Checking for processes on TCP port ${TARGET_PORT}..."
    if command -v lsof &> /dev/null; then
        log "lsof is available. Checking port ${TARGET_PORT} with lsof..."
        # Try to get PIDs, allow failure if no process is found
        LSOF_PIDS=$(lsof -t -i:${TARGET_PORT} || true)
        if [ -n "$LSOF_PIDS" ]; then
            # Replace newlines with spaces if multiple PIDs are found
            LSOF_PIDS_CLEANED=$(echo $LSOF_PIDS | tr '\n' ' ')
            log "Process(es) $LSOF_PIDS_CLEANED found on port ${TARGET_PORT} by lsof. Attempting to kill..."
            # Kill the PIDs, allow failure if they already exited or kill fails
            kill -9 $LSOF_PIDS_CLEANED || log "kill -9 $LSOF_PIDS_CLEANED (from lsof) failed. This might be okay."
            sleep 1 # Give a moment for the port to be released
        else
            log "No process found on port ${TARGET_PORT} with lsof."
        fi
    else
        log "lsof command not found. Skipping lsof check."
    fi

    if command -v fuser &> /dev/null; then
        log "fuser is available. Attempting to free port ${TARGET_PORT} with fuser..."
        fuser -k -TERM ${TARGET_PORT}/tcp || log "fuser -TERM ${TARGET_PORT}/tcp failed or no process found. This is okay."
        sleep 0.5 # Shorter sleep
        fuser -k -KILL ${TARGET_PORT}/tcp || log "fuser -KILL ${TARGET_PORT}/tcp failed or no process found. This is okay."
    else
        log "fuser command not found. Skipping fuser check. Port ${TARGET_PORT} might still be in use if Rust server fails to start."
    fi
    # Rotate log before starting
    rotate_log_file "${RUST_LOG_FILE}"
    # Start Rust server, redirect stdout/stderr to its log file
    /app/webxr --gpu-debug > "${RUST_LOG_FILE}" 2>&1 &
    RUST_PID=$!
    log "Rust server started (PID: $RUST_PID)"
    # Basic check if process started
    sleep 2
    if ! kill -0 $RUST_PID 2>/dev/null; then
        log "ERROR: Rust server failed to start. Check ${RUST_LOG_FILE}."
        # exit 1 # Allow container to stay up for debugging even if Rust server fails
    fi
}

# Start Vite dev server in the background
start_vite() {
    cd /app/client
    log "Starting Vite dev server (logging to ${VITE_LOG_FILE})..."
    # Rotate log before starting
    rotate_log_file "${VITE_LOG_FILE}"
    # Start Vite, redirect stdout/stderr to its log file
    # Use --host 0.0.0.0 to ensure it's accessible within the container network
    FORCE_COLOR=1 npm run dev -- --host 0.0.0.0 --port 5173 > "${VITE_LOG_FILE}" 2>&1 &
    VITE_PID=$!
    log "Vite dev server started (PID: $VITE_PID)"
    # Basic check if process started
    sleep 5 # Vite can take a bit longer to spin up
    if ! kill -0 $VITE_PID 2>/dev/null; then
        log "ERROR: Vite server failed to start. Check ${VITE_LOG_FILE}."
        exit 1
    fi
    cd /app # Go back to app root
}

# Start Nginx in the foreground
start_nginx() {
    log "Starting Nginx..."
    # Ensure Nginx config is valid before starting
    nginx -t
    # Start Nginx in foreground mode
    nginx -g 'daemon off;' &
    NGINX_PID=$!
    log "Nginx started (PID: $NGINX_PID)"
    log "Development environment accessible at http://localhost:3001"
}

# --- Main Execution ---
log "Starting development environment services..."

start_rust_server
start_vite
start_nginx

# Wait for Nginx (foreground process) to exit
wait $NGINX_PID

# If Nginx exits, trigger cleanup
log "Nginx process ended. Initiating cleanup..."
cleanup

log "Entrypoint script will now sleep indefinitely to keep container alive for debugging."
sleep infinity

### scripts/dev.sh

#!/bin/bash
set -euo pipefail

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

# Get the absolute path of the script's directory
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"

# Global variables
DOCKER_COMPOSE_FILE="$PROJECT_ROOT/docker-compose.dev.yml"
CONTAINER_NAME="logseq_spring_thing_webxr"
PROJECT_IDENTIFIER="logseq_spring_thing_dev"  # Unique identifier for our project's processes

log() {
    echo -e "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# Cleanup function
cleanup() {
    log "${YELLOW}Cleaning up development environment...${NC}"
    
    # Stop Docker containers
    if docker ps -q -f name=$CONTAINER_NAME > /dev/null; then
        log "${YELLOW}Stopping Docker containers...${NC}"
        cd "$PROJECT_ROOT" && docker compose -f $DOCKER_COMPOSE_FILE stop # Changed 'down' to 'stop' to prevent container removal
    fi
    
    # Host process cleanup removed as Node/Vite run inside the container
    
    log "${GREEN}Cleanup complete${NC}"
}

# Trap signals
trap cleanup SIGINT SIGTERM EXIT

# Setup function removed as dependencies are installed during Docker build
# Start development servers
start_dev() {
    log "${YELLOW}Starting development servers...${NC}"
    
    # Build and start containers with updated configuration
    log "${YELLOW}Starting Docker containers...${NC}"
    cd "$PROJECT_ROOT" && DOCKER_BUILDKIT=1 docker compose -f $DOCKER_COMPOSE_FILE up --build
}

# Main execution
cleanup  # Clean up any existing processes first
# setup_dev call removed
start_dev

### scripts/launch-production.sh

#!/usr/bin/env bash

###############################################################################
# PRODUCTION DEPLOYMENT SCRIPT
###############################################################################
# This script builds and deploys the application in production mode.
# Key differences from development mode:
# - No volume mounts for client code (static build included in container)
# - Production optimized builds
# - Cloudflared for secure WebSocket connections
# - Proper routing through Nginx
# - GPU acceleration configured for production use
###############################################################################

###############################################################################
# SAFETY SETTINGS
###############################################################################
# -e  Exit on any command returning a non-zero status
# -u  Treat unset variables as errors
# -o pipefail  Return error if any part of a pipeline fails
set -euo pipefail

###############################################################################
# DETECT SCRIPT & PROJECT ROOT
###############################################################################
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
PROJECT_ROOT="$( cd "$SCRIPT_DIR/.." && pwd )"

###############################################################################
# COLOR CONSTANTS
###############################################################################
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'  # No color

###############################################################################
# CONFIGURATION
###############################################################################
# Container names for easier management
WEBXR_CONTAINER="logseq-spring-thing-webxr"
CLOUDFLARED_CONTAINER="cloudflared-tunnel"

# Docker compose file for production
DOCKER_COMPOSE_FILE="docker-compose.production.yml"

# Default CUDA architecture if not specified in .env
DEFAULT_CUDA_ARCH="89"  # Ada Lovelace architecture

###############################################################################
# LOGGING & EXIT HANDLING
###############################################################################
log() {
    # Logs a message with a timestamp
    echo -e "[$(date "+%Y-%m-%d %H:%M:%S")] $1"
}

section() {
    # Prints a section header
    echo -e "\n${BLUE}=== $1 ===${NC}"
}

handle_exit() {
    # Called when the script receives a signal (Ctrl+C, kill, etc.)
    log "\n${YELLOW}Exiting to shell. Containers will continue running.${NC}"
    log "${YELLOW}Use 'docker compose down' to stop containers if needed.${NC}"
    exit 0
}

# Trap Ctrl+C, kill, etc. so we can exit gracefully
trap handle_exit INT TERM

###############################################################################
# UTILITY FUNCTIONS
###############################################################################

# Determine Docker Compose command (v1 or v2)
get_docker_compose_cmd() {
    if docker compose version &>/dev/null; then
        echo "docker compose"
    elif docker-compose version &>/dev/null; then
        echo "docker-compose"
    else
        log "${RED}Error: Docker Compose not found${NC}"
        exit 1
    fi
}

# Check if a command exists
command_exists() {
    command -v "$1" &> /dev/null
}

###############################################################################
# VALIDATION FUNCTIONS
###############################################################################

check_dependencies() {
    section "Checking Dependencies"

    # Check Docker
    if ! command_exists docker; then
        log "${RED}Error: Docker is not installed${NC}"
        return 1
    fi
    log "${GREEN}✓ Docker is installed${NC}"

    # Check Docker Compose
    if ! command_exists docker-compose && ! docker compose version &>/dev/null; then
        log "${RED}Error: Docker Compose not found${NC}"
        return 1
    fi
    log "${GREEN}✓ Docker Compose is installed${NC}"

    # Check NVIDIA tools for GPU support
    if ! command_exists nvidia-smi; then
        log "${YELLOW}Warning: nvidia-smi not found. GPU acceleration may not work.${NC}"
    else
        log "${GREEN}✓ NVIDIA drivers are installed${NC}"
    fi

    # Check CUDA compiler for PTX generation
    if ! command_exists nvcc; then
        log "${YELLOW}Warning: NVIDIA CUDA Compiler (nvcc) not found${NC}"
        log "${YELLOW}Will attempt to use pre-compiled PTX file if available${NC}"
    else
        log "${GREEN}✓ CUDA toolkit is installed${NC}"
    fi

    return 0
}

check_environment_file() {
    section "Checking Environment Configuration"

    # Check if .env file exists
    if [ ! -f "$PROJECT_ROOT/.env" ]; then
        log "${RED}Error: .env file not found in $PROJECT_ROOT${NC}"
        log "${YELLOW}Please create a .env file based on .env.template${NC}"
        return 1
    fi
    log "${GREEN}✓ .env file exists${NC}"

    # Check if settings.yaml exists
    if [ ! -f "$PROJECT_ROOT/data/settings.yaml" ]; then
        log "${RED}Error: settings.yaml not found in $PROJECT_ROOT/data${NC}"
        log "${YELLOW}Please create a settings.yaml file${NC}"
        return 1
    fi
    log "${GREEN}✓ settings.yaml file exists${NC}"

    return 0
}

check_gpu_availability() {
    section "Checking GPU Availability"

    if ! command_exists nvidia-smi; then
        log "${YELLOW}Warning: Cannot check GPU availability (nvidia-smi not found)${NC}"
        return 0
    fi

    # Check if GPU is available
    # Check if nvidia-smi command runs successfully.
    # It might return non-zero even if GPUs exist but are busy/inaccessible temporarily.
    if ! nvidia-smi > /dev/null 2>&1; then
        log "${YELLOW}Warning: nvidia-smi command failed or no NVIDIA GPU detected by it.${NC}"
        log "${YELLOW}GPU acceleration features might be unavailable. Script will continue.${NC}"
        # Allow script to continue, but log the warning. Return 0 as it's non-fatal for the script logic.
        return 0
    fi

    # Get GPU info
    log "${YELLOW}GPU Information:${NC}"
    nvidia-smi --query-gpu=name,memory.total,memory.used,memory.free --format=csv,noheader

    # Check if GPU has enough memory (at least 2GB free)
    local gpu_info
    gpu_info=$(nvidia-smi --query-gpu=memory.free --format=csv,noheader)
    local free_memory
    free_memory=$(echo "$gpu_info" | head -n1 | grep -o '[0-9]\+')

    if [ "$free_memory" -lt 2048 ]; then
        log "${YELLOW}Warning: Less than 2GB of GPU memory available (${free_memory} MiB)${NC}"
        log "${YELLOW}Performance may be degraded${NC}"
    else
        log "${GREEN}✓ Sufficient GPU memory available (${free_memory} MiB)${NC}"
    fi

    return 0
}

check_ragflow_network() {
    section "Checking RAGFlow Network"

    if ! docker network ls | grep -q "docker_ragflow"; then
        log "${YELLOW}RAGFlow network not found, creating it...${NC}"
        docker network create docker_ragflow
        log "${GREEN}✓ Created docker_ragflow network${NC}"
    else
        log "${GREEN}✓ RAGFlow network exists${NC}"
    fi

    return 0
}

###############################################################################
# BUILD FUNCTIONS
###############################################################################

check_ptx_status() {
    section "Checking PTX Status"

    # Check if PTX file exists
    if [ -f "$PROJECT_ROOT/src/utils/compute_forces.ptx" ]; then
        log "${GREEN}✓ PTX file exists${NC}"

        # Check if source CUDA file exists
        if [ -f "$PROJECT_ROOT/src/utils/compute_forces.cu" ]; then
            # Check if PTX is older than CUDA source
            if [ "$PROJECT_ROOT/src/utils/compute_forces.ptx" -ot "$PROJECT_ROOT/src/utils/compute_forces.cu" ]; then
                log "${YELLOW}PTX file is older than CUDA source${NC}"
                log "${YELLOW}PTX will be compiled during Docker build${NC}"
                # Set flag to force PTX compilation in Docker
                export REBUILD_PTX=true
            else
                log "${GREEN}✓ PTX file is up-to-date${NC}"
            fi
        fi
    else
        log "${YELLOW}PTX file not found${NC}"
        log "${YELLOW}PTX will be compiled during Docker build${NC}"
        # Set flag to force PTX compilation in Docker
        export REBUILD_PTX=true
    fi

    return 0
}

# build_client function removed as client is built inside Dockerfile.production
build_docker_images() {
    section "Building Docker Images"

    # Get Docker Compose command
    DOCKER_COMPOSE=$(get_docker_compose_cmd)

    # Set build arguments
    export NVIDIA_GPU_UUID=${NVIDIA_GPU_UUID:-"GPU-553dc306-dab3-32e2-c69b-28175a6f4da6"}
    export NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-$NVIDIA_GPU_UUID}
    export GIT_HASH=$(git rev-parse HEAD 2>/dev/null || echo "production")
    export NODE_ENV=production
    export REBUILD_PTX=${REBUILD_PTX:-false}

    log "${YELLOW}Building Docker images with:${NC}"
    log "  - NVIDIA_GPU_UUID: $NVIDIA_GPU_UUID"
    log "  - GIT_HASH: $GIT_HASH"
    log "  - REBUILD_PTX: $REBUILD_PTX"

    # Build Docker images
    # Relying on exported variables from earlier 'source .env'
    $DOCKER_COMPOSE -f "$PROJECT_ROOT/$DOCKER_COMPOSE_FILE" build --no-cache

    log "${GREEN}✓ Docker images built successfully${NC}"

    return 0
}

###############################################################################
# DEPLOYMENT FUNCTIONS
###############################################################################

clean_existing_containers() {
    section "Cleaning Existing Containers"

    # Get Docker Compose command
    DOCKER_COMPOSE=$(get_docker_compose_cmd)

    # Stop and remove existing containers
    log "${YELLOW}Stopping and removing existing containers...${NC}"

    # Check if containers exist
    if docker ps -a --format '{{.Names}}' | grep -q "$WEBXR_CONTAINER"; then
        log "${YELLOW}Stopping and removing $WEBXR_CONTAINER...${NC}"
        docker stop "$WEBXR_CONTAINER" 2>/dev/null || true
        docker rm "$WEBXR_CONTAINER" 2>/dev/null || true
    fi

    if docker ps -a --format '{{.Names}}' | grep -q "$CLOUDFLARED_CONTAINER"; then
        log "${YELLOW}Stopping and removing $CLOUDFLARED_CONTAINER...${NC}"
        docker stop "$CLOUDFLARED_CONTAINER" 2>/dev/null || true
        docker rm "$CLOUDFLARED_CONTAINER" 2>/dev/null || true
    fi

    # Down any existing compose setup
    # More thorough cleanup: remove orphans and volumes associated with the compose file
    $DOCKER_COMPOSE -f "$PROJECT_ROOT/$DOCKER_COMPOSE_FILE" down --remove-orphans --volumes 2>/dev/null || true

    log "${GREEN}✓ Cleanup complete${NC}"

    return 0
}

start_containers() {
    section "Starting Containers"

    # Get Docker Compose command
    DOCKER_COMPOSE=$(get_docker_compose_cmd)

    # Start containers
    log "${YELLOW}Starting containers...${NC}"
    # Let Docker Compose load the .env file automatically
    $DOCKER_COMPOSE -f "$PROJECT_ROOT/$DOCKER_COMPOSE_FILE" up -d

    log "${GREEN}✓ Containers started${NC}"

    return 0
}

check_application_readiness() {
    section "Checking Application Readiness"

    local max_attempts=60
    local attempt=1
    local wait_secs=2

    log "${YELLOW}Waiting for application to be ready...${NC}"

    while [ "$attempt" -le "$max_attempts" ]; do
        # Check if containers are running
        if ! docker ps --format '{{.Names}}' | grep -q "$WEBXR_CONTAINER"; then
            log "${YELLOW}Attempt $attempt/$max_attempts: Container not running${NC}"
            sleep "$wait_secs"
            attempt=$((attempt + 1))
            continue
        fi

        # Check if HTTP endpoint is accessible
        if ! curl -s http://localhost:4000/health >/dev/null; then
            log "${YELLOW}Attempt $attempt/$max_attempts: HTTP endpoint not ready${NC}"
            sleep "$wait_secs"
            attempt=$((attempt + 1))
            continue
        fi

        # All checks passed
        log "${GREEN}✓ Application is ready${NC}"
        return 0
    done

    log "${RED}Error: Application failed to start properly${NC}"
    return 1
}

###############################################################################
# MAIN EXECUTION
###############################################################################

main() {
    section "Starting Production Deployment"

    # Change to project root
    cd "$PROJECT_ROOT"

    # Docker Compose will automatically load .env from the project root
    if [ ! -f .env ]; then
        log "${YELLOW}Warning: .env file not found in project root. CLOUDFLARE_TUNNEL_TOKEN and other variables may be missing.${NC}"
    fi

    # Run validation checks
    check_dependencies || exit 1
    check_environment_file || exit 1
    check_gpu_availability || true  # Non-fatal
    check_ragflow_network || exit 1

    # Build steps
    check_ptx_status || true  # Non-fatal, just sets flags
    # build_client call removed
    clean_existing_containers || exit 1
    build_docker_images || exit 1

    # Deployment
    start_containers || exit 1
    check_application_readiness || exit 1

    # Final status
    section "Deployment Complete"
    log "${GREEN}🚀 Application is running in production mode!${NC}"

    # Show resource usage
    log "\n${YELLOW}Resource Usage:${NC}"
    docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}"

    # Show endpoints
    log "\n${YELLOW}Endpoints:${NC}"
    echo "HTTP:      http://localhost:4000"
    echo "WebSocket: wss://localhost:4000/wss"

    # Show useful commands
    log "\n${YELLOW}Useful Commands:${NC}"
    DOCKER_COMPOSE=$(get_docker_compose_cmd)
    echo "View logs:    $DOCKER_COMPOSE -f $DOCKER_COMPOSE_FILE logs -f"
    echo "Stop:         $DOCKER_COMPOSE -f $DOCKER_COMPOSE_FILE down"
    echo "Restart:      $DOCKER_COMPOSE -f $DOCKER_COMPOSE_FILE restart"

    # Show logs
    log "\n${YELLOW}Showing logs (Ctrl+C to exit)...${NC}"
    $DOCKER_COMPOSE -f "$DOCKER_COMPOSE_FILE" logs -f &

    wait
}

# Execute main function
main

### scripts/start.sh

#!/bin/bash
set -euo pipefail

# Function to log messages with timestamps
log() {
    echo "[$(date "+%Y-%m-%d %H:%M:%S")] $1"
}

# Check for GPU environment variables
log "Checking GPU environment variables..."

if [ -z "${NVIDIA_GPU_UUID:-}" ]; then
    # Use the specific GPU UUID that we know works
    NVIDIA_GPU_UUID="GPU-553dc306-dab3-32e2-c69b-28175a6f4da6"
    log "Setting NVIDIA_GPU_UUID to known value: $NVIDIA_GPU_UUID"
    export NVIDIA_GPU_UUID
    
    # Also set NVIDIA_VISIBLE_DEVICES to ensure Docker uses this GPU
    if [ -z "${NVIDIA_VISIBLE_DEVICES:-}" ]; then
        export NVIDIA_VISIBLE_DEVICES="$NVIDIA_GPU_UUID"
        log "Setting NVIDIA_VISIBLE_DEVICES to: $NVIDIA_VISIBLE_DEVICES"
    fi
    
    # For older CUDA versions, also set CUDA_VISIBLE_DEVICES
    if [ -z "${CUDA_VISIBLE_DEVICES:-}" ]; then
        # Use device index 0 since NVIDIA_VISIBLE_DEVICES will map to this
        export CUDA_VISIBLE_DEVICES="0"
        log "Setting CUDA_VISIBLE_DEVICES to: $CUDA_VISIBLE_DEVICES"
    fi
else
    log "Using GPU UUID: $NVIDIA_GPU_UUID"
fi

# Parse command line arguments
START_WEBXR=true
if [ $# -gt 0 ] && [ "$1" = "--no-webxr" ]; then
    START_WEBXR=false
fi

# Verify settings file permissions and ensure accessibility
log "Verifying settings.yaml permissions..."
# Ensure the file is accessible by the current user before checking existence
if [ -f "/app/settings.yaml" ]; then
    chmod 666 /app/settings.yaml
    log "settings.yaml permissions set to 666"
else
    log "Error: settings.yaml not found at /app/settings.yaml"
    exit 1
fi
log "settings.yaml permissions verified"

# Set up runtime environment
# Start nginx
log "Starting nginx..."
nginx -t && nginx
log "nginx started successfully"

# Execute the webxr binary only if not in debug mode
if [ "$START_WEBXR" = true ]; then
    log "Preparing to execute webxr with extended GPU diagnostics..."
    log "GPU information:"
    if command -v nvidia-smi &>/dev/null; then
        nvidia-smi
        # Get device uuid to verify it matches our expected value
        UUID=$(nvidia-smi --query-gpu=uuid --format=csv,noheader)
        log "GPU UUID detected by nvidia-smi: $UUID"
    else
        log "WARNING: nvidia-smi not available - this may indicate NVIDIA driver issues"
    fi
    
    # Verify that PTX file exists and is readable
    if [ -f "/app/src/utils/compute_forces.ptx" ]; then
        PTX_SIZE=$(stat -c%s "/app/src/utils/compute_forces.ptx")
        log "✅ PTX file exists and is readable (size: $PTX_SIZE bytes)"
    else
        log "⚠️ PTX file NOT found at /app/src/utils/compute_forces.ptx"
        # Try to create a link to an alternative location if it exists elsewhere
        if [ -f "./src/utils/compute_forces.ptx" ]; then
            log "PTX file found at ./src/utils/compute_forces.ptx, creating symlink"
            ln -sf "$(pwd)/src/utils/compute_forces.ptx" "/app/src/utils/compute_forces.ptx"
        fi
    fi
    
    # Check CUDA visibility
    if [ -n "${CUDA_VISIBLE_DEVICES:-}" ]; then
        log "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"
    else 
        # If not set, explicitly set it to ensure CUDA can see device
        export CUDA_VISIBLE_DEVICES=0
        log "Explicitly setting CUDA_VISIBLE_DEVICES=0"
    fi
    # Always enable GPU debugging to ensure physics simulation runs
    log "Starting webxr with GPU compute enabled"
    exec /app/webxr --gpu-debug
else
    log "Skipping webxr execution (debug mode)"
    # Keep the container running
    tail -f /dev/null
fi
### scripts/compile_ptx.sh

#!/bin/bash

CUDA_ARCH=${CUDA_ARCH:-89}

nvcc \
    -arch=sm_${CUDA_ARCH} \
    -O3 \
    --use_fast_math \
    -ptx \
    -rdc=true \
    --compiler-options -fPIC \
    src/utils/compute_forces.cu \
    -o src/utils/compute_forces.ptx

chmod 644 src/utils/compute_forces.ptx
### scripts/diagnostics.sh

#!/bin/bash
# Modernized diagnostics tool that combines logging and endpoint checking

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

CONTAINER_NAME="logseq_spring_thing_webxr"

show_diagnostics() {
    echo -e "${YELLOW}=== Container Status ===${NC}"
    docker ps -a | grep $CONTAINER_NAME

    echo -e "\n${YELLOW}=== Container Logs ===${NC}"
    docker logs $CONTAINER_NAME

    echo -e "\n${YELLOW}=== Application Logs ===${NC}"
    docker exec $CONTAINER_NAME cat /app/webxr.log

    echo -e "\n${YELLOW}=== Environment Variables ===${NC}"
    docker exec $CONTAINER_NAME env

    echo -e "\n${YELLOW}=== Network Status ===${NC}"
    docker exec $CONTAINER_NAME ip addr show
    docker exec $CONTAINER_NAME netstat -tulpn

    echo -e "\n${YELLOW}=== Resource Usage ===${NC}"
    docker stats $CONTAINER_NAME --no-stream

    echo -e "\n${YELLOW}=== GPU Status ===${NC}"
    docker exec $CONTAINER_NAME nvidia-smi
}

check_endpoints() {
    echo -e "${YELLOW}=== Testing Endpoints ===${NC}"
    endpoints=(
        "http://localhost:4000/api/health"
        "http://localhost:4000/api/graph/data"
        "http://localhost:4000/api/files/fetch"
    )

    for endpoint in "${endpoints[@]}"; do
        echo -e "\nTesting $endpoint"
        curl -v $endpoint
    done
}

# Main execution
echo -e "${GREEN}Starting diagnostics...${NC}"
show_diagnostics
check_endpoints
### scripts/check-rust-logs.sh

#!/bin/bash

# Colors
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

# Log file path
LOG_FILE="scripts/logs/rust.log"

# Function to display usage
usage() {
    echo -e "${YELLOW}Usage:${NC}"
    echo -e "  ./scripts/check-rust-logs.sh [options]"
    echo -e "\n${YELLOW}Options:${NC}"
    echo -e "  -f, --follow    Follow the log file (like tail -f)"
    echo -e "  -n, --lines N   Show last N lines (default: 20)"
    echo -e "  -r, --rotated N Show rotated log file number N (1-3)"
    echo -e "  -h, --help      Show this help message"
    echo -e "\n${YELLOW}Examples:${NC}"
    echo -e "  ./scripts/check-rust-logs.sh            # Show last 20 lines of current log"
    echo -e "  ./scripts/check-rust-logs.sh -f         # Follow the current log file"
    echo -e "  ./scripts/check-rust-logs.sh -n 50      # Show last 50 lines of current log"
    echo -e "  ./scripts/check-rust-logs.sh -r 1       # Show rotated log file 1 (most recent)"
}

# Default values
FOLLOW=false
LINES=20
ROTATED_LOG=""

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -f|--follow)
            FOLLOW=true
            shift
            ;;
        -n|--lines)
            LINES="$2"
            shift 2
            ;;
        -r|--rotated)
            ROTATED_LOG="$2"
            shift 2
            ;;
        -h|--help)
            usage
            exit 0
            ;;
        *)
            echo -e "${YELLOW}Unknown option: $1${NC}"
            usage
            exit 1
            ;;
    esac
done

# Determine which log file to use
if [ -n "$ROTATED_LOG" ]; then
    ROTATED_FILE="${LOG_FILE}.${ROTATED_LOG}"
    if [ ! -f "$ROTATED_FILE" ]; then
        echo -e "${YELLOW}Rotated log file not found: $ROTATED_FILE${NC}"
        echo -e "Available log files:"
        ls -l "${LOG_FILE}"* 2>/dev/null || echo "No log files found."
        exit 1
    fi
    ACTIVE_LOG="$ROTATED_FILE"
    echo -e "${GREEN}Viewing rotated log file: $ROTATED_FILE${NC}"
    FOLLOW=false  # Can't follow rotated logs
else
    ACTIVE_LOG="$LOG_FILE"
    # Check if log file exists
    if [ ! -f "$ACTIVE_LOG" ]; then
        echo -e "${YELLOW}Log file not found: $ACTIVE_LOG${NC}"
        echo -e "Make sure the development server is running."
        exit 1
    fi
fi

# Display log file
echo -e "${GREEN}Rust Server Logs:${NC}"
if [ "$FOLLOW" = true ]; then
    echo -e "${YELLOW}Following log file. Press Ctrl+C to exit.${NC}"
    tail -f "$ACTIVE_LOG"
else
    tail -n "$LINES" "$ACTIVE_LOG"
fi

### scripts/check-vite.sh

#!/bin/bash

# Colors
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

# Container name
CONTAINER_NAME="logseq_spring_thing_webxr"

# Check if container is running
if ! docker ps -q -f name=$CONTAINER_NAME > /dev/null; then
    echo -e "${RED}Container $CONTAINER_NAME is not running.${NC}"
    echo -e "Start the development environment with ${YELLOW}./scripts/dev.sh${NC} first."
    exit 1
fi

# Function to display usage
usage() {
    echo -e "${YELLOW}Usage:${NC}"
    echo -e "  ./scripts/check-vite.sh [options]"
    echo -e "\n${YELLOW}Options:${NC}"
    echo -e "  -f, --follow    Follow the Vite logs (like tail -f)"
    echo -e "  -n, --lines N   Show last N lines (default: 50)"
    echo -e "  -h, --help      Show this help message"
    echo -e "\n${YELLOW}Examples:${NC}"
    echo -e "  ./scripts/check-vite.sh            # Show last 50 lines"
    echo -e "  ./scripts/check-vite.sh -f         # Follow the logs"
    echo -e "  ./scripts/check-vite.sh -n 100     # Show last 100 lines"
}

# Default values
FOLLOW=false
LINES=50

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -f|--follow)
            FOLLOW=true
            shift
            ;;
        -n|--lines)
            LINES="$2"
            shift 2
            ;;
        -h|--help)
            usage
            exit 0
            ;;
        *)
            echo -e "${YELLOW}Unknown option: $1${NC}"
            usage
            exit 1
            ;;
    esac
done

# Check Vite process status
echo -e "${GREEN}Checking Vite process status:${NC}"
docker exec $CONTAINER_NAME ps aux | grep -v grep | grep -E "npm run dev|node.*vite"

# Display Vite logs
echo -e "\n${GREEN}Vite Server Logs:${NC}"
if [ "$FOLLOW" = true ]; then
    echo -e "${YELLOW}Following logs. Press Ctrl+C to exit.${NC}"
    docker logs -f $CONTAINER_NAME | grep -v "Rust server" | grep -v "Rotating logs"
else
    docker logs $CONTAINER_NAME --tail $LINES | grep -v "Rust server" | grep -v "Rotating logs"
fi

### scripts/test.sh

#!/bin/bash
set -euo pipefail

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

# Target production container
CONTAINER_NAME="logseq-spring-thing-webxr"
LOG_DIR="logs"
mkdir -p "$LOG_DIR"

# Enhanced diagnostics
check_process_status() {
    echo -e "\n${YELLOW}Checking processes inside container:${NC}"
    docker exec ${CONTAINER_NAME} ps aux || echo "Could not check processes"
    
    # Use ss instead of netstat (more commonly available)
    echo -e "\n${YELLOW}Checking listening ports inside container:${NC}"
    docker exec ${CONTAINER_NAME} ss -tulpn || echo "Could not check ports"
    
    # Check webxr process specifically
    echo -e "\n${YELLOW}Checking webxr process:${NC}"
    docker exec ${CONTAINER_NAME} pgrep -a webxr || echo "No webxr process found"
    
    # Enhanced log checking
    echo -e "\n${YELLOW}Checking Rust server logs:${NC}"
    docker exec ${CONTAINER_NAME} bash -c 'for f in /app/webxr.log /app/*.log; do if [ -f "$f" ]; then echo "=== $f ==="; tail -n 20 "$f"; fi; done' 2>/dev/null || echo "No logs found"
    # Check Nginx logs
    echo -e "\n${YELLOW}Checking Nginx Access Logs:${NC}"
    docker exec ${CONTAINER_NAME} tail -n 20 /var/log/nginx/access.log 2>/dev/null || echo "No Nginx access logs found or accessible"
    echo -e "\n${YELLOW}Checking Nginx Error Logs:${NC}"
    docker exec ${CONTAINER_NAME} tail -n 20 /var/log/nginx/error.log 2>/dev/null || echo "No Nginx error logs found or accessible"
}

test_endpoints() {
    echo -e "${YELLOW}Testing basic connectivity...${NC}"
    
    # Check container status
    echo -e "\n${YELLOW}Container Status:${NC}"
    docker ps | grep ${CONTAINER_NAME}
    
    # Check container logs with timestamp
    echo -e "\n${YELLOW}Recent Container Logs:${NC}"
    docker logs --timestamps ${CONTAINER_NAME} --tail 20

    # Check cloudflared logs
    echo -e "\n${YELLOW}Recent Cloudflared Logs:${NC}"
    if docker ps -q -f name=cloudflared-tunnel > /dev/null; then
        docker logs --timestamps cloudflared-tunnel --tail 20
    else
        echo -e "${YELLOW}Skipping cloudflared logs: container not running.${NC}"
    fi
    
    # Test root endpoint on host port
    echo -e "\n${YELLOW}Testing Root Endpoint (localhost:4000/):${NC}"
    curl -v http://localhost:4000/ 2>&1 || echo -e "${RED}Failed to connect to root endpoint on localhost:4000${NC}"

    # Test API endpoint on host port
    echo -e "\n${YELLOW}Testing API Endpoint (localhost:4000/api/settings):${NC}"
    curl -v http://localhost:4000/api/settings 2>&1 || echo -e "${RED}Failed to connect to API endpoint on localhost:4000${NC}"
    
    # Test Production Endpoint (Root)
    echo -e "\n${YELLOW}Testing Production Endpoint (Root - https://www.visionflow.info/):${NC}"
    curl -v --connect-timeout 10 https://www.visionflow.info/ 2>&1 || echo -e "${RED}Failed to connect to Production Root Endpoint${NC}"

    # Test Production Endpoint (API)
    echo -e "\n${YELLOW}Testing Production Endpoint (API - https://www.visionflow.info/api/settings):${NC}"
    curl -v --connect-timeout 10 https://www.visionflow.info/api/settings 2>&1 || echo -e "${RED}Failed to connect to Production API Endpoint${NC}"

    # Production Health endpoint test removed
    # Internal network test removed (cannot execute commands in cloudflared image easily)
    echo -e "\n${YELLOW}Skipping Internal Network Test (cannot execute commands in cloudflared image easily)${NC}"
}

check_container_health() {
    echo -e "\n${YELLOW}Container Details:${NC}"
    docker inspect ${CONTAINER_NAME} | grep -A 20 "State"
    
    # Add GPU check
    echo -e "\n${YELLOW}GPU Status:${NC}"
    docker exec ${CONTAINER_NAME} nvidia-smi || echo "Could not access GPU"
}

# Restart logic removed (this script is for testing, not management)

# Main execution
echo -e "${GREEN}Starting comprehensive diagnostics...${NC}"
test_endpoints
check_process_status
check_container_health

# Provide next steps
echo -e "\n${YELLOW}Diagnostic Summary:${NC}"
echo "1. Host Port 4000 (Root /): $(curl -s -o /dev/null -w "%{http_code}" http://localhost:4000/ 2>/dev/null || echo "Failed")"
echo "2. Host Port 4000 (API /api/settings): $(curl -s -o /dev/null -w "%{http_code}" http://localhost:4000/api/settings 2>/dev/null || echo "Failed")"
echo "3. Production Root (https://www.visionflow.info/): $(curl -s -o /dev/null -w "%{http_code}" https://www.visionflow.info/ 2>/dev/null || echo "Failed")"
echo "4. Production API (https://www.visionflow.info/api/settings): $(curl -s -o /dev/null -w "%{http_code}" https://www.visionflow.info/api/settings 2>/dev/null || echo "Failed")"
# Production Health check removed
# Internal network test summary line removed again
echo "5. Container Status: $(docker inspect --format='{{.State.Status}}' ${CONTAINER_NAME} 2>/dev/null || echo "Not Found")" # Renumber again

### scripts/generateCodebase.sh

#!/bin/bash

# Path to the export repository relative to this script
EXPORT_REPO="/mnt/mldata/githubs/export-repository-to-prompt-for-llm"

# Activate virtual environment and ensure we deactivate it even if script fails
activate_venv() {
    source "$EXPORT_REPO/venv/bin/activate"
}


# Export Docker and deployment configuration
export_docker_config() {
    # Add project metadata
    echo -e "# Project Codebase\n" >> codebase.txt
    echo -e "Generated: $(date)\n" >> codebase.txt
    echo -e "## Project Structure\n" >> codebase.txt
    echo -e "- Server: Rust (src directory)\n- Client: TypeScript (client directory)\n" >> codebase.txt

    echo -e "\n## README.md\n" >> codebase.txt
    cat ../README.md >> codebase.txt

    echo -e "\n\n## Docker Configuration\n" >> codebase.txt
    
    # Add each file with proper headers
    for file in "../docker-compose.yml" "../docker-compose.dev.yml" "../docker-compose.production.yml" \
                "../Dockerfile" "../Dockerfile.dev" "../Dockerfile.production" \
                "../nginx.conf" "../nginx.dev.conf" \
                "../data/settings.yaml" "../.dockerignore"; do
        if [ -f "$file" ]; then
            echo -e "\n### $(basename $file)\n" >> codebase.txt
            cat "$file" >> codebase.txt
        else
            echo -e "\n### $(basename $file) - MISSING\n" >> codebase.txt
        fi
    done

    # Add package management and config files
    echo -e "\n\n## Configuration Files\n" >> codebase.txt
    for file in "../Cargo.toml" "../client/package.json" "../client/vite.config.ts" "../.env.template" \
                "../tsconfig.json" "../.eslintrc" "../.gitignore" \
                "../client/tsconfig.json"; do
        if [ -f "$file" ]; then
            echo -e "\n### $(basename $file)\n" >> codebase.txt
            cat "$file" >> codebase.txt
        else
            echo -e "\n### $(basename $file) - MISSING\n" >> codebase.txt
        fi
    done

    # Export docker directory if it exists
    if [ -d "../docker" ]; then
        echo -e "\n\n## Docker Directory Contents\n" >> codebase.txt
        for file in ../docker/*; do
            if [ -f "$file" ]; then
                echo -e "\n### docker/$(basename $file)\n" >> codebase.txt
                cat "$file" >> codebase.txt
            fi
        done
    fi

    echo -e "\n\n## Important Scripts\n" >> codebase.txt
    for script_file in "../scripts/dev-entrypoint.sh" "../scripts/dev.sh" \
                       "../scripts/launch-production.sh" "../scripts/start.sh" \
                       "../scripts/compile_ptx.sh" "../scripts/diagnostics.sh" \
                       "../scripts/check-rust-logs.sh" "../scripts/check-vite.sh" \
                       "../scripts/test.sh" "../scripts/generateCodebase.sh"; do
        if [ -f "$script_file" ]; then
            echo -e "\n### scripts/$(basename $script_file)\n" >> codebase.txt
            cat "$script_file" >> codebase.txt
        else
            echo -e "\n### scripts/$(basename $script_file) - MISSING\n" >> codebase.txt
        fi
    done

    # Vite environment files (example, adjust if actual files differ)
    echo -e "\n\n## Vite Environment Configuration\n" >> codebase.txt
    # Add client .env files if they exist and are relevant (usually gitignored)
    # For now, we'll just note that vite.config.ts and .env.template are captured.
    # If specific .env files like .env.development or .env.production exist at client root, add them.
    echo -e "Vite configuration is primarily in 'client/vite.config.ts' (captured above)." >> codebase.txt
    echo -e "Environment variable templates are in '.env.template' (captured above)." >> codebase.txt
    # Example for specific vite env files if they were used:
    # for vite_env_file in "../client/.env.development" "../client/.env.production"; do
    #     if [ -f "$vite_env_file" ]; then
    #         echo -e "\n### client/$(basename $vite_env_file)\n" >> codebase.txt
    #         cat "$vite_env_file" >> codebase.txt
    #     else
    #         echo -e "\n### client/$(basename $vite_env_file) - MISSING (or not applicable)\n" >> codebase.txt
    #     fi
    # done

}

# Export Docker network information
export_network_info() {
    echo -e "\n\n=== Docker Network Configuration ===\n" >> codebase.txt
    echo -e "\n--- docker network inspect docker_ragflow ---\n" >> codebase.txt
    docker network inspect docker_ragflow >> codebase.txt 2>/dev/null || echo "Unable to fetch network info - docker daemon not running or network doesn't exist" >> codebase.txt
}

# Export both directories and combine them
export_and_combine() {
    # Export server (src) code
    python "$EXPORT_REPO/export-repository-to-file.py" "../src"
    mv output.txt server.txt

    # Export client code
    python "$EXPORT_REPO/export-repository-to-file.py" "../client"
    mv output.txt client.txt

    # Export docs code
    python "$EXPORT_REPO/export-repository-to-file.py" "../docs"
    mv output.txt docs.txt

    # Combine files with clear separation
    echo -e "\n\n## Server Code (Rust)\n" >> codebase.txt
    cat server.txt >> codebase.txt
    
    echo -e "\n\n## Client Code (TypeScript)\n" >> codebase.txt
    cat client.txt >> codebase.txt
    
    echo -e "\n\n## Documentation\n" >> codebase.txt
    cat docs.txt >> codebase.txt
    
    rm server.txt
    rm client.txt
    rm docs.txt
}

# Add project structure information
export_project_structure() {
    echo -e "\n## Project Structure Tree\n" >> codebase.txt
    echo -e "\`\`\`" >> codebase.txt
    # Show root level files
    echo "Root files:" >> codebase.txt
    ls -p ../ | grep -v / >> codebase.txt
    echo -e "\nDirectories:" >> codebase.txt
    # Show client, src, and docs directories structure
    tree -I 'node_modules|target|dist|.git|venv' ../client ../src ../docs >> codebase.txt
    echo -e "\`\`\`\n" >> codebase.txt
}

# Main execution
if [ ! -d "$EXPORT_REPO" ]; then
    echo "Error: Export repository not found at $EXPORT_REPO"
    exit 1
fi

if [ ! -d "$EXPORT_REPO/venv" ]; then
    echo "Error: Virtual environment not found at $EXPORT_REPO/venv"
    exit 1
fi

# Execute the export process
activate_venv

# Add Docker configuration and network info
export_project_structure
export_docker_config
export_network_info

export_and_combine
deactivate



echo "Successfully generated codebase.txt with Docker configuration and network info"


## Vite Environment Configuration

Vite configuration is primarily in 'client/vite.config.ts' (captured above).
Environment variable templates are in '.env.template' (captured above).


=== Docker Network Configuration ===


--- docker network inspect docker_ragflow ---

[
    {
        "Name": "docker_ragflow",
        "Id": "b0c38a1301451c0329969ef53fdedde5221b1b05b063ad94d66017a45d3ddaa3",
        "Created": "2025-04-05T14:36:31.500965678Z",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv4": true,
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
                {
                    "Subnet": "172.18.0.0/16",
                    "Gateway": "172.18.0.1"
                }
            ]
        },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
        },
        "ConfigOnly": false,
        "Containers": {
            "0ee1e0c4711fb2c8e7510fad22b1c0ecfcbb12d2d98bdded338b877e73cc493e": {
                "Name": "ragflow-es-01",
                "EndpointID": "fb15464ae3e1aed7fece2a1ba7ade0a8c62eee7b09a6a16a4f43d1aeab2b5ba3",
                "MacAddress": "76:91:00:ac:bf:3e",
                "IPv4Address": "172.18.0.3/16",
                "IPv6Address": ""
            },
            "20a9aca36ed7b47cf9e095c04f478fd11e3609fe99263e62bd02f2527b6e7854": {
                "Name": "ragflow-redis",
                "EndpointID": "a22884eaf2e221456233848c75fd8b7cfc757f993157703d14c1f664b8915cd5",
                "MacAddress": "ea:c9:4d:07:42:32",
                "IPv4Address": "172.18.0.2/16",
                "IPv6Address": ""
            },
            "45661ac3f1e9c7db1716112564332a4d7b1974e0ab6c726d182ba39645146409": {
                "Name": "ragflow-minio",
                "EndpointID": "9ec70994dfdb9bb33f2931bf9927588ef5a1b5b40545ca7f0898b41fb63a71d2",
                "MacAddress": "f2:47:39:c6:3d:e3",
                "IPv4Address": "172.18.0.5/16",
                "IPv6Address": ""
            },
            "72c5945d3c295de8190942b0496a77972309312a606d95653c405067ff3c8a25": {
                "Name": "ragflow-server",
                "EndpointID": "1bfa655864aa0f130561774140832ea22ec0ab9a4f0e7bf0a700494e6f45d024",
                "MacAddress": "f2:aa:ff:83:9e:ad",
                "IPv4Address": "172.18.0.7/16",
                "IPv6Address": ""
            },
            "72f633088af185fe100176017bb6617949aa276318ec281606fda86bc295bdc4": {
                "Name": "logseq_spring_thing_webxr",
                "EndpointID": "dd15ba74cf432daffd936f27975df514ed5e135bfe8fa5f12decd052393e6c55",
                "MacAddress": "c2:72:b5:17:ba:bd",
                "IPv4Address": "172.18.0.12/16",
                "IPv6Address": ""
            },
            "7383a98e5d170d817bdf2ead6a0998f848918d6a3e556207199e58d7762a1365": {
                "Name": "xinference",
                "EndpointID": "7069410d9a5ea5cad435be24f5bf2e9ef60ae004d2d99c4bfbc3cf6a2ade4b4e",
                "MacAddress": "6a:a5:e1:68:dc:4e",
                "IPv4Address": "172.18.0.11/16",
                "IPv6Address": ""
            },
            "858c8d3e47bbbe93c36f2090d591c3282596cde09e9a7c0945c5e8ea4c41fb29": {
                "Name": "ragflow-mysql",
                "EndpointID": "4c80ee8f0a620164047b30975e2bcf530a62fbdcb5aad9aac3bec1358f9e8c91",
                "MacAddress": "a2:15:bf:08:4f:39",
                "IPv4Address": "172.18.0.6/16",
                "IPv6Address": ""
            },
            "ad1da00366274c912323b431b5e4b075c88fddb28b6e24c1d27fa0a12c7b4e35": {
                "Name": "whisper-webui",
                "EndpointID": "ca10f354145d3263e5896f9243044892da031484201cc17070b10f45b602f77e",
                "MacAddress": "7e:eb:aa:7e:dd:cd",
                "IPv4Address": "172.18.0.10/16",
                "IPv6Address": ""
            },
            "b71da5779f19daa32c2bf5f3f6583e642ee80a45cfffc97caaca740632b6da7b": {
                "Name": "open-webui",
                "EndpointID": "0fcf91b0ed24a4cef7007660bb550f37aeb23a06a700650becad05b62374d2c1",
                "MacAddress": "86:55:60:7e:62:c1",
                "IPv4Address": "172.18.0.9/16",
                "IPv6Address": ""
            },
            "ee48ae53212bac56639e23c906606c713239b2a6ee57d08a9546ceb08457a87c": {
                "Name": "practical_cori",
                "EndpointID": "5a72c118bdda2da960a6b3d9da4ffb1321acade5adab15c5b5f943445f9d49d1",
                "MacAddress": "32:a4:1d:e2:67:db",
                "IPv4Address": "172.18.0.8/16",
                "IPv6Address": ""
            },
            "f8fa3cfa39aae7876230a8018fde3fc07de5ed2b4d51bfb68da8e963e7a8ddca": {
                "Name": "ollama",
                "EndpointID": "c0718fbf18e60ac6158d7f8e009c3f55e79267ff9f11888df104a9242545f9ec",
                "MacAddress": "4a:c1:b9:21:6f:45",
                "IPv4Address": "172.18.0.4/16",
                "IPv6Address": ""
            }
        },
        "Options": {},
        "Labels": {
            "com.docker.compose.config-hash": "20de4b714cebc3288cab9ac5bf17cbed67f64545e9b273c2e547d4a6538609b9",
            "com.docker.compose.network": "ragflow",
            "com.docker.compose.project": "docker",
            "com.docker.compose.version": "2.34.0"
        }
    }
]


## Server Code (Rust)

The following text represents a project with code. The structure of the text consists of sections beginning with ----, followed by a single line containing the file path and file name, and then a variable number of lines containing the file contents. The text representing the project ends when the symbols --END-- are encountered. Any further text beyond --END-- is meant to be interpreted as instructions using the aforementioned project as context.
----
main.rs
use webxr::services::nostr_service::NostrService;
use webxr::{
    AppState,
    config::AppFullSettings, // Import AppFullSettings only
    handlers::{
        api_handler,
        health_handler,
        pages_handler,
        socket_flow_handler::{socket_flow_handler, PreReadSocketSettings}, // Import PreReadSocketSettings
        speech_socket_handler::speech_socket_handler,
        nostr_handler,
    },
    services::{
        file_service::FileService,
        graph_service::GraphService,
        github::{GitHubClient, ContentAPI, GitHubConfig},
    },
    utils::gpu_compute::GPUCompute,
    services::speech_service::SpeechService,
};

use actix_web::{web, App, HttpServer, middleware};
use actix_cors::Cors;
// use actix_files::Files; // Removed unused import
use std::sync::Arc;
use tokio::sync::RwLock;
use tokio::time::Duration;
use dotenvy::dotenv;
use log::{error, info, debug, warn};
use webxr::utils::logging::{init_logging_with_config, LogConfig};
use tokio::signal::unix::{signal, SignalKind};

#[actix_web::main]
async fn main() -> std::io::Result<()> {
    // Make dotenv optional since env vars can come from Docker
    dotenv().ok();

    // Load settings first to get the log level
    // Use AppFullSettings here as this is the main server configuration loaded from YAML/Env
    let settings = match AppFullSettings::new() { // Changed to AppFullSettings::new()
        Ok(s) => {
            info!("AppFullSettings loaded successfully from: {}", 
                std::env::var("SETTINGS_FILE_PATH").unwrap_or_else(|_| "/app/settings.yaml".to_string()));
            Arc::new(RwLock::new(s)) // Now holds Arc<RwLock<AppFullSettings>>
        },
        Err(e) => {
            error!("Failed to load AppFullSettings: {:?}", e);
            // Try loading the client-facing Settings as a fallback for debugging? Unlikely to work.
            // error!("Attempting fallback load of client-facing Settings struct...");
            // match ClientFacingSettings::new() { // This ::new doesn't exist on client Settings
            //     Ok(_) => error!("Fallback load seemed to work structurally, but AppState expects AppFullSettings!"),
            //     Err(fe) => error!("Fallback load also failed: {:?}", fe),
            // }
            return Err(std::io::Error::new(std::io::ErrorKind::Other, format!("Failed to initialize AppFullSettings: {:?}", e)));
        }
    };

    // --- BEGIN GPU TEST BEFORE LOGGING ---
    println!("[PRE-LOGGING CHECK] Starting GPU detection test before logging is initialized");
    tokio::time::sleep(Duration::from_millis(1000)).await;
    
    match webxr::utils::gpu_compute::GPUCompute::test_gpu().await {
        Ok(_) => println!("[PRE-LOGGING CHECK] GPU test successful."),
        Err(e) => {
            eprintln!("[PRE-LOGGING CHECK] GPU test failed: {}", e);
            eprintln!("[PRE-LOGGING CHECK] Will retry once with additional delay");
            tokio::time::sleep(Duration::from_millis(2000)).await;
            
            match webxr::utils::gpu_compute::GPUCompute::test_gpu().await {
                Ok(_) => println!("[PRE-LOGGING CHECK] GPU test successful on retry!"),
                Err(e) => eprintln!("[PRE-LOGGING CHECK] GPU test failed on retry: {}", e),
            }
        }
    }
    // --- END GPU TEST BEFORE LOGGING ---


    // Initialize logging with settings-based configuration
    let log_config = {
        let settings_read = settings.read().await; // Reads AppFullSettings
        // Access log level correctly from AppFullSettings structure
        let log_level = &settings_read.system.debug.log_level; 
        
        LogConfig::new(
            log_level,
            log_level, // Assuming same level for app and deps for now
        )
    };

    init_logging_with_config(log_config)?;

    debug!("Successfully loaded AppFullSettings"); // Updated log message

    info!("Starting WebXR application...");
    
    // Create web::Data instances first
    // This now holds Data<Arc<RwLock<AppFullSettings>>>
    let settings_data = web::Data::new(settings.clone()); 

    // Initialize services
    let github_config = match GitHubConfig::from_env() {
        Ok(config) => config,
        Err(e) => return Err(std::io::Error::new(std::io::ErrorKind::Other, format!("Failed to load GitHub config: {}", e)))
    };

    // GitHubClient::new might need adjustment if it expects client-facing Settings
    // Assuming it can work with AppFullSettings for now.
    let github_client = match GitHubClient::new(github_config, settings.clone()).await {
        Ok(client) => Arc::new(client),
        Err(e) => return Err(std::io::Error::new(std::io::ErrorKind::Other, format!("Failed to initialize GitHub client: {}", e)))
    };

    let content_api = Arc::new(ContentAPI::new(github_client.clone()));

    // Initialize speech service
    // SpeechService::new might need adjustment if it expects client-facing Settings
    let speech_service = {
        let service = SpeechService::new(settings.clone());
        Some(Arc::new(service))
    };
    
    // Initialize app state asynchronously
    // AppState::new now correctly receives Arc<RwLock<AppFullSettings>>
    let mut app_state = match AppState::new(
            settings.clone(),
            github_client.clone(),
            content_api.clone(),
            None, // Perplexity placeholder
            None, // RAGFlow placeholder
            speech_service,
            None, // GPU Compute placeholder
            "default_session".to_string() // RAGFlow session ID placeholder
        ).await {
            Ok(state) => state,
            Err(e) => return Err(std::io::Error::new(std::io::ErrorKind::Other, format!("Failed to initialize app state: {}", e)))
        };

    // Initialize Nostr service
    nostr_handler::init_nostr_service(&mut app_state);

    // First, try to load existing metadata without waiting for GitHub download
    info!("Loading existing metadata for quick initialization");
    let metadata_store = FileService::load_or_create_metadata()
        .map_err(|e| {
            error!("Failed to load existing metadata: {}", e);
            std::io::Error::new(std::io::ErrorKind::Other, e.to_string())
        })?;

    info!("Note: Background GitHub data fetch is disabled to resolve compilation issues");

    if metadata_store.is_empty() {
        error!("No metadata found and could not create empty store");
        return Err(std::io::Error::new(std::io::ErrorKind::Other, 
            "No metadata found and could not create empty store".to_string()));
    }

    info!("Loaded {} items from metadata store", metadata_store.len());

    // Update metadata in app state
    {
        let mut app_metadata = app_state.metadata.write().await;
        *app_metadata = metadata_store.clone();
        info!("Loaded metadata into app state");
    }

    // Build initial graph from metadata and initialize GPU compute
    info!("Building initial graph from existing metadata for physics simulation");
    
    let client_manager = app_state.ensure_client_manager().await;
    
    match GraphService::build_graph_from_metadata(&metadata_store).await {
        Ok(graph_data) => {            
            if app_state.gpu_compute.is_none() {
                info!("No GPU compute instance found, initializing one now");
                match GPUCompute::new(&graph_data).await {
                    Ok(gpu_instance) => {
                        info!("GPU compute initialized successfully");
                        app_state.gpu_compute = Some(gpu_instance);
                        
                        info!("Shutting down existing graph service before reinitializing with GPU");
                        let shutdown_start = std::time::Instant::now();
                        
                        match tokio::time::timeout(Duration::from_secs(5), app_state.graph_service.shutdown()).await {
                            Ok(_) => info!("Graph service shutdown completed successfully in {:?}", shutdown_start.elapsed()),
                            Err(_) => {
                                warn!("Graph service shutdown timed out after 5 seconds");
                                warn!("Proceeding with reinitialization anyway - old simulation loop will self-terminate");
                            }
                        }
                        
                        tokio::time::sleep(Duration::from_millis(100)).await;
                        
                        info!("Reinitializing graph service with GPU compute");
                        // GraphService::new receives Arc<RwLock<AppFullSettings>>
                        app_state.graph_service = GraphService::new(
                            settings.clone(),
                            app_state.gpu_compute.clone(),
                            client_manager.clone() // Pass client manager
                        ).await;
                        
                        info!("Graph service successfully reinitialized with GPU compute");
                    },
                    Err(e) => {
                        warn!("Failed to initialize GPU compute: {}. Continuing with CPU fallback.", e);
                        
                        let shutdown_start = std::time::Instant::now();
                        match tokio::time::timeout(Duration::from_secs(5), app_state.graph_service.shutdown()).await {
                            Ok(_) => info!("Graph service shutdown completed successfully in {:?}", shutdown_start.elapsed()),
                            Err(_) => {
                                warn!("Graph service shutdown timed out after 5 seconds");
                                warn!("Proceeding with reinitialization anyway - old simulation loop will self-terminate");
                            }
                        }
                        
                        // Reinitialize graph service with None as GPU compute
                        app_state.graph_service = GraphService::new(
                            settings.clone(),
                            None,
                            client_manager.clone() // Pass client manager
                        ).await;
                        
                        info!("Graph service initialized with CPU fallback");
                    }
                }
            }

            // Update graph data after GPU is initialized (or CPU fallback)
            let mut graph = app_state.graph_service.get_graph_data_mut().await;
            let mut node_map = app_state.graph_service.get_node_map_mut().await;
            *graph = graph_data;
            
            node_map.clear();
            for node in &graph.nodes {
                node_map.insert(node.id.clone(), node.clone());
            }
            
            drop(graph);
            drop(node_map);

            info!("Built initial graph from metadata");
            
        },
        Err(e) => {
            error!("Failed to build initial graph: {}", e);
            return Err(std::io::Error::new(std::io::ErrorKind::Other, format!("Failed to build initial graph: {}", e)));
        }
    }

    info!("Waiting for initial physics layout calculation to complete...");
    tokio::time::sleep(Duration::from_millis(500)).await;
    info!("Initial delay complete. Starting HTTP server...");
    
    app_state.graph_service.start_broadcast_loop(client_manager.clone());
    info!("Position broadcast loop started");
 
    // Create web::Data after all initialization is complete
    let app_state_data = web::Data::new(app_state);

    // Start the server
    let bind_address = {
        let settings_read = settings.read().await; // Reads AppFullSettings
        // Access network settings correctly
        format!("{}:{}", settings_read.system.network.bind_address, settings_read.system.network.port)
    };

    // Pre-read WebSocket settings for SocketFlowServer
    let pre_read_ws_settings = {
        let s = settings.read().await;
        PreReadSocketSettings {
            min_update_rate: s.system.websocket.min_update_rate,
            max_update_rate: s.system.websocket.max_update_rate,
            motion_threshold: s.system.websocket.motion_threshold,
            motion_damping: s.system.websocket.motion_damping,
            compression_enabled: s.system.websocket.compression_enabled,
            compression_threshold: s.system.websocket.compression_threshold,
            heartbeat_interval_ms: s.system.websocket.heartbeat_interval, // Assuming these exist
            heartbeat_timeout_ms: s.system.websocket.heartbeat_timeout,   // Assuming these exist
        }
    };
    let pre_read_ws_settings_data = web::Data::new(pre_read_ws_settings);

    info!("Starting HTTP server on {}", bind_address);

    let server = HttpServer::new(move || {
        let cors = Cors::default()
            .allow_any_origin()
            .allow_any_method()
            .allow_any_header()
            .max_age(3600)
            .supports_credentials();

        let mut app = App::new()
            .wrap(middleware::Logger::default())
            .wrap(cors)
            .wrap(middleware::Compress::default())
            // Pass AppFullSettings wrapped in Data
            .app_data(settings_data.clone())
            .app_data(web::Data::new(github_client.clone()))
            .app_data(web::Data::new(content_api.clone()))
            .app_data(app_state_data.clone()) // Add the complete AppState
            .app_data(pre_read_ws_settings_data.clone()) // Add pre-read WebSocket settings
            .app_data(app_state_data.nostr_service.clone().unwrap_or_else(|| web::Data::new(NostrService::default()))) // Provide default if None
            .app_data(app_state_data.feature_access.clone())
            .route("/wss", web::get().to(socket_flow_handler)) // Changed from /ws to /wss
            .route("/speech", web::get().to(speech_socket_handler))
            .service(
                web::scope("")
                    .configure(api_handler::config)
                    .service(web::scope("/health").configure(health_handler::config))
                    .service(web::scope("/pages").configure(pages_handler::config))
            );
        
        app
    })
    .bind(&bind_address)?
    .run();

    let server_handle = server.handle();

    // Set up signal handlers
    let mut sigterm = signal(SignalKind::terminate())?;
    let mut sigint = signal(SignalKind::interrupt())?;

    tokio::spawn(async move {
        tokio::select! {
            _ = sigterm.recv() => {
                info!("Received SIGTERM signal");
            }
            _ = sigint.recv() => {
                info!("Received SIGINT signal");
            }
        }
        info!("Initiating graceful shutdown");
        server_handle.stop(true).await;
    });

    server.await?;

    info!("HTTP server stopped");
    Ok(())
}

----
app_state.rs
use std::sync::{Arc, atomic::{AtomicUsize, Ordering}};
use tokio::sync::RwLock;
use actix_web::web;
use log::info;

use crate::handlers::socket_flow_handler::ClientManager;
use crate::config::AppFullSettings; // Renamed for clarity, ClientFacingSettings removed
use tokio::time::Duration;
use crate::config::feature_access::FeatureAccess;
use crate::models::metadata::MetadataStore;
use crate::models::protected_settings::{ProtectedSettings, ApiKeys, NostrUser};
use crate::services::graph_service::GraphService;
use crate::services::github::{GitHubClient, ContentAPI};
use crate::services::perplexity_service::PerplexityService;
use crate::services::speech_service::SpeechService;
use crate::services::ragflow_service::RAGFlowService;
use crate::services::nostr_service::NostrService;
use crate::utils::gpu_compute::GPUCompute;
use once_cell::sync::Lazy;

#[derive(Clone)]
pub struct AppState {
    pub graph_service: GraphService,
    pub gpu_compute: Option<Arc<RwLock<GPUCompute>>>,
    pub settings: Arc<RwLock<AppFullSettings>>, // Changed to AppFullSettings
    pub protected_settings: Arc<RwLock<ProtectedSettings>>,
    pub metadata: Arc<RwLock<MetadataStore>>,
    pub github_client: Arc<GitHubClient>,
    pub content_api: Arc<ContentAPI>,
    pub perplexity_service: Option<Arc<PerplexityService>>,
    pub ragflow_service: Option<Arc<RAGFlowService>>,
    pub speech_service: Option<Arc<SpeechService>>,
    pub nostr_service: Option<web::Data<NostrService>>,
    pub feature_access: web::Data<FeatureAccess>,
    pub ragflow_session_id: String,
    pub active_connections: Arc<AtomicUsize>,
    // pub client_manager: Option<Arc<ClientManager>>, // Removed, use ensure_client_manager
}

static APP_CLIENT_MANAGER: Lazy<Arc<ClientManager>> =
    Lazy::new(|| Arc::new(ClientManager::new()));

impl AppState {
    pub async fn new(
        settings: Arc<RwLock<AppFullSettings>>, // Changed to AppFullSettings
        github_client: Arc<GitHubClient>,
        content_api: Arc<ContentAPI>,
        perplexity_service: Option<Arc<PerplexityService>>,
        ragflow_service: Option<Arc<RAGFlowService>>,
        speech_service: Option<Arc<SpeechService>>,
        gpu_compute: Option<Arc<RwLock<GPUCompute>>>,
        ragflow_session_id: String,
    ) -> Result<Self, Box<dyn std::error::Error + Send + Sync>> {
        info!("[AppState::new] Initializing GraphService");
        tokio::time::sleep(Duration::from_millis(50)).await;
        
        // GraphService::new might need adjustment if it expects client-facing Settings
        // For now, passing AppFullSettings. This will likely require GraphService changes.
        let graph_service = GraphService::new(settings.clone(), gpu_compute.clone(), APP_CLIENT_MANAGER.clone()).await;
        info!("[AppState::new] GraphService initialization complete");
        
        Ok(Self {
            graph_service,
            gpu_compute,
            settings, // Storing AppFullSettings
            protected_settings: Arc::new(RwLock::new(ProtectedSettings::default())),
            metadata: Arc::new(RwLock::new(MetadataStore::new())),
            github_client,
            content_api,
            perplexity_service,
            ragflow_service,
            speech_service,
            nostr_service: None,
            feature_access: web::Data::new(FeatureAccess::from_env()),
            ragflow_session_id,
            active_connections: Arc::new(AtomicUsize::new(0)),
            // client_manager: Some(APP_CLIENT_MANAGER.clone()), // Removed
        })
    }

    pub fn increment_connections(&self) -> usize {
        self.active_connections.fetch_add(1, Ordering::SeqCst)
    }

    pub fn decrement_connections(&self) -> usize {
        self.active_connections.fetch_sub(1, Ordering::SeqCst)
    }

    pub async fn get_api_keys(&self, pubkey: &str) -> ApiKeys {
        let protected_settings = self.protected_settings.read().await;
        protected_settings.get_api_keys(pubkey)
    }

    pub async fn get_nostr_user(&self, pubkey: &str) -> Option<NostrUser> {
        if let Some(nostr_service) = &self.nostr_service {
            nostr_service.get_user(pubkey).await
        } else {
            None
        }
    }

    pub async fn validate_nostr_session(&self, pubkey: &str, token: &str) -> bool {
        if let Some(nostr_service) = &self.nostr_service {
            nostr_service.validate_session(pubkey, token).await
        } else {
            false
        }
    }

    pub async fn update_nostr_user_api_keys(&self, pubkey: &str, api_keys: ApiKeys) -> Result<NostrUser, String> {
        if let Some(nostr_service) = &self.nostr_service {
            nostr_service.update_user_api_keys(pubkey, api_keys)
                .await
                .map_err(|e| e.to_string())
        } else {
            Err("Nostr service not initialized".to_string())
        }
    }

    pub fn set_nostr_service(&mut self, service: NostrService) {
        self.nostr_service = Some(web::Data::new(service));
    }

    pub fn is_power_user(&self, pubkey: &str) -> bool {
        self.feature_access.is_power_user(pubkey)
    }

    pub fn can_sync_settings(&self, pubkey: &str) -> bool {
        self.feature_access.can_sync_settings(pubkey)
    }

    pub fn has_feature_access(&self, pubkey: &str, feature: &str) -> bool {
        self.feature_access.has_feature_access(pubkey, feature)
    }

    pub fn get_available_features(&self, pubkey: &str) -> Vec<String> {
        self.feature_access.get_available_features(pubkey)
    }
    
    pub async fn ensure_client_manager(&self) -> Arc<ClientManager> {
        APP_CLIENT_MANAGER.clone()
    }
}

----
state.rs
use std::sync::Arc;
use tokio::sync::RwLock;
use crate::config::Settings;

#[derive(Debug)]  // Only Debug derive, remove Clone
pub struct AppState {
    pub settings: Arc<RwLock<Settings>>,
}

impl AppState {
    pub fn new(settings: Settings) -> Self {
        Self {
            settings: Arc::new(RwLock::new(settings)),
        }
    }

    pub fn clone_settings(&self) -> Arc<RwLock<Settings>> {
        self.settings.clone()
    }
} 
----
lib.rs
pub mod app_state;
pub mod config;
pub mod handlers;
pub mod models;
pub mod services;
pub mod types;
pub mod utils;

pub use app_state::AppState;
pub use models::metadata::MetadataStore;
pub use models::protected_settings::ProtectedSettings;
pub use models::simulation_params::SimulationParams;
pub use models::ui_settings::UISettings;
pub use models::user_settings::UserSettings;

----
utils/logging.rs
use log::LevelFilter;
use log::info;
use simplelog::{CombinedLogger, Config, TermLogger, TerminalMode, WriteLogger};
use std::fs::File;
use std::io;

#[derive(Debug)]
pub struct LogConfig {
    file_level: LevelFilter,
    console_level: LevelFilter,
}

impl Default for LogConfig {
    fn default() -> Self {
        Self {
            file_level: LevelFilter::Debug,
            console_level: LevelFilter::Info,
        }
    }
}

impl LogConfig {
    pub fn new(file_level: &str, console_level: &str) -> Self {
        Self {
            file_level: match file_level {
                "trace" => LevelFilter::Trace,
                "debug" => LevelFilter::Debug,
                "info" => LevelFilter::Info,
                "warn" => LevelFilter::Warn,
                "error" => LevelFilter::Error,
                _ => LevelFilter::Info,
            },
            console_level: match console_level {
                "trace" => LevelFilter::Trace,
                "debug" => LevelFilter::Debug,
                "info" => LevelFilter::Info,
                "warn" => LevelFilter::Warn,
                "error" => LevelFilter::Error,
                _ => LevelFilter::Info,
            },
        }
    }
}

pub fn init_logging_with_config(config: LogConfig) -> io::Result<()> {
    let log_file = File::create("/tmp/webxr.log")?;
    
    CombinedLogger::init(vec![
        TermLogger::new(
            config.console_level,
            Config::default(),
            TerminalMode::Mixed,
            simplelog::ColorChoice::Auto,
        ),
        WriteLogger::new(
            config.file_level,
            Config::default(),
            log_file,
        ),
    ]).map_err(|e| io::Error::new(io::ErrorKind::Other, e))?;

    info!("Logging initialized with level file:{:?} console:{:?}", 
          config.file_level, config.console_level);
    Ok(())
}

pub fn init_logging() -> io::Result<()> {
    init_logging_with_config(LogConfig::default())
} 
----
utils/compute_forces.cu
#include <cuda_runtime.h>

extern "C" {
    // Vec3Data struct definition to match Rust's Vec3Data
    struct Vec3Data {
        float x;    // 4 bytes
        float y;    // 4 bytes
        float z;    // 4 bytes
    };

    // Updated BinaryNodeData struct to match Rust's memory layout
    // Previous version used arrays which caused memory layout mismatches
    struct BinaryNodeData {
        // Now using Vec3Data structs instead of arrays to match Rust memory layout
        Vec3Data position;    // 12 bytes - matches Rust Vec3Data struct
        Vec3Data velocity;    // 12 bytes - matches Rust Vec3Data struct
        
        // These fields remain unchanged and are still
        // used internally but not transmitted over the wire
        // The binary_protocol.rs still sets default values when decoding
        
        unsigned char mass;   // 1 byte  - matches Rust u8
        unsigned char flags;  // 1 byte  - matches Rust u8
        unsigned char padding[2]; // 2 bytes - matches Rust padding
    };

    __global__ void compute_forces_kernel(
        BinaryNodeData* nodes,
        int num_nodes,
        float spring_k,
        float damping,
        float repel_k,
        float dt,
        float max_repulsion_dist,
        float viewport_bounds,
        int iteration_count
    ) {
        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= num_nodes) return;

        const float MAX_FORCE = 3.0f; // Reduced maximum force magnitude
        const float MAX_VELOCITY = 0.02f; // Stricter velocity cap to prevent momentum buildup
        const float MIN_DISTANCE = 0.15f; // Slightly increased minimum distance
        
        // Progressive force application parameters
        // First 100 iterations use a ramp-up factor
        const int WARMUP_ITERATIONS = 100;
        float ramp_up_factor = 1.0f;
        
        if (iteration_count < WARMUP_ITERATIONS) {
            // Gradually increase from 0.01 to 1.0 over WARMUP_ITERATIONS
            ramp_up_factor = 0.01f + (iteration_count / (float)WARMUP_ITERATIONS) * 0.99f;
            
            // Also use higher damping in initial iterations to stabilize the system
            damping = fmaxf(damping, 0.9f - 0.4f * (iteration_count / (float)WARMUP_ITERATIONS));
        }
        
        float3 total_force = make_float3(0.0f, 0.0f, 0.0f);
        float3 pos = make_float3(nodes[idx].position.x, nodes[idx].position.y, nodes[idx].position.z);
        float3 vel = make_float3(nodes[idx].velocity.x, nodes[idx].velocity.y, nodes[idx].velocity.z);

        // Zero out velocity in the very first iterations to prevent explosion
        if (iteration_count < 5) {
            vel = make_float3(0.0f, 0.0f, 0.0f);
        }
        
        // Convert mass from u8 to float (approximately 0-1 range)
        float mass;
        if (nodes[idx].mass == 0) {
            mass = 0.5f; // Default mid-range mass value
        } else {
            mass = (nodes[idx].mass + 1.0f) / 256.0f; // Add 1 to avoid zero mass
        }
        
        bool is_active = true; // All nodes are active by default
        
        if (!is_active) return; // Skip inactive nodes
        
        // Process all node interactions
        for (int j = 0; j < num_nodes; j++) {
            if (j == idx) continue;
            
            // All nodes are considered active by default
            // We no longer check the flags since all nodes are treated as active
            
            // Handle other node's mass the same way
            float other_mass = (nodes[j].mass == 0) ? 0.5f : (nodes[j].mass + 1.0f) / 256.0f;
            
            float3 other_pos = make_float3(
                nodes[j].position.x,
                nodes[j].position.y,
                nodes[j].position.z
            );
            
            float3 diff = make_float3(
                other_pos.x - pos.x,
                other_pos.y - pos.y,
                other_pos.z - pos.z
            );
            
            float dist = sqrtf(diff.x * diff.x + diff.y * diff.y + diff.z * diff.z);
            // Only process if nodes are at a meaningful distance apart
            if (dist > MIN_DISTANCE) {
                float3 dir = make_float3(
                    diff.x / dist,
                    diff.y / dist,
                    diff.z / dist
                );
                
                // Apply spring forces to all nodes by default
                {
                    // Use natural length of 1.0 to match world units
                    float natural_length = 1.0f;
                    
                    // Progressive spring forces - stronger when further apart
                    // Apply the ramp_up_factor to gradually increase spring forces
                    float spring_force = -spring_k * ramp_up_factor * (dist - natural_length);
                    
                    // Apply progressively stronger springs for very distant nodes
                    if (dist > natural_length * 3.0f) {
                        spring_force *= (1.0f + (dist - natural_length * 3.0f) * 0.1f);
                    }
                    
                    
                    float spring_scale = mass * other_mass;
                    float force_magnitude = spring_force * spring_scale;
                    
                    // Repulsion forces - only apply at close distances
                    if (dist < max_repulsion_dist) {
                        float repel_scale = repel_k * mass * other_mass;
                        // Apply the ramp_up_factor to gradually increase repulsion forces
                        float dist_sq = fmaxf(dist * dist, MIN_DISTANCE);
                        // Cap maximum repulsion force to prevent explosion
                        float repel_force = fminf(repel_scale / dist_sq, repel_scale * 2.0f);
                        total_force.x -= dir.x * repel_force;
                        total_force.y -= dir.y * repel_force;
                        total_force.z -= dir.z * repel_force;
                    } else {
                        // Always apply spring forces
                        // We use -= because spring_force is negative for attraction
                        total_force.x -= dir.x * force_magnitude;
                        total_force.y -= dir.y * force_magnitude;
                        total_force.z -= dir.z * force_magnitude;
                    }
                }
            }
        }
        
        // Stronger center gravity to prevent nodes from drifting too far
        float center_strength = 0.015f * mass * ramp_up_factor; // Apply ramp_up to center gravity too
        float center_dist = sqrtf(pos.x*pos.x + pos.y*pos.y + pos.z*pos.z);
        if (center_dist > 3.0f) { // Apply at shorter distances
            float center_factor = center_strength * (center_dist - 3.0f) / center_dist;
            total_force.x -= pos.x * center_factor;
            total_force.y -= pos.y * center_factor;
            total_force.z -= pos.z * center_factor;
        }

        // Calculate total force magnitude
        float force_magnitude = sqrtf(
            total_force.x*total_force.x + 
            total_force.y*total_force.y + 
            total_force.z*total_force.z);
        
        // Scale down excessive forces to prevent explosion
        if (force_magnitude > MAX_FORCE) {
            float scale_factor = MAX_FORCE / force_magnitude;
            total_force.x *= scale_factor;
            total_force.y *= scale_factor;
            total_force.z *= scale_factor;
            
            // Additional logging to help debug extreme forces after randomization
            if (idx == 0 && iteration_count < 5)
                printf("Force clamped from %f to %f (iteration %d)\n", force_magnitude, MAX_FORCE, iteration_count);
        }

        // Apply damping and bounded forces to velocity
        vel.x = vel.x * (1.0f - damping) + fminf(MAX_FORCE, fmaxf(-MAX_FORCE, total_force.x)) * dt;
        vel.y = vel.y * (1.0f - damping) + fminf(MAX_FORCE, fmaxf(-MAX_FORCE, total_force.y)) * dt;
        vel.z = vel.z * (1.0f - damping) + fminf(MAX_FORCE, fmaxf(-MAX_FORCE, total_force.z)) * dt;
        
        // Apply STRICT velocity cap to prevent runaway momentum
        float vel_magnitude = sqrtf(vel.x*vel.x + vel.y*vel.y + vel.z*vel.z);
        if (vel_magnitude > MAX_VELOCITY) {
            float scale_factor = MAX_VELOCITY / vel_magnitude;
            vel.x *= scale_factor;
            vel.y *= scale_factor;
            vel.z *= scale_factor;
        }
        
        // Update position
        pos.x += vel.x * dt;
        pos.y += vel.y * dt;
        pos.z += vel.z * dt;

        // Progressive boundary approach - stronger the further you go
        if (viewport_bounds > 0.0f && iteration_count > 10) { // Only apply boundary after initial stabilization
            float soft_margin = 0.3f * viewport_bounds; // 30% soft boundary
            float bound_with_margin = viewport_bounds - soft_margin;

            // Apply progressively stronger boundary forces
            if (fabsf(pos.x) > bound_with_margin) {
                pos.x *= 0.92f; // Pull back by 8%
                // Also add dampening to velocity in this direction
                vel.x *= 0.85f;
            }
            if (fabsf(pos.y) > bound_with_margin) {
                pos.y *= 0.92f; // Pull back by 8%
                vel.y *= 0.85f;
            }
            if (fabsf(pos.z) > bound_with_margin) {
                pos.z *= 0.92f; // Pull back by 8%
                vel.z *= 0.85f;
            }
        }

        // Store results back
        nodes[idx].position.x = pos.x;
        nodes[idx].position.y = pos.y;
        nodes[idx].position.z = pos.z;
        nodes[idx].velocity.x = vel.x;
        nodes[idx].velocity.y = vel.y;
        nodes[idx].velocity.z = vel.z;

        // Debug output for first node
        if (idx == 0 && (iteration_count < 5 || iteration_count % 20 == 0)) {
            float force_mag = sqrtf(
                total_force.x * total_force.x +
                total_force.y * total_force.y +
                total_force.z * total_force.z
            );
            printf("Node %d: force_mag=%f, pos=(%f,%f,%f), vel=(%f,%f,%f)\n",
                idx, force_mag, 
                pos.x, pos.y, pos.z,
                vel.x, vel.y, vel.z);
                
            // More detailed logging during initialization
            if (iteration_count < WARMUP_ITERATIONS)
                printf("Node %d: iteration=%d, ramp_up=%f, damping=%f\n", idx, iteration_count, ramp_up_factor, damping);
        }
    }
}

----
utils/audio_processor.rs
use serde_json::Value;
use base64::{Engine as _, engine::general_purpose::STANDARD as BASE64};
use std::sync::Arc;
use tokio::sync::RwLock;
use crate::config::Settings;
use log::{error, info, warn};

pub struct AudioProcessor {
    settings: Arc<RwLock<Settings>>,
}

impl AudioProcessor {
    pub fn new(settings: Arc<RwLock<Settings>>) -> Self {
        Self { settings }
    }

    pub async fn process_json_response(&self, response_data: &[u8]) -> Result<(String, Vec<u8>), String> {
        let _settings = self.settings.read().await;
        
        // Parse the JSON response
        let json_response: Value = serde_json::from_slice(response_data)
            .map_err(|e| format!("Failed to parse JSON response: {}", e))?;
        
        // Log the entire JSON response if data debug is enabled
        info!("Received JSON response: {}", 
            serde_json::to_string_pretty(&json_response).unwrap_or_else(|_| "Unable to prettify JSON".to_string())
        );
        
        // Check if the response contains an error message
        if let Some(error_msg) = json_response["error"].as_str() {
            error!("Error in JSON response: {}", error_msg);
            return Err(format!("Error in JSON response: {}", error_msg));
        }

        // Extract the text answer with better error handling
        let answer = json_response["data"]["answer"]
            .as_str()
            .or_else(|| json_response["answer"].as_str())
            .ok_or_else(|| {
                error!("Text answer not found in JSON response");
                "Text answer not found in JSON response".to_string()
            })?
            .to_string();

        // Try to extract the audio data from different possible locations with detailed logging
        let audio_data = if let Some(audio) = json_response["data"]["audio"].as_str() {
            info!("Found audio data in data.audio");
            BASE64.decode(audio).map_err(|e| format!("Failed to decode base64 audio data from data.audio: {}", e))?
        } else if let Some(audio) = json_response["audio"].as_str() {
            info!("Found audio data in root.audio");
            BASE64.decode(audio).map_err(|e| format!("Failed to decode base64 audio data from root.audio: {}", e))?
        } else {
            // Log available paths in the JSON for debugging
            warn!("Audio data not found in JSON response. Available paths:");
            if let Some(obj) = json_response.as_object() {
                for (key, value) in obj {
                    warn!("- {}: {}", key, match value {
                        Value::Null => "null",
                        Value::Bool(_) => "boolean",
                        Value::Number(_) => "number",
                        Value::String(_) => "string",
                        Value::Array(_) => "array",
                        Value::Object(_) => "object",
                    });
                }
            }
            return Err("Audio data not found in JSON response".to_string());
        };
        
        info!("Successfully processed audio data: {} bytes", audio_data.len());
        
        // Validate WAV header
        if audio_data.len() >= 44 {
            info!("WAV header: {:?}", &audio_data[..44]);
            
            if &audio_data[..4] != b"RIFF" || &audio_data[8..12] != b"WAVE" {
                error!("Invalid WAV header detected");
                return Err("Invalid WAV header".to_string());
            }
            
            // Extract and log WAV format information
            let channels = u16::from_le_bytes([audio_data[22], audio_data[23]]);
            let sample_rate = u32::from_le_bytes([audio_data[24], audio_data[25], audio_data[26], audio_data[27]]);
            let bits_per_sample = u16::from_le_bytes([audio_data[34], audio_data[35]]);
            
            info!("WAV format: {} channels, {} Hz, {} bits per sample", 
                channels, sample_rate, bits_per_sample);
        } else {
            error!("Audio data too short to contain WAV header: {} bytes", audio_data.len());
            return Err("Audio data too short".to_string());
        }
        
        Ok((answer, audio_data))
    }

    pub async fn validate_wav_header(&self, audio_data: &[u8]) -> Result<(), String> {
        if audio_data.len() < 44 {
            return Err("Audio data too short for WAV header".to_string());
        }

        if &audio_data[..4] != b"RIFF" {
            return Err("Missing RIFF header".to_string());
        }

        if &audio_data[8..12] != b"WAVE" {
            return Err("Missing WAVE format".to_string());
        }

        let channels = u16::from_le_bytes([audio_data[22], audio_data[23]]);
        let sample_rate = u32::from_le_bytes([audio_data[24], audio_data[25], audio_data[26], audio_data[27]]);
        let bits_per_sample = u16::from_le_bytes([audio_data[34], audio_data[35]]);

        info!("Validated WAV format: {} channels, {} Hz, {} bits per sample",
            channels, sample_rate, bits_per_sample);

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;
    use tokio::runtime::Runtime;

    fn create_test_settings() -> Arc<RwLock<Settings>> {
        let settings = Settings {
            debug_mode: false,
            debug: crate::config::DebugSettings {
                enable_websocket_debug: false,
                enable_data_debug: false,
                log_binary_headers: false,
                log_full_json: false,
            },
            // Add other required fields with default values
            ..Default::default()
        };
        Arc::new(RwLock::new(settings))
    }

    #[test]
    fn test_process_json_response_valid() {
        let rt = Runtime::new().unwrap();
        let settings = create_test_settings();
        let processor = AudioProcessor::new(settings);

        let test_wav = vec![
            b'R', b'I', b'F', b'F', // ChunkID
            0x24, 0x00, 0x00, 0x00, // ChunkSize
            b'W', b'A', b'V', b'E', // Format
            b'f', b'm', b't', b' ', // Subchunk1ID
            0x10, 0x00, 0x00, 0x00, // Subchunk1Size
            0x01, 0x00,             // AudioFormat (PCM)
            0x01, 0x00,             // NumChannels (Mono)
            0x44, 0xAC, 0x00, 0x00, // SampleRate (44100)
            0x88, 0x58, 0x01, 0x00, // ByteRate
            0x02, 0x00,             // BlockAlign
            0x10, 0x00,             // BitsPerSample (16)
            b'd', b'a', b't', b'a', // Subchunk2ID
            0x00, 0x00, 0x00, 0x00  // Subchunk2Size
        ];

        let json_data = json!({
            "data": {
                "answer": "Test answer",
                "audio": BASE64.encode(test_wav)
            }
        });

        let result = rt.block_on(processor.process_json_response(
            serde_json::to_vec(&json_data).unwrap().as_slice()
        ));

        assert!(result.is_ok());
        let (answer, audio) = result.unwrap();
        assert_eq!(answer, "Test answer");
        assert_eq!(&audio[..4], b"RIFF");
    }

    #[test]
    fn test_process_json_response_invalid_wav() {
        let rt = Runtime::new().unwrap();
        let settings = create_test_settings();
        let processor = AudioProcessor::new(settings);

        let invalid_wav = vec![0x00; 44]; // Invalid WAV header
        let json_data = json!({
            "data": {
                "answer": "Test answer",
                "audio": BASE64.encode(invalid_wav)
            }
        });

        let result = rt.block_on(processor.process_json_response(
            serde_json::to_vec(&json_data).unwrap().as_slice()
        ));

        assert!(result.is_err());
    }
}

----
utils/socket_flow_messages.rs
use serde::{Deserialize, Serialize};
use bytemuck::{Pod, Zeroable};
use std::collections::HashMap;
use crate::types::vec3::Vec3Data;
use std::sync::atomic::{AtomicU32, Ordering};
use cudarc::driver::{DeviceRepr, ValidAsZeroBits};
use glam::Vec3;

// Static counter for generating unique numeric IDs
static NEXT_NODE_ID: AtomicU32 = AtomicU32::new(1);  // Start from 1 (0 could be reserved)

#[repr(C)]
#[derive(Debug, Clone, Copy, Pod, Zeroable, Serialize, Deserialize)]
/// Binary node data structure for efficient transmission and GPU processing
/// 
/// Wire format (26 bytes per node):
/// - position: Vec3Data (12 bytes)
/// - velocity: Vec3Data (12 bytes)
/// - id: u16 (2 bytes)
///
/// Note: mass, flags, and padding are server-side only and not transmitted over the wire
/// to optimize bandwidth. They are still available for GPU processing and physics calculations.
pub struct BinaryNodeData {
    pub position: Vec3Data,
    pub velocity: Vec3Data,
    pub mass: u8,      // Server-side only, not transmitted
    pub flags: u8,     // Server-side only, not transmitted
    pub padding: [u8; 2], // Server-side only, not transmitted
}

// Implement DeviceRepr for BinaryNodeData
unsafe impl DeviceRepr for BinaryNodeData {}

// Implement ValidAsZeroBits for BinaryNodeData
unsafe impl ValidAsZeroBits for BinaryNodeData {}

#[derive(Debug, Serialize, Deserialize)]
pub struct PingMessage {
    #[serde(rename = "type")]
    pub type_: String,
    #[serde(default = "default_timestamp")]
    pub timestamp: u64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct PongMessage {
    #[serde(rename = "type")]
    pub type_: String,
    pub timestamp: u64,
}

fn default_timestamp() -> u64 {
    chrono::Utc::now().timestamp_millis() as u64
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct Node {
    // Core data
    pub id: String,
    pub metadata_id: String,  // Store the original filename for lookup
    pub label: String,
    pub data: BinaryNodeData,

    // Metadata
    #[serde(skip_serializing_if = "HashMap::is_empty")]
    pub metadata: HashMap<String, String>,
    // We need to keep this attribute to maintain WebSocket protocol compatibility
    #[serde(skip)]
    pub file_size: u64,

    // Rendering properties
    #[serde(rename = "type")]
    #[serde(skip_serializing_if = "Option::is_none")]
    pub node_type: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub size: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub color: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub weight: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub group: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub user_data: Option<HashMap<String, String>>,
}

impl Node {
    pub fn new(metadata_id: String) -> Self {
        // Generate a unique numeric ID for binary protocol compatibility
        let id = NEXT_NODE_ID.fetch_add(1, Ordering::SeqCst).to_string();
        
        Self {
            id,
            metadata_id: metadata_id.clone(),
            label: metadata_id,
            data: BinaryNodeData {
                position: Vec3Data::zero(),
                velocity: Vec3Data::zero(),
                mass: 0, // default mass, will be updated based on file size
                flags: 1, // Set to 1 by default (active state)
                padding: [0, 0],
            },
            metadata: HashMap::new(),
            // file_size is set to 0 initially, will be updated later with set_file_size
            file_size: 0,
            node_type: None,
            size: None,
            color: None,
            weight: None,
            group: None,
            user_data: None,
        }
    }

    pub fn calculate_mass(file_size: u64) -> u8 {
        // Use log scale to prevent extremely large masses
        // Add 1 to file_size to handle empty files (log(0) is undefined)
        // Scale down by 10000 to keep masses in a reasonable range
        let base_mass = ((file_size + 1) as f32).log10() / 4.0;
        // Ensure minimum mass of 0.1 and maximum of 10.0
        let mass = base_mass.max(0.1).min(10.0);
        (mass * 255.0 / 10.0) as u8
    }

    pub fn set_file_size(&mut self, size: u64) {
        self.file_size = size;
        // Update mass based on new file size
        self.data.mass = Self::calculate_mass(size);
        
        // Add the file_size to the metadata HashMap so it gets serialized to the client
        // This is our workaround since we can't directly serialize the file_size field
        if size > 0 {
            self.metadata.insert("fileSize".to_string(), size.to_string());
        }
    }

    // Convenience getters/setters for x, y, z coordinates
    pub fn x(&self) -> f32 { self.data.position.x }
    pub fn y(&self) -> f32 { self.data.position.y }
    pub fn z(&self) -> f32 { self.data.position.z }
    pub fn vx(&self) -> f32 { self.data.velocity.x }
    pub fn vy(&self) -> f32 { self.data.velocity.y }
    pub fn vz(&self) -> f32 { self.data.velocity.z }
    
    pub fn set_x(&mut self, val: f32) { self.data.position.x = val; }
    pub fn set_y(&mut self, val: f32) { self.data.position.y = val; }
    pub fn set_z(&mut self, val: f32) { self.data.position.z = val; }
    pub fn set_vx(&mut self, val: f32) { self.data.velocity.x = val; }
    pub fn set_vy(&mut self, val: f32) { self.data.velocity.y = val; }
    pub fn set_vz(&mut self, val: f32) { self.data.velocity.z = val; }
    
    /// Create a new node with a specific ID or use a stored ID if available
    pub fn new_with_id(metadata_id: String, stored_node_id: Option<String>) -> Self {
        // Use stored ID if available, otherwise generate a new one
        let id = match stored_node_id {
            Some(stored_id) => stored_id,
            None => NEXT_NODE_ID.fetch_add(1, Ordering::SeqCst).to_string(),
        };
        
        Self {
            id,
            metadata_id: metadata_id.clone(),
            label: metadata_id,
            data: BinaryNodeData {
                position: Vec3Data::zero(),
                velocity: Vec3Data::zero(),
                mass: 0, // default mass, will be updated based on file size
                flags: 1, // Set to 1 by default (active state)
                padding: [0, 0],
            },
            metadata: HashMap::new(),
            // file_size is set to 0 initially, will be updated later with set_file_size
            file_size: 0,
            node_type: None,
            size: None,
            color: None,
            weight: None,
            group: None,
            user_data: None,
        }
    }
}

#[derive(Debug, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum Message {
    #[serde(rename = "ping")]
    Ping { timestamp: u64 },
    
    #[serde(rename = "pong")]
    Pong { timestamp: u64 },
    
    #[serde(rename = "enableRandomization")]
    EnableRandomization { enabled: bool },
}

// Helper functions to convert between Vec3Data and [f32; 3] for GPU computations
#[inline]
pub fn vec3data_to_array(vec: &Vec3Data) -> [f32; 3] {
    [vec.x, vec.y, vec.z]
}

#[inline]
pub fn array_to_vec3data(arr: [f32; 3]) -> Vec3Data {
    Vec3Data::new(arr[0], arr[1], arr[2])
}

#[inline]
pub fn vec3data_to_glam(vec: &Vec3Data) -> Vec3 {
    Vec3::new(vec.x, vec.y, vec.z)
}

----
utils/socket_flow_constants.rs
// Node and graph constants
pub const NODE_SIZE: f32 = 1.0;  // Base node size in world units
pub const EDGE_WIDTH: f32 = 0.1; // Base edge width
pub const MIN_DISTANCE: f32 = 0.75; // Minimum distance between nodes - reduced to prevent overcrowding
pub const MAX_DISTANCE: f32 = 10.0; // Maximum distance - reduced to keep nodes closer to center

// WebSocket constants - matching nginx configuration
pub const HEARTBEAT_INTERVAL: u64 = 30; // seconds - matches nginx proxy_connect_timeout
pub const CLIENT_TIMEOUT: u64 = 60; // seconds - double heartbeat interval for safety
pub const MAX_CLIENT_TIMEOUT: u64 = 3600; // seconds - matches nginx proxy_read_timeout
pub const MAX_MESSAGE_SIZE: usize = 100 * 1024 * 1024; // 100MB
pub const BINARY_CHUNK_SIZE: usize = 64 * 1024; // 64KB

// Update rate constants
pub const POSITION_UPDATE_RATE: u32 = 5; // Hz (matching client's MAX_UPDATES_PER_SECOND)
pub const METADATA_UPDATE_RATE: u32 = 1; // Hz

// Binary message constants
pub const NODE_POSITION_SIZE: usize = 24; // 6 f32s (x,y,z,vx,vy,vz) * 4 bytes
pub const BINARY_HEADER_SIZE: usize = 4; // 1 f32 for header

// Compression constants
pub const COMPRESSION_THRESHOLD: usize = 1024; // 1KB
pub const ENABLE_COMPRESSION: bool = true;

----
utils/auth.rs
use actix_web::{HttpRequest, HttpResponse};
use log::{warn, error};
use crate::services::nostr_service::NostrService;

pub enum AccessLevel {
    Authenticated,  // Any authenticated Nostr user
    PowerUser,      // Power users only
}

pub async fn verify_access(
    req: &HttpRequest,
    nostr_service: &NostrService,
    required_level: AccessLevel,
) -> Result<String, HttpResponse> {
    // Get pubkey from header
    let pubkey = match req.headers().get("X-Nostr-Pubkey") {
        Some(value) => value.to_str().unwrap_or("").to_string(),
        None => {
            warn!("Missing Nostr pubkey in request headers");
            return Err(HttpResponse::Forbidden().body("Authentication required"));
        }
    };

    // Get token from header
    let token = match req.headers().get("X-Nostr-Token") {
        Some(value) => value.to_str().unwrap_or("").to_string(),
        None => {
            warn!("Missing Nostr token in request headers");
            return Err(HttpResponse::Forbidden().body("Authentication required"));
        }
    };

    // Validate session
    if !nostr_service.validate_session(&pubkey, &token).await {
        warn!("Invalid or expired session for user {}", pubkey);
        return Err(HttpResponse::Unauthorized().body("Invalid or expired session"));
    }

    // Check access level
    match required_level {
        AccessLevel::Authenticated => {
            // Any valid session is sufficient
            Ok(pubkey)
        }
        AccessLevel::PowerUser => {
            if nostr_service.is_power_user(&pubkey).await {
                Ok(pubkey)
            } else {
                warn!("Non-power user {} attempted restricted operation", pubkey);
                Err(HttpResponse::Forbidden().body("This operation requires power user access"))
            }
        }
    }
}

// Helper function for handlers that require power user access
pub async fn verify_power_user(
    req: &HttpRequest,
    nostr_service: &NostrService,
) -> Result<String, HttpResponse> {
    verify_access(req, nostr_service, AccessLevel::PowerUser).await
}

// Helper function for handlers that require authentication
pub async fn verify_authenticated(
    req: &HttpRequest,
    nostr_service: &NostrService,
) -> Result<String, HttpResponse> {
    verify_access(req, nostr_service, AccessLevel::Authenticated).await
}
----
utils/mod.rs
pub mod audio_processor;
pub mod binary_protocol;
pub mod edge_data;
pub mod gpu_compute;
pub mod logging;
pub mod socket_flow_constants;
pub mod socket_flow_messages;

----
utils/gpu_diagnostics.rs
use crate::utils::gpu_compute::GPUCompute;
use log::{info, warn, error};
use std::env;
use std::path::Path;
use std::io::{Error, ErrorKind};

pub fn run_gpu_diagnostics() -> String {
    let mut report = String::new();
    report.push_str("==== GPU DIAGNOSTIC REPORT ====\n");
    
    // Check environment variables
    report.push_str("Environment Variables:\n");
    for var in &["NVIDIA_GPU_UUID", "NVIDIA_VISIBLE_DEVICES", "CUDA_VISIBLE_DEVICES"] {
        match env::var(var) {
            Ok(val) => {
                report.push_str(&format!("  {} = {}\n", var, val));
                info!("GPU Diagnostic: {} = {}", var, val);
            },
            Err(_) => {
                report.push_str(&format!("  {} = <not set>\n", var));
                warn!("GPU Diagnostic: {} not set", var);
            }
        }
    }
    
    // Check for PTX file
    let ptx_paths = ["/app/src/utils/compute_forces.ptx", "./src/utils/compute_forces.ptx"];
    report.push_str("\nPTX File Status:\n");
    let mut ptx_found = false;
    
    for path in &ptx_paths {
        if Path::new(path).exists() {
            ptx_found = true;
            report.push_str(&format!("  ✅ PTX file found at: {}\n", path));
            info!("GPU Diagnostic: PTX file found at {}", path);
            // Try to get file size
            match std::fs::metadata(path) {
                Ok(metadata) => {
                    report.push_str(&format!("     Size: {} bytes\n", metadata.len()));
                    info!("GPU Diagnostic: PTX file size = {} bytes", metadata.len());
                },
                Err(e) => {
                    report.push_str(&format!("     Error getting file info: {}\n", e));
                    warn!("GPU Diagnostic: Error getting PTX file info: {}", e);
                }
            }
        } else {
            report.push_str(&format!("  ❌ PTX file NOT found at: {}\n", path));
            warn!("GPU Diagnostic: PTX file NOT found at {}", path);
        }
    }
    
    if !ptx_found {
        error!("GPU Diagnostic: No PTX file found at any expected location");
        // This is a critical error for GPU computation
        report.push_str("  ⚠️ CRITICAL ERROR: No PTX file found. GPU physics will not work.\n");
    }
    
    // Check GPU device creation
    report.push_str("\nCUDA Device Detection:\n");
    match GPUCompute::test_gpu() {
        Ok(_) => {
            report.push_str("  ✅ CUDA device successfully detected and tested\n");
            info!("GPU Diagnostic: CUDA device detected and tested successfully");
        },
        Err(e) => {
            report.push_str(&format!("  ❌ CUDA device test failed: {}\n", e));
            error!("GPU Diagnostic: CUDA device test failed: {}", e);
            
            // This is likely why GPU physics isn't working
            report.push_str("  ⚠️ GPU PHYSICS WILL NOT WORK: Could not create CUDA device\n");
        }
    }
    
    report.push_str("=============================\n");
    info!("GPU diagnostic report complete");
    report
}

pub fn fix_cuda_environment() -> Result<(), Error> {
    info!("Attempting to fix CUDA environment...");
    
    // Check and set CUDA_VISIBLE_DEVICES if not set
    if env::var("CUDA_VISIBLE_DEVICES").is_err() {
        info!("CUDA_VISIBLE_DEVICES not set, setting to 0");
        env::set_var("CUDA_VISIBLE_DEVICES", "0");
    }
    
    // Check if PTX file exists; if not, try to find it or create a symlink
    let primary_path = "/app/src/utils/compute_forces.ptx";
    let alternative_path = "./src/utils/compute_forces.ptx";
    
    if !Path::new(primary_path).exists() {
        info!("Primary PTX file not found at {}", primary_path);
        
        if Path::new(alternative_path).exists() {
            info!("Alternative PTX file found at {}, attempting to create symlink", alternative_path);
            
            let alt_path_abs = std::fs::canonicalize(alternative_path)
                .map_err(|e| Error::new(ErrorKind::Other, format!("Failed to get canonical path: {}", e)))?;
                
            let dir_path = Path::new(primary_path).parent()
                .ok_or_else(|| Error::new(ErrorKind::Other, "Invalid PTX path"))?;
                
            if !dir_path.exists() {
                std::fs::create_dir_all(dir_path)
                    .map_err(|e| Error::new(ErrorKind::Other, format!("Failed to create PTX directory: {}", e)))?;
            }
            
            #[cfg(unix)]
            std::os::unix::fs::symlink(&alt_path_abs, primary_path)
                .map_err(|e| Error::new(ErrorKind::Other, format!("Failed to create symlink: {}", e)))?;
                
            #[cfg(not(unix))]
            std::fs::copy(&alt_path_abs, primary_path)
                .map_err(|e| Error::new(ErrorKind::Other, format!("Failed to copy PTX file: {}", e)))?;
                
            info!("Successfully created PTX file at {}", primary_path);
        } else {
            return Err(Error::new(ErrorKind::NotFound, "No PTX file found anywhere. GPU physics will not work."));
        }
    }
    
    info!("CUDA environment has been fixed");
    Ok(())
}
----
utils/binary_protocol.rs
use byteorder::{LittleEndian, WriteBytesExt, ReadBytesExt};
use std::io::Cursor;
use crate::utils::socket_flow_messages::BinaryNodeData;
use log::debug;

// Binary format (simplified):
// - For each node (26 bytes total):
//   - Node Index: 2 bytes (u16)
//   - Position: 3 × 4 bytes = 12 bytes
//   - Velocity: 3 × 4 bytes = 12 bytes
// Total: 26 bytes per node

pub fn encode_node_data(nodes: &[(u16, BinaryNodeData)]) -> Vec<u8> {
    // Only log non-empty node transmissions to reduce spam
    if nodes.len() > 0 {
        debug!("Encoding {} nodes for binary transmission", nodes.len());
    }
    
    let mut buffer = Vec::new();
    
    // Log some samples of the encoded data
    let sample_size = std::cmp::min(3, nodes.len());
    if sample_size > 0 {
        debug!("Sample of nodes being encoded:");
    }
    
    for (node_id, node) in nodes {
        // Log the first few nodes for debugging
        if sample_size > 0 && *node_id < sample_size as u16 {
            debug!("Encoding node {}: pos=[{:.3},{:.3},{:.3}], vel=[{:.3},{:.3},{:.3}]", 
                node_id, 
                node.position.x, node.position.y, node.position.z,
                node.velocity.x, node.velocity.y, node.velocity.z);
        }
        // Write node ID (u16)
        buffer.write_u16::<LittleEndian>(*node_id).unwrap();
        
        // Write position Vec3Data
        buffer.write_f32::<LittleEndian>(node.position.x).unwrap();
        buffer.write_f32::<LittleEndian>(node.position.y).unwrap();
        buffer.write_f32::<LittleEndian>(node.position.z).unwrap();
        
        // Write velocity Vec3Data
        buffer.write_f32::<LittleEndian>(node.velocity.x).unwrap();
        buffer.write_f32::<LittleEndian>(node.velocity.y).unwrap();
        buffer.write_f32::<LittleEndian>(node.velocity.z).unwrap();

        // Mass, flags, and padding are no longer sent to the client
        // They are still available in the BinaryNodeData struct for server-side use
    }

    // Only log non-empty node transmissions to reduce spam
    if nodes.len() > 0 {
        debug!("Encoded binary data: {} bytes for {} nodes", buffer.len(), nodes.len());
    }
    buffer
}

pub fn decode_node_data(data: &[u8]) -> Result<Vec<(u16, BinaryNodeData)>, String> {
    let mut cursor = Cursor::new(data);
    
    // Check if data is empty
    if data.len() < 2 { // At least a node ID (2 bytes)
        return Err("Data too small to contain any nodes".into());
    }
    
    // Log header information
    debug!(
        "Decoding binary data: size={} bytes, expected nodes={}",
        data.len(), data.len() / 26
    );
    
    // Always log this for visibility
    debug!("Decoding binary data of size: {} bytes", data.len());
    
    let mut updates = Vec::new();
    
    // Set up sample logging
    let max_samples = 3;
    let mut samples_logged = 0;
    
    debug!("Starting binary data decode, expecting nodes with position and velocity data");
    
    while cursor.position() < data.len() as u64 {
        // Each node update is 26 bytes: 2 (nodeId) + 12 (position) + 12 (velocity)
        if cursor.position() + 26 > data.len() as u64 {
            return Err("Unexpected end of data while reading node update".into());
        }
        
        // Read node ID (u16)
        let node_id = cursor.read_u16::<LittleEndian>()
            .map_err(|e| format!("Failed to read node ID: {}", e))?;
        
        // Read position Vec3Data
        let pos_x = cursor.read_f32::<LittleEndian>()
            .map_err(|e| format!("Failed to read position[0]: {}", e))?;
        let pos_y = cursor.read_f32::<LittleEndian>()
            .map_err(|e| format!("Failed to read position[1]: {}", e))?;
        let pos_z = cursor.read_f32::<LittleEndian>()
            .map_err(|e| format!("Failed to read position[2]: {}", e))?;

        let position = crate::types::vec3::Vec3Data::new(pos_x, pos_y, pos_z);
        
        // Read velocity Vec3Data
        let vel_x = cursor.read_f32::<LittleEndian>()
            .map_err(|e| format!("Failed to read velocity[0]: {}", e))?;
        let vel_y = cursor.read_f32::<LittleEndian>()
            .map_err(|e| format!("Failed to read velocity[1]: {}", e))?;
        let vel_z = cursor.read_f32::<LittleEndian>()
            .map_err(|e| format!("Failed to read velocity[2]: {}", e))?;
        let velocity = crate::types::vec3::Vec3Data::new(vel_x, vel_y, vel_z);

        // Default mass value - this will be replaced with the actual mass from the node_map
        // in socket_flow_handler.rs for accurate physics calculations
        let mass = 100u8; // Default mass
        let flags = 0u8;  // Default flags
        let padding = [0u8, 0u8]; // Default padding
        
        // Log the first few decoded items as samples
        if samples_logged < max_samples {
            debug!(
                "Decoded node {}: pos=[{:.3},{:.3},{:.3}], vel=[{:.3},{:.3},{:.3}]", 
                node_id, position.x, position.y, position.z, 
                velocity.x, velocity.y, velocity.z
            );
            samples_logged += 1;
        }
        updates.push((node_id, BinaryNodeData {
            position,
            velocity,
            mass,
            flags,
            padding,
        }));
    }
    
    debug!("Successfully decoded {} nodes from binary data", updates.len());
    Ok(updates)
}

pub fn calculate_message_size(updates: &[(u16, BinaryNodeData)]) -> usize {
    // Each update: u16 (node_id) + 3*f32 (position) + 3*f32 (velocity)
    updates.len() * 26
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_encode_decode_roundtrip() {
        let nodes = vec![
            (1u16, BinaryNodeData {
                position: crate::types::vec3::Vec3Data::new(1.0, 2.0, 3.0),
                velocity: crate::types::vec3::Vec3Data::new(0.1, 0.2, 0.3),
                mass: 100,
                flags: 1,
                padding: [0, 0],
            }),
            (2u16, BinaryNodeData {
                position: crate::types::vec3::Vec3Data::new(4.0, 5.0, 6.0),
                velocity: crate::types::vec3::Vec3Data::new(0.4, 0.5, 0.6),
                mass: 200,
                flags: 1,
                padding: [0, 0],
            }),
        ];

        let encoded = encode_node_data(&nodes);
        let decoded = decode_node_data(&encoded).unwrap();

        assert_eq!(nodes.len(), decoded.len());

        for ((orig_id, orig_data), (dec_id, dec_data)) in nodes.iter().zip(decoded.iter()) {
            assert_eq!(orig_id, dec_id);
            assert_eq!(orig_data.position, dec_data.position);
            assert_eq!(orig_data.velocity, dec_data.velocity);
            // Note: mass, flags, and padding are not compared as they're not transmitted
        }
    }

    #[test]
    fn test_decode_invalid_data() {
        // Test with data that's too short
        let result = decode_node_data(&[0u8; 25]);
        assert!(result.is_err());
    }
}

----
utils/edge_data.rs
use bytemuck::{Pod, Zeroable};
use cudarc::driver::{DeviceRepr, ValidAsZeroBits};

#[repr(C)]
#[derive(Debug, Clone, Copy, Pod, Zeroable)]
pub struct EdgeData {
    pub source_idx: i32,
    pub target_idx: i32,
    pub weight: f32,
}

// Implement DeviceRepr for EdgeData
unsafe impl DeviceRepr for EdgeData {}

// Implement ValidAsZeroBits for EdgeData
unsafe impl ValidAsZeroBits for EdgeData {}
----
utils/gpu_compute.rs
use cudarc::driver::{CudaDevice, CudaFunction, CudaSlice, LaunchConfig, LaunchAsync};
use cudarc::nvrtc::Ptx;
use cudarc::driver::sys::CUdevice_attribute_enum;

use std::io::{Error, ErrorKind};
use std::sync::Arc;
use log::{error, warn, info, debug};
use crate::models::graph::GraphData;
use std::collections::HashMap;
use crate::models::simulation_params::SimulationParams;
use crate::utils::socket_flow_messages::BinaryNodeData;
use crate::types::vec3::Vec3Data;
use std::path::Path;
use std::env;
use tokio::sync::RwLock;
use std::time::Duration;
use tokio::time::sleep;

// Constants for GPU computation
const BLOCK_SIZE: u32 = 256;
const MAX_NODES: u32 = 1_000_000;
const NODE_SIZE: u32 = std::mem::size_of::<BinaryNodeData>() as u32;
const SHARED_MEM_SIZE: u32 = BLOCK_SIZE * NODE_SIZE;

// Constants for retry mechanism
const MAX_GPU_INIT_RETRIES: u32 = 3;
const RETRY_DELAY_MS: u64 = 500; // 500ms delay between retries

// Throttle debug output every 60 iterations (or adjust as needed)
const DEBUG_THROTTLE: u32 = 60;

// Note: CPU fallback code has been removed as we're always using GPU now

#[derive(Debug)]
pub struct GPUCompute {
    pub device: Arc<CudaDevice>,
    pub force_kernel: CudaFunction,
    pub node_data: CudaSlice<BinaryNodeData>,
    pub num_nodes: u32,
    pub node_indices: HashMap<String, usize>,
    pub simulation_params: SimulationParams,
    pub iteration_count: u32,
}

impl GPUCompute {
    /// Runs a basic GPU test.
    pub async fn test_gpu() -> Result<(), Error> {
        info!("Running GPU test");
        sleep(Duration::from_millis(500)).await;
        debug!("About to create CUDA device for testing");
        let device = Self::create_cuda_device().await?;
        debug!("Device created successfully, performing memory test");
        sleep(Duration::from_millis(500)).await;
        let test_data: Vec<f32> = vec![1.0, 2.0, 3.0, 4.0, 5.0];
        let gpu_data = device.alloc_zeros::<f32>(5)
            .map_err(|e| Error::new(ErrorKind::Other, e.to_string()))?;
        sleep(Duration::from_millis(500)).await;
        device.dtoh_sync_copy_into(&gpu_data, &mut test_data.clone())
            .map_err(|e| Error::new(ErrorKind::Other, e.to_string()))?;
        info!("GPU test successful");
        Ok(())
    }
    
    async fn create_cuda_device() -> Result<Arc<CudaDevice>, Error> {
        debug!("Starting CUDA device initialization sequence");
        if let Ok(uuid) = env::var("NVIDIA_GPU_UUID") {
            debug!("Found NVIDIA_GPU_UUID: {}", uuid);
            info!("Attempting to create CUDA device with UUID: {}", uuid);
            info!("Using GPU UUID {} via environment variables", uuid);
            if let Ok(devices) = env::var("CUDA_VISIBLE_DEVICES") {
                debug!("Found CUDA_VISIBLE_DEVICES: {}", devices);
                info!("CUDA_VISIBLE_DEVICES is set to: {}", devices);
            }
        }
        debug!("Preparing to create CUDA device with index 0");
        sleep(Duration::from_millis(500)).await;
        debug!("Checking CUDA device availability");
        sleep(Duration::from_millis(500)).await;
        debug!("Attempting CUDA device creation");
        sleep(Duration::from_millis(1000)).await;
        info!("Creating CUDA device with index 0");
        match CudaDevice::new(0) {
            Ok(device) => {
                debug!("CUDA device creation successful");
                info!("Successfully created CUDA device with index 0 (for GPU UUID: {})",
                    env::var("NVIDIA_GPU_UUID").unwrap_or_else(|_| "unknown".to_string()));
                Ok(device.into())
            },
            Err(e) => {
                debug!("CUDA device creation failed with error: {}", e);
                error!("Failed to create CUDA device with index 0: {}", e);
                Err(Error::new(ErrorKind::Other,
                    format!("Failed to create CUDA device: {}. Ensure CUDA drivers are installed and GPU is detected.", e)))
            }
        }
    }

    /// Initializes the GPUCompute instance with retry logic.
    pub async fn new(graph: &GraphData) -> Result<Arc<RwLock<Self>>, Error> {
        let num_nodes = graph.nodes.len() as u32;
        info!("Initializing GPU compute with {} nodes (with retry mechanism)", num_nodes);

        if num_nodes > MAX_NODES {
            return Err(Error::new(
                ErrorKind::Other,
                format!("Node count exceeds limit: {}", MAX_NODES),
            ));
        }
        Self::with_retry(MAX_GPU_INIT_RETRIES, RETRY_DELAY_MS, |attempt| async move {
            Self::initialize_gpu(graph, num_nodes, attempt).await
        }).await
    }
    
    async fn test_gpu_capabilities() -> Result<(), Error> {
        debug!("Starting GPU capabilities test");
        info!("Testing CUDA capabilities");
        sleep(Duration::from_millis(300)).await;
        debug!("Checking environment variables");
        match env::var("NVIDIA_GPU_UUID") {
            Ok(uuid) => {
                debug!("Found NVIDIA_GPU_UUID");
                info!("NVIDIA_GPU_UUID is set to: {}", uuid)
            },
            Err(_) => {
                debug!("NVIDIA_GPU_UUID not found");
                warn!("NVIDIA_GPU_UUID environment variable is not set")
            }
        }
        sleep(Duration::from_millis(500)).await;
        debug!("Querying CUDA device count");
        match CudaDevice::count() {
            Ok(count) => {
                debug!("CUDA device count: {}", count);
                info!("Found {} CUDA device(s)", count);
                if count == 0 {
                    debug!("No CUDA devices found, returning error");
                    return Err(Error::new(ErrorKind::NotFound,
                        "No CUDA devices found. Ensure NVIDIA drivers are installed and working."));
                }
                debug!("GPU capabilities test completed successfully");
                Ok(())
            },
            Err(e) => {
                debug!("Failed to get CUDA device count: {}", e);
                error!("Failed to get CUDA device count: {}", e);
                Err(Error::new(ErrorKind::Other,
                    format!("Failed to get CUDA device count: {}. Check NVIDIA drivers.", e)))
            }
        }
    }
    
    fn diagnostic_cuda_info() -> Result<(), Error> {
        debug!("Starting CUDA diagnostic info collection");
        info!("Running CUDA diagnostic checks");
        debug!("Checking CUDA-related environment variables");
        info!("Checking CUDA-related environment variables:");
        for var in &["NVIDIA_GPU_UUID", "NVIDIA_VISIBLE_DEVICES", "CUDA_VISIBLE_DEVICES"] {
            debug!("Checking variable: {}", var);
            match env::var(var) {
                Ok(val) => {
                    debug!("Found {}: {}", var, val);
                    info!("  {}={}", var, val)
                },
                Err(_) => {
                    debug!("{} not set", var);
                    info!("  {} is not set", var)
                }
            }
        }
        debug!("Attempting to get CUDA device count");
        match CudaDevice::count() {
            Ok(count) => {
                debug!("Retrieved CUDA device count: {}", count);
                info!("CUDA device count: {}", count)
            },
            Err(e) => {
                debug!("Failed to get device count: {}", e);
                error!("Failed to get CUDA device count: {}", e)
            }
        }
        debug!("CUDA diagnostic info collection completed");
        Ok(())
    }
    
    async fn initialize_gpu(graph: &GraphData, num_nodes: u32, attempt: u32) -> Result<Arc<RwLock<Self>>, Error> {
        info!("GPU initialization attempt {}/{}", attempt + 1, MAX_GPU_INIT_RETRIES);
        match Self::test_gpu_capabilities().await {
            Ok(_) => info!("GPU capabilities check passed"),
            Err(e) => {
                warn!("GPU capabilities check failed on attempt {}: {}", attempt + 1, e);
                return Err(e);
            }
        }
        info!("Attempting to create CUDA device (attempt {}/{})", attempt + 1, MAX_GPU_INIT_RETRIES);
        let device = match Self::create_cuda_device().await {
            Ok(dev) => {
                info!("CUDA device created successfully");
                let max_threads = dev.as_ref().attribute(CUdevice_attribute_enum::CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK as _)
                    .map_err(|e| Error::new(ErrorKind::Other, e.to_string()))?;
                let compute_mode = dev.as_ref().attribute(CUdevice_attribute_enum::CU_DEVICE_ATTRIBUTE_COMPUTE_MODE as _)
                    .map_err(|e| Error::new(ErrorKind::Other, e.to_string()))?;
                let multiprocessor_count = dev.as_ref().attribute(CUdevice_attribute_enum::CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT as _)
                    .map_err(|e| Error::new(ErrorKind::Other, e.to_string()))?;
                
                info!("GPU Device detected:");
                info!("  Max threads per MP: {}", max_threads);
                info!("  Multiprocessor count: {}", multiprocessor_count);
                info!("  Compute mode: {}", compute_mode);
                
                if max_threads < 256 {
                    let err = Error::new(ErrorKind::Other,
                        format!("GPU capability too low: {} threads per multiprocessor; minimum required is 256", max_threads));
                    warn!("GPU capability check failed: {}", err);
                    return Err(err);
                }
                dev
            },
            Err(e) => {
                error!("Failed to create CUDA device (attempt {}/{}): {}", attempt + 1, MAX_GPU_INIT_RETRIES, e);
                Self::diagnostic_cuda_info()?;
                return Err(Error::new(ErrorKind::Other,
                   format!("Failed to create CUDA device: {}. See logs for diagnostics.", e)));
            }
        };

        info!("Proceeding to load compute kernel (attempt {}/{})", attempt + 1, MAX_GPU_INIT_RETRIES);
        Self::load_compute_kernel(device, num_nodes, graph).await
    }
    
    /// Generic asynchronous retry mechanism with exponential backoff.
    async fn with_retry<F, Fut, T>(max_attempts: u32, base_delay_ms: u64, operation: F) -> Result<T, Error>
    where
        F: Fn(u32) -> Fut,
        Fut: std::future::Future<Output = Result<T, Error>>,
    {
        let mut last_error: Option<Error> = None;
        for attempt in 0..max_attempts {
            match operation(attempt).await {
                Ok(result) => {
                    if attempt > 0 {
                        info!("Operation succeeded after {} retries", attempt);
                    }
                    return Ok(result);
                }
                Err(e) => {
                    let delay = base_delay_ms * (1 << attempt);
                    warn!("Operation failed (attempt {}/{}): {}. Retrying in {}ms...", 
                          attempt + 1, max_attempts, e, delay);
                    last_error = Some(e);
                    if attempt + 1 < max_attempts {
                        sleep(Duration::from_millis(delay)).await;
                    }
                }
            }
        }
        error!("Operation failed after {} attempts", max_attempts);
        Err(last_error.unwrap_or_else(|| Error::new(ErrorKind::Other, 
            format!("All {} retry attempts failed", max_attempts))))
    }
    
    async fn load_compute_kernel(
        device: Arc<CudaDevice>, 
        num_nodes: u32, 
        graph: &GraphData
    ) -> Result<Arc<RwLock<Self>>, Error> {
        let ptx_path = "/app/src/utils/compute_forces.ptx";
        let ptx_path_obj = Path::new(ptx_path);
        if !ptx_path_obj.exists() {
            error!("PTX file does not exist at {} - required for GPU physics", ptx_path);
            return Err(Error::new(ErrorKind::NotFound, format!("PTX file not found at {}", ptx_path)));
        }
        let ptx = Ptx::from_file(ptx_path);
        info!("Successfully loaded PTX file");
        
        device.load_ptx(ptx, "compute_forces_kernel", &["compute_forces_kernel"])
            .map_err(|e| Error::new(ErrorKind::Other, e.to_string()))?;
        let force_kernel = device.get_func("compute_forces_kernel", "compute_forces_kernel")
            .ok_or_else(|| Error::new(ErrorKind::Other, "Function compute_forces_kernel not found"))?;
        
        info!("Allocating device memory for {} nodes", num_nodes);
        let node_data = device.alloc_zeros::<BinaryNodeData>(num_nodes as usize)
            .map_err(|e| Error::new(ErrorKind::Other, e.to_string()))?;
        
        info!("Creating GPU compute instance");
        let mut node_indices = HashMap::new();
        for (idx, node) in graph.nodes.iter().enumerate() {
            node_indices.insert(node.id.clone(), idx);
        }

        let mut instance = Self {
            device: Arc::clone(&device),
            force_kernel,
            node_data,
            num_nodes,
            node_indices,
            simulation_params: SimulationParams::default(),
            iteration_count: 0,
        };

        info!("Copying initial graph data to device memory");
        instance.update_graph_data(graph)?;
        info!("GPU compute initialization complete");
        Ok(Arc::new(RwLock::new(instance)))
    }

    pub fn update_graph_data(&mut self, graph: &GraphData) -> Result<(), Error> {
        debug!("Updating graph data for {} nodes", graph.nodes.len());
        self.node_indices.clear();
        for (idx, node) in graph.nodes.iter().enumerate() {
            self.node_indices.insert(node.id.clone(), idx);
        }
        if graph.nodes.len() as u32 != self.num_nodes {
            info!("Reallocating GPU buffer for {} nodes", graph.nodes.len());
            self.node_data = self.device.alloc_zeros::<BinaryNodeData>(graph.nodes.len())
                .map_err(|e| Error::new(ErrorKind::Other, e.to_string()))?;
            self.num_nodes = graph.nodes.len() as u32;
            self.iteration_count = 0;
        }
        let mut node_data = Vec::with_capacity(graph.nodes.len());
        if !graph.nodes.is_empty() {
            let sample_size = std::cmp::min(3, graph.nodes.len());
            debug!("Sample of first {} nodes before GPU transfer:", sample_size);
            for i in 0..sample_size {
                let node = &graph.nodes[i];
                debug!(
                    "Node[{}] id={}: pos=[{:.3},{:.3},{:.3}], vel=[{:.3},{:.3},{:.3}]",
                    i, node.id,
                    node.data.position.x, node.data.position.y, node.data.position.z,
                    node.data.velocity.x, node.data.velocity.y, node.data.velocity.z
                );
            }
        }
        for node in &graph.nodes {
            node_data.push(BinaryNodeData {
                position: node.data.position.clone(),
                velocity: node.data.velocity.clone(),
                mass: node.data.mass,
                flags: node.data.flags, 
                padding: node.data.padding,
            });
            if node.id == "0" || node.id == "1" {
                debug!(
                    "Node {} data prepared for GPU: pos=[{:.3},{:.3},{:.3}], vel=[{:.3},{:.3},{:.3}]",
                    node.id,
                    node.data.position.x, node.data.position.y, node.data.position.z,
                    node.data.velocity.x, node.data.velocity.y, node.data.velocity.z
                );
            }
        }
        debug!("Copying {} nodes to GPU", graph.nodes.len());
        self.device.htod_sync_copy_into(&node_data, &mut self.node_data)
            .map_err(|e| Error::new(ErrorKind::Other, format!("Failed to copy node data to GPU: {}", e)))?;
        Ok(())
    }

    pub fn update_simulation_params(&mut self, params: &SimulationParams) -> Result<(), Error> {
        debug!("Updating simulation parameters: {:?}", params);
        self.simulation_params = params.clone();
        Ok(())
    }

    /// Computes forces on the GPU. To reduce log clutter from repeated messages, some logging is gated.
    pub fn compute_forces(&mut self) -> Result<(), Error> {
        // Only log detailed GPU computation info every DEBUG_THROTTLE iterations.
        if self.iteration_count % DEBUG_THROTTLE == 0 {
            debug!("Starting force computation on GPU");
        }
        let blocks = ((self.num_nodes + BLOCK_SIZE - 1) / BLOCK_SIZE).max(1);
        let cfg = LaunchConfig {
            grid_dim: (blocks, 1, 1),
            block_dim: (BLOCK_SIZE, 1, 1),
            shared_mem_bytes: SHARED_MEM_SIZE,
        };
        if self.iteration_count % DEBUG_THROTTLE == 0 {
            debug!("Launch config: blocks={}, threads={}, shared_mem={}", blocks, BLOCK_SIZE, SHARED_MEM_SIZE);
        }
        unsafe {
            self.force_kernel.clone().launch(cfg, (
                &self.node_data,
                self.num_nodes as i32,
                self.simulation_params.spring_strength,
                self.simulation_params.damping,
                self.simulation_params.repulsion,
                self.simulation_params.time_step,
                self.simulation_params.max_repulsion_distance,
                if self.simulation_params.enable_bounds {
                    self.simulation_params.viewport_bounds
                } else {
                    f32::MAX // disable bounds
                },
                self.iteration_count as i32,
            )).map_err(|e| {
                error!("Kernel launch failed: {}", e);
                Error::new(ErrorKind::Other, e.to_string())
            })?;
        }
        if self.iteration_count % DEBUG_THROTTLE == 0 {
            debug!("Force computation completed");
        }
        self.iteration_count += 1;
        Ok(())
    }

    pub fn get_node_data(&self) -> Result<Vec<BinaryNodeData>, Error> {
        let mut gpu_raw_data = vec![BinaryNodeData {
            position: Vec3Data::zero(),
            velocity: Vec3Data::zero(),
            mass: 0,
            flags: 0,
            padding: [0, 0],
        }; self.num_nodes as usize];
        self.device.dtoh_sync_copy_into(&self.node_data, &mut gpu_raw_data)
            .map_err(|e| Error::new(ErrorKind::Other, format!("Failed to copy data from GPU: {}", e)))?;
        if !gpu_raw_data.is_empty() {
            let sample_size = std::cmp::min(5, gpu_raw_data.len());
            debug!("Sample of first {} nodes after GPU calculation:", sample_size);
            for i in 0..sample_size {
                let node = &gpu_raw_data[i];
                let force_mag = (node.velocity.x * node.velocity.x +
                                 node.velocity.y * node.velocity.y +
                                 node.velocity.z * node.velocity.z).sqrt();
                debug!(
                    "Node[{}]: force_mag={:.6}, pos=[{:.3},{:.3},{:.3}], vel=[{:.6},{:.6},{:.6}]",
                    i, force_mag,
                    node.position.x, node.position.y, node.position.z,
                    node.velocity.x, node.velocity.y, node.velocity.z
                );
            }
        }
        Ok(gpu_raw_data)
    }

    /// Advances one simulation step.
    pub fn step(&mut self) -> Result<(), Error> {
        debug!("Executing physics step (iteration {})", self.iteration_count);
        self.compute_forces()?;
        if self.iteration_count % DEBUG_THROTTLE == 0 {
            debug!("Detailed simulation status:");
            debug!("  - Iteration: {}", self.iteration_count);
            debug!("  - Node count: {}", self.num_nodes);
            debug!("  - Spring strength: {}", self.simulation_params.spring_strength);
            debug!("  - Repulsion: {}", self.simulation_params.repulsion);
            debug!("  - Damping: {}", self.simulation_params.damping);
        } else {
            debug!("Physics step complete, iteration count: {}", self.iteration_count);
        }
        Ok(())
    }
    
    /// Runs a minimal test computation on the GPU.
    pub fn test_compute(&self) -> Result<(), Error> {
        info!("Running test computation on GPU instance");
        match self.device.synchronize() {
            Ok(_) => { info!("GPU device access test passed"); },
            Err(e) => {
                error!("GPU device access test failed: {}", e);
                return Err(Error::new(ErrorKind::Other, format!("GPU device access test failed: {}", e)));
            }
        }
        info!("GPU test computation successful");
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_gpu_compute_initialization() {
        info!("Running GPU compute initialization test");
        let graph = GraphData::default();
        let gpu_compute = GPUCompute::new(&graph).await;
        assert!(gpu_compute.is_ok());
    }

    #[tokio::test]
    async fn test_node_data_transfer() {
        info!("Running node data transfer test");
        let mut graph = GraphData::default();
        let gpu_compute = GPUCompute::new(&graph).await.unwrap();
        let gpu_compute = Arc::try_unwrap(gpu_compute).unwrap().into_inner();
        let node_data = gpu_compute.get_node_data().unwrap();
        assert_eq!(node_data.len(), graph.nodes.len());
    }

    #[test]
    fn test_node_data_memory_layout() {
        info!("Checking BinaryNodeData memory layout");
        use std::mem::size_of;
        assert_eq!(size_of::<BinaryNodeData>(), 28);
    }
}

----
utils/compute_forces.ptx
//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34097967
// Cuda compilation tools, release 12.4, V12.4.131
// Based on NVVM 7.0.1
//

.version 8.4
.target sm_86
.address_size 64

	// .globl	compute_forces_kernel
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.global .align 1 .b8 $str[44] = {70, 111, 114, 99, 101, 32, 99, 108, 97, 109, 112, 101, 100, 32, 102, 114, 111, 109, 32, 37, 102, 32, 116, 111, 32, 37, 102, 32, 40, 105, 116, 101, 114, 97, 116, 105, 111, 110, 32, 37, 100, 41, 10};
.global .align 1 .b8 $str$1[55] = {78, 111, 100, 101, 32, 37, 100, 58, 32, 102, 111, 114, 99, 101, 95, 109, 97, 103, 61, 37, 102, 44, 32, 112, 111, 115, 61, 40, 37, 102, 44, 37, 102, 44, 37, 102, 41, 44, 32, 118, 101, 108, 61, 40, 37, 102, 44, 37, 102, 44, 37, 102, 41, 10};
.global .align 1 .b8 $str$2[47] = {78, 111, 100, 101, 32, 37, 100, 58, 32, 105, 116, 101, 114, 97, 116, 105, 111, 110, 61, 37, 100, 44, 32, 114, 97, 109, 112, 95, 117, 112, 61, 37, 102, 44, 32, 100, 97, 109, 112, 105, 110, 103, 61, 37, 102, 10};

.visible .entry compute_forces_kernel(
	.param .u64 compute_forces_kernel_param_0,
	.param .u32 compute_forces_kernel_param_1,
	.param .f32 compute_forces_kernel_param_2,
	.param .f32 compute_forces_kernel_param_3,
	.param .f32 compute_forces_kernel_param_4,
	.param .f32 compute_forces_kernel_param_5,
	.param .f32 compute_forces_kernel_param_6,
	.param .f32 compute_forces_kernel_param_7,
	.param .u32 compute_forces_kernel_param_8
)
{
	.local .align 16 .b8 	__local_depot0[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<41>;
	.reg .b16 	%rs<5>;
	.reg .f32 	%f<326>;
	.reg .b32 	%r<31>;
	.reg .f64 	%fd<12>;
	.reg .b64 	%rd<21>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd6, [compute_forces_kernel_param_0];
	ld.param.u32 	%r9, [compute_forces_kernel_param_1];
	ld.param.f32 	%f120, [compute_forces_kernel_param_2];
	ld.param.f32 	%f288, [compute_forces_kernel_param_3];
	ld.param.f32 	%f122, [compute_forces_kernel_param_4];
	ld.param.f32 	%f123, [compute_forces_kernel_param_5];
	ld.param.f32 	%f124, [compute_forces_kernel_param_6];
	ld.param.f32 	%f125, [compute_forces_kernel_param_7];
	ld.param.u32 	%r10, [compute_forces_kernel_param_8];
	cvta.to.global.u64 	%rd1, %rd6;
	mov.u32 	%r11, %ntid.x;
	mov.u32 	%r12, %ctaid.x;
	mov.u32 	%r13, %tid.x;
	mad.lo.s32 	%r1, %r12, %r11, %r13;
	setp.ge.s32 	%p1, %r1, %r9;
	@%p1 bra 	$L__BB0_45;

	setp.gt.s32 	%p2, %r10, 99;
	mov.f32 	%f287, 0f3F800000;
	@%p2 bra 	$L__BB0_3;

	cvt.rn.f32.s32 	%f127, %r10;
	mov.f32 	%f128, 0f42C80000;
	div.approx.ftz.f32 	%f129, %f127, %f128;
	fma.rn.ftz.f32 	%f287, %f129, 0f3F7D70A4, 0f3C23D70A;
	fma.rn.ftz.f32 	%f130, %f129, 0fBECCCCCD, 0f3F666666;
	max.ftz.f32 	%f288, %f288, %f130;

$L__BB0_3:
	mul.wide.s32 	%rd7, %r1, 28;
	add.s64 	%rd2, %rd1, %rd7;
	ld.global.f32 	%f5, [%rd2];
	ld.global.f32 	%f6, [%rd2+4];
	ld.global.f32 	%f7, [%rd2+8];
	ld.global.f32 	%f8, [%rd2+12];
	ld.global.f32 	%f9, [%rd2+16];
	ld.global.f32 	%f10, [%rd2+20];
	ld.global.u8 	%rs1, [%rd2+24];
	setp.eq.s16 	%p3, %rs1, 0;
	mov.f32 	%f289, 0f3F000000;
	@%p3 bra 	$L__BB0_5;

	cvt.rn.f32.u16 	%f132, %rs1;
	add.ftz.f32 	%f133, %f132, 0f3F800000;
	mov.f32 	%f134, 0f43800000;
	div.approx.ftz.f32 	%f289, %f133, %f134;

$L__BB0_5:
	setp.lt.s32 	%p4, %r9, 1;
	mov.f32 	%f294, 0f00000000;
	mov.f32 	%f295, %f294;
	mov.f32 	%f296, %f294;
	@%p4 bra 	$L__BB0_31;

	mul.ftz.f32 	%f13, %f287, %f120;
	mul.ftz.f32 	%f14, %f289, %f122;
	and.b32  	%r2, %r9, 1;
	setp.eq.s32 	%p5, %r9, 1;
	mov.f32 	%f296, 0f00000000;
	mov.u32 	%r30, 0;
	mov.f32 	%f295, %f296;
	mov.f32 	%f294, %f296;
	@%p5 bra 	$L__BB0_23;

	sub.s32 	%r29, %r9, %r2;
	mov.f32 	%f296, 0f00000000;
	mov.u32 	%r30, 0;

$L__BB0_8:
	mul.wide.s32 	%rd8, %r30, 28;
	add.s64 	%rd3, %rd1, %rd8;
	setp.eq.s32 	%p6, %r30, %r1;
	@%p6 bra 	$L__BB0_15;

	ld.global.u8 	%rs2, [%rd3+24];
	setp.eq.s16 	%p7, %rs2, 0;
	mov.f32 	%f293, 0f3F000000;
	@%p7 bra 	$L__BB0_11;

	cvt.rn.f32.u16 	%f146, %rs2;
	add.ftz.f32 	%f147, %f146, 0f3F800000;
	mov.f32 	%f148, 0f43800000;
	div.approx.ftz.f32 	%f293, %f147, %f148;

$L__BB0_11:
	ld.global.f32 	%f149, [%rd3];
	sub.ftz.f32 	%f20, %f149, %f5;
	ld.global.f32 	%f150, [%rd3+4];
	sub.ftz.f32 	%f21, %f150, %f6;
	ld.global.f32 	%f151, [%rd3+8];
	sub.ftz.f32 	%f22, %f151, %f7;
	mul.ftz.f32 	%f152, %f21, %f21;
	fma.rn.ftz.f32 	%f153, %f20, %f20, %f152;
	fma.rn.ftz.f32 	%f154, %f22, %f22, %f153;
	sqrt.approx.ftz.f32 	%f23, %f154;
	setp.leu.ftz.f32 	%p8, %f23, 0f3E19999A;
	@%p8 bra 	$L__BB0_15;

	div.approx.ftz.f32 	%f24, %f20, %f23;
	div.approx.ftz.f32 	%f25, %f21, %f23;
	div.approx.ftz.f32 	%f26, %f22, %f23;
	add.ftz.f32 	%f155, %f23, 0fC0400000;
	fma.rn.ftz.f32 	%f27, %f155, 0f3DCCCCCD, 0f3F800000;
	setp.lt.ftz.f32 	%p9, %f23, %f124;
	@%p9 bra 	$L__BB0_14;
	bra.uni 	$L__BB0_13;

$L__BB0_14:
	mul.ftz.f32 	%f166, %f14, %f293;
	mul.ftz.f32 	%f167, %f23, %f23;
	mov.f32 	%f168, 0f3E19999A;
	max.ftz.f32 	%f169, %f167, %f168;
	div.approx.ftz.f32 	%f170, %f166, %f169;
	add.ftz.f32 	%f171, %f166, %f166;
	min.ftz.f32 	%f172, %f170, %f171;
	mul.ftz.f32 	%f173, %f24, %f172;
	sub.ftz.f32 	%f294, %f294, %f173;
	mul.ftz.f32 	%f174, %f25, %f172;
	sub.ftz.f32 	%f295, %f295, %f174;
	mul.ftz.f32 	%f175, %f26, %f172;
	sub.ftz.f32 	%f296, %f296, %f175;
	bra.uni 	$L__BB0_15;

$L__BB0_13:
	add.ftz.f32 	%f156, %f23, 0fBF800000;
	mul.ftz.f32 	%f157, %f13, %f156;
	neg.ftz.f32 	%f158, %f157;
	mul.ftz.f32 	%f159, %f289, %f293;
	setp.gt.ftz.f32 	%p10, %f23, 0f40400000;
	mul.ftz.f32 	%f160, %f27, %f158;
	selp.f32 	%f161, %f160, %f158, %p10;
	mul.ftz.f32 	%f162, %f159, %f161;
	mul.ftz.f32 	%f163, %f162, %f24;
	sub.ftz.f32 	%f294, %f294, %f163;
	mul.ftz.f32 	%f164, %f162, %f25;
	sub.ftz.f32 	%f295, %f295, %f164;
	mul.ftz.f32 	%f165, %f162, %f26;
	sub.ftz.f32 	%f296, %f296, %f165;

$L__BB0_15:
	add.s32 	%r16, %r30, 1;
	setp.eq.s32 	%p11, %r16, %r1;
	@%p11 bra 	$L__BB0_22;

	ld.global.u8 	%rs3, [%rd3+52];
	setp.eq.s16 	%p12, %rs3, 0;
	mov.f32 	%f297, 0f3F000000;
	@%p12 bra 	$L__BB0_18;

	cvt.rn.f32.u16 	%f177, %rs3;
	add.ftz.f32 	%f178, %f177, 0f3F800000;
	mov.f32 	%f179, 0f43800000;
	div.approx.ftz.f32 	%f297, %f178, %f179;

$L__BB0_18:
	ld.global.f32 	%f180, [%rd3+28];
	sub.ftz.f32 	%f39, %f180, %f5;
	ld.global.f32 	%f181, [%rd3+32];
	sub.ftz.f32 	%f40, %f181, %f6;
	ld.global.f32 	%f182, [%rd3+36];
	sub.ftz.f32 	%f41, %f182, %f7;
	mul.ftz.f32 	%f183, %f40, %f40;
	fma.rn.ftz.f32 	%f184, %f39, %f39, %f183;
	fma.rn.ftz.f32 	%f185, %f41, %f41, %f184;
	sqrt.approx.ftz.f32 	%f42, %f185;
	setp.leu.ftz.f32 	%p13, %f42, 0f3E19999A;
	@%p13 bra 	$L__BB0_22;

	div.approx.ftz.f32 	%f43, %f39, %f42;
	div.approx.ftz.f32 	%f44, %f40, %f42;
	div.approx.ftz.f32 	%f45, %f41, %f42;
	add.ftz.f32 	%f186, %f42, 0fC0400000;
	fma.rn.ftz.f32 	%f46, %f186, 0f3DCCCCCD, 0f3F800000;
	setp.lt.ftz.f32 	%p14, %f42, %f124;
	@%p14 bra 	$L__BB0_21;
	bra.uni 	$L__BB0_20;

$L__BB0_21:
	mul.ftz.f32 	%f197, %f14, %f297;
	mul.ftz.f32 	%f198, %f42, %f42;
	mov.f32 	%f199, 0f3E19999A;
	max.ftz.f32 	%f200, %f198, %f199;
	div.approx.ftz.f32 	%f201, %f197, %f200;
	add.ftz.f32 	%f202, %f197, %f197;
	min.ftz.f32 	%f203, %f201, %f202;
	mul.ftz.f32 	%f204, %f43, %f203;
	sub.ftz.f32 	%f294, %f294, %f204;
	mul.ftz.f32 	%f205, %f44, %f203;
	sub.ftz.f32 	%f295, %f295, %f205;
	mul.ftz.f32 	%f206, %f45, %f203;
	sub.ftz.f32 	%f296, %f296, %f206;
	bra.uni 	$L__BB0_22;

$L__BB0_20:
	add.ftz.f32 	%f187, %f42, 0fBF800000;
	mul.ftz.f32 	%f188, %f13, %f187;
	neg.ftz.f32 	%f189, %f188;
	mul.ftz.f32 	%f190, %f289, %f297;
	setp.gt.ftz.f32 	%p15, %f42, 0f40400000;
	mul.ftz.f32 	%f191, %f46, %f189;
	selp.f32 	%f192, %f191, %f189, %p15;
	mul.ftz.f32 	%f193, %f190, %f192;
	mul.ftz.f32 	%f194, %f193, %f43;
	sub.ftz.f32 	%f294, %f294, %f194;
	mul.ftz.f32 	%f195, %f193, %f44;
	sub.ftz.f32 	%f295, %f295, %f195;
	mul.ftz.f32 	%f196, %f193, %f45;
	sub.ftz.f32 	%f296, %f296, %f196;

$L__BB0_22:
	add.s32 	%r30, %r30, 2;
	add.s32 	%r29, %r29, -2;
	setp.ne.s32 	%p16, %r29, 0;
	@%p16 bra 	$L__BB0_8;

$L__BB0_23:
	setp.eq.s32 	%p17, %r2, 0;
	@%p17 bra 	$L__BB0_31;

	setp.eq.s32 	%p18, %r30, %r1;
	@%p18 bra 	$L__BB0_31;

	mul.wide.s32 	%rd9, %r30, 28;
	add.s64 	%rd10, %rd1, %rd9;
	add.s64 	%rd4, %rd10, 24;
	ld.global.u8 	%rs4, [%rd10+24];
	setp.eq.s16 	%p19, %rs4, 0;
	mov.f32 	%f307, 0f3F000000;
	@%p19 bra 	$L__BB0_27;

	cvt.rn.f32.u16 	%f208, %rs4;
	add.ftz.f32 	%f209, %f208, 0f3F800000;
	mov.f32 	%f210, 0f43800000;
	div.approx.ftz.f32 	%f307, %f209, %f210;

$L__BB0_27:
	ld.global.f32 	%f211, [%rd4+-24];
	sub.ftz.f32 	%f64, %f211, %f5;
	ld.global.f32 	%f212, [%rd4+-20];
	sub.ftz.f32 	%f65, %f212, %f6;
	ld.global.f32 	%f213, [%rd4+-16];
	sub.ftz.f32 	%f66, %f213, %f7;
	mul.ftz.f32 	%f214, %f65, %f65;
	fma.rn.ftz.f32 	%f215, %f64, %f64, %f214;
	fma.rn.ftz.f32 	%f216, %f66, %f66, %f215;
	sqrt.approx.ftz.f32 	%f67, %f216;
	setp.leu.ftz.f32 	%p20, %f67, 0f3E19999A;
	@%p20 bra 	$L__BB0_31;

	div.approx.ftz.f32 	%f68, %f64, %f67;
	div.approx.ftz.f32 	%f69, %f65, %f67;
	div.approx.ftz.f32 	%f70, %f66, %f67;
	add.ftz.f32 	%f217, %f67, 0fBF800000;
	mul.ftz.f32 	%f218, %f13, %f217;
	neg.ftz.f32 	%f219, %f218;
	add.ftz.f32 	%f220, %f67, 0fC0400000;
	fma.rn.ftz.f32 	%f221, %f220, 0f3DCCCCCD, 0f3F800000;
	mul.ftz.f32 	%f222, %f221, %f219;
	setp.gt.ftz.f32 	%p21, %f67, 0f40400000;
	selp.f32 	%f71, %f222, %f219, %p21;
	setp.lt.ftz.f32 	%p22, %f67, %f124;
	@%p22 bra 	$L__BB0_30;
	bra.uni 	$L__BB0_29;

$L__BB0_30:
	mul.ftz.f32 	%f228, %f14, %f307;
	mul.ftz.f32 	%f229, %f67, %f67;
	mov.f32 	%f230, 0f3E19999A;
	max.ftz.f32 	%f231, %f229, %f230;
	div.approx.ftz.f32 	%f232, %f228, %f231;
	add.ftz.f32 	%f233, %f228, %f228;
	min.ftz.f32 	%f234, %f232, %f233;
	mul.ftz.f32 	%f235, %f68, %f234;
	sub.ftz.f32 	%f294, %f294, %f235;
	mul.ftz.f32 	%f236, %f69, %f234;
	sub.ftz.f32 	%f295, %f295, %f236;
	mul.ftz.f32 	%f237, %f70, %f234;
	sub.ftz.f32 	%f296, %f296, %f237;
	bra.uni 	$L__BB0_31;

$L__BB0_29:
	mul.ftz.f32 	%f223, %f289, %f307;
	mul.ftz.f32 	%f224, %f223, %f71;
	mul.ftz.f32 	%f225, %f224, %f68;
	sub.ftz.f32 	%f294, %f294, %f225;
	mul.ftz.f32 	%f226, %f224, %f69;
	sub.ftz.f32 	%f295, %f295, %f226;
	mul.ftz.f32 	%f227, %f224, %f70;
	sub.ftz.f32 	%f296, %f296, %f227;

$L__BB0_31:
	mul.ftz.f32 	%f238, %f6, %f6;
	fma.rn.ftz.f32 	%f239, %f5, %f5, %f238;
	fma.rn.ftz.f32 	%f240, %f7, %f7, %f239;
	sqrt.approx.ftz.f32 	%f81, %f240;
	setp.leu.ftz.f32 	%p23, %f81, 0f40400000;
	@%p23 bra 	$L__BB0_33;

	add.ftz.f32 	%f241, %f81, 0fC0400000;
	mul.ftz.f32 	%f242, %f289, 0f3C75C28F;
	mul.ftz.f32 	%f243, %f287, %f242;
	mul.ftz.f32 	%f244, %f243, %f241;
	div.approx.ftz.f32 	%f245, %f244, %f81;
	mul.ftz.f32 	%f246, %f5, %f245;
	sub.ftz.f32 	%f294, %f294, %f246;
	mul.ftz.f32 	%f247, %f6, %f245;
	sub.ftz.f32 	%f295, %f295, %f247;
	mul.ftz.f32 	%f248, %f7, %f245;
	sub.ftz.f32 	%f296, %f296, %f248;

$L__BB0_33:
	mul.ftz.f32 	%f249, %f295, %f295;
	fma.rn.ftz.f32 	%f250, %f294, %f294, %f249;
	fma.rn.ftz.f32 	%f251, %f296, %f296, %f250;
	sqrt.approx.ftz.f32 	%f88, %f251;
	setp.leu.ftz.f32 	%p24, %f88, 0f40400000;
	add.u64 	%rd11, %SP, 0;
	add.u64 	%rd5, %SPL, 0;
	@%p24 bra 	$L__BB0_36;

	setp.gt.s32 	%p25, %r10, 4;
	mov.f32 	%f252, 0f40400000;
	div.approx.ftz.f32 	%f253, %f252, %f88;
	mul.ftz.f32 	%f294, %f294, %f253;
	mul.ftz.f32 	%f295, %f295, %f253;
	mul.ftz.f32 	%f296, %f296, %f253;
	setp.ne.s32 	%p26, %r1, 0;
	or.pred  	%p27, %p26, %p25;
	@%p27 bra 	$L__BB0_36;

	cvt.ftz.f64.f32 	%fd1, %f88;
	mov.f64 	%fd2, 0d4008000000000000;
	st.local.v2.f64 	[%rd5], {%fd1, %fd2};
	st.local.u32 	[%rd5+16], %r10;
	mov.u64 	%rd12, $str;
	cvta.global.u64 	%rd13, %rd12;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd13;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd11;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r17, [retval0+0];
	} // callseq 0

$L__BB0_36:
	setp.lt.s32 	%p28, %r10, 5;
	mov.f32 	%f254, 0f3F800000;
	sub.ftz.f32 	%f255, %f254, %f288;
	selp.f32 	%f256, 0f00000000, %f8, %p28;
	mov.f32 	%f257, 0fC0400000;
	max.ftz.f32 	%f258, %f257, %f294;
	mov.f32 	%f259, 0f40400000;
	min.ftz.f32 	%f260, %f259, %f258;
	mul.ftz.f32 	%f261, %f260, %f123;
	fma.rn.ftz.f32 	%f320, %f255, %f256, %f261;
	selp.f32 	%f262, 0f00000000, %f9, %p28;
	max.ftz.f32 	%f263, %f257, %f295;
	min.ftz.f32 	%f264, %f259, %f263;
	mul.ftz.f32 	%f265, %f264, %f123;
	fma.rn.ftz.f32 	%f321, %f255, %f262, %f265;
	selp.f32 	%f266, 0f00000000, %f10, %p28;
	max.ftz.f32 	%f267, %f257, %f296;
	min.ftz.f32 	%f268, %f259, %f267;
	mul.ftz.f32 	%f269, %f268, %f123;
	fma.rn.ftz.f32 	%f322, %f255, %f266, %f269;
	mul.ftz.f32 	%f270, %f321, %f321;
	fma.rn.ftz.f32 	%f271, %f320, %f320, %f270;
	fma.rn.ftz.f32 	%f272, %f322, %f322, %f271;
	sqrt.approx.ftz.f32 	%f98, %f272;
	setp.leu.ftz.f32 	%p29, %f98, 0f3CA3D70A;
	@%p29 bra 	$L__BB0_38;

	mov.f32 	%f273, 0f3CA3D70A;
	div.approx.ftz.f32 	%f274, %f273, %f98;
	mul.ftz.f32 	%f320, %f320, %f274;
	mul.ftz.f32 	%f321, %f321, %f274;
	mul.ftz.f32 	%f322, %f322, %f274;

$L__BB0_38:
	fma.rn.ftz.f32 	%f323, %f320, %f123, %f5;
	fma.rn.ftz.f32 	%f324, %f321, %f123, %f6;
	fma.rn.ftz.f32 	%f325, %f322, %f123, %f7;
	setp.lt.s32 	%p30, %r10, 11;
	setp.leu.ftz.f32 	%p31, %f125, 0f00000000;
	or.pred  	%p32, %p31, %p30;
	@%p32 bra 	$L__BB0_41;

	fma.rn.ftz.f32 	%f275, %f125, 0fBE99999A, %f125;
	abs.ftz.f32 	%f276, %f323;
	setp.gt.ftz.f32 	%p33, %f276, %f275;
	mul.ftz.f32 	%f277, %f320, 0f3F59999A;
	selp.f32 	%f320, %f277, %f320, %p33;
	mul.ftz.f32 	%f278, %f323, 0f3F6B851F;
	selp.f32 	%f323, %f278, %f323, %p33;
	abs.ftz.f32 	%f279, %f324;
	setp.gt.ftz.f32 	%p34, %f279, %f275;
	mul.ftz.f32 	%f280, %f321, 0f3F59999A;
	selp.f32 	%f321, %f280, %f321, %p34;
	mul.ftz.f32 	%f281, %f324, 0f3F6B851F;
	selp.f32 	%f324, %f281, %f324, %p34;
	abs.ftz.f32 	%f282, %f325;
	setp.leu.ftz.f32 	%p35, %f282, %f275;
	@%p35 bra 	$L__BB0_41;

	mul.ftz.f32 	%f325, %f325, 0f3F6B851F;
	mul.ftz.f32 	%f322, %f322, 0f3F59999A;

$L__BB0_41:
	st.global.f32 	[%rd2], %f323;
	st.global.f32 	[%rd2+4], %f324;
	st.global.f32 	[%rd2+8], %f325;
	st.global.f32 	[%rd2+12], %f320;
	st.global.f32 	[%rd2+16], %f321;
	st.global.f32 	[%rd2+20], %f322;
	setp.ne.s32 	%p36, %r1, 0;
	@%p36 bra 	$L__BB0_45;

	setp.gt.s32 	%p37, %r10, 4;
	mul.hi.s32 	%r18, %r10, 1717986919;
	shr.u32 	%r19, %r18, 31;
	shr.s32 	%r20, %r18, 3;
	add.s32 	%r21, %r20, %r19;
	mul.lo.s32 	%r22, %r21, 20;
	sub.s32 	%r23, %r10, %r22;
	setp.ne.s32 	%p38, %r23, 0;
	and.pred  	%p39, %p37, %p38;
	@%p39 bra 	$L__BB0_45;

	mul.ftz.f32 	%f283, %f295, %f295;
	fma.rn.ftz.f32 	%f284, %f294, %f294, %f283;
	fma.rn.ftz.f32 	%f285, %f296, %f296, %f284;
	sqrt.approx.ftz.f32 	%f286, %f285;
	cvt.ftz.f64.f32 	%fd3, %f286;
	mov.u32 	%r24, 0;
	st.local.u32 	[%rd5], %r24;
	st.local.f64 	[%rd5+8], %fd3;
	cvt.ftz.f64.f32 	%fd4, %f324;
	cvt.ftz.f64.f32 	%fd5, %f323;
	st.local.v2.f64 	[%rd5+16], {%fd5, %fd4};
	cvt.ftz.f64.f32 	%fd6, %f320;
	cvt.ftz.f64.f32 	%fd7, %f325;
	st.local.v2.f64 	[%rd5+32], {%fd7, %fd6};
	cvt.ftz.f64.f32 	%fd8, %f322;
	cvt.ftz.f64.f32 	%fd9, %f321;
	st.local.v2.f64 	[%rd5+48], {%fd9, %fd8};
	mov.u64 	%rd15, $str$1;
	cvta.global.u64 	%rd16, %rd15;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd16;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd11;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r25, [retval0+0];
	} // callseq 1
	@%p2 bra 	$L__BB0_45;

	st.local.v2.u32 	[%rd5], {%r24, %r10};
	cvt.ftz.f64.f32 	%fd10, %f287;
	st.local.f64 	[%rd5+8], %fd10;
	cvt.ftz.f64.f32 	%fd11, %f288;
	st.local.f64 	[%rd5+16], %fd11;
	mov.u64 	%rd18, $str$2;
	cvta.global.u64 	%rd19, %rd18;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd19;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd11;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r27, [retval0+0];
	} // callseq 2

$L__BB0_45:
	ret;

}


----
utils/tests/socket_flow_tests.rs
use crate::utils::socket_flow_messages::{Node, BinaryNodeData};
use crate::models::edge::Edge;
use crate::models::graph::GraphData;
use crate::utils::socket_flow_messages::{ServerMessage, ClientMessage, UpdatePositionsMessage};
use crate::AppState;

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_node_serialization() {
        // Create test node data
        let node_data = BinaryNodeData {
            position: [1.0, 2.0, 3.0],
            velocity: [0.1, 0.2, 0.3],
        };

        let node = Node {
            id: "test_node".to_string(),
            label: "Test Node".to_string(),
            data: node_data,
            metadata: Default::default(),
            file_size: 0,
            node_type: None,
            size: None,
            color: None,
            weight: None,
            group: None,
            user_data: None,
        };

        // Test serialization
        let serialized = serde_json::to_string(&node).unwrap();
        let deserialized: Node = serde_json::from_str(&serialized).unwrap();

        assert_eq!(node.id, deserialized.id);
        assert_eq!(node.data.position, deserialized.data.position);
        assert_eq!(node.data.velocity, deserialized.data.velocity);
    }

    #[test]
    fn test_binary_node_data() {
        // Create test nodes
        let node1_data = BinaryNodeData {
            position: [1.0, 2.0, 3.0],
            velocity: [0.1, 0.2, 0.3],
        };

        let node2_data = BinaryNodeData {
            position: [4.0, 5.0, 6.0],
            velocity: [0.4, 0.5, 0.6],
        };

        let nodes = vec![
            Node {
                id: "1".to_string(),
                label: "Node 1".to_string(),
                data: node1_data,
                metadata: Default::default(),
                file_size: 0,
                node_type: None,
                size: None,
                color: None,
                weight: None,
                group: None,
                user_data: None,
            },
            Node {
                id: "2".to_string(),
                label: "Node 2".to_string(),
                data: node2_data,
                metadata: Default::default(),
                file_size: 0,
                node_type: None,
                size: None,
                color: None,
                weight: None,
                group: None,
                user_data: None,
            },
        ];

        // Test binary conversion
        let binary_nodes: Vec<(u32, BinaryNodeData)> = nodes.iter()
            .map(|node| (
                node.id.parse::<u32>().unwrap(),
                node.data
            ))
            .collect();

        assert_eq!(binary_nodes.len(), 2);
        assert_eq!(binary_nodes[0].0, 1);
        assert_eq!(binary_nodes[0].1.position, [1.0, 2.0, 3.0]);
        assert_eq!(binary_nodes[0].1.velocity, [0.1, 0.2, 0.3]);
        assert_eq!(binary_nodes[1].0, 2);
        assert_eq!(binary_nodes[1].1.position, [4.0, 5.0, 6.0]);
        assert_eq!(binary_nodes[1].1.velocity, [0.4, 0.5, 0.6]);
    }
}

----
models/graph.rs
use crate::utils::socket_flow_messages::Node;
use super::edge::Edge;
use super::metadata::MetadataStore;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// Represents the graph data structure containing nodes, edges, and metadata.
/// All fields use camelCase serialization for client compatibility.
#[derive(Default, Serialize, Deserialize, Clone, Debug)]
#[serde(rename_all = "camelCase")]
pub struct GraphData {
    /// List of nodes in the graph.
    pub nodes: Vec<Node>,
    /// List of edges connecting the nodes.
    pub edges: Vec<Edge>,
    /// Metadata associated with the graph, using camelCase keys.
    pub metadata: MetadataStore,
    /// Mapping from numeric ID to metadata ID (filename) for lookup
    #[serde(skip)]
    pub id_to_metadata: HashMap<String, String>,
}

impl GraphData {
    pub fn new() -> Self {
        Self {
            nodes: Vec::new(),
            edges: Vec::new(),
            metadata: MetadataStore::new(),
            id_to_metadata: HashMap::new(),
        }
    }
}

----
models/node.rs
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::atomic::{AtomicU32, Ordering};
use crate::utils::socket_flow_messages::BinaryNodeData;
use crate::types::vec3::Vec3Data;

// Static counter for generating unique numeric IDs
static NEXT_NODE_ID: AtomicU32 = AtomicU32::new(1);  // Start from 1 (0 could be reserved)

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct Node {
    // Core data
    pub id: String,
    pub metadata_id: String,  // Store the original filename for lookup
    pub label: String,
    pub data: BinaryNodeData,

    // Metadata
    #[serde(skip_serializing_if = "HashMap::is_empty")]
    pub metadata: HashMap<String, String>,
    #[serde(skip)]
    pub file_size: u64,

    // Rendering properties
    #[serde(rename = "type")]
    #[serde(skip_serializing_if = "Option::is_none")]
    pub node_type: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub size: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub color: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub weight: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub group: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub user_data: Option<HashMap<String, String>>,
}

impl Node {
    pub fn new(metadata_id: String) -> Self {
        Self::new_with_id(metadata_id, None)
    }

    pub fn new_with_id(metadata_id: String, provided_id: Option<String>) -> Self {
        // Always generate a new ID on the server side
        // Use provided ID only if it's a valid numeric string (from a previous session)
        let id = match provided_id {
            Some(id) if !id.is_empty() && id != "0" && id.parse::<u32>().is_ok() => {
                // Use the provided ID only if it's a valid numeric ID
                id
            },
            _ => {
                NEXT_NODE_ID.fetch_add(1, Ordering::SeqCst).to_string()
            }
        };
        
        Self {
            id,
            metadata_id: metadata_id.clone(),
            label: String::new(), // Initialize as empty string, will be set from metadata later
            data: BinaryNodeData {
                position: Vec3Data::zero(),
                velocity: Vec3Data::zero(),
                mass: 0,
                flags: 1, // Active by default
                padding: [0, 0],
            },
            metadata: HashMap::new(),
            file_size: 0,
            node_type: None,
            size: None,
            color: None,
            weight: None,
            group: None,
            user_data: None,
        }
    }

    pub fn set_file_size(&mut self, size: u64) {
        self.file_size = size;
        // Calculate mass using log scale to prevent extremely large masses
        let base_mass = ((size + 1) as f32).log10() / 4.0;
        // Scale to 0-255 range for u8
        self.data.mass = ((base_mass.max(0.1).min(10.0) * 25.5) as u8).max(1);
    }

    pub fn with_position(mut self, x: f32, y: f32, z: f32) -> Self {
        self.data.position = Vec3Data::new(x, y, z);
        self
    }

    pub fn with_velocity(mut self, vx: f32, vy: f32, vz: f32) -> Self {
        self.data.velocity = Vec3Data::new(vx, vy, vz);
        self
    }

    pub fn with_label(mut self, label: String) -> Self {
        self.label = label;
        self
    }

    pub fn with_metadata(mut self, key: String, value: String) -> Self {
        self.metadata.insert(key, value);
        self
    }

    pub fn with_type(mut self, node_type: String) -> Self {
        self.node_type = Some(node_type);
        self
    }

    pub fn with_size(mut self, size: f32) -> Self {
        self.size = Some(size);
        self
    }

    pub fn with_color(mut self, color: String) -> Self {
        self.color = Some(color);
        self
    }

    pub fn with_weight(mut self, weight: f32) -> Self {
        self.weight = Some(weight);
        self
    }

    pub fn with_group(mut self, group: String) -> Self {
        self.group = Some(group);
        self
    }

    // Convenience getters/setters for position and velocity
    pub fn x(&self) -> f32 { self.data.position.x }
    pub fn y(&self) -> f32 { self.data.position.y }
    pub fn z(&self) -> f32 { self.data.position.z }
    pub fn vx(&self) -> f32 { self.data.velocity.x }
    pub fn vy(&self) -> f32 { self.data.velocity.y }
    pub fn vz(&self) -> f32 { self.data.velocity.z }
    
    pub fn set_x(&mut self, val: f32) { self.data.position.x = val; }
    pub fn set_y(&mut self, val: f32) { self.data.position.y = val; }
    pub fn set_z(&mut self, val: f32) { self.data.position.z = val; }
    pub fn set_vx(&mut self, val: f32) { self.data.velocity.x = val; }
    pub fn set_vy(&mut self, val: f32) { self.data.velocity.y = val; }
    pub fn set_vz(&mut self, val: f32) { self.data.velocity.z = val; }
}

#[cfg(test)]
mod tests {
    use std::sync::atomic::Ordering;
    use super::*;

    #[test]
    fn test_numeric_id_generation() {
        // Read the current value of the counter (it might have been incremented elsewhere)
        let start_value = NEXT_NODE_ID.load(Ordering::SeqCst);
        
        // Create two nodes with different metadata IDs
        let node1 = Node::new("test-file-1.md".to_string());
        let node2 = Node::new("test-file-2.md".to_string());
        
        // Verify each node has a unique numeric ID
        assert_ne!(node1.id, node2.id);
        
        // Verify metadata_id is stored correctly
        assert_eq!(node1.metadata_id, "test-file-1.md");
        assert_eq!(node2.metadata_id, "test-file-2.md");
        
        // Verify IDs are consecutive numbers (as strings)
        let id1: u32 = node1.id.parse().unwrap();
        let id2: u32 = node2.id.parse().unwrap();
        assert_eq!(id1 + 1, id2);
        
        // Verify final counter value
        let end_value = NEXT_NODE_ID.load(Ordering::SeqCst);
        assert_eq!(end_value, start_value + 2);
    }

    #[test]
    fn test_node_creation() {
        let node = Node::new("test".to_string())
            .with_label("Test Node".to_string())
            .with_position(1.0, 2.0, 3.0)
            .with_velocity(0.1, 0.2, 0.3)
            .with_type("test_type".to_string())
            .with_size(1.5)
            .with_color("#FF0000".to_string())
            .with_weight(2.0)
            .with_group("group1".to_string());

        // ID should be a numeric string now, not "test"
        assert!(node.id.parse::<u32>().is_ok(), "ID should be numeric, got: {}", node.id);
        assert_eq!(node.metadata_id, "test");
        assert_eq!(node.label, "Test Node");
        assert_eq!(node.data.position.x, 1.0);
        assert_eq!(node.data.position.y, 2.0);
        assert_eq!(node.data.position.z, 3.0);
        assert_eq!(node.data.velocity.x, 0.1);
        assert_eq!(node.data.velocity.y, 0.2);
        assert_eq!(node.data.velocity.z, 0.3);
        assert_eq!(node.node_type, Some("test_type".to_string()));
        assert_eq!(node.size, Some(1.5));
        assert_eq!(node.color, Some("#FF0000".to_string()));
        assert_eq!(node.weight, Some(2.0));
        assert_eq!(node.group, Some("group1".to_string()));
    }

    #[test]
    fn test_position_velocity_getters_setters() {
        let mut node = Node::new("test".to_string());
        
        node.set_x(1.0);
        node.set_y(2.0);
        node.set_z(3.0);
        node.set_vx(0.1);
        node.set_vy(0.2);
        node.set_vz(0.3);

        assert_eq!(node.x(), 1.0);
        assert_eq!(node.y(), 2.0);
        assert_eq!(node.z(), 3.0);
        assert_eq!(node.vx(), 0.1);
        assert_eq!(node.vy(), 0.2);
        assert_eq!(node.vz(), 0.3);
    }

    #[test]
    fn test_mass_calculation() {
        let mut node = Node::new("test".to_string());
        
        // Test small file
        node.set_file_size(100);  // 100 bytes
        assert!(node.data.mass > 0 && node.data.mass < 128);

        // Test large file
        node.set_file_size(1_000_000);  // 1MB
        assert!(node.data.mass > 128 && node.data.mass < 255);
    }
}

----
models/mod.rs
pub mod edge;
pub mod graph;
pub mod metadata;
pub mod node;
pub mod pagination;
pub mod protected_settings;
pub mod simulation_params;
pub mod ui_settings;
pub mod user_settings;
pub mod client_settings_payload; // Add new module

pub use metadata::MetadataStore;
pub use pagination::PaginationParams;
pub use protected_settings::ProtectedSettings;
pub use simulation_params::SimulationParams;
pub use ui_settings::UISettings;
pub use user_settings::UserSettings;

----
models/ui_settings.rs
use serde::{Deserialize, Serialize};
// Import the necessary structs from config
use crate::config::{
    AppFullSettings, // Use the full server settings struct
    ClientWebSocketSettings, // The structure expected by the client for websocket settings
    DebugSettings, 
    VisualisationSettings, 
    XRSettings,
    // Settings as ClientFacingSettings, // No longer needed for the From impl
};

// UISettings remains the structure sent to the client
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
#[serde(rename_all = "camelCase")]
pub struct UISettings {
    pub visualisation: VisualisationSettings,
    pub system: UISystemSettings,
    pub xr: XRSettings, // Assuming XRSettings structure is compatible enough for UI
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
#[serde(rename_all = "camelCase")]
pub struct UISystemSettings {
    // This must use the client-expected structure
    pub websocket: ClientWebSocketSettings, 
    pub debug: DebugSettings,
    // Note: persist_settings from client SystemSettings is not included here,
    // as it's likely not needed for direct UI rendering based on UISettings.
    // Add it if necessary.
}

// WebSocketClientSettings definition remains the same as it defines the client structure
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
#[serde(rename_all = "camelCase")]
pub struct WebSocketClientSettings {
    pub reconnect_attempts: u32,
    pub reconnect_delay: u64,
    pub binary_chunk_size: usize,
    pub compression_enabled: bool,
    pub compression_threshold: usize,
    pub update_rate: u32,
}

// Updated From implementation to convert from AppFullSettings
impl From<&AppFullSettings> for UISettings {
    fn from(settings: &AppFullSettings) -> Self {
        Self {
            visualisation: settings.visualisation.clone(),
            system: UISystemSettings {
                // Map fields from ServerFullWebSocketSettings to ClientWebSocketSettings
                websocket: ClientWebSocketSettings {
                    reconnect_attempts: settings.system.websocket.reconnect_attempts,
                    reconnect_delay: settings.system.websocket.reconnect_delay,
                    binary_chunk_size: settings.system.websocket.binary_chunk_size,
                    compression_enabled: settings.system.websocket.compression_enabled,
                    compression_threshold: settings.system.websocket.compression_threshold,
                    update_rate: settings.system.websocket.update_rate,
                },
                // Debug settings structure is assumed compatible
                debug: settings.system.debug.clone(), 
            },
            // XR settings structure is assumed compatible enough for UI purposes
            xr: settings.xr.clone(), 
        }
    }
}

// Commenting out merge_into_settings as the merge logic is now centralized
// in settings_handler.rs for better control, especially with AppFullSettings.
// impl UISettings {
//     pub fn merge_into_settings(&self, settings: &mut AppFullSettings) {
//         settings.visualisation = self.visualisation.clone();
//         // Careful mapping needed here, especially for websocket
//         let server_ws = &mut settings.system.websocket;
//         let ui_ws = &self.system.websocket;
//         server_ws.reconnect_attempts = ui_ws.reconnect_attempts;
//         server_ws.reconnect_delay = ui_ws.reconnect_delay;
//         server_ws.binary_chunk_size = ui_ws.binary_chunk_size;
//         server_ws.compression_enabled = ui_ws.compression_enabled;
//         server_ws.compression_threshold = ui_ws.compression_threshold;
//         server_ws.update_rate = ui_ws.update_rate;
//         // Other server_ws fields remain untouched by UISettings merge
        
//         settings.system.debug = self.system.debug.clone();
//         settings.xr = self.xr.clone();
//         // persist_settings? auth? AI settings? - Not part of UISettings merge
//     }
// }
----
models/metadata.rs
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// Stores metadata about a processed file.
/// All fields use camelCase serialization for client compatibility.
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
#[serde(rename_all = "camelCase")]
pub struct Metadata {
    #[serde(default)]
    pub file_name: String,
    #[serde(default)]
    pub file_size: usize,
    #[serde(default)]
    pub node_size: f64,
    #[serde(default)]
    pub hyperlink_count: usize,
    #[serde(default)]
    pub sha1: String,
    #[serde(default = "default_node_id")]
    pub node_id: String,
    #[serde(default = "Utc::now")]
    pub last_modified: DateTime<Utc>,
    #[serde(default)]
    pub perplexity_link: String,
    #[serde(default)]
    pub last_perplexity_process: Option<DateTime<Utc>>,
    #[serde(default)]
    pub topic_counts: HashMap<String, usize>,
}

// Default function for node_id to ensure backward compatibility
fn default_node_id() -> String {
    // Will be replaced with actual ID during processing
    "0".to_string()
}

/// Type alias for metadata storage with camelCase keys
pub type MetadataStore = HashMap<String, Metadata>;

// Implement helper methods directly on HashMap<String, Metadata>
pub trait MetadataOps {
    fn validate_files(&self, markdown_dir: &str) -> bool;
    fn get_max_node_id(&self) -> u32;
}

impl MetadataOps for MetadataStore {
    fn get_max_node_id(&self) -> u32 {
        // Find the maximum node_id in the metadata store
        self.values()
            .map(|m| m.node_id.parse::<u32>().unwrap_or(0))
            .max()
            .unwrap_or(0)
    }
    
    fn validate_files(&self, markdown_dir: &str) -> bool {
        if self.is_empty() {
            return false;
        }

        // Check if the markdown files referenced in metadata actually exist
        for filename in self.keys() {
            let file_path = format!("{}/{}", markdown_dir, filename);
            if !std::path::Path::new(&file_path).exists() {
                return false;
            }
        }
        
        true
    }
}

----
models/pagination.rs
use serde::{Deserialize, Serialize};
use crate::models::edge::Edge;
use crate::utils::socket_flow_messages::Node;

#[derive(Debug, Deserialize)]
pub struct PaginationParams {
    pub page: Option<u32>,
    pub page_size: Option<u32>,
}

#[derive(Debug, Serialize)]
pub struct PaginatedGraphData {
    pub nodes: Vec<Node>,
    pub edges: Vec<Edge>,
    pub total_pages: u32,
    pub current_page: u32,
    pub total_nodes: usize,
    pub total_edges: usize,
    pub metadata: serde_json::Value,
}

----
models/user_settings.rs
use serde::{Deserialize, Serialize};
use std::fs;
use std::path::PathBuf;
use std::sync::{Arc, RwLock};
use std::collections::HashMap;
use std::time::{Duration, Instant};
use log::{info, error, debug, warn};
use once_cell::sync::Lazy;

use crate::models::UISettings;

// Global cache for user settings
static USER_SETTINGS_CACHE: Lazy<Arc<RwLock<HashMap<String, CachedUserSettings>>>> = 
    Lazy::new(|| Arc::new(RwLock::new(HashMap::new())));

// Cache expiration time (10 minutes)
const CACHE_EXPIRATION: Duration = Duration::from_secs(10 * 60);

// Cache entry with timestamp
struct CachedUserSettings {
    settings: UserSettings,
    timestamp: Instant,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UserSettings {
    pub pubkey: String,
    pub settings: UISettings,
    pub last_modified: i64,
}

impl UserSettings {
    pub fn new(pubkey: &str, settings: UISettings) -> Self {
        Self {
            pubkey: pubkey.to_string(),
            settings,
            last_modified: chrono::Utc::now().timestamp(),
        }
    }

    pub fn load(pubkey: &str) -> Option<Self> {
        // First check the cache
        {
            let cache = USER_SETTINGS_CACHE.read().unwrap();
            if let Some(cached) = cache.get(pubkey) {
                // Check if cache is still valid
                if cached.timestamp.elapsed() < CACHE_EXPIRATION {
                    debug!("Using cached settings for user {}", pubkey);
                    return Some(cached.settings.clone());
                }
                // Cache expired, will reload from disk
                debug!("Cache expired for user {}, reloading from disk", pubkey);
            }
        }
        
        // Not in cache or expired, load from disk
        let path = Self::get_settings_path(pubkey);
        match fs::read_to_string(&path) {
            Ok(content) => {
                match serde_yaml::from_str::<UserSettings>(&content) {
                    Ok(settings) => {
                        // Add to cache
                        let settings_clone = settings.clone();
                        {
                            let mut cache = USER_SETTINGS_CACHE.write().unwrap();
                            cache.insert(pubkey.to_string(), CachedUserSettings {
                                settings: settings_clone,
                                timestamp: Instant::now(),
                            });
                        }
                        info!("Loaded settings for user {} and added to cache", pubkey);
                        Some(settings)
                    }
                    Err(e) => {
                        error!("Failed to parse settings for user {}: {}", pubkey, e);
                        None
                    }
                }
            }
            Err(e) => {
                debug!("No settings file found for user {}: {}", pubkey, e);
                None
            },
        }
    }

    pub fn save(&self) -> Result<(), String> {
        let path = Self::get_settings_path(&self.pubkey);
        
        // Update cache first (this is fast and ensures immediate availability)
        {
            let mut cache = USER_SETTINGS_CACHE.write().unwrap();
            cache.insert(self.pubkey.clone(), CachedUserSettings {
                settings: self.clone(),
                timestamp: Instant::now(),
            });
            debug!("Updated cache for user {}", self.pubkey);
        }
        
        // Ensure directory exists
        if let Some(parent) = path.parent() {
            if let Err(e) = fs::create_dir_all(parent) {
                warn!("Failed to create settings directory: {}", e);
                return Err(format!("Failed to create settings directory: {}", e));
            }
        }

        // Save settings to disk asynchronously to avoid blocking
        // For now we'll use a simple thread, but this could be improved with a proper async task
        let pubkey = self.pubkey.clone();
        let settings_clone = self.clone();
        
        std::thread::spawn(move || {
            debug!("Background thread saving settings for user {}", pubkey);
            match serde_yaml::to_string(&settings_clone) {
                Ok(yaml) => {
                    match fs::write(&path, yaml) {
                        Ok(_) => info!("Saved settings for user {} to disk", pubkey),
                        Err(e) => error!("Failed to write settings file for {}: {}", pubkey, e)
                    }
                }
                Err(e) => error!("Failed to serialize settings for {}: {}", pubkey, e),
            }
        });
        
        // Return success immediately since we've updated the cache
        Ok(())
    }

    fn get_settings_path(pubkey: &str) -> PathBuf {
        PathBuf::from("/app/user_settings").join(format!("{}.yaml", pubkey))
    }
    
    // Clear the cache entry for a specific user
    pub fn clear_cache(pubkey: &str) {
        let mut cache = USER_SETTINGS_CACHE.write().unwrap();
        if cache.remove(pubkey).is_some() {
            debug!("Cleared cache for user {}", pubkey);
        }
    }
    
    // Clear all cached settings
    pub fn clear_all_cache() {
        let mut cache = USER_SETTINGS_CACHE.write().unwrap();
        let count = cache.len();
        cache.clear();
        debug!("Cleared all cached settings ({} entries)", count);
    }
}
----
models/edge.rs
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// Edge structure representing connections between nodes
#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct Edge {
    pub source: String,
    pub target: String,
    pub weight: f32,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub edge_type: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub metadata: Option<HashMap<String, String>>,
}

impl Edge {
    pub fn new(source: String, target: String, weight: f32) -> Self {
        Self {
            source,
            target,
            weight,
            edge_type: None,
            metadata: None,
        }
    }
}

----
models/client_settings_payload.rs
use serde::Deserialize;

// Consistent camelCase for client JSON interaction

// --- MovementAxes DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientMovementAxes {
    pub horizontal: Option<i32>,
    pub vertical: Option<i32>,
}

// --- XR Settings DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientXRSettings {
    pub enabled: Option<bool>,
    pub mode: Option<String>, // Maps to client's displayMode or server's mode
    pub room_scale: Option<f32>,
    pub space_type: Option<String>,
    pub quality: Option<String>,
    
    pub enable_hand_tracking: Option<bool>, // Mapped from client's handTracking
    pub hand_mesh_enabled: Option<bool>,
    pub hand_mesh_color: Option<String>,
    pub hand_mesh_opacity: Option<f32>,
    pub hand_point_size: Option<f32>,
    pub hand_ray_enabled: Option<bool>,
    pub hand_ray_color: Option<String>,
    pub hand_ray_width: Option<f32>,
    
    pub gesture_smoothing: Option<f32>,
    pub enable_haptics: Option<bool>, // Mapped from client's enableHaptics
    
    pub drag_threshold: Option<f32>,
    pub pinch_threshold: Option<f32>,
    pub rotation_threshold: Option<f32>,
    
    pub interaction_radius: Option<f32>, // Mapped from client's interactionDistance
    
    pub movement_speed: Option<f32>,
    pub dead_zone: Option<f32>,
    pub movement_axes: Option<ClientMovementAxes>,
    
    pub enable_light_estimation: Option<bool>,
    pub enable_plane_detection: Option<bool>,
    pub enable_scene_understanding: Option<bool>,
    pub plane_color: Option<String>,
    pub plane_opacity: Option<f32>,
    pub plane_detection_distance: Option<f32>,
    pub show_plane_overlay: Option<bool>,
    pub snap_to_floor: Option<bool>,
    
    pub enable_passthrough_portal: Option<bool>,
    pub passthrough_opacity: Option<f32>,
    pub passthrough_brightness: Option<f32>,
    pub passthrough_contrast: Option<f32>,
    pub portal_size: Option<f32>,
    pub portal_edge_color: Option<String>,
    pub portal_edge_width: Option<f32>,

    pub controller_model: Option<String>,   // Mapped from client's controllerModel
    pub render_scale: Option<f32>,          // Mapped from client's renderScale
    pub locomotion_method: Option<String>,  // Mapped from client's locomotionMethod
    pub teleport_ray_color: Option<String>, // Mapped from client's teleportRayColor
    pub controller_ray_color: Option<String>,// Mapped from client's controllerRayColor
    // Note: client's 'displayMode' should map to 'mode' in this DTO.
}

// --- Node Settings DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientNodeSettings {
    pub base_color: Option<String>,
    pub metalness: Option<f32>,
    pub opacity: Option<f32>,
    pub roughness: Option<f32>,
    pub size_range: Option<Vec<f32>>, // Client sends [number, number]
    pub quality: Option<String>, // "low" | "medium" | "high"
    pub enable_instancing: Option<bool>,
    pub enable_hologram: Option<bool>,
    pub enable_metadata_shape: Option<bool>,
    pub enable_metadata_visualisation: Option<bool>,
}

// --- Edge Settings DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientEdgeSettings {
    pub arrow_size: Option<f32>,
    pub base_width: Option<f32>,
    pub color: Option<String>,
    pub enable_arrows: Option<bool>,
    pub opacity: Option<f32>,
    pub width_range: Option<Vec<f32>>, // Client sends [number, number]
    pub quality: Option<String>, // "low" | "medium" | "high"
    // Fields from client's EdgeSettings not in server's EdgeSettings (src/config/mod.rs)
    // These will be deserialized if present in JSON due to no deny_unknown_fields
    // but won't map to AppFullSettings unless explicitly handled.
    pub enable_flow_effect: Option<bool>, 
    pub flow_speed: Option<f32>,
    pub flow_intensity: Option<f32>,
    pub glow_strength: Option<f32>,
    pub distance_intensity: Option<f32>,
    pub use_gradient: Option<bool>,
    pub gradient_colors: Option<Vec<String>>, // Client sends [string, string]
}

// --- Physics Settings DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientPhysicsSettings {
    pub attraction_strength: Option<f32>,
    pub bounds_size: Option<f32>,
    pub collision_radius: Option<f32>,
    pub damping: Option<f32>,
    pub enable_bounds: Option<bool>,
    pub enabled: Option<bool>,
    pub iterations: Option<u32>,
    pub max_velocity: Option<f32>,
    pub repulsion_strength: Option<f32>,
    pub spring_strength: Option<f32>,
    pub repulsion_distance: Option<f32>,
    pub mass_scale: Option<f32>,
    pub boundary_damping: Option<f32>,
}

// --- Rendering Settings DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientRenderingSettings {
    pub ambient_light_intensity: Option<f32>,
    pub background_color: Option<String>,
    pub directional_light_intensity: Option<f32>,
    pub enable_ambient_occlusion: Option<bool>,
    pub enable_antialiasing: Option<bool>,
    pub enable_shadows: Option<bool>,
    pub environment_intensity: Option<f32>,
    // Fields from client's RenderingSettings not in server's (src/config/mod.rs)
    pub shadow_map_size: Option<String>, 
    pub shadow_bias: Option<f32>,
    pub context: Option<String>, // "desktop" | "ar"
}

// --- Animation Settings DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientAnimationSettings {
    pub enable_motion_blur: Option<bool>,
    pub enable_node_animations: Option<bool>,
    pub motion_blur_strength: Option<f32>,
    pub selection_wave_enabled: Option<bool>,
    pub pulse_enabled: Option<bool>,
    pub pulse_speed: Option<f32>,
    pub pulse_strength: Option<f32>,
    pub wave_speed: Option<f32>,
}

// --- Label Settings DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientLabelSettings {
    pub desktop_font_size: Option<f32>,
    pub enable_labels: Option<bool>,
    pub text_color: Option<String>,
    pub text_outline_color: Option<String>,
    pub text_outline_width: Option<f32>,
    pub text_resolution: Option<u32>,
    pub text_padding: Option<f32>,
    pub billboard_mode: Option<String>, // "camera" | "vertical" (client) vs "camera" | "fixed" | "horizontal" (server, needs mapping)
}

// --- Bloom Settings DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientBloomSettings {
    pub edge_bloom_strength: Option<f32>,
    pub enabled: Option<bool>,
    pub environment_bloom_strength: Option<f32>,
    pub node_bloom_strength: Option<f32>,
    pub radius: Option<f32>,
    pub strength: Option<f32>,
    // Field from client's BloomSettings not in server's (src/config/mod.rs)
    pub threshold: Option<f32>,
}

// --- Hologram Settings DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientHologramSettings {
    pub ring_count: Option<u32>,
    pub ring_color: Option<String>,
    pub ring_opacity: Option<f32>,
    pub sphere_sizes: Option<Vec<f32>>, // Client sends [number, number]
    pub ring_rotation_speed: Option<f32>,
    pub enable_buckminster: Option<bool>,
    pub buckminster_size: Option<f32>,
    pub buckminster_opacity: Option<f32>,
    pub enable_geodesic: Option<bool>,
    pub geodesic_size: Option<f32>,
    pub geodesic_opacity: Option<f32>,
    pub enable_triangle_sphere: Option<bool>,
    pub triangle_sphere_size: Option<f32>,
    pub triangle_sphere_opacity: Option<f32>,
    pub global_rotation_speed: Option<f32>,
}

// --- Camera Settings DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientCameraPosition {
    pub x: Option<f32>,
    pub y: Option<f32>,
    pub z: Option<f32>,
}
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientCameraSettings {
    pub fov: Option<f32>,
    pub near: Option<f32>,
    pub far: Option<f32>,
    pub position: Option<ClientCameraPosition>,
    pub look_at: Option<ClientCameraPosition>,
}


// --- Visualisation Settings DTO (Aggregator) ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientVisualisationSettings {
    pub nodes: Option<ClientNodeSettings>,
    pub edges: Option<ClientEdgeSettings>,
    pub physics: Option<ClientPhysicsSettings>,
    pub rendering: Option<ClientRenderingSettings>,
    pub animations: Option<ClientAnimationSettings>,
    pub labels: Option<ClientLabelSettings>,
    pub bloom: Option<ClientBloomSettings>,
    pub hologram: Option<ClientHologramSettings>,
    pub camera: Option<ClientCameraSettings>, // Client can send camera settings
}

// --- WebSocket Settings DTO (from client/src/features/settings/config/settings.ts) ---
// This can reuse src/config/mod.rs::ClientWebSocketSettings if it's identical
// For clarity, defining it here based on client's definition.
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientPayloadWebSocketSettings {
    pub reconnect_attempts: Option<u32>,
    pub reconnect_delay: Option<u64>, // TS number can be u64
    pub binary_chunk_size: Option<usize>, // TS number can be usize
    pub compression_enabled: Option<bool>,
    pub compression_threshold: Option<usize>,
    pub update_rate: Option<u32>,
}

// --- Debug Settings DTO (from client/src/features/settings/config/settings.ts) ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientPayloadDebugSettings {
    pub enabled: Option<bool>,
    pub enable_data_debug: Option<bool>,
    pub enable_websocket_debug: Option<bool>,
    pub log_binary_headers: Option<bool>,
    pub log_full_json: Option<bool>,
    // Fields from client's DebugSettings not in server's DebugSettings (src/config/mod.rs)
    pub enable_physics_debug: Option<bool>, 
    pub enable_node_debug: Option<bool>,
    pub enable_shader_debug: Option<bool>,
    pub enable_matrix_debug: Option<bool>,
    pub enable_performance_debug: Option<bool>,
    // Note: log_level and log_format are server-side only, not expected from client payload.
}

// --- System Settings DTO (Aggregator) ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientSystemSettings {
    pub websocket: Option<ClientPayloadWebSocketSettings>,
    pub debug: Option<ClientPayloadDebugSettings>,
    pub persist_settings: Option<bool>,
    pub custom_backend_url: Option<String>,
}

// --- Auth Settings DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientAuthSettings {
    pub enabled: Option<bool>,
    pub provider: Option<String>, // "nostr" | string
    pub required: Option<bool>,
}

// --- AI Service Settings DTOs ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientRagFlowSettings {
    pub api_key: Option<String>,
    pub agent_id: Option<String>,
    pub api_base_url: Option<String>,
    pub timeout: Option<u64>, // TS number
    pub max_retries: Option<u32>, // TS number
    pub chat_id: Option<String>,
}

#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientPerplexitySettings {
    pub api_key: Option<String>,
    pub model: Option<String>,
    pub api_url: Option<String>,
    pub max_tokens: Option<u32>,
    pub temperature: Option<f32>,
    pub top_p: Option<f32>,
    pub presence_penalty: Option<f32>,
    pub frequency_penalty: Option<f32>,
    pub timeout: Option<u64>,
    pub rate_limit: Option<u32>,
}

#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientOpenAISettings {
    pub api_key: Option<String>,
    pub base_url: Option<String>,
    pub timeout: Option<u64>,
    pub rate_limit: Option<u32>,
}

#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientKokoroSettings {
    pub api_url: Option<String>,
    pub default_voice: Option<String>,
    pub default_format: Option<String>,
    pub default_speed: Option<f32>,
    pub timeout: Option<u64>,
    pub stream: Option<bool>,
    pub return_timestamps: Option<bool>,
    pub sample_rate: Option<u32>,
}


// --- Top-Level Client Settings Payload DTO ---
#[derive(Deserialize, Debug, Default, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientSettingsPayload {
    pub visualisation: Option<ClientVisualisationSettings>,
    pub system: Option<ClientSystemSettings>,
    pub xr: Option<ClientXRSettings>,
    pub auth: Option<ClientAuthSettings>,
    pub ragflow: Option<ClientRagFlowSettings>,
    pub perplexity: Option<ClientPerplexitySettings>,
    pub openai: Option<ClientOpenAISettings>,
    pub kokoro: Option<ClientKokoroSettings>,
}
----
models/simulation_params.rs
use serde::{Deserialize, Serialize};
use bytemuck::{Pod, Zeroable};

#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "camelCase")]
pub enum SimulationMode {
    Remote,  // GPU-accelerated remote computation (default)
    GPU,     // Local GPU computation (deprecated)
    Local,   // CPU-based computation (disabled)
}

impl Default for SimulationMode {
    fn default() -> Self {
        SimulationMode::Remote
    }
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "camelCase")]
pub enum SimulationPhase {
    Initial,    // Heavy computation for initial layout
    Dynamic,    // Lighter computation for dynamic updates
    Finalize,   // Final positioning and cleanup
}

impl Default for SimulationPhase {
    fn default() -> Self {
        SimulationPhase::Initial
    }
}

// GPU-compatible simulation parameters
#[repr(C)]
#[derive(Default, Clone, Copy, Pod, Zeroable, Debug)]
pub struct GPUSimulationParams {
    pub iterations: u32,
    pub spring_strength: f32,
    pub repulsion: f32,
    pub damping: f32,
    pub max_repulsion_distance: f32,
    pub viewport_bounds: f32,
    pub mass_scale: f32,
    pub boundary_damping: f32,
}

#[derive(Default, Serialize, Deserialize, Clone, Debug)]
#[serde(rename_all = "camelCase")]
pub struct SimulationParams {
    // Core iteration parameters
    pub iterations: u32,           // Range: 1-500, Default: varies by phase
    pub time_step: f32,           // Range: 0.01-1, Default: 0.2 (5fps)
    
    // Force parameters
    pub spring_strength: f32,      // Range: 0.1-10, Default: 0.5
    pub repulsion: f32,           // Default: 100
    pub max_repulsion_distance: f32, // Default: 500
    
    // Mass and damping
    pub mass_scale: f32,          // Default: 1.0, Affects force scaling
    pub damping: f32,             // Range: 0-1, Default: 0.5
    pub boundary_damping: f32,    // Range: 0.5-1, Default: 0.9
    
    // Boundary control
    pub viewport_bounds: f32,     // Range: 100-5000, Default: 1000
    pub enable_bounds: bool,      // Default: true
    
    // Simulation state
    pub phase: SimulationPhase,   // Current simulation phase
    pub mode: SimulationMode,     // Computation mode
}

impl SimulationParams {
    pub fn new() -> Self {
        Self {
            iterations: 100,
            time_step: 0.2,
            spring_strength: 0.5,
            repulsion: 100.0,
            max_repulsion_distance: 500.0,
            mass_scale: 1.0,
            damping: 0.5,
            boundary_damping: 0.9,
            viewport_bounds: 1000.0,
            enable_bounds: true,
            phase: SimulationPhase::Initial,
            mode: SimulationMode::Remote,
        }
    }

    pub fn with_phase(phase: SimulationPhase) -> Self {
        match phase {
            SimulationPhase::Initial => Self {
                iterations: 300,
                time_step: 0.2,
                spring_strength: 0.3,      // Reduced for initial spread
                repulsion: 200.0,          // Increased for better separation
                max_repulsion_distance: 800.0, // Larger range for initial layout
                mass_scale: 1.2,           // Slightly higher mass influence
                damping: 0.95,             // High damping for stability
                boundary_damping: 0.95,
                viewport_bounds: 1000.0,
                enable_bounds: true,
                phase,
                mode: SimulationMode::Remote,
            },
            SimulationPhase::Dynamic => Self {
                iterations: 50,
                time_step: 0.2,
                spring_strength: 0.5,
                repulsion: 100.0,
                max_repulsion_distance: 500.0,
                mass_scale: 1.0,
                damping: 0.5,
                boundary_damping: 0.9,
                viewport_bounds: 1000.0,
                enable_bounds: true,
                phase,
                mode: SimulationMode::Remote,
            },
            SimulationPhase::Finalize => Self {
                iterations: 200,
                time_step: 0.2,
                spring_strength: 0.1,      // Minimal spring forces
                repulsion: 50.0,           // Reduced repulsion
                max_repulsion_distance: 300.0, // Tighter packing
                mass_scale: 0.8,           // Reduced mass influence
                damping: 0.95,             // High damping for stability
                boundary_damping: 0.95,
                viewport_bounds: 1000.0,
                enable_bounds: true,
                phase,
                mode: SimulationMode::Remote,
            },
        }
    }

    // Convert to GPU-compatible parameters
    pub fn to_gpu_params(&self) -> GPUSimulationParams {
        GPUSimulationParams {
            iterations: self.iterations,
            spring_strength: self.spring_strength,
            repulsion: self.repulsion,
            damping: self.damping,
            max_repulsion_distance: self.max_repulsion_distance,
            viewport_bounds: if self.enable_bounds { self.viewport_bounds } else { 0.0 },
            mass_scale: self.mass_scale,
            boundary_damping: self.boundary_damping,
        }
    }
}

----
models/protected_settings.rs
use serde::{Deserialize, Serialize};
use chrono::Utc;

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ApiKeys {
    pub perplexity: Option<String>,
    pub openai: Option<String>,
    pub ragflow: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct NostrUser {
    pub pubkey: String,
    pub npub: String,
    pub is_power_user: bool,
    pub api_keys: ApiKeys,
    pub last_seen: i64,
    pub session_token: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ProtectedSettings {
    pub network: NetworkSettings,
    pub security: SecuritySettings,
    pub websocket_server: WebSocketServerSettings,
    pub users: std::collections::HashMap<String, NostrUser>,
    pub default_api_keys: ApiKeys,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct NetworkSettings {
    pub bind_address: String,
    pub domain: String,
    pub port: u16,
    pub enable_http2: bool,
    pub enable_tls: bool,
    pub min_tls_version: String,
    pub max_request_size: usize,
    pub enable_rate_limiting: bool,
    pub rate_limit_requests: u32,
    pub rate_limit_window: u32,
    pub tunnel_id: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct SecuritySettings {
    pub allowed_origins: Vec<String>,
    pub audit_log_path: String,
    pub cookie_httponly: bool,
    pub cookie_samesite: String,
    pub cookie_secure: bool,
    pub csrf_token_timeout: u32,
    pub enable_audit_logging: bool,
    pub enable_request_validation: bool,
    pub session_timeout: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct WebSocketServerSettings {
    pub max_connections: usize,
    pub max_message_size: usize,
    pub url: String,
}

impl Default for ApiKeys {
    fn default() -> Self {
        Self {
            perplexity: None,
            openai: None,
            ragflow: None,
        }
    }
}

impl Default for ProtectedSettings {
    fn default() -> Self {
        Self {
            network: NetworkSettings {
                bind_address: "127.0.0.1".to_string(),
                domain: "localhost".to_string(),
                port: 3000,
                enable_http2: true,
                enable_tls: false,
                min_tls_version: "TLS1.2".to_string(),
                max_request_size: 10 * 1024 * 1024, // 10MB
                enable_rate_limiting: true,
                rate_limit_requests: 100,
                rate_limit_window: 60,
                tunnel_id: String::new(),
            },
            security: SecuritySettings {
                allowed_origins: vec!["http://localhost:3000".to_string()],
                audit_log_path: "./audit.log".to_string(),
                cookie_httponly: true,
                cookie_samesite: "Lax".to_string(),
                cookie_secure: false,
                csrf_token_timeout: 3600,
                enable_audit_logging: true,
                enable_request_validation: true,
                session_timeout: 86400,
            },
            websocket_server: WebSocketServerSettings {
                max_connections: 100,
                max_message_size: 32 * 1024 * 1024, // 32MB
                url: String::new(),
            },
            users: std::collections::HashMap::new(),
            default_api_keys: ApiKeys::default(),
        }
    }
}

impl ProtectedSettings {
    pub fn merge(&mut self, other: serde_json::Value) -> Result<(), String> {
        if let Some(network) = other.get("network") {
            if let Ok(network_settings) = serde_json::from_value(network.clone()) {
                self.network = network_settings;
            }
        }

        if let Some(security) = other.get("security") {
            if let Ok(security_settings) = serde_json::from_value(security.clone()) {
                self.security = security_settings;
            }
        }

        if let Some(websocket) = other.get("websocketServer") {
            if let Ok(websocket_settings) = serde_json::from_value(websocket.clone()) {
                self.websocket_server = websocket_settings;
            }
        }

        if let Some(users) = other.get("users") {
            if let Ok(user_settings) = serde_json::from_value(users.clone()) {
                self.users = user_settings;
            }
        }

        if let Some(api_keys) = other.get("defaultApiKeys") {
            if let Ok(keys) = serde_json::from_value(api_keys.clone()) {
                self.default_api_keys = keys;
            }
        }

        Ok(())
    }

    pub fn get_api_keys(&self, pubkey: &str) -> ApiKeys {
        if let Some(user) = self.users.get(pubkey) {
            if user.is_power_user {
                // Power users get environment-based keys
                ApiKeys {
                    perplexity: std::env::var("PERPLEXITY_API_KEY").ok(),
                    openai: std::env::var("OPENAI_API_KEY").ok(),
                    ragflow: std::env::var("RAGFLOW_API_KEY").ok(),
                }
            } else {
                // Normal users get their stored keys
                user.api_keys.clone()
            }
        } else {
            // Default keys for unauthenticated users
            self.default_api_keys.clone()
        }
    }

    pub fn validate_client_token(&self, pubkey: &str, token: &str) -> bool {
        if let Some(user) = self.users.get(pubkey) {
            if let Some(session_token) = &user.session_token {
                return session_token == token;
            }
        }
        false
    }

    pub fn store_client_token(&mut self, pubkey: String, token: String) {
        if let Some(user) = self.users.get_mut(&pubkey) {
            user.session_token = Some(token);
            user.last_seen = Utc::now().timestamp();
        }
    }

    pub fn cleanup_expired_tokens(&mut self, max_age_hours: i64) {
        let now = Utc::now().timestamp();
        let max_age_secs = max_age_hours * 3600;
        
        self.users.retain(|_, user| {
            now - user.last_seen < max_age_secs
        });
    }

    pub fn update_user_api_keys(&mut self, pubkey: &str, api_keys: ApiKeys) -> Result<NostrUser, String> {
        if let Some(user) = self.users.get_mut(pubkey) {
            if !user.is_power_user {
                user.api_keys = api_keys;
                user.last_seen = Utc::now().timestamp();
                Ok(user.clone())
            } else {
                Err("Cannot update API keys for power users".to_string())
            }
        } else {
            Err("User not found".to_string())
        }
    }

    pub fn load(path: &str) -> Result<Self, String> {
        let content = std::fs::read_to_string(path)
            .map_err(|e| format!("Failed to read protected settings: {}", e))?;
        
        serde_json::from_str(&content)
            .map_err(|e| format!("Failed to parse protected settings: {}", e))
    }

    pub fn save(&self, path: &str) -> Result<(), String> {
        let content = serde_json::to_string_pretty(self)
            .map_err(|e| format!("Failed to serialize protected settings: {}", e))?;
        
        std::fs::write(path, content)
            .map_err(|e| format!("Failed to write protected settings: {}", e))
    }
}
----
handlers/settings_handler.rs
use crate::app_state::AppState;
use crate::models::{UISettings, UserSettings};
use crate::config::AppFullSettings; // Removed ClientFacingSettings alias
use crate::models::client_settings_payload::*; // Import all DTOs
// use crate::handlers::socket_flow_handler::ClientManager;
use actix_web::{web, Error, HttpResponse, HttpRequest};
use chrono::Utc;
use serde_json::json;
use crate::config::feature_access::FeatureAccess;
use log::{info, error, warn, debug};
use std::time::Instant;

// Helper function to convert AppFullSettings to UISettings (requires From impl update)
// This assumes the From impl is updated in models/ui_settings.rs
fn convert_to_ui_settings(full_settings: &AppFullSettings) -> UISettings {
    UISettings::from(full_settings) // Rely on the From trait implementation
}

// --- Helper Macros for Merging Settings ---

// Helper macro for merging Option fields
// Assigns source value (wrapped in Some) to target if source is Some.
macro_rules! merge_copy_option {
    ($target:expr, $source:expr) => {
        if let Some(value_ref) = $source.as_ref() {
            $target = *value_ref; // For Copy types
        }
    };
}

macro_rules! merge_clone_option {
    ($target:expr, $source:expr) => {
        if let Some(value_ref) = $source.as_ref() {
            $target = value_ref.clone(); // For Clone types
        }
    };
}

// --- Cache Clearing Endpoints (Unaffected by Settings struct changes) ---

async fn clear_user_settings_cache(
    req: HttpRequest,
    feature_access: web::Data<FeatureAccess>
) -> Result<HttpResponse, Error> {
    let pubkey = match req.headers().get("X-Nostr-Pubkey") {
        Some(value) => value.to_str().unwrap_or("").to_string(),
        None => {
            warn!("Missing Nostr pubkey in request headers");
            return Ok(HttpResponse::BadRequest().body("Missing Nostr pubkey"));
        }
    };
    if !feature_access.can_sync_settings(&pubkey) {
        warn!("User {} attempted to clear settings cache without permission", pubkey);
        return Ok(HttpResponse::Forbidden().body("Settings sync not enabled for this user"));
    }
    UserSettings::clear_cache(&pubkey);
    info!("Cleared settings cache for user {}", pubkey);
    Ok(HttpResponse::Ok().json(json!({ "status": "success", "message": "Settings cache cleared" })))
}

async fn clear_all_settings_cache(
    req: HttpRequest,
    feature_access: web::Data<FeatureAccess>
) -> Result<HttpResponse, Error> {
    let pubkey = match req.headers().get("X-Nostr-Pubkey") {
        Some(value) => value.to_str().unwrap_or("").to_string(),
        None => {
            warn!("Missing Nostr pubkey in request headers");
            return Ok(HttpResponse::BadRequest().body("Missing Nostr pubkey"));
        }
    };
    if !feature_access.is_power_user(&pubkey) {
        warn!("Non-power user {} attempted to clear all settings caches", pubkey);
        return Ok(HttpResponse::Forbidden().body("Only power users can clear all settings caches"));
    }
    UserSettings::clear_all_cache();
    info!("Power user {} cleared all settings caches", pubkey);
    Ok(HttpResponse::Ok().json(json!({ "status": "success", "message": "All settings caches cleared" })))
}

// --- Configuration ---

pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::resource("/user-settings")
            .route(web::get().to(get_public_settings))
            .route(web::post().to(update_settings))
    ).service(
        web::resource("/user-settings/sync")
            .route(web::get().to(get_user_settings))
            .route(web::post().to(update_user_settings)) // This now points to the updated function
    ).service(
        web::resource("/user-settings/clear-cache")
            .route(web::post().to(clear_user_settings_cache))
    ).service(
        web::resource("/admin/settings/clear-all-cache")
            .route(web::post().to(clear_all_settings_cache))
    );
}

// --- GET Endpoints ---

pub async fn get_public_settings(state: web::Data<AppState>) -> Result<HttpResponse, Error> {
    let settings_guard = state.settings.read().await;
    let ui_settings = convert_to_ui_settings(&*settings_guard);
    Ok(HttpResponse::Ok().json(&ui_settings))
}

async fn get_user_settings(
    req: HttpRequest,
    state: web::Data<AppState>,
    feature_access: web::Data<FeatureAccess>
) -> Result<HttpResponse, Error> {
    let start_time = Instant::now();
    let pubkey = match req.headers().get("X-Nostr-Pubkey") {
        Some(value) => value.to_str().unwrap_or("").to_string(),
        None => {
            warn!("Missing Nostr pubkey in request headers for get_user_settings");
            return Ok(HttpResponse::BadRequest().body("Missing Nostr pubkey"));
        }
    };
    debug!("Processing get_user_settings request for user: {}", pubkey);

    if !feature_access.can_sync_settings(&pubkey) {
        warn!("User {} attempted get_user_settings without permission", pubkey);
        return Ok(HttpResponse::Forbidden().body("Settings sync not enabled for this user"));
    }

    let is_power_user = feature_access.is_power_user(&pubkey);
    let result;

    if is_power_user {
        let settings_guard = state.settings.read().await;
        let ui_settings = convert_to_ui_settings(&*settings_guard);
        debug!("Returning global UI settings for power user {}", pubkey);
        result = Ok(HttpResponse::Ok().json(ui_settings));
    } else {
        let user_settings = UserSettings::load(&pubkey).unwrap_or_else(|| {
            debug!("Creating new user settings for {} with default settings", pubkey);
            UserSettings::new(&pubkey, UISettings::default())
        });
        result = Ok(HttpResponse::Ok().json(&user_settings.settings));
    }

    let elapsed = start_time.elapsed();
    debug!("Settings request for {} processed in {:?}", pubkey, elapsed);
    result
}

// --- POST Endpoints ---

// Handles updates from the main settings UI (/user-settings/sync)
async fn update_user_settings(
    req: HttpRequest,
    state: web::Data<AppState>,
    feature_access: web::Data<FeatureAccess>,
    payload: web::Json<ClientSettingsPayload>, // Use the new DTO
) -> Result<HttpResponse, Error> {
    let _start_time = Instant::now(); // Prefixed with underscore
    let client_payload = payload.into_inner();

    debug!("Received client settings payload: {:?}", client_payload);

    let pubkey = match req.headers().get("X-Nostr-Pubkey") {
        Some(value) => value.to_str().unwrap_or("").to_string(),
        None => {
            warn!("Update settings request received without Nostr pubkey.");
            return Ok(HttpResponse::BadRequest().body("Missing Nostr pubkey for settings update"));
        }
    };
    debug!("Processing update_user_settings for user: {}", pubkey);

    if !feature_access.can_sync_settings(&pubkey) {
        warn!("User {} attempted update_user_settings without permission", pubkey);
        return Ok(HttpResponse::Forbidden().body("Settings sync not enabled for this user"));
    }

    let is_power_user = feature_access.is_power_user(&pubkey);

    if is_power_user {
        let mut settings_guard = state.settings.write().await; // AppFullSettings

        // --- Merge from ClientSettingsPayload DTO into AppFullSettings ---
        // Macros are now defined at module level

        if let Some(vis_dto) = client_payload.visualisation {
            let target_vis = &mut settings_guard.visualisation;
            if let Some(nodes_dto) = vis_dto.nodes {
                merge_clone_option!(target_vis.nodes.base_color, nodes_dto.base_color);
                merge_copy_option!(target_vis.nodes.metalness, nodes_dto.metalness);
                merge_copy_option!(target_vis.nodes.opacity, nodes_dto.opacity);
                merge_copy_option!(target_vis.nodes.roughness, nodes_dto.roughness);
                merge_clone_option!(target_vis.nodes.size_range, nodes_dto.size_range);
                merge_clone_option!(target_vis.nodes.quality, nodes_dto.quality);
                merge_copy_option!(target_vis.nodes.enable_instancing, nodes_dto.enable_instancing);
                merge_copy_option!(target_vis.nodes.enable_hologram, nodes_dto.enable_hologram);
                merge_copy_option!(target_vis.nodes.enable_metadata_shape, nodes_dto.enable_metadata_shape);
                merge_copy_option!(target_vis.nodes.enable_metadata_visualisation, nodes_dto.enable_metadata_visualisation);
            }
            if let Some(edges_dto) = vis_dto.edges {
                let target_edges = &mut target_vis.edges;
                merge_copy_option!(target_edges.arrow_size, edges_dto.arrow_size);
                merge_copy_option!(target_edges.base_width, edges_dto.base_width);
                merge_clone_option!(target_edges.color, edges_dto.color);
                merge_copy_option!(target_edges.enable_arrows, edges_dto.enable_arrows);
                merge_copy_option!(target_edges.opacity, edges_dto.opacity);
                merge_clone_option!(target_edges.width_range, edges_dto.width_range);
                merge_clone_option!(target_edges.quality, edges_dto.quality);
                // Note: ClientEdgeSettings DTO has extra fields not in server's EdgeSettings.
                // They are ignored here as AppFullSettings.visualisation.edges doesn't have them.
            }
            if let Some(physics_dto) = vis_dto.physics { // physics_dto is ClientPhysicsSettings
                let target_physics = &mut target_vis.physics; // Type: config::PhysicsSettings
                merge_copy_option!(target_physics.attraction_strength, physics_dto.attraction_strength);
                merge_copy_option!(target_physics.bounds_size, physics_dto.bounds_size);
                merge_copy_option!(target_physics.collision_radius, physics_dto.collision_radius);
                merge_copy_option!(target_physics.damping, physics_dto.damping);
                merge_copy_option!(target_physics.enable_bounds, physics_dto.enable_bounds);
                merge_copy_option!(target_physics.enabled, physics_dto.enabled);
                merge_copy_option!(target_physics.iterations, physics_dto.iterations);
                merge_copy_option!(target_physics.max_velocity, physics_dto.max_velocity);
                merge_copy_option!(target_physics.repulsion_strength, physics_dto.repulsion_strength);
                merge_copy_option!(target_physics.spring_strength, physics_dto.spring_strength);
                merge_copy_option!(target_physics.repulsion_distance, physics_dto.repulsion_distance);
                merge_copy_option!(target_physics.mass_scale, physics_dto.mass_scale);
                merge_copy_option!(target_physics.boundary_damping, physics_dto.boundary_damping);
            }
             if let Some(rendering_dto) = vis_dto.rendering { // rendering_dto is ClientRenderingSettings
                let target_rendering = &mut target_vis.rendering; // Type: config::RenderingSettings
                merge_copy_option!(target_rendering.ambient_light_intensity, rendering_dto.ambient_light_intensity);
                merge_clone_option!(target_rendering.background_color, rendering_dto.background_color);
                merge_copy_option!(target_rendering.directional_light_intensity, rendering_dto.directional_light_intensity);
                merge_copy_option!(target_rendering.enable_ambient_occlusion, rendering_dto.enable_ambient_occlusion);
                merge_copy_option!(target_rendering.enable_antialiasing, rendering_dto.enable_antialiasing);
                merge_copy_option!(target_rendering.enable_shadows, rendering_dto.enable_shadows);
                merge_copy_option!(target_rendering.environment_intensity, rendering_dto.environment_intensity);
                // Client DTO has shadow_map_size, shadow_bias, context - not in server RenderingSettings
            }
             if let Some(anim_dto) = vis_dto.animations { // anim_dto is ClientAnimationSettings
                let target_anim = &mut target_vis.animations; // Type: config::AnimationSettings
                merge_copy_option!(target_anim.enable_motion_blur, anim_dto.enable_motion_blur);
                merge_copy_option!(target_anim.enable_node_animations, anim_dto.enable_node_animations);
                merge_copy_option!(target_anim.motion_blur_strength, anim_dto.motion_blur_strength);
                merge_copy_option!(target_anim.selection_wave_enabled, anim_dto.selection_wave_enabled);
                merge_copy_option!(target_anim.pulse_enabled, anim_dto.pulse_enabled);
                merge_copy_option!(target_anim.pulse_speed, anim_dto.pulse_speed);
                merge_copy_option!(target_anim.pulse_strength, anim_dto.pulse_strength);
                merge_copy_option!(target_anim.wave_speed, anim_dto.wave_speed);
            }
             if let Some(labels_dto) = vis_dto.labels { // labels_dto is ClientLabelSettings
                let target_labels = &mut target_vis.labels; // Type: config::LabelSettings
                merge_copy_option!(target_labels.desktop_font_size, labels_dto.desktop_font_size);
                merge_copy_option!(target_labels.enable_labels, labels_dto.enable_labels);
                merge_clone_option!(target_labels.text_color, labels_dto.text_color);
                merge_clone_option!(target_labels.text_outline_color, labels_dto.text_outline_color);
                merge_copy_option!(target_labels.text_outline_width, labels_dto.text_outline_width);
                merge_copy_option!(target_labels.text_resolution, labels_dto.text_resolution);
                merge_copy_option!(target_labels.text_padding, labels_dto.text_padding);
                merge_clone_option!(target_labels.billboard_mode, labels_dto.billboard_mode);
            }
             if let Some(bloom_dto) = vis_dto.bloom { // bloom_dto is ClientBloomSettings
                let target_bloom = &mut target_vis.bloom; // Type: config::BloomSettings
                merge_copy_option!(target_bloom.edge_bloom_strength, bloom_dto.edge_bloom_strength);
                merge_copy_option!(target_bloom.enabled, bloom_dto.enabled);
                merge_copy_option!(target_bloom.environment_bloom_strength, bloom_dto.environment_bloom_strength);
                merge_copy_option!(target_bloom.node_bloom_strength, bloom_dto.node_bloom_strength);
                merge_copy_option!(target_bloom.radius, bloom_dto.radius);
                merge_copy_option!(target_bloom.strength, bloom_dto.strength);
                // Client DTO has threshold - not in server BloomSettings
            }
             if let Some(hologram_dto) = vis_dto.hologram { // hologram_dto is ClientHologramSettings
                let target_hologram = &mut target_vis.hologram; // Type: config::HologramSettings
                merge_copy_option!(target_hologram.ring_count, hologram_dto.ring_count);
                merge_clone_option!(target_hologram.ring_color, hologram_dto.ring_color);
                merge_copy_option!(target_hologram.ring_opacity, hologram_dto.ring_opacity);
                merge_clone_option!(target_hologram.sphere_sizes, hologram_dto.sphere_sizes);
                merge_copy_option!(target_hologram.ring_rotation_speed, hologram_dto.ring_rotation_speed);
                merge_copy_option!(target_hologram.enable_buckminster, hologram_dto.enable_buckminster);
                merge_copy_option!(target_hologram.buckminster_size, hologram_dto.buckminster_size);
                merge_copy_option!(target_hologram.buckminster_opacity, hologram_dto.buckminster_opacity);
                merge_copy_option!(target_hologram.enable_geodesic, hologram_dto.enable_geodesic);
                merge_copy_option!(target_hologram.geodesic_size, hologram_dto.geodesic_size);
                merge_copy_option!(target_hologram.geodesic_opacity, hologram_dto.geodesic_opacity);
                merge_copy_option!(target_hologram.enable_triangle_sphere, hologram_dto.enable_triangle_sphere);
                merge_copy_option!(target_hologram.triangle_sphere_size, hologram_dto.triangle_sphere_size);
                merge_copy_option!(target_hologram.triangle_sphere_opacity, hologram_dto.triangle_sphere_opacity);
                merge_copy_option!(target_hologram.global_rotation_speed, hologram_dto.global_rotation_speed);
            }
            // Camera settings are not part of AppFullSettings.visualisation, so ignore vis_dto.camera
        }

        if let Some(xr_dto) = client_payload.xr {
            let target_xr = &mut settings_guard.xr;
            merge_clone_option!(target_xr.mode, xr_dto.mode);
            merge_copy_option!(target_xr.room_scale, xr_dto.room_scale);
            merge_clone_option!(target_xr.space_type, xr_dto.space_type);
            merge_clone_option!(target_xr.quality, xr_dto.quality);
            merge_copy_option!(target_xr.enable_hand_tracking, xr_dto.enable_hand_tracking);
            merge_copy_option!(target_xr.hand_mesh_enabled, xr_dto.hand_mesh_enabled);
            merge_clone_option!(target_xr.hand_mesh_color, xr_dto.hand_mesh_color);
            merge_copy_option!(target_xr.hand_mesh_opacity, xr_dto.hand_mesh_opacity);
            merge_copy_option!(target_xr.hand_point_size, xr_dto.hand_point_size);
            merge_copy_option!(target_xr.hand_ray_enabled, xr_dto.hand_ray_enabled);
            merge_clone_option!(target_xr.hand_ray_color, xr_dto.hand_ray_color);
            merge_copy_option!(target_xr.hand_ray_width, xr_dto.hand_ray_width);
            merge_copy_option!(target_xr.gesture_smoothing, xr_dto.gesture_smoothing);
            merge_copy_option!(target_xr.enable_haptics, xr_dto.enable_haptics);
            merge_copy_option!(target_xr.drag_threshold, xr_dto.drag_threshold);
            merge_copy_option!(target_xr.pinch_threshold, xr_dto.pinch_threshold);
            merge_copy_option!(target_xr.rotation_threshold, xr_dto.rotation_threshold);
            merge_copy_option!(target_xr.interaction_radius, xr_dto.interaction_radius);
            merge_copy_option!(target_xr.movement_speed, xr_dto.movement_speed);
            merge_copy_option!(target_xr.dead_zone, xr_dto.dead_zone);
            if let Some(axes_dto) = xr_dto.movement_axes {
                merge_copy_option!(target_xr.movement_axes.horizontal, axes_dto.horizontal);
                merge_copy_option!(target_xr.movement_axes.vertical, axes_dto.vertical);
            }
            merge_copy_option!(target_xr.enable_light_estimation, xr_dto.enable_light_estimation);
            merge_copy_option!(target_xr.enable_plane_detection, xr_dto.enable_plane_detection);
            merge_copy_option!(target_xr.enable_scene_understanding, xr_dto.enable_scene_understanding);
            merge_clone_option!(target_xr.plane_color, xr_dto.plane_color);
            merge_copy_option!(target_xr.plane_opacity, xr_dto.plane_opacity);
            merge_copy_option!(target_xr.plane_detection_distance, xr_dto.plane_detection_distance);
            merge_copy_option!(target_xr.show_plane_overlay, xr_dto.show_plane_overlay);
            merge_copy_option!(target_xr.snap_to_floor, xr_dto.snap_to_floor);
            merge_copy_option!(target_xr.enable_passthrough_portal, xr_dto.enable_passthrough_portal);
            merge_copy_option!(target_xr.passthrough_opacity, xr_dto.passthrough_opacity);
            merge_copy_option!(target_xr.passthrough_brightness, xr_dto.passthrough_brightness);
            merge_copy_option!(target_xr.passthrough_contrast, xr_dto.passthrough_contrast);
            merge_copy_option!(target_xr.portal_size, xr_dto.portal_size);
            merge_clone_option!(target_xr.portal_edge_color, xr_dto.portal_edge_color);
            merge_copy_option!(target_xr.portal_edge_width, xr_dto.portal_edge_width);
            
            // Manual merge for Option<T> fields in XRSettings, as target_xr fields are Option<T>
            if xr_dto.enabled.is_some() { target_xr.enabled = xr_dto.enabled; }
            if xr_dto.controller_model.is_some() { target_xr.controller_model = xr_dto.controller_model.clone(); }
            if xr_dto.render_scale.is_some() { target_xr.render_scale = xr_dto.render_scale; }
            if xr_dto.locomotion_method.is_some() { target_xr.locomotion_method = xr_dto.locomotion_method.clone(); }
            if xr_dto.teleport_ray_color.is_some() { target_xr.teleport_ray_color = xr_dto.teleport_ray_color.clone(); }
            // xr_dto.mode (Option<String>) maps to target_xr.display_mode (Option<String>)
            if xr_dto.mode.is_some() { target_xr.display_mode = xr_dto.mode.clone(); }
            if xr_dto.controller_ray_color.is_some() { target_xr.controller_ray_color = xr_dto.controller_ray_color.clone(); }
        }

        if let Some(auth_dto) = client_payload.auth {
            let target_auth = &mut settings_guard.auth;
            merge_copy_option!(target_auth.enabled, auth_dto.enabled);
            merge_clone_option!(target_auth.provider, auth_dto.provider);
            merge_copy_option!(target_auth.required, auth_dto.required);
        }

        if let Some(sys_dto) = client_payload.system {
            let target_sys_config = &mut settings_guard.system; // ServerSystemConfigFromFile
            if let Some(ws_dto) = sys_dto.websocket {
                let target_ws = &mut target_sys_config.websocket; // ServerFullWebSocketSettings
                merge_copy_option!(target_ws.reconnect_attempts, ws_dto.reconnect_attempts);
                merge_copy_option!(target_ws.reconnect_delay, ws_dto.reconnect_delay);
                merge_copy_option!(target_ws.binary_chunk_size, ws_dto.binary_chunk_size);
                merge_copy_option!(target_ws.compression_enabled, ws_dto.compression_enabled);
                merge_copy_option!(target_ws.compression_threshold, ws_dto.compression_threshold);
                merge_copy_option!(target_ws.update_rate, ws_dto.update_rate);
            }
            if let Some(debug_dto) = sys_dto.debug {
                let target_debug = &mut target_sys_config.debug; // DebugSettings (server version)
                merge_copy_option!(target_debug.enabled, debug_dto.enabled);
                merge_copy_option!(target_debug.enable_data_debug, debug_dto.enable_data_debug);
                merge_copy_option!(target_debug.enable_websocket_debug, debug_dto.enable_websocket_debug);
                merge_copy_option!(target_debug.log_binary_headers, debug_dto.log_binary_headers);
                merge_copy_option!(target_debug.log_full_json, debug_dto.log_full_json);
                // Server DebugSettings has log_level, log_format not in ClientPayloadDebugSettings
            }
            merge_copy_option!(target_sys_config.persist_settings, sys_dto.persist_settings);
            // custom_backend_url is client-only, not in ServerSystemConfigFromFile
        }
        
        // AI settings merge (all are Option<Struct> on AppFullSettings)
        if client_payload.ragflow.is_some() { settings_guard.ragflow = client_payload.ragflow.map(|dto| crate::config::RagFlowSettings {
            api_key: dto.api_key, agent_id: dto.agent_id, api_base_url: dto.api_base_url,
            timeout: dto.timeout, max_retries: dto.max_retries, chat_id: dto.chat_id,
        })};
        if client_payload.perplexity.is_some() { settings_guard.perplexity = client_payload.perplexity.map(|dto| crate::config::PerplexitySettings {
            api_key: dto.api_key, model: dto.model, api_url: dto.api_url, max_tokens: dto.max_tokens,
            temperature: dto.temperature, top_p: dto.top_p, presence_penalty: dto.presence_penalty,
            frequency_penalty: dto.frequency_penalty, timeout: dto.timeout, rate_limit: dto.rate_limit,
        })};
        if client_payload.openai.is_some() { settings_guard.openai = client_payload.openai.map(|dto| crate::config::OpenAISettings {
            api_key: dto.api_key, base_url: dto.base_url, timeout: dto.timeout, rate_limit: dto.rate_limit,
        })};
        if client_payload.kokoro.is_some() { settings_guard.kokoro = client_payload.kokoro.map(|dto| crate::config::KokoroSettings {
            api_url: dto.api_url, default_voice: dto.default_voice, default_format: dto.default_format,
            default_speed: dto.default_speed, timeout: dto.timeout, stream: dto.stream,
            return_timestamps: dto.return_timestamps, sample_rate: dto.sample_rate,
        })};
        // --- End Merge ---

        if let Err(e) = settings_guard.save() {
            error!("Failed to save global AppFullSettings after update from {}: {}", pubkey, e);
            return Ok(HttpResponse::InternalServerError().body(format!("Failed to save settings: {}", e)));
        }

        info!("Power user {} updated global settings", pubkey);
        let updated_ui_settings = convert_to_ui_settings(&*settings_guard);
        Ok(HttpResponse::Ok().json(updated_ui_settings))

    } else { // Regular user - updates their UserSettings file (which stores UISettings)
        let mut user_settings = UserSettings::load(&pubkey).unwrap_or_else(|| {
            debug!("Creating new user settings for {}", pubkey);
            UserSettings::new(&pubkey, UISettings::default())
        });

        // Merge relevant parts of ClientSettingsPayload into user_settings.settings (UISettings)
        let target_ui_settings = &mut user_settings.settings;

        if let Some(vis_dto) = client_payload.visualisation { // vis_dto is ClientVisualisationSettings
            let target_vis = &mut target_ui_settings.visualisation; // Type: config::VisualisationSettings
            if let Some(nodes_dto) = vis_dto.nodes { // nodes_dto is ClientNodeSettings
                let target_nodes = &mut target_vis.nodes;
                merge_clone_option!(target_nodes.base_color, nodes_dto.base_color);
                merge_copy_option!(target_nodes.metalness, nodes_dto.metalness);
                merge_copy_option!(target_nodes.opacity, nodes_dto.opacity);
                merge_copy_option!(target_nodes.roughness, nodes_dto.roughness);
                merge_clone_option!(target_nodes.size_range, nodes_dto.size_range);
                merge_clone_option!(target_nodes.quality, nodes_dto.quality);
                merge_copy_option!(target_nodes.enable_instancing, nodes_dto.enable_instancing);
                merge_copy_option!(target_nodes.enable_hologram, nodes_dto.enable_hologram);
                merge_copy_option!(target_nodes.enable_metadata_shape, nodes_dto.enable_metadata_shape);
                merge_copy_option!(target_nodes.enable_metadata_visualisation, nodes_dto.enable_metadata_visualisation);
            }
            if let Some(edges_dto) = vis_dto.edges { // edges_dto is ClientEdgeSettings
                let target_edges = &mut target_vis.edges;
                merge_copy_option!(target_edges.arrow_size, edges_dto.arrow_size);
                merge_copy_option!(target_edges.base_width, edges_dto.base_width);
                merge_clone_option!(target_edges.color, edges_dto.color);
                merge_copy_option!(target_edges.enable_arrows, edges_dto.enable_arrows);
                merge_copy_option!(target_edges.opacity, edges_dto.opacity);
                merge_clone_option!(target_edges.width_range, edges_dto.width_range);
                merge_clone_option!(target_edges.quality, edges_dto.quality);
                // Extra fields in ClientEdgeSettings DTO (enable_flow_effect etc.) are ignored as they are not in config::EdgeSettings
            }
            if let Some(physics_dto) = vis_dto.physics { // physics_dto is ClientPhysicsSettings
                let target_physics = &mut target_vis.physics; // Type: config::PhysicsSettings
                merge_copy_option!(target_physics.attraction_strength, physics_dto.attraction_strength);
                merge_copy_option!(target_physics.bounds_size, physics_dto.bounds_size);
                merge_copy_option!(target_physics.collision_radius, physics_dto.collision_radius);
                merge_copy_option!(target_physics.damping, physics_dto.damping);
                merge_copy_option!(target_physics.enable_bounds, physics_dto.enable_bounds);
                merge_copy_option!(target_physics.enabled, physics_dto.enabled);
                merge_copy_option!(target_physics.iterations, physics_dto.iterations);
                merge_copy_option!(target_physics.max_velocity, physics_dto.max_velocity);
                merge_copy_option!(target_physics.repulsion_strength, physics_dto.repulsion_strength);
                merge_copy_option!(target_physics.spring_strength, physics_dto.spring_strength);
                merge_copy_option!(target_physics.repulsion_distance, physics_dto.repulsion_distance);
                merge_copy_option!(target_physics.mass_scale, physics_dto.mass_scale);
                merge_copy_option!(target_physics.boundary_damping, physics_dto.boundary_damping);
            }
             if let Some(rendering_dto) = vis_dto.rendering { // rendering_dto is ClientRenderingSettings
                let target_rendering = &mut target_vis.rendering; // Type: config::RenderingSettings
                merge_copy_option!(target_rendering.ambient_light_intensity, rendering_dto.ambient_light_intensity);
                merge_clone_option!(target_rendering.background_color, rendering_dto.background_color);
                merge_copy_option!(target_rendering.directional_light_intensity, rendering_dto.directional_light_intensity);
                merge_copy_option!(target_rendering.enable_ambient_occlusion, rendering_dto.enable_ambient_occlusion);
                merge_copy_option!(target_rendering.enable_antialiasing, rendering_dto.enable_antialiasing);
                merge_copy_option!(target_rendering.enable_shadows, rendering_dto.enable_shadows);
                merge_copy_option!(target_rendering.environment_intensity, rendering_dto.environment_intensity);
                 // Extra fields in ClientRenderingSettings DTO (shadow_map_size etc.) are ignored.
            }
             if let Some(anim_dto) = vis_dto.animations { // anim_dto is ClientAnimationSettings
                let target_anim = &mut target_vis.animations; // Type: config::AnimationSettings
                merge_copy_option!(target_anim.enable_motion_blur, anim_dto.enable_motion_blur);
                merge_copy_option!(target_anim.enable_node_animations, anim_dto.enable_node_animations);
                merge_copy_option!(target_anim.motion_blur_strength, anim_dto.motion_blur_strength);
                merge_copy_option!(target_anim.selection_wave_enabled, anim_dto.selection_wave_enabled);
                merge_copy_option!(target_anim.pulse_enabled, anim_dto.pulse_enabled);
                merge_copy_option!(target_anim.pulse_speed, anim_dto.pulse_speed);
                merge_copy_option!(target_anim.pulse_strength, anim_dto.pulse_strength);
                merge_copy_option!(target_anim.wave_speed, anim_dto.wave_speed);
            }
             if let Some(labels_dto) = vis_dto.labels { // labels_dto is ClientLabelSettings
                let target_labels = &mut target_vis.labels; // Type: config::LabelSettings
                merge_copy_option!(target_labels.desktop_font_size, labels_dto.desktop_font_size);
                merge_copy_option!(target_labels.enable_labels, labels_dto.enable_labels);
                merge_clone_option!(target_labels.text_color, labels_dto.text_color);
                merge_clone_option!(target_labels.text_outline_color, labels_dto.text_outline_color);
                merge_copy_option!(target_labels.text_outline_width, labels_dto.text_outline_width);
                merge_copy_option!(target_labels.text_resolution, labels_dto.text_resolution);
                merge_copy_option!(target_labels.text_padding, labels_dto.text_padding);
                merge_clone_option!(target_labels.billboard_mode, labels_dto.billboard_mode);
            }
             if let Some(bloom_dto) = vis_dto.bloom { // bloom_dto is ClientBloomSettings
                let target_bloom = &mut target_vis.bloom; // Type: config::BloomSettings
                merge_copy_option!(target_bloom.edge_bloom_strength, bloom_dto.edge_bloom_strength);
                merge_copy_option!(target_bloom.enabled, bloom_dto.enabled);
                merge_copy_option!(target_bloom.environment_bloom_strength, bloom_dto.environment_bloom_strength);
                merge_copy_option!(target_bloom.node_bloom_strength, bloom_dto.node_bloom_strength);
                merge_copy_option!(target_bloom.radius, bloom_dto.radius);
                merge_copy_option!(target_bloom.strength, bloom_dto.strength);
                 // Extra field 'threshold' in ClientBloomSettings DTO is ignored.
            }
             if let Some(hologram_dto) = vis_dto.hologram { // hologram_dto is ClientHologramSettings
                let target_hologram = &mut target_vis.hologram; // Type: config::HologramSettings
                merge_copy_option!(target_hologram.ring_count, hologram_dto.ring_count);
                merge_clone_option!(target_hologram.ring_color, hologram_dto.ring_color);
                merge_copy_option!(target_hologram.ring_opacity, hologram_dto.ring_opacity);
                merge_clone_option!(target_hologram.sphere_sizes, hologram_dto.sphere_sizes);
                merge_copy_option!(target_hologram.ring_rotation_speed, hologram_dto.ring_rotation_speed);
                merge_copy_option!(target_hologram.enable_buckminster, hologram_dto.enable_buckminster);
                merge_copy_option!(target_hologram.buckminster_size, hologram_dto.buckminster_size);
                merge_copy_option!(target_hologram.buckminster_opacity, hologram_dto.buckminster_opacity);
                merge_copy_option!(target_hologram.enable_geodesic, hologram_dto.enable_geodesic);
                merge_copy_option!(target_hologram.geodesic_size, hologram_dto.geodesic_size);
                merge_copy_option!(target_hologram.geodesic_opacity, hologram_dto.geodesic_opacity);
                merge_copy_option!(target_hologram.enable_triangle_sphere, hologram_dto.enable_triangle_sphere);
                merge_copy_option!(target_hologram.triangle_sphere_size, hologram_dto.triangle_sphere_size);
                merge_copy_option!(target_hologram.triangle_sphere_opacity, hologram_dto.triangle_sphere_opacity);
                merge_copy_option!(target_hologram.global_rotation_speed, hologram_dto.global_rotation_speed);
            }
            // ClientVisualisationSettings DTO has 'camera' but UISettings.visualisation (config::VisualisationSettings) does not.
        }

        if let Some(xr_dto) = client_payload.xr { // xr_dto is ClientXRSettings
            let target_xr = &mut target_ui_settings.xr; // Type: config::XRSettings
            merge_clone_option!(target_xr.mode, xr_dto.mode);
            merge_copy_option!(target_xr.room_scale, xr_dto.room_scale);
            merge_clone_option!(target_xr.space_type, xr_dto.space_type);
            merge_clone_option!(target_xr.quality, xr_dto.quality);
            merge_copy_option!(target_xr.enable_hand_tracking, xr_dto.enable_hand_tracking);
            merge_copy_option!(target_xr.hand_mesh_enabled, xr_dto.hand_mesh_enabled);
            merge_clone_option!(target_xr.hand_mesh_color, xr_dto.hand_mesh_color);
            merge_copy_option!(target_xr.hand_mesh_opacity, xr_dto.hand_mesh_opacity);
            merge_copy_option!(target_xr.hand_point_size, xr_dto.hand_point_size);
            merge_copy_option!(target_xr.hand_ray_enabled, xr_dto.hand_ray_enabled);
            merge_clone_option!(target_xr.hand_ray_color, xr_dto.hand_ray_color);
            merge_copy_option!(target_xr.hand_ray_width, xr_dto.hand_ray_width);
            merge_copy_option!(target_xr.gesture_smoothing, xr_dto.gesture_smoothing);
            merge_copy_option!(target_xr.enable_haptics, xr_dto.enable_haptics);
            merge_copy_option!(target_xr.drag_threshold, xr_dto.drag_threshold);
            merge_copy_option!(target_xr.pinch_threshold, xr_dto.pinch_threshold);
            merge_copy_option!(target_xr.rotation_threshold, xr_dto.rotation_threshold);
            merge_copy_option!(target_xr.interaction_radius, xr_dto.interaction_radius);
            merge_copy_option!(target_xr.movement_speed, xr_dto.movement_speed);
            merge_copy_option!(target_xr.dead_zone, xr_dto.dead_zone);
            if let Some(axes_dto) = xr_dto.movement_axes { // axes_dto is ClientMovementAxes
                merge_copy_option!(target_xr.movement_axes.horizontal, axes_dto.horizontal);
                merge_copy_option!(target_xr.movement_axes.vertical, axes_dto.vertical);
            }
            merge_copy_option!(target_xr.enable_light_estimation, xr_dto.enable_light_estimation);
            merge_copy_option!(target_xr.enable_plane_detection, xr_dto.enable_plane_detection);
            merge_copy_option!(target_xr.enable_scene_understanding, xr_dto.enable_scene_understanding);
            merge_clone_option!(target_xr.plane_color, xr_dto.plane_color);
            merge_copy_option!(target_xr.plane_opacity, xr_dto.plane_opacity);
            merge_copy_option!(target_xr.plane_detection_distance, xr_dto.plane_detection_distance);
            merge_copy_option!(target_xr.show_plane_overlay, xr_dto.show_plane_overlay);
            merge_copy_option!(target_xr.snap_to_floor, xr_dto.snap_to_floor);
            merge_copy_option!(target_xr.enable_passthrough_portal, xr_dto.enable_passthrough_portal);
            merge_copy_option!(target_xr.passthrough_opacity, xr_dto.passthrough_opacity);
            merge_copy_option!(target_xr.passthrough_brightness, xr_dto.passthrough_brightness);
            merge_copy_option!(target_xr.passthrough_contrast, xr_dto.passthrough_contrast);
            merge_copy_option!(target_xr.portal_size, xr_dto.portal_size);
            merge_clone_option!(target_xr.portal_edge_color, xr_dto.portal_edge_color);
            merge_copy_option!(target_xr.portal_edge_width, xr_dto.portal_edge_width);
            
            // Manual merge for Option<T> fields in XRSettings
            if xr_dto.enabled.is_some() { target_xr.enabled = xr_dto.enabled; }
            if xr_dto.controller_model.is_some() { target_xr.controller_model = xr_dto.controller_model.clone(); }
            if xr_dto.render_scale.is_some() { target_xr.render_scale = xr_dto.render_scale; }
            if xr_dto.locomotion_method.is_some() { target_xr.locomotion_method = xr_dto.locomotion_method.clone(); }
            if xr_dto.teleport_ray_color.is_some() { target_xr.teleport_ray_color = xr_dto.teleport_ray_color.clone(); }
            if xr_dto.mode.is_some() { target_xr.display_mode = xr_dto.mode.clone(); } // xr_dto.mode maps to target_xr.display_mode (Option<String>)
            if xr_dto.controller_ray_color.is_some() { target_xr.controller_ray_color = xr_dto.controller_ray_color.clone(); }
        }

        if let Some(sys_dto) = client_payload.system { // sys_dto is ClientSystemSettings DTO
            // target_ui_settings.system is UISystemSettings
            if let Some(ws_dto) = sys_dto.websocket { // ws_dto is ClientPayloadWebSocketSettings DTO
                let target_ws = &mut target_ui_settings.system.websocket; // Type: config::ClientWebSocketSettings
                merge_copy_option!(target_ws.reconnect_attempts, ws_dto.reconnect_attempts);
                merge_copy_option!(target_ws.reconnect_delay, ws_dto.reconnect_delay);
                merge_copy_option!(target_ws.binary_chunk_size, ws_dto.binary_chunk_size);
                merge_copy_option!(target_ws.compression_enabled, ws_dto.compression_enabled);
                merge_copy_option!(target_ws.compression_threshold, ws_dto.compression_threshold);
                merge_copy_option!(target_ws.update_rate, ws_dto.update_rate);
            }
            if let Some(debug_dto) = sys_dto.debug { // debug_dto is ClientPayloadDebugSettings DTO
                let target_debug = &mut target_ui_settings.system.debug; // Type: config::DebugSettings
                merge_copy_option!(target_debug.enabled, debug_dto.enabled);
                merge_copy_option!(target_debug.enable_data_debug, debug_dto.enable_data_debug);
                merge_copy_option!(target_debug.enable_websocket_debug, debug_dto.enable_websocket_debug);
                merge_copy_option!(target_debug.log_binary_headers, debug_dto.log_binary_headers);
                merge_copy_option!(target_debug.log_full_json, debug_dto.log_full_json);
                // Extra fields in ClientPayloadDebugSettings DTO are ignored.
                // log_level, log_format in config::DebugSettings are not settable by regular users via this DTO.
            }
            // persist_settings and custom_backend_url from ClientSystemSettings DTO are not part of UISystemSettings.
        }
        // Auth and AI settings are not part of UISettings for regular users and are not mapped.

        user_settings.last_modified = Utc::now().timestamp();

        if let Err(e) = user_settings.save() {
            error!("Failed to save user settings for {}: {}", pubkey, e);
            return Ok(HttpResponse::InternalServerError().body(format!("Failed to save user settings: {}", e)));
        }

        debug!("User {} updated their settings", pubkey);
        Ok(HttpResponse::Ok().json(&user_settings.settings))
    }
}

// Handles updates from the older /user-settings endpoint (needs review/deprecation?)
async fn update_settings( // This is the deprecated endpoint
    req: HttpRequest,
    state: web::Data<AppState>,
    feature_access: web::Data<FeatureAccess>,
    payload: web::Json<ClientSettingsPayload>, // Should also use DTO if kept
) -> Result<HttpResponse, Error> {
    warn!("Received settings update via deprecated /user-settings endpoint. Use /user-settings/sync instead.");
    // For now, let's assume this endpoint might not need the full DTO merge logic
    // or should be fully deprecated. If it needs to work like /sync, copy merge logic.
    // For simplicity in this step, we'll keep its old behavior but with the DTO.
    // This will likely fail if ClientSettingsPayload is not directly convertible to AppFullSettings parts.
    // TODO: Refactor or remove this deprecated endpoint properly.
    // The following is a placeholder and likely incorrect without proper mapping.
    let client_payload = payload.into_inner();
    debug!("Deserialized payload via deprecated /user-settings: {:?}", client_payload);

    let pubkey = match req.headers().get("X-Nostr-Pubkey") {
        Some(value) => value.to_str().unwrap_or("").to_string(),
        None => {
            warn!("Attempt to update settings via /user-settings without authentication");
            return Ok(HttpResponse::BadRequest().body("Missing Nostr pubkey"));
        }
    };

    if !feature_access.is_power_user(&pubkey) {
        warn!("Non-power user {} attempted to modify global settings via /user-settings", pubkey);
        return Ok(HttpResponse::Forbidden().body("Only power users can modify global settings"));
    }

    // Perform the same careful merge as in update_user_settings
    let mut settings_guard = state.settings.write().await; // Locks AppFullSettings

    // --- Merge from ClientSettingsPayload DTO into AppFullSettings ---
    // Macros are defined at module level

    if let Some(vis_dto) = client_payload.visualisation {
        let target_vis = &mut settings_guard.visualisation;
        if let Some(nodes_dto) = vis_dto.nodes {
            merge_clone_option!(target_vis.nodes.base_color, nodes_dto.base_color);
            merge_copy_option!(target_vis.nodes.metalness, nodes_dto.metalness);
            merge_copy_option!(target_vis.nodes.opacity, nodes_dto.opacity);
            merge_copy_option!(target_vis.nodes.roughness, nodes_dto.roughness);
            merge_clone_option!(target_vis.nodes.size_range, nodes_dto.size_range);
            merge_clone_option!(target_vis.nodes.quality, nodes_dto.quality);
            merge_copy_option!(target_vis.nodes.enable_instancing, nodes_dto.enable_instancing);
            merge_copy_option!(target_vis.nodes.enable_hologram, nodes_dto.enable_hologram);
            merge_copy_option!(target_vis.nodes.enable_metadata_shape, nodes_dto.enable_metadata_shape);
            merge_copy_option!(target_vis.nodes.enable_metadata_visualisation, nodes_dto.enable_metadata_visualisation);
        }
        if let Some(edges_dto) = vis_dto.edges {
            let target_edges = &mut target_vis.edges;
            merge_copy_option!(target_edges.arrow_size, edges_dto.arrow_size);
            merge_copy_option!(target_edges.base_width, edges_dto.base_width);
            merge_clone_option!(target_edges.color, edges_dto.color);
            merge_copy_option!(target_edges.enable_arrows, edges_dto.enable_arrows);
            merge_copy_option!(target_edges.opacity, edges_dto.opacity);
            merge_clone_option!(target_edges.width_range, edges_dto.width_range);
            merge_clone_option!(target_edges.quality, edges_dto.quality);
        }
        if let Some(physics_dto) = vis_dto.physics { // physics_dto is ClientPhysicsSettings
            let target_physics = &mut target_vis.physics; // Type: config::PhysicsSettings
            merge_copy_option!(target_physics.attraction_strength, physics_dto.attraction_strength);
            merge_copy_option!(target_physics.bounds_size, physics_dto.bounds_size);
            merge_copy_option!(target_physics.collision_radius, physics_dto.collision_radius);
            merge_copy_option!(target_physics.damping, physics_dto.damping);
            merge_copy_option!(target_physics.enable_bounds, physics_dto.enable_bounds);
            merge_copy_option!(target_physics.enabled, physics_dto.enabled);
            merge_copy_option!(target_physics.iterations, physics_dto.iterations);
            merge_copy_option!(target_physics.max_velocity, physics_dto.max_velocity);
            merge_copy_option!(target_physics.repulsion_strength, physics_dto.repulsion_strength);
            merge_copy_option!(target_physics.spring_strength, physics_dto.spring_strength);
            merge_copy_option!(target_physics.repulsion_distance, physics_dto.repulsion_distance);
            merge_copy_option!(target_physics.mass_scale, physics_dto.mass_scale);
            merge_copy_option!(target_physics.boundary_damping, physics_dto.boundary_damping);
        }
         if let Some(rendering_dto) = vis_dto.rendering { // rendering_dto is ClientRenderingSettings
            let target_rendering = &mut target_vis.rendering; // Type: config::RenderingSettings
            merge_copy_option!(target_rendering.ambient_light_intensity, rendering_dto.ambient_light_intensity);
            merge_clone_option!(target_rendering.background_color, rendering_dto.background_color);
            merge_copy_option!(target_rendering.directional_light_intensity, rendering_dto.directional_light_intensity);
            merge_copy_option!(target_rendering.enable_ambient_occlusion, rendering_dto.enable_ambient_occlusion);
            merge_copy_option!(target_rendering.enable_antialiasing, rendering_dto.enable_antialiasing);
            merge_copy_option!(target_rendering.enable_shadows, rendering_dto.enable_shadows);
            merge_copy_option!(target_rendering.environment_intensity, rendering_dto.environment_intensity);
        }
         if let Some(anim_dto) = vis_dto.animations { // anim_dto is ClientAnimationSettings
            let target_anim = &mut target_vis.animations; // Type: config::AnimationSettings
            merge_copy_option!(target_anim.enable_motion_blur, anim_dto.enable_motion_blur);
            merge_copy_option!(target_anim.enable_node_animations, anim_dto.enable_node_animations);
            merge_copy_option!(target_anim.motion_blur_strength, anim_dto.motion_blur_strength);
            merge_copy_option!(target_anim.selection_wave_enabled, anim_dto.selection_wave_enabled);
            merge_copy_option!(target_anim.pulse_enabled, anim_dto.pulse_enabled);
            merge_copy_option!(target_anim.pulse_speed, anim_dto.pulse_speed);
            merge_copy_option!(target_anim.pulse_strength, anim_dto.pulse_strength);
            merge_copy_option!(target_anim.wave_speed, anim_dto.wave_speed);
        }
         if let Some(labels_dto) = vis_dto.labels { // labels_dto is ClientLabelSettings
            let target_labels = &mut target_vis.labels; // Type: config::LabelSettings
            merge_copy_option!(target_labels.desktop_font_size, labels_dto.desktop_font_size);
            merge_copy_option!(target_labels.enable_labels, labels_dto.enable_labels);
            merge_clone_option!(target_labels.text_color, labels_dto.text_color);
            merge_clone_option!(target_labels.text_outline_color, labels_dto.text_outline_color);
            merge_copy_option!(target_labels.text_outline_width, labels_dto.text_outline_width);
            merge_copy_option!(target_labels.text_resolution, labels_dto.text_resolution);
            merge_copy_option!(target_labels.text_padding, labels_dto.text_padding);
            merge_clone_option!(target_labels.billboard_mode, labels_dto.billboard_mode);
        }
         if let Some(bloom_dto) = vis_dto.bloom { // bloom_dto is ClientBloomSettings
            let target_bloom = &mut target_vis.bloom; // Type: config::BloomSettings
            merge_copy_option!(target_bloom.edge_bloom_strength, bloom_dto.edge_bloom_strength);
            merge_copy_option!(target_bloom.enabled, bloom_dto.enabled);
            merge_copy_option!(target_bloom.environment_bloom_strength, bloom_dto.environment_bloom_strength);
            merge_copy_option!(target_bloom.node_bloom_strength, bloom_dto.node_bloom_strength);
            merge_copy_option!(target_bloom.radius, bloom_dto.radius);
            merge_copy_option!(target_bloom.strength, bloom_dto.strength);
        }
         if let Some(hologram_dto) = vis_dto.hologram { // hologram_dto is ClientHologramSettings
            let target_hologram = &mut target_vis.hologram; // Type: config::HologramSettings
            merge_copy_option!(target_hologram.ring_count, hologram_dto.ring_count);
            merge_clone_option!(target_hologram.ring_color, hologram_dto.ring_color);
            merge_copy_option!(target_hologram.ring_opacity, hologram_dto.ring_opacity);
            merge_clone_option!(target_hologram.sphere_sizes, hologram_dto.sphere_sizes);
            merge_copy_option!(target_hologram.ring_rotation_speed, hologram_dto.ring_rotation_speed);
            merge_copy_option!(target_hologram.enable_buckminster, hologram_dto.enable_buckminster);
            merge_copy_option!(target_hologram.buckminster_size, hologram_dto.buckminster_size);
            merge_copy_option!(target_hologram.buckminster_opacity, hologram_dto.buckminster_opacity);
            merge_copy_option!(target_hologram.enable_geodesic, hologram_dto.enable_geodesic);
            merge_copy_option!(target_hologram.geodesic_size, hologram_dto.geodesic_size);
            merge_copy_option!(target_hologram.geodesic_opacity, hologram_dto.geodesic_opacity);
            merge_copy_option!(target_hologram.enable_triangle_sphere, hologram_dto.enable_triangle_sphere);
            merge_copy_option!(target_hologram.triangle_sphere_size, hologram_dto.triangle_sphere_size);
            merge_copy_option!(target_hologram.triangle_sphere_opacity, hologram_dto.triangle_sphere_opacity);
            merge_copy_option!(target_hologram.global_rotation_speed, hologram_dto.global_rotation_speed);
        }
    }

    if let Some(xr_dto) = client_payload.xr {
        let target_xr = &mut settings_guard.xr;
        merge_clone_option!(target_xr.mode, xr_dto.mode);
        merge_copy_option!(target_xr.room_scale, xr_dto.room_scale);
        merge_clone_option!(target_xr.space_type, xr_dto.space_type);
        merge_clone_option!(target_xr.quality, xr_dto.quality);
        merge_copy_option!(target_xr.enable_hand_tracking, xr_dto.enable_hand_tracking);
        merge_copy_option!(target_xr.hand_mesh_enabled, xr_dto.hand_mesh_enabled);
        merge_clone_option!(target_xr.hand_mesh_color, xr_dto.hand_mesh_color);
        merge_copy_option!(target_xr.hand_mesh_opacity, xr_dto.hand_mesh_opacity);
        merge_copy_option!(target_xr.hand_point_size, xr_dto.hand_point_size);
        merge_copy_option!(target_xr.hand_ray_enabled, xr_dto.hand_ray_enabled);
        merge_clone_option!(target_xr.hand_ray_color, xr_dto.hand_ray_color);
        merge_copy_option!(target_xr.hand_ray_width, xr_dto.hand_ray_width);
        merge_copy_option!(target_xr.gesture_smoothing, xr_dto.gesture_smoothing);
        merge_copy_option!(target_xr.enable_haptics, xr_dto.enable_haptics);
        merge_copy_option!(target_xr.drag_threshold, xr_dto.drag_threshold);
        merge_copy_option!(target_xr.pinch_threshold, xr_dto.pinch_threshold);
        merge_copy_option!(target_xr.rotation_threshold, xr_dto.rotation_threshold);
        merge_copy_option!(target_xr.interaction_radius, xr_dto.interaction_radius);
        merge_copy_option!(target_xr.movement_speed, xr_dto.movement_speed);
        merge_copy_option!(target_xr.dead_zone, xr_dto.dead_zone);
        if let Some(axes_dto) = xr_dto.movement_axes {
            merge_copy_option!(target_xr.movement_axes.horizontal, axes_dto.horizontal);
            merge_copy_option!(target_xr.movement_axes.vertical, axes_dto.vertical);
        }
        merge_copy_option!(target_xr.enable_light_estimation, xr_dto.enable_light_estimation);
        merge_copy_option!(target_xr.enable_plane_detection, xr_dto.enable_plane_detection);
        merge_copy_option!(target_xr.enable_scene_understanding, xr_dto.enable_scene_understanding);
        merge_clone_option!(target_xr.plane_color, xr_dto.plane_color);
        merge_copy_option!(target_xr.plane_opacity, xr_dto.plane_opacity);
        merge_copy_option!(target_xr.plane_detection_distance, xr_dto.plane_detection_distance);
        merge_copy_option!(target_xr.show_plane_overlay, xr_dto.show_plane_overlay);
        merge_copy_option!(target_xr.snap_to_floor, xr_dto.snap_to_floor);
        merge_copy_option!(target_xr.enable_passthrough_portal, xr_dto.enable_passthrough_portal);
        merge_copy_option!(target_xr.passthrough_opacity, xr_dto.passthrough_opacity);
        merge_copy_option!(target_xr.passthrough_brightness, xr_dto.passthrough_brightness);
        merge_copy_option!(target_xr.passthrough_contrast, xr_dto.passthrough_contrast);
        merge_copy_option!(target_xr.portal_size, xr_dto.portal_size);
        merge_clone_option!(target_xr.portal_edge_color, xr_dto.portal_edge_color);
        merge_copy_option!(target_xr.portal_edge_width, xr_dto.portal_edge_width);
        
        // Manual merge for Option<T> fields in XRSettings
        if xr_dto.enabled.is_some() { target_xr.enabled = xr_dto.enabled; }
        if xr_dto.controller_model.is_some() { target_xr.controller_model = xr_dto.controller_model.clone(); }
        if xr_dto.render_scale.is_some() { target_xr.render_scale = xr_dto.render_scale; }
        if xr_dto.locomotion_method.is_some() { target_xr.locomotion_method = xr_dto.locomotion_method.clone(); }
        if xr_dto.teleport_ray_color.is_some() { target_xr.teleport_ray_color = xr_dto.teleport_ray_color.clone(); }
        if xr_dto.mode.is_some() { target_xr.display_mode = xr_dto.mode.clone(); } // xr_dto.mode maps to target_xr.display_mode (Option<String>)
        if xr_dto.controller_ray_color.is_some() { target_xr.controller_ray_color = xr_dto.controller_ray_color.clone(); }
    }

if let Some(auth_dto) = client_payload.auth {
        let target_auth = &mut settings_guard.auth;
        merge_copy_option!(target_auth.enabled, auth_dto.enabled);
        merge_clone_option!(target_auth.provider, auth_dto.provider);
        merge_copy_option!(target_auth.required, auth_dto.required);
    }

    if let Some(sys_dto) = client_payload.system {
        let target_sys_config = &mut settings_guard.system; // ServerSystemConfigFromFile
        if let Some(ws_dto) = sys_dto.websocket {
            let target_ws = &mut target_sys_config.websocket; // ServerFullWebSocketSettings
            merge_copy_option!(target_ws.reconnect_attempts, ws_dto.reconnect_attempts);
            merge_copy_option!(target_ws.reconnect_delay, ws_dto.reconnect_delay);
            merge_copy_option!(target_ws.binary_chunk_size, ws_dto.binary_chunk_size);
            merge_copy_option!(target_ws.compression_enabled, ws_dto.compression_enabled);
            merge_copy_option!(target_ws.compression_threshold, ws_dto.compression_threshold);
            merge_copy_option!(target_ws.update_rate, ws_dto.update_rate);
        }
        if let Some(debug_dto) = sys_dto.debug {
            let target_debug = &mut target_sys_config.debug; // DebugSettings (server version)
            merge_copy_option!(target_debug.enabled, debug_dto.enabled);
            merge_copy_option!(target_debug.enable_data_debug, debug_dto.enable_data_debug);
            merge_copy_option!(target_debug.enable_websocket_debug, debug_dto.enable_websocket_debug);
            merge_copy_option!(target_debug.log_binary_headers, debug_dto.log_binary_headers);
            merge_copy_option!(target_debug.log_full_json, debug_dto.log_full_json);
        }
        merge_copy_option!(target_sys_config.persist_settings, sys_dto.persist_settings);
    }
    
    // AI settings merge (all are Option<Struct> on AppFullSettings)
    if client_payload.ragflow.is_some() { settings_guard.ragflow = client_payload.ragflow.map(|dto| crate::config::RagFlowSettings {
        api_key: dto.api_key, agent_id: dto.agent_id, api_base_url: dto.api_base_url,
        timeout: dto.timeout, max_retries: dto.max_retries, chat_id: dto.chat_id,
    })};
    if client_payload.perplexity.is_some() { settings_guard.perplexity = client_payload.perplexity.map(|dto| crate::config::PerplexitySettings {
        api_key: dto.api_key, model: dto.model, api_url: dto.api_url, max_tokens: dto.max_tokens,
        temperature: dto.temperature, top_p: dto.top_p, presence_penalty: dto.presence_penalty,
        frequency_penalty: dto.frequency_penalty, timeout: dto.timeout, rate_limit: dto.rate_limit,
    })};
    if client_payload.openai.is_some() { settings_guard.openai = client_payload.openai.map(|dto| crate::config::OpenAISettings {
        api_key: dto.api_key, base_url: dto.base_url, timeout: dto.timeout, rate_limit: dto.rate_limit,
    })};
    if client_payload.kokoro.is_some() { settings_guard.kokoro = client_payload.kokoro.map(|dto| crate::config::KokoroSettings {
        api_url: dto.api_url, default_voice: dto.default_voice, default_format: dto.default_format,
        default_speed: dto.default_speed, timeout: dto.timeout, stream: dto.stream,
        return_timestamps: dto.return_timestamps, sample_rate: dto.sample_rate,
    })};
    // --- End Merge ---

    if let Err(e) = settings_guard.save() {
        error!("Failed to save global AppFullSettings after update from {}: {}", pubkey, e);
        return Ok(HttpResponse::InternalServerError().body(format!("Failed to save settings: {}", e)));
    }

    info!("Power user {} updated global settings via /user-settings endpoint", pubkey);
    let updated_ui_settings = convert_to_ui_settings(&*settings_guard);
    // Consider broadcasting here too if this endpoint remains active
    Ok(HttpResponse::Ok().json(updated_ui_settings))
}

// --- GET Graph Specific Settings ---

pub async fn get_graph_settings(app_state: web::Data<AppState>) -> Result<HttpResponse, Error> {
    let settings_guard = app_state.settings.read().await; // Reads AppFullSettings
    Ok(HttpResponse::Ok().json(&settings_guard.visualisation))
}

----
handlers/file_handler.rs
use actix_web::{web, Error as ActixError, HttpResponse};
use serde_json::json;
use log::{info, debug, error};

use crate::AppState;
use crate::services::file_service::{FileService, MARKDOWN_DIR};
use crate::services::graph_service::GraphService;

pub async fn fetch_and_process_files(state: web::Data<AppState>) -> HttpResponse {
    info!("Initiating optimized file fetch and processing");

    // Load or create metadata
    let mut metadata_store = match FileService::load_or_create_metadata() {
        Ok(store) => store,
        Err(e) => {
            error!("Failed to load or create metadata: {}", e);
            return HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Failed to initialize metadata: {}", e)
            }));
        }
    };
    
    // Create FileService instance
    let file_service = FileService::new(state.settings.clone());
    
    // Process files with optimized approach
    match file_service.fetch_and_process_files(&state.content_api, state.settings.clone(), &mut metadata_store).await {
        Ok(processed_files) => {
            let file_names: Vec<String> = processed_files.iter()
                .map(|pf| pf.file_name.clone())
                .collect();

            info!("Successfully processed {} public markdown files", processed_files.len());

            // Update metadata store
            {
                let mut metadata = state.metadata.write().await;
                for processed_file in &processed_files {
                    metadata_store.insert(processed_file.file_name.clone(), processed_file.metadata.clone());
                    debug!("Updated metadata for: {}", processed_file.file_name);
                }
                *metadata = metadata_store.clone();
            }

            // Save the updated metadata
            if let Err(e) = FileService::save_metadata(&metadata_store) {
                error!("Failed to save metadata: {}", e);
                return HttpResponse::InternalServerError().json(json!({
                    "status": "error",
                    "message": format!("Failed to save metadata: {}", e)
                }));
            }

            // Update graph with processed files
            match GraphService::build_graph(&state).await {
                Ok(graph_data) => {
                    let mut graph = state.graph_service.graph_data.write().await;
                    *graph = graph_data.clone();
                    info!("Graph data structure updated successfully");

                    // Send binary position update to clients
                    if let Some(gpu) = &state.gpu_compute {
                        if let Ok(_nodes) = gpu.read().await.get_node_data() {
                            debug!("GPU node positions updated successfully");
                        } else {
                            error!("Failed to get node positions from GPU");
                        }
                    }

                    HttpResponse::Ok().json(json!({
                        "status": "success",
                        "processed_files": file_names
                    }))
                },
                Err(e) => {
                    error!("Failed to build graph data: {}", e);
                    HttpResponse::InternalServerError().json(json!({
                        "status": "error",
                        "message": format!("Failed to build graph data: {}", e)
                    }))
                }
            }
        },
        Err(e) => {
            error!("Error processing files: {}", e);
            HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Error processing files: {}", e)
            }))
        }
    }
}

pub async fn get_file_content(_state: web::Data<AppState>, file_name: web::Path<String>) -> HttpResponse {
    // Read file directly from disk
    let file_path = format!("{}/{}", MARKDOWN_DIR, file_name);
    match std::fs::read_to_string(&file_path) {
        Ok(content) => HttpResponse::Ok().body(content),
        Err(e) => {
            error!("Failed to read file {}: {}", file_name, e);
            HttpResponse::NotFound().json(json!({
                "status": "error",
                "message": format!("File not found or unreadable: {}", file_name)
            }))
        }
    }
}

pub async fn refresh_graph(state: web::Data<AppState>) -> HttpResponse {
    info!("Manually triggering graph refresh");

    // Load metadata from file
    let metadata_store = match FileService::load_or_create_metadata() {
        Ok(store) => store,
        Err(e) => {
            error!("Failed to load metadata: {}", e);
            return HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Failed to load metadata: {}", e)
            }));
        }
    };

    // Build graph directly from metadata
    match GraphService::build_graph_from_metadata(&metadata_store).await {
        Ok(graph_data) => {
            let mut graph = state.graph_service.graph_data.write().await;
            *graph = graph_data.clone();
            info!("Graph data structure refreshed successfully");

            // Send binary position update to clients
            if let Some(gpu) = &state.gpu_compute {
                if let Ok(_nodes) = gpu.read().await.get_node_data() {
                    // Note: Socket-flow server will handle broadcasting
                    debug!("GPU node positions updated successfully");
                } else {
                    error!("Failed to get node positions from GPU");
                }
            }

            HttpResponse::Ok().json(json!({
                "status": "success",
                "message": "Graph refreshed successfully"
            }))
        },
        Err(e) => {
            error!("Failed to refresh graph data: {}", e);
            HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Failed to refresh graph data: {}", e)
            }))
        }
    }
}

pub async fn update_graph(state: web::Data<AppState>) -> Result<HttpResponse, ActixError> {
    // Load metadata from file
    let metadata_store = match FileService::load_or_create_metadata() {
        Ok(store) => store,
        Err(e) => {
            error!("Failed to load metadata: {}", e);
            return Ok(HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Failed to load metadata: {}", e)
            })));
        }
    };

    // Build graph directly from metadata
    match GraphService::build_graph_from_metadata(&metadata_store).await {
        Ok(graph) => {
            // Update graph data
            *state.graph_service.graph_data.write().await = graph.clone();
            
            // Send binary position update to clients
            if let Some(gpu) = &state.gpu_compute {
                if let Ok(_nodes) = gpu.read().await.get_node_data() {
                    // Note: Socket-flow server will handle broadcasting
                    debug!("GPU node positions updated successfully");
                } else {
                    error!("Failed to get node positions from GPU");
                }
            }
            
            Ok(HttpResponse::Ok().json(json!({
                "status": "success",
                "message": "Graph updated successfully"
            })))
        },
        Err(e) => {
            error!("Failed to build graph: {}", e);
            Ok(HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Failed to build graph: {}", e)
            })))
        }
    }
}

----
handlers/health_handler.rs
use actix_web::{web, HttpResponse, Result, get};
use serde::{Deserialize, Serialize};
use crate::AppState;
use log::info;
use chrono::Utc;

#[derive(Serialize, Deserialize)]
pub struct PhysicsSimulationStatus {
    status: String,
    details: String,
    timestamp: String,
}

pub async fn health_check(app_state: web::Data<AppState>) -> Result<HttpResponse> {
    let metadata = app_state.metadata.read().await;
    let graph = app_state.graph_service.get_graph_data_mut().await;
    
    Ok(HttpResponse::Ok().json(serde_json::json!({
        "status": "healthy",
        "metadata_count": metadata.len(),
        "nodes_count": graph.nodes.len(),
        "edges_count": graph.edges.len()
    })))
}

#[get("/physics")]
pub async fn check_physics_simulation(app_state: web::Data<AppState>) -> Result<HttpResponse> {
    let current_time = Utc::now();
    
    // Get diagnostic information from the graph service
    let diagnostics = app_state.graph_service.get_simulation_diagnostics().await;
    
    info!("Physics simulation diagnostic check at {}: {}", current_time, diagnostics);
    
    // Determine overall status
    let status = if diagnostics.contains("Is this instance active: true") && 
                  diagnostics.contains("Global running flag: true") {
        "healthy".to_string()
    } else {
        "warning".to_string()  // Not an error, but indicates potential issues
    };
    
    Ok(HttpResponse::Ok().json(PhysicsSimulationStatus {
        status,
        details: diagnostics,
        timestamp: current_time.to_rfc3339(),
    }))
}

pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::resource("")
            .route(web::get().to(health_check))
    );
    cfg.service(check_physics_simulation);
}
----
handlers/mod.rs
pub mod api_handler;
pub mod health_handler;
pub mod pages_handler;
pub mod perplexity_handler;
pub mod ragflow_handler;
pub mod settings_handler;
pub mod socket_flow_handler;
pub mod speech_socket_handler;
pub mod nostr_handler;

----
handlers/visualization_handler.rs
use crate::config::Settings;
use crate::AppState;
use actix_web::{web, HttpResponse};
use log::{debug, error, info};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::collections::HashMap;
use std::fs;
use std::path::PathBuf;
use std::sync::Arc;
use tokio::sync::RwLock;

// Internal helper function to convert camelCase or kebab-case to snake_case
// This replaces the dependency on case_conversion.rs
fn to_snake_case(s: &str) -> String {
    // First handle kebab-case by replacing hyphens with underscores
    let s = s.replace('-', "_");
    
    // Then handle camelCase by adding underscores before uppercase letters
    let mut result = String::with_capacity(s.len() + 4);
    let mut chars = s.chars().peekable();
    
    while let Some(c) = chars.next() {
        if c.is_ascii_uppercase() {
            // If this is an uppercase letter, add an underscore before it
            // unless it's at the beginning of the string
            if !result.is_empty() {
                result.push('_');
            }
            result.push(c.to_ascii_lowercase());
        } else {
            result.push(c);
        }
    }
    result
}

#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct SettingResponse {
    pub category: String,
    pub setting: String,
    pub value: Value,
    pub success: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub error: Option<String>,
}

#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct CategorySettingsResponse {
    pub category: String,
    pub settings: HashMap<String, Value>,
    pub success: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub error: Option<String>,
}

#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct SettingValue {
    pub value: Value,
}

fn get_setting_value(settings: &Settings, category: &str, setting: &str) -> Result<Value, String> {
    debug!(
        "Attempting to get setting value for category: {}, setting: {}",
        category, setting
    );

    // Convert kebab-case URL parameters to snake_case
    let category_snake = to_snake_case(category);
    let setting_snake = to_snake_case(setting);
    debug!(
        "Converted category '{}' to snake_case: '{}'",
        category, category_snake
    );
    debug!(
        "Converted setting '{}' to snake_case: '{}'",
        setting, setting_snake
    );

    // Convert settings to Value for easier access
    let settings_value = match serde_json::to_value(&settings) {
        Ok(v) => {
            debug!("Successfully serialized settings to JSON");
            v
        }
        Err(e) => {
            error!("Failed to serialize settings to JSON: {}", e);
            return Err(format!("Failed to serialize settings: {}", e));
        }
    };

    debug!("Settings JSON structure: {}", settings_value);

    // Handle nested categories
    let parts: Vec<&str> = category_snake.split('.').collect();
    let mut current_value = &settings_value;

    for part in parts {
        current_value = match current_value.get(part) {
            Some(v) => {
                debug!("Found category part '{}' in settings", part);
                v
            }
            None => {
                error!("Category part '{}' not found in settings", part);
                return Err(format!("Category '{}' not found", category));
            }
        };
    }

    // Get setting value using snake_case for internal lookup
    let setting_value = match current_value.get(&setting_snake) {
        Some(v) => {
            debug!(
                "Found setting '{}' in category '{}'",
                setting_snake, category_snake
            );
            v
        }
        None => {
            error!(
                "Setting '{}' not found in category '{}'",
                setting_snake, category_snake
            );
            return Err(format!(
                "Setting '{}' not found in category '{}'",
                setting, category
            ));
        }
    };

    debug!("Found setting value: {:?}", setting_value);
    Ok(setting_value.clone())
}

fn update_setting_value(
    settings: &mut Settings,
    category: &str,
    setting: &str,
    value: &Value,
) -> Result<(), String> {
    debug!(
        "Attempting to update setting value for category: {}, setting: {}",
        category, setting
    );

    // Convert kebab-case URL parameters to snake_case
    let category_snake = to_snake_case(category);
    let setting_snake = to_snake_case(setting);
    debug!(
        "Converted category '{}' to snake_case: '{}'",
        category, category_snake
    );
    debug!(
        "Converted setting '{}' to snake_case: '{}'",
        setting, setting_snake
    );

    // Convert settings to Value for manipulation
    let mut settings_value = match serde_json::to_value(&*settings) {
        Ok(v) => {
            debug!("Successfully serialized settings to JSON");
            v
        }
        Err(e) => {
            error!("Failed to serialize settings to JSON: {}", e);
            return Err(format!("Failed to serialize settings: {}", e));
        }
    };

    debug!("Settings JSON structure: {}", settings_value);

    // Handle nested categories
    let parts: Vec<&str> = category_snake.split('.').collect();
    let mut current_value = &mut settings_value;

    for part in parts {
        current_value = match current_value.get_mut(part) {
            Some(v) => {
                debug!("Found category part '{}' in settings", part);
                v
            }
            None => {
                error!("Category part '{}' not found in settings", part);
                return Err(format!("Category '{}' not found", category));
            }
        };
    }

    // Update setting value
    if let Some(obj) = current_value.as_object_mut() {
        obj.insert(setting_snake.to_string(), value.clone());
        debug!("Updated setting value successfully");

        // Convert back to Settings
        match serde_json::from_value(settings_value) {
            Ok(new_settings) => {
                debug!("Successfully converted updated JSON back to Settings");
                *settings = new_settings;
                Ok(())
            }
            Err(e) => {
                error!("Failed to convert JSON back to Settings: {}", e);
                Err(format!("Failed to deserialize settings: {}", e))
            }
        }
    } else {
        error!("Category '{}' is not an object", category_snake);
        Err(format!("Category '{}' is not an object", category))
    }
}

fn get_category_settings_value(settings: &Settings, category: &str) -> Result<Value, String> {
    debug!("Getting settings for category: {}", category);
    let value = match category {
        "visualisation.nodes" => serde_json::to_value(&settings.visualisation.nodes)
            .map_err(|e| format!("Failed to serialize node settings: {}", e))?,
        "visualisation.edges" => serde_json::to_value(&settings.visualisation.edges)
            .map_err(|e| format!("Failed to serialize edge settings: {}", e))?,
        "visualisation.rendering" => serde_json::to_value(&settings.visualisation.rendering)
            .map_err(|e| format!("Failed to serialize rendering settings: {}", e))?,
        "visualisation.labels" => serde_json::to_value(&settings.visualisation.labels)
            .map_err(|e| format!("Failed to serialize labels settings: {}", e))?,
        "visualisation.bloom" => serde_json::to_value(&settings.visualisation.bloom)
            .map_err(|e| format!("Failed to serialize bloom settings: {}", e))?,
        "visualisation.animations" => serde_json::to_value(&settings.visualisation.animations)
            .map_err(|e| format!("Failed to serialize animations settings: {}", e))?,
        "visualisation.physics" => serde_json::to_value(&settings.visualisation.physics)
            .map_err(|e| format!("Failed to serialize physics settings: {}", e))?,
        "visualisation.hologram" => serde_json::to_value(&settings.visualisation.hologram)
            .map_err(|e| format!("Failed to serialize hologram settings: {}", e))?,
        "system.network" => serde_json::to_value(&settings.system.network)
            .map_err(|e| format!("Failed to serialize network settings: {}", e))?,
        "system.websocket" => serde_json::to_value(&settings.system.websocket)
            .map_err(|e| format!("Failed to serialize websocket settings: {}", e))?,
        "system.security" => serde_json::to_value(&settings.system.security)
            .map_err(|e| format!("Failed to serialize security settings: {}", e))?,
        "system.debug" => serde_json::to_value(&settings.system.debug)
            .map_err(|e| format!("Failed to serialize debug settings: {}", e))?,
        "xr" => serde_json::to_value(&settings.xr)
            .map_err(|e| format!("Failed to serialize xr settings: {}", e))?,
        "github" => serde_json::to_value(&settings.github)
            .map_err(|e| format!("Failed to serialize github settings: {}", e))?,
        "ragflow" => serde_json::to_value(&settings.ragflow)
            .map_err(|e| format!("Failed to serialize ragflow settings: {}", e))?,
        "perplexity" => serde_json::to_value(&settings.perplexity)
            .map_err(|e| format!("Failed to serialize perplexity settings: {}", e))?,
        "openai" => serde_json::to_value(&settings.openai)
            .map_err(|e| format!("Failed to serialize openai settings: {}", e))?,
        _ => return Err(format!("Invalid category: {}", category)),
    };
    debug!("Successfully retrieved settings for category: {}", category);
    Ok(value)
}

pub async fn get_setting(
    settings: web::Data<Arc<RwLock<Settings>>>,
    path: web::Path<(String, String)>,
) -> HttpResponse {
    let (category, setting) = path.into_inner();
    info!(
        "Getting setting for category: {}, setting: {}",
        category, setting
    );

    let settings_guard = match settings.read().await {
        guard => {
            debug!("Successfully acquired settings read lock");
            guard
        }
    };

    match get_setting_value(&*settings_guard, &category, &setting) {
        Ok(value) => {
            debug!("Successfully retrieved setting value: {:?}", value);
            HttpResponse::Ok().json(SettingResponse {
                category,
                setting,
                value,
                success: true,
                error: None,
            })
        }
        Err(e) => {
            error!("Failed to get setting value: {}", e);
            HttpResponse::BadRequest().json(SettingResponse {
                category,
                setting,
                value: Value::Null,
                success: false,
                error: Some(e),
            })
        }
    }
}

pub async fn update_setting(
    settings: web::Data<Arc<RwLock<Settings>>>,
    path: web::Path<(String, String)>,
    value: web::Json<Value>,
) -> HttpResponse {
    let (category, setting) = path.into_inner();
    info!(
        "Updating setting for category: {}, setting: {}",
        category, setting
    );

    let mut settings_guard = match settings.write().await {
        guard => {
            debug!("Successfully acquired settings write lock");
            guard
        }
    };

    match update_setting_value(&mut *settings_guard, &category, &setting, &value) {
        Ok(_) => {
            if let Err(e) = save_settings_to_file(&*settings_guard) {
                error!("Failed to save settings to file: {}", e);
                return HttpResponse::InternalServerError().json(SettingResponse {
                    category,
                    setting,
                    value: value.into_inner(),
                    success: false,
                    error: Some("Failed to persist settings".to_string()),
                });
            }
            HttpResponse::Ok().json(SettingResponse {
                category,
                setting,
                value: value.into_inner(),
                success: true,
                error: None,
            })
        }
        Err(e) => {
            error!("Failed to update setting value: {}", e);
            HttpResponse::BadRequest().json(SettingResponse {
                category,
                setting,
                value: value.into_inner(),
                success: false,
                error: Some(e),
            })
        }
    }
}

pub async fn get_category_settings(
    settings: web::Data<Arc<RwLock<Settings>>>,
    path: web::Path<String>,
) -> HttpResponse {
    let settings_read = settings.read().await;
    let debug_enabled = settings_read.system.debug.enabled;
    let log_json = debug_enabled && settings_read.system.debug.log_full_json;

    let category = path.into_inner();
    match get_category_settings_value(&settings_read, &category) {
        Ok(value) => {
            if log_json {
                debug!(
                    "Category '{}' settings: {}",
                    category,
                    serde_json::to_string_pretty(&value).unwrap_or_default()
                );
            }
            let settings_map: HashMap<String, Value> = value
                .as_object()
                .map(|m| m.iter().map(|(k, v)| (k.clone(), v.clone())).collect())
                .unwrap_or_default();

            HttpResponse::Ok().json(CategorySettingsResponse {
                category: category.clone(),
                settings: settings_map,
                success: true,
                error: None,
            })
        }
        Err(e) => {
            error!("Failed to get category settings for '{}': {}", category, e);
            HttpResponse::NotFound().json(CategorySettingsResponse {
                category: category.clone(),
                settings: HashMap::new(),
                success: false,
                error: Some(e),
            })
        }
    }
}

pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.route("/settings/{category}/{setting}", web::get().to(get_setting))
        .route(
            "/settings/{category}/{setting}",
            web::put().to(update_setting),
        )
        .route("/settings/{category}", web::get().to(get_category_settings));
}

fn save_settings_to_file(settings: &Settings) -> std::io::Result<()> {
    debug!("Attempting to save settings to file");

    let settings_path = std::env::var("SETTINGS_FILE_PATH")
        .map(PathBuf::from)
        .unwrap_or_else(|_| PathBuf::from("/app/settings.yaml"));

    info!("Attempting to save settings to: {:?}", settings_path);

    if let Some(parent) = settings_path.parent() {
        match fs::create_dir_all(parent) {
            Ok(_) => debug!("Created parent directories: {:?}", parent),
            Err(e) => {
                error!("Failed to create parent directories: {}", e);
                return Err(e);
            }
        }
    }

    if settings_path.exists() {
        match fs::metadata(&settings_path) {
            Ok(metadata) => {
                if metadata.permissions().readonly() {
                    error!("Settings file is read-only: {:?}", settings_path);
                    return Err(std::io::Error::new(
                        std::io::ErrorKind::PermissionDenied,
                        "Settings file is read-only",
                    ));
                }
            }
            Err(e) => {
                error!("Failed to check settings file permissions: {}", e);
                return Err(e);
            }
        }
    }

    let yaml_string = match serde_yaml::to_string(&settings) {
        Ok(s) => s,
        Err(e) => {
            error!("Failed to serialize settings to YAML: {}", e);
            return Err(std::io::Error::new(std::io::ErrorKind::Other, e));
        }
    };

    match fs::write(&settings_path, yaml_string) {
        Ok(_) => {
            info!("Settings saved successfully to: {:?}", settings_path);
            Ok(())
        }
        Err(e) => {
            error!("Failed to write settings file: {}", e);
            Err(e)
        }
    }
}

pub async fn get_visualisation_settings(
    app_state: web::Data<AppState>,
    category: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    debug!("Getting settings for category: {}", category);

    if category.as_str() == "clientDebug" {
        debug!("Checking UI container status for debugging");
    }

    let settings = app_state.settings.read().await;
    Ok(HttpResponse::Ok().json(&*settings))
}

----
handlers/pages_handler.rs
use actix_web::{web, HttpResponse, Result};
use crate::AppState;
use serde::Serialize;
use futures::future::join_all;
use crate::models::metadata::Metadata;
use crate::services::github::GitHubFileMetadata;

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
pub struct PageInfo {
    id: String,
    title: String,
    path: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    parent: Option<String>,
    modified: i64,
}

pub async fn get_pages(app_state: web::Data<AppState>) -> Result<HttpResponse> {
    let settings = app_state.settings.read().await;
    let debug_enabled = settings.system.debug.enabled;
    drop(settings);

    if debug_enabled {
        log::debug!("Starting pages retrieval");
    }

    let metadata = app_state.metadata.read().await;
    if debug_enabled {
        log::debug!("Found {} metadata entries to process", metadata.len());
    }

    let futures: Vec<_> = metadata.iter()
        .map(|(id, meta)| {
            let content_api = app_state.content_api.clone();
            let file_name = meta.file_name.clone();
            let id = id.clone();
            let meta = meta.clone();
            let debug_enabled = debug_enabled;

            async move {
                if debug_enabled {
                    log::debug!("Processing file: {} (ID: {})", file_name, id);
                }

                let github_meta = content_api
                    .list_markdown_files("")  // Empty string since base path is already configured
                    .await;

                match github_meta {
                    Ok(files) => {
                        if debug_enabled {
                            log::debug!("Found {} GitHub files for {}", files.len(), file_name);
                        }

                        let matching_file = files.into_iter()
                            .find(|f| f.name == file_name);

                        if debug_enabled {
                            if let Some(ref file) = matching_file {
                                log::debug!("Found matching GitHub file for {}: {:?}", file_name, file);
                            } else {
                                log::debug!("No matching GitHub file found for {}", file_name);
                            }
                        }

                        Ok((id, meta, matching_file))
                    },
                    Err(e) => {
                        log::error!("Failed to fetch GitHub metadata for {}: {}", file_name, e);
                        Ok((id, meta, None))
                    }
                }
            }
        })
        .collect();
    
    if debug_enabled {
        log::debug!("Created {} futures for parallel processing", futures.len());
    }

    let results = join_all(futures).await;
    
    let pages: Vec<PageInfo> = results.into_iter()
        .filter_map(|result: Result<(String, Metadata, Option<GitHubFileMetadata>), actix_web::Error>| {
            match result {
                Ok((id, meta, github_meta)) => {
                    if debug_enabled {
                        log::debug!("Building page info for {} (ID: {})", meta.file_name, id);
                    }

                    let modified = github_meta
                        .and_then(|gm| gm.last_modified)
                        .map(|dt| dt.timestamp())
                        .unwrap_or_else(|| {
                            if debug_enabled {
                                log::debug!("No modification time found for {}, using 0", meta.file_name);
                            }
                            0
                        });

                    Some(PageInfo {
                        id,
                        title: meta.file_name.clone(),
                        path: format!("/app/data/markdown/{}", meta.file_name),
                        parent: None,
                        modified,
                    })
                },
                Err(e) => {
                    log::error!("Failed to process page: {}", e);
                    None
                }
            }
        })
        .collect();

    if debug_enabled {
        log::debug!("Returning {} processed pages", pages.len());
    }

    Ok(HttpResponse::Ok().json(pages))
}

pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::resource("")
            .route(web::get().to(get_pages))
    );
} 
----
handlers/graph_handler.rs
use actix_web::{web, HttpResponse, Responder};
use crate::AppState;
use serde::{Serialize, Deserialize};
use log::{info, debug, error, warn};
use std::collections::HashMap;
use std::sync::Arc;
use crate::models::metadata::Metadata;
use crate::utils::socket_flow_messages::Node;
use crate::services::file_service::FileService;
use crate::services::graph_service::GraphService;

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
pub struct GraphResponse {
    pub nodes: Vec<Node>,
    pub edges: Vec<crate::models::edge::Edge>,
    pub metadata: HashMap<String, Metadata>,
}

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
pub struct PaginatedGraphResponse {
    pub nodes: Vec<Node>,
    pub edges: Vec<crate::models::edge::Edge>,
    pub metadata: HashMap<String, Metadata>,
    pub total_pages: usize,
    pub current_page: usize,
    pub total_items: usize,
    pub page_size: usize,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct GraphQuery {
    pub query: Option<String>,
    pub page: Option<usize>,
    #[serde(rename = "pageSize")]
    pub page_size: Option<usize>,
    pub sort: Option<String>,
    pub filter: Option<String>,
}

pub async fn get_graph_data(state: web::Data<AppState>) -> impl Responder {
    info!("Received request for graph data");
    
    // Make sure the GPU layout is calculated before sending data
    if let Some(gpu_compute) = &state.graph_service.get_gpu_compute().await {
        let mut graph = state.graph_service.get_graph_data_mut().await;
        let mut node_map = state.graph_service.get_node_map_mut().await;
        
        // Get physics settings
        let settings = state.settings.read().await;
        let physics_settings = settings.visualisation.physics.clone();
        
        // Create simulation parameters
        let params = crate::models::simulation_params::SimulationParams {
            iterations: physics_settings.iterations,
            spring_strength: physics_settings.spring_strength,
            repulsion: physics_settings.repulsion_strength,
            damping: physics_settings.damping,
            max_repulsion_distance: physics_settings.repulsion_distance,
            viewport_bounds: physics_settings.bounds_size,
            mass_scale: physics_settings.mass_scale,
            boundary_damping: physics_settings.boundary_damping,
            enable_bounds: physics_settings.enable_bounds,
            time_step: 0.016,
            phase: crate::models::simulation_params::SimulationPhase::Dynamic,
            mode: crate::models::simulation_params::SimulationMode::Remote,
        };
        
        // Calculate graph layout using GPU
        info!("Processing graph layout with GPU before sending to client");
        if let Err(e) = crate::services::graph_service::GraphService::calculate_layout(
            gpu_compute, &mut graph, &mut node_map, &params
        ).await {
            warn!("Error calculating graph layout: {}", e);
        }
        
        // Drop locks
        drop(graph);
        drop(node_map);
    } else {
        info!("GPU compute not available, sending graph without GPU processing");
    }
    
    let graph = state.graph_service.get_graph_data_mut().await;
    
    // Log position data to debug zero positions
    if !graph.nodes.is_empty() {
        // Log a few nodes for debugging
        for (i, node) in graph.nodes.iter().take(5).enumerate() {
            debug!("Node {}: id={}, label={}, pos=[{:.3},{:.3},{:.3}]", 
                i, node.id, node.label, node.data.position[0], node.data.position[1], node.data.position[2]);
        }
    }
    
    // Log edge data
    if !graph.edges.is_empty() {
        for (i, edge) in graph.edges.iter().take(5).enumerate() {
            debug!("Edge {}: source={}, target={}, weight={:.3}", 
                i, edge.source, edge.target, edge.weight);
        }
    }
    
    info!("Preparing graph response with {} nodes and {} edges",
        graph.nodes.len(),
        graph.edges.len()
    );

    let response = GraphResponse {
        nodes: graph.nodes.clone(),
        edges: graph.edges.clone(),
        metadata: graph.metadata.clone(),
    };

    HttpResponse::Ok().json(response)
}

pub async fn get_paginated_graph_data(
    state: web::Data<AppState>,
    query: web::Query<GraphQuery>,
) -> impl Responder {
    info!("Received request for paginated graph data with params: {:?}", query);
    
    // Ensure GPU layout is calculated before sending first page of data
    if query.page.unwrap_or(1) == 1 {
        if let Some(gpu_compute) = &state.graph_service.get_gpu_compute().await {
            let mut graph = state.graph_service.get_graph_data_mut().await;
            let mut node_map = state.graph_service.get_node_map_mut().await;
            
            // Get physics settings
            let settings = state.settings.read().await;
            let physics_settings = settings.visualisation.physics.clone();
            
            // Create simulation parameters
            let params = crate::models::simulation_params::SimulationParams {
                iterations: physics_settings.iterations,
                spring_strength: physics_settings.spring_strength,
                repulsion: physics_settings.repulsion_strength,
                damping: physics_settings.damping,
                max_repulsion_distance: physics_settings.repulsion_distance,
                viewport_bounds: physics_settings.bounds_size,
                mass_scale: physics_settings.mass_scale,
                boundary_damping: physics_settings.boundary_damping,
                enable_bounds: physics_settings.enable_bounds,
                time_step: 0.016,
                phase: crate::models::simulation_params::SimulationPhase::Dynamic,
                mode: crate::models::simulation_params::SimulationMode::Remote,
            };
            
            // Calculate graph layout using GPU
            info!("Processing paginated graph layout with GPU before sending to client");
            if let Err(e) = crate::services::graph_service::GraphService::calculate_layout(
                gpu_compute, &mut graph, &mut node_map, &params
            ).await {
                warn!("Error calculating graph layout for paginated data: {}", e);
            }
            
            // Drop locks
            drop(graph);
            drop(node_map);
        } else {
            info!("GPU compute not available, sending paginated graph without GPU processing");
        }
    }

    // Convert to 0-based indexing internally
    let page = query.page.map(|p| p.saturating_sub(1)).unwrap_or(0);
    let page_size = query.page_size.unwrap_or(100);

    if page_size == 0 {
        error!("Invalid page size: {}", page_size);
        return HttpResponse::BadRequest().json(serde_json::json!({
            "error": "Page size must be greater than 0"
        }));
    }

    let graph = state.graph_service.get_graph_data_mut().await;
    let total_items = graph.nodes.len();
    
    if total_items == 0 {
        debug!("Graph is empty");
        return HttpResponse::Ok().json(PaginatedGraphResponse {
            nodes: Vec::new(),
            edges: Vec::new(),
            metadata: HashMap::new(),
            total_pages: 0,
            current_page: 1, // Return 1-based page number
            total_items: 0,
            page_size,
        });
    }

    let total_pages = (total_items + page_size - 1) / page_size;

    if page >= total_pages {
        warn!("Requested page {} exceeds total pages {}", page + 1, total_pages);
        return HttpResponse::BadRequest().json(serde_json::json!({
            "error": format!("Page {} exceeds total available pages {}", page + 1, total_pages)
        }));
    }

    let start = page * page_size;
    let end = std::cmp::min(start + page_size, total_items);

    debug!("Calculating slice from {} to {} out of {} total items", start, end, total_items);

    let page_nodes = graph.nodes[start..end].to_vec();

    // Get edges where either source or target is in the current page
    let node_ids: std::collections::HashSet<_> = page_nodes.iter()
        .map(|node| node.id.clone())
        .collect();

    let relevant_edges: Vec<_> = graph.edges.iter()
        .filter(|edge| {
            // Include edges where either the source or target is in our page
            node_ids.contains(&edge.source) || node_ids.contains(&edge.target)
        })
        .cloned()
        .collect();

    debug!("Found {} relevant edges for {} nodes", relevant_edges.len(), page_nodes.len());

    let response = PaginatedGraphResponse {
        nodes: page_nodes,
        edges: relevant_edges,
        metadata: graph.metadata.clone(),
        total_pages,
        current_page: page + 1, // Convert back to 1-based indexing for response
        total_items,
        page_size,
    };

    HttpResponse::Ok().json(response)
}

// Rebuild graph from existing metadata
pub async fn refresh_graph(state: web::Data<AppState>) -> impl Responder {
    info!("Received request to refresh graph");
    
    let metadata = state.metadata.read().await.clone();
    debug!("Building graph from {} metadata entries", metadata.len());
    
    match GraphService::build_graph_from_metadata(&metadata).await {
        Ok(mut new_graph) => {
            let mut graph = state.graph_service.get_graph_data_mut().await;
            let mut node_map = state.graph_service.get_node_map_mut().await;
            
            // Preserve existing node positions
            // Use metadata_id (filename) to match nodes between old and new graphs
            let old_positions: HashMap<String, (f32, f32, f32)> = graph.nodes.iter() 
                .map(|node| (node.metadata_id.clone(), (node.x(), node.y(), node.z())))
                .collect();
            
            debug!("Preserved positions for {} existing nodes by metadata_id", old_positions.len());
            
            // Update positions in new graph
            for node in &mut new_graph.nodes {
                // Look up by metadata_id (filename) instead of numeric ID
                if let Some(&(x, y, z)) = old_positions.get(&node.metadata_id) {
                    node.set_x(x);
                    node.set_y(y);
                    node.set_z(z);
                }
            }
            
            *graph = new_graph;
            
            // Update node_map with new graph nodes
            node_map.clear();
            for node in &graph.nodes {
                node_map.insert(node.id.clone(), node.clone());
            }
            
            info!("Graph refreshed successfully with {} nodes and {} edges", 
                graph.nodes.len(), 
                graph.edges.len()
            );
            
            HttpResponse::Ok().json(serde_json::json!({
                "success": true,
                "message": "Graph refreshed successfully"
            }))
        },
        Err(e) => {
            error!("Failed to refresh graph: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "error": format!("Failed to refresh graph: {}", e)
            }))
        }
    }
}

// Fetch new metadata and rebuild graph
pub async fn update_graph(state: web::Data<AppState>) -> impl Responder {
    info!("Received request to update graph");
    
    // Load current metadata
    let mut metadata = match FileService::load_or_create_metadata() {
        Ok(m) => m,
        Err(e) => {
            error!("Failed to load metadata: {}", e);
            return HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "error": format!("Failed to load metadata: {}", e)
            }));
        }
    };
    
    // Fetch and process new files
    let file_service = FileService::new(Arc::clone(&state.settings));
    match file_service.fetch_and_process_files(&state.content_api, Arc::clone(&state.settings), &mut metadata).await {
        Ok(processed_files) => {
            if processed_files.is_empty() {
                debug!("No new files to process");
                return HttpResponse::Ok().json(serde_json::json!({
                    "success": true,
                    "message": "No updates needed"
                }));
            }
            
            debug!("Processing {} new files", processed_files.len());
            
            // Update metadata in app state
            {
                let mut app_metadata = state.metadata.write().await;
                *app_metadata = metadata.clone();
            }
            
            // Build new graph
            match GraphService::build_graph_from_metadata(&metadata).await {
                Ok(mut new_graph) => {
                    let mut graph = state.graph_service.get_graph_data_mut().await;
                    let mut node_map = state.graph_service.get_node_map_mut().await;
                    
                    // Preserve existing node positions
                    // Use metadata_id (filename) to match nodes between old and new graphs
                    let old_positions: HashMap<String, (f32, f32, f32)> = graph.nodes.iter() 
                        .map(|node| (node.metadata_id.clone(), (node.x(), node.y(), node.z())))
                        .collect();
                    
                    debug!("Preserved positions for {} existing nodes by metadata_id", old_positions.len());
                    
                    // Update positions in new graph
                    for node in &mut new_graph.nodes {
                        // Look up by metadata_id (filename) instead of numeric ID
                        if let Some(&(x, y, z)) = old_positions.get(&node.metadata_id) {
                            node.set_x(x);
                            node.set_y(y);
                            node.set_z(z);
                        }
                    }
                    
                    *graph = new_graph;
                    
                    // Update node_map with new graph nodes
                    node_map.clear();
                    for node in &graph.nodes {
                        node_map.insert(node.id.clone(), node.clone());
                    }
                    
                    debug!("Graph updated successfully");
                    
                    HttpResponse::Ok().json(serde_json::json!({
                        "success": true,
                        "message": format!("Graph updated with {} new files", processed_files.len())
                    }))
                },
                Err(e) => {
                    error!("Failed to build new graph: {}", e);
                    HttpResponse::InternalServerError().json(serde_json::json!({
                        "success": false,
                        "error": format!("Failed to build new graph: {}", e)
                    }))
                }
            }
        },
        Err(e) => {
            error!("Failed to fetch and process files: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "error": format!("Failed to fetch and process files: {}", e)
            }))
        }
    }
}

----
handlers/socket_flow_handler.rs
use actix::{prelude::*, Actor, Handler, Message};
use actix_web::{web, Error, HttpRequest, HttpResponse};
use actix_web_actors::ws;
use crate::config::AppFullSettings;
use flate2::{write::ZlibEncoder, Compression};
use log::{debug, error, info, warn};
use std::io::Write;
use std::collections::HashMap;
use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};
use tokio::sync::RwLock;
use std::time::Instant;

use crate::app_state::AppState;
use crate::utils::binary_protocol;
use crate::types::vec3::Vec3Data;
use crate::utils::socket_flow_messages::{BinaryNodeData, PingMessage, PongMessage};

// Constants for throttling debug logs
const DEBUG_LOG_SAMPLE_RATE: usize = 10; // Only log 1 in 10 updates

// Constants for data optimization
const COMPRESSION_LEVEL: Compression = Compression::best(); // Use best compression
// Default values for deadbands if not provided in settings
const DEFAULT_POSITION_DEADBAND: f32 = 0.01; // 1cm deadband 
const DEFAULT_VELOCITY_DEADBAND: f32 = 0.005; // 5mm/s deadband
// Default values for dynamic update rate
// const DEFAULT_MIN_UPDATE_RATE: u32 = 5;   // Min 5 updates per second when stable // Dead Code
const BATCH_UPDATE_WINDOW_MS: u64 = 200;  // Check motion every 200ms
// const DEFAULT_MAX_UPDATE_RATE: u32 = 60;  // Max 60 updates per second when active // Dead Code
// const DEFAULT_MOTION_THRESHOLD: f32 = 0.05;  // 5% of nodes need to be moving // Dead Code
// const DEFAULT_MOTION_DAMPING: f32 = 0.9;  // Smooth transitions in rate // Dead Code

// Maximum value for u16 node IDs
const MAX_U16_VALUE: u32 = 65535;

/// Struct to hold pre-read WebSocket settings to avoid blocking in async context
#[derive(Clone, Debug)]
pub struct PreReadSocketSettings {
    pub min_update_rate: u32,
    pub max_update_rate: u32,
    pub motion_threshold: f32,
    pub motion_damping: f32,
    pub compression_enabled: bool,
    pub compression_threshold: usize,
    pub heartbeat_interval_ms: u64, // Added for heartbeat
    pub heartbeat_timeout_ms: u64,  // Added for heartbeat
}

/// ClientManager keeps track of all connected WebSocket clients
/// and provides methods for broadcasting data to all clients
#[derive(Debug)]
pub struct ClientManager {
    /// Map of client IDs to associated actor addresses
    clients: RwLock<HashMap<usize, actix::Addr<SocketFlowServer>>>,
    /// Counter for generating unique client IDs
    next_id: AtomicUsize,
}

impl ClientManager {
    /// Create a new ClientManager
    pub fn new() -> Self {
        Self {
            clients: RwLock::new(HashMap::new()),
            next_id: AtomicUsize::new(1),
        }
    }

    /// Register a new client with the manager
    pub async fn register(&self, addr: actix::Addr<SocketFlowServer>) -> usize {
        let id = self.next_id.fetch_add(1, Ordering::SeqCst);
        let mut clients = self.clients.write().await;
        clients.insert(id, addr);
        info!("[ClientManager] Registered new client: {} (total: {})", id, clients.len());
        id
    }

    /// Unregister a client from the manager
    pub async fn unregister(&self, id: usize) {
        let mut clients = self.clients.write().await;
        clients.remove(&id);
        info!("[ClientManager] Unregistered client: {} (remaining: {})", id, clients.len());
    }

    /// Broadcast node positions to all connected clients
    pub async fn broadcast_node_positions(&self, nodes: Vec<crate::utils::socket_flow_messages::Node>) {
        if nodes.is_empty() {
            return;
        }

        let clients = self.clients.read().await;
        if clients.is_empty() {
            return;
        }

        // Convert nodes to binary format
        let binary_data = nodes.into_iter()
            .filter_map(|node| {
                // Parse node ID as u16 for binary protocol
                node.id.parse::<u16>().ok().map(|id| (id, BinaryNodeData {
                    position: node.data.position,
                    velocity: node.data.velocity,
                    mass: node.data.mass,
                    flags: node.data.flags,
                    padding: node.data.padding,
                }))
            })
            .collect::<Vec<_>>();

        // Send the update to all clients
        for (id, addr) in clients.iter() {
            addr.do_send(BroadcastPositionUpdate(binary_data.clone()));
            debug!("[ClientManager] Sent position update to client {}", id);
        }
    }
}

// Message to set client ID after registration
#[derive(Message)]
#[rtype(result = "()")]
struct SetClientId(usize);

// Implement handler for SetClientId message
impl Handler<SetClientId> for SocketFlowServer {
    type Result = ();

    fn handle(&mut self, msg: SetClientId, _ctx: &mut Self::Context) -> Self::Result {
        self.client_id = Some(msg.0);
        info!("[WebSocket] Client assigned ID: {}", msg.0);
    }
}

// Implement handler for BroadcastPositionUpdate message
impl Handler<BroadcastPositionUpdate> for SocketFlowServer {
    type Result = ();

    fn handle(&mut self, msg: BroadcastPositionUpdate, ctx: &mut Self::Context) -> Self::Result {
        if !msg.0.is_empty() {
            // Encode the binary message
            let binary_data = binary_protocol::encode_node_data(&msg.0);
            
            // Apply compression if needed
            let compressed_data = self.maybe_compress(binary_data);
            
            // Send to client
            ctx.binary(compressed_data);
            
            // Debug logging - limit to avoid spamming logs
            if self.should_log_update() {
                debug!("[WebSocket] Position update sent: {} nodes", msg.0.len());
            }
        }
    }
}
/// Message type for broadcasting position updates to clients
#[derive(Message, Clone)]
#[rtype(result = "()")]
pub struct BroadcastPositionUpdate(pub Vec<(u16, BinaryNodeData)>);

pub struct SocketFlowServer {
    app_state: Arc<AppState>,
    client_id: Option<usize>,
    client_manager: Option<Arc<ClientManager>>,
    last_ping: Option<u64>,
    update_counter: usize, // Counter for throttling debug logs
    last_activity: std::time::Instant, // Track last activity time
    heartbeat_timer_set: bool, // Flag to track if heartbeat timer is set
    // Fields for batched updates and deadband filtering
    _node_position_cache: HashMap<String, BinaryNodeData>, // Dead Code: Field is never read
    last_sent_positions: HashMap<String, Vec3Data>,
    last_sent_velocities: HashMap<String, Vec3Data>,
    position_deadband: f32, // Minimum position change to trigger an update
    velocity_deadband: f32, // Minimum velocity change to trigger an update
    // Performance metrics
    last_transfer_size: usize,
    last_transfer_time: Instant,
    total_bytes_sent: usize,
    update_count: usize,
    nodes_sent_count: usize,
    
    // Dynamic update rate fields
    last_batch_time: Instant, // Last time we sent a batch of updates
    current_update_rate: u32,  // Current rate in updates per second
    // Store pre-read settings directly
    min_update_rate: u32,
    max_update_rate: u32,
    motion_threshold: f32,
    motion_damping: f32,
    compression_enabled: bool,
    compression_threshold: usize,
    heartbeat_interval_ms: u64,
    heartbeat_timeout_ms: u64,
    nodes_in_motion: usize,    // Counter for nodes currently in motion
    total_node_count: usize,   // Total node count for percentage calculation
    last_motion_check: Instant, // Last time we checked motion percentage,
}

impl SocketFlowServer {
    pub fn new(app_state: Arc<AppState>, pre_read_settings: PreReadSocketSettings, client_manager: Option<Arc<ClientManager>>) -> Self {
        let min_update_rate = pre_read_settings.min_update_rate;
        let max_update_rate = pre_read_settings.max_update_rate;
        let motion_threshold = pre_read_settings.motion_threshold;
        let motion_damping = pre_read_settings.motion_damping;
        let compression_enabled = pre_read_settings.compression_enabled;
        let compression_threshold = pre_read_settings.compression_threshold;
        let heartbeat_interval_ms = pre_read_settings.heartbeat_interval_ms;
        let heartbeat_timeout_ms = pre_read_settings.heartbeat_timeout_ms;

        // Use position and velocity deadbands from constants
        let position_deadband = DEFAULT_POSITION_DEADBAND;
        let velocity_deadband = DEFAULT_VELOCITY_DEADBAND;

        // Start at max update rate and adjust dynamically based on motion
        let current_update_rate = max_update_rate;

        Self {
            app_state,
            client_id: None,
            client_manager,
            last_ping: None,
            update_counter: 0,
            last_activity: std::time::Instant::now(),
            heartbeat_timer_set: false,
            _node_position_cache: HashMap::new(), // Dead Code: Field is never read
            last_sent_positions: HashMap::new(),
            last_sent_velocities: HashMap::new(),
            position_deadband,
            velocity_deadband,
            last_transfer_size: 0,
            last_transfer_time: Instant::now(),
            total_bytes_sent: 0,
            last_batch_time: Instant::now(),
            update_count: 0,
            nodes_sent_count: 0,
            current_update_rate,
            min_update_rate,
            max_update_rate,
            motion_threshold,
            motion_damping,
            compression_enabled,
            compression_threshold,
            heartbeat_interval_ms,
            heartbeat_timeout_ms,
            nodes_in_motion: 0,
            total_node_count: 0,
            last_motion_check: Instant::now()
        }
    }

    fn handle_ping(&mut self, msg: PingMessage) -> PongMessage {
        self.last_ping = Some(msg.timestamp);
        PongMessage {
            type_: "pong".to_string(),
            timestamp: msg.timestamp,
        }
    }
    
    // maybe_compress needs access to compression settings
    fn maybe_compress(&mut self, data: Vec<u8>) -> Vec<u8> {
        let enabled = self.compression_enabled;
        let threshold = self.compression_threshold;

        if enabled && data.len() > threshold {
            let mut encoder = ZlibEncoder::new(Vec::new(), COMPRESSION_LEVEL);
            if encoder.write_all(&data).is_ok() {
                if let Ok(compressed) = encoder.finish() {
                    if compressed.len() < data.len() {
                        // Compression logging logic...
                        return compressed;
                    }
                }
            }
        }
        data // Return original data if not compressed
    }
    
    // Helper method to determine if we should log this update (for throttling)
    fn should_log_update(&mut self) -> bool {
        self.update_counter = (self.update_counter + 1) % DEBUG_LOG_SAMPLE_RATE;
        self.update_counter == 0
    }
    
    // Check if a node's position or velocity has changed enough to warrant an update
    fn has_node_changed_significantly(&mut self, node_id: &str, new_position: Vec3Data, new_velocity: Vec3Data) -> bool {
        let position_changed = if let Some(last_position) = self.last_sent_positions.get(node_id) {
            // Calculate Euclidean distance between last sent position and new position
            let dx = new_position.x - last_position.x;
            let dy = new_position.y - last_position.y;
            let dz = new_position.z - last_position.z;
            let distance_squared = dx*dx + dy*dy + dz*dz;
            
            // Check if position has changed by more than the deadband
            distance_squared > self.position_deadband * self.position_deadband
        } else {
            // First time seeing this node, always consider it changed
            true
        };
        
        let velocity_changed = if let Some(last_velocity) = self.last_sent_velocities.get(node_id) {
            // Calculate velocity change magnitude
            let dvx = new_velocity.x - last_velocity.x;
            let dvy = new_velocity.y - last_velocity.y;
            let dvz = new_velocity.z - last_velocity.z;
            let velocity_change_squared = dvx*dvx + dvy*dvy + dvz*dvz;
            
            // Check if velocity has changed by more than the deadband
            velocity_change_squared > self.velocity_deadband * self.velocity_deadband
        } else {
            // First time seeing this node's velocity, always consider it changed
            true
        };
        
        // Update stored values if changed
        if position_changed || velocity_changed {
            self.last_sent_positions.insert(node_id.to_string(), new_position);
            self.last_sent_velocities.insert(node_id.to_string(), new_velocity);
            return true;
        }
        
        false
    }

    // Calculate the current update interval based on the dynamic rate
    fn get_current_update_interval(&self) -> std::time::Duration {
        let millis = (1000.0 / self.current_update_rate as f64) as u64;
        std::time::Duration::from_millis(millis)
    }
    
    // Calculate the percentage of nodes in motion
    fn calculate_motion_percentage(&self) -> f32 {
        if self.total_node_count == 0 {
            return 0.0;
        }
        
        (self.nodes_in_motion as f32) / (self.total_node_count as f32)
    }
    
    // Update the dynamic rate based on current motion
    fn update_dynamic_rate(&mut self) {
        // Only recalculate periodically to avoid rapid changes
        let now = Instant::now();
        let batch_window = std::time::Duration::from_millis(BATCH_UPDATE_WINDOW_MS);
        let elapsed = now.duration_since(self.last_batch_time);
        
        // If we've waited at least the batch window time, or this is the first update
        if elapsed >= batch_window {
            // Calculate the current motion percentage
            let motion_pct = self.calculate_motion_percentage();
            
            // Adjust the update rate based on the motion percentage
            if motion_pct > self.motion_threshold {
                // Gradually increase rate for high motion scenarios
                self.current_update_rate = ((self.current_update_rate as f32) * self.motion_damping + 
                                           (self.max_update_rate as f32) * (1.0 - self.motion_damping)) as u32;
            } else {
                // Gradually decrease rate for low motion scenarios
                self.current_update_rate = ((self.current_update_rate as f32) * self.motion_damping + 
                                           (self.min_update_rate as f32) * (1.0 - self.motion_damping)) as u32;
            }
            
            // Ensure rate stays within min and max bounds
            self.current_update_rate = self.current_update_rate.clamp(self.min_update_rate, self.max_update_rate);
            
            // Update the last motion check time
            self.last_motion_check = now;
        }
    }

    // New method to mark a batch as sent
    // fn mark_batch_sent(&mut self) { self.last_batch_time = Instant::now(); } // Dead Code
    
    // New method to collect nodes that have changed position
    // fn collect_changed_nodes(&mut self) -> Vec<(u16, BinaryNodeData)> { // Dead Code
    //     let mut changed_nodes = Vec::new();
        
    //     for (node_id, node_data) in self._node_position_cache.drain() { // Adjusted to use _node_position_cache
    //         if let Ok(node_id_u16) = node_id.parse::<u16>() {
    //             changed_nodes.push((node_id_u16, node_data));
    //         }
    //     }
        
    //     changed_nodes
    // }
}

impl Actor for SocketFlowServer {
    type Context = ws::WebsocketContext<Self>;

    fn started(&mut self, ctx: &mut Self::Context) {
        // Register this client with the client manager
        if let Some(client_manager) = &self.client_manager {
            let addr = ctx.address();
            let addr_clone = addr.clone();
            
            // Use actix's runtime to avoid blocking in the actor's started method
            let cm_clone = client_manager.clone();
            actix::spawn(async move {
                let client_id = cm_clone.register(addr_clone).await;
                // Send a message back to the actor with its client ID
                addr.do_send(SetClientId(client_id));
            });
        }
    
        info!("[WebSocket] New client connected");
        self.last_activity = std::time::Instant::now();
        
        // We'll retrieve client ID asynchronously via message
        self.client_id = None;

        // Set up server-side heartbeat ping to keep connection alive
        if !self.heartbeat_timer_set {
            ctx.run_interval(std::time::Duration::from_secs(5), |act, ctx| {
                // Send a heartbeat ping every 5 seconds
                debug!("[WebSocket] Sending server heartbeat ping");
                ctx.ping(b"");
                
                // Update last activity timestamp to prevent client-side timeout
                act.last_activity = std::time::Instant::now();
            });
        }

        // Send simple connection established message
        let response = serde_json::json!({
            "type": "connection_established",
            "timestamp": chrono::Utc::now().timestamp_millis()
        });

        if let Ok(msg_str) = serde_json::to_string(&response) {
            ctx.text(msg_str);
            self.last_activity = std::time::Instant::now();
        }

        // Send a "loading" message to indicate the client should display a loading indicator
        let loading_msg = serde_json::json!({
            "type": "loading",
            "message": "Calculating initial layout..."
        });
        ctx.text(serde_json::to_string(&loading_msg).unwrap_or_default());
        self.last_activity = std::time::Instant::now();
    }

    fn stopped(&mut self, _ctx: &mut Self::Context) {
        // Unregister this client when it disconnects
        if let Some(client_id) = self.client_id {
            if let Some(client_manager) = &self.client_manager {
                let client_manager_clone = client_manager.clone();
                actix::spawn(async move {
                    client_manager_clone.unregister(client_id).await;
                });
            }
            info!("[WebSocket] Client {} disconnected", client_id);
        }
    }
}

// Helper function to fetch nodes without borrowing from the actor
// Update signature to accept AppFullSettings
async fn fetch_nodes(
    app_state: Arc<AppState>,
    settings_arc: Arc<RwLock<AppFullSettings>> // Renamed for clarity
) -> Option<(Vec<(u16, BinaryNodeData)>, bool)> {
    // Fetch raw nodes asynchronously
    let raw_nodes = app_state.graph_service.get_node_positions().await;
    
    if raw_nodes.is_empty() {
        debug!("[WebSocket] No nodes to send! Empty graph data.");
        return None;
    }

    // Acquire the read lock asynchronously
    let settings_read = settings_arc.read().await; // <--- USE ASYNC READ LOCK
    let detailed_debug = settings_read.system.debug.enabled &&
                         settings_read.system.debug.enable_websocket_debug;
    drop(settings_read); // Release the lock as soon as it's no longer needed

    if detailed_debug {
        debug!("Raw nodes count: {}, showing first 5 nodes IDs:", raw_nodes.len());
        for (i, node) in raw_nodes.iter().take(5).enumerate() {
            debug!("  Node {}: id={} (numeric), metadata_id={} (filename)", 
                i, node.id, node.metadata_id);
        }
    }
    
    let mut nodes = Vec::with_capacity(raw_nodes.len());
    for node in raw_nodes {
        // First try to parse as u16
        let node_id_result = match node.id.parse::<u16>() {
            Ok(id) => Ok(id),
            Err(_) => {
                // If parsing as u16 fails, try parsing as u32 and check if it's within u16 range
                match node.id.parse::<u32>() {
                    Ok(id) if id <= MAX_U16_VALUE => Ok(id as u16),
                    _ => Err(())
                }
            }
        };
        if let Ok(node_id) = node_id_result {
            let node_data = BinaryNodeData {
                position: node.data.position,
                velocity: node.data.velocity,
                mass: node.data.mass,
                flags: node.data.flags,
                padding: node.data.padding,
            };
            nodes.push((node_id, node_data));
        } else {
            // Log more detailed information about the node ID
            if let Ok(id) = node.id.parse::<u32>() {
                warn!("[WebSocket] Node ID too large for u16: '{}' ({}), metadata_id: '{}'", 
                    node.id, id, node.metadata_id);
            } else {
                warn!("[WebSocket] Failed to parse node ID as u16: '{}', metadata_id: '{}'", 
                    node.id, node.metadata_id);
            }
        }
    }
    
    if nodes.is_empty() {
        return None;
    }
    
    // Return nodes and debug flag
    Some((nodes, detailed_debug))
}

impl StreamHandler<Result<ws::Message, ws::ProtocolError>> for SocketFlowServer {
    fn handle(&mut self, msg: Result<ws::Message, ws::ProtocolError>, ctx: &mut Self::Context) {
        match msg {
            Ok(ws::Message::Ping(msg)) => {
                debug!("[WebSocket] Received ping");
                ctx.pong(&msg);
                self.last_activity = std::time::Instant::now();
            }
            Ok(ws::Message::Pong(_)) => {
                // Logging every pong creates too much noise, only log in detailed debug mode
                if self.app_state.settings.try_read().map(|s| s.system.debug.enable_websocket_debug).unwrap_or(false) {
                    debug!("[WebSocket] Received pong");
                }
                self.last_activity = std::time::Instant::now();
            }
            Ok(ws::Message::Text(text)) => {
                info!("Received text message: {}", text);
                self.last_activity = std::time::Instant::now();
                match serde_json::from_str::<serde_json::Value>(&text) {
                    Ok(msg) => {
                        match msg.get("type").and_then(|t| t.as_str()) {
                            Some("ping") => {
                                if let Ok(ping_msg) =
                                    serde_json::from_value::<PingMessage>(msg.clone())
                                {
                                    let pong = self.handle_ping(ping_msg);
                                    self.last_activity = std::time::Instant::now();
                                    if let Ok(response) = serde_json::to_string(&pong) {
                                        ctx.text(response);
                                    }
                                }
                            }
                            Some("requestInitialData") => {
                                info!("Client requested initial data - sending authoritative server state");

                                // Use a smaller initial interval to start updates quickly
                                let initial_interval = std::time::Duration::from_millis(10);
                                let app_state = self.app_state.clone();
                                let settings_clone = self.app_state.settings.clone();
                                
                                // First check if we should log this update
                                let should_log = self.should_log_update();
                                
                                ctx.run_later(initial_interval, move |_act, ctx| {
                                    // Wrap the async function in an actor future
                                    let fut = fetch_nodes(app_state.clone(), settings_clone.clone());
                                    let fut = actix::fut::wrap_future::<_, Self>(fut);
                                    
                                    ctx.spawn(fut.map(move |result, act, ctx| {
                                        if let Some((nodes, detailed_debug)) = result {
                                            // Now that we're back in the actor context, we can filter the nodes
                                            // Filter nodes to only include those that have changed significantly
                                            let mut filtered_nodes = Vec::new();
                                            for (node_id, node_data) in &nodes {
                                                let node_id_str = node_id.to_string();
                                                let position = node_data.position.clone();
                                                let velocity = node_data.velocity.clone();
                                                
                                                // Apply filtering before adding to filtered nodes
                                                if act.has_node_changed_significantly(
                                                    &node_id_str,
                                                    position.clone(),
                                                    velocity.clone()
                                                ) {
                                                    filtered_nodes.push((*node_id, node_data.clone()));
                                                }
                                                
                                                if detailed_debug && filtered_nodes.len() <= 5 {
                                                    debug!("Including node {} in update", node_id_str);
                                                }
                                            }
                                            
                                            // If no nodes have changed significantly, don't send an update
                                            if filtered_nodes.is_empty() {
                                                return;
                                            }
                                            
                                            // Encode only the nodes that have changed significantly
                                            let binary_data = binary_protocol::encode_node_data(&filtered_nodes);
                                            
                                            // Update motion metrics for dynamic rate adjustment
                                            act.total_node_count = filtered_nodes.len();
                                              
                                            // Count nodes in motion (with non-zero velocity)
                                            let moving_nodes = filtered_nodes.iter()
                                                .filter(|(_, node_data)| {
                                                    let vel = &node_data.velocity;
                                                    vel.x.abs() > 0.001 || vel.y.abs() > 0.001 || vel.z.abs() > 0.001
                                                })
                                                .count();
                                            
                                            act.nodes_in_motion = moving_nodes;
                                            
                                            // Update the dynamic rate based on current motion
                                            act.update_dynamic_rate();
                                            
                                            // Get the current update interval for the next update
                                            let update_interval = act.get_current_update_interval();
                                            
                                            if detailed_debug && should_log {
                                                debug!("[WebSocket] Motion: {}/{} nodes, Rate: {} updates/sec, Interval: {:?}",
                                                    moving_nodes, filtered_nodes.len(), act.current_update_rate, update_interval);
                                            }
                                            
                                            if detailed_debug && should_log && !binary_data.is_empty() {
                                                debug!("[WebSocket] Encoded binary data: {} bytes for {} nodes", binary_data.len(), filtered_nodes.len());
                                                
                                                // Log details about a sample node to track position changes
                                                if !filtered_nodes.is_empty() {
                                                    let node = &filtered_nodes[0];
                                                    debug!(
                                                        "Sample node: id={}, pos=[{:.2},{:.2},{:.2}], vel=[{:.2},{:.2},{:.2}]",
                                                        node.0, 
                                                        node.1.position.x, node.1.position.y, node.1.position.z,
                                                        node.1.velocity.x, node.1.velocity.y, node.1.velocity.z
                                                    );
                                                }
                                            }

                                            // Only send data if we have nodes to update
                                            if !filtered_nodes.is_empty() {
                                                let final_data = act.maybe_compress(binary_data);
                                                
                                                // Update performance metrics
                                                act.last_transfer_size = final_data.len();
                                                act.total_bytes_sent += final_data.len();
                                                act.update_count += 1;
                                                act.nodes_sent_count += filtered_nodes.len();
                                                let now = Instant::now();
                                                let elapsed = now.duration_since(act.last_transfer_time);
                                                act.last_transfer_time = now;
                                                
                                                // Schedule the next update using the dynamic rate
                                                let next_interval = act.get_current_update_interval();
                                                
                                                // Use a simple recursive approach to restart the cycle
                                                let _app_state = act.app_state.clone();
                    let _settings_clone = act.app_state.settings.clone();
                                                ctx.run_later(next_interval, move |act, ctx| {
                                                    // Recursively call the handler to restart the cycle
                                                    <SocketFlowServer as StreamHandler<Result<ws::Message, ws::ProtocolError>>>::handle(act, Ok(ws::Message::Text("{\"type\":\"requestPositionUpdates\"}".to_string().into())), ctx);
                                                });
                                                
                                                // Log performance metrics periodically
                                                if detailed_debug && should_log {
                                                    let avg_bytes_per_update = if act.update_count > 0 {
                                                        act.total_bytes_sent / act.update_count
                                                    } else { 0 };
                                                    
                                                    debug!("[WebSocket] Transfer: {} bytes, {} nodes, {:?} since last, avg {} bytes/update",
                                                        final_data.len(), filtered_nodes.len(), elapsed, avg_bytes_per_update);
                                                }
                                                
                                                ctx.binary(final_data);
                                            } else if detailed_debug && should_log {
                                                // Log keepalive
                                                debug!("[WebSocket] Sending keepalive (no position changes)");
                                            }
                                        }
                                    }));
                                });

                                let response = serde_json::json!({
                                    "type": "updatesStarted",
                                    "timestamp": chrono::Utc::now().timestamp_millis()
                                });
                                if let Ok(msg_str) = serde_json::to_string(&response) {
                                    self.last_activity = std::time::Instant::now();
                                    ctx.text(msg_str);
                                }
                            }
                            Some("enableRandomization") => {
                                if let Ok(enable_msg) = serde_json::from_value::<serde_json::Value>(msg.clone()) {
                                    let enabled = enable_msg.get("enabled").and_then(|e| e.as_bool()).unwrap_or(false);
                                    info!("Client requested to {} node position randomization (server-side randomization removed)", 
                                         if enabled { "enable" } else { "disable" });
                                    
                                    // Server-side randomization has been removed, but we still acknowledge the client's request
                                    // to maintain backward compatibility with existing clients
                                    actix::spawn(async move {
                                        // Log that we received the request but server-side randomization is no longer supported
                                        info!("Node position randomization request acknowledged, but server-side randomization is no longer supported");
                                        info!("Client-side randomization is now used instead");
                                    });
                                }
                            }
                            _ => {
                                warn!("[WebSocket] Unknown message type: {:?}", msg);
                            }
                        }
                    }
                    Err(e) => {
                        warn!("[WebSocket] Failed to parse text message: {}", e);
                        let error_msg = serde_json::json!({
                            "type": "error",
                            "message": format!("Failed to parse text message: {}", e)
                        });
                        if let Ok(msg_str) = serde_json::to_string(&error_msg) {
                            ctx.text(msg_str);
                        }
                    }
                }
            }
            Ok(ws::Message::Binary(data)) => {
                // Enhanced logging for binary message reception
                info!("Received binary message, length: {}", data.len());
                self.last_activity = std::time::Instant::now();
                
                // Enhanced logging for binary messages (26 bytes per node now)
                if data.len() % 26 != 0 {
                    warn!(
                        "Binary message size mismatch: {} bytes (not a multiple of 26, remainder: {})",
                        data.len(),
                        data.len() % 26
                    );
                }
                
                match binary_protocol::decode_node_data(&data) {
                    Ok(nodes) => {
                        info!("Decoded {} nodes from binary message", nodes.len());
                        let _nodes_vec: Vec<_> = nodes.clone().into_iter().collect();

                        // CRITICAL FIX: Remove node count limitation to allow processing batches from randomization
                        // Previous code only allowed 2 nodes maximum, which blocked randomization batches
                        {
                            let app_state = self.app_state.clone();
                            let nodes_vec: Vec<_> = nodes.clone().into_iter().collect();

                            let fut = async move {
                                for (node_id, node_data) in &nodes_vec {
                                    // Convert node_id to string for lookup
                                    let _node_id_str = node_id.to_string();
                                    
                                    // Debug logging for node ID tracking
                                    if *node_id < 5 {
                                        debug!(
                                            "Processing binary update for node ID: {} with position [{:.3}, {:.3}, {:.3}]",
                                            node_id, node_data.position.x, node_data.position.y, node_data.position.z
                                        );
                                    }
                                }

                                let mut graph = app_state.graph_service.get_graph_data_mut().await;
                                let mut node_map = app_state.graph_service.get_node_map_mut().await;

                                for (node_id, node_data) in nodes_vec {
                                    let node_id_str = node_id.to_string();
                                    
                                    if let Some(node) = node_map.get_mut(&node_id_str) {
                                        // Node exists with this numeric ID
                                        // Explicitly preserve existing mass and flags
                                        let original_mass = node.data.mass;
                                        let original_flags = node.data.flags;
                                        
                                        node.data.position = node_data.position;
                                        node.data.velocity = node_data.velocity;
                                        // Explicitly restore mass and flags after updating position/velocity
                                        debug!("Updated position for node ID {} to [{:.3}, {:.3}, {:.3}]", 
                                             node_id_str, node_data.position.x, node_data.position.y, node_data.position.z);
                                        node.data.mass = original_mass;
                                        node.data.flags = original_flags; // Restore flags needed for GPU code
                                    // Mass, flags, and padding are not overwritten as they're only 
                                    // present on the server side and not transmitted over the wire
                                    } else {
                                        debug!("Received update for unknown node ID: {}", node_id_str);
                                    }
                                }
                                
                                // Add more detailed debug information for mass maintenance
                                debug!("Updated node positions from binary data (preserving server-side properties)");

                                // Update graph nodes with new positions/velocities from the map, preserving other properties
                                for node in &mut graph.nodes {
                                    if let Some(updated_node) = node_map.get(&node.id) {
                                        // Explicitly preserve mass and flags before updating
                                        let original_mass = node.data.mass;
                                        let original_flags = node.data.flags;
                                        node.data.position = updated_node.data.position;
                                        node.data.velocity = updated_node.data.velocity;
                                        node.data.mass = original_mass; // Restore mass after updating
                                        node.data.flags = original_flags; // Restore flags after updating
                                    }
                                }

                                // Trigger force calculation after updating node positions
                                info!("Preparing to recalculate layout after client-side node position update");
                                
                                // Get the GPU compute from GraphService
                                let gpu_compute = app_state.graph_service.get_gpu_compute().await;
                                
                                if let Some(gpu_compute) = &gpu_compute {
                                    // Read settings outside the GraphService lock to avoid deadlocks
                                    let settings = app_state.settings.read().await;
                                    let physics_settings = settings.visualisation.physics.clone();
                                    drop(settings); // Release the read lock
                                    
                                    let params = crate::models::simulation_params::SimulationParams {
                                        iterations: physics_settings.iterations,
                                        spring_strength: physics_settings.spring_strength,
                                        repulsion: physics_settings.repulsion_strength,
                                        damping: physics_settings.damping,
                                        max_repulsion_distance: physics_settings.repulsion_distance,
                                        viewport_bounds: physics_settings.bounds_size,
                                        mass_scale: physics_settings.mass_scale,
                                        boundary_damping: physics_settings.boundary_damping,
                                        enable_bounds: physics_settings.enable_bounds,
                                        time_step: 0.016, // Fixed time step
                                        phase: crate::models::simulation_params::SimulationPhase::Dynamic,
                                        mode: crate::models::simulation_params::SimulationMode::Remote,
                                    };
                                    info!("Recalculating layout with params: spring_strength={:.3}, repulsion={:.3}, damping={:.3}", 
                                        params.spring_strength, params.repulsion, params.damping);
                                    
                                    if let Err(e) = crate::services::graph_service::GraphService::calculate_layout(gpu_compute, &mut graph, &mut node_map, &params).await {
                                        error!("Error calculating layout after node position update: {}", e);
                                    }
                                    else { 
                                        info!("Successfully recalculated layout after node position update");
                                    }
                                }
                                else {
                                    warn!("GPU compute not available, cannot recalculate layout after node position update");
                                }
                            };

                            let fut = fut.into_actor(self);
                            ctx.spawn(fut.map(|_, _, _| ()));
                        }
                    }
                    Err(e) => {
                        error!("Failed to decode binary message: {}", e);
                        let error_msg = serde_json::json!({
                            "type": "error",
                            "message": format!("Failed to decode binary message: {}", e)
                        });
                        if let Ok(msg_str) = serde_json::to_string(&error_msg) {
                            ctx.text(msg_str);
                        }
                    }
                }
            }
            Ok(ws::Message::Close(reason)) => {
                info!("[WebSocket] Client initiated close: {:?}", reason);
                ctx.close(reason); // Use client's reason for closing
                ctx.stop();
            }
            Ok(ws::Message::Continuation(_)) => {
                warn!("[WebSocket] Received unexpected continuation frame");
            }
            Ok(ws::Message::Nop) => {
                debug!("[WebSocket] Received Nop");
            }
            Err(e) => {
                error!("[WebSocket] Error in WebSocket connection: {}", e);
                // Close with protocol error status code before stopping
                ctx.close(Some(ws::CloseReason::from(ws::CloseCode::Protocol)));
            }
        }
    }
}

pub async fn socket_flow_handler(
    req: HttpRequest,
    stream: web::Payload,
    app_state_data: web::Data<AppState>, // Renamed for clarity
    pre_read_ws_settings: web::Data<PreReadSocketSettings>, // New data
) -> Result<HttpResponse, Error> {
    let app_state_arc = app_state_data.into_inner(); // Get the Arc<AppState>
    // Ensure ClientManager exists in app_state or create it if not present
    let client_manager = app_state_arc.ensure_client_manager().await;
    
    // Access debug settings through app_state (still needs async read for this one-off check)
    // Or, include debug.enable_websocket_debug in PreReadSocketSettings if frequently used here.
    // For now, keeping the async read here for just this debug flag.
    let should_debug = {
        let settings_read = app_state_arc.settings.read().await;
        settings_read.system.debug.enabled && settings_read.system.debug.enable_websocket_debug
    };

    if should_debug {
        debug!("WebSocket connection attempt from {:?}", req.peer_addr());
    }

    // Check for WebSocket upgrade
    if !req.headers().contains_key("Upgrade") {
        return Ok(HttpResponse::BadRequest().body("WebSocket upgrade required"));
    }
    
    // Pass the pre-read settings to SocketFlowServer::new
    let ws = SocketFlowServer::new(app_state_arc, pre_read_ws_settings.get_ref().clone(), Some(client_manager));

    match ws::start(ws, &req, stream) {
        Ok(response) => {
            info!("[WebSocket] Client connected successfully");
            Ok(response)
        }
        Err(e) => {
            error!("[WebSocket] Failed to start WebSocket: {}", e);
            Err(e)
        }
    }
}

----
handlers/ragflow_handler.rs
use actix_web::{web, HttpResponse, ResponseError, Responder};
use crate::AppState;
use serde::{Serialize, Deserialize};
use log::{error, info};
use serde_json::json;
use futures::StreamExt;
use actix_web::web::Bytes;
use crate::services::ragflow_service::RAGFlowError;
use actix_web::web::ServiceConfig;
use crate::types::speech::SpeechOptions;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct CreateSessionRequest {
    pub user_id: String,
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct CreateSessionResponse {
    pub success: bool,
    pub session_id: String,
    pub message: Option<String>,
}

#[derive(Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct SendMessageRequest {
    pub question: String,
    pub stream: Option<bool>,
    pub session_id: Option<String>,
    pub enable_tts: Option<bool>,
}

// Implement ResponseError for RAGFlowError
impl ResponseError for RAGFlowError {
    fn error_response(&self) -> HttpResponse {
        HttpResponse::InternalServerError()
            .json(json!({"error": self.to_string()}))
    }
}

/// Handler for sending a message to the RAGFlow service.
pub async fn send_message(
    state: web::Data<AppState>,
    request: web::Json<SendMessageRequest>,
) -> impl Responder {
    let ragflow_service = match &state.ragflow_service {
        Some(service) => service,
        None => return HttpResponse::ServiceUnavailable().json(json!({
            "error": "RAGFlow service is not available"
        }))
    };

    // Get session ID from request or use the default one from app state if not provided
    let session_id = match &request.session_id {
        Some(id) => id.clone(),
        None => state.ragflow_session_id.clone(),
    };

    let enable_tts = request.enable_tts.unwrap_or(false);
    // The quote and doc_ids parameters are not used in the new API
    match ragflow_service.send_message(
        session_id,
        request.question.clone(),
        false, // quote parameter (unused)
        None,  // doc_ids parameter (unused)
        request.stream.unwrap_or(true),
    ).await {
        Ok(response_stream) => {
            // Check if TTS is enabled and speech service exists
            if enable_tts {
                if let Some(speech_service) = &state.speech_service {
                    let speech_service = speech_service.clone();
                    // Clone the question to pass to TTS
                    let question = request.question.clone();
                    // Spawn a task to process TTS in the background
                    actix_web::rt::spawn(async move {
                        let speech_options = SpeechOptions::default();
                        // The exact question will be sent to TTS
                        if let Err(e) = speech_service.text_to_speech(question, speech_options).await {
                            error!("Error processing TTS: {:?}", e);
                        }
                    });
                }
            }
            
            // Continue with normal text response handling
            let enable_tts = enable_tts; // Clone for capture in closure
            let mapped_stream = response_stream.map(move |result| {
                result.map(|answer| {
                    // Skip empty messages (like the end marker)
                    if answer.is_empty() {
                        return Bytes::new();
                    }
                    
                    // If TTS is enabled, send answer to speech service
                    if enable_tts {
                        if let Some(speech_service) = &state.speech_service {
                            let speech_service = speech_service.clone();
                            let speech_options = SpeechOptions::default();
                            let answer_clone = answer.clone();
                            actix_web::rt::spawn(async move {
                                if let Err(e) = speech_service.text_to_speech(answer_clone, speech_options).await {
                                    error!("Error processing TTS for answer: {:?}", e);
                                }
                            });
                        }
                    }
                    
                    let json_response = json!({
                        "answer": answer,
                        "success": true
                    });
                    Bytes::from(json_response.to_string())
                })
                .map_err(|e| actix_web::error::ErrorInternalServerError(e))
            });
            HttpResponse::Ok().streaming(mapped_stream)
        },
        Err(e) => {
            error!("Error sending message: {}", e);
            HttpResponse::InternalServerError().json(json!({
                "error": format!("Failed to send message: {}", e)
            }))
        }
    }
}

/// Handler for initiating a new session with RAGFlow agent.
pub async fn create_session(
    state: web::Data<AppState>,
    request: web::Json<CreateSessionRequest>,
) -> impl Responder {
    let user_id = request.user_id.clone();
    let ragflow_service = match &state.ragflow_service {
        Some(service) => service,
        None => return HttpResponse::ServiceUnavailable().json(json!({
            "error": "RAGFlow service is not available"
        }))
    };

    match ragflow_service.create_session(user_id.clone()).await {
        Ok(session_id) => {
            // Store the session ID in the AppState for future use
            // We can't directly modify AppState through an Arc, but we can clone it and create a new state
            // For now, we'll log this situation but not update the shared state
            // In a production environment, you'd want a better solution like using RwLock for the session_id
            info!(
                "Created new RAGFlow session: {}. Note: session ID cannot be stored in shared AppState.",
                session_id
            );
            // Use the session_id directly from the request in subsequent calls
            
            HttpResponse::Ok().json(CreateSessionResponse {
                success: true,
                session_id,
                message: None,
            })
        },
        Err(e) => {
            error!("Failed to initialize chat: {}", e);
            HttpResponse::InternalServerError().json(json!({
                "error": format!("Failed to initialize chat: {}", e)
            }))
        }
    }
}

/// Handler for retrieving session history.
pub async fn get_session_history(
    state: web::Data<AppState>,
    session_id: web::Path<String>,
) -> impl Responder {
    let ragflow_service = match &state.ragflow_service {
        Some(service) => service,
        None => return HttpResponse::ServiceUnavailable().json(json!({
            "error": "RAGFlow service is not available"
        }))
    };

    match ragflow_service.get_session_history(session_id.to_string()).await {
        Ok(history) => HttpResponse::Ok().json(history),
        Err(e) => {
            error!("Failed to get session history: {}", e);
            HttpResponse::InternalServerError().json(json!({
                "error": format!("Failed to get chat history: {}", e)
            }))
        }
    }
}

/// Configure RAGFlow API routes
pub fn config(cfg: &mut ServiceConfig) {
    cfg.service(
        web::scope("/ragflow")
            .route("/session", web::post().to(create_session))
            .route("/message", web::post().to(send_message))
            .route("/history/{session_id}", web::get().to(get_session_history))
    );
}

----
handlers/speech_socket_handler.rs
use actix::prelude::*;
use actix_web::{web, Error, HttpRequest, HttpResponse};
use actix_web_actors::ws;
use log::{debug, error, info};
use std::sync::Arc;
use std::time::{Duration, Instant};
use serde::{Deserialize, Serialize};
use serde_json::json;
use crate::app_state::AppState;
use crate::types::speech::SpeechOptions;
use tokio::sync::broadcast;
use futures::FutureExt;

// Constants for heartbeat
const HEARTBEAT_INTERVAL: Duration = Duration::from_secs(5);
const CLIENT_TIMEOUT: Duration = Duration::from_secs(10);

// Define message types
#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
struct TextToSpeechRequest {
    text: String,
    voice: Option<String>,
    speed: Option<f32>,
    stream: Option<bool>,
}

#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
struct SetProviderRequest {
    provider: String,
}

pub struct SpeechSocket {
    id: String,
    app_state: Arc<AppState>,
    heartbeat: Instant,
    audio_rx: Option<broadcast::Receiver<Vec<u8>>>,
}

impl SpeechSocket {
    pub fn new(id: String, app_state: Arc<AppState>) -> Self {
        let audio_rx = if let Some(speech_service) = &app_state.speech_service {
            Some(speech_service.subscribe_to_audio())
        } else {
            None
        };

        Self {
            id,
            app_state,
            heartbeat: Instant::now(),
            audio_rx,
        }
    }
    
    // Helper method to handle heartbeat
    fn start_heartbeat(&self, ctx: &mut ws::WebsocketContext<Self>) {
        ctx.run_interval(HEARTBEAT_INTERVAL, |act, ctx| {
            if Instant::now().duration_since(act.heartbeat) > CLIENT_TIMEOUT {
                info!("SpeechSocket client heartbeat failed, disconnecting!");
                ctx.stop();
                return;
            }
            ctx.ping(b"");
        });
    }
    
    // Process text-to-speech request
    async fn process_tts_request(app_state: Arc<AppState>, req: TextToSpeechRequest) -> Result<(), String> {
        if let Some(speech_service) = &app_state.speech_service {
            // Get default settings from app state, handling optional Kokoro settings
            let settings = app_state.settings.read().await;
            let kokoro_config = settings.kokoro.as_ref(); // Get Option<&KokoroSettings>

            // Provide defaults if Kokoro config or specific fields are None
            let default_voice = kokoro_config.and_then(|k| k.default_voice.clone()).unwrap_or_else(|| "default_voice_placeholder".to_string()); // Provide a sensible default
            let default_speed = kokoro_config.and_then(|k| k.default_speed).unwrap_or(1.0);
            let default_stream = kokoro_config.and_then(|k| k.stream).unwrap_or(true); // Default to streaming?
            
            drop(settings); // Release lock
            
            // Create options with defaults or provided values
            let options = SpeechOptions {
                voice: req.voice.unwrap_or(default_voice),
                speed: req.speed.unwrap_or(default_speed),
                stream: req.stream.unwrap_or(default_stream),
            };
            
            // Send request to TTS service
            match speech_service.text_to_speech(req.text, options).await {
                Ok(_) => Ok(()),
                Err(e) => Err(format!("Failed to process TTS request: {}", e)),
            }
        } else {
            Err("Speech service is not available".to_string())
        }
    }
}

impl Actor for SpeechSocket {
    type Context = ws::WebsocketContext<Self>;

    fn started(&mut self, ctx: &mut Self::Context) {
        info!("[SpeechSocket] Client connected: {}", self.id);
        
        // Start heartbeat
        self.start_heartbeat(ctx);
        
        // Send welcome message
        let welcome = json!({
            "type": "connected",
            "message": "Connected to speech service"
        });
        
        ctx.text(welcome.to_string());
        
        // Start listening for audio data
        if let Some(mut rx) = self.audio_rx.take() {
            let addr = ctx.address();
            
            ctx.spawn(Box::pin(async move {
                while let Ok(audio_data) = rx.recv().await {
                    // Send audio data to the client
                    if addr.try_send(AudioChunkMessage(audio_data)).is_err() {
                        break;
                    }
                }
            }.into_actor(self)));
        }
    }
}

// Message type for audio data
struct AudioChunkMessage(Vec<u8>);

impl Message for AudioChunkMessage {
    type Result = ();
}

impl Handler<AudioChunkMessage> for SpeechSocket {
    type Result = ();

    fn handle(&mut self, msg: AudioChunkMessage, ctx: &mut Self::Context) -> Self::Result {
        // Send binary audio data to the client
        ctx.binary(msg.0);
    }
}

impl StreamHandler<Result<ws::Message, ws::ProtocolError>> for SpeechSocket {
    fn handle(&mut self, msg: Result<ws::Message, ws::ProtocolError>, ctx: &mut Self::Context) {
        match msg {
            Ok(ws::Message::Ping(msg)) => {
                self.heartbeat = Instant::now();
                ctx.pong(&msg);
            }
            Ok(ws::Message::Pong(_)) => {
                self.heartbeat = Instant::now();
            }
            Ok(ws::Message::Text(text)) => {
                debug!("[SpeechSocket] Received text: {}", text);
                self.heartbeat = Instant::now();
                
                // Parse the message
                match serde_json::from_str::<serde_json::Value>(&text) {
                    Ok(msg) => {
                        // Process based on message type
                        let msg_type = msg.get("type").and_then(|t| t.as_str());
                        match msg_type {
                            Some("tts") => {
                                // Parse as TextToSpeechRequest
                                if let Ok(tts_req) = serde_json::from_value::<TextToSpeechRequest>(msg) {
                                    // Process TTS request
                                    let app_state = self.app_state.clone();
                                    let fut = Self::process_tts_request(app_state, tts_req).boxed().into_actor(self);
                                    ctx.spawn(fut.map(|result, _, ctx| {
                                        if let Err(e) = result {
                                            let error_msg = json!({
                                                "type": "error",
                                                "message": e
                                            });
                                            ctx.text(error_msg.to_string());
                                        }
                                    }));
                                } else {
                                    ctx.text(json!({"type": "error", "message": "Invalid TTS request format"}).to_string());
                                }
                            }
                            _ => {
                                ctx.text(json!({"type": "error", "message": "Unknown message type"}).to_string());
                            }
                        }
                    }
                    Err(e) => {
                        ctx.text(json!({"type": "error", "message": format!("Invalid JSON: {}", e)}).to_string());
                    }
                }
            }
            Ok(ws::Message::Binary(_)) => {
                // Binary data from client not supported in this handler
                ctx.text(json!({"type": "error", "message": "Binary data not supported"}).to_string());
            }
            Ok(ws::Message::Close(reason)) => {
                info!("[SpeechSocket] Client disconnected: {}", self.id);
                ctx.close(reason);
                ctx.stop();
            }
            _ => (),
        }
    }
}

// Handler for the WebSocket route
pub async fn speech_socket_handler(
    req: HttpRequest,
    stream: web::Payload,
    app_state: web::Data<AppState>,
) -> Result<HttpResponse, Error> {
    let socket_id = format!("speech_{}", uuid::Uuid::new_v4());
    let socket = SpeechSocket::new(socket_id, app_state.into_inner());
    
    match ws::start(socket, &req, stream) {
        Ok(response) => {
            info!("[SpeechSocket] WebSocket connection established");
            Ok(response)
        }
        Err(e) => {
            error!("[SpeechSocket] Failed to start WebSocket: {}", e);
            Err(e)
        }
    }
}
----
handlers/nostr_handler.rs
use crate::app_state::AppState;
use crate::models::protected_settings::ApiKeys;
use crate::services::nostr_service::{NostrService, AuthEvent, NostrError};
use crate::config::feature_access::FeatureAccess;
use actix_web::{web, Error, HttpRequest, HttpResponse};
use serde::{Deserialize, Serialize};
use serde_json::json;

#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct AuthResponse {
    pub user: UserResponseDTO,
    pub token: String,
    pub expires_at: i64,
    pub features: Vec<String>,
}

// Data transfer object for user response that matches client expectations
#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct UserResponseDTO {
    pub pubkey: String,
    pub npub: Option<String>,
    pub is_power_user: bool,
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct VerifyResponse {
    pub valid: bool,
    pub user: Option<UserResponseDTO>,
    pub features: Vec<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ApiKeysRequest {
    pub perplexity: Option<String>,
    pub openai: Option<String>,
    pub ragflow: Option<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ValidateRequest {
    pub pubkey: String,
    pub token: String,
}

pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/auth/nostr")  // Now mounted under /api/auth/nostr due to API handler configuration
            .route("", web::post().to(login))
            .route("", web::delete().to(logout))
            .route("/verify", web::post().to(verify))
            .route("/refresh", web::post().to(refresh))
            .route("/api-keys", web::post().to(update_api_keys))
            .route("/api-keys", web::get().to(get_api_keys))
            .route("/power-user-status", web::get().to(check_power_user_status))
            .route("/features", web::get().to(get_available_features))
            .route("/features/{feature}", web::get().to(check_feature_access))
    );
}

async fn check_power_user_status(
    req: HttpRequest,
    feature_access: web::Data<FeatureAccess>,
) -> Result<HttpResponse, Error> {
    let pubkey = req.headers()
        .get("X-Nostr-Pubkey")
        .and_then(|h| h.to_str().ok())
        .unwrap_or("");

    if pubkey.is_empty() {
        return Ok(HttpResponse::BadRequest().json(json!({
            "error": "Missing Nostr pubkey"
        })));
    }

    Ok(HttpResponse::Ok().json(json!({
        "is_power_user": feature_access.is_power_user(pubkey)
    })))
}

async fn get_available_features(
    req: HttpRequest,
    feature_access: web::Data<FeatureAccess>,
) -> Result<HttpResponse, Error> {
    let pubkey = req.headers()
        .get("X-Nostr-Pubkey")
        .and_then(|h| h.to_str().ok())
        .unwrap_or("");

    if pubkey.is_empty() {
        return Ok(HttpResponse::BadRequest().json(json!({
            "error": "Missing Nostr pubkey"
        })));
    }

    let features = feature_access.get_available_features(pubkey);
    Ok(HttpResponse::Ok().json(json!({
        "features": features
    })))
}

async fn check_feature_access(
    req: HttpRequest,
    feature_access: web::Data<FeatureAccess>,
    feature: web::Path<String>,
) -> Result<HttpResponse, Error> {
    let pubkey = req.headers()
        .get("X-Nostr-Pubkey")
        .and_then(|h| h.to_str().ok())
        .unwrap_or("");

    if pubkey.is_empty() {
        return Ok(HttpResponse::BadRequest().json(json!({
            "error": "Missing Nostr pubkey"
        })));
    }

    Ok(HttpResponse::Ok().json(json!({
        "has_access": feature_access.has_feature_access(pubkey, &feature)
    })))
}

async fn login(
    event: web::Json<AuthEvent>,
    nostr_service: web::Data<NostrService>,
    feature_access: web::Data<FeatureAccess>,
) -> Result<HttpResponse, Error> {
    match nostr_service.verify_auth_event(event.into_inner()).await {
        Ok(user) => {
            let token = user.session_token.clone().unwrap_or_default();
            let expires_at = user.last_seen + std::env::var("AUTH_TOKEN_EXPIRY")
                .unwrap_or_else(|_| "3600".to_string())
                .parse::<i64>()
                .unwrap_or(3600);

            // Get available features for the user
            let features = feature_access.get_available_features(&user.pubkey);

            // Create simplified user DTO for response
            let user_dto = UserResponseDTO {
                pubkey: user.pubkey.clone(),
                npub: Some(user.npub.clone()),
                is_power_user: user.is_power_user,
            };

            Ok(HttpResponse::Ok().json(AuthResponse {
                user: user_dto,
                token,
                expires_at,
                features,
            }))
        }
        Err(NostrError::InvalidSignature) => {
            Ok(HttpResponse::Unauthorized().json(json!({
                "error": "Invalid signature"
            })))
        }
        Err(e) => {
            Ok(HttpResponse::InternalServerError().json(json!({
                "error": format!("Authentication error: {}", e)
            })))
        }
    }
}

async fn logout(
    req: web::Json<ValidateRequest>,
    nostr_service: web::Data<NostrService>,
) -> Result<HttpResponse, Error> {
    // Validate session before logout
    if !nostr_service.validate_session(&req.pubkey, &req.token).await {
        return Ok(HttpResponse::Unauthorized().json(json!({
            "error": "Invalid session"
        })));
    }

    match nostr_service.logout(&req.pubkey).await {
        Ok(_) => Ok(HttpResponse::Ok().json(json!({
            "message": "Logged out successfully"
        }))),
        Err(e) => Ok(HttpResponse::InternalServerError().json(json!({
            "error": format!("Logout error: {}", e)
        }))),
    }
}

async fn verify(
    req: web::Json<ValidateRequest>,
    nostr_service: web::Data<NostrService>,
    feature_access: web::Data<FeatureAccess>,
) -> Result<HttpResponse, Error> {
    let is_valid = nostr_service.validate_session(&req.pubkey, &req.token).await;
    let user = if is_valid {
        nostr_service.get_user(&req.pubkey).await
                .map(|u| UserResponseDTO {
                    pubkey: u.pubkey,
                    npub: Some(u.npub),
                    is_power_user: u.is_power_user,
                })
    } else {
        None
    };

    // Get available features if session is valid
    let features = if is_valid {
        feature_access.get_available_features(&req.pubkey)
    } else {
        Vec::new()
    };

    Ok(HttpResponse::Ok().json(VerifyResponse {
        valid: is_valid,
        user,
        features,
    }))
}

async fn refresh(
    req: web::Json<ValidateRequest>,
    nostr_service: web::Data<NostrService>,
    feature_access: web::Data<FeatureAccess>,
) -> Result<HttpResponse, Error> {
    // First validate the current session
    if !nostr_service.validate_session(&req.pubkey, &req.token).await {
        return Ok(HttpResponse::Unauthorized().json(json!({
            "error": "Invalid session"
        })));
    }

    match nostr_service.refresh_session(&req.pubkey).await {
        Ok(new_token) => {
            if let Some(user) = nostr_service.get_user(&req.pubkey).await {
                let expires_at = user.last_seen + std::env::var("AUTH_TOKEN_EXPIRY")
                    .unwrap_or_else(|_| "3600".to_string())
                    .parse::<i64>()
                    .unwrap_or(3600);
// Get available features for the refreshed session
let features = feature_access.get_available_features(&req.pubkey);

Ok(HttpResponse::Ok().json(AuthResponse {
    user: UserResponseDTO {
        pubkey: user.pubkey.clone(),
        npub: Some(user.npub.clone()),
        is_power_user: user.is_power_user,
    },
    token: new_token,
    expires_at,
    features,
}))
} else {
                Ok(HttpResponse::InternalServerError().json(json!({
                    "error": "User not found after refresh"
                })))
            }
        }
        Err(e) => Ok(HttpResponse::InternalServerError().json(json!({
            "error": format!("Session refresh error: {}", e)
        }))),
    }
}

async fn update_api_keys(
    req: web::Json<ApiKeysRequest>,
    nostr_service: web::Data<NostrService>,
    pubkey: web::Path<String>,
) -> Result<HttpResponse, Error> {
    let api_keys = ApiKeys {
        perplexity: req.perplexity.clone(),
        openai: req.openai.clone(),
        ragflow: req.ragflow.clone(),
    };

    match nostr_service.update_user_api_keys(&pubkey, api_keys).await {
        Ok(user) => {
            let user_dto = UserResponseDTO {
                pubkey: user.pubkey.clone(),
                npub: Some(user.npub.clone()),
                is_power_user: user.is_power_user,
            };
            Ok(HttpResponse::Ok().json(user_dto))
        },
        Err(NostrError::UserNotFound) => {
            Ok(HttpResponse::NotFound().json(json!({
                "error": "User not found"
            })))
        }
        Err(NostrError::PowerUserOperation) => {
            Ok(HttpResponse::Forbidden().json(json!({
                "error": "Cannot update API keys for power users"
            })))
        }
        Err(e) => {
            Ok(HttpResponse::InternalServerError().json(json!({
                "error": format!("Failed to update API keys: {}", e)
            })))
        }
    }
}

async fn get_api_keys(
    state: web::Data<AppState>,
    pubkey: web::Path<String>,
) -> Result<HttpResponse, Error> {
    let protected_settings = state.protected_settings.read().await;
    let api_keys = protected_settings.get_api_keys(&pubkey);
    
    Ok(HttpResponse::Ok().json(api_keys))
}

// Add the handler to app_state initialization
pub fn init_nostr_service(app_state: &mut AppState) {
    let nostr_service = NostrService::new();
    
    // Start session cleanup task
    let service_clone = nostr_service.clone();
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(tokio::time::Duration::from_secs(3600)); // Every hour
        loop {
            interval.tick().await;
            service_clone.cleanup_sessions(24).await; // Clean up sessions older than 24 hours
        }
    });

    app_state.nostr_service = Some(web::Data::new(nostr_service));
}
----
handlers/perplexity_handler.rs
use crate::AppState;
use actix_web::{post, web, HttpResponse, Responder};
use serde::{Deserialize, Serialize};
use serde_json::json;
use log::{error, info};

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct PerplexityRequest {
    pub query: String,
    pub conversation_id: Option<String>,
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct PerplexityResponse {
    pub answer: String,
    pub conversation_id: String,
}

#[post("")]
pub async fn handle_perplexity(
    state: web::Data<AppState>,
    request: web::Json<PerplexityRequest>,
) -> impl Responder {
    info!("Received perplexity request: {:?}", request);

    let perplexity_service = match &state.perplexity_service {
        Some(service) => service,
        None => return HttpResponse::ServiceUnavailable().json(json!({
            "error": "Perplexity service is not available"
        }))
    };

    let conversation_id = state.ragflow_session_id.clone();
    match perplexity_service.query(&request.query, &conversation_id).await {
        Ok(answer) => {
            let response = PerplexityResponse {
                answer,
                conversation_id,
            };
            HttpResponse::Ok().json(response)
        }
        Err(e) => {
            error!("Error processing perplexity request: {}", e);
            HttpResponse::InternalServerError().json(format!("Error: {}", e))
        }
    }
}

----
handlers/api_handler/mod.rs
pub mod files;
pub mod graph;
pub mod visualisation;

// Re-export specific types and functions
// Re-export specific types and functions
pub use files::{
    fetch_and_process_files,
    get_file_content,
};

pub use graph::{
    get_graph_data,
    get_paginated_graph_data,
    refresh_graph,
    update_graph,
};

pub use visualisation::get_visualisation_settings;

use actix_web::web;

// Configure all API routes
pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/api")
            .configure(files::config)
            .configure(graph::config)
            .configure(visualisation::config)
            .configure(crate::handlers::nostr_handler::config)
            .configure(crate::handlers::settings_handler::config)
    );
}

----
handlers/api_handler/visualisation/mod.rs
use crate::config::Settings;
use crate::AppState;
use actix_web::{error::ErrorInternalServerError, web, Error, HttpResponse, Result};
use log::{debug, error, info};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::collections::HashMap;
use std::fs;
use std::path::PathBuf;
use std::sync::Arc;
use tokio::sync::RwLock;

// Internal helper function to convert camelCase or kebab-case to snake_case
// This replaces the dependency on case_conversion.rs
fn to_snake_case(s: &str) -> String {
    // First handle kebab-case by replacing hyphens with underscores
    let s = s.replace('-', "_");
    
    // Then handle camelCase by adding underscores before uppercase letters
    let mut result = String::with_capacity(s.len() + 4);
    let mut chars = s.chars().peekable();
    
    while let Some(c) = chars.next() {
        if c.is_ascii_uppercase() {
            // If this is an uppercase letter, add an underscore before it
            // unless it's at the beginning of the string
            if !result.is_empty() {
                result.push('_');
            }
            result.push(c.to_ascii_lowercase());
        } else {
            result.push(c);
        }
    }
    result
}

#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct SettingResponse {
    pub category: String,
    pub setting: String,
    pub value: Value,
    pub success: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub error: Option<String>,
}

#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct CategorySettingsResponse {
    pub category: String,
    pub settings: HashMap<String, Value>,
    pub success: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub error: Option<String>,
}

#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct SettingValue {
    pub value: Value,
}

fn get_setting_value(settings: &Settings, category: &str, setting: &str) -> Result<Value, String> {
    debug!(
        "Attempting to get setting value for category: {}, setting: {}",
        category, setting
    );

    let category_snake = to_snake_case(category);
    let setting_snake = to_snake_case(setting);
    debug!(
        "Converted category '{}' to snake_case: '{}'",
        category, category_snake
    );
    debug!(
        "Converted setting '{}' to snake_case: '{}'",
        setting, setting_snake
    );

    let settings_value = match serde_json::to_value(&settings) {
        Ok(v) => {
            debug!("Successfully serialized settings to JSON");
            v
        }
        Err(e) => {
            error!("Failed to serialize settings to JSON: {}", e);
            return Err(format!("Failed to serialize settings: {}", e));
        }
    };

    debug!("Settings JSON structure: {}", settings_value);

    // Handle nested categories
    let parts: Vec<&str> = category_snake.split('.').collect();
    let mut current_value = &settings_value;

    for part in parts {
        current_value = match current_value.get(part) {
            Some(v) => {
                debug!("Found category part '{}' in settings", part);
                v
            }
            None => {
                error!("Category part '{}' not found in settings", part);
                return Err(format!("Category '{}' not found", category));
            }
        };
    }

    let setting_value = match current_value.get(&setting_snake) {
        Some(v) => {
            debug!(
                "Found setting '{}' in category '{}'",
                setting_snake, category_snake
            );
            v
        }
        None => {
            error!(
                "Setting '{}' not found in category '{}'",
                setting_snake, category_snake
            );
            return Err(format!(
                "Setting '{}' not found in category '{}'",
                setting, category
            ));
        }
    };

    debug!("Found setting value: {:?}", setting_value);
    Ok(setting_value.clone())
}

fn update_setting_value(
    settings: &mut Settings,
    category: &str,
    setting: &str,
    value: &Value,
) -> Result<(), String> {
    debug!(
        "Attempting to update setting value for category: {}, setting: {}",
        category, setting
    );

    let category_snake = to_snake_case(category);
    let setting_snake = to_snake_case(setting);
    debug!(
        "Converted category '{}' to snake_case: '{}'",
        category, category_snake
    );
    debug!(
        "Converted setting '{}' to snake_case: '{}'",
        setting, setting_snake
    );

    let mut settings_value = match serde_json::to_value(&*settings) {
        Ok(v) => {
            debug!("Successfully serialized settings to JSON");
            v
        }
        Err(e) => {
            error!("Failed to serialize settings to JSON: {}", e);
            return Err(format!("Failed to serialize settings: {}", e));
        }
    };

    debug!("Settings JSON structure: {}", settings_value);

    // Handle nested categories
    let parts: Vec<&str> = category_snake.split('.').collect();
    let mut current_value = &mut settings_value;

    for part in parts {
        current_value = match current_value.get_mut(part) {
            Some(v) => {
                debug!("Found category part '{}' in settings", part);
                v
            }
            None => {
                error!("Category part '{}' not found in settings", part);
                return Err(format!("Category '{}' not found", category));
            }
        };
    }

    if let Some(obj) = current_value.as_object_mut() {
        obj.insert(setting_snake.to_string(), value.clone());
        debug!("Updated setting value successfully");

        match serde_json::from_value(settings_value) {
            Ok(new_settings) => {
                debug!("Successfully converted updated JSON back to Settings");
                *settings = new_settings;
                Ok(())
            }
            Err(e) => {
                error!("Failed to convert JSON back to Settings: {}", e);
                Err(format!("Failed to deserialize settings: {}", e))
            }
        }
    } else {
        error!("Category '{}' is not an object", category_snake);
        Err(format!("Category '{}' is not an object", category))
    }
}

fn get_category_settings_value(settings: &Settings, category: &str) -> Result<Value, String> {
    debug!("Getting settings for category: {}", category);
    let settings_value = serde_json::to_value(&settings)
        .map_err(|e| format!("Failed to serialize settings: {}", e))?;

    // Handle nested categories
    let parts: Vec<&str> = category.split('.').collect();
    let mut current_value = &settings_value;

    for part in parts {
        current_value = match current_value.get(part) {
            Some(v) => {
                debug!("Found category part '{}' in settings", part);
                v
            }
            None => {
                error!("Category part '{}' not found in settings", part);
                return Err(format!("Category '{}' not found", category));
            }
        };
    }

    debug!("Successfully retrieved settings for category: {}", category);
    Ok(current_value.clone())
}

pub async fn get_setting(
    settings: web::Data<Arc<RwLock<Settings>>>,
    path: web::Path<(String, String)>,
) -> HttpResponse {
    let (category, setting) = path.into_inner();
    info!(
        "Getting setting for category: {}, setting: {}",
        category, setting
    );

    let settings_guard = match settings.read().await {
        guard => {
            debug!("Successfully acquired settings read lock");
            guard
        }
    };

    match get_setting_value(&*settings_guard, &category, &setting) {
        Ok(value) => {
            debug!("Successfully retrieved setting value: {:?}", value);
            HttpResponse::Ok().json(SettingResponse {
                category,
                setting,
                value,
                success: true,
                error: None,
            })
        }
        Err(e) => {
            error!("Failed to get setting value: {}", e);
            HttpResponse::BadRequest().json(SettingResponse {
                category,
                setting,
                value: Value::Null,
                success: false,
                error: Some(e),
            })
        }
    }
}

pub async fn update_setting(
    settings: web::Data<Arc<RwLock<Settings>>>,
    path: web::Path<(String, String)>,
    value: web::Json<Value>,
) -> HttpResponse {
    let (category, setting) = path.into_inner();
    info!(
        "Updating setting for category: {}, setting: {}",
        category, setting
    );

    let mut settings_guard = match settings.write().await {
        guard => {
            debug!("Successfully acquired settings write lock");
            guard
        }
    };

    match update_setting_value(&mut *settings_guard, &category, &setting, &value) {
        Ok(_) => {
            if let Err(e) = save_settings_to_file(&*settings_guard) {
                error!("Failed to save settings to file: {}", e);
                return HttpResponse::InternalServerError().json(SettingResponse {
                    category,
                    setting,
                    value: value.into_inner(),
                    success: false,
                    error: Some("Failed to persist settings".to_string()),
                });
            }
            HttpResponse::Ok().json(SettingResponse {
                category,
                setting,
                value: value.into_inner(),
                success: true,
                error: None,
            })
        }
        Err(e) => {
            error!("Failed to update setting value: {}", e);
            HttpResponse::BadRequest().json(SettingResponse {
                category,
                setting,
                value: value.into_inner(),
                success: false,
                error: Some(e),
            })
        }
    }
}

pub async fn get_category_settings(
    settings: web::Data<Arc<RwLock<Settings>>>,
    path: web::Path<String>,
) -> HttpResponse {
    let settings_read = settings.read().await;
    let settings_value = serde_json::to_value(&*settings_read)
        .map_err(|e| format!("Failed to serialize settings: {}", e))
        .unwrap_or_default();

    let debug_enabled = settings_value
        .get("system")
        .and_then(|s| s.get("debug"))
        .and_then(|d| d.get("enabled"))
        .and_then(|e| e.as_bool())
        .unwrap_or(false);

    let log_json = debug_enabled
        && settings_value
            .get("system")
            .and_then(|s| s.get("debug"))
            .and_then(|d| d.get("log_full_json"))
            .and_then(|l| l.as_bool())
            .unwrap_or(false);

    let category = path.into_inner();
    match get_category_settings_value(&settings_read, &category) {
        Ok(value) => {
            if log_json {
                debug!(
                    "Category '{}' settings: {}",
                    category,
                    serde_json::to_string_pretty(&value).unwrap_or_default()
                );
            }
            let settings_map: HashMap<String, Value> = value
                .as_object()
                .map(|m| m.iter().map(|(k, v)| (k.clone(), v.clone())).collect())
                .unwrap_or_default();

            HttpResponse::Ok().json(CategorySettingsResponse {
                category: category.clone(),
                settings: settings_map,
                success: true,
                error: None,
            })
        }
        Err(e) => {
            error!("Failed to get category settings for '{}': {}", category, e);
            HttpResponse::NotFound().json(CategorySettingsResponse {
                category: category.clone(),
                settings: HashMap::new(),
                success: false,
                error: Some(e),
            })
        }
    }
}

pub async fn get_visualisation_settings(
    app_state: web::Data<AppState>,
    category: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    debug!("Getting settings for category: {}", category);

    if category.as_str() == "client_debug" {
        debug!("Checking UI container status for debugging");
    }

    let settings = app_state.settings.read().await;
    Ok(HttpResponse::Ok().json(&*settings))
}

pub async fn get_settings_category(
    category: web::Path<String>,
    app_state: web::Data<AppState>,
) -> Result<HttpResponse, Error> {
    let settings = app_state.settings.read().await;
    let settings_value = serde_json::to_value(&*settings).map_err(ErrorInternalServerError)?;

    let value = match category.as_str() {
        cat if cat.starts_with("visualisation.") || cat.starts_with("system.") || cat == "xr" => {
            let parts: Vec<&str> = cat.split('.').collect();
            let mut current_value = &settings_value;

            for part in parts {
                current_value = match current_value.get(part) {
                    Some(v) => v,
                    None => return Ok(HttpResponse::NotFound().finish()),
                };
            }
            current_value.clone()
        }
        _ => return Ok(HttpResponse::NotFound().finish()),
    };

    Ok(HttpResponse::Ok().json(value))
}

fn save_settings_to_file(settings: &Settings) -> std::io::Result<()> {
    debug!("Attempting to save settings to file");

    let settings_path = std::env::var("SETTINGS_FILE_PATH")
        .map(PathBuf::from)
        .unwrap_or_else(|_| PathBuf::from("/app/settings.yaml"));

    info!("Attempting to save settings to: {:?}", settings_path);

    if let Some(parent) = settings_path.parent() {
        match fs::create_dir_all(parent) {
            Ok(_) => debug!("Created parent directories: {:?}", parent),
            Err(e) => {
                error!("Failed to create parent directories: {}", e);
                return Err(e);
            }
        }
    }

    if settings_path.exists() {
        match fs::metadata(&settings_path) {
            Ok(metadata) => {
                if metadata.permissions().readonly() {
                    error!("Settings file is read-only: {:?}", settings_path);
                    return Err(std::io::Error::new(
                        std::io::ErrorKind::PermissionDenied,
                        "Settings file is read-only",
                    ));
                }
            }
            Err(e) => {
                error!("Failed to check settings file permissions: {}", e);
                return Err(e);
            }
        }
    }

    let yaml_string = match serde_yaml::to_string(&settings) {
        Ok(s) => s,
        Err(e) => {
            error!("Failed to serialize settings to YAML: {}", e);
            return Err(std::io::Error::new(std::io::ErrorKind::Other, e));
        }
    };

    match fs::write(&settings_path, yaml_string) {
        Ok(_) => {
            info!("Settings saved successfully to: {:?}", settings_path);
            Ok(())
        }
        Err(e) => {
            error!("Failed to write settings file: {}", e);
            Err(e)
        }
    }
}

pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/visualisation")
            .route("/settings/{category}/{setting}", web::get().to(get_setting))
            .route(
                "/settings/{category}/{setting}",
                web::put().to(update_setting),
            )
            .route("/settings/{category}", web::get().to(get_category_settings))
            .route(
                "/get_settings/{category}",
                web::get().to(get_visualisation_settings),
            ),
    );
}

----
handlers/api_handler/files/mod.rs
use actix_web::{web, Error as ActixError, HttpResponse};
use serde_json::json;
use log::{info, debug, error};

use crate::AppState;
use crate::services::file_service::{FileService, MARKDOWN_DIR};
use crate::services::graph_service::GraphService;

pub async fn fetch_and_process_files(state: web::Data<AppState>) -> HttpResponse {
    info!("Initiating optimized file fetch and processing");

    let mut metadata_store = match FileService::load_or_create_metadata() {
        Ok(store) => store,
        Err(e) => {
            error!("Failed to load or create metadata: {}", e);
            return HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Failed to initialize metadata: {}", e)
            }));
        }
    };
    
    let file_service = FileService::new(state.settings.clone());
    
    match file_service.fetch_and_process_files(state.content_api.clone(), state.settings.clone(), &mut metadata_store).await {
        Ok(processed_files) => {
            let file_names: Vec<String> = processed_files.iter()
                .map(|pf| pf.file_name.clone())
                .collect();

            info!("Successfully processed {} public markdown files", processed_files.len());

            {
                let mut metadata = state.metadata.write().await;
                for processed_file in &processed_files {
                    metadata_store.insert(processed_file.file_name.clone(), processed_file.metadata.clone());
                    debug!("Updated metadata for: {}", processed_file.file_name);
                }
                *metadata = metadata_store.clone();
            }

            if let Err(e) = FileService::save_metadata(&metadata_store) {
                error!("Failed to save metadata: {}", e);
                return HttpResponse::InternalServerError().json(json!({
                    "status": "error",
                    "message": format!("Failed to save metadata: {}", e)
                }));
            }

            match GraphService::build_graph(&state).await {
                Ok(graph_data) => {
                    let mut graph = state.graph_service.get_graph_data_mut().await;
                    let mut node_map = state.graph_service.get_node_map_mut().await;
                    *graph = graph_data.clone();
                    
                    // Update node_map with new graph nodes
                    node_map.clear();
                    for node in &graph.nodes {
                        node_map.insert(node.id.clone(), node.clone());
                    }
                    
                    info!("Graph data structure updated successfully");

                    if let Some(gpu) = &state.gpu_compute {
                        if let Ok(_nodes) = gpu.read().await.get_node_data() {
                            debug!("GPU node positions updated successfully");
                        } else {
                            error!("Failed to get node positions from GPU");
                        }
                    }

                    HttpResponse::Ok().json(json!({
                        "status": "success",
                        "processed_files": file_names
                    }))
                },
                Err(e) => {
                    error!("Failed to build graph data: {}", e);
                    HttpResponse::InternalServerError().json(json!({
                        "status": "error",
                        "message": format!("Failed to build graph data: {}", e)
                    }))
                }
            }
        },
        Err(e) => {
            error!("Error processing files: {}", e);
            HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Error processing files: {}", e)
            }))
        }
    }
}

pub async fn get_file_content(_state: web::Data<AppState>, file_name: web::Path<String>) -> HttpResponse {
    let file_path = format!("{}/{}", MARKDOWN_DIR, file_name);
    match std::fs::read_to_string(&file_path) {
        Ok(content) => HttpResponse::Ok().body(content),
        Err(e) => {
            error!("Failed to read file {}: {}", file_name, e);
            HttpResponse::NotFound().json(json!({
                "status": "error",
                "message": format!("File not found or unreadable: {}", file_name)
            }))
        }
    }
}

pub async fn refresh_graph(state: web::Data<AppState>) -> HttpResponse {
    info!("Manually triggering graph refresh");

    let metadata_store = match FileService::load_or_create_metadata() {
        Ok(store) => store,
        Err(e) => {
            error!("Failed to load metadata: {}", e);
            return HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Failed to load metadata: {}", e)
            }));
        }
    };

    match GraphService::build_graph_from_metadata(&metadata_store).await {
        Ok(graph_data) => {
            let mut graph = state.graph_service.get_graph_data_mut().await;
            let mut node_map = state.graph_service.get_node_map_mut().await;
            *graph = graph_data.clone();
            
            // Update node_map with new graph nodes
            node_map.clear();
            for node in &graph.nodes {
                node_map.insert(node.id.clone(), node.clone());
            }
            
            info!("Graph data structure refreshed successfully");

            if let Some(gpu) = &state.gpu_compute {
                if let Ok(_nodes) = gpu.read().await.get_node_data() {
                    debug!("GPU node positions updated successfully");
                } else {
                    error!("Failed to get node positions from GPU");
                }
            }

            HttpResponse::Ok().json(json!({
                "status": "success",
                "message": "Graph refreshed successfully"
            }))
        },
        Err(e) => {
            error!("Failed to refresh graph data: {}", e);
            HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Failed to refresh graph data: {}", e)
            }))
        }
    }
}

pub async fn update_graph(state: web::Data<AppState>) -> Result<HttpResponse, ActixError> {
    let metadata_store = match FileService::load_or_create_metadata() {
        Ok(store) => store,
        Err(e) => {
            error!("Failed to load metadata: {}", e);
            return Ok(HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Failed to load metadata: {}", e)
            })));
        }
    };

    match GraphService::build_graph_from_metadata(&metadata_store).await {
        Ok(graph) => {
            let mut graph_data = state.graph_service.get_graph_data_mut().await;
            let mut node_map = state.graph_service.get_node_map_mut().await;
            *graph_data = graph.clone();
            
            // Update node_map with new graph nodes
            node_map.clear();
            for node in &graph_data.nodes {
                node_map.insert(node.id.clone(), node.clone());
            }
            
            if let Some(gpu) = &state.gpu_compute {
                if let Ok(_nodes) = gpu.read().await.get_node_data() {
                    debug!("GPU node positions updated successfully");
                } else {
                    error!("Failed to get node positions from GPU");
                }
            }
            
            Ok(HttpResponse::Ok().json(json!({
                "status": "success",
                "message": "Graph updated successfully"
            })))
        },
        Err(e) => {
            error!("Failed to build graph: {}", e);
            Ok(HttpResponse::InternalServerError().json(json!({
                "status": "error",
                "message": format!("Failed to build graph: {}", e)
            })))
        }
    }
}

// Configure routes using snake_case
pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/files")
            .route("/process", web::post().to(fetch_and_process_files))
            .route("/get_content/{filename}", web::get().to(get_file_content))
            .route("/refresh_graph", web::post().to(refresh_graph))
            .route("/update_graph", web::post().to(update_graph))
    );
}

----
handlers/api_handler/graph/mod.rs
use actix_web::{web, HttpResponse, Responder};
use crate::AppState;
use serde::{Serialize, Deserialize};
use log::{info, debug, error, warn};
use std::collections::HashMap;
use std::sync::Arc;
use crate::models::metadata::Metadata;
use crate::utils::socket_flow_messages::Node;
use crate::services::file_service::FileService;
use crate::services::graph_service::GraphService;

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
pub struct GraphResponse {
    pub nodes: Vec<Node>,
    pub edges: Vec<crate::models::edge::Edge>,
    pub metadata: HashMap<String, Metadata>,
}

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
pub struct PaginatedGraphResponse {
    pub nodes: Vec<Node>,
    pub edges: Vec<crate::models::edge::Edge>,
    pub metadata: HashMap<String, Metadata>,
    pub total_pages: usize,
    pub current_page: usize,
    pub total_items: usize,
    pub page_size: usize,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct GraphQuery {
    pub query: Option<String>,
    pub page: Option<usize>,
    pub page_size: Option<usize>,
    pub sort: Option<String>,
    pub filter: Option<String>,
}

pub async fn get_graph_data(state: web::Data<AppState>) -> impl Responder {
    info!("Received request for graph data");
    let graph = state.graph_service.get_graph_data_mut().await;
    
    debug!("Preparing graph response with {} nodes and {} edges",
        graph.nodes.len(),
        graph.edges.len()
    );

    let response = GraphResponse {
        nodes: graph.nodes.clone(),
        edges: graph.edges.clone(),
        metadata: graph.metadata.clone(),
    };

    HttpResponse::Ok().json(response)
}

pub async fn get_paginated_graph_data(
    state: web::Data<AppState>,
    query: web::Query<GraphQuery>,
) -> impl Responder {
    info!("Received request for paginated graph data with params: {:?}", query);

    let page = query.page.map(|p| p.saturating_sub(1)).unwrap_or(0);
    let page_size = query.page_size.unwrap_or(100);

    if page_size == 0 {
        error!("Invalid page size: {}", page_size);
        return HttpResponse::BadRequest().json(serde_json::json!({
            "error": "Page size must be greater than 0"
        }));
    }

    let graph = state.graph_service.get_graph_data_mut().await;
    let total_items = graph.nodes.len();
    
    if total_items == 0 {
        debug!("Graph is empty");
        return HttpResponse::Ok().json(PaginatedGraphResponse {
            nodes: Vec::new(),
            edges: Vec::new(),
            metadata: HashMap::new(),
            total_pages: 0,
            current_page: 1,
            total_items: 0,
            page_size,
        });
    }

    let total_pages = (total_items + page_size - 1) / page_size;

    if page >= total_pages {
        warn!("Requested page {} exceeds total pages {}", page + 1, total_pages);
        return HttpResponse::BadRequest().json(serde_json::json!({
            "error": format!("Page {} exceeds total available pages {}", page + 1, total_pages)
        }));
    }

    let start = page * page_size;
    let end = std::cmp::min(start + page_size, total_items);

    debug!("Calculating slice from {} to {} out of {} total items", start, end, total_items);

    let page_nodes = graph.nodes[start..end].to_vec();

    let node_ids: std::collections::HashSet<_> = page_nodes.iter()
        .map(|node| node.id.clone())
        .collect();

    let relevant_edges: Vec<_> = graph.edges.iter()
        .filter(|edge| {
            node_ids.contains(&edge.source) || node_ids.contains(&edge.target)
        })
        .cloned()
        .collect();

    debug!("Found {} relevant edges for {} nodes", relevant_edges.len(), page_nodes.len());

    let response = PaginatedGraphResponse {
        nodes: page_nodes,
        edges: relevant_edges,
        metadata: graph.metadata.clone(),
        total_pages,
        current_page: page + 1,
        total_items,
        page_size,
    };

    HttpResponse::Ok().json(response)
}

pub async fn refresh_graph(state: web::Data<AppState>) -> impl Responder {
    info!("Received request to refresh graph");
    
    let metadata = state.metadata.read().await.clone();
    debug!("Building graph from {} metadata entries", metadata.len());
    
    match GraphService::build_graph_from_metadata(&metadata).await {
        Ok(mut new_graph) => {
            let mut graph = state.graph_service.get_graph_data_mut().await;
            let mut node_map = state.graph_service.get_node_map_mut().await;
            
            let old_positions: HashMap<String, (f32, f32, f32)> = graph.nodes.iter()
                .map(|node| (node.id.clone(), (node.x(), node.y(), node.z())))
                .collect();
            
            debug!("Preserved positions for {} existing nodes", old_positions.len());
            
            for node in &mut new_graph.nodes {
                if let Some(&(x, y, z)) = old_positions.get(&node.id) {
                    node.set_x(x);
                    node.set_y(y);
                    node.set_z(z);
                }
            }
            
            *graph = new_graph;
            
            // Update node_map with new graph nodes
            node_map.clear();
            for node in &graph.nodes {
                node_map.insert(node.id.clone(), node.clone());
            }
            
            info!("Graph refreshed successfully with {} nodes and {} edges", 
                graph.nodes.len(), 
                graph.edges.len()
            );
            
            HttpResponse::Ok().json(serde_json::json!({
                "success": true,
                "message": "Graph refreshed successfully"
            }))
        },
        Err(e) => {
            error!("Failed to refresh graph: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "error": format!("Failed to refresh graph: {}", e)
            }))
        }
    }
}

pub async fn update_graph(state: web::Data<AppState>) -> impl Responder {
    info!("Received request to update graph");
    
    let mut metadata = match FileService::load_or_create_metadata() {
        Ok(m) => m,
        Err(e) => {
            error!("Failed to load metadata: {}", e);
            return HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "error": format!("Failed to load metadata: {}", e)
            }));
        }
    };
    
    let file_service = FileService::new(Arc::clone(&state.settings));
    match file_service.fetch_and_process_files(state.content_api.clone(), Arc::clone(&state.settings), &mut metadata).await {
        Ok(processed_files) => {
            if processed_files.is_empty() {
                debug!("No new files to process");
                return HttpResponse::Ok().json(serde_json::json!({
                    "success": true,
                    "message": "No updates needed"
                }));
            }
            
            debug!("Processing {} new files", processed_files.len());
            
            {
                let mut app_metadata = state.metadata.write().await;
                *app_metadata = metadata.clone();
            }
            
            match GraphService::build_graph_from_metadata(&metadata).await {
                Ok(mut new_graph) => {
                    let mut graph = state.graph_service.get_graph_data_mut().await;
                    let mut node_map = state.graph_service.get_node_map_mut().await;
                    
                    let old_positions: HashMap<String, (f32, f32, f32)> = graph.nodes.iter()
                        .map(|node| (node.id.clone(), (node.x(), node.y(), node.z())))
                        .collect();
                    
                    for node in &mut new_graph.nodes {
                        if let Some(&(x, y, z)) = old_positions.get(&node.id) {
                            node.set_x(x);
                            node.set_y(y);
                            node.set_z(z);
                        }
                    }
                    
                    *graph = new_graph;
                    
                    // Update node_map with new graph nodes
                    node_map.clear();
                    for node in &graph.nodes {
                        node_map.insert(node.id.clone(), node.clone());
                    }
                    
                    debug!("Graph updated successfully");
                    
                    HttpResponse::Ok().json(serde_json::json!({
                        "success": true,
                        "message": format!("Graph updated with {} new files", processed_files.len())
                    }))
                },
                Err(e) => {
                    error!("Failed to build new graph: {}", e);
                    HttpResponse::InternalServerError().json(serde_json::json!({
                        "success": false,
                        "error": format!("Failed to build new graph: {}", e)
                    }))
                }
            }
        },
        Err(e) => {
            error!("Failed to fetch and process files: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "error": format!("Failed to fetch and process files: {}", e)
            }))
        }
    }
}

// Configure routes using snake_case
pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/graph")
            // Match client's endpoint pattern exactly
            .route("/data", web::get().to(get_graph_data))
            .route("/data/paginated", web::get().to(get_paginated_graph_data))
            .route("/update", web::post().to(update_graph))
            // Keep refresh endpoint for admin/maintenance
            .route("/refresh", web::post().to(refresh_graph))
    );
}

----
types/speech.rs
use tokio::sync::mpsc;
use std::error::Error;
use std::fmt;

#[derive(Debug)]
pub enum SpeechError {
    WebSocketError(tungstenite::Error),
    ConnectionError(String),
    SendError(mpsc::error::SendError<SpeechCommand>),
    SerializationError(serde_json::Error),
    ProcessError(std::io::Error),
    Base64Error(base64::DecodeError),
    BroadcastError(String),
    TTSError(String),
}

impl fmt::Display for SpeechError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            SpeechError::WebSocketError(e) => write!(f, "WebSocket error: {}", e),
            SpeechError::ConnectionError(msg) => write!(f, "Connection error: {}", msg),
            SpeechError::SendError(e) => write!(f, "Send error: {}", e),
            SpeechError::SerializationError(e) => write!(f, "Serialization error: {}", e),
            SpeechError::ProcessError(e) => write!(f, "Process error: {}", e),
            SpeechError::Base64Error(e) => write!(f, "Base64 error: {}", e),
            SpeechError::BroadcastError(msg) => write!(f, "Broadcast error: {}", msg),
            SpeechError::TTSError(msg) => write!(f, "TTS error: {}", msg),
        }
    }
}

impl Error for SpeechError {}

impl From<tungstenite::Error> for SpeechError {
    fn from(err: tungstenite::Error) -> Self {
        SpeechError::WebSocketError(err)
    }
}

impl From<mpsc::error::SendError<SpeechCommand>> for SpeechError {
    fn from(err: mpsc::error::SendError<SpeechCommand>) -> Self {
        SpeechError::SendError(err)
    }
}

impl From<serde_json::Error> for SpeechError {
    fn from(err: serde_json::Error) -> Self {
        SpeechError::SerializationError(err)
    }
}

impl From<std::io::Error> for SpeechError {
    fn from(err: std::io::Error) -> Self {
        SpeechError::ProcessError(err)
    }
}

impl From<base64::DecodeError> for SpeechError {
    fn from(err: base64::DecodeError) -> Self {
        SpeechError::Base64Error(err)
    }
}

#[derive(Debug, Clone)]
pub enum TTSProvider {
    OpenAI,
    Kokoro,
}

#[derive(Debug)]
pub enum SpeechCommand {
    Initialize,
    SendMessage(String),
    TextToSpeech(String, SpeechOptions),
    Close,
    SetTTSProvider(TTSProvider),
}

#[derive(Debug, Clone)]
pub struct SpeechOptions {
    pub voice: String,
    pub speed: f32,
    pub stream: bool,
}

impl Default for SpeechOptions {
    fn default() -> Self {
        Self {
            voice: "af_heart".to_string(), // Default Kokoro voice
            speed: 1.0,
            stream: true,
        }
    }
}

----
types/mod.rs
pub mod speech;
pub mod vec3;

pub use vec3::Vec3Data;

----
types/vec3.rs
use glam::Vec3;
use bytemuck::{Pod, Zeroable};
use serde::{Serialize, Deserialize};

/// A 3D vector type that is compatible with both CUDA and WebSocket binary protocol
#[repr(C)]
#[derive(Debug, Clone, Copy, Pod, Zeroable, Serialize, Deserialize)]
pub struct Vec3Data {
    pub x: f32,
    pub y: f32,
    pub z: f32,
}

impl From<Vec3> for Vec3Data {
    fn from(v: Vec3) -> Self {
        Self {
            x: v.x,
            y: v.y,
            z: v.z,
        }
    }
}

impl From<Vec3Data> for Vec3 {
    fn from(v: Vec3Data) -> Self {
        Vec3::new(v.x, v.y, v.z)
    }
}

impl From<[f32; 3]> for Vec3Data {
    fn from(arr: [f32; 3]) -> Self {
        Self {
            x: arr[0],
            y: arr[1],
            z: arr[2],
        }
    }
}

impl From<Vec3Data> for [f32; 3] {
    fn from(v: Vec3Data) -> Self {
        [v.x, v.y, v.z]
    }
}

impl Vec3Data {
    pub fn new(x: f32, y: f32, z: f32) -> Self {
        Self { x, y, z }
    }

    pub fn zero() -> Self {
        Self::new(0.0, 0.0, 0.0)
    }

    pub fn as_array(&self) -> [f32; 3] {
        [self.x, self.y, self.z]
    }

    pub fn as_vec3(&self) -> Vec3 {
        Vec3::new(self.x, self.y, self.z)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_vec3_data_conversions() {
        let vec3 = Vec3::new(1.0, 2.0, 3.0);
        let vec3_data: Vec3Data = vec3.into();
        let array: [f32; 3] = vec3_data.into();
        let back_to_vec3: Vec3 = vec3_data.into();

        assert_eq!(vec3_data.x, 1.0);
        assert_eq!(vec3_data.y, 2.0);
        assert_eq!(vec3_data.z, 3.0);
        assert_eq!(array, [1.0, 2.0, 3.0]);
        assert_eq!(back_to_vec3, vec3);
    }

    #[test]
    fn test_array_conversion() {
        let array = [1.0, 2.0, 3.0];
        let vec3_data: Vec3Data = array.into();
        let back_to_array: [f32; 3] = vec3_data.into();

        assert_eq!(vec3_data.x, 1.0);
        assert_eq!(vec3_data.y, 2.0);
        assert_eq!(vec3_data.z, 3.0);
        assert_eq!(back_to_array, array);
    }

    #[test]
    fn test_zero() {
        let zero = Vec3Data::zero();
        assert_eq!(zero.x, 0.0);
        assert_eq!(zero.y, 0.0);
        assert_eq!(zero.z, 0.0);
    }
}
----
services/perplexity_service.rs
use crate::config::AppFullSettings; // Use AppFullSettings, ConfigPerplexitySettings removed
use crate::models::metadata::Metadata;
use crate::services::file_service::ProcessedFile;
use chrono::Utc;
use log::{error, info};
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::error::Error as StdError;
use std::fs;
use std::path::Path;
use std::sync::Arc;
use tokio::sync::RwLock;
use std::collections::HashMap;

const MARKDOWN_DIR: &str = "data/markdown";

#[derive(Debug, Serialize, Deserialize)]
struct PerplexityResponse {
    content: String,
    link: String,
}

#[derive(Debug, Serialize)]
struct QueryRequest {
    query: String,
    conversation_id: String,
    model: String,
    max_tokens: u32,
    temperature: f32,
    top_p: f32,
    presence_penalty: f32,
    frequency_penalty: f32,
}

pub struct PerplexityService {
    client: Client,
    settings: Arc<RwLock<AppFullSettings>>, // Changed to AppFullSettings
}

impl PerplexityService {
    pub async fn new(settings: Arc<RwLock<AppFullSettings>>) -> Result<Self, Box<dyn StdError + Send + Sync>> { // Changed signature
        let timeout_duration = {
            let settings_read = settings.read().await;
            // Safely access optional perplexity settings, provide default timeout
            settings_read.perplexity.as_ref().and_then(|p| p.timeout).unwrap_or(30) // Default 30s
        };

        let client = Client::builder()
            .timeout(std::time::Duration::from_secs(timeout_duration)) // Use extracted timeout
            .build()?;

        Ok(Self { 
            client,
            settings: Arc::clone(&settings)
        })
    }

    pub async fn query(&self, query: &str, conversation_id: &str) -> Result<String, Box<dyn StdError + Send + Sync>> {
        let settings_read = self.settings.read().await;
        
        // Get perplexity settings or return error if not configured
        let perplexity_config = match settings_read.perplexity.as_ref() {
            Some(p) => p,
            None => return Err("Perplexity settings not configured".into()),
        };

        // Safely get required fields or return error
        let api_url = perplexity_config.api_url.as_deref().ok_or("Perplexity API URL not configured")?;
        let api_key = perplexity_config.api_key.as_deref().ok_or("Perplexity API Key not configured")?;
        let model = perplexity_config.model.as_deref().ok_or("Perplexity model not configured")?;

        info!("Sending query to Perplexity API: {}", api_url);

        // Use defaults for optional parameters if not set in config
        let request = QueryRequest {
            query: query.to_string(),
            conversation_id: conversation_id.to_string(),
            model: model.to_string(),
            max_tokens: perplexity_config.max_tokens.unwrap_or(4096),
            temperature: perplexity_config.temperature.unwrap_or(0.5),
            top_p: perplexity_config.top_p.unwrap_or(0.9),
            presence_penalty: perplexity_config.presence_penalty.unwrap_or(0.0),
            frequency_penalty: perplexity_config.frequency_penalty.unwrap_or(0.0),
        };

        let response = self.client
            .post(api_url)
            .header("Authorization", format!("Bearer {}", api_key))
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        if !status.is_success() {
            let error_text = response.text().await?;
            error!("Perplexity API error: Status: {}, Error: {}", status, error_text);
            return Err(format!("Perplexity API error: {}", error_text).into());
        }

        let perplexity_response: PerplexityResponse = response.json().await?;
        Ok(perplexity_response.content)
    }

    pub async fn process_file(&self, file_name: &str) -> Result<ProcessedFile, Box<dyn StdError + Send + Sync>> {
        let file_path = format!("{}/{}", MARKDOWN_DIR, file_name);
        if !Path::new(&file_path).exists() {
            return Err(format!("File not found: {}", file_name).into());
        }

        let content = fs::read_to_string(&file_path)?;
        let settings_read = self.settings.read().await;

        // Get perplexity settings or return error if not configured
        let perplexity_config = match settings_read.perplexity.as_ref() {
            Some(p) => p,
            None => return Err("Perplexity settings not configured".into()),
        };
        
        // Safely get required fields or return error
        let api_url = perplexity_config.api_url.as_deref().ok_or("Perplexity API URL not configured")?;
        let api_key = perplexity_config.api_key.as_deref().ok_or("Perplexity API Key not configured")?;

        info!("Sending request to Perplexity API: {}", api_url);

        // Assuming the API takes the raw content as JSON string body? If not, adjust .json(&content)
        let response = self.client
            .post(api_url)
            .header("Authorization", format!("Bearer {}", api_key))
            .json(&content)
            .send()
            .await?;

        let status = response.status();
        if !status.is_success() {
            let error_text = response.text().await?;
            error!("Perplexity API error: Status: {}, Error: {}", status, error_text);
            return Err(format!("Perplexity API error: {}", error_text).into());
        }

        let perplexity_response: PerplexityResponse = response.json().await?;
        
        // Create metadata for processed file
        let metadata = Metadata {
            file_name: file_name.to_string(),
            file_size: perplexity_response.content.len(),
            node_id: "0".to_string(), // Will be assigned properly later
            node_size: 10.0, // Default size
            hyperlink_count: 0,
            sha1: String::new(),
            last_modified: Utc::now(),
            perplexity_link: perplexity_response.link,
            last_perplexity_process: Some(Utc::now()),
            topic_counts: HashMap::new(),
        };

        Ok(ProcessedFile {
            file_name: file_name.to_string(),
            content: perplexity_response.content,
            is_public: true,
            metadata,
        })
    }
}

----
services/file_service.rs
use crate::models::metadata::{Metadata, MetadataStore, MetadataOps};
use crate::models::graph::GraphData;
use crate::config::AppFullSettings; // Use AppFullSettings, ClientFacingSettings removed
use serde::{Deserialize, Serialize};
use log::{info, debug, error};
use std::sync::atomic::{AtomicU32, Ordering};
use regex::Regex;
use std::fs;
use std::path::Path;
use chrono::Utc;
use std::sync::Arc;
use tokio::sync::RwLock;
use std::error::Error as StdError;
use std::time::Duration;
use tokio::time::sleep;
use actix_web::web;
use std::collections::HashMap;
use std::fs::File;
use std::io::Error;
use super::github::{GitHubClient, ContentAPI, GitHubConfig};

// Constants
const METADATA_PATH: &str = "/app/data/metadata/metadata.json";
pub const MARKDOWN_DIR: &str = "/app/data/markdown";
const GITHUB_API_DELAY: Duration = Duration::from_millis(500);

#[derive(Serialize, Deserialize, Clone)]
pub struct ProcessedFile {
    pub file_name: String,
    pub content: String,
    pub is_public: bool,
    pub metadata: Metadata,
}

pub struct FileService {
    _settings: Arc<RwLock<AppFullSettings>>, // Changed to AppFullSettings, prefixed with underscore
    // Counter for assigning node IDs, initialized based on existing metadata
    node_id_counter: AtomicU32,
}

impl FileService {
    pub fn new(_settings: Arc<RwLock<AppFullSettings>>) -> Self { // Changed to AppFullSettings, parameter prefixed
        // Initialize with a default counter
        let service = Self {
            _settings, // Prefixed with underscore
            node_id_counter: AtomicU32::new(1),
        };
        
        // Try to initialize the counter based on existing metadata
        if let Ok(metadata) = Self::load_or_create_metadata() {
            let max_id = metadata.get_max_node_id();
            if max_id > 0 {
                // Start from the next ID after the maximum
                service.node_id_counter.store(max_id + 1, Ordering::SeqCst);
                info!("Initialized node ID counter to {} based on existing metadata", max_id + 1);
            }
        }
        
        service
    }
    
    /// Get the next unique node ID
    fn get_next_node_id(&self) -> u32 {
        self.node_id_counter.fetch_add(1, Ordering::SeqCst)
    }
    
    /// Update node IDs for processed files
    fn update_node_ids(&self, processed_files: &mut Vec<ProcessedFile>) {
        for processed_file in processed_files {
            if processed_file.metadata.node_id == "0" {
                processed_file.metadata.node_id = self.get_next_node_id().to_string();
            }
        }
    }

    /// Process uploaded file and return graph data
    pub async fn process_file_upload(&self, payload: web::Bytes) -> Result<GraphData, Error> {
        let content = String::from_utf8(payload.to_vec())
            .map_err(|e| Error::new(std::io::ErrorKind::InvalidData, e.to_string()))?;
        let metadata = Self::load_or_create_metadata()
            .map_err(|e| Error::new(std::io::ErrorKind::Other, e))?;
        let mut graph_data = GraphData::new();
        
        // Create a temporary file to process
        let temp_filename = format!("temp_{}.md", Utc::now().timestamp());
        let temp_path = format!("{}/{}", MARKDOWN_DIR, temp_filename);
        if let Err(e) = fs::write(&temp_path, &content) {
            return Err(Error::new(std::io::ErrorKind::Other, e.to_string()));
        }

        // Extract references and create metadata
        let valid_nodes: Vec<String> = metadata.keys()
            .map(|name| name.trim_end_matches(".md").to_string())
            .collect();

        let references = Self::extract_references(&content, &valid_nodes);
        let topic_counts = Self::convert_references_to_topic_counts(references);

        // Create metadata for the uploaded file
        let file_size = content.len();
        let node_size = Self::calculate_node_size(file_size);
        let file_metadata = Metadata {
            file_name: temp_filename.clone(),
            file_size,
            node_size,
            node_id: "0".to_string(),
            hyperlink_count: Self::count_hyperlinks(&content),
            sha1: Self::calculate_sha1(&content),
            last_modified: Utc::now(),
            perplexity_link: String::new(),
            last_perplexity_process: None,
            topic_counts,
        };

        // Assign a unique node ID
        let mut file_metadata = file_metadata;
        file_metadata.node_id = self.get_next_node_id().to_string();

        // Update graph data
        graph_data.metadata.insert(temp_filename.clone(), file_metadata);

        // Clean up temporary file
        if let Err(e) = fs::remove_file(&temp_path) {
            error!("Failed to remove temporary file: {}", e);
        }

        Ok(graph_data)
    }

    /// List available files
    pub async fn list_files(&self) -> Result<Vec<String>, Error> {
        let metadata = Self::load_or_create_metadata()
            .map_err(|e| Error::new(std::io::ErrorKind::Other, e))?;
        Ok(metadata.keys().cloned().collect())
    }

    /// Load a specific file and return graph data
    pub async fn load_file(&self, filename: &str) -> Result<GraphData, Error> {
        let file_path = format!("{}/{}", MARKDOWN_DIR, filename);
        if !Path::new(&file_path).exists() {
            return Err(Error::new(std::io::ErrorKind::NotFound, format!("File not found: {}", filename)));
        }

        let content = fs::read_to_string(&file_path)
            .map_err(|e| Error::new(std::io::ErrorKind::Other, e.to_string()))?;
        let metadata = Self::load_or_create_metadata()
            .map_err(|e| Error::new(std::io::ErrorKind::Other, e))?;
        let mut graph_data = GraphData::new();

        // Extract references and update metadata
        let valid_nodes: Vec<String> = metadata.keys()
            .map(|name| name.trim_end_matches(".md").to_string())
            .collect();

        let references = Self::extract_references(&content, &valid_nodes);
        let topic_counts = Self::convert_references_to_topic_counts(references);

        // Update or create metadata for the file
        let file_size = content.len();
        let node_size = Self::calculate_node_size(file_size);
        let file_metadata = Metadata {
            file_name: filename.to_string(),
            file_size,
            node_size,
            node_id: "0".to_string(),
            hyperlink_count: Self::count_hyperlinks(&content),
            sha1: Self::calculate_sha1(&content),
            last_modified: Utc::now(),
            perplexity_link: String::new(),
            last_perplexity_process: None,
            topic_counts,
        };

        // Assign a unique node ID
        let mut file_metadata = file_metadata;
        file_metadata.node_id = self.get_next_node_id().to_string();

        // Update graph data
        graph_data.metadata.insert(filename.to_string(), file_metadata);
        
        Ok(graph_data)
    }

    /// Load metadata from file or create new if not exists
    pub fn load_or_create_metadata() -> Result<MetadataStore, String> {
        // Ensure metadata directory exists
        std::fs::create_dir_all("/app/data/metadata")
            .map_err(|e| format!("Failed to create metadata directory: {}", e))?;
        
        let metadata_path = "/app/data/metadata/metadata.json";
        
        if let Ok(file) = File::open(metadata_path) {
            info!("Loading existing metadata from {}", metadata_path);
            serde_json::from_reader(file)
                .map_err(|e| format!("Failed to parse metadata: {}", e))
        } else {
            info!("Creating new metadata file at {}", metadata_path);
            let empty_store = MetadataStore::default();
            let file = File::create(metadata_path)
                .map_err(|e| format!("Failed to create metadata file: {}", e))?;
                
            serde_json::to_writer_pretty(file, &empty_store)
                .map_err(|e| format!("Failed to write metadata: {}", e))?;
                
            // Verify file was created with correct permissions
            let metadata = std::fs::metadata(metadata_path)
                .map_err(|e| format!("Failed to verify metadata file: {}", e))?;
            
            if !metadata.is_file() {
                return Err("Metadata file was not created properly".to_string());
            }
            
            Ok(empty_store)
        }
    }

    /// Calculate node size based on file size
    fn calculate_node_size(file_size: usize) -> f64 {
        const BASE_SIZE: f64 = 1000.0; // Base file size for scaling
        const MIN_SIZE: f64 = 5.0;  // Minimum node size
        const MAX_SIZE: f64 = 50.0; // Maximum node size

        let size = (file_size as f64 / BASE_SIZE).min(5.0);
        MIN_SIZE + (size * (MAX_SIZE - MIN_SIZE) / 5.0)
    }

    /// Extract references to other files based on their names (case insensitive)
    fn extract_references(content: &str, valid_nodes: &[String]) -> Vec<String> {
        let mut references = Vec::new();
        let content_lower = content.to_lowercase();
        
        for node_name in valid_nodes {
            let node_name_lower = node_name.to_lowercase();
            
            // Create a regex pattern with word boundaries
            let pattern = format!(r"\b{}\b", regex::escape(&node_name_lower));
            if let Ok(re) = Regex::new(&pattern) {
                // Count case-insensitive matches of the filename
                let count = re.find_iter(&content_lower).count();
                
                // If we found any references, add them to the map
                if count > 0 {
                    debug!("Found {} references to {} in content", count, node_name);
                    // Add the reference multiple times based on count
                    for _ in 0..count {
                        references.push(node_name.clone());
                    }
                }
            }
        }
        
        references
    }

    fn convert_references_to_topic_counts(references: Vec<String>) -> HashMap<String, usize> {
        let mut topic_counts = HashMap::new();
        for reference in references {
            *topic_counts.entry(reference).or_insert(0) += 1;
        }
        topic_counts
    }

    /// Initialize local storage with files from GitHub
    pub async fn initialize_local_storage(
        settings: Arc<RwLock<AppFullSettings>>, // Changed to AppFullSettings
    ) -> Result<(), Box<dyn StdError + Send + Sync>> {
        // Create GitHub client using environment variables
        let github_config = GitHubConfig::from_env()
            .map_err(|e| Box::new(e) as Box<dyn StdError + Send + Sync>)?;
            
        let github = GitHubClient::new(github_config, Arc::clone(&settings)).await?;
        let content_api = ContentAPI::new(Arc::new(github));

        // Check if we already have a valid local setup
        if Self::has_valid_local_setup() {
            info!("Valid local setup found, skipping initialization");
            return Ok(());
        }

        info!("Initializing local storage with files from GitHub");

        // Ensure directories exist and have proper permissions
        Self::ensure_directories()?;

        // Get all markdown files from GitHub
        let github_files = content_api.list_markdown_files("").await?;
        info!("Found {} markdown files in GitHub", github_files.len());

        let mut metadata_store = MetadataStore::new();

        // Process files in batches to prevent timeouts
        const BATCH_SIZE: usize = 5;
        for chunk in github_files.chunks(BATCH_SIZE) {
            let mut futures = Vec::new();
            
            for file_meta in chunk {
                let file_meta = file_meta.clone();
                let content_api = content_api.clone();
                
                futures.push(async move {
                    // First check if file is public
                    match content_api.check_file_public(&file_meta.download_url).await {
                        Ok(is_public) => {
                            if !is_public {
                                debug!("Skipping non-public file: {}", file_meta.name);
                                return Ok(None);
                            }

                            // Only fetch full content for public files
                            match content_api.fetch_file_content(&file_meta.download_url).await {
                                Ok(content) => {
                                    let file_path = format!("{}/{}", MARKDOWN_DIR, file_meta.name);
                                    if let Err(e) = fs::write(&file_path, &content) {
                                        error!("Failed to write file {}: {}", file_path, e);
                                        return Err(e.into());
                                    }

                                    Ok(Some((file_meta, content)))
                                }
                                Err(e) => {
                                    error!("Failed to fetch content for {}: {}", file_meta.name, e);
                                    Err(e)
                                }
                            }
                        }
                        Err(e) => {
                            error!("Failed to check public status for {}: {}", file_meta.name, e);
                            Err(e)
                        }
                    }
                });
            }

            // Wait for batch to complete
            let results = futures::future::join_all(futures).await;
            
            for result in results {
                match result {
                    Ok(Some((file_meta, content))) => {
                        let _node_name = file_meta.name.trim_end_matches(".md").to_string();
                        let file_size = content.len();
                        let node_size = Self::calculate_node_size(file_size);

                        // Create metadata entry
                        let metadata = Metadata {
                            file_name: file_meta.name.clone(),
                            file_size,
                            node_size,
                            node_id: "0".to_string(), // Will be assigned properly later
                            hyperlink_count: Self::count_hyperlinks(&content),
                            sha1: Self::calculate_sha1(&content),
                            last_modified: file_meta.last_modified.unwrap_or_else(|| Utc::now()),
                            perplexity_link: String::new(),
                            last_perplexity_process: None,
                            topic_counts: HashMap::new(), // Will be updated later
                        };

                        metadata_store.insert(file_meta.name, metadata);
                    }
                    Ok(None) => continue, // Skipped non-public file
                    Err(e) => {
                        error!("Failed to process file in batch: {}", e);
                    }
                }
            }

            sleep(GITHUB_API_DELAY).await;
        }

        // Update topic counts after all files are processed
        Self::update_topic_counts(&mut metadata_store)?;

        // Save metadata
        info!("Saving metadata for {} public files", metadata_store.len());
        Self::save_metadata(&metadata_store)?;

        info!("Initialization complete. Processed {} public files", metadata_store.len());
        Ok(())
    }

    /// Update topic counts for all files
    fn update_topic_counts(metadata_store: &mut MetadataStore) -> Result<(), Error> {
        let valid_nodes: Vec<String> = metadata_store.keys()
            .map(|name| name.trim_end_matches(".md").to_string())
            .collect();

        for file_name in metadata_store.keys().cloned().collect::<Vec<_>>() {
            let file_path = format!("{}/{}", MARKDOWN_DIR, file_name);
            if let Ok(content) = fs::read_to_string(&file_path) {
                let references = Self::extract_references(&content, &valid_nodes);
                let topic_counts = Self::convert_references_to_topic_counts(references);
                
                if let Some(metadata) = metadata_store.get_mut(&file_name) {
                    metadata.topic_counts = topic_counts;
                }
            }
        }

        Ok(())
    }

    /// Check if we have a valid local setup
    fn has_valid_local_setup() -> bool {
        if let Ok(metadata_content) = fs::read_to_string(METADATA_PATH) {
            if metadata_content.trim().is_empty() {
                return false;
            }
            
            if let Ok(metadata) = serde_json::from_str::<MetadataStore>(&metadata_content) {
                return metadata.validate_files(MARKDOWN_DIR);
            }
        }
        false
    }

    /// Ensures all required directories exist with proper permissions
    fn ensure_directories() -> Result<(), Error> {
        // Create markdown directory
        let markdown_dir = Path::new(MARKDOWN_DIR);
        if !markdown_dir.exists() {
            info!("Creating markdown directory at {:?}", markdown_dir);
            fs::create_dir_all(markdown_dir)
                .map_err(|e| Error::new(std::io::ErrorKind::Other, format!("Failed to create markdown directory: {}", e)))?;
            // Set permissions to allow writing
            #[cfg(unix)]
            {
                use std::os::unix::fs::PermissionsExt;
                fs::set_permissions(markdown_dir, fs::Permissions::from_mode(0o777))
                    .map_err(|e| Error::new(std::io::ErrorKind::Other, format!("Failed to set markdown directory permissions: {}", e)))?;
            }
        }

        // Create metadata directory if it doesn't exist
        let metadata_dir = Path::new(METADATA_PATH).parent().unwrap();
        if !metadata_dir.exists() {
            info!("Creating metadata directory at {:?}", metadata_dir);
            fs::create_dir_all(metadata_dir)
                .map_err(|e| Error::new(std::io::ErrorKind::Other, format!("Failed to create metadata directory: {}", e)))?;
            #[cfg(unix)]
            {
                use std::os::unix::fs::PermissionsExt;
                fs::set_permissions(metadata_dir, fs::Permissions::from_mode(0o777))
                    .map_err(|e| Error::new(std::io::ErrorKind::Other, format!("Failed to set metadata directory permissions: {}", e)))?;
            }
        }

        // Verify permissions by attempting to create a test file
        let test_file = format!("{}/test_permissions", MARKDOWN_DIR);
        match fs::write(&test_file, "test") {
            Ok(_) => {
                info!("Successfully wrote test file to {}", test_file);
                fs::remove_file(&test_file)
                    .map_err(|e| Error::new(std::io::ErrorKind::Other, format!("Failed to remove test file: {}", e)))?;
                info!("Successfully removed test file");
                info!("Directory permissions verified");
                Ok(())
            },
            Err(e) => {
                error!("Failed to verify directory permissions: {}", e);
                if let Ok(current_dir) = std::env::current_dir() {
                    error!("Current directory: {:?}", current_dir);
                }
                if let Ok(dir_contents) = fs::read_dir(MARKDOWN_DIR) {
                    error!("Directory contents: {:?}", dir_contents);
                }
                Err(Error::new(std::io::ErrorKind::PermissionDenied, format!("Failed to verify directory permissions: {}", e)))
            }
        }
    }

    /// Save metadata to file
    pub fn save_metadata(metadata: &MetadataStore) -> Result<(), Error> {
        let json = serde_json::to_string_pretty(metadata)
            .map_err(|e| Error::new(std::io::ErrorKind::Other, e.to_string()))?;
        fs::write(METADATA_PATH, json)
            .map_err(|e| Error::new(std::io::ErrorKind::Other, e.to_string()))?;
        Ok(())
    }

    /// Calculate SHA1 hash of content
    fn calculate_sha1(content: &str) -> String {
        use sha1::{Sha1, Digest};
        let mut hasher = Sha1::new();
        hasher.update(content.as_bytes());
        format!("{:x}", hasher.finalize())
    }

    /// Count hyperlinks in content
    fn count_hyperlinks(content: &str) -> usize {
        let re = Regex::new(r"\[([^\]]+)\]\(([^)]+)\)").unwrap();
        re.find_iter(content).count()
    }

    /// Fetch and process files from GitHub
    pub async fn fetch_and_process_files(
        &self,
        content_api: Arc<ContentAPI>,
        _settings: Arc<RwLock<AppFullSettings>>, // Changed to AppFullSettings (though unused)
        metadata_store: &mut MetadataStore,
    ) -> Result<Vec<ProcessedFile>, Box<dyn StdError + Send + Sync>> {
        let mut processed_files = Vec::new();

        // Get all markdown files from GitHub
        let github_files = content_api.list_markdown_files("").await?;
        info!("Found {} markdown files in GitHub", github_files.len());

        // Process files in batches to prevent timeouts
        const BATCH_SIZE: usize = 5;
        for chunk in github_files.chunks(BATCH_SIZE) {
            let mut futures = Vec::new();
            
            for file_meta in chunk {
                let file_meta = file_meta.clone();
                let content_api = content_api.clone();
                
                futures.push(async move {
                    // First check if file is public
                    match content_api.check_file_public(&file_meta.download_url).await {
                        Ok(is_public) => {
                            if !is_public {
                                debug!("Skipping non-public file: {}", file_meta.name);
                                return Ok(None);
                            }

                            // Only fetch full content for public files
                            match content_api.fetch_file_content(&file_meta.download_url).await {
                                Ok(content) => {
                                    let file_path = format!("{}/{}", MARKDOWN_DIR, file_meta.name);
                                    if let Err(e) = fs::write(&file_path, &content) {
                                        error!("Failed to write file {}: {}", file_path, e);
                                        return Err(e.into());
                                    }

                                    let file_size = content.len();
                                    let node_size = Self::calculate_node_size(file_size);

                                    let metadata = Metadata {
                                        file_name: file_meta.name.clone(),
                                        file_size,
                                        node_size,
                                        node_id: "0".to_string(), // Will be assigned properly later
                                        hyperlink_count: Self::count_hyperlinks(&content),
                                        sha1: Self::calculate_sha1(&content),
                                        last_modified: file_meta.last_modified.unwrap_or_else(|| Utc::now()),
                                        perplexity_link: String::new(),
                                        last_perplexity_process: None,
                                        topic_counts: HashMap::new(), // Will be updated later
                                    };

                                    Ok(Some(ProcessedFile {
                                        file_name: file_meta.name.clone(),
                                        content,
                                        is_public: true,
                                        metadata,
                                    }))
                                }
                                Err(e) => {
                                    error!("Failed to fetch content for {}: {}", file_meta.name, e);
                                    Err(e)
                                }
                            }
                        }
                        Err(e) => {
                            error!("Failed to check public status for {}: {}", file_meta.name, e);
                            Err(e)
                        }
                    }
                });
            }

            // Wait for batch to complete
            let results = futures::future::join_all(futures).await;
            
            for result in results {
                match result {
                    Ok(Some(processed_file)) => {
                        processed_files.push(processed_file);
                    }
                    Ok(None) => continue, // Skipped non-public file
                    Err(e) => {
                        error!("Failed to process file in batch: {}", e);
                    }
                }
            }

            sleep(GITHUB_API_DELAY).await;
        }

        // Assign node IDs to any new files
        self.update_node_ids(&mut processed_files);

        // Update topic counts after all files are processed
        Self::update_topic_counts(metadata_store)?;

        Ok(processed_files)
    }
}
----
services/empty_graph_check.rs
use crate::models::graph::GraphData;
use std::io::{Error, ErrorKind};
use log::warn;

/// This function checks if a graph is empty or contains too few nodes
/// It is used before GPU operations to prevent errors
pub fn check_empty_graph(graph: &GraphData, min_nodes: usize) -> Result<(), Error> {
    // Check for completely empty graph
    if graph.nodes.is_empty() {
        return Err(Error::new(ErrorKind::InvalidData, 
            "Graph contains no nodes, cannot perform GPU computation on empty graph"));
    }
    
    // Check if graph is below recommended threshold
    if graph.nodes.len() < min_nodes {
        warn!("[Empty Graph Check] Graph contains only {} nodes, which is below the recommended minimum of {}. 
              This may cause instability in GPU computation.", graph.nodes.len(), min_nodes);
    }
    
    Ok(())
}
----
services/nostr_service.rs
use crate::models::protected_settings::{NostrUser, ApiKeys};
use crate::config::feature_access::FeatureAccess;
use nostr_sdk::{
    prelude::*,
    event::Error as EventError
};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use chrono::Utc;
use thiserror::Error;
use log::{debug, error, info};
use uuid::Uuid;

#[derive(Debug, Error)]
pub enum NostrError {
    #[error("Invalid event: {0}")]
    InvalidEvent(String),
    #[error("Invalid signature")]
    InvalidSignature,
    #[error("User not found")]
    UserNotFound,
    #[error("Invalid token")]
    InvalidToken,
    #[error("Session expired")]
    SessionExpired,
    #[error("Power user operation not allowed")]
    PowerUserOperation,
    #[error("Nostr event error: {0}")]
    NostrError(#[from] EventError),
    #[error("JSON error: {0}")]
    JsonError(#[from] serde_json::Error),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AuthEvent {
    pub id: String,
    pub pubkey: String,
    pub content: String,
    pub sig: String,
    pub created_at: i64,
    pub kind: i32,
    pub tags: Vec<Vec<String>>,
}

#[derive(Clone)]
pub struct NostrService {
    users: Arc<RwLock<HashMap<String, NostrUser>>>,
    power_user_pubkeys: Vec<String>,
    token_expiry: i64,
    feature_access: Arc<RwLock<FeatureAccess>>,
}

impl NostrService {
    pub fn new() -> Self {
        let power_users = std::env::var("POWER_USER_PUBKEYS")
            .unwrap_or_default()
            .split(',')
            .map(|s| s.trim().to_string())
            .collect();

        let token_expiry = std::env::var("AUTH_TOKEN_EXPIRY")
            .unwrap_or_else(|_| "3600".to_string())
            .parse()
            .unwrap_or(3600);

        let feature_access = Arc::new(RwLock::new(FeatureAccess::from_env()));
        Self {
            users: Arc::new(RwLock::new(HashMap::new())),
            power_user_pubkeys: power_users,
            feature_access,
            token_expiry,
        }
    }

    pub async fn verify_auth_event(&self, event: AuthEvent) -> Result<NostrUser, NostrError> {
        // Convert to Nostr Event for verification
        // Convert to JSON string and parse as Nostr Event
        debug!("Verifying auth event with id: {} and pubkey: {}", event.id, event.pubkey);

        let json_str = match serde_json::to_string(&event) {
            Ok(s) => s,
            Err(e) => {
                error!("Failed to serialize auth event with id {}: {}", event.id, e);
                return Err(NostrError::JsonError(e));
            }
        };

        debug!("Event JSON for verification (truncated): {}...", 
               if json_str.len() > 100 { &json_str[0..100] } else { &json_str });

        let nostr_event = match Event::from_json(&json_str) {
            Ok(e) => e,
            Err(e) => {
                error!("Failed to parse Nostr event for pubkey {}: {}", event.pubkey, e);
                return Err(NostrError::InvalidEvent(format!("Parse error for event {}: {}", event.id, e)));
            }
        };

        if let Err(e) = nostr_event.verify() {
            error!("Signature verification failed for pubkey {}: {}", event.pubkey, e);
            return Err(NostrError::InvalidSignature);
        }

        // Register new user if not already registered
        let mut feature_access = self.feature_access.write().await;
        if feature_access.register_new_user(&event.pubkey) {
            info!("Registered new user with basic access: {}", event.pubkey);
        }

        let now = Utc::now();
        let is_power_user = self.power_user_pubkeys.contains(&event.pubkey);

        // Generate session token
        let session_token = Uuid::new_v4().to_string();

        let user = NostrUser {
            pubkey: event.pubkey.clone(),
            npub: nostr_event.pubkey.to_bech32()
                .map_err(|_| NostrError::NostrError(EventError::InvalidId))?,
            is_power_user,
            api_keys: ApiKeys::default(),
            last_seen: now.timestamp(),
            session_token: Some(session_token),
        };

        // Log successful user creation
        info!("Created/updated user: pubkey={}, is_power_user={}", user.pubkey, user.is_power_user);

        // Store or update user
        let mut users = self.users.write().await;
        users.insert(user.pubkey.clone(), user.clone());

        Ok(user)
    }

    pub async fn get_user(&self, pubkey: &str) -> Option<NostrUser> {
        let users = self.users.read().await;
        users.get(pubkey).cloned()
    }

    pub async fn update_user_api_keys(&self, pubkey: &str, api_keys: ApiKeys) -> Result<NostrUser, NostrError> {
        let mut users = self.users.write().await;
        
        if let Some(user) = users.get_mut(pubkey) {
            if user.is_power_user {
                return Err(NostrError::PowerUserOperation);
            }
            user.api_keys = api_keys;
            user.last_seen = Utc::now().timestamp();
            Ok(user.clone())
        } else {
            Err(NostrError::UserNotFound)
        }
    }

    pub async fn validate_session(&self, pubkey: &str, token: &str) -> bool {
        if let Some(user) = self.get_user(pubkey).await {
            if let Some(session_token) = user.session_token {
                let now = Utc::now().timestamp();
                if now - user.last_seen <= self.token_expiry {
                    return session_token == token;
                }
            }
        }
        false
    }

    pub async fn refresh_session(&self, pubkey: &str) -> Result<String, NostrError> {
        let mut users = self.users.write().await;
        
        if let Some(user) = users.get_mut(pubkey) {
            let now = Utc::now().timestamp();
            let new_token = Uuid::new_v4().to_string();
            user.session_token = Some(new_token.clone());
            user.last_seen = now;
            Ok(new_token)
        } else {
            Err(NostrError::UserNotFound)
        }
    }

    pub async fn logout(&self, pubkey: &str) -> Result<(), NostrError> {
        let mut users = self.users.write().await;
        
        if let Some(user) = users.get_mut(pubkey) {
            user.session_token = None;
            user.last_seen = Utc::now().timestamp();
            Ok(())
        } else {
            Err(NostrError::UserNotFound)
        }
    }

    pub async fn cleanup_sessions(&self, max_age_hours: i64) {
        let now = Utc::now();
        let mut users = self.users.write().await;
        
        users.retain(|_, user| {
            let age = now.timestamp() - user.last_seen;
            age < (max_age_hours * 3600)
        });
    }

    pub async fn is_power_user(&self, pubkey: &str) -> bool {
        if let Some(user) = self.get_user(pubkey).await {
            user.is_power_user
        } else {
            false
        }
    }
}

impl Default for NostrService {
    fn default() -> Self {
        Self::new()
    }
}
----
services/graph_service.rs
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use tokio::sync::RwLock;
use std::collections::{HashMap, HashSet};
use actix_web::web;
use rand::distributions::{Alphanumeric, DistString};
use rand::Rng;
use std::io::{Error, ErrorKind};
use serde_json;
use std::pin::Pin;
use std::time::{Duration, Instant};
use futures::Future;
use log::{info, warn, error, debug, trace};
use scopeguard;

use tokio::fs::File as TokioFile;
use crate::models::graph::GraphData;
use crate::utils::socket_flow_messages::Node;
use crate::models::edge::Edge;
use crate::models::metadata::MetadataStore;
use crate::app_state::AppState;
use crate::config::AppFullSettings; // Use AppFullSettings, ClientFacingSettings removed
use crate::utils::gpu_compute::GPUCompute;
use crate::models::simulation_params::{SimulationParams, SimulationPhase, SimulationMode};
use crate::models::pagination::PaginatedGraphData;
use crate::handlers::socket_flow_handler::ClientManager;
use tokio::sync::Mutex;
use once_cell::sync::Lazy;

// Static flag to prevent multiple simultaneous graph rebuilds
static GRAPH_REBUILD_IN_PROGRESS: AtomicBool = AtomicBool::new(false);

// Static flag to track if a simulation loop is already running and current simulation ID
static SIMULATION_LOOP_RUNNING: AtomicBool = AtomicBool::new(false);

// A mutex to synchronize simulation loop creation and shutdown
// This is necessary to avoid race conditions when a new GraphService is created
// while an old one is being shut down
static SIMULATION_MUTEX: Lazy<Mutex<String>> = Lazy::new(|| Mutex::new(String::new()));

// Cache configuration
const NODE_POSITION_CACHE_TTL_MS: u64 = 50; // 50ms cache time
const METADATA_FILE_WAIT_TIMEOUT_MS: u64 = 5000; // 5 second wait timeout
const SHUTDOWN_TIMEOUT_MS: u64 = 5000; // 5 second shutdown timeout

// Physics stabilization constants
// const STABLE_THRESHOLD_ITERATIONS: usize = 100; // Number of iterations with minimal movement // Dead Code
// const POSITION_STABILITY_THRESHOLD: f32 = 0.001; // 1mm threshold for stability // Dead Code

// Rate limiting and conflict resolution constants
const UPDATE_RATE_LIMIT_MS: u64 = 16; // ~60fps max update rate
// const POSITION_CONFLICT_THRESHOLD: f32 = 0.001; // 1mm threshold for position conflicts // Dead Code
// const MAX_CONCURRENT_UPDATES: usize = 100; // Maximum number of node updates per batch // Dead Code
const METADATA_FILE_CHECK_INTERVAL_MS: u64 = 100; // Check every 100ms
// Constants for GPU retry mechanism
const MAX_GPU_CALCULATION_RETRIES: u32 = 3;
const GPU_RETRY_DELAY_MS: u64 = 500; // 500ms delay between retries

#[derive(Clone)]
pub struct GraphService {
    graph_data: Arc<RwLock<GraphData>>,
    shutdown_complete: Arc<AtomicBool>,
    node_map: Arc<RwLock<HashMap<String, Node>>>,
    gpu_compute: Option<Arc<RwLock<GPUCompute>>>,
    node_positions_cache: Arc<RwLock<Option<(Vec<Node>, Instant)>>>,
    last_update: Arc<RwLock<Instant>>,
    _pending_updates: Arc<RwLock<HashMap<String, (Node, Instant)>>>, // Dead Code
    cache_enabled: bool,
    simulation_id: String,
    // client_manager: Option<Arc<ClientManager>>, // Removed: ClientManager will be passed to methods needing it
    _is_initialized: Arc<AtomicBool>, // Dead Code
    shutdown_requested: Arc<AtomicBool>,
}

impl GraphService {
    pub async fn new(
        settings: Arc<RwLock<AppFullSettings>>, // Changed to AppFullSettings
        gpu_compute: Option<Arc<RwLock<GPUCompute>>>,
        client_manager_for_loop: Arc<ClientManager> // Added for the simulation loop
    ) -> Self {
        // Get physics settings
        let physics_settings = settings.read().await.visualisation.physics.clone();

        // Generate a unique ID for this GraphService instance
        let simulation_id = Alphanumeric.sample_string(&mut rand::thread_rng(), 8);
        info!("[GraphService::new] Creating new GraphService instance with ID: {}", simulation_id);
        
        // Acquire the mutex to ensure exclusive access during initialization
        let mut guard = SIMULATION_MUTEX.lock().await;
        
        // Check if there's already an instance running
        let is_running = SIMULATION_LOOP_RUNNING.load(Ordering::SeqCst);
        if is_running {
            error!("[GraphService::new] 🚨 CRITICAL: A simulation loop is already running with ID: {}! Creating a new GraphService without shutting down the previous one may cause dual simulation loops.", *guard);
            warn!("[GraphService::new] Current simulation ID: {} will replace previous ID: {}", simulation_id, *guard);
        }
        
        // Create the shared node map
        let node_map = Arc::new(RwLock::new(HashMap::new()));

        if gpu_compute.is_some() {
            info!("[GraphService] GPU compute is enabled - physics simulation will run");
            info!("[GraphService] Testing GPU compute functionality at startup");
            tokio::spawn(Self::test_gpu_at_startup(gpu_compute.clone()));
        } else {
            error!("[GraphService] GPU compute is NOT enabled - physics simulation will use CPU fallback");
        }

        // Create shutdown signal
        let shutdown_requested = Arc::new(AtomicBool::new(false));
        // Create the GraphService with caching enabled 
        let _cache = Arc::new(RwLock::new(Option::<(Vec<Node>, Instant)>::None));
        let graph_service = Self {
            graph_data: Arc::new(RwLock::new(GraphData::default())),
            shutdown_complete: Arc::new(AtomicBool::new(false)),
            node_map: node_map.clone(),
            gpu_compute,
            last_update: Arc::new(RwLock::new(Instant::now())),
            _pending_updates: Arc::new(RwLock::new(HashMap::new())), // Dead Code
            node_positions_cache: Arc::new(RwLock::new(None)),
            cache_enabled: true,
            // client_manager, // Removed
            _is_initialized: Arc::new(AtomicBool::new(false)), // Dead Code
            simulation_id: simulation_id.clone(),
            shutdown_requested: shutdown_requested.clone(),
        };
        
        // Prepare for simulation loop
        let graph_data = Arc::clone(&graph_service.graph_data);
        let node_positions_cache = Arc::clone(&graph_service.node_positions_cache);
        let gpu_compute = graph_service.gpu_compute.clone();
        let loop_simulation_id = simulation_id.clone();
        
        // Log more detailed information about the GPU compute status
        if gpu_compute.is_some() {
            info!("[GraphService] 🔹 GPU compute is enabled and will be used for physics simulation (ID: {})", simulation_id);
            // Try to gather device information
            if let Some(gpu) = &gpu_compute {
                if let Ok(gpu_lock) = gpu.try_read() {
                    info!("[GraphService] GPU device information: iterations={} (ID: {})", gpu_lock.iteration_count, simulation_id);
                }
            }
        } else {
            warn!("[GraphService] 🔸 GPU compute is NOT available - will use CPU fallback for physics (ID: {})", simulation_id);
        }
        
        // Update the current simulation ID in the shared mutex
        *guard = simulation_id.clone();
        
        // Check if a simulation loop is already running and attempt to replace it
        if SIMULATION_LOOP_RUNNING.compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst).is_err() {
            warn!("[GraphService] Simulation loop already running, attempting to replace it (new ID: {})", simulation_id);
            // We're replacing an existing simulation, wait for the flag to be reset
            // by forcing a reset ourselves since we have the mutex
            SIMULATION_LOOP_RUNNING.store(false, Ordering::SeqCst);
            // Then set it again for our new loop
            SIMULATION_LOOP_RUNNING.store(true, Ordering::SeqCst);
        }
        
        // Release the mutex before spawning the task
        drop(guard);
        
        info!("[GraphService] Starting physics simulation loop (ID: {})", loop_simulation_id);
        
        // Clone graph_service twice - one for the async block and one for return
        let _graph_service_clone = graph_service.clone(); // Prefixed with underscore as it's not directly used after cloning for the loop
        let return_service = graph_service.clone();
        let captured_client_manager = client_manager_for_loop.clone(); // Capture ClientManager for the loop
        tokio::spawn(async move {
            let params = SimulationParams {
                iterations: physics_settings.iterations,
                spring_strength: physics_settings.spring_strength,
                repulsion: physics_settings.repulsion_strength,
                damping: physics_settings.damping,
                max_repulsion_distance: physics_settings.repulsion_distance,
                viewport_bounds: physics_settings.bounds_size,
                mass_scale: physics_settings.mass_scale,
                boundary_damping: physics_settings.boundary_damping,
                enable_bounds: physics_settings.enable_bounds,
                time_step: 0.016,  // ~60fps
                phase: SimulationPhase::Dynamic,
                mode: SimulationMode::Remote,
            };
            
            // Create a guard to reset the flag when the task exits
            let loop_guard = scopeguard::guard((), |_| { 
                info!("[Graph] Physics simulation loop exiting, resetting SIMULATION_LOOP_RUNNING flag (ID: {})", loop_simulation_id);
                // Use compare_exchange to safely reset the flag
                if SIMULATION_LOOP_RUNNING.compare_exchange(true, false, Ordering::SeqCst, Ordering::SeqCst).is_ok() {
                    graph_service.shutdown_complete.store(true, Ordering::SeqCst);
                } else {
                    error!("[Graph] Failed to reset SIMULATION_LOOP_RUNNING flag - was already false (ID: {})", 
                           loop_simulation_id);
                }
            });
            
            loop {
                // Check if shutdown was requested
                if shutdown_requested.load(Ordering::SeqCst) {
                    info!("[Graph] Shutdown requested for simulation loop (ID: {})", loop_simulation_id);
                    break;
                }
                
                // Update positions - using loop ID in logs to track which loop is running
                trace!("[Graph:{}] Starting physics calculation iteration", loop_simulation_id);
                let mut graph = graph_data.write().await;
                let mut node_map = node_map.write().await;

                let gpu_status = if gpu_compute.is_some() { "available" } else { "NOT available" };
                trace!("[Graph:{}] GPU compute status: {}, physics enabled: {}",
                       loop_simulation_id, gpu_status, physics_settings.enabled);
                       
                if physics_settings.enabled {
                    if let Some(gpu) = &gpu_compute {
                        if let Err(e) = Self::calculate_layout_with_retry(gpu, &mut graph, &mut node_map, &params).await {
                            error!("[Graph:{}] Error updating positions: {}", loop_simulation_id, e);
                        } else {
                            trace!("[Graph:{}] GPU calculation completed successfully", loop_simulation_id);
                            trace!("[Graph:{}] Successfully calculated layout for {} nodes", loop_simulation_id, graph.nodes.len());
                            
                            // Broadcast position updates to all clients
                            Self::broadcast_positions(captured_client_manager.clone(), &graph.nodes).await;
                        }
                    } else {
                        // Use CPU fallback when GPU is not available
                        trace!("[Graph:{}] GPU compute not available - using CPU fallback for physics calculation", loop_simulation_id);
                        if let Err(e) = Self::calculate_layout_cpu(&mut graph, &mut node_map, &params) {
                            error!("[Graph:{}] Error updating positions with CPU fallback: {}", loop_simulation_id, e);
                        } else {
                            trace!("[Graph:{}] CPU calculation completed successfully", loop_simulation_id);
                            trace!("[Graph:{}] Successfully calculated layout with CPU fallback for {} nodes", loop_simulation_id, graph.nodes.len());
                            
                            // Broadcast position updates to all clients
                            Self::broadcast_positions(captured_client_manager.clone(), &graph.nodes).await;
                        }
                    }
                } else {
                    trace!("[Graph:{}] Physics disabled in settings - skipping physics calculation", loop_simulation_id);
                }
                drop(graph); // Release locks before sleep
                drop(node_map);
                tokio::time::sleep(tokio::time::Duration::from_millis(16)).await;
                let mut cache = node_positions_cache.write().await;
                *cache = None;
            }
            drop(loop_guard); // Explicitly drop the guard to trigger the cleanup
        }); 

        return_service
    }
    
    // Helper method to check for update rate limiting
    async fn should_rate_limit(&self) -> bool {
        let now = Instant::now();
        let last = *self.last_update.read().await;
        if now.duration_since(last).as_millis() < UPDATE_RATE_LIMIT_MS as u128 {
            return true;
        }
        *self.last_update.write().await = now;
        false
    }

    // Dead Code: Associated item `resolve_position_conflict` is never used
    // // Helper method to resolve position conflicts
    // fn resolve_position_conflict(current: &Node, update: &Node) -> Node {
    //     let mut resolved = current.clone();
        
    //     // Calculate position differences
    //     let dx = update.data.position.x - current.data.position.x;
    //     let dy = update.data.position.y - current.data.position.y;
    //     let dz = update.data.position.z - current.data.position.z;
        
    //     // If difference is significant, use update position
    //     if dx*dx + dy*dy + dz*dz > POSITION_CONFLICT_THRESHOLD*POSITION_CONFLICT_THRESHOLD { // POSITION_CONFLICT_THRESHOLD is commented out
    //         resolved.data.position = update.data.position.clone();
            
    //         // Average the velocities to smooth transitions
    //         resolved.data.velocity.x = (current.data.velocity.x + update.data.velocity.x) * 0.5;
    //         resolved.data.velocity.y = (current.data.velocity.y + update.data.velocity.y) * 0.5;
    //         resolved.data.velocity.z = (current.data.velocity.z + update.data.velocity.z) * 0.5;
    //     }
        
    //     // Preserve mass and flags from current node
    //     resolved.data.mass = current.data.mass;
    //     resolved.data.flags = current.data.flags;
        
    //     resolved
    // }

    // Dead Code: Associated item `cleanup_pending_updates` is never used
    // // Helper method to clean up old pending updates
    // async fn cleanup_pending_updates(&self) {
    //     let mut pending = self._pending_updates.write().await; // Adjusted to use _pending_updates
    //     let now = Instant::now();
    //     pending.retain(|_, (_, timestamp)| {
    //         now.duration_since(*timestamp).as_millis() < UPDATE_RATE_LIMIT_MS as u128
    //     });
    // }
 
    // Helper method to broadcast position updates to all clients
    async fn broadcast_positions(client_manager: Arc<ClientManager>, nodes: &[Node]) {
        // Clone nodes for broadcasting
        let nodes_to_broadcast = nodes.to_vec();
        
        // Broadcast to all clients through the client manager
        client_manager.broadcast_node_positions(nodes_to_broadcast).await;
    }

    /// Shutdown the simulation loop to allow creating a new instance
    pub async fn shutdown(&self) {
        info!("[GraphService] Shutting down simulation loop (ID: {})", self.simulation_id);
        
        // Acquire the mutex to ensure we don't have race conditions during shutdown
        let guard = SIMULATION_MUTEX.lock().await;
        
        // Check if this is the currently running simulation
        if *guard != self.simulation_id {
            warn!("[GraphService] Cannot shutdown simulation - current running loop has different ID: {} (this instance ID: {})", 
                  *guard, self.simulation_id);
            return;
        }
        
        // Signal the loop to stop by setting the shutdown flag
        self.shutdown_requested.store(true, Ordering::SeqCst);
        info!("[GraphService] Set shutdown flag for simulation loop (ID: {})", self.simulation_id);
        
        // Reset shutdown complete flag before waiting
        self.shutdown_complete.store(false, Ordering::SeqCst);
        
        // Wait for the loop to fully exit with a 5 second timeout
        let max_attempts = SHUTDOWN_TIMEOUT_MS / 50; // 5 seconds total at 50ms intervals
        for attempt in 0..max_attempts {
            if !SIMULATION_LOOP_RUNNING.load(Ordering::SeqCst) {
                // Double check that shutdown is complete
                if self.shutdown_complete.load(Ordering::SeqCst) {
                    info!("[GraphService] Simulation loop successfully stopped (ID: {})", self.simulation_id);
                    return;
                }
            }
            
            // Log progress every second
            if attempt % 20 == 0 {
                info!("[GraphService] Waiting for simulation loop to stop (attempt {}/{})", attempt, max_attempts);
            }
            
            tokio::time::sleep(Duration::from_millis(50)).await;
            if attempt == max_attempts - 1 {
                error!("[GraphService] Shutdown timeout after {}ms for simulation (ID: {})", 
                    SHUTDOWN_TIMEOUT_MS, self.simulation_id);
            }
        }
    }
    
    /// Get diagnostic information about the simulation status
    pub async fn get_simulation_diagnostics(&self) -> String {
        // Get the current simulation ID from the mutex
        let current_id = match SIMULATION_MUTEX.try_lock() {
            Ok(guard) => {
                let id = guard.clone();
                // Drop the guard immediately to avoid holding it
                drop(guard);
                id
            },
            Err(_) => "Unable to acquire mutex".to_string(),
        };
        
        // Check if this is the active simulation
        let is_active = current_id == self.simulation_id;
        
        // Check the global running flag
        let is_running = SIMULATION_LOOP_RUNNING.load(Ordering::SeqCst);
        
        // Check if shutdown has been requested for this instance
        let shutdown_requested = self.shutdown_requested.load(Ordering::SeqCst);
        
        format!(
            "Simulation Diagnostics:\n- This instance ID: {}\n- Current active ID: {}\n- Is this instance active: {}\n- Global running flag: {}\n- Shutdown requested: {}\n- Has GPU compute: {}",
            self.simulation_id,
            current_id,
            is_active,
            is_running,
            shutdown_requested,
            self.gpu_compute.is_some()
        )
    }
    
    /// Test GPU compute at startup to verify it's working
    async fn test_gpu_at_startup(gpu_compute: Option<Arc<RwLock<GPUCompute>>>) {
        // Add a small delay to let other initialization complete
        tokio::time::sleep(Duration::from_millis(1000)).await;
        
        info!("[GraphService] Running GPU startup test");
        
        if let Some(gpu) = &gpu_compute {
            match gpu.read().await.test_compute() {
                Ok(_) => {
                    info!("[GraphService] ✅ GPU test computation succeeded - GPU physics is working");
                },
                Err(e) => {
                    error!("[GraphService] ❌ GPU test computation failed: {}", e);
                    error!("[GraphService] The system will fall back to CPU physics which may be slower");
                    
                    // Try initializing a new GPU instance
                    info!("[GraphService] Attempting to reinitialize GPU...");
                    let _new_gpu = GPUCompute::new(&GraphData::default()).await; // Using _ to avoid unused warning
                }
            }
        } else {
            error!("[GraphService] ❌ No GPU compute instance available for testing");
        }
    }
    
    /// Wait for metadata file to be available (mounted by Docker)
    pub async fn wait_for_metadata_file() -> bool {
        info!("Checking for metadata file from Docker volume mount...");
        
        // Path to metadata file
        let metadata_path = std::path::Path::new("/app/data/metadata/metadata.json");
        
        // Start timer
        let start_time = Instant::now();
        let timeout = Duration::from_millis(METADATA_FILE_WAIT_TIMEOUT_MS);
        
        // Loop until timeout
        while start_time.elapsed() < timeout {
            // Check if file exists and is not empty
            match tokio::fs::metadata(&metadata_path).await {
                Ok(metadata) => {
                    if metadata.is_file() && metadata.len() > 0 {
                        // Try to open and validate the file
                        match TokioFile::open(&metadata_path).await {
                            Ok(_) => {
                                let elapsed = start_time.elapsed();
                                info!("Metadata file found and accessible after {:?}", elapsed);
                                return true;
                            }
                            Err(e) => {
                                trace!("Metadata file exists but couldn't be opened: {}", e);
                                // Continue waiting - might still be being written to
                            }
                        }
                    } else {
                        trace!("Metadata file exists but is empty or not a regular file");
                    }
                }
                Err(e) => {
                    trace!("Waiting for metadata file to be mounted: {}", e);
                }
            }
            
            // Sleep before checking again
            tokio::time::sleep(Duration::from_millis(METADATA_FILE_CHECK_INTERVAL_MS)).await;
        }
        
        // Timeout reached
        warn!("Timed out waiting for metadata file after {:?}", timeout);
        
        // Timeout reached, file not found or accessible
        false
    }

    pub async fn build_graph_from_metadata(metadata: &MetadataStore) -> Result<GraphData, Box<dyn std::error::Error + Send + Sync>> {
        // Check if a rebuild is already in progress
        info!("Building graph from {} metadata entries", metadata.len());
        trace!("Building graph from {} metadata entries", metadata.len());
        
        if GRAPH_REBUILD_IN_PROGRESS.compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst).is_err() {
            warn!("Graph rebuild already in progress, skipping duplicate rebuild");
            return Err("Graph rebuild already in progress".into());
        }      
        
        // Create a guard struct to ensure the flag is reset when this function returns
        struct RebuildGuard;
        impl Drop for RebuildGuard {
            fn drop(&mut self) {
                GRAPH_REBUILD_IN_PROGRESS.store(false, Ordering::SeqCst);
            }
        }
        // This guard will reset the flag when it goes out of scope
        let _guard = RebuildGuard;
        
        let mut graph = GraphData::new();
        let mut edge_map = HashMap::new();
        let mut node_map = HashMap::new();

        // First pass: Create nodes from files in metadata
        let mut valid_nodes = HashSet::new();
        trace!("Creating nodes from {} metadata entries", metadata.len());
        for file_name in metadata.keys() {
            let node_id = file_name.trim_end_matches(".md").to_string();
            valid_nodes.insert(node_id);
        }
        trace!("Created valid_nodes set with {} nodes", valid_nodes.len());

        // Create nodes for all valid node IDs
        for node_id in &valid_nodes {
            // Get metadata for this node, including the node_id if available
            let metadata_entry = graph.metadata.get(&format!("{}.md", node_id));
            let stored_node_id = metadata_entry.map(|m| m.node_id.clone());
            
            // Create node with stored ID or generate a new one if not available
            let mut node = Node::new_with_id(node_id.clone(), stored_node_id);
            graph.id_to_metadata.insert(node.id.clone(), node_id.clone());

            // Get metadata for this node
            if let Some(metadata) = metadata.get(&format!("{}.md", node_id)) {
                // Set file size which also calculates mass
                node.set_file_size(metadata.file_size as u64);  // This will update both file_size and mass
                
                // Set the node label to the file name without extension
                // This will be used as the display name for the node
                node.label = metadata.file_name.trim_end_matches(".md").to_string();
                
                // Set visual properties from metadata
                node.size = Some(metadata.node_size as f32);
                
                // Add metadata fields to node's metadata map
                // Add all relevant metadata fields to ensure consistency
                node.metadata.insert("fileName".to_string(), metadata.file_name.clone());
                
                // Add name field (without .md extension) for client-side metadata ID mapping
                if metadata.file_name.ends_with(".md") {
                    let name = metadata.file_name[..metadata.file_name.len() - 3].to_string();
                    node.metadata.insert("name".to_string(), name.clone());
                    node.metadata.insert("metadataId".to_string(), name);
                } else {
                    node.metadata.insert("name".to_string(), metadata.file_name.clone());
                    node.metadata.insert("metadataId".to_string(), metadata.file_name.clone());
                }
                
                node.metadata.insert("fileSize".to_string(), metadata.file_size.to_string());
                node.metadata.insert("nodeSize".to_string(), metadata.node_size.to_string());
                node.metadata.insert("hyperlinkCount".to_string(), metadata.hyperlink_count.to_string());
                node.metadata.insert("sha1".to_string(), metadata.sha1.clone());
                node.metadata.insert("lastModified".to_string(), metadata.last_modified.to_string());
                
                if !metadata.perplexity_link.is_empty() {
                    node.metadata.insert("perplexityLink".to_string(), metadata.perplexity_link.clone());
                }
                
                if let Some(last_process) = metadata.last_perplexity_process {
                    node.metadata.insert("lastPerplexityProcess".to_string(), last_process.to_string());
                }
                
                // We don't add topic_counts to metadata as it would create circular references
                // and is already used to create edges
                
                // Ensure flags is set to 1 (default active state)
                node.data.flags = 1;
            }

            let node_clone = node.clone();
            graph.nodes.push(node_clone);
            // Store nodes in map by numeric ID for efficient lookups
            node_map.insert(node.id.clone(), node);
        }

        // Store metadata in graph
        trace!("Storing {} metadata entries in graph", metadata.len());
        graph.metadata = metadata.clone();
        trace!("Created {} nodes in graph", graph.nodes.len());
        // Second pass: Create edges from topic counts
        for (source_file, metadata) in metadata.iter() {
            let source_id = source_file.trim_end_matches(".md").to_string();
            // Find the node with this metadata_id to get its numeric ID
            let source_node = graph.nodes.iter().find(|n| n.metadata_id == source_id);
            if source_node.is_none() {
                continue; // Skip if node not found
            }
            let source_numeric_id = source_node.unwrap().id.clone();
            
            trace!("Processing edges for source: {} (ID: {})", source_id, source_numeric_id);
            for (target_file, count) in &metadata.topic_counts {
                let target_id = target_file.trim_end_matches(".md").to_string();
                // Find the node with this metadata_id to get its numeric ID
                let target_node = graph.nodes.iter().find(|n| n.metadata_id == target_id);
                if target_node.is_none() {
                    continue; // Skip if node not found
                }
                let target_numeric_id = target_node.unwrap().id.clone();

                trace!("  Edge: {} -> {} (weight: {})", source_numeric_id, target_numeric_id, count);

                // Only create edge if both nodes exist and they're different
                if source_numeric_id != target_numeric_id {
                    let edge_key = if source_numeric_id < target_numeric_id {
                        (source_numeric_id.clone(), target_numeric_id.clone())
                    } else {
                        (target_numeric_id.clone(), source_numeric_id.clone())
                    };

                    edge_map.entry(edge_key)
                        .and_modify(|weight| *weight += *count as f32)
                        .or_insert(*count as f32);
                }
            }
        }

        // Convert edge map to edges
        trace!("Edge map contains {} unique connections", edge_map.len());
        for ((source, target), weight) in &edge_map {
            trace!("Edge map entry: {} -- {} (weight: {})", source, target, weight);
        }

        trace!("Converting edge map to {} edges", edge_map.len());
        graph.edges = edge_map.into_iter()
            .map(|((source, target), weight)| {
                Edge::new(source, target, weight)
            })
            .collect();

        // Initialize random positions
        Self::initialize_random_positions(&mut graph);

        info!("Built graph with {} nodes and {} edges", graph.nodes.len(), graph.edges.len());
        trace!("Completed graph build: {} nodes, {} edges", graph.nodes.len(), graph.edges.len());
        Ok(graph)
    }

    pub async fn build_graph(state: &web::Data<AppState>) -> Result<GraphData, Box<dyn std::error::Error + Send + Sync>> {
        info!("Building graph from app state");
        // Check if a rebuild is already in progress
        if GRAPH_REBUILD_IN_PROGRESS.compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst).is_err() {
            warn!("Graph rebuild already in progress, skipping duplicate rebuild");
            return Err("Graph rebuild already in progress".into());
        }
        
        // Create a guard struct to ensure the flag is reset when this function returns
        struct RebuildGuard;
        impl Drop for RebuildGuard {
            fn drop(&mut self) {
                GRAPH_REBUILD_IN_PROGRESS.store(false, Ordering::SeqCst);
            }
        }
        // This guard will reset the flag when it goes out of scope
        let _guard = RebuildGuard;
        
        let current_graph = state.graph_service.get_graph_data_mut().await;
        let mut graph = GraphData::new();
        let mut node_map = HashMap::new();
        trace!("Starting graph build process");

        // Copy metadata from current graph
        graph.metadata = current_graph.metadata.clone();
        trace!("Copied {} metadata entries from current graph", graph.metadata.len());
        
        let mut edge_map = HashMap::new();

        // Create nodes from metadata entries
        let mut valid_nodes = HashSet::new();
        for file_name in graph.metadata.keys() {
            let node_id = file_name.trim_end_matches(".md").to_string();
            valid_nodes.insert(node_id);
        }
        trace!("Created valid_nodes set with {} nodes", valid_nodes.len());

        // Create nodes for all valid node IDs
        for node_id in &valid_nodes {
            // Get metadata for this node, including the node_id if available
            let metadata_entry = graph.metadata.get(&format!("{}.md", node_id));
            let stored_node_id = metadata_entry.map(|m| m.node_id.clone());
            
            // Create node with stored ID or generate a new one if not available
            let mut node = Node::new_with_id(node_id.clone(), stored_node_id);
            graph.id_to_metadata.insert(node.id.clone(), node_id.clone());

            // Get metadata for this node
            if let Some(metadata) = graph.metadata.get(&format!("{}.md", node_id)) {
                // Set file size which also calculates mass
                node.set_file_size(metadata.file_size as u64);  // This will update both file_size and mass
                
                // Set the node label to the file name without extension
                // This will be used as the display name for the node
                node.label = metadata.file_name.trim_end_matches(".md").to_string();
                
                // Set visual properties from metadata
                node.size = Some(metadata.node_size as f32);
                
                // Add metadata fields to node's metadata map
                // Add all relevant metadata fields to ensure consistency
                node.metadata.insert("fileName".to_string(), metadata.file_name.clone());
                
                // Add name field (without .md extension) for client-side metadata ID mapping
                if metadata.file_name.ends_with(".md") {
                    let name = metadata.file_name[..metadata.file_name.len() - 3].to_string();
                    node.metadata.insert("name".to_string(), name.clone());
                    node.metadata.insert("metadataId".to_string(), name);
                } else {
                    node.metadata.insert("name".to_string(), metadata.file_name.clone());
                    node.metadata.insert("metadataId".to_string(), metadata.file_name.clone());
                }
                
                node.metadata.insert("fileSize".to_string(), metadata.file_size.to_string());
                node.metadata.insert("nodeSize".to_string(), metadata.node_size.to_string());
                node.metadata.insert("hyperlinkCount".to_string(), metadata.hyperlink_count.to_string());
                node.metadata.insert("sha1".to_string(), metadata.sha1.clone());
                node.metadata.insert("lastModified".to_string(), metadata.last_modified.to_string());
                
                if !metadata.perplexity_link.is_empty() {
                    node.metadata.insert("perplexityLink".to_string(), metadata.perplexity_link.clone());
                }
                
                if let Some(last_process) = metadata.last_perplexity_process {
                    node.metadata.insert("lastPerplexityProcess".to_string(), last_process.to_string());
                }
                
                // We don't add topic_counts to metadata as it would create circular references
                // and is already used to create edges
                
                // Ensure flags is set to 1 (default active state)
                node.data.flags = 1;
            }
            
            let node_clone = node.clone();
            graph.nodes.push(node_clone);
            // Store nodes in map by numeric ID for efficient lookups
            node_map.insert(node.id.clone(), node);
        }

        // Create edges from metadata topic counts
        for (source_file, metadata) in graph.metadata.iter() {
            let source_id = source_file.trim_end_matches(".md").to_string();
            trace!("Processing edges for source file: {}", source_file);
            // Find the node with this metadata_id to get its numeric ID
            let source_node = graph.nodes.iter().find(|n| n.metadata_id == source_id);
            if source_node.is_none() {
                continue; // Skip if node not found
            }
            let source_numeric_id = source_node.unwrap().id.clone();
            
            // Process outbound links from this file to other topics
            for (target_file, count) in &metadata.topic_counts {
                let target_id = target_file.trim_end_matches(".md").to_string();
                // Find the node with this metadata_id to get its numeric ID
                let target_node = graph.nodes.iter().find(|n| n.metadata_id == target_id);
                trace!("  Processing potential edge: {} -> {} (count: {})", source_id, target_id, count);
                if target_node.is_none() {
                    continue; // Skip if node not found
                }
                let target_numeric_id = target_node.unwrap().id.clone();
                trace!("  Found target node: {} (ID: {})", target_id, target_numeric_id);

                // Only create edge if both nodes exist and they're different
                if source_numeric_id != target_numeric_id {
                    let edge_key = if source_numeric_id < target_numeric_id {
                        (source_numeric_id.clone(), target_numeric_id.clone())
                    } else {
                        (target_numeric_id.clone(), source_numeric_id.clone())
                    };

                    trace!("  Creating/updating edge: {:?} with weight {}", edge_key, count);
                    // Sum the weights for bi-directional references
                    edge_map.entry(edge_key)
                        .and_modify(|w| *w += *count as f32)
                        .or_insert(*count as f32);
                }
            }
        }

        // Log edge_map contents before transformation
        trace!("Edge map contains {} unique connections", edge_map.len());
        for ((source, target), weight) in &edge_map {
            trace!("Edge map entry: {} -- {} (weight: {})", source, target, weight);
        }

        // Convert edge map to edges
        trace!("Converting edge map to {} edges", edge_map.len());
        graph.edges = edge_map.into_iter()
            .map(|((source, target), weight)| {
                Edge::new(source, target, weight)
            })
            .collect();

        // Initialize random positions for all nodes
        Self::initialize_random_positions(&mut graph);

        info!("Built graph with {} nodes and {} edges", graph.nodes.len(), graph.edges.len());
        trace!("Completed graph build: {} nodes, {} edges", graph.nodes.len(), graph.edges.len());
        Ok(graph)
    }

    fn initialize_random_positions(graph: &mut GraphData) {
        let mut rng = rand::thread_rng();
        let node_count = graph.nodes.len() as f32;
        let initial_radius = 3.0; // Increasing radius for better visibility
        let golden_ratio = (1.0 + 5.0_f32.sqrt()) / 2.0;
        
        // Log the initialization process
        info!("Initializing random positions for {} nodes with radius {}", 
             node_count, initial_radius);
        info!("First 5 node numeric IDs: {}", graph.nodes.iter().take(5).map(|n| n.id.clone()).collect::<Vec<_>>().join(", "));
        info!("First 5 node metadata IDs: {}", graph.nodes.iter().take(5).map(|n| n.metadata_id.clone()).collect::<Vec<_>>().join(", "));
        
        // Use Fibonacci sphere distribution for more uniform initial positions
        for (i, node) in graph.nodes.iter_mut().enumerate() {
            let i_float: f32 = i as f32;
            
            // Calculate Fibonacci sphere coordinates
            let theta = 2.0 * std::f32::consts::PI * i_float / golden_ratio;
            let phi = (1.0 - 2.0 * (i_float + 0.5) / node_count).acos();
            
            // Add slight randomness to prevent exact overlaps
            let r = initial_radius * (0.9 + rng.gen_range(0.0..0.2));
            
            node.set_x(r * phi.sin() * theta.cos());
            node.set_y(r * phi.sin() * theta.sin());
            node.set_z(r * phi.cos());
            
            // Initialize with zero velocity
            node.set_vx(0.0);
            node.set_vy(0.0);
            node.set_vz(0.0);

            // Log first 5 nodes for debugging
            if i < 5 {
                info!("Initialized node {}: id={}, pos=[{:.3},{:.3},{:.3}]", 
                     i,
                     node.id,
                     node.data.position.x, 
                     node.data.position.y, 
                     node.data.position.z);
            }
        }
    }

    /// Helper function to retry GPU layout calculation with exponential backoff
    pub async fn calculate_layout_with_retry(
        gpu_compute: &Arc<RwLock<GPUCompute>>,
        graph: &mut GraphData,
        node_map: &mut HashMap<String, Node>, 
        params: &SimulationParams,
    ) -> std::io::Result<()> {
        trace!("[calculate_layout_with_retry] Starting GPU calculation with retry mechanism");
        let mut last_error: Option<Error> = None;
        
        for attempt in 0..MAX_GPU_CALCULATION_RETRIES {
            match Self::calculate_layout(gpu_compute, graph, node_map, params).await {
                Ok(()) => {
                    if attempt > 0 {
                        info!("[calculate_layout] Succeeded after {} retries", attempt);
                        trace!("[calculate_layout_with_retry] GPU calculation succeeded after retries");
                    }
                    return Ok(());
                }
                Err(e) => {
                    let delay = GPU_RETRY_DELAY_MS * (1 << attempt); // Exponential backoff
                    warn!("[calculate_layout] Failed (attempt {}/{}): {}. Retrying in {}ms...", 
                          attempt + 1, MAX_GPU_CALCULATION_RETRIES, e, delay);
                    last_error = Some(e);
                    
                    if attempt + 1 < MAX_GPU_CALCULATION_RETRIES {
                        tokio::time::sleep(Duration::from_millis(delay)).await;
                    }
                }
            }
        }
        
        // If we get here, all attempts failed
        trace!("[calculate_layout_with_retry] All GPU attempts failed, falling back to CPU");
        error!("[calculate_layout] Failed after {} attempts, falling back to CPU", MAX_GPU_CALCULATION_RETRIES);
        
        // As a fallback, try CPU calculation when GPU fails repeatedly
        match Self::calculate_layout_cpu(graph, node_map, params) {
            Ok(()) => {
                info!("[calculate_layout] Successfully fell back to CPU calculation");
                Ok(())
            }
            Err(cpu_err) => {
                error!("[calculate_layout] CPU fallback also failed: {}", cpu_err);
                // Return the last GPU error as it's likely more relevant
                Err(last_error.unwrap_or_else(|| Error::new(ErrorKind::Other, 
                    format!("All {} GPU retry attempts failed and CPU fallback failed", MAX_GPU_CALCULATION_RETRIES))))
            }
        }
    }

    pub async fn calculate_layout(
        gpu_compute: &Arc<RwLock<GPUCompute>>,
        graph: &mut GraphData,
        node_map: &mut HashMap<String, Node>, 
        params: &SimulationParams,
    ) -> std::io::Result<()> {
        {
            debug!("[calculate_layout] Starting GPU physics calculation for {} nodes, {} edges with mode {:?}",
                  graph.nodes.len(), graph.edges.len(), params.mode);
            
            // Get current timestamp for performance tracking
            let start_time = std::time::Instant::now();

            let mut gpu_compute = gpu_compute.write().await;

            debug!("[calculate_layout] params: iterations={}, spring_strength={:.3}, repulsion={:.3}, damping={:.3}",
                 params.iterations, params.spring_strength, params.repulsion, params.damping);
            
            // Update data and parameters
            if let Err(e) = gpu_compute.update_graph_data(graph) {
                error!("[calculate_layout] Failed to update graph data in GPU: {}, node count: {}", 
                      e, graph.nodes.len());
                // Log more details about the graph for debugging
                if !graph.nodes.is_empty() {
                    trace!("First node: id={}, position=[{:.3},{:.3},{:.3}]", graph.nodes[0].id, graph.nodes[0].data.position.x, graph.nodes[0].data.position.y, graph.nodes[0].data.position.z);
                }
                return Err(e);
            }
            
            if let Err(e) = gpu_compute.update_simulation_params(params) {
                error!("[calculate_layout] Failed to update simulation parameters in GPU: {}", e);
                return Err(e);
            }
            
            // Perform computation step
            if let Err(e) = gpu_compute.step() {
                error!("[calculate_layout] Failed to execute physics step: {}, graph has {} nodes and {} edges", 
                       e, graph.nodes.len(), graph.edges.len());
                return Err(e);
            }
            
            // Get updated positions
            let updated_nodes = match gpu_compute.get_node_data() {
                Ok(nodes) => {
                    debug!("[calculate_layout] Successfully retrieved {} nodes from GPU", nodes.len());
                    nodes
                },
                Err(e) => {
                    error!("[calculate_layout] Failed to get node data from GPU: {}", e);
                    return Err(e);
                }
            };
            
            // Update graph with new positions
            let mut nodes_updated = 0;
            for (i, node) in graph.nodes.iter_mut().enumerate() {
                if i >= updated_nodes.len() {
                    error!("[calculate_layout] Node index out of range: {} >= {}", i, updated_nodes.len());
                    continue;
                }
                
                // Update position and velocity from GPU data
                node.data = updated_nodes[i];
                nodes_updated += 1;
                
                // Update node_map as well
                if let Some(map_node) = node_map.get_mut(&node.id) {
                    map_node.data = updated_nodes[i];
                } else {
                    warn!("[calculate_layout] Node {} not found in node_map", node.id);
                }
            }
            
            // Log performance info
            let elapsed = start_time.elapsed();
            
                // Log sample positions for debugging (first 2 nodes)
                let sample_positions = if graph.nodes.len() >= 2 {
                    format!("[{:.2},{:.2},{:.2}], [{:.2},{:.2},{:.2}]", 
                        graph.nodes[0].data.position.x, graph.nodes[0].data.position.y, graph.nodes[0].data.position.z,
                        graph.nodes[1].data.position.x, graph.nodes[1].data.position.y, graph.nodes[1].data.position.z)
                } else if graph.nodes.len() == 1 {
                    format!("[{:.2},{:.2},{:.2}]", graph.nodes[0].data.position.x, graph.nodes[0].data.position.y, graph.nodes[0].data.position.z)
                } else { "no nodes".to_string() };
            
                debug!("[calculate_layout] Updated positions for {}/{} nodes in {:?}. Sample positions: {}", nodes_updated, graph.nodes.len(), elapsed, sample_positions);
            
            Ok(())
        }
    }

    /// CPU fallback implementation of force-directed graph layout
    pub fn calculate_layout_cpu(
        graph: &mut GraphData,
        node_map: &mut HashMap<String, Node>,
        params: &SimulationParams,
    ) -> std::io::Result<()> {
        let nodes_len = graph.nodes.len();
        trace!("[calculate_layout_cpu] Starting CPU calculation with {} nodes", nodes_len);
        
        // Early return if there are no nodes to process
        if nodes_len == 0 {
            return Ok(());
        }
        
        // Initialize force accumulators for each node
        let mut forces = vec![(0.0, 0.0, 0.0); nodes_len];
        
        // Calculate repulsive forces between all pairs of nodes
        for i in 0..nodes_len {
            for j in (i+1)..nodes_len {
                let node_i = &graph.nodes[i];
                let node_j = &graph.nodes[j];
                
                // Calculate distance between nodes
                let dx = node_j.data.position.x - node_i.data.position.x;
                let dy = node_j.data.position.y - node_i.data.position.y;
                let dz = node_j.data.position.z - node_i.data.position.z;
                let distance_squared = dx * dx + dy * dy + dz * dz;
                
                // Avoid division by zero and limit maximum repulsion distance
                if distance_squared < 0.0001 { continue; }
                let distance = distance_squared.sqrt();
                if distance > params.max_repulsion_distance { continue; }
                
                // Calculate repulsion strength based on node masses (stored in data.mass) and distance
                let mass_i = (node_i.data.mass as f32 / 255.0) * 10.0 * params.mass_scale;
                let mass_j = (node_j.data.mass as f32 / 255.0) * 10.0 * params.mass_scale;
                let repulsion_factor = params.repulsion * mass_i * mass_j / distance_squared;
                
                // Normalize direction
                let nx = dx / distance;
                let ny = dy / distance;
                let nz = dz / distance;
                
                // Calculate forces (nodes push each other away)
                let fx = nx * repulsion_factor;
                let fy = ny * repulsion_factor;
                let fz = nz * repulsion_factor;
                
                // Apply forces to both nodes (equal and opposite)
                forces[i].0 -= fx;
                forces[i].1 -= fy;
                forces[i].2 -= fz;
                forces[j].0 += fx;
                forces[j].1 += fy;
                forces[j].2 += fz;
            }
        }
        
        // Calculate attractive forces for edges (spring forces)
        for edge in &graph.edges {
            let source_idx = graph.nodes.iter().position(|n| n.id == edge.source);
            let target_idx = graph.nodes.iter().position(|n| n.id == edge.target);
            
            if let (Some(i), Some(j)) = (source_idx, target_idx) {
                let node_i = &graph.nodes[i];
                let node_j = &graph.nodes[j];
                
                // Calculate distance between nodes
                let dx = node_j.data.position.x - node_i.data.position.x;
                let dy = node_j.data.position.y - node_i.data.position.y;
                let dz = node_j.data.position.z - node_i.data.position.z;
                let distance_squared = dx * dx + dy * dy + dz * dz;
                if distance_squared < 0.0001 { continue; }
                let distance = distance_squared.sqrt();
                
                // Spring force increases with distance and edge weight
                let spring_factor = params.spring_strength * edge.weight * distance;
                
                // Normalize direction
                let nx = dx / distance;
                let ny = dy / distance;
                let nz = dz / distance;
                
                // Calculate spring forces (edges pull nodes together)
                let fx = nx * spring_factor;
                let fy = ny * spring_factor;
                let fz = nz * spring_factor;
                
                // Apply spring forces 
                forces[i].0 += fx;
                forces[i].1 += fy;
                forces[i].2 += fz;
                forces[j].0 -= fx;
                forces[j].1 -= fy;
                forces[j].2 -= fz;
            }
        }
        
        // Update velocities and positions for all nodes
        for (i, node) in graph.nodes.iter_mut().enumerate() {            
            // Apply force to velocity with damping
            node.set_vx(node.data.velocity.x * params.damping + forces[i].0 * params.time_step);
            node.set_vy(node.data.velocity.y * params.damping + forces[i].1 * params.time_step);
            node.set_vz(node.data.velocity.z * params.damping + forces[i].2 * params.time_step);
            
            // Update position based on velocity
            node.set_x(node.data.position.x + node.data.velocity.x * params.time_step);
            node.set_y(node.data.position.y + node.data.velocity.y * params.time_step);
            node.set_z(node.data.position.z + node.data.velocity.z * params.time_step);
            
            // Update node_map as well
            if let Some(map_node) = node_map.get_mut(&node.id) {
                map_node.data = node.data.clone();
            }
        }
        
        Ok(())
    }

    pub async fn get_paginated_graph_data(
        &self,
        page: u32,
        page_size: u32,
    ) -> Result<PaginatedGraphData, Box<dyn std::error::Error + Send + Sync>> {
        let graph = self.graph_data.read().await;
        
        // Convert page and page_size to usize for vector operations
        let page = page as usize;
        let page_size = page_size as usize;
        let total_nodes = graph.nodes.len();
        
        let start = page * page_size;
        let end = std::cmp::min((page + 1) * page_size, total_nodes);

        let page_nodes: Vec<Node> = graph.nodes
            .iter()
            .skip(start)
            .take(end - start)
            .cloned() 
            .collect();

        // Get edges that connect to these nodes
        let node_ids: HashSet<String> = page_nodes.iter()
            .map(|n| n.id.clone())
            .collect();

        let edges: Vec<Edge> = graph.edges
            .iter()
            .filter(|e| node_ids.contains(&e.source) || node_ids.contains(&e.target))
            .cloned()
            .collect();

        Ok(PaginatedGraphData {
            nodes: page_nodes,
            edges,
            metadata: serde_json::to_value(graph.metadata.clone()).unwrap_or_default(),
            total_nodes,
            total_edges: graph.edges.len(),
            total_pages: ((total_nodes as f32 / page_size as f32).ceil()) as u32,
            current_page: page as u32,
        })
    }
    
    // Clear position cache to force a refresh on next request
    pub async fn clear_position_cache(&self) {
        let mut cache = self.node_positions_cache.write().await;
        *cache = None;
    }

    pub async fn get_node_positions(&self) -> Vec<Node> {
        let start_time = Instant::now();

        // First check if we have a valid cached result
        if self.cache_enabled {
            let cache = self.node_positions_cache.read().await;
            if let Some((cached_nodes, timestamp)) = &*cache {
                let age = start_time.duration_since(*timestamp);
                
                // If cache is still fresh, use it
                if age < Duration::from_millis(NODE_POSITION_CACHE_TTL_MS) {
                    trace!("Using cached node positions ({} nodes, age: {:?})",
                           cached_nodes.len(), age);
                    return cached_nodes.clone();
                }
            }
        }

        // No valid cache, fetch from graph data
        let nodes = {
            let graph = self.graph_data.read().await;
            
            // Only log node position data in debug level
            trace!("get_node_positions: reading {} nodes from graph (cache miss)", graph.nodes.len());
            
            // Clone the nodes vector 
            graph.nodes.clone()
        };

        // Update cache with new result
        if self.cache_enabled {
            let mut cache = self.node_positions_cache.write().await;
            *cache = Some((nodes.clone(), start_time));
        }

        let elapsed = start_time.elapsed();
        trace!("Node position fetch completed in {:?} for {} nodes", elapsed, nodes.len());
        
        // Log first 5 nodes only when debug is enabled
        let sample_size = std::cmp::min(5, nodes.len());
        if sample_size > 0 && log::log_enabled!(log::Level::Debug) {
            trace!("Node position sample: {} samples of {} nodes", sample_size, nodes.len());
        }
        nodes
    }

    pub async fn get_graph_data_mut(&self) -> tokio::sync::RwLockWriteGuard<'_, GraphData> {
        self.graph_data.write().await
    }

    pub async fn get_node_map_mut(&self) -> tokio::sync::RwLockWriteGuard<'_, HashMap<String, Node>> {
        self.node_map.write().await
    }
    
    // Add method to get GPU compute instance
    pub async fn get_gpu_compute(&self) -> Option<Arc<RwLock<GPUCompute>>> {
        self.gpu_compute.clone()
    }
 
    pub async fn update_node_positions(&self, updates: Vec<(u16, Node)>, client_manager: Arc<ClientManager>) -> Result<(), Error> {
        let mut graph = self.graph_data.write().await;
        let mut node_map = self.node_map.write().await;
        
        // Process node updates efficiently
        let mut _updated_count = 0;
        let mut _skipped_count = 0;
        
        // Process updates in batches
        for (node_id_u16, update_node) in updates {
            let node_id = node_id_u16.to_string(); 

            // Skip if this is a redundant update based on rate limiting
            if self.should_rate_limit().await {
                _skipped_count += 1;
                continue;
            }
            
            // Apply update with conflict resolution if node exists
            if let Some(existing_node) = node_map.get_mut(&node_id) {
                // Create a new node with updated position/velocity but preserving other data
                let mut resolved_node = update_node.clone();
                
                // Preserve important attributes from existing node
                resolved_node.data.mass = existing_node.data.mass;
                resolved_node.data.flags = existing_node.data.flags;
                resolved_node.metadata = existing_node.metadata.clone();
                
                // Update the node in the map
                *existing_node = resolved_node;
                _updated_count += 1;
            }
        }
        
        // Sync graph nodes with node_map
        graph.nodes.iter_mut().for_each(|node| {
            if let Some(map_node) = node_map.get(&node.id) {
                node.data = map_node.data.clone();
            }
        });
        
        // Broadcast all positions
        Self::broadcast_positions(client_manager, &graph.nodes).await;
        
        Ok(())
    }

    pub fn update_positions(&mut self) -> Pin<Box<dyn Future<Output = Result<(), Error>> + '_>> {
        Box::pin(async move {
            if let Some(gpu) = &self.gpu_compute {
                let mut gpu = gpu.write().await;
                gpu.compute_forces()?;
                Ok(())
            } else {
                // Initialize GPU if not already done
                if self.gpu_compute.is_none() {
                    let graph_data_clone = {
                        let guard = self.graph_data.read().await;
                        guard.clone()
                    }; // Read guard is dropped here
                    self.initialize_gpu(&graph_data_clone).await?;
                    return self.update_positions().await;
                }
                Err(Error::new(ErrorKind::Other, "GPU compute not initialized"))
            }
        })
    }
 
pub async fn initialize_gpu(&mut self, graph_data: &GraphData) -> Result<(), Error> {
    info!("Initializing GPU compute system...");
 

        // If GPU is already initialized, don't reinitialize
        if self.gpu_compute.is_some() {
            info!("GPU compute is already initialized, skipping initialization");
            return Ok(());
        }

        match GPUCompute::new(graph_data).await {
            Ok(gpu_instance) => {
                // Try a test computation before accepting the GPU
                {
                    let mut gpu = gpu_instance.write().await;
                    if let Err(e) = gpu.compute_forces() {
                        error!("GPU test computation failed: {}", e);
                        return Err(Error::new(ErrorKind::Other, format!("GPU test computation failed: {}", e)));
                    }
                    info!("GPU test computation succeeded");
                }

                self.gpu_compute = Some(gpu_instance);
                info!("GPU compute system successfully initialized");
                Ok(())
            }
            Err(e) => {
                error!("Failed to initialize GPU compute: {}. Physics simulation will not work.", e);
                Err(Error::new(ErrorKind::Other, format!("GPU initialization failed: {}", e)))
            }
        }
    }

    /// Helper method to check GPU availability and print detailed diagnostics
    pub fn diagnose_gpu_status(gpu_compute: Option<Arc<RwLock<GPUCompute>>>) -> Pin<Box<dyn Future<Output = bool> + Send>> {
        Box::pin(async move {
            info!("[GraphService] Diagnosing GPU status...");
            
            match gpu_compute {
                Some(gpu) => {
                    info!("[GraphService] GPU compute is available in service");
                    // Try a test computation 
                    if let Ok(gpu_lock) = gpu.try_read() {
                        match gpu_lock.test_compute() {
                            Ok(_) => {
                                info!("[GraphService] GPU test computation succeeded");
                                true
                            },
                            Err(e) => {
                                error!("[GraphService] GPU test computation failed: {}", e);
                                false
                            }
                        }
                    } else {
                        info!("[GraphService] Could not acquire GPU lock for diagnostics");
                        false
                    }
                },
                None => {
                    error!("[GraphService] GPU compute is NOT available in service");
                    
                    // Try to initialize it
                    info!("[GraphService] Attempting to initialize GPU on demand...");
                    false
                }
            }
        })
    }

    // Development test function to verify metadata transfer
    #[cfg(test)]
    pub async fn test_metadata_transfer() -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        use chrono::Utc;
        use std::collections::HashMap;
        use crate::models::metadata::Metadata;

        // Create test metadata
        let mut metadata = crate::models::metadata::MetadataStore::new();
        let file_name = "test.md";
        
        // Create a test metadata entry
        let meta = Metadata {
            file_name: file_name.to_string(),
            file_size: 1000,
            node_size: 1.5,
            hyperlink_count: 5,
            sha1: "abc123".to_string(),
            node_id: "1".to_string(),
            last_modified: Utc::now(),
            perplexity_link: "https://example.com".to_string(),
            last_perplexity_process: Some(Utc::now()),
            topic_counts: HashMap::new(),
        };
        
        metadata.insert(file_name.to_string(), meta.clone());
        
        // Build graph from metadata
        let graph = Self::build_graph_from_metadata(&metadata).await?;
        
        // Check that the graph has one node with the correct metadata
        assert_eq!(graph.nodes.len(), 1);
        
        // Verify metadata_id
        let node = &graph.nodes[0];
        assert_eq!(node.metadata_id, "test");
        
        // Verify metadata fields
        assert!(node.metadata.contains_key("fileName"));
        assert_eq!(node.metadata.get("fileName").unwrap(), "test.md");
        
        assert!(node.metadata.contains_key("fileSize"));
        assert_eq!(node.metadata.get("fileSize").unwrap(), "1000");
        
        assert!(node.metadata.contains_key("nodeSize"));
        assert_eq!(node.metadata.get("nodeSize").unwrap(), "1.5");
        
        assert!(node.metadata.contains_key("hyperlinkCount"));
        assert_eq!(node.metadata.get("hyperlinkCount").unwrap(), "5");
        
        assert!(node.metadata.contains_key("sha1"));
        assert!(node.metadata.contains_key("lastModified"));
        
        // Check flags
        assert_eq!(node.data.flags, 1);

        println!("All metadata tests passed!");
        Ok(())
    }
    
    /// Start a separate broadcast loop to periodically push position updates to all clients
    pub fn start_broadcast_loop(&self, client_manager: Arc<ClientManager>) {
        info!("[GraphService] Starting position broadcast loop for client synchronization...");
 
        // Clone what we need for the async task
        let service_clone = self.clone();
        let simulation_id = self.simulation_id.clone();
        let captured_client_manager = client_manager.clone(); // Capture ClientManager for the loop
 
        // Spawn a new task for the broadcast loop
        tokio::spawn(async move {
            info!("[GraphService:{}] Position broadcast loop starting", simulation_id);
 
            // Main broadcast loop
            loop {
                // Check if shutdown was requested
                if service_clone.shutdown_requested.load(Ordering::SeqCst) {
                    info!("[GraphService:{}] Broadcast loop shutting down due to shutdown request", simulation_id);
                    break;
                }
 
                // Get current node positions
                let nodes = service_clone.get_node_positions().await;
 
                // Broadcast positions to all clients if we have any
                if !nodes.is_empty() {
                    GraphService::broadcast_positions(captured_client_manager.clone(), &nodes).await;
                }
 
                // Sleep to avoid excessive updates
                tokio::time::sleep(Duration::from_millis(100)).await;
            }
 
            info!("[GraphService:{}] Position broadcast loop exited", simulation_id);
        });
        info!("[GraphService] Position broadcast loop started");
    }
}

----
services/mod.rs
pub mod github;
pub mod file_service;
pub mod graph_service;
pub mod nostr_service;
pub mod perplexity_service;
pub mod ragflow_service;
pub mod speech_service;

----
services/speech_service.rs
use tokio::sync::{mpsc, Mutex, RwLock};
use tokio_tungstenite::{connect_async, WebSocketStream, MaybeTlsStream, tungstenite};
use tungstenite::http::Request;
use serde_json::json;
use std::sync::Arc;
use tokio::task;
use tokio::sync::broadcast;
use crate::config::AppFullSettings;
// use crate::config::Settings; // AppFullSettings is used from self.settings
use log::{info, error, debug};
use futures::{SinkExt, StreamExt};
use std::error::Error;
use tokio::net::TcpStream;
use url::Url;
use base64::Engine as _;
use base64::engine::general_purpose::{STANDARD as BASE64};
use crate::types::speech::{SpeechError, SpeechCommand, TTSProvider, SpeechOptions};
use reqwest::Client;


pub struct SpeechService {
    sender: Arc<Mutex<mpsc::Sender<SpeechCommand>>>,
    settings: Arc<RwLock<AppFullSettings>>,
    tts_provider: Arc<RwLock<TTSProvider>>,
    // Audio broadcast channel for distributing TTS audio to all connected clients
    audio_tx: broadcast::Sender<Vec<u8>>,
    http_client: Arc<Client>,
}

impl SpeechService {
    pub fn new(settings: Arc<RwLock<AppFullSettings>>) -> Self {
        let (tx, rx) = mpsc::channel(100);
        let sender = Arc::new(Mutex::new(tx));

        // Create a broadcast channel for audio data with buffer size of 100
        let (audio_tx, _) = broadcast::channel(100);
        
        // Create HTTP client for Kokoro TTS API
        let http_client = Arc::new(Client::new());

        let service = SpeechService {
            sender,
            settings,
            tts_provider: Arc::new(RwLock::new(TTSProvider::Kokoro)), // Updated default to Kokoro
            audio_tx,
            http_client,
        };

        service.start(rx);
        service
    }

    fn start(&self, mut receiver: mpsc::Receiver<SpeechCommand>) {
        let settings: Arc<RwLock<AppFullSettings>> = Arc::clone(&self.settings);
        let http_client = Arc::clone(&self.http_client);
        let tts_provider = Arc::clone(&self.tts_provider);
        let audio_tx = self.audio_tx.clone();

        task::spawn(async move {
            let mut ws_stream: Option<WebSocketStream<MaybeTlsStream<TcpStream>>> = None;

            while let Some(command) = receiver.recv().await {
                match command {
                    SpeechCommand::Initialize => {
                        let settings_read = settings.read().await;
                        
                        // Safely get OpenAI API key
                        let openai_api_key = match settings_read.openai.as_ref().and_then(|o| o.api_key.as_ref()) {
                            Some(key) if !key.is_empty() => key.clone(),
                            _ => {
                                error!("OpenAI API key not configured or empty. Cannot initialize OpenAI Realtime API.");
                                continue; // Skip initialization if key is missing
                            }
                        };
                        
                        let url_str = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01";
                        let url = match Url::parse(url_str) {
                            Ok(url) => url,
                            Err(e) => {
                                error!("Failed to parse OpenAI URL '{}': {}", url_str, e);
                                continue;
                            }
                        };
                        
                        let request = match Request::builder()
                            .uri(url.as_str())
                            .header("Authorization", format!("Bearer {}", openai_api_key))
                            .header("OpenAI-Beta", "realtime=v1")
                            .header("Content-Type", "application/json")
                            .header("User-Agent", "WebXR Graph")
                            .header("Sec-WebSocket-Version", "13")
                            .header("Sec-WebSocket-Key", tungstenite::handshake::client::generate_key())
                            .header("Connection", "Upgrade")
                            .header("Upgrade", "websocket")
                            .body(()) {
                                Ok(req) => req,
                                Err(e) => {
                                    error!("Failed to build request: {}", e);
                                    continue;
                                }
                            };

                        match connect_async(request).await {
                            Ok((mut stream, _)) => {
                                info!("Connected to OpenAI Realtime API");
                                
                                let init_event = json!({
                                    "type": "response.create",
                                    "response": {
                                        "modalities": ["text", "audio"],
                                        "instructions": "You are a helpful AI assistant. Respond naturally and conversationally."
                                    }
                                });
                                
                                if let Err(e) = stream.send(tungstenite::Message::Text(init_event.to_string())).await {
                                    error!("Failed to send initial response.create event: {}", e);
                                    continue;
                                }
                                
                                ws_stream = Some(stream);
                            },
                            Err(e) => error!("Failed to connect to OpenAI Realtime API: {}", e),
                        }
                    },
                    SpeechCommand::SendMessage(msg) => {
                        if let Some(stream) = &mut ws_stream {
                            let msg_event = json!({
                                "type": "conversation.item.create",
                                "item": {
                                    "type": "message",
                                    "role": "user",
                                    "content": [{
                                        "type": "input_text",
                                        "text": msg
                                    }]
                                }
                            });

                            if let Err(e) = stream.send(tungstenite::Message::Text(msg_event.to_string())).await {
                                error!("Failed to send message to OpenAI: {}", e);
                                continue;
                            }

                            let response_event = json!({
                                "type": "response.create"
                            });
                            
                            if let Err(e) = stream.send(tungstenite::Message::Text(response_event.to_string())).await {
                                error!("Failed to request response from OpenAI: {}", e);
                                continue;
                            }
                            
                            while let Some(message) = stream.next().await {
                                match message {
                                    Ok(tungstenite::Message::Text(text)) => {
                                        let event = match serde_json::from_str::<serde_json::Value>(&text) {
                                            Ok(event) => event,
                                            Err(e) => {
                                                error!("Failed to parse server event: {}", e);
                                                continue;
                                            }
                                        };
                                        
                                        match event["type"].as_str() {
                                            Some("conversation.item.created") => {
                                                if let Some(content) = event["item"]["content"].as_array() {
                                                    for item in content {
                                                        if item["type"] == "audio" {
                                                            if let Some(audio_data) = item["audio"].as_str() {
                                                                match BASE64.decode(audio_data) {
                                                                    Ok(audio_bytes) => {
                                                                        // Note: Audio data will be handled by socket-flow server
                                                                        debug!("Received audio data of size: {}", audio_bytes.len());
                                                                    },
                                                                    Err(e) => error!("Failed to decode audio data: {}", e),
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            },
                                            Some("error") => {
                                                error!("OpenAI Realtime API error: {:?}", event);
                                                break;
                                            },
                                            Some("response.completed") => break,
                                            _ => {}
                                        }
                                    },
                                    Ok(tungstenite::Message::Close(_)) => break,
                                    Err(e) => {
                                        error!("Error receiving from OpenAI: {}", e);
                                        break;
                                    },
                                    _ => {}
                                }
                            }
                        } else {
                            error!("OpenAI WebSocket not initialized");
                        }
                    },
                    SpeechCommand::Close => {
                        if let Some(mut stream) = ws_stream.take() {
                            if let Err(e) = stream.send(tungstenite::Message::Close(None)).await {
                                error!("Failed to send close frame: {}", e);
                            }
                        }
                        break;
                    },
                    SpeechCommand::SetTTSProvider(provider) => {
                        // Update the provider
                        let mut current_provider = tts_provider.write().await;
                        *current_provider = provider.clone();
                        info!("TTS provider updated to: {:?}", provider);
                    },
                    SpeechCommand::TextToSpeech(text, options) => {
                        // Check which provider to use
                        let provider = {
                            let p = tts_provider.read().await;
                            p.clone()
                        };

                        match provider {
                            TTSProvider::OpenAI => {
                                // Ignore OpenAI for now and just log
                                info!("TextToSpeech command with OpenAI provider not implemented");
                            },
                            TTSProvider::Kokoro => {
                                info!("Processing TextToSpeech command with Kokoro provider");
                                let kokoro_config = { // Read settings within scope
                                    let s = settings.read().await;
                                    s.kokoro.clone() // Clone the Option<KokoroSettings>
                                };

                                // Check if Kokoro is configured
                                if let Some(config) = kokoro_config {
                                    // Safely get API URL or skip if missing
                                    let api_url_base = match config.api_url.as_deref() {
                                        Some(url) if !url.is_empty() => url,
                                        _ => {
                                            error!("Kokoro API URL not configured or empty.");
                                            continue; // Skip this TTS request
                                        }
                                    };
                                    let api_url = format!("{}/v1/audio/speech", api_url_base.trim_end_matches('/'));
                                    info!("Sending TTS request to Kokoro API: {}", api_url);

                                    // Use defaults from config if available, otherwise hardcoded defaults
                                    let response_format = config.default_format.as_deref().unwrap_or("mp3");

                                    let request_body = json!({
                                        "model": "kokoro", // Assuming model is fixed
                                        "input": text,
                                        "voice": options.voice.clone(), // Voice comes from request options
                                        "response_format": response_format,
                                        "speed": options.speed, // Speed comes from request options
                                        "stream": options.stream // Stream comes from request options
                                    });

                                let response = match http_client
                                    .post(&api_url)
                                    .header("Content-Type", "application/json")
                                    .body(request_body.to_string())
                                    .send()
                                    .await
                                {
                                    Ok(response) => {
                                        if !response.status().is_success() {
                                            let status = response.status();
                                            let error_text = response.text().await.unwrap_or_default();
                                            error!("Kokoro API error {}: {}", status, error_text);
                                            continue;
                                        }
                                        response
                                    }
                                    Err(e) => {
                                        error!("Failed to connect to Kokoro API: {}", e);
                                        continue;
                                    }
                                };

                                // Handle the response (streaming or not)
                                if options.stream {
                                    let stream = response.bytes_stream();
                                    let audio_broadcaster = audio_tx.clone();

                                    // Process the streaming response
                                    tokio::spawn(async move {
                                        let mut stream = Box::pin(stream);

                                        while let Some(item) = stream.next().await {
                                            match item {
                                                Ok(bytes) => {
                                                    // Send audio chunk to all connected clients
                                                    if let Err(e) = audio_broadcaster.send(bytes.to_vec()) {
                                                        error!("Failed to broadcast audio chunk: {}", e);
                                                    }
                                                }
                                                Err(e) => {
                                                    error!("Error receiving audio stream: {}", e);
                                                    break;
                                                }
                                            }
                                        }
                                        debug!("Finished streaming audio from Kokoro");
                                    });
                                } else {
                                    // Handle non-streaming response
                                    match response.bytes().await {
                                        Ok(bytes) => {
                                            // Send the complete audio file in one chunk
                                            if let Err(e) = audio_tx.send(bytes.to_vec()) {
                                                error!("Failed to send audio data: {}", e);
                                            } else {
                                                debug!("Sent {} bytes of audio data", bytes.len());
                                            }
                                        }
                                        Err(e) => {
                                            error!("Failed to get audio bytes: {}", e);
                                        }
                                    }
                                }
                            }
                        }
                        // info!("TextToSpeech arm commented out for debugging delimiter issue."); // This line can be removed now
                    }
                }
            }
}
        }); // Removed semicolon
    }

    pub async fn initialize(&self) -> Result<(), Box<dyn Error>> {
        let command = SpeechCommand::Initialize;
        self.sender.lock().await.send(command).await.map_err(|e| Box::new(SpeechError::from(e)))?;
        Ok(())
    }

    pub async fn send_message(&self, message: String) -> Result<(), Box<dyn Error>> {
        let command = SpeechCommand::SendMessage(message);
        self.sender.lock().await.send(command).await.map_err(|e| Box::new(SpeechError::from(e)))?;
        Ok(())
    }
    
    pub async fn text_to_speech(&self, text: String, options: SpeechOptions) -> Result<(), Box<dyn Error>> {
        let command = SpeechCommand::TextToSpeech(text, options);
        self.sender.lock().await.send(command).await.map_err(|e| Box::new(SpeechError::from(e)))?;
        Ok(())
    }

    pub async fn close(&self) -> Result<(), Box<dyn Error>> {
        let command = SpeechCommand::Close;
        self.sender.lock().await.send(command).await.map_err(|e| Box::new(SpeechError::from(e)))?;
        Ok(())
    }
    
    pub async fn set_tts_provider(&self, provider: TTSProvider) -> Result<(), Box<dyn Error>> {
        let command = SpeechCommand::SetTTSProvider(provider);
        self.sender.lock().await.send(command).await.map_err(|e| Box::new(SpeechError::from(e)))?;
        Ok(())
    }

    // Get a subscriber to the audio broadcast channel
    pub fn subscribe_to_audio(&self) -> broadcast::Receiver<Vec<u8>> {
        self.audio_tx.subscribe()
    }
    
    // Current provider
    pub async fn get_tts_provider(&self) -> TTSProvider {
        self.tts_provider.read().await.clone()
    }
}

----
services/ragflow_service.rs
use reqwest::{Client, StatusCode};
use log::{error, info};
use crate::config::AppFullSettings; // Use AppFullSettings, ConfigRagFlowSettings removed
use std::fmt;
use futures::stream::{Stream, StreamExt};
use std::pin::Pin;
use std::sync::Arc;
use tokio::sync::RwLock;
use serde::{Deserialize, Serialize};

#[derive(Debug)]
pub enum RAGFlowError {
    ReqwestError(reqwest::Error),
    StatusError(StatusCode, String),
    ParseError(String),
    IoError(std::io::Error),
}

impl fmt::Display for RAGFlowError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            RAGFlowError::ReqwestError(e) => write!(f, "Reqwest error: {}", e),
            RAGFlowError::StatusError(status, msg) => write!(f, "Status error ({}): {}", status, msg),
            RAGFlowError::ParseError(msg) => write!(f, "Parse error: {}", msg),
            RAGFlowError::IoError(e) => write!(f, "IO error: {}", e),
        }
    }
}

impl std::error::Error for RAGFlowError {}

impl From<reqwest::Error> for RAGFlowError {
    fn from(err: reqwest::Error) -> Self {
        RAGFlowError::ReqwestError(err)
    }
}

impl From<std::io::Error> for RAGFlowError {
    fn from(err: std::io::Error) -> Self {
        RAGFlowError::IoError(err)
    }
}

#[derive(Debug, Deserialize)]
struct SessionResponse {
    code: i32,
    data: SessionData,
}

#[derive(Debug, Deserialize)]
struct SessionData {
    id: String,
    message: Option<Vec<Message>>,
}

#[derive(Debug, Deserialize)]
struct Message {
    role: String,
    content: String,
}

#[derive(Debug, Deserialize)]
struct CompletionResponse {
    code: i32,
    data: CompletionData,
}

#[derive(Debug, Deserialize)]
struct CompletionData {
    answer: Option<String>,
    reference: Option<serde_json::Value>,
    id: Option<String>,
    session_id: Option<String>,
}

#[derive(Debug, Serialize)]
struct CompletionRequest {
    question: String,
    stream: bool,
    session_id: Option<String>,
    user_id: Option<String>,
    sync_dsl: Option<bool>,
}

pub struct RAGFlowService {
    client: Client,
    api_key: String,
    base_url: String,
    agent_id: String,
}

impl RAGFlowService {
    // Updated signature and logic to handle optional settings
    pub async fn new(settings: Arc<RwLock<AppFullSettings>>) -> Result<Self, RAGFlowError> {
        let client = Client::new();
        let settings_read = settings.read().await;

        // Safely extract RAGFlow settings or return an error
        let ragflow_config = settings_read.ragflow.as_ref()
            .ok_or_else(|| RAGFlowError::ParseError("RAGFlow settings section is missing".to_string()))?;

        let api_key = ragflow_config.api_key.as_deref()
            .ok_or_else(|| RAGFlowError::ParseError("RAGFlow api_key is missing".to_string()))?
            .to_string();
            
        let base_url = ragflow_config.api_base_url.as_deref()
            .ok_or_else(|| RAGFlowError::ParseError("RAGFlow api_base_url is missing".to_string()))?
            .to_string();
            
        let agent_id = ragflow_config.agent_id.as_deref()
            .ok_or_else(|| RAGFlowError::ParseError("RAGFlow agent_id is missing".to_string()))?
            .to_string();

        // Check if essential fields are empty
        if api_key.is_empty() || base_url.is_empty() || agent_id.is_empty() {
             return Err(RAGFlowError::ParseError("RAGFlow api_key, base_url, or agent_id is empty".to_string()));
        }

        Ok(RAGFlowService {
            client,
            api_key,
            base_url,
            agent_id,
        })
    }

    pub async fn create_session(&self, user_id: String) -> Result<String, RAGFlowError> {
        info!("Creating session for user: {}", user_id);
        let url = format!(
            "{}/api/v1/agents/{}/sessions?user_id={}", 
            self.base_url.trim_end_matches('/'), 
            self.agent_id,
            user_id
        );
        info!("Full URL for create_session: {}", url);
        
        let response = self.client.post(&url)
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .body("{}")  // Empty JSON body as we don't have any Begin parameters
            .send()
            .await?;

        let status = response.status();
        info!("Response status: {}", status);

        if status.is_success() {
            let result: serde_json::Value = response.json().await?;
            info!("Successful response: {:?}", result);
            
            // Extract session ID from the response
            match result["data"]["id"].as_str() {
                Some(id) => Ok(id.to_string()),
                None => {
                    error!("Failed to parse session ID from response: {:?}", result);
                    Err(RAGFlowError::ParseError("Failed to parse session ID".to_string()))
                }
            }
        } else {
            let error_message = response.text().await?;
            error!("Failed to create session. Status: {}, Error: {}", status, error_message);
            Err(RAGFlowError::StatusError(status, error_message))
        }
    }

    pub async fn send_message(
        &self,
        session_id: String,
        message: String,
        _quote: bool,  // Not used in new API
        _doc_ids: Option<Vec<String>>,  // Not used in new API
        stream: bool,
    ) -> Result<Pin<Box<dyn Stream<Item = Result<String, RAGFlowError>> + Send + 'static>>, RAGFlowError> {
        info!("Sending message to session: {}", session_id);
        let url = format!(
            "{}/api/v1/agents/{}/completions", 
            self.base_url.trim_end_matches('/'),
            self.agent_id
        );
        info!("Full URL for send_message: {}", url);
        
        let request_body = CompletionRequest {
            question: message,
            stream,
            session_id: Some(session_id),
            user_id: None,
            sync_dsl: Some(false),
        };

        info!("Request body: {:?}", serde_json::to_string(&request_body).unwrap_or_default());

        let response = self.client.post(&url)
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await?;

        let status = response.status();
        info!("Response status: {}", status);
       
        if status.is_success() {
            if stream {
                let stream = response.bytes_stream().map(move |chunk_result| {
                    match chunk_result {
                        Ok(chunk) => {
                            let chunk_str = String::from_utf8_lossy(&chunk);
                            // Handle SSE format (data: {...})
                            let chunk_str = chunk_str.trim();
                            
                            if chunk_str.starts_with("data:") {
                                let json_str = chunk_str.trim_start_matches("data:").trim();
                                match serde_json::from_str::<serde_json::Value>(json_str) {
                                    Ok(json_response) => {
                                        if let Some(true) = json_response["data"].as_bool() {
                                            // This is the end marker
                                            Ok("".to_string())
                                        } else if let Some(answer) = json_response["data"]["answer"].as_str() {
                                            Ok(answer.to_string())
                                        } else {
                                            Err(RAGFlowError::ParseError("No answer found in response".to_string()))
                                        }
                                    },
                                    Err(e) => Err(RAGFlowError::ParseError(format!("Failed to parse JSON: {}, content: {}", e, json_str))),
                                }
                            } else {
                                Err(RAGFlowError::ParseError(format!("Invalid SSE format: {}", chunk_str)))
                            }
                        },
                        Err(e) => Err(RAGFlowError::ReqwestError(e)),
                    }
                });

                Ok(Box::pin(stream))
            } else {
                // Non-streaming response handling
                let result: serde_json::Value = response.json().await?;
                
                if let Some(answer) = result["data"]["answer"].as_str() {
                    // Create a one-item stream with the answer
                    let stream = futures::stream::once(futures::future::ok(answer.to_string()));
                    Ok(Box::pin(stream))
                } else {
                    Err(RAGFlowError::ParseError("No answer found in response".to_string()))
                }
            }
        } else {
            let error_message = response.text().await?;
            error!("Failed to send message. Status: {}, Error: {}", status, error_message);
            Err(RAGFlowError::StatusError(status, error_message))
        }
    }

    pub async fn get_session_history(&self, session_id: String) -> Result<serde_json::Value, RAGFlowError> {
        let url = format!(
            "{}/api/v1/agents/{}/sessions?id={}", 
            self.base_url.trim_end_matches('/'), 
            self.agent_id,
            session_id
        );
        
        let response = self.client.get(&url)
            .header("Authorization", format!("Bearer {}", self.api_key))
            .send()
            .await?;

        let status = response.status();
        if status.is_success() {
            let history: serde_json::Value = response.json().await?;
            Ok(history)
        } else {
            let error_message = response.text().await?;
            error!("Failed to get session history. Status: {}, Error: {}", status, error_message);
            Err(RAGFlowError::StatusError(status, error_message))
        }
    }
}

impl Clone for RAGFlowService {
    fn clone(&self) -> Self {
        RAGFlowService {
            client: self.client.clone(),
            api_key: self.api_key.clone(),
            base_url: self.base_url.clone(),
            agent_id: self.agent_id.clone(),
        }
    }
}

----
services/github/pr.rs
use super::api::GitHubClient;
use super::types::{CreateBranchRequest, CreatePullRequest, UpdateFileRequest, PullRequestResponse};
use base64::{Engine as _, engine::general_purpose::STANDARD as BASE64};
use log::{error, info};
use std::error::Error;
use chrono::Utc;

/// Handles GitHub Pull Request operations
use std::sync::Arc;

pub struct PullRequestAPI {
    client: Arc<GitHubClient>,
}

impl PullRequestAPI {
    /// Create a new PullRequestAPI instance
    pub fn new(client: Arc<GitHubClient>) -> Self {
        Self { client }
    }

    /// Create a pull request for a file update
    pub async fn create_pull_request(
        &self,
        file_name: &str,
        content: &str,
        original_sha: &str,
    ) -> Result<String, Box<dyn Error + Send + Sync>> {
        let timestamp = Utc::now().timestamp();
        let branch_name = format!("update-{}-{}", file_name.replace(".md", ""), timestamp);
        
        let main_sha = self.get_main_branch_sha().await?;
        self.create_branch(&branch_name, &main_sha).await?;
        
        let file_path = format!("{}/{}", self.client.base_path(), file_name);
        let new_sha = self.update_file(&file_path, content, &branch_name, original_sha).await?;
        
        let url = format!(
            "https://api.github.com/repos/{}/{}/pulls",
            self.client.owner(), self.client.repo()
        );

        let pr_body = CreatePullRequest {
            title: format!("Update: {}", file_name),
            head: branch_name,
            base: "main".to_string(),
            body: format!(
                "This PR updates content for {}.\n\nOriginal SHA: {}\nNew SHA: {}",
                file_name, original_sha, new_sha
            ),
        };

        let response = self.client.client()
            .post(&url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .json(&pr_body)
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            error!("Failed to create PR: {}", error_text);
            return Err(format!("GitHub API error: {}", error_text).into());
        }

        let pr_response: PullRequestResponse = response.json().await?;
        info!("Created PR: {}", pr_response.html_url);
        Ok(pr_response.html_url)
    }

    /// Get the SHA of the main branch
    async fn get_main_branch_sha(&self) -> Result<String, Box<dyn Error + Send + Sync>> {
        let url = format!(
            "https://api.github.com/repos/{}/{}/git/ref/heads/main",
            self.client.owner(), self.client.repo()
        );

        let response = self.client.client()
            .get(&url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            error!("Failed to get main branch SHA: {}", error_text);
            return Err(format!("GitHub API error: {}", error_text).into());
        }

        let response_json: serde_json::Value = response.json().await?;
        Ok(response_json["object"]["sha"]
            .as_str()
            .ok_or_else(|| "SHA not found in response".to_string())?
            .to_string())
    }

    /// Create a new branch
    async fn create_branch(&self, branch_name: &str, sha: &str) -> Result<(), Box<dyn Error + Send + Sync>> {
        let url = format!(
            "https://api.github.com/repos/{}/{}/git/refs",
            self.client.owner(), self.client.repo()
        );

        let body = CreateBranchRequest {
            ref_name: format!("refs/heads/{}", branch_name),
            sha: sha.to_string(),
        };

        let response = self.client.client()
            .post(&url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .json(&body)
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            error!("Failed to create branch: {}", error_text);
            return Err(format!("GitHub API error: {}", error_text).into());
        }

        Ok(())
    }

    /// Update a file in a branch
    async fn update_file(
        &self,
        file_path: &str,
        content: &str,
        branch_name: &str,
        original_sha: &str,
    ) -> Result<String, Box<dyn Error + Send + Sync>> {
        let url = format!(
            "https://api.github.com/repos/{}/{}/contents/{}",
            self.client.owner(), self.client.repo(), file_path
        );

        let encoded_content = BASE64.encode(content);
        
        let body = UpdateFileRequest {
            message: format!("Update {}", file_path),
            content: encoded_content,
            sha: original_sha.to_string(),
            branch: branch_name.to_string(),
        };

        let response = self.client.client()
            .put(&url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .json(&body)
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            error!("Failed to update file: {}", error_text);
            return Err(format!("GitHub API error: {}", error_text).into());
        }

        let response_json: serde_json::Value = response.json().await?;
        Ok(response_json["content"]["sha"]
            .as_str()
            .ok_or_else(|| "SHA not found in response".to_string())?
            .to_string())
    }
}
----
services/github/config.rs
use std::env;
use std::error::Error;
use std::fmt;

#[derive(Debug)]
pub enum GitHubConfigError {
    MissingEnvVar(String),
    ValidationError(String),
}

impl fmt::Display for GitHubConfigError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Self::MissingEnvVar(var) => write!(f, "Missing environment variable: {}", var),
            Self::ValidationError(msg) => write!(f, "Configuration validation error: {}", msg),
        }
    }
}

impl Error for GitHubConfigError {}

#[derive(Debug, Clone)]
pub struct GitHubConfig {
    pub token: String,
    pub owner: String,
    pub repo: String,
    pub base_path: String,
    pub rate_limit: bool,
    pub version: String,
}

impl GitHubConfig {
    pub fn from_env() -> Result<Self, GitHubConfigError> {
        let token = env::var("GITHUB_TOKEN")
            .map_err(|_| GitHubConfigError::MissingEnvVar("GITHUB_TOKEN".to_string()))?;
            
        let owner = env::var("GITHUB_OWNER")
            .map_err(|_| GitHubConfigError::MissingEnvVar("GITHUB_OWNER".to_string()))?;
            
        let repo = env::var("GITHUB_REPO")
            .map_err(|_| GitHubConfigError::MissingEnvVar("GITHUB_REPO".to_string()))?;
            
        let base_path = env::var("GITHUB_BASE_PATH")
            .map_err(|_| GitHubConfigError::MissingEnvVar("GITHUB_BASE_PATH".to_string()))?;

        // Optional settings with defaults
        let rate_limit = env::var("GITHUB_RATE_LIMIT")
            .map(|v| v.parse::<bool>().unwrap_or(true))
            .unwrap_or(true);

        let version = env::var("GITHUB_API_VERSION")
            .unwrap_or_else(|_| "v3".to_string());

        let config = Self {
            token,
            owner,
            repo,
            base_path,
            rate_limit,
            version,
        };

        config.validate()?;

        Ok(config)
    }

    fn validate(&self) -> Result<(), GitHubConfigError> {
        if self.token.is_empty() {
            return Err(GitHubConfigError::ValidationError(
                "GitHub token cannot be empty".to_string(),
            ));
        }

        if self.owner.is_empty() {
            return Err(GitHubConfigError::ValidationError(
                "GitHub owner cannot be empty".to_string(),
            ));
        }

        if self.repo.is_empty() {
            return Err(GitHubConfigError::ValidationError(
                "GitHub repository cannot be empty".to_string(),
            ));
        }

        if self.base_path.is_empty() {
            return Err(GitHubConfigError::ValidationError(
                "GitHub base path cannot be empty".to_string(),
            ));
        }

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::env;

    #[test]
    fn test_missing_required_vars() {
        env::remove_var("GITHUB_TOKEN");
        env::remove_var("GITHUB_OWNER");
        env::remove_var("GITHUB_REPO");
        env::remove_var("GITHUB_BASE_PATH");

        match GitHubConfig::from_env() {
            Err(GitHubConfigError::MissingEnvVar(var)) => {
                assert_eq!(var, "GITHUB_TOKEN");
            }
            _ => panic!("Expected MissingEnvVar error"),
        }
    }

    #[test]
    fn test_empty_values() {
        env::set_var("GITHUB_TOKEN", "");
        env::set_var("GITHUB_OWNER", "owner");
        env::set_var("GITHUB_REPO", "repo");
        env::set_var("GITHUB_BASE_PATH", "path");

        match GitHubConfig::from_env() {
            Err(GitHubConfigError::ValidationError(msg)) => {
                assert!(msg.contains("token cannot be empty"));
            }
            _ => panic!("Expected ValidationError"),
        }
    }

    #[test]
    fn test_valid_config() {
        env::set_var("GITHUB_TOKEN", "token");
        env::set_var("GITHUB_OWNER", "owner");
        env::set_var("GITHUB_REPO", "repo");
        env::set_var("GITHUB_BASE_PATH", "path");

        let config = GitHubConfig::from_env().unwrap();
        assert_eq!(config.token, "token");
        assert_eq!(config.owner, "owner");
        assert_eq!(config.repo, "repo");
        assert_eq!(config.base_path, "path");
        assert!(config.rate_limit); // Default value
        assert_eq!(config.version, "v3"); // Default value
    }

    #[test]
    fn test_optional_settings() {
        env::set_var("GITHUB_TOKEN", "token");
        env::set_var("GITHUB_OWNER", "owner");
        env::set_var("GITHUB_REPO", "repo");
        env::set_var("GITHUB_BASE_PATH", "path");
        env::set_var("GITHUB_RATE_LIMIT", "false");
        env::set_var("GITHUB_API_VERSION", "v4");

        let config = GitHubConfig::from_env().unwrap();
        assert!(!config.rate_limit);
        assert_eq!(config.version, "v4");
    }
}
----
services/github/mod.rs
//! GitHub service module providing API interactions for content and pull requests
//!
//! This module is split into:
//! - Content API: Handles fetching and checking markdown files
//! - Pull Request API: Manages creation and updates of pull requests
//! - Common types and error handling
//! - Configuration: Environment-based configuration

mod api;
mod content;
mod pr;
pub mod types;
pub mod config;

pub use api::GitHubClient;
pub use content::ContentAPI;
pub use pr::PullRequestAPI;
pub use types::{GitHubError, GitHubFile, GitHubFileMetadata};
pub use config::GitHubConfig;

// Re-export commonly used types for convenience
pub use types::{ContentResponse, PullRequestResponse};
----
services/github/api.rs
use reqwest::Client;
use std::time::Duration;
use log::debug;
use super::config::GitHubConfig;
use std::sync::Arc;
use tokio::sync::RwLock;
use std::error::Error;
use crate::config::AppFullSettings; // Changed from Settings to AppFullSettings

const GITHUB_API_DELAY: Duration = Duration::from_millis(500);
const MAX_RETRIES: u32 = 3;
const RETRY_DELAY: Duration = Duration::from_secs(2);

/// Core GitHub API client providing common functionality
pub struct GitHubClient {
    client: Client,
    token: String,
    owner: String,
    repo: String,
    base_path: String,
    settings: Arc<RwLock<AppFullSettings>>, // Changed from Settings to AppFullSettings
}

impl GitHubClient {
    /// Create a new GitHub API client
    pub async fn new(
        config: GitHubConfig,
        settings: Arc<RwLock<AppFullSettings>>, // Changed from Settings to AppFullSettings
    ) -> Result<Self, Box<dyn Error + Send + Sync>> {
        let settings_guard = settings.read().await;
        let debug_enabled = settings_guard.system.debug.enabled;
        drop(settings_guard);

        if debug_enabled {
            debug!("Initializing GitHub client - Owner: '{}', Repo: '{}', Base path: '{}'",
                config.owner, config.repo, config.base_path);
        }

        // Build HTTP client with configuration
        if debug_enabled {
            debug!("Configuring HTTP client - Timeout: 30s, User-Agent: github-api-client");
        }

        let client = Client::builder()
            .user_agent("github-api-client")
            .timeout(Duration::from_secs(30))
            .build()?;

        if debug_enabled {
            debug!("HTTP client configured successfully");
        }

        // First decode any existing encoding
        let decoded_path = urlencoding::decode(&config.base_path)
            .unwrap_or(std::borrow::Cow::Owned(config.base_path.clone()))
            .into_owned();
        
        if debug_enabled {
            debug!("Decoded base path: '{}'", decoded_path);
        }
        
        // Clean the path
        let base_path = decoded_path
            .trim_matches('/')
            .replace("//", "/")
            .replace('\\', "/");
        
        if debug_enabled {
            debug!("Cleaned base path: '{}' (original: '{}')", base_path, base_path);
            debug!("GitHub client initialization complete");
        }

        Ok(Self {
            client,
            token: config.token,
            owner: config.owner,
            repo: config.repo,
            base_path,
            settings: Arc::clone(&settings),
        })
    }

    /// Get the properly encoded API path
    pub(crate) async fn get_api_path(&self) -> String {
        let settings = self.settings.read().await;
        let debug_enabled = settings.system.debug.enabled;
        drop(settings);

        if debug_enabled {
            debug!("Getting API path from base_path: '{}'", self.base_path);
        }

        let decoded_path = urlencoding::decode(&self.base_path)
            .unwrap_or(std::borrow::Cow::Owned(self.base_path.clone()))
            .into_owned();

        if debug_enabled {
            log::debug!("Decoded base path: '{}'", decoded_path);
        }

        let trimmed_path = decoded_path.trim_matches('/');
        
        if debug_enabled {
            log::debug!("Trimmed path: '{}'", trimmed_path);
        }
        
        if trimmed_path.is_empty() {
            if debug_enabled {
                log::debug!("Path is empty, returning empty string");
            }
            String::new()
        } else {
            let encoded = url::form_urlencoded::byte_serialize(trimmed_path.as_bytes())
                .collect::<String>();
            
            if debug_enabled {
                log::debug!("Final encoded API path: '{}'", encoded);
            }
            encoded
        }
    }

    /// Get the full path for a file
    pub(crate) async fn get_full_path(&self, path: &str) -> String {
        let settings = self.settings.read().await;
        let debug_enabled = settings.system.debug.enabled;
        drop(settings);

        if debug_enabled {
            debug!("Getting full path - Base: '{}', Input path: '{}'",
                self.base_path, path);
        }

        let base = self.base_path.trim_matches('/');
        let path = path.trim_matches('/');

        if debug_enabled {
            log::debug!("Trimmed paths - Base: '{}', Path: '{}'", base, path);
        }
        
        // First decode any existing encoding to prevent double-encoding
        let decoded_path = urlencoding::decode(path)
            .unwrap_or(std::borrow::Cow::Owned(path.to_string()))
            .into_owned();
        let decoded_base = urlencoding::decode(base)
            .unwrap_or(std::borrow::Cow::Owned(base.to_string()))
            .into_owned();
        
        if debug_enabled {
            log::debug!("Decoded paths - Base: '{}', Path: '{}'",
                decoded_base, decoded_path);
        }
        
        let full_path = if !decoded_base.is_empty() {
            if decoded_path.is_empty() {
                if debug_enabled {
                    log::debug!("Using base path only: '{}'", decoded_base);
                }
                decoded_base
            } else {
                let combined = format!("{}/{}", decoded_base, decoded_path);
                if debug_enabled {
                    log::debug!("Combined path: '{}'", combined);
                }
                combined
            }
        } else {
            if debug_enabled {
                log::debug!("Using decoded path only: '{}'", decoded_path);
            }
            decoded_path
        };

        let encoded = url::form_urlencoded::byte_serialize(full_path.as_bytes())
            .collect::<String>();

        if debug_enabled {
            log::debug!("Final encoded full path: '{}'", encoded);
        }

        encoded
    }

    /// Get the base URL for contents API
    pub(crate) async fn get_contents_url(&self, path: &str) -> String {
        let settings = self.settings.read().await;
        let debug_enabled = settings.system.debug.enabled;
        drop(settings);

        if debug_enabled {
            debug!("Constructing contents URL - Owner: '{}', Repo: '{}', Path: '{}'",
                self.owner, self.repo, path);
        }

        let full_path = self.get_full_path(path).await;
        
        if debug_enabled {
            debug!("Encoded full path: '{}'", full_path);
        }

        let url = format!(
            "https://api.github.com/repos/{}/{}/contents/{}",
            self.owner,
            self.repo,
            full_path
        );

        if debug_enabled {
            debug!("Final contents URL: '{}'", url);
        }

        url
    }

    /// Get the client for making requests
    pub(crate) fn client(&self) -> &Client {
        &self.client
    }

    /// Get the authorization token
    pub(crate) fn token(&self) -> &str {
        &self.token
    }

    /// Get owner name
    pub(crate) fn owner(&self) -> &str {
        &self.owner
    }

    /// Get repository name
    pub(crate) fn repo(&self) -> &str {
        &self.repo
    }

    /// Get base path
    pub(crate) fn base_path(&self) -> &str {
        &self.base_path
    }

    /// Get settings
    pub(crate) fn settings(&self) -> &Arc<RwLock<AppFullSettings>> { // Changed from Settings to AppFullSettings
        &self.settings
    }

    /// Get constants
    pub(crate) fn constants() -> (Duration, u32, Duration) {
        (GITHUB_API_DELAY, MAX_RETRIES, RETRY_DELAY)
    }
}
----
services/github/types.rs
use serde::{Deserialize, Serialize};
use chrono::{DateTime, Utc};
use std::error::Error;
use std::fmt;

/// Rate limit information from GitHub API
#[derive(Debug, Clone)]
pub struct RateLimitInfo {
    pub remaining: u32,
    pub limit: u32,
    pub reset_time: DateTime<Utc>,
}

/// Represents errors that can occur during GitHub API operations
#[derive(Debug)]
pub enum GitHubError {
    /// Error returned by the GitHub API itself
    ApiError(String),
    /// Network-related errors during API calls
    NetworkError(reqwest::Error),
    /// JSON serialization/deserialization errors
    SerializationError(serde_json::Error),
    /// Input validation errors
    ValidationError(String),
    /// Base64 encoding/decoding errors
    Base64Error(base64::DecodeError),
    /// Rate limit exceeded
    RateLimitExceeded(RateLimitInfo),
    /// Resource not found
    NotFound(String),
}

impl fmt::Display for GitHubError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            GitHubError::ApiError(msg) => write!(f, "GitHub API error: {}", msg),
            GitHubError::NetworkError(e) => write!(f, "Network error: {}", e),
            GitHubError::SerializationError(e) => write!(f, "Serialization error: {}", e),
            GitHubError::ValidationError(msg) => write!(f, "Validation error: {}", msg),
            GitHubError::Base64Error(e) => write!(f, "Base64 encoding error: {}", e),
            GitHubError::RateLimitExceeded(info) => {
                write!(f, "Rate limit exceeded. Remaining: {}/{}, Reset time: {}",
                    info.remaining, info.limit, info.reset_time)
            }
            GitHubError::NotFound(path) => {
                write!(f, "Resource not found: {}", path)
            }
        }
    }
}

impl Error for GitHubError {}

impl From<reqwest::Error> for GitHubError {
    fn from(err: reqwest::Error) -> Self {
        GitHubError::NetworkError(err)
    }
}

impl From<serde_json::Error> for GitHubError {
    fn from(err: serde_json::Error) -> Self {
        GitHubError::SerializationError(err)
    }
}

impl From<base64::DecodeError> for GitHubError {
    fn from(err: base64::DecodeError) -> Self {
        GitHubError::Base64Error(err)
    }
}

/// Represents a file in the GitHub repository
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct GitHubFile {
    /// Name of the file
    pub name: String,
    /// Full path to the file in the repository
    pub path: String,
    /// SHA hash of the file content
    pub sha: String,
    /// Size of the file in bytes
    pub size: usize,
    /// GitHub API URL for the file
    pub url: String,
    /// Direct download URL for the file content
    pub download_url: String,
}

/// Metadata about a file from GitHub including tracking information
#[derive(Debug, Serialize, Deserialize, Clone, Eq, PartialEq, Hash)]
pub struct GitHubFileMetadata {
    /// Name of the file
    pub name: String,
    /// SHA hash of the file content
    pub sha: String,
    /// Direct download URL for the file content
    pub download_url: String,
    /// ETag for caching
    pub etag: Option<String>,
    /// When this metadata was last checked
    #[serde(with = "chrono::serde::ts_seconds_option")]
    pub last_checked: Option<DateTime<Utc>>,
    /// When the file was last modified on GitHub
    #[serde(with = "chrono::serde::ts_seconds_option")]
    pub last_modified: Option<DateTime<Utc>>,
}

/// Response from content-related API calls
#[derive(Debug, Deserialize)]
pub struct ContentResponse {
    pub sha: String,
}

/// Response from pull request creation
#[derive(Debug, Deserialize)]
pub struct PullRequestResponse {
    pub html_url: String,
    pub number: u32,
    pub state: String,
}

/// Request to create a new branch
#[derive(Debug, Serialize)]
pub struct CreateBranchRequest {
    pub ref_name: String,
    pub sha: String,
}

/// Request to create a pull request
#[derive(Debug, Serialize)]
pub struct CreatePullRequest {
    pub title: String,
    pub head: String,
    pub base: String,
    pub body: String,
}

/// Request to update a file
#[derive(Debug, Serialize)]
pub struct UpdateFileRequest {
    pub message: String,
    pub content: String,
    pub sha: String,
    pub branch: String,
}
----
services/github/content.rs
use super::api::GitHubClient;
use super::types::{GitHubFileMetadata, GitHubError, RateLimitInfo};
use chrono::{DateTime, Utc};
use log::{debug, error, info};
use std::error::Error;
use std::sync::Arc;
use reqwest::header::HeaderMap;
use std::collections::HashMap;
use tokio::sync::RwLock;
use std::time::Duration;
use std::pin::Pin;
use std::future::Future;

const BATCH_SIZE: usize = 5;
const BATCH_DELAY: Duration = Duration::from_millis(500);

/// Handles GitHub content API operations
#[derive(Clone)]
pub struct ContentAPI {
    client: Arc<GitHubClient>,
    rate_limits: Arc<RwLock<HashMap<String, RateLimitInfo>>>,
}

impl ContentAPI {
    /// Create a new ContentAPI instance
    pub fn new(client: Arc<GitHubClient>) -> Self {
        Self {
            client,
            rate_limits: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    /// Ensure consistent URL encoding for paths
    async fn encode_path(&self, path: &str) -> String {
        let settings = self.client.settings().read().await;
        let debug_enabled = settings.system.debug.enabled;
        drop(settings);

        if debug_enabled {
            debug!("Encoding path: '{}'", path);
        }

        // First decode to prevent double-encoding
        let decoded = urlencoding::decode(path)
            .unwrap_or(std::borrow::Cow::Owned(path.to_string()))
            .into_owned();
        
        if debug_enabled {
            debug!("Decoded path: '{}'", decoded);
        }
        
        // Clean the path
        let cleaned = decoded
            .trim_matches('/')
            .replace("//", "/")
            .replace('\\', "/");

        if debug_enabled {
            debug!("Cleaned path: '{}'", cleaned);
        }

        // Encode using form URL encoding for consistent handling
        let encoded = url::form_urlencoded::byte_serialize(cleaned.as_bytes())
            .collect::<String>();

        if debug_enabled {
            debug!("Final encoded path: '{}'", encoded);
        }

        encoded
    }

    /// Extract and update rate limit information from response headers
    async fn update_rate_limits(&self, headers: &HeaderMap) {
        let settings = self.client.settings().read().await;
        let debug_enabled = settings.system.debug.enabled;
        drop(settings);

        if debug_enabled {
            debug!("Processing rate limit headers: {:?}", headers);
        }

        if let (Some(remaining), Some(limit), Some(reset)) = (
            headers.get("x-ratelimit-remaining"),
            headers.get("x-ratelimit-limit"),
            headers.get("x-ratelimit-reset")
        ) {
            let remaining = remaining.to_str().unwrap_or("0").parse().unwrap_or(0);
            let limit = limit.to_str().unwrap_or("0").parse().unwrap_or(0);
            let reset = reset.to_str().unwrap_or("0").parse().unwrap_or(0);
            
            if debug_enabled {
                debug!("Rate limit values - Remaining: {}, Limit: {}, Reset: {}",
                    remaining, limit, reset);
            }
            
            let reset_time = DateTime::from_timestamp(reset, 0)
                .unwrap_or_else(|| Utc::now());

            let info = RateLimitInfo {
                remaining,
                limit,
                reset_time,
            };

            if debug_enabled {
                debug!("Updating rate limits - New info: {:?}", info);
            }

            let mut limits = self.rate_limits.write().await;
            limits.insert("core".to_string(), info);
        } else if debug_enabled {
            debug!("No rate limit headers found in response");
        }
    }

    /// Check rate limits and handle backoff if needed
    fn check_rate_limit(&self) -> Pin<Box<dyn Future<Output = Result<(), GitHubError>> + '_>> {
        Box::pin(async move {
            let settings = self.client.settings().read().await;
            let debug_enabled = settings.system.debug.enabled;
            drop(settings);

            if debug_enabled {
                debug!("Checking rate limits...");
            }

            let limits = self.rate_limits.read().await;
            if let Some(info) = limits.get("core") {
                if debug_enabled {
                    debug!("Current rate limit info: {:?}", info);
                }

                if info.remaining == 0 {
                    let now = Utc::now();
                    if debug_enabled {
                        debug!("Rate limit exhausted. Current time: {}, Reset time: {}",
                            now, info.reset_time);
                    }

                    if now < info.reset_time {
                        let wait_time = info.reset_time - now;
                        let backoff = wait_time.num_seconds().min(30) as u64;
                        
                        if debug_enabled {
                            debug!("Rate limited. Wait time: {}s, Using backoff: {}s",
                                wait_time.num_seconds(), backoff);
                        }
                        
                        // Drop the read lock before sleeping
                        drop(limits);
                        
                        // Sleep with exponential backoff, max 30 seconds
                        tokio::time::sleep(Duration::from_secs(backoff)).await;
                        
                        if debug_enabled {
                            debug!("Backoff complete, rechecking rate limits");
                        }
                        
                        // Recursively check rate limit
                        return self.check_rate_limit().await;
                    }

                    if debug_enabled {
                        debug!("Rate limit exceeded and reset time passed");
                    }
                    return Err(GitHubError::RateLimitExceeded(info.clone()));
                }

                if debug_enabled {
                    debug!("Rate limit check passed. Remaining: {}/{}",
                        info.remaining, info.limit);
                }
            } else if debug_enabled {
                debug!("No rate limit information available");
            }
            Ok(())
        })
    }

    /// Check if a file is public by reading just the first line
    pub async fn check_file_public(&self, download_url: &str) -> Result<bool, Box<dyn Error + Send + Sync>> {
        // Check rate limits before making request
        self.check_rate_limit().await?;

        // First try a HEAD request to get content length
        let head_response = self.client.client()
            .head(download_url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .send()
            .await?;

        // Update rate limits from HEAD response
        self.update_rate_limits(head_response.headers()).await;

        // Get content length, default to 1024 if not available
        let content_length: u64 = head_response
            .headers()
            .get("content-length")
            .and_then(|v| v.to_str().ok())
            .and_then(|v| v.parse().ok())
            .unwrap_or(1024);

        // Calculate appropriate range based on content length
        let range = if content_length < 100 {
            format!("bytes=0-{}", content_length - 1)
        } else {
            "bytes=0-100".to_string()
        };

        debug!("Using range {} for file of size {}", range, content_length);

        let response = self.client.client()
            .get(download_url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .header("Range", range)
            .send()
            .await?;

        // Update rate limits from response headers
        self.update_rate_limits(response.headers()).await;

        let status = response.status();
        match status.as_u16() {
            200 | 206 => { // Success or Partial Content
                let content = response.text().await?;
                debug!("First line check ({}): '{}'", download_url, content.trim());
                Ok(content.trim().starts_with("public:: true"))
            },
            404 => {
                error!("File not found: {}", download_url);
                Err(Box::new(GitHubError::NotFound(download_url.to_string())))
            },
            416 => { // Range Not Satisfiable
                debug!("File exists but is empty or too small: {}", download_url);
                Ok(false)
            },
            429 => {
                let limits = self.rate_limits.read().await;
                if let Some(info) = limits.get("core") {
                    Err(Box::new(GitHubError::RateLimitExceeded(info.clone())))
                } else {
                    Err("Rate limit exceeded without limit info".into())
                }
            },
            _ => {
                let error_text = response.text().await.unwrap_or_else(|_| "Unknown error".to_string());
                error!("Failed to check file public status. Status: {}, Error: {}", status, error_text);
                Err(Box::new(GitHubError::ApiError(format!("{} - {}", status, error_text))))
            }
        }
    }

    /// Fetch full content of a file
    pub async fn fetch_file_content(&self, download_url: &str) -> Result<String, Box<dyn Error + Send + Sync>> {
        // Check rate limits before making request
        self.check_rate_limit().await?;

        let response = self.client.client()
            .get(download_url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .send()
            .await?;

        // Update rate limits from response headers
        self.update_rate_limits(response.headers()).await;

        let status = response.status();
        match status.as_u16() {
            200 => {
                let content = response.text().await?;
                Ok(content)
            },
            404 => {
                error!("File not found: {}", download_url);
                Err(Box::new(GitHubError::NotFound(download_url.to_string())))
            },
            429 => {
                let limits = self.rate_limits.read().await;
                if let Some(info) = limits.get("core") {
                    Err(Box::new(GitHubError::RateLimitExceeded(info.clone())))
                } else {
                    Err("Rate limit exceeded without limit info".into())
                }
            },
            _ => {
                let error_text = response.text().await.unwrap_or_else(|_| "Unknown error".to_string());
                error!("Failed to fetch file content. Status: {}, Error: {}", status, error_text);
                Err(Box::new(GitHubError::ApiError(format!("{} - {}", status, error_text))))
            }
        }
    }

    /// Get the last modified time for a file
    pub async fn get_file_last_modified(&self, file_path: &str) -> Result<DateTime<Utc>, Box<dyn Error + Send + Sync>> {
        // Check rate limits before making request
        self.check_rate_limit().await?;

        // Use GitHubClient's path handling
        let encoded_path = self.client.get_full_path(file_path).await;
        let url = format!(
            "https://api.github.com/repos/{}/{}/commits",
            self.client.owner(), self.client.repo()
        );

        debug!("GitHub API URL: {}", url);
        debug!("Query parameters: path={}, per_page=1", encoded_path);
        debug!("Getting last modified time - Original path: {}, Encoded path: {}",
            file_path, encoded_path);

        let response = self.client.client()
            .get(&url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .query(&[("path", encoded_path.as_str()), ("per_page", "1")])
            .send()
            .await?;

        // Update rate limits from response headers
        self.update_rate_limits(response.headers()).await;

        let status = response.status();
        if !status.is_success() {
            let error_text = response.text().await?;
            error!("Failed to get last modified time. Status: {}, Error: {}", status, error_text);
            
            return match status.as_u16() {
                404 => Err(Box::new(GitHubError::NotFound(file_path.to_string()))),
                429 => {
                    let limits = self.rate_limits.read().await;
                    if let Some(info) = limits.get("core") {
                        Err(Box::new(GitHubError::RateLimitExceeded(info.clone())))
                    } else {
                        Err(format!("Rate limit exceeded without limit info").into())
                    }
                },
                _ => Err(format!("GitHub API error: {} - {}", status, error_text).into())
            };
        }

        let response_text = response.text().await?;
        debug!("GitHub API Response for commits: {}", response_text);
        
        let commits: Vec<serde_json::Value> = serde_json::from_str(&response_text)?;
        
        if commits.is_empty() {
            error!("Empty commits array returned for path: {} (encoded: {})", file_path, encoded_path);
            return Err(Box::new(GitHubError::NotFound(format!("No commit history found for {}", file_path))));
        }
        
        if let Some(last_commit) = commits.first() {
            debug!("Found commit data: {}", serde_json::to_string_pretty(last_commit)?);
            if let Some(commit) = last_commit["commit"]["committer"]["date"].as_str() {
                if let Ok(date) = DateTime::parse_from_rfc3339(commit) {
                    return Ok(date.with_timezone(&Utc));
                } else {
                    error!("Failed to parse commit date: {}", commit);
                    return Err("Failed to parse commit date from GitHub response".into());
                }
            } else {
                error!("No committer date found in commit data");
                return Err("No committer date found in GitHub response".into());
            }
        } else {
            error!("No commits found for file: {} (encoded path: {})", file_path, encoded_path);
            return Err(format!("No commit history found for file: {} (API path: {})", file_path, encoded_path).into());
        }
    }

    /// List all markdown files in a directory
    pub async fn list_markdown_files(&self, path: &str) -> Result<Vec<GitHubFileMetadata>, Box<dyn Error + Send + Sync>> {
        // Use GitHubClient's contents URL construction
        let url = self.client.get_contents_url(path).await;
        
        info!("GitHub API Request: URL={}, Original Path={}",
            url, path);

        let response = self.client.client()
            .get(&url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .send()
            .await?;

        let status = response.status();
        let headers = response.headers().clone();
        
        info!("GitHub API Response: Status={}, Headers={:?}", status, headers);

        let body = response.text().await?;
        info!("GitHub API Response Body (first 1000 chars): {}", &body[..body.len().min(1000)]);

        if !status.is_success() {
            let error_msg = match serde_json::from_str::<serde_json::Value>(&body) {
                Ok(error_json) => {
                    let msg = error_json["message"].as_str().unwrap_or("Unknown error");
                    format!("GitHub API error: {} - {}", status, msg)
                },
                Err(_) => format!("GitHub API error: {} - {}", status, body)
            };
            error!("{}", error_msg);
            return Err(error_msg.into());
        }

        let contents: Vec<serde_json::Value> = serde_json::from_str(&body)?;

        let settings = self.client.settings().read().await;
        let debug_enabled = settings.system.debug.enabled;
        drop(settings);

        if debug_enabled {
            debug!("Found {} total items in directory", contents.len());
            debug!("Batch size: {}, Expected batches: {}",
                BATCH_SIZE,
                (contents.len() + BATCH_SIZE - 1) / BATCH_SIZE
            );
            
            // Log file types distribution
            let file_count = contents.iter()
                .filter(|item| item["type"].as_str().unwrap_or("") == "file")
                .count();
            let md_count = contents.iter()
                .filter(|item| {
                    item["type"].as_str().unwrap_or("") == "file" &&
                    item["name"].as_str().unwrap_or("").ends_with(".md")
                })
                .count();
            debug!("Content distribution - Total: {}, Files: {}, Markdown: {}",
                contents.len(), file_count, md_count);
        }
        
        let mut markdown_files = Vec::new();
        let mut current_idx = 0;
        
        // Process files in batches
        while current_idx < contents.len() {
            let end_idx = (current_idx + BATCH_SIZE).min(contents.len());
            let batch_number = current_idx / BATCH_SIZE + 1;
            let total_batches = (contents.len() + BATCH_SIZE - 1) / BATCH_SIZE;
            
            if debug_enabled {
                debug!("Starting batch {}/{} (items {}-{} of {})",
                    batch_number,
                    total_batches,
                    current_idx + 1,
                    end_idx,
                    contents.len()
                );
            }
            
            for item in &contents[current_idx..end_idx] {
                let item_type = item["type"].as_str().unwrap_or("");
                let item_name = item["name"].as_str().unwrap_or("");
                
                if debug_enabled {
                    debug!("Examining item: type='{}', name='{}'", item_type, item_name);
                }

                if item_type == "file" && item_name.ends_with(".md") {
                    let name = item_name.to_string();
                    
                    if debug_enabled {
                        if !name.contains("Debug Test Page") && !name.contains("debug linked node") {
                            debug!("Skipping non-debug file in debug mode: {}", name);
                            continue;
                        }
                        debug!("Processing debug markdown file: {}", name);
                    } else {
                        debug!("Processing markdown file: {}", name);
                    }
                
                // Use the file name directly since base path is already handled
                debug!("Repository path for commits query: {}", name);
                
                // Combine with base path and get last modified time
                let full_path = if path.is_empty() {
                    name.clone()
                } else {
                    format!("{}/{}", path.trim_matches('/'), name)
                };
                // Add delay between API calls within batch
                tokio::time::sleep(BATCH_DELAY).await;
                
                if debug_enabled {
                    debug!("Fetching last modified time for: {}", full_path);
                }

                let last_modified = match self.get_file_last_modified(&full_path).await {
                    Ok(time) => {
                        if debug_enabled {
                            debug!("Got last modified time for {}: {}", name, time);
                        }
                        Some(time)
                    },
                    Err(e) => {
                        error!("Failed to get last modified time for {}: {}", name, e);
                        if debug_enabled {
                            debug!("Using current time as fallback for {}", name);
                        }
                        Some(Utc::now())
                    }
                };

                let sha = item["sha"].as_str().unwrap_or("").to_string();
                let download_url = item["download_url"].as_str().unwrap_or("").to_string();
                
                if debug_enabled {
                    debug!("Collecting metadata - Name: {}, SHA: {}, URL: {}",
                        name, sha, download_url);
                }
                
                markdown_files.push(GitHubFileMetadata {
                    name,
                    sha,
                    download_url,
                    etag: None,
                    last_checked: Some(Utc::now()),
                    last_modified,
                });
                }
            }
            
            // Move to next batch
            current_idx = end_idx;
            
            let batch_number = current_idx / BATCH_SIZE;
            let total_batches = (contents.len() + BATCH_SIZE - 1) / BATCH_SIZE;
            let progress = (current_idx * 100) / contents.len();
            
            // Log batch completion with detailed stats
            info!("Completed batch {}/{} - {}% complete ({} files processed)",
                batch_number,
                total_batches,
                progress,
                markdown_files.len()
            );
            
            if debug_enabled {
                let remaining_items = contents.len() - current_idx;
                let est_remaining_batches = (remaining_items + BATCH_SIZE - 1) / BATCH_SIZE;
                let est_remaining_time = est_remaining_batches as u64 * BATCH_DELAY.as_secs();
                
                debug!("Batch performance - Remaining items: {}, Est. remaining batches: {}, Est. time: {}s",
                    remaining_items,
                    est_remaining_batches,
                    est_remaining_time
                );
            }
            
            // Add delay between batches if not the last batch
            if current_idx < contents.len() {
                if debug_enabled {
                    debug!("Adding inter-batch delay of {}ms", BATCH_DELAY.as_millis());
                }
                tokio::time::sleep(BATCH_DELAY).await;
            }
        }

        if debug_enabled {
            info!("Debug mode: Processing only debug test files");
        }

        info!("Found {} markdown files in {} batches",
            markdown_files.len(),
            (contents.len() + BATCH_SIZE - 1) / BATCH_SIZE
        );
        Ok(markdown_files)
    }
}
----
config/mod.rs
use config::{ConfigBuilder, ConfigError, Environment};
use log::{debug, error}; // Added error log
use serde::{Deserialize, Serialize};
use serde_json::Value;
use serde_yaml;
use std::path::PathBuf;
// use std::collections::BTreeMap; // For ordered map during serialization - Removed as unused

pub mod feature_access;

// Recursive function to convert JSON Value keys to snake_case
fn keys_to_snake_case(value: Value) -> Value {
    match value {
        Value::Object(map) => {
            let new_map = map.into_iter().map(|(k, v)| {
                let snake_key = k.chars().fold(String::new(), |mut acc, c| {
                    if c.is_ascii_uppercase() {
                        if !acc.is_empty() {
                            acc.push('_');
                        }
                        acc.push(c.to_ascii_lowercase());
                    } else {
                        acc.push(c);
                    }
                    acc
                });
                (snake_key, keys_to_snake_case(v))
            }).collect();
            Value::Object(new_map)
        }
        Value::Array(arr) => {
            Value::Array(arr.into_iter().map(keys_to_snake_case).collect())
        }
        _ => value,
    }
}

// Recursive function to convert JSON Value keys to camelCase (if needed for comparison/debugging)
fn _keys_to_camel_case(value: Value) -> Value {
     match value {
         Value::Object(map) => {
             let new_map = map.into_iter().map(|(k, v)| {
                 let camel_key = k.split('_').enumerate().map(|(i, part)| {
                     if i == 0 {
                         part.to_string()
                     } else {
                         part.chars().next().map_or(String::new(), |c| c.to_uppercase().collect::<String>() + &part[1..])
                     }
                 }).collect::<String>();
                 (camel_key, _keys_to_camel_case(v))
             }).collect();
             Value::Object(new_map)
         }
         Value::Array(arr) => {
             Value::Array(arr.into_iter().map(_keys_to_camel_case).collect())
         }
         _ => value,
     }
 }


#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct MovementAxes {
    pub horizontal: i32,
    pub vertical: i32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct NodeSettings {
    pub base_color: String,
    pub metalness: f32,
    pub opacity: f32,
    pub roughness: f32,
    pub size_range: Vec<f32>,
    pub quality: String,
    pub enable_instancing: bool,
    pub enable_hologram: bool,
    pub enable_metadata_shape: bool,
    pub enable_metadata_visualisation: bool,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct EdgeSettings {
    pub arrow_size: f32,
    pub base_width: f32,
    pub color: String,
    pub enable_arrows: bool,
    pub opacity: f32,
    pub width_range: Vec<f32>,
    pub quality: String,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct PhysicsSettings {
    pub attraction_strength: f32,
    pub bounds_size: f32,
    pub collision_radius: f32,
    pub damping: f32,
    pub enable_bounds: bool,
    pub enabled: bool,
    pub iterations: u32,
    pub max_velocity: f32,
    pub repulsion_strength: f32,
    pub spring_strength: f32,
    pub repulsion_distance: f32,
    pub mass_scale: f32,
    pub boundary_damping: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct RenderingSettings {
    pub ambient_light_intensity: f32,
    pub background_color: String,
    pub directional_light_intensity: f32,
    pub enable_ambient_occlusion: bool,
    pub enable_antialiasing: bool,
    pub enable_shadows: bool,
    pub environment_intensity: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct AnimationSettings {
    pub enable_motion_blur: bool,
    pub enable_node_animations: bool,
    pub motion_blur_strength: f32,
    pub selection_wave_enabled: bool,
    pub pulse_enabled: bool,
    pub pulse_speed: f32,
    pub pulse_strength: f32,
    pub wave_speed: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct LabelSettings {
    pub desktop_font_size: f32,
    pub enable_labels: bool,
    pub text_color: String,
    pub text_outline_color: String,
    pub text_outline_width: f32,
    pub text_resolution: u32,
    pub text_padding: f32,
    pub billboard_mode: String,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct BloomSettings {
    pub edge_bloom_strength: f32,
    pub enabled: bool,
    pub environment_bloom_strength: f32,
    pub node_bloom_strength: f32,
    pub radius: f32,
    pub strength: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct HologramSettings {
    pub ring_count: u32,
    pub ring_color: String,
    pub ring_opacity: f32,
    pub sphere_sizes: Vec<f32>,
    pub ring_rotation_speed: f32,
    pub enable_buckminster: bool,
    pub buckminster_size: f32,
    pub buckminster_opacity: f32,
    pub enable_geodesic: bool,
    pub geodesic_size: f32,
    pub geodesic_opacity: f32,
    pub enable_triangle_sphere: bool,
    pub triangle_sphere_size: f32,
    pub triangle_sphere_opacity: f32,
    pub global_rotation_speed: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct VisualisationSettings {
    pub nodes: NodeSettings,
    pub edges: EdgeSettings,
    pub physics: PhysicsSettings,
    pub rendering: RenderingSettings,
    pub animations: AnimationSettings,
    pub labels: LabelSettings,
    pub bloom: BloomSettings,
    pub hologram: HologramSettings,
}

// --- Server-Specific Config Structs (from YAML, snake_case) ---

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// No rename_all needed if YAML keys are snake_case
pub struct NetworkSettings {
    pub bind_address: String,
    pub domain: String,
    pub enable_http2: bool,
    pub enable_rate_limiting: bool,
    pub enable_tls: bool,
    pub max_request_size: usize,
    pub min_tls_version: String,
    pub port: u16,
    pub rate_limit_requests: u32,
    pub rate_limit_window: u32,
    pub tunnel_id: String,
    pub api_client_timeout: u64,
    pub enable_metrics: bool,
    pub max_concurrent_requests: u32,
    pub max_retries: u32,
    pub metrics_port: u16,
    pub retry_delay: u32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
// No rename_all needed if YAML keys are snake_case
pub struct ServerFullWebSocketSettings {
    pub binary_chunk_size: usize,
    pub binary_update_rate: u32,
    pub min_update_rate: u32,
    pub max_update_rate: u32,
    pub motion_threshold: f32,
    pub motion_damping: f32,
    pub binary_message_version: u32,
    pub compression_enabled: bool,
    pub compression_threshold: usize,
    pub heartbeat_interval: u64,
    pub heartbeat_timeout: u64,
    pub max_connections: usize,
    pub max_message_size: usize,
    pub reconnect_attempts: u32,
    pub reconnect_delay: u64,
    pub update_rate: u32,
}

impl Default for ServerFullWebSocketSettings {
    fn default() -> Self { // Defaults from settings.yaml
        Self {
            binary_chunk_size: 2048, binary_update_rate: 30, min_update_rate: 5,
            max_update_rate: 60, motion_threshold: 0.05, motion_damping: 0.9,
            binary_message_version: 1, compression_enabled: false, compression_threshold: 512,
            heartbeat_interval: 10000, heartbeat_timeout: 600000, max_connections: 100,
            max_message_size: 10485760, reconnect_attempts: 5, reconnect_delay: 1000,
            update_rate: 60,
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// No rename_all needed if YAML keys are snake_case
pub struct SecuritySettings {
    pub allowed_origins: Vec<String>,
    pub audit_log_path: String,
    pub cookie_httponly: bool,
    pub cookie_samesite: String,
    pub cookie_secure: bool,
    pub csrf_token_timeout: u32,
    pub enable_audit_logging: bool,
    pub enable_request_validation: bool,
    pub session_timeout: u32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct DebugSettings { // Matches TS DebugSettings + YAML fields
    pub enabled: bool,
    pub enable_data_debug: bool,
    pub enable_websocket_debug: bool,
    pub log_binary_headers: bool,
    pub log_full_json: bool,
    // Added back from YAML - these might need snake_case for YAML loading if config crate doesn't handle rename_all
    // Let's assume config crate handles it based on struct field names for YAML.
    pub log_level: String,
    pub log_format: String,
}


#[derive(Debug, Deserialize, Clone)] // Only Deserialize needed for loading YAML
// No rename_all needed if YAML keys are snake_case
pub struct ServerSystemConfigFromFile {
    pub network: NetworkSettings,
    pub websocket: ServerFullWebSocketSettings,
    pub security: SecuritySettings,
    pub debug: DebugSettings, // Assumes YAML debug section matches DebugSettings struct fields (snake_case)
    #[serde(default)]
    pub persist_settings: bool,
}

// --- Client-Facing Config Structs (for JSON, camelCase) ---

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ClientWebSocketSettings { // What client sends/expects
    pub reconnect_attempts: u32,
    pub reconnect_delay: u64,
    pub binary_chunk_size: usize,
    pub compression_enabled: bool,
    pub compression_threshold: usize,
    pub update_rate: u32,
}

impl Default for ClientWebSocketSettings {
    fn default() -> Self {
        Self {
            reconnect_attempts: 3, reconnect_delay: 5000, binary_chunk_size: 65536,
            compression_enabled: true, compression_threshold: 1024, update_rate: 30,
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct SystemSettings { // Client-facing System structure
    pub websocket: ClientWebSocketSettings,
    pub debug: DebugSettings, // DebugSettings uses camelCase for JSON
    #[serde(default)]
    pub persist_settings: bool,
    // network and security are not part of client-facing system settings
}

impl Default for SystemSettings {
    fn default() -> Self {
        Self {
            websocket: ClientWebSocketSettings::default(),
            debug: DebugSettings::default(),
            persist_settings: true,
        }
    }
}


#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct XRSettings { // Client-facing XR structure + YAML fields
    // Fields from YAML (snake_case in YAML, camelCase in JSON)
    pub mode: String,
    pub room_scale: f32,
    pub space_type: String,
    pub quality: String,
    #[serde(alias = "handTracking")]
    pub enable_hand_tracking: bool,
    pub hand_mesh_enabled: bool,
    pub hand_mesh_color: String,
    pub hand_mesh_opacity: f32,
    pub hand_point_size: f32,
    pub hand_ray_enabled: bool,
    pub hand_ray_color: String,
    pub hand_ray_width: f32,
    pub gesture_smoothing: f32,
    pub enable_haptics: bool,
    pub drag_threshold: f32,
    pub pinch_threshold: f32,
    pub rotation_threshold: f32,
    #[serde(alias = "interactionDistance")]
    pub interaction_radius: f32,
    pub movement_speed: f32,
    pub dead_zone: f32,
    pub movement_axes: MovementAxes,
    pub enable_light_estimation: bool,
    pub enable_plane_detection: bool,
    pub enable_scene_understanding: bool,
    pub plane_color: String,
    pub plane_opacity: f32,
    pub plane_detection_distance: f32,
    pub show_plane_overlay: bool,
    pub snap_to_floor: bool,
    pub enable_passthrough_portal: bool,
    pub passthrough_opacity: f32,
    pub passthrough_brightness: f32,
    pub passthrough_contrast: f32,
    pub portal_size: f32,
    pub portal_edge_color: String,
    pub portal_edge_width: f32,

    // Fields from TS (camelCase in JSON)
    #[serde(default)]
    pub enabled: Option<bool>, // TS 'enabled' field
    #[serde(default, alias = "controllerModel")]
    pub controller_model: Option<String>,
    #[serde(default, alias = "renderScale")]
    pub render_scale: Option<f32>,
    #[serde(default, alias = "locomotionMethod")]
    pub locomotion_method: Option<String>,
    #[serde(default, alias = "teleportRayColor")]
    pub teleport_ray_color: Option<String>,
    #[serde(default, alias = "displayMode")]
    pub display_mode: Option<String>,
    #[serde(default, alias = "controllerRayColor")]
    pub controller_ray_color: Option<String>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct AuthSettings { // Client-facing
    pub enabled: bool,
    pub provider: String,
    pub required: bool,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct RagFlowSettings { // Client-facing
    #[serde(default)] pub api_key: Option<String>,
    #[serde(default)] pub agent_id: Option<String>,
    #[serde(default)] pub api_base_url: Option<String>,
    #[serde(default)] pub timeout: Option<u64>,
    #[serde(default)] pub max_retries: Option<u32>,
    #[serde(default)] pub chat_id: Option<String>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct PerplexitySettings { // Client-facing
    #[serde(default)] pub api_key: Option<String>,
    #[serde(default)] pub model: Option<String>,
    #[serde(default)] pub api_url: Option<String>,
    #[serde(default)] pub max_tokens: Option<u32>,
    #[serde(default)] pub temperature: Option<f32>,
    #[serde(default)] pub top_p: Option<f32>,
    #[serde(default)] pub presence_penalty: Option<f32>,
    #[serde(default)] pub frequency_penalty: Option<f32>,
    #[serde(default)] pub timeout: Option<u64>,
    #[serde(default)] pub rate_limit: Option<u32>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct OpenAISettings { // Client-facing
    #[serde(default)] pub api_key: Option<String>,
    #[serde(default)] pub base_url: Option<String>,
    #[serde(default)] pub timeout: Option<u64>,
    #[serde(default)] pub rate_limit: Option<u32>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
// #[serde(rename_all = "camelCase")] // Reverted
pub struct KokoroSettings { // Client-facing
    #[serde(default)] pub api_url: Option<String>,
    #[serde(default)] pub default_voice: Option<String>,
    #[serde(default)] pub default_format: Option<String>,
    #[serde(default)] pub default_speed: Option<f32>,
    #[serde(default)] pub timeout: Option<u64>,
    #[serde(default)] pub stream: Option<bool>,
    #[serde(default)] pub return_timestamps: Option<bool>,
    #[serde(default)] pub sample_rate: Option<u32>,
}

// --- Client-Facing Settings Struct (for JSON deserialization) ---
#[derive(Debug, Serialize, Deserialize, Clone, Default)]
#[serde(rename_all = "camelCase")]
pub struct Settings { // Renamed to ClientFacingSettings conceptually
    pub visualisation: VisualisationSettings,
    pub system: SystemSettings, // Uses ClientWebSocketSettings internally
    pub xr: XRSettings,
    pub auth: AuthSettings,
    #[serde(default)] pub ragflow: Option<RagFlowSettings>,
    #[serde(default)] pub perplexity: Option<PerplexitySettings>,
    #[serde(default)] pub openai: Option<OpenAISettings>,
    #[serde(default)] pub kokoro: Option<KokoroSettings>,
}

// --- Full App Settings Struct (for server state, loaded from YAML) ---
#[derive(Debug, Clone, Deserialize)] // Deserialize for YAML loading
// No rename_all needed if YAML keys are snake_case
pub struct AppFullSettings {
    pub visualisation: VisualisationSettings, // Assumes YAML keys are snake_case
    pub system: ServerSystemConfigFromFile,   // Contains ServerFullWebSocketSettings
    pub xr: XRSettings,                       // Assumes YAML keys are snake_case
    pub auth: AuthSettings,                   // Assumes YAML keys are snake_case
    #[serde(default)] pub ragflow: Option<RagFlowSettings>, // Assumes YAML keys are snake_case
    #[serde(default)] pub perplexity: Option<PerplexitySettings>,
    #[serde(default)] pub openai: Option<OpenAISettings>,
    #[serde(default)] pub kokoro: Option<KokoroSettings>,
}

// Manual Serialize implementation for AppFullSettings to ensure snake_case YAML output
impl Serialize for AppFullSettings {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        // Convert self to a serde_json::Value first.
        // The sub-structs might have rename_all="camelCase", so this Value will be camelCase.
        match serde_json::to_value(self) {
            Ok(camel_case_value) => {
                // Convert the camelCase Value to snake_case Value.
                let snake_case_value = keys_to_snake_case(camel_case_value);
                // Serialize the snake_case Value.
                snake_case_value.serialize(serializer)
            }
            Err(e) => {
                error!("Failed to convert AppFullSettings to intermediate Value for saving: {}", e);
                // Handle error appropriately, maybe serialize a default or error state
                Err(serde::ser::Error::custom(format!("Serialization error: {}", e)))
            }
        }
    }
}
// We also need Serialize for the sub-structs used by AppFullSettings
// if they are not already deriving Serialize. They are deriving it, but
// their rename_all attribute will cause camelCase serialization.
// The keys_to_snake_case function handles this during AppFullSettings serialization.


impl AppFullSettings {
    pub fn new() -> Result<Self, ConfigError> {
        debug!("Initializing AppFullSettings from YAML");
        dotenvy::dotenv().ok();

        let settings_path = std::env::var("SETTINGS_FILE_PATH")
            .map(PathBuf::from)
            .unwrap_or_else(|_| PathBuf::from("/app/settings.yaml"));
        debug!("Loading AppFullSettings from YAML file: {:?}", settings_path);

        let builder = ConfigBuilder::<config::builder::DefaultState>::default()
            .add_source(config::File::from(settings_path.clone()).required(true)) // Use path directly
            .add_source(
                Environment::default()
                    .separator("_") // Match SYSTEM_NETWORK_PORT style
                    .list_separator(",")
                // No .prefix("APP") // Allow direct environment variable override
            );
        let config = builder.build()?;
        debug!("Configuration built successfully. Deserializing AppFullSettings...");
        
        // Deserialize using field names (should match snake_case YAML)
        let result: Result<AppFullSettings, ConfigError> = config.clone().try_deserialize();
        if let Err(e) = &result {
             error!("Failed to deserialize AppFullSettings from {:?}: {}", settings_path, e);
             // Log raw value for debugging
             match config.try_deserialize::<Value>() { // config is still available here as the first try_deserialize consumed a clone
                 Ok(raw_value) => error!("Raw settings structure from YAML: {:?}", raw_value),
                 Err(val_err) => error!("Failed to deserialize into raw Value as well: {:?}", val_err),
             }
        }
        result
    }

    // Save method for AppFullSettings, ensuring snake_case YAML output
    pub fn save(&self) -> Result<(), String> {
        let settings_path = std::env::var("SETTINGS_FILE_PATH")
            .map(PathBuf::from)
            .unwrap_or_else(|_| PathBuf::from("/app/settings.yaml"));
        debug!("Saving AppFullSettings to YAML file: {:?}", settings_path);

        // Serialize self using the custom Serialize impl which converts keys to snake_case
        let yaml = serde_yaml::to_string(&self)
            .map_err(|e| format!("Failed to serialize AppFullSettings to YAML: {}", e))?;

        std::fs::write(&settings_path, yaml)
            .map_err(|e| format!("Failed to write settings file {:?}: {}", settings_path, e))?;
        debug!("Successfully saved AppFullSettings to {:?}", settings_path);
        Ok(())
    }
}


#[cfg(test)]
mod tests {
    // mod feature_access_test;
}
----
config/feature_access.rs
use std::env;
use std::fs;
use std::path::PathBuf;
use log::{info, warn};

/// Represents the access control configuration for various features and user roles
pub struct FeatureAccess {
    // Base access control
    pub approved_pubkeys: Vec<String>,
    
    // Feature-specific access
    pub perplexity_enabled: Vec<String>,
    pub openai_enabled: Vec<String>,
    pub ragflow_enabled: Vec<String>,
    
    // Role-based access control
    pub power_users: Vec<String>,
    pub settings_sync_enabled: Vec<String>,
}

impl FeatureAccess {
    /// Creates a new FeatureAccess instance from environment variables
    pub fn from_env() -> Self {
        Self {
            // Base access
            approved_pubkeys: Self::load_pubkeys_from_env("APPROVED_PUBKEYS"),
            
            // Feature access
            perplexity_enabled: Self::load_pubkeys_from_env("PERPLEXITY_ENABLED_PUBKEYS"),
            openai_enabled: Self::load_pubkeys_from_env("OPENAI_ENABLED_PUBKEYS"),
            ragflow_enabled: Self::load_pubkeys_from_env("RAGFLOW_ENABLED_PUBKEYS"),
            
            // Role-based access
            power_users: Self::load_pubkeys_from_env("POWER_USER_PUBKEYS"),
            settings_sync_enabled: Self::load_pubkeys_from_env("SETTINGS_SYNC_ENABLED_PUBKEYS"),
        }
    }

    /// Helper function to load and parse pubkeys from environment variables
    fn load_pubkeys_from_env(var_name: &str) -> Vec<String> {
        env::var(var_name)
            .unwrap_or_default()
            .split(',')
            .map(|s| s.trim().to_string())
            .filter(|s| !s.is_empty())
            .collect()
    }

    /// Registers a new user with basic access and default features
    pub fn register_new_user(&mut self, pubkey: &str) -> bool {
        let pubkey = pubkey.to_string();
        
        // Don't register if already approved
        if self.approved_pubkeys.contains(&pubkey) {
            return false;
        }

        // Add to approved pubkeys
        self.approved_pubkeys.push(pubkey.clone());
        
        // Grant RAGFlow access by default
        self.ragflow_enabled.push(pubkey.clone());
        
        // Grant OpenAI (Kokoros) access by default
        self.openai_enabled.push(pubkey.clone());

        // Update the environment file
        self.save_to_env_file();

        info!("Registered new user: {}", pubkey);
        true
    }

    /// Saves the current access configuration back to the .env file
    fn save_to_env_file(&self) {
        let env_path = PathBuf::from(".env");
        if let Ok(content) = fs::read_to_string(&env_path) {
            let mut lines: Vec<String> = content
                .lines()
                .map(|line| line.to_string())
                .collect();

            // Update the relevant lines
            self.update_env_line(&mut lines, "APPROVED_PUBKEYS", &self.approved_pubkeys);
            self.update_env_line(&mut lines, "RAGFLOW_ENABLED_PUBKEYS", &self.ragflow_enabled);
            self.update_env_line(&mut lines, "OPENAI_ENABLED_PUBKEYS", &self.openai_enabled);

            if let Err(e) = fs::write(&env_path, lines.join("\n")) {
                warn!("Failed to update .env file: {}", e);
            }
        }
    }

    fn update_env_line(&self, lines: &mut Vec<String>, var_name: &str, pubkeys: &[String]) {
        let new_line = format!("{}={}", var_name, pubkeys.join(","));
        if let Some(pos) = lines.iter().position(|line| line.starts_with(var_name)) {
            lines[pos] = new_line;
        } else {
            lines.push(new_line);
        }
    }

    /// Checks if a pubkey has basic access
    pub fn has_access(&self, pubkey: &str) -> bool {
        self.approved_pubkeys.contains(&pubkey.to_string())
    }

    /// Checks if a pubkey has access to Perplexity features
    pub fn has_perplexity_access(&self, pubkey: &str) -> bool {
        self.perplexity_enabled.contains(&pubkey.to_string())
    }

    /// Checks if a pubkey has access to OpenAI features
    pub fn has_openai_access(&self, pubkey: &str) -> bool {
        self.openai_enabled.contains(&pubkey.to_string())
    }

    /// Checks if a pubkey has access to RagFlow features
    pub fn has_ragflow_access(&self, pubkey: &str) -> bool {
        self.ragflow_enabled.contains(&pubkey.to_string())
    }

    /// Checks if a pubkey has power user status
    pub fn is_power_user(&self, pubkey: &str) -> bool {
        self.power_users.contains(&pubkey.to_string())
    }

    /// Checks if a pubkey has settings sync access
    pub fn can_sync_settings(&self, pubkey: &str) -> bool {
        // Power users automatically get settings sync access
        self.is_power_user(pubkey) || self.settings_sync_enabled.contains(&pubkey.to_string())
    }

    /// Checks if a pubkey has access to a specific feature
    pub fn has_feature_access(&self, pubkey: &str, feature: &str) -> bool {
        match feature {
            "perplexity" => self.has_perplexity_access(pubkey),
            "openai" => self.has_openai_access(pubkey),
            "ragflow" => self.has_ragflow_access(pubkey),
            "settings_sync" => self.can_sync_settings(pubkey),
            _ => false,
        }
    }

    /// Gets all features available to a pubkey
    pub fn get_available_features(&self, pubkey: &str) -> Vec<String> {
        let mut features = Vec::new();
        
        if self.has_perplexity_access(pubkey) {
            features.push("perplexity".to_string());
        }
        if self.has_openai_access(pubkey) {
            features.push("openai".to_string());
        }
        if self.has_ragflow_access(pubkey) {
            features.push("ragflow".to_string());
        }
        if self.can_sync_settings(pubkey) {
            features.push("settings_sync".to_string());
        }
        if self.is_power_user(pubkey) {
            features.push("power_user".to_string());
        }
        
        features
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::env;

    fn setup_test_env() {
        env::set_var("APPROVED_PUBKEYS", "pub1,pub2");
        env::set_var("POWER_USER_PUBKEYS", "pub1");
        env::set_var("PERPLEXITY_ENABLED_PUBKEYS", "pub1,pub2");
        env::set_var("OPENAI_ENABLED_PUBKEYS", "pub1");
        env::set_var("SETTINGS_SYNC_ENABLED_PUBKEYS", "pub2");
    }

    #[test]
    fn test_basic_access() {
        setup_test_env();
        let access = FeatureAccess::from_env();
        
        assert!(access.has_access("pub1"));
        assert!(access.has_access("pub2"));
        assert!(!access.has_access("pub3"));
    }

    #[test]
    fn test_power_user_status() {
        setup_test_env();
        let access = FeatureAccess::from_env();
        
        assert!(access.is_power_user("pub1"));
        assert!(!access.is_power_user("pub2"));
    }

    #[test]
    fn test_feature_access() {
        setup_test_env();
        let access = FeatureAccess::from_env();
        
        // Test pub1 (power user)
        assert!(access.has_perplexity_access("pub1"));
        assert!(access.has_openai_access("pub1"));
        assert!(access.can_sync_settings("pub1")); // Power users can always sync
        
        // Test pub2 (regular user with some features)
        assert!(access.has_perplexity_access("pub2"));
        assert!(!access.has_openai_access("pub2"));
        assert!(access.can_sync_settings("pub2")); // Explicitly granted
    }

    #[test]
    fn test_available_features() {
        setup_test_env();
        let access = FeatureAccess::from_env();
        
        let pub1_features = access.get_available_features("pub1");
        assert!(pub1_features.contains(&"power_user".to_string()));
        assert!(pub1_features.contains(&"perplexity".to_string()));
        assert!(pub1_features.contains(&"openai".to_string()));
        assert!(pub1_features.contains(&"settings_sync".to_string()));
        
        let pub2_features = access.get_available_features("pub2");
        assert!(!pub2_features.contains(&"power_user".to_string()));
        assert!(pub2_features.contains(&"perplexity".to_string()));
        assert!(pub2_features.contains(&"settings_sync".to_string()));
    }
}
----
config/feature_access_test.rs
use super::FeatureAccess;
use std::env;

fn setup_test_env() {
    // Clear any existing environment variables
    env::remove_var("APPROVED_PUBKEYS");
    env::remove_var("POWER_USER_PUBKEYS");
    env::remove_var("SETTINGS_SYNC_ENABLED_PUBKEYS");
    env::remove_var("PERPLEXITY_ENABLED_PUBKEYS");
    env::remove_var("OPENAI_ENABLED_PUBKEYS");
    env::remove_var("RAGFLOW_ENABLED_PUBKEYS");
}

fn setup_test_pubkeys() {
    env::set_var("APPROVED_PUBKEYS", "pub1,pub2,pub3");
    env::set_var("POWER_USER_PUBKEYS", "pub1");
    env::set_var("SETTINGS_SYNC_ENABLED_PUBKEYS", "pub2");
    env::set_var("PERPLEXITY_ENABLED_PUBKEYS", "pub1,pub2");
    env::set_var("OPENAI_ENABLED_PUBKEYS", "pub1,pub3");
    env::set_var("RAGFLOW_ENABLED_PUBKEYS", "pub1,pub2");
}

#[test]
fn test_environment_loading() {
    setup_test_env();
    setup_test_pubkeys();
    
    let access = FeatureAccess::from_env();
    
    assert_eq!(access.approved_pubkeys.len(), 3);
    assert_eq!(access.power_users.len(), 1);
    assert_eq!(access.settings_sync_enabled.len(), 1);
    assert_eq!(access.perplexity_enabled.len(), 2);
    assert_eq!(access.openai_enabled.len(), 2);
    assert_eq!(access.ragflow_enabled.len(), 2);
}

#[test]
fn test_empty_environment() {
    setup_test_env();
    
    let access = FeatureAccess::from_env();
    
    assert!(access.approved_pubkeys.is_empty());
    assert!(access.power_users.is_empty());
    assert!(access.settings_sync_enabled.is_empty());
    assert!(access.perplexity_enabled.is_empty());
    assert!(access.openai_enabled.is_empty());
    assert!(access.ragflow_enabled.is_empty());
}

#[test]
fn test_power_user_privileges() {
    setup_test_env();
    setup_test_pubkeys();
    
    let access = FeatureAccess::from_env();
    
    // Test power user (pub1)
    assert!(access.is_power_user("pub1"));
    assert!(access.can_sync_settings("pub1")); // Power users can always sync
    
    // Test regular user with sync access (pub2)
    assert!(!access.is_power_user("pub2"));
    assert!(access.can_sync_settings("pub2")); // Explicitly granted
    
    // Test regular user without sync access (pub3)
    assert!(!access.is_power_user("pub3"));
    assert!(!access.can_sync_settings("pub3"));
}

#[test]
fn test_feature_access_combinations() {
    setup_test_env();
    setup_test_pubkeys();
    
    let access = FeatureAccess::from_env();
    
    // Test power user (pub1) - should have access to everything
    assert!(access.has_perplexity_access("pub1"));
    assert!(access.has_openai_access("pub1"));
    assert!(access.has_ragflow_access("pub1"));
    
    // Test user with some features (pub2)
    assert!(access.has_perplexity_access("pub2"));
    assert!(!access.has_openai_access("pub2"));
    assert!(access.has_ragflow_access("pub2"));
    
    // Test user with limited access (pub3)
    assert!(!access.has_perplexity_access("pub3"));
    assert!(access.has_openai_access("pub3"));
    assert!(!access.has_ragflow_access("pub3"));
}

#[test]
fn test_feature_access_helper() {
    setup_test_env();
    setup_test_pubkeys();
    
    let access = FeatureAccess::from_env();
    
    // Test power user (pub1)
    assert!(access.has_feature_access("pub1", "perplexity"));
    assert!(access.has_feature_access("pub1", "openai"));
    assert!(access.has_feature_access("pub1", "ragflow"));
    assert!(access.has_feature_access("pub1", "settings_sync"));
    
    // Test regular users
    assert!(access.has_feature_access("pub2", "perplexity"));
    assert!(!access.has_feature_access("pub2", "openai"));
    assert!(access.has_feature_access("pub3", "openai"));
    assert!(!access.has_feature_access("pub3", "perplexity"));
}

#[test]
fn test_available_features() {
    setup_test_env();
    setup_test_pubkeys();
    
    let access = FeatureAccess::from_env();
    
    // Test power user (pub1)
    let pub1_features = access.get_available_features("pub1");
    assert!(pub1_features.contains(&"power_user".to_string()));
    assert!(pub1_features.contains(&"perplexity".to_string()));
    assert!(pub1_features.contains(&"openai".to_string()));
    assert!(pub1_features.contains(&"ragflow".to_string()));
    assert!(pub1_features.contains(&"settings_sync".to_string()));
    
    // Test user with some features (pub2)
    let pub2_features = access.get_available_features("pub2");
    assert!(!pub2_features.contains(&"power_user".to_string()));
    assert!(pub2_features.contains(&"perplexity".to_string()));
    assert!(!pub2_features.contains(&"openai".to_string()));
    assert!(pub2_features.contains(&"ragflow".to_string()));
    assert!(pub2_features.contains(&"settings_sync".to_string()));
    
    // Test user with limited access (pub3)
    let pub3_features = access.get_available_features("pub3");
    assert!(!pub3_features.contains(&"power_user".to_string()));
    assert!(!pub3_features.contains(&"perplexity".to_string()));
    assert!(pub3_features.contains(&"openai".to_string()));
    assert!(!pub3_features.contains(&"settings_sync".to_string()));
}

#[test]
fn test_invalid_pubkeys() {
    setup_test_env();
    setup_test_pubkeys();
    
    let access = FeatureAccess::from_env();
    let invalid_pubkey = "invalid_pubkey";
    
    assert!(!access.has_access(invalid_pubkey));
    assert!(!access.is_power_user(invalid_pubkey));
    assert!(!access.can_sync_settings(invalid_pubkey));
    assert!(!access.has_perplexity_access(invalid_pubkey));
    assert!(!access.has_openai_access(invalid_pubkey));
    assert!(!access.has_ragflow_access(invalid_pubkey));
    
    let features = access.get_available_features(invalid_pubkey);
    assert!(features.is_empty());
}
--END--

## Client Code (TypeScript)

The following text represents a project with code. The structure of the text consists of sections beginning with ----, followed by a single line containing the file path and file name, and then a variable number of lines containing the file contents. The text representing the project ends when the symbols --END-- are encountered. Any further text beyond --END-- is meant to be interpreted as instructions using the aforementioned project as context.
----
vite-start.js
#!/usr/bin/env node

// Override console methods to ensure all logs are visible
const originalConsole = {
  log: console.log,
  info: console.info,
  warn: console.warn,
  error: console.error,
  debug: console.debug
};

// Prefix all console output
function prefixLog(prefix, originalFn) {
  return function(...args) {
    if (typeof args[0] === 'string') {
      originalFn(prefix + args[0], ...args.slice(1));
    } else {
      originalFn(prefix, ...args);
    }
  };
}

// Apply overrides
console.log = prefixLog('[VITE] ', originalConsole.log);
console.info = prefixLog('[VITE] ', originalConsole.info);
console.warn = prefixLog('[VITE] ', originalConsole.warn);
console.error = prefixLog('[VITE] ', originalConsole.error);
console.debug = prefixLog('[VITE] ', originalConsole.debug);

// Run Vite
require('vite/cli');

----
tailwind.config.js
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        border: "hsl(var(--border))",
        input: "hsl(var(--input))",
        ring: "hsl(var(--ring))",
        background: "hsl(var(--background))",
        foreground: "hsl(var(--foreground))",
        primary: {
          DEFAULT: "hsl(var(--primary))",
          foreground: "hsl(var(--primary-foreground))",
        },
        secondary: {
          DEFAULT: "hsl(var(--secondary))",
          foreground: "hsl(var(--secondary-foreground))",
        },
        destructive: {
          DEFAULT: "hsl(var(--destructive))",
          foreground: "hsl(var(--destructive-foreground))",
        },
        muted: {
          DEFAULT: "hsl(var(--muted))",
          foreground: "hsl(var(--muted-foreground))",
        },
        accent: {
          DEFAULT: "hsl(var(--accent))",
          foreground: "hsl(var(--accent-foreground))",
        },
        card: {
          DEFAULT: "hsl(var(--card))",
          foreground: "hsl(var(--card-foreground))",
        },
        popover: {
          DEFAULT: "hsl(var(--popover))",
          foreground: "hsl(var(--popover-foreground))",
        },
      },
      borderRadius: {
        lg: "var(--radius)",
        md: "calc(var(--radius) - 2px)",
        sm: "calc(var(--radius) - 4px)",
      },
      animation: {
        "collapsible-down": "collapsible-down 0.2s ease-out",
        "collapsible-up": "collapsible-up 0.2s ease-out",
      },
      keyframes: {
        "collapsible-down": {
          "0%": { height: "0" },
          "100%": { height: "var(--radix-collapsible-content-height)" },
        },
        "collapsible-up": {
          "0%": { height: "var(--radix-collapsible-content-height)" },
          "100%": { height: "0" },
        },
      },
    },
  },
  plugins: [],
}
----
vite.config.ts

import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';
import path from 'path';

export default defineConfig({
  plugins: [react()],
  optimizeDeps: {
    include: ['@getalby/sdk']
  },
  build: {
    outDir: 'dist',
    emptyOutDir: true,
  },
  server: {
    host: '0.0.0.0',
    // Use the VITE_DEV_SERVER_PORT from env (should be 5173 now)
    port: parseInt(process.env.VITE_DEV_SERVER_PORT || '5173'),
    strictPort: true,
    hmr: {
      // HMR port is internal (24678), client connects via Nginx (3001)
      port: parseInt(process.env.VITE_HMR_PORT || '24678'),
      // Let client infer host from window.location
      protocol: 'ws',
      clientPort: 3001, // Client connects to Nginx port
      path: '/ws' // Explicitly set the path Nginx proxies
    },
    // Proxy is now handled by Nginx, remove proxy config from Vite
  },
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './src'),
    },
  },
});


----
index.html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>New Two-Pane App</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/app/main.tsx"></script>
  </body>
</html>
----
index.html.orig
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="icon" href="data:,">
    <link rel="stylesheet" href="/src/styles/globals.css">
    <title>LogseqSpringThing</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/app/main.tsx"></script>
  </body>
</html>

----
tsconfig.json
{
  "compilerOptions": {
    "baseUrl": ".",
    "paths": {
      "@/*": ["src/*"],
      "@/components/*": ["src/components/*"],
      "@/features/*": ["src/features/*"],
      "@/ui/*": ["src/ui/*"],
      "@/services/*": ["src/services/*"],
      "@/utils/*": ["src/utils/*"],
      "@/types/*": ["src/types/*"],
      "@/contexts/*": ["src/contexts/*"],
      "@/store/*": ["src/store/*"]
    },
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "lib": ["es2020", "dom", "dom.iterable"],
    "moduleResolution": "node",
    "skipLibCheck": true,
    "target": "es2020",
    "module": "es2020",
    "resolveJsonModule": true,
    "allowSyntheticDefaultImports": true,
    "typeRoots": ["./node_modules/@types"]
  },
  "include": ["src/**/*.ts", "src/**/*.tsx", "src/**/*.js", "src/**/*.jsx", "src/types/react-three-fiber.d.ts"],
  "exclude": ["node_modules"]
}

----
package.json.bak
{
  "name": "logseq-spring-thing-client",
  "private": true,
  "version": "0.1.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview",
    "lint": "eslint src --ext ts,tsx --report-unused-disable-directives"
  },
  "dependencies": {
    "@radix-ui/react-tooltip": "^1.0.7",
    "@radix-ui/react-dialog": "^1.0.5",
    "@radix-ui/react-dropdown-menu": "^2.0.6",
    "@radix-ui/react-slot": "^1.0.2",
    "@radix-ui/react-toast": "^1.1.5",
    "@react-three/fiber": "^8.15.19",
    "@react-three/drei": "^9.99.7",
    "three": "^0.162.0",
    "@types/three": "^0.162.0",
    "@types/node": "^20.17.25",
    "class-variance-authority": "^0.7.0",
    "framer-motion": "^11.18.2",
    "hls.js": "^1.5.20",
    "lucide-react": "^0.358.0",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-rnd": "^10.4.1"
  },
  "devDependencies": {
    "@types/react": "^18.2.0",
    "@types/react-dom": "^18.2.0",
    "@vitejs/plugin-react": "^4.2.0",
    "typescript": "^5.0.2",
    "vite": "^4.5.0"
  }
}

----
package.json
{
  "name": "logseq-spring-thing-client",
  "private": true,
  "version": "0.1.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview",
    "lint": "eslint src --ext ts,tsx --report-unused-disable-directives"
  },
  "dependencies": {
    "@getalby/sdk": "^4.1.1",
    "@radix-ui/react-collapsible": "^1.1.4",
    "@radix-ui/react-dialog": "^1.1.7",
    "@radix-ui/react-dropdown-menu": "^2.1.7",
    "@radix-ui/react-label": "^2.1.3",
    "@radix-ui/react-radio-group": "^1.1.3",
    "@radix-ui/react-select": "^2.2.4",
    "@radix-ui/react-slider": "^1.2.4",
    "@radix-ui/react-slot": "^1.2.0",
    "@radix-ui/react-switch": "^1.1.4",
    "@radix-ui/react-toast": "^1.2.7",
    "@radix-ui/react-tooltip": "^1.2.0",
    "@react-three/drei": "^9.80.0",
    "@react-three/fiber": "^8.15.0",
    "@react-three/postprocessing": "^2.15.0",
    "@react-three/xr": "^6.0.0",
    "@types/node": "^22.14.1",
    "@types/three": "^0.175.0",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "framer-motion": "^12.6.5",
    "hls.js": "^1.6.2",
    "immer": "^10.1.1",
    "lucide-react": "^0.487.0",
    "nostr-tools": "^2.12.0",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-markdown": "^10.1.0",
    "react-rnd": "^10.5.2",
    "react-syntax-highlighter": "^15.6.1",
    "remark-gfm": "^4.0.1",
    "tailwind-merge": "^3.2.0",
    "three": "^0.175.0",
    "uuid": "^11.1.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.0",
    "@types/react-dom": "^18.2.0",
    "@types/uuid": "^10.0.0",
    "@vitejs/plugin-react": "^4.3.4",
    "autoprefixer": "^10.4.21",
    "postcss": "^8.5.3",
    "tailwindcss": "^4.1.3",
    "typescript": "^5.8.3",
    "vite": "^6.2.6"
  }
}

----
components
import React from 'react'
import { Button } from '../../../components/ui/button'
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '../../../components/ui/card'
import useAuth from '../../lib/hooks/useAuth'

const NostrAuthSection = () => {
  const { authenticated, user, authError, login, logout } = useAuth()

  return (
    <Card>
      <CardHeader>
        <CardTitle>Nostr Authentication</CardTitle>
        <CardDescription>Authenticate with your Nostr key to unlock advanced features.</CardDescription>
      </CardHeader>
      <CardContent className="flex flex-col space-y-2">
        {authenticated ? (
          <>
            <div className="flex items-center space-x-2">
              <span>Logged in as:</span>
              <span>{user?.pubkey.slice(0, 8)}...{user?.pubkey.slice(-8)}</span>
            </div>
            <div>
              <span>Role:</span>
              <span>{user?.isPowerUser ? 'Power User' : 'Authenticated User'}</span>
            </div>
            <Button variant="destructive" onClick={logout}>
              Logout
            </Button>
          </>
        ) : (
          <>
            <Button onClick={login}>Login with Nostr</Button>
            {authError && <div className="text-red-500">{authError}</div>}
          </>
        )}
      </CardContent>
    </Card>
  )
}

export default NostrAuthSection
----
src/app/App.tsx
import { useEffect, Component, ReactNode, useCallback } from 'react'
import AppInitializer from './AppInitializer'
import { ThemeProvider } from '../ui/ThemeProvider'
import { ApplicationModeProvider } from '../contexts/ApplicationModeContext'
import { Toaster } from '../ui/Toaster'
// import { TooltipProvider } from '../ui/Tooltip'
import SafeXRProvider from '../features/xr/providers/SafeXRProvider'
// Removed GraphCanvas, ViewportContainer, MainLayout, DockingZone, ViewportControls, PanelProvider, Panel, SystemPanel, WindowSizeProvider
import { useSettingsStore } from '../store/settingsStore'
import { createLogger, createErrorMetadata } from '../utils/logger'
// Removed SimpleThreeWindowPage import as it's not used
// Removed SimpleThreeWindowPage import
// import SimpleGraphPage from '../pages/AppPage' // Corrected path: SimpleGraphPage is exported from AppPage.tsx
import TwoPaneLayout from './TwoPaneLayout'; // Added import for TwoPaneLayout

import '../styles/tokens.css'
// Removed layout.css import
const logger = createLogger('App')

// Error boundary component to catch rendering errors
interface ErrorBoundaryProps {
  children: ReactNode;
  fallback?: ReactNode;
}

class ErrorBoundary extends Component<ErrorBoundaryProps, { hasError: boolean; error: Error | null; errorInfo: any }> {
  state = { hasError: false, error: null, errorInfo: null };

  static getDerivedStateFromError(error: any) {
    return { hasError: true, error };
  }

  componentDidCatch(error: any, errorInfo: any) {
    logger.error('React error boundary caught error:', {
      ...createErrorMetadata(error),
      component: errorInfo?.componentStack
        ? errorInfo.componentStack.split('\n')[1]?.trim()
        : 'Unknown component'
    });
    this.setState({ errorInfo });
  }

  render() {
    if (this.state.hasError) {
      return this.props.fallback || (
        <div className="p-4 bg-destructive text-destructive-foreground rounded-md">
          <h2 className="text-xl font-bold mb-2">Something went wrong</h2>
          <p className="mb-4">The application encountered an error. Try refreshing the page.</p>
          {process.env.NODE_ENV === 'development' && (
            <pre className="bg-muted p-2 rounded text-sm overflow-auto">
              {this.state.error
                ? (this.state.error.message || String(this.state.error))
                : 'No error details available'}
            </pre>
          )}
        </div>
      );
    }
    return this.props.children;
  }
}

function App() {
  // Removed isLoading, panel visibility states, isSimpleMode state
  // Select the primitive value directly to avoid unnecessary re-renders
  const initialized = useSettingsStore(state => state.initialized)

  // Simplified useEffect, only checking initialization
  useEffect(() => {
    // No need to set isLoading here if AppInitializer handles it or SimpleGraphPage has its own loading state
  }, [initialized])

  // Wrap handleInitialized in useCallback to stabilize its reference
  const handleInitialized = useCallback(() => {
    const settings = useSettingsStore.getState().settings;
    const debugEnabled = settings?.system?.debug?.enabled === true;
    if (debugEnabled) {
      logger.debug('Application initialized');
    }
    // No need for setIsLoading(false) here if SimpleGraphPage handles its own loading
  }, []) // Dependency array is empty as it only uses getState

  // Removed viewport control handlers (handleResetCamera, etc.) as they belong in SimpleGraphPage or its children
  // Removed panel toggle handlers (handleToggleLeftPanel, etc.)
  // Removed handleViewportResize callback

  // No longer need the isSimpleMode check, always render SimpleGraphPage

  return (
    <ThemeProvider defaultTheme="dark">
      {/* Removed WindowSizeProvider */}
      <ErrorBoundary>
        <ApplicationModeProvider>
          {/* Removed PanelProvider */}
          <SafeXRProvider>
            {/* Render TwoPaneLayout */}
            <TwoPaneLayout />
            <AppInitializer onInitialized={handleInitialized} />
            {/* Toaster remains at the top level */}
            <Toaster />
          </SafeXRProvider>
        </ApplicationModeProvider>
      </ErrorBoundary>
    </ThemeProvider>
  )
}

export default App

----
src/app/AppInitializer.tsx
import React, { useEffect } from 'react';
import { createLogger, createErrorMetadata } from '../utils/logger';
import { debugState } from '../utils/debugState';
import { useSettingsStore } from '../store/settingsStore';
import WebSocketService from '../services/WebSocketService';
import { graphDataManager } from '../features/graph/managers/graphDataManager';
import { initializeAuth } from '../features/auth/initAuth';

// Load and initialize all services
const loadServices = async (): Promise<void> => {
  if (debugState.isEnabled()) {
    logger.info('Initializing services...');
  }

  try {
    // Initialize auth system
    await initializeAuth();

    if (debugState.isEnabled()) {
      logger.info('Auth system initialized');
    }
  } catch (error) {
    logger.error('Error initializing services:', createErrorMetadata(error));
  }
}

const logger = createLogger('AppInitializer');

interface AppInitializerProps {
  onInitialized: () => void;
}

const AppInitializer: React.FC<AppInitializerProps> = ({ onInitialized }) => {
  const { settings, initialize } = useSettingsStore();

  useEffect(() => {
    const initApp = async () => {
      // Load services first
      await loadServices();

      if (debugState.isEnabled()) {
        logger.info('Starting application initialization...');
        }

        try {
          // Initialize settings
          const settings = await initialize();

          // Apply debug settings safely
          if (settings.system?.debug) {
            try {
              const debugSettings = settings.system.debug;
              debugState.enableDebug(debugSettings.enabled);
              if (debugSettings.enabled) {
                debugState.enableDataDebug(debugSettings.enableDataDebug);
                debugState.enablePerformanceDebug(debugSettings.enablePerformanceDebug);
              }
            } catch (debugError) {
              logger.warn('Error applying debug settings:', createErrorMetadata(debugError));
            }
          }

          // Try to initialize WebSocket
          if (typeof WebSocketService !== 'undefined' && typeof graphDataManager !== 'undefined') {
            try {
              // Initialize WebSocket
              await initializeWebSocket(settings);
              // logger.info('WebSocket initialization deliberately disabled - using REST API only.'); // Commented out the disabling message
            } catch (wsError) {
              logger.error('WebSocket initialization failed, continuing with UI only:', createErrorMetadata(wsError));
              // We'll proceed without WebSocket connectivity
            }
          } else {
            logger.warn('WebSocket services not available, continuing with UI only');
          }

          // Fetch initial graph data AFTER settings and BEFORE signaling completion
          try {
            logger.info('Fetching initial graph data via REST API');
            await graphDataManager.fetchInitialData();
            if (debugState.isDataDebugEnabled()) {
              logger.debug('Initial graph data fetched successfully');
            }
          } catch (fetchError) {
            logger.error('Failed to fetch initial graph data:', createErrorMetadata(fetchError));
            // Initialize with empty data as fallback
            graphDataManager.setGraphData({ nodes: [], edges: [] });
          }

          if (debugState.isEnabled()) {
            logger.info('Application initialized successfully');
          }

          // Signal that initialization is complete
          onInitialized();

      } catch (error) {
          logger.error('Failed to initialize application components:', createErrorMetadata(error));
          // Even if initialization fails, try to signal completion to show UI
          onInitialized();
      }
    };

    initApp();
  }, [initialize, onInitialized]);

  // Initialize WebSocket and set up event handlers - now safer with more error handling
  const initializeWebSocket = async (settings: any): Promise<void> => {
    try {
      const websocketService = WebSocketService.getInstance();

      // Handle binary position updates from WebSocket
      websocketService.onBinaryMessage((data) => {
        if (data instanceof ArrayBuffer) {
          try {
            // Log receipt of binary data only if data debug is enabled
            if (debugState.isDataDebugEnabled()) {
              logger.info(`Received binary data from WebSocket: ${data.byteLength} bytes`);
            }

            // Process binary position update through graph data manager
            graphDataManager.updateNodePositions(data);
            if (debugState.isDataDebugEnabled()) {
              logger.debug(`Processed binary position update: ${data.byteLength} bytes`);
            }
          } catch (error) {
            logger.error('Failed to process binary position update:', createErrorMetadata(error));

            // Add diagnostic info in debug mode
            if (debugState.isEnabled()) {
              // Display basic info about the data
              logger.debug(`Binary data size: ${data.byteLength} bytes`);

              // Display the first few bytes for debugging - helps detect compression headers
              try {
                const view = new DataView(data);
                const hexBytes = [];
                const maxBytesToShow = Math.min(16, data.byteLength);

                for (let i = 0; i < maxBytesToShow; i++) {
                  hexBytes.push(view.getUint8(i).toString(16).padStart(2, '0'));
                }

                logger.debug(`First ${maxBytesToShow} bytes: ${hexBytes.join(' ')}`);

                // Check if data might be compressed (zlib headers)
                if (data.byteLength >= 2) {
                  const firstByte = view.getUint8(0);
                  const secondByte = view.getUint8(1);
                  if (firstByte === 0x78 && (secondByte === 0x01 || secondByte === 0x9C || secondByte === 0xDA)) {
                    logger.debug('Data appears to be zlib compressed (has zlib header)');
                  }
                }
              } catch (e) {
                logger.debug('Could not display binary data preview');
              }

              // Check if the data length is a multiple of expected formats
              const nodeSize = 26; // 2 bytes (ID) + 12 bytes (position) + 12 bytes (velocity)
              if (data.byteLength % nodeSize !== 0) {
                logger.debug(`Invalid data length: not a multiple of ${nodeSize} bytes per node (remainder: ${data.byteLength % nodeSize})`);
              }
            }
          }
        }
      });

      // Set up connection status handler
      websocketService.onConnectionStatusChange((connected) => {
        if (debugState.isEnabled()) {
          logger.info(`WebSocket connection status changed: ${connected}`);
        }

        // Check if websocket is both connected AND ready (received 'connection_established' message)
        if (connected) {
          try {
            if (websocketService.isReady()) {
              // WebSocket is fully ready, now it's safe to enable binary updates
              logger.info('WebSocket is connected and fully established - enabling binary updates');
              graphDataManager.setBinaryUpdatesEnabled(true);

              // Subscribe to position updates
              logger.info('Sending subscribe_position_updates message to server');
              websocketService.sendMessage('subscribe_position_updates', {
                binary: true,
                interval: settings?.system?.websocket?.updateRate || 60
              });

              if (debugState.isDataDebugEnabled()) {
                logger.debug('Binary updates enabled and subscribed to position updates');
              }
            } else {
              logger.info('WebSocket connected but not fully established yet - waiting for readiness');

              // We'll let graphDataManager handle the binary updates enablement
              // through its retry mechanism that now checks for websocket readiness
              graphDataManager.enableBinaryUpdates();

              // Set up a listener for the 'connection_established' message
              const unsubscribe = websocketService.onMessage((message) => {
                if (message.type === 'connection_established') {
                  // Now that we're fully connected, subscribe to position updates
                  logger.info('Connection established message received, sending subscribe_position_updates');
                  websocketService.sendMessage('subscribe_position_updates', {
                    binary: true,
                    interval: settings?.system?.websocket?.updateRate || 60
                  });
                  unsubscribe(); // Remove this one-time listener

                  if (debugState.isDataDebugEnabled()) {
                    logger.debug('Connection established, subscribed to position updates');
                  }
                }
              });
            }
          } catch (connectionError) {
            logger.error('Error during WebSocket status change handling:', createErrorMetadata(connectionError));
          }
        }
      });

      // Configure GraphDataManager with WebSocket service (adapter pattern)
      if (websocketService) {
        const wsAdapter = {
          send: (data: ArrayBuffer) => {
            websocketService.sendRawBinaryData(data);
          },
          isReady: () => websocketService.isReady()
        };
        graphDataManager.setWebSocketService(wsAdapter);
      }

      try {
        // Connect WebSocket
        await websocketService.connect();
      } catch (connectError) {
        logger.error('Failed to connect to WebSocket:', createErrorMetadata(connectError));
      }
    } catch (error) {
      logger.error('Failed during WebSocket/data initialization:', createErrorMetadata(error));
      throw error;
    }
  };

  return null; // This component doesn't render anything directly
};

export default AppInitializer;

----
src/app/TwoPaneLayout.tsx
import React, { useState, useCallback, CSSProperties } from 'react';
import GraphViewport from '../features/graph/components/GraphViewport';
import RightPaneControlPanel from './components/RightPaneControlPanel';
import MarkdownDisplayPanel from './components/MarkdownDisplayPanel';
import NarrativeGoldminePanel from './components/NarrativeGoldminePanel';

const TwoPaneLayout: React.FC = () => {
  const [leftPaneWidth, setLeftPaneWidth] = useState<number>(300); // Initial width of the left pane
  const [isDraggingVertical, setIsDraggingVertical] = useState<boolean>(false);
  const [isRightPaneDocked, setIsRightPaneDocked] = useState<boolean>(false);

  // State for TOP horizontal splitter in right pane (dividing Control Panel and the rest)
  const [rightPaneTopHeight, setRightPaneTopHeight] = useState<number>(300); // Adjusted initial height
  const [isDraggingHorizontalTop, setIsDraggingHorizontalTop] = useState<boolean>(false); // Renamed

  // State for the new BOTTOM horizontal splitter within the lower part of the right pane
  const [bottomRightUpperHeight, setBottomRightUpperHeight] = useState<number>(200); // Initial height for Markdown panel
  const [isDraggingHorizontalBottom, setIsDraggingHorizontalBottom] = useState<boolean>(false);


  const handleVerticalMouseDown = useCallback((e: React.MouseEvent) => {
    setIsDraggingVertical(true);
    // Prevent text selection while dragging
    e.preventDefault();
  }, []);

  const handleVerticalMouseUp = useCallback(() => {
    setIsDraggingVertical(false);
  }, []);

  const handleVerticalMouseMove = useCallback(
    (e: MouseEvent) => {
      if (isDraggingVertical && !isRightPaneDocked) {
        const newWidth = e.clientX;
        if (newWidth > 50 && newWidth < window.innerWidth - 50) {
          setLeftPaneWidth(newWidth);
        }
      }
    },
    [isDraggingVertical, isRightPaneDocked]
  );

  // Event handlers for TOP horizontal splitter
  const handleHorizontalTopMouseDown = useCallback((e: React.MouseEvent) => {
    setIsDraggingHorizontalTop(true);
    e.preventDefault();
  }, []);

  const handleHorizontalTopMouseUp = useCallback(() => {
    setIsDraggingHorizontalTop(false);
  }, []);

  const handleHorizontalTopMouseMove = useCallback(
    (e: MouseEvent) => {
      if (isDraggingHorizontalTop) {
        const rightPaneContainer = document.getElementById('right-pane-container');
        if (rightPaneContainer) {
            const rect = rightPaneContainer.getBoundingClientRect();
            const relativeNewHeight = e.clientY - rect.top;
            if (relativeNewHeight > 50 && relativeNewHeight < rect.height - 110) { // Min 50 for top, 110 for bottom container (50+10+50)
                 setRightPaneTopHeight(relativeNewHeight);
            }
        }
      }
    },
    [isDraggingHorizontalTop]
  );

  // Event handlers for BOTTOM horizontal splitter
  const handleHorizontalBottomMouseDown = useCallback((e: React.MouseEvent) => {
    setIsDraggingHorizontalBottom(true);
    e.preventDefault();
  }, []);

  const handleHorizontalBottomMouseUp = useCallback(() => {
    setIsDraggingHorizontalBottom(false);
  }, []);

  const handleHorizontalBottomMouseMove = useCallback(
    (e: MouseEvent) => {
      if (isDraggingHorizontalBottom) {
        const bottomRightContainer = document.getElementById('right-pane-bottom-container');
        if (bottomRightContainer) {
            const rect = bottomRightContainer.getBoundingClientRect();
            const relativeNewHeight = e.clientY - rect.top;
            if (relativeNewHeight > 50 && relativeNewHeight < rect.height - 60) { // Min 50 for upper, 50 for lower + 10 for divider
                 setBottomRightUpperHeight(relativeNewHeight);
            }
        }
      }
    },
    [isDraggingHorizontalBottom]
  );

  const toggleRightPaneDock = () => {
    setIsRightPaneDocked(!isRightPaneDocked);
    if (!isRightPaneDocked) {
      // Optionally, reset left pane width or set to a specific value when docking
    } else {
      // Optionally, restore left pane width or set to a specific value when undocking
      // For now, it will just expand based on leftPaneWidth
    }
  };

  // Add and remove mouse move/up listeners on the window
  React.useEffect(() => {
    const handleGlobalMouseMove = (e: MouseEvent) => {
      handleVerticalMouseMove(e);
      handleHorizontalTopMouseMove(e);
      handleHorizontalBottomMouseMove(e);
    };

    const handleGlobalMouseUp = () => {
      handleVerticalMouseUp();
      handleHorizontalTopMouseUp();
      handleHorizontalBottomMouseUp();
    };

    if (isDraggingVertical || isDraggingHorizontalTop || isDraggingHorizontalBottom) {
      window.addEventListener('mousemove', handleGlobalMouseMove);
      window.addEventListener('mouseup', handleGlobalMouseUp);
    } else {
      window.removeEventListener('mousemove', handleGlobalMouseMove);
      window.removeEventListener('mouseup', handleGlobalMouseUp);
    }
    return () => {
      window.removeEventListener('mousemove', handleGlobalMouseMove);
      window.removeEventListener('mouseup', handleGlobalMouseUp);
    };
  }, [
      isDraggingVertical, isDraggingHorizontalTop, isDraggingHorizontalBottom,
      handleVerticalMouseMove, handleHorizontalTopMouseMove, handleHorizontalBottomMouseMove,
      handleVerticalMouseUp, handleHorizontalTopMouseUp, handleHorizontalBottomMouseUp
    ]);

  const containerStyle: CSSProperties = {
    display: 'flex',
    height: '100vh', // Full viewport height
    overflow: 'hidden', // Prevent scrollbars on the container itself
  };

  const leftPaneStyle: CSSProperties = {
    width: isRightPaneDocked ? '100%' : `${leftPaneWidth}px`,
    minWidth: '50px', // Minimum width for the left pane
    // backgroundColor: '#f0f0f0', // Removed, canvas has its own
    // padding: '20px', // Removed, GraphViewport handles its own layout
    // overflow: 'auto', // Removed, GraphViewport handles its own overflow/scroll
    height: '100%', // Ensure left pane takes full height for the canvas
    position: 'relative', // For potential absolute positioned elements within GraphViewport
    transition: 'width 0.3s ease', // Smooth transition for docking
  };

  const dividerStyle: CSSProperties = {
    width: '10px',
    cursor: isRightPaneDocked ? 'default' : 'ew-resize', // Change cursor when docked
    backgroundColor: '#cccccc',
    display: isRightPaneDocked ? 'none' : 'flex', // Hide divider when docked
    alignItems: 'center',
    justifyContent: 'center',
    userSelect: 'none',
  };

  const rightPaneContainerStyle: CSSProperties = { // Renamed for clarity
    flexGrow: 1,
    display: isRightPaneDocked ? 'none' : 'flex', // Use flex column for top/bottom sections
    flexDirection: 'column',
    overflow: 'hidden', // Containing div handles overflow
    height: '100vh', // Ensure it takes full viewport height
  };

  const rightPaneTopStyle: CSSProperties = {
    height: `${rightPaneTopHeight}px`,
    minHeight: '50px', // Min height for top section
    // backgroundColor: '#e0e0e0', // Removed, panel has its own
    // padding: '10px', // Removed, panel has its own
    overflowY: 'hidden', // Panel itself will scroll its content
    position: 'relative',
  };

  const horizontalTopDividerStyle: CSSProperties = { // Renamed
    height: '10px',
    cursor: 'ns-resize',
    backgroundColor: '#b0b0b0',
    display: 'flex',
    alignItems: 'center',
    justifyContent: 'center',
    userSelect: 'none',
    borderTop: '1px solid #999999',
    borderBottom: '1px solid #999999',
    flexShrink: 0,
  };

  const rightPaneBottomContainerStyle: CSSProperties = { // New container for the split
    flexGrow: 1,
    minHeight: '110px', // 50 (upper) + 10 (divider) + 50 (lower)
    display: 'flex',
    flexDirection: 'column',
    overflow: 'hidden',
    backgroundColor: '#d0d0d0', // Base for this area
  };

  const bottomRightUpperStyle: CSSProperties = {
    height: `${bottomRightUpperHeight}px`,
    minHeight: '50px',
    // backgroundColor: '#d8d8d8', // Panel has its own bg
    padding: '0px', // Panel has its own padding
    overflowY: 'hidden', // Panel handles scroll
    position: 'relative',
  };

  const horizontalBottomDividerStyle: CSSProperties = { // New divider
    height: '10px',
    cursor: 'ns-resize',
    backgroundColor: '#a0a0a0',
    display: 'flex',
    alignItems: 'center',
    justifyContent: 'center',
    userSelect: 'none',
    borderTop: '1px solid #888888',
    borderBottom: '1px solid #888888',
    flexShrink: 0,
  };

  const bottomRightLowerStyle: CSSProperties = {
    flexGrow: 1,
    minHeight: '50px',
    // backgroundColor: '#c8c8c8', // Panel has its own bg
    padding: '0px', // Panel has its own padding
    overflowY: 'hidden', // Panel handles scroll
    position: 'relative',
  };

  const dockButtonStyle: CSSProperties = {
    position: 'absolute',
    top: '10px',
    right: isRightPaneDocked ? '10px' : `${10 + (isRightPaneDocked ? 0 : 0)}px`, // Adjust button position
    zIndex: 100,
    padding: '5px 10px',
    cursor: 'pointer',
  };


  return (
    <div style={containerStyle}>
      <div style={leftPaneStyle}>
        <GraphViewport />
      </div>
      <div
        style={dividerStyle}
        onMouseDown={!isRightPaneDocked ? handleVerticalMouseDown : undefined}
        title={isRightPaneDocked ? "" : "Drag to resize"}
      >
        ||
      </div>
      <div id="right-pane-container" style={rightPaneContainerStyle}>
        {!isRightPaneDocked && (
          <>
            <div style={rightPaneTopStyle}>
              <RightPaneControlPanel />
            </div>
            <div
              style={horizontalTopDividerStyle}
              onMouseDown={handleHorizontalTopMouseDown}
              title="Drag to resize Control Panel / Lower Area"
            >
              ══
            </div>
            <div id="right-pane-bottom-container" style={rightPaneBottomContainerStyle}>
              <div style={bottomRightUpperStyle}>
                <MarkdownDisplayPanel />
              </div>
              <div
                style={horizontalBottomDividerStyle}
                onMouseDown={handleHorizontalBottomMouseDown}
                title="Drag to resize Markdown / Narrative Goldmine"
              >
                ══
              </div>
              <div style={bottomRightLowerStyle}>
                <NarrativeGoldminePanel />
              </div>
            </div>
          </>
        )}
      </div>
      <button onClick={toggleRightPaneDock} style={dockButtonStyle} title={isRightPaneDocked ? "Expand Right Pane" : "Collapse Right Pane"}>
        {isRightPaneDocked ? '>' : '<'}
      </button>
    </div>
  );
};

export default TwoPaneLayout;
----
src/app/main.tsx
import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App';
import '../styles/tokens.css'; // Use relative path
// Removed import for layout.css as the file was deleted
import '../styles/globals.css'; // Use relative path

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>
);

----
src/app/components/NarrativeGoldminePanel.tsx
import React, { CSSProperties } from 'react';

const NarrativeGoldminePanel: React.FC = () => {
  const panelStyle: CSSProperties = {
    width: '100%',
    height: '100%',
    overflow: 'hidden', // Iframe will handle its own scrolling
    backgroundColor: '#000', // Optional: background while iframe loads
  };

  const iframeStyle: CSSProperties = {
    width: '100%',
    height: '100%',
    border: 'none', // Remove default iframe border
  };

  return (
    <div style={panelStyle}>
      <iframe
        src="https://narrativegoldmine.com"
        style={iframeStyle}
        title="Narrative Goldmine"
        sandbox="allow-scripts allow-same-origin allow-popups allow-forms" // Standard sandbox attributes
        loading="lazy"
        referrerPolicy="no-referrer"
      ></iframe>
    </div>
  );
};

export default NarrativeGoldminePanel;
----
src/app/components/RightPaneControlPanel.tsx
import React, { CSSProperties, useState, createContext, useContext } from 'react';
import { settingsUIDefinition, UICategoryDefinition } from '../../features/settings/config/settingsUIDefinition';
import { SettingsSection } from '../../features/settings/components/SettingsSection';
import { Collapsible, CollapsibleContent, CollapsibleTrigger } from '@/ui/Collapsible';
import { Button } from '@/ui/Button';
import { Eye, Settings as SettingsIcon, Smartphone, Brain, ChevronDown, ChevronUp, ShieldCheck } from 'lucide-react'; // Added ShieldCheck for Auth
import NostrAuthSection from '../../features/auth/components/NostrAuthSection';


// Simplified Context for advancedMode, similar to control-panel-context.tsx
interface ControlPanelContextType {
  advancedMode: boolean;
  toggleAdvancedMode: () => void;
  // Add other context values if SettingsSection depends on them, e.g., detachedSections
}
const ControlPanelContext = createContext<ControlPanelContextType | undefined>(undefined);

export const useControlPanelContext = () => {
  const context = useContext(ControlPanelContext);
  if (!context) {
    throw new Error('useControlPanelContext must be used within a ControlPanelProvider');
  }
  return context;
};

// Map icon names from settingsUIDefinition to Lucide components
const iconMap: { [key: string]: React.ElementType } = {
  Eye: Eye,
  Settings: SettingsIcon,
  Smartphone: Smartphone,
  Brain: Brain,
  ShieldCheck: ShieldCheck, // Added for Auth
  // Add other icons as needed
};


const RightPaneControlPanel: React.FC = () => {
  const [advancedMode, setAdvancedMode] = useState(false);
  const [openCategories, setOpenCategories] = useState<Record<string, boolean>>({
    visualisation: true, // Default Visualisation to open
  });

  const toggleAdvancedMode = () => setAdvancedMode(prev => !prev);

  const toggleCategory = (categoryKey: string) => {
    setOpenCategories(prev => ({ ...prev, [categoryKey]: !prev[categoryKey] }));
  };

  const panelStyle: CSSProperties = {
    width: '100%',
    height: '100%',
    display: 'flex',
    flexDirection: 'column',
    overflowY: 'auto',
    padding: '0px', // Padding will be handled by inner elements or sections
    boxSizing: 'border-box',
    backgroundColor: '#ffffff', // Main panel background
  };

  const categoryHeaderStyle: CSSProperties = {
    padding: '8px 12px',
    borderBottom: '1px solid #e5e7eb', // tailwind gray-200
    cursor: 'pointer',
    display: 'flex',
    justifyContent: 'space-between',
    alignItems: 'center',
    backgroundColor: '#f9fafb', // tailwind gray-50
  };

  const categoryTitleStyle: CSSProperties = {
    fontSize: '1em',
    fontWeight: '600', // semibold
    color: '#1f2937', // tailwind gray-800
    display: 'flex',
    alignItems: 'center',
    gap: '8px',
  };

  const categoryContentStyle: CSSProperties = {
    padding: '12px', // Padding for content within a category
    borderBottom: '1px solid #e5e7eb',
  };
  
  const authSectionStyle: CSSProperties = {
    padding: '12px',
    borderBottom: '1px solid #e5e7eb',
  };


  return (
    <ControlPanelContext.Provider value={{ advancedMode, toggleAdvancedMode }}>
      <div style={panelStyle} className="custom-scrollbar">
        {/* Auth Section - Always visible at the top */}
        <div style={authSectionStyle}>
            <NostrAuthSection />
        </div>

        {/* Advanced Mode Toggle - Placed strategically, e.g., at the top or bottom */}
        <div style={{ padding: '12px', borderBottom: '1px solid #e5e7eb', backgroundColor: '#f9fafb' }}>
            <label htmlFor="advancedModeToggle" className="flex items-center cursor-pointer">
                <input
                    type="checkbox"
                    id="advancedModeToggle"
                    checked={advancedMode}
                    onChange={toggleAdvancedMode}
                    className="mr-2 h-4 w-4 rounded border-gray-300 text-indigo-600 focus:ring-indigo-500"
                />
                <span className="text-sm font-medium text-gray-700">Show Advanced Settings</span>
            </label>
        </div>

        {Object.entries(settingsUIDefinition).map(([categoryKey, categoryDef]) => {
          const IconComponent = categoryDef.icon ? iconMap[categoryDef.icon] : SettingsIcon; // Default icon
          const isCategoryOpen = openCategories[categoryKey] ?? false;

          return (
            <Collapsible key={categoryKey} open={isCategoryOpen} onOpenChange={() => toggleCategory(categoryKey)} className="w-full">
              <CollapsibleTrigger asChild>
                <div style={categoryHeaderStyle} role="button" tabIndex={0} aria-expanded={isCategoryOpen}>
                  <span style={categoryTitleStyle}>
                    {IconComponent && <IconComponent size={16} />}
                    {categoryDef.label}
                  </span>
                  {isCategoryOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
                </div>
              </CollapsibleTrigger>
              <CollapsibleContent>
                <div style={categoryContentStyle}>
                  {Object.entries(categoryDef.subsections).map(([subsectionKey, subsectionDef]) => (
                    <SettingsSection
                      key={subsectionKey}
                      id={`settings-${categoryKey}-${subsectionKey}`}
                      title={subsectionDef.label}
                      subsectionSettings={subsectionDef.settings}
                    />
                  ))}
                </div>
              </CollapsibleContent>
            </Collapsible>
          );
        })}
      </div>
    </ControlPanelContext.Provider>
  );
};

export default RightPaneControlPanel;
----
src/app/components/MarkdownDisplayPanel.tsx
import React, { CSSProperties } from 'react';
import MarkdownRenderer from '../../ui/markdown/MarkdownRenderer'; // Adjusted path

const sampleMarkdownContent = `
# Markdown Display Panel

This panel uses the existing \`MarkdownRenderer\` component.

## Features
*   Renders Markdown text.
*   Supports GitHub Flavored Markdown (GFM).
*   Includes syntax highlighting for code blocks.

\`\`\`javascript
// Example JavaScript code
function helloWorld() {
  console.log("Hello, from the Markdown Panel!");
}
helloWorld();
\`\`\`

### More Content
You can add more Markdown content here to test scrolling and layout.
This panel is designed to fit within one of the resizable sub-panes.

${'- List item to add more content for scrolling.\n'.repeat(15)}

End of sample content.
`;

const MarkdownDisplayPanel: React.FC = () => {
  const panelStyle: CSSProperties = {
    width: '100%',
    height: '100%',
    overflowY: 'auto', // Enable vertical scroll for overflow within this panel
    padding: '10px', // Inner padding for the content area
    boxSizing: 'border-box',
    backgroundColor: '#fff', // White background for the markdown content area
  };

  return (
    <div style={panelStyle} className="custom-scrollbar">
      <MarkdownRenderer content={sampleMarkdownContent} className="" />
    </div>
  );
};

export default MarkdownDisplayPanel;
----
src/utils/logger.ts
/**
 * Simple logger utility with color-coded console output and log storage
 */

type LogLevel = 'debug' | 'info' | 'warn' | 'error';

interface LogEntry {
  timestamp: string;
  level: LogLevel;
  namespace: string;
  message: string;
  args: any[];
}

interface LoggerOptions {
  disabled?: boolean;
  level?: LogLevel;
  maxLogEntries?: number; // Optional limit for stored logs
}

const LOG_LEVEL_PRIORITY: Record<LogLevel, number> = {
  debug: 0,
  info: 1,
  warn: 2,
  error: 3,
};

const LOG_COLORS = {
  debug: '#8c8c8c', // gray
  info: '#4c9aff',  // blue
  warn: '#ffab00',  // orange
  error: '#ff5630', // red
};

// Central log storage (can be enhanced later if needed)
const logStorage: LogEntry[] = [];
const DEFAULT_MAX_LOG_ENTRIES = 1000;

export function createLogger(namespace: string, options: LoggerOptions = {}) {
  const { disabled = false, level = 'info', maxLogEntries = DEFAULT_MAX_LOG_ENTRIES } = options;
  const levelPriority = LOG_LEVEL_PRIORITY[level];

  function shouldLog(msgLevel: LogLevel): boolean {
    if (disabled) return false;
    return LOG_LEVEL_PRIORITY[msgLevel] >= levelPriority;
  }

  function formatMessage(message: any): string {
    if (typeof message === 'string') return message;
    if (message instanceof Error) {
      return message.stack ? message.stack : message.message;
    }
    try {
      // Attempt to stringify complex objects, handle potential circular references
      return JSON.stringify(message, (key, value) => {
        if (typeof value === 'object' && value !== null) {
          // Basic circular reference check (can be improved)
          if (value === message && key !== '') return '[Circular Reference]';
        }
        return value;
      }, 2);
    } catch (e) {
      return String(message);
    }
  }

  // Function to format arguments, handling Errors specifically
  function formatArgs(args: any[]): any[] {
      return args.map(arg => {
        if (arg instanceof Error) {
          return { message: arg.message, name: arg.name, stack: arg.stack }; // Serialize error
        }
        // Add more type handling if needed (e.g., Functions, DOM elements)
        return arg;
      });
  }


  function createLogMethod(logLevel: LogLevel) {
    return function(message: any, ...args: any[]) {
      if (!shouldLog(logLevel)) return;

      const color = LOG_COLORS[logLevel];
      const now = new Date();
      const timestamp = now.toISOString();
      const consoleTimestamp = now.toISOString().split('T')[1].slice(0, -1);
      const prefix = `%c[${consoleTimestamp}] [${namespace}]`;

      const formattedArgs = formatArgs(args);
      const formattedMessage = formatMessage(message);

      // Store the log entry
      logStorage.push({
        timestamp,
        level: logLevel,
        namespace,
        message: formattedMessage, // Store the formatted message
        args: formattedArgs, // Store formatted args
      });

      // Trim log storage if it exceeds the limit
      if (logStorage.length > maxLogEntries) {
        logStorage.shift(); // Remove the oldest entry
      }

      // Output to console
      console[logLevel === 'debug' ? 'log' : logLevel](
        `${prefix} ${formattedMessage}`,
        `color: ${color}; font-weight: bold;`,
        ...args // Log original args to console for better interactivity
      );
    };
  }

  // Function to retrieve stored logs
  function getLogs(): LogEntry[] {
    // Return a copy to prevent external modification
    return [...logStorage];
  }

  return {
    debug: createLogMethod('debug'),
    info: createLogMethod('info'),
    warn: createLogMethod('warn'),
    error: createLogMethod('error'),
    getLogs, // Expose the getLogs method
  };
}

export function createErrorMetadata(error: unknown): Record<string, any> {
  if (error instanceof Error) {
    return {
      message: error.message,
      name: error.name,
      stack: error.stack,
      // Potentially add other known properties of custom errors if any
    };
  }
  // If it's not an Error instance, try to get more details
  if (typeof error === 'object' && error !== null) {
    // Attempt to serialize the object.
    try {
      // Using Object.getOwnPropertyNames to include non-enumerable properties if error is an object
      const errorKeys = Object.getOwnPropertyNames(error);
      const serializableError = errorKeys.reduce((acc, key) => {
        acc[key] = (error as any)[key];
        return acc;
      }, {} as Record<string, any>);

      const serializedErrorString = JSON.stringify(serializableError, null, 2); // Pretty print
      return {
        message: `Non-Error object encountered. Details: ${serializedErrorString.substring(0, 500)}${serializedErrorString.length > 500 ? '...' : ''}`, // Truncate for sanity
        originalErrorType: 'Object', // Indicate it was an object
        // Consider if including the full 'error' object is too verbose or has circular refs
        // For now, relying on the stringified version.
      };
    } catch (e) {
      // JSON.stringify failed (e.g., circular references not caught by custom serializer)
      return {
        message: `Non-Error object (serialization failed): ${String(error)}`,
        originalErrorType: typeof error,
      };
    }
  }
  // Fallback for primitives or other types
  return {
    message: `Unknown error type: ${String(error)}`,
    originalErrorType: typeof error,
  };
}

export function createDataMetadata(data: Record<string, any>): Record<string, any> {
  return {
    ...data,
    timestamp: new Date().toISOString(),
  };
}
----
src/utils/utils.ts
import { type ClassValue, clsx } from "clsx"
import { twMerge } from "tailwind-merge" // Already installed in package.json

/**
 * Merges class names with Tailwind CSS classes
 */
export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}

/**
 * Format a setting name for display (convert camelCase to Title Case)
 */
export function formatSettingName(name: string): string {
  // Handle special case acronyms (e.g., "XR" should remain uppercase)
  if (name === 'xr') return 'XR';
  
  // Replace camelCase with spaces
  const spacedName = name.replace(/([A-Z])/g, ' $1').trim();
  
  // Capitalize first letter of each word
  return spacedName.charAt(0).toUpperCase() + spacedName.slice(1);
}

/**
 * Check if a value is defined (not undefined and not null)
 */
export function isDefined<T>(value: T | undefined | null): value is T {
  return value !== undefined && value !== null;
}

/**
 * Debounce a function call
 */
export function debounce<T extends (...args: any[]) => any>(
  func: T,
  wait: number
): (...args: Parameters<T>) => void {
  let timeout: ReturnType<typeof setTimeout> | null = null;
  
  return function(...args: Parameters<T>) {
    if (timeout) {
      clearTimeout(timeout);
    }
    
    timeout = setTimeout(() => {
      func(...args);
    }, wait);
  };
}

/**
 * Truncate a string to the specified length
 */
export function truncate(str: string, length: number): string {
  if (str.length <= length) {
    return str;
  }
  
  return str.slice(0, length) + '...';
}
----
src/utils/binaryUtils.ts
/**
 * Utility functions for binary data handling
 */
import { createLogger, createErrorMetadata } from './logger';
import { debugState } from './debugState';

const logger = createLogger('BinaryUtils');

/**
 * Check if binary data is likely compressed with zlib
 * Zlib header usually starts with bytes 0x78 0x01, 0x78 0x9C, or 0x78 0xDA
 * 
 * The possible headers (first byte is 0x78):
 * - 0x01: No compression or lowest compression level
 * - 0x5E: Level 1 compression
 * - 0x9C: Default compression (level 6)
 * - 0xDA: Maximum compression (level 9)
 */
export function isZlibCompressed(data: ArrayBuffer): boolean {
  if (data.byteLength < 2) {
    return false;
  }
  
  const view = new Uint8Array(data);
  
  // First byte for zlib must be 0x78
  if (view[0] !== 0x78) {
    return false;
  }
  
  // Common second bytes for zlib headers
  const validSecondBytes = [0x01, 0x5E, 0x9C, 0xDA];
  const isCompressed = validSecondBytes.includes(view[1]);
  
  if (isCompressed && debugState.isDataDebugEnabled()) {
    // Log compression details for debugging
    let compressionLevel = "unknown";
    switch (view[1]) {
      case 0x01: compressionLevel = "no compression/lowest"; break;
      case 0x5E: compressionLevel = "level 1"; break;
      case 0x9C: compressionLevel = "default (level 6)"; break;
      case 0xDA: compressionLevel = "maximum (level 9)"; break;
    }
    logger.debug(`Detected zlib compressed data: ${compressionLevel} compression, size: ${data.byteLength} bytes`);
  }
  
  return isCompressed;
}

/**
 * Decompress zlib compressed data
 * Using the DecompressionStream API available in modern browsers
 */
export async function decompressZlib(compressedData: ArrayBuffer): Promise<ArrayBuffer> {
  // Start timing the decompression
  const startTime = performance.now();
  
  // For browsers that support DecompressionStream (Chrome, Firefox, Safari)
  if (typeof DecompressionStream !== 'undefined') {
    try {
      const cs = new DecompressionStream('deflate-raw');
      const writer = cs.writable.getWriter();
      writer.write(new Uint8Array(compressedData.slice(2))); // Skip zlib header (2 bytes)
      writer.close();
      const output = [];
      const reader = cs.readable.getReader();
      
      while (true) {
        const { value, done } = await reader.read();
        if (done) break;
        output.push(value);
      }
      
      // Combine all chunks
      const totalLength = output.reduce((acc, arr) => acc + arr.length, 0);
      const result = new Uint8Array(totalLength);
      let offset = 0;
      
      for (const arr of output) {
        result.set(arr, offset);
        offset += arr.length;
      }
      
      // End timing and log
      const endTime = performance.now();
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Decompressed ${compressedData.byteLength} bytes to ${result.buffer.byteLength} bytes in ${(endTime - startTime).toFixed(2)}ms (${((result.buffer.byteLength / compressedData.byteLength) * 100).toFixed(2)}% expansion)`);
      }
      
      return result.buffer;
    } catch (error) {
      logger.error('Error decompressing data:', createErrorMetadata(error));
      throw new Error('Failed to decompress data');
    }
  } else {
    // DecompressionStream not available
    logger.error('DecompressionStream API not available in this browser');
    throw new Error('Decompression not supported in this browser');
  }
}

/**
 * Detect and decompress binary data if it's compressed
 */
export async function maybeDecompress(data: ArrayBuffer): Promise<ArrayBuffer> {
  // Check for invalid data
  if (!data || data.byteLength === 0) {
    logger.warn('Empty or invalid binary data received');
    return data;
  }
  
  // Log the first few bytes to help with debugging
  if (debugState.isDataDebugEnabled()) {
    const view = new Uint8Array(data);
    const hexBytes = [];
    const maxBytesToShow = Math.min(16, data.byteLength);
    
    for (let i = 0; i < maxBytesToShow; i++) {
      hexBytes.push(view[i].toString(16).padStart(2, '0'));
    }
    
    logger.debug(`Binary data header (${data.byteLength} bytes): ${hexBytes.join(' ')}`);
  }
  
  if (isZlibCompressed(data)) {
    try {
      const decompressed = await decompressZlib(data);
      return decompressed;
    } catch (error) {
      logger.error('Failed to decompress data, using raw data instead:', createErrorMetadata(error));
      // Fall back to original data if decompression fails
      return data;
    }
  } else {
    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Processing uncompressed binary data (${data.byteLength} bytes)`);
    }
    return data;
  }
} 
----
src/utils/deepMerge.ts
/**
 * Deep merge utility for merging nested objects
 * This is used to properly merge settings objects with nested properties
 */

/**
 * Checks if a value is an object (but not null, array, or function)
 */
export function isObject(item: any): boolean {
  return (
    item !== null &&
    typeof item === 'object' &&
    !Array.isArray(item) &&
    !(item instanceof Date) &&
    !(item instanceof RegExp) &&
    !(item instanceof Map) &&
    !(item instanceof Set)
  );
}

/**
 * Deep merges multiple objects together
 * Later objects in the arguments list take precedence over earlier ones
 */
export function deepMerge<T extends Record<string, any>>(...objects: (T | undefined)[]): T {
  // Filter out undefined objects
  const validObjects = objects.filter(obj => obj !== undefined) as T[];
  
  // Return empty object if no valid objects
  if (validObjects.length === 0) {
    return {} as T;
  }
  
  // Return the first object if only one is provided
  if (validObjects.length === 1) {
    return { ...validObjects[0] };
  }
  
  // Start with a copy of the first object
  const result = { ...validObjects[0] };
  
  // Merge each subsequent object
  for (let i = 1; i < validObjects.length; i++) {
    const obj = validObjects[i];
    
    // Skip if undefined
    if (!obj) continue;
    
    // Merge each property
    for (const key in obj) {
      if (Object.prototype.hasOwnProperty.call(obj, key)) {
        const value = obj[key];
        
        // If both values are objects, recursively merge them
        if (isObject(result[key]) && isObject(value)) {
          result[key] = deepMerge(result[key], value);
        } 
        // Otherwise, use the value from the current object
        else {
          result[key] = value;
        }
      }
    }
  }
  
  return result;
}

----
src/utils/debugState.ts
import { createLogger } from './logger';

const logger = createLogger('DebugState');

class DebugState {
  private debugEnabled: boolean = false;
  private dataDebugEnabled: boolean = false;
  private performanceDebugEnabled: boolean = false;

  constructor() {
    // Initialize from localStorage if available
    this.loadFromStorage();
  }

  private loadFromStorage(): void {
    if (typeof window !== 'undefined') {
      try {
        this.debugEnabled = localStorage.getItem('debug.enabled') === 'true';
        this.dataDebugEnabled = localStorage.getItem('debug.data') === 'true';
        this.performanceDebugEnabled = localStorage.getItem('debug.performance') === 'true';
      } catch (e) {
        logger.warn('Failed to load debug state from localStorage');
      }
    }
  }

  private saveToStorage(): void {
    if (typeof window !== 'undefined') {
      try {
        localStorage.setItem('debug.enabled', this.debugEnabled.toString());
        localStorage.setItem('debug.data', this.dataDebugEnabled.toString());
        localStorage.setItem('debug.performance', this.performanceDebugEnabled.toString());
      } catch (e) {
        logger.warn('Failed to save debug state to localStorage');
      }
    }
  }

  public isEnabled(): boolean {
    return this.debugEnabled;
  }

  public enableDebug(enable: boolean = true): void {
    this.debugEnabled = enable;
    this.saveToStorage();
    logger.info(`Debug mode ${enable ? 'enabled' : 'disabled'}`);
  }

  public isDataDebugEnabled(): boolean {
    return this.debugEnabled && this.dataDebugEnabled;
  }

  public enableDataDebug(enable: boolean = true): void {
    this.dataDebugEnabled = enable;
    this.saveToStorage();
    logger.info(`Data debug mode ${enable ? 'enabled' : 'disabled'}`);
  }

  public isPerformanceDebugEnabled(): boolean {
    return this.debugEnabled && this.performanceDebugEnabled;
  }

  public enablePerformanceDebug(enable: boolean = true): void {
    this.performanceDebugEnabled = enable;
    this.saveToStorage();
    logger.info(`Performance debug mode ${enable ? 'enabled' : 'disabled'}`);
  }
}

// Create a singleton instance
export const debugState = new DebugState();
----
src/utils/objectPath.ts
/**
 * Utility functions for working with object paths
 * Uses dot notation to access nested properties (e.g., "visualisation.nodes.baseColor")
 */

type NestedObject = Record<string, any>;

/**
 * Gets a value from a nested object using a dot notation path
 * @param obj The object to get the value from
 * @param path The path to the value, using dot notation (e.g., "visualisation.nodes.baseColor")
 * @param defaultValue A default value to return if the path doesn't exist
 * @returns The value at the path, or the default value if not found
 */
export function get(obj: NestedObject, path: string, defaultValue?: any): any {
  if (!path || !obj) {
    return defaultValue;
  }

  const keys = path.split('.');
  let current = obj;

  for (let i = 0; i < keys.length; i++) {
    const key = keys[i];
    
    // Handle array indices in path
    if (key.includes('[') && key.includes(']')) {
      const arrayKey = key.substring(0, key.indexOf('['));
      const indexStr = key.substring(key.indexOf('[') + 1, key.indexOf(']'));
      const index = parseInt(indexStr, 10);
      
      if (current[arrayKey] === undefined || 
          !Array.isArray(current[arrayKey]) || 
          current[arrayKey][index] === undefined) {
        return defaultValue;
      }
      
      current = current[arrayKey][index];
      continue;
    }
    
    if (current[key] === undefined) {
      return defaultValue;
    }
    
    current = current[key];
  }
  
  return current;
}

/**
 * Sets a value in a nested object using a dot notation path
 * Creates the object structure if it doesn't exist
 * @param obj The object to set the value in
 * @param path The path to set, using dot notation (e.g., "visualisation.nodes.baseColor")
 * @param value The value to set
 */
export function set(obj: NestedObject, path: string, value: any): void {
  if (!path || !obj) {
    return;
  }

  const keys = path.split('.');
  let current = obj;

  for (let i = 0; i < keys.length - 1; i++) {
    const key = keys[i];
    
    // Handle array indices in path
    if (key.includes('[') && key.includes(']')) {
      const arrayKey = key.substring(0, key.indexOf('['));
      const indexStr = key.substring(key.indexOf('[') + 1, key.indexOf(']'));
      const index = parseInt(indexStr, 10);
      
      if (current[arrayKey] === undefined) {
        current[arrayKey] = [];
      }
      
      if (!Array.isArray(current[arrayKey])) {
        current[arrayKey] = [];
      }
      
      if (current[arrayKey][index] === undefined) {
        current[arrayKey][index] = {};
      }
      
      current = current[arrayKey][index];
      continue;
    }
    
    if (current[key] === undefined || typeof current[key] !== 'object' || current[key] === null) {
      current[key] = {};
    }
    
    current = current[key];
  }
  
  // Handle the last key
  const lastKey = keys[keys.length - 1];
  
  // Check if last key is an array index
  if (lastKey.includes('[') && lastKey.includes(']')) {
    const arrayKey = lastKey.substring(0, lastKey.indexOf('['));
    const indexStr = lastKey.substring(lastKey.indexOf('[') + 1, lastKey.indexOf(']'));
    const index = parseInt(indexStr, 10);
    
    if (current[arrayKey] === undefined) {
      current[arrayKey] = [];
    }
    
    if (!Array.isArray(current[arrayKey])) {
      current[arrayKey] = [];
    }
    
    current[arrayKey][index] = value;
  } else {
    current[lastKey] = value;
  }
}
----
src/utils/cn.ts
import { type ClassValue, clsx } from "clsx"
import { twMerge } from "tailwind-merge"

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}

----
src/utils/caseConversion.ts
/**
 * Utility functions for converting between different case styles (snake_case, camelCase)
 * Used primarily for API communication where server uses snake_case and client uses camelCase
 */

/**
 * Converts a snake_case string to camelCase
 * @param str The snake_case string to convert
 * @returns The camelCase version of the string
 */
export function snakeToCamel(str: string): string {
  return str.replace(/_([a-z])/g, (_, letter) => letter.toUpperCase());
}

/**
 * Converts a camelCase string to snake_case
 * @param str The camelCase string to convert
 * @returns The snake_case version of the string
 */
export function camelToSnake(str: string): string {
  return str.replace(/([A-Z])/g, (_, letter) => `_${letter.toLowerCase()}`);
}

/**
 * Recursively converts all keys in an object from snake_case to camelCase
 * @param obj The object with snake_case keys
 * @returns A new object with all keys converted to camelCase
 */
export function convertSnakeToCamelCase<T extends Record<string, any>>(obj: T): Record<string, any> {
  if (typeof obj !== 'object' || obj === null) {
    return obj;
  }

  if (Array.isArray(obj)) {
    return obj.map(item => convertSnakeToCamelCase(item)) as any;
  }

  return Object.keys(obj).reduce((result, key) => {
    const camelKey = snakeToCamel(key);
    const value = obj[key];

    result[camelKey] = typeof value === 'object' && value !== null
      ? convertSnakeToCamelCase(value)
      : value;

    return result;
  }, {} as Record<string, any>);
}

/**
 * Recursively converts all keys in an object from camelCase to snake_case
 * @param obj The object with camelCase keys
 * @returns A new object with all keys converted to snake_case
 */
export function convertCamelToSnakeCase<T extends Record<string, any>>(obj: T): Record<string, any> {
  if (typeof obj !== 'object' || obj === null) {
    return obj;
  }

  if (Array.isArray(obj)) {
    return obj.map(item => convertCamelToSnakeCase(item)) as any;
  }

  return Object.keys(obj).reduce((result, key) => {
    const snakeKey = camelToSnake(key);
    const value = obj[key];

    result[snakeKey] = typeof value === 'object' && value !== null
      ? convertCamelToSnakeCase(value)
      : value;

    return result;
  }, {} as Record<string, any>);
}

----
src/ui/ThemeProvider.tsx
import { createContext, useContext, useEffect, useState } from "react"

type Theme = "dark" | "light" | "system"

type ThemeProviderProps = {
  children: React.ReactNode
  defaultTheme?: Theme
  storageKey?: string
}

type ThemeProviderState = {
  theme: Theme
  setTheme: (theme: Theme) => void
}

const initialState: ThemeProviderState = {
  theme: "system",
  setTheme: () => null,
}

const ThemeProviderContext = createContext<ThemeProviderState>(initialState)

export function ThemeProvider({
  children,
  defaultTheme = "system",
  storageKey = "ui-theme",
  ...props
}: ThemeProviderProps) {
  const [theme, setTheme] = useState<Theme>(
    () => (localStorage.getItem(storageKey) as Theme) || defaultTheme
  )

  useEffect(() => {
    const root = window.document.documentElement
    
    root.classList.remove("light", "dark")
    
    if (theme === "system") {
      const systemTheme = window.matchMedia("(prefers-color-scheme: dark)")
        .matches
        ? "dark"
        : "light"
      
      root.classList.add(systemTheme)
      return
    }
    
    root.classList.add(theme)
  }, [theme])

  const value = {
    theme,
    setTheme: (theme: Theme) => {
      localStorage.setItem(storageKey, theme)
      setTheme(theme)
    },
  }

  return (
    <ThemeProviderContext.Provider {...props} value={value}>
      {children}
    </ThemeProviderContext.Provider>
  )
}

export const useTheme = () => {
  const context = useContext(ThemeProviderContext)
  
  if (context === undefined)
    throw new Error("useTheme must be used within a ThemeProvider")
  
  return context
}
----
src/ui/Toast.tsx
import * as React from "react"
import * as ToastPrimitives from "@radix-ui/react-toast"
import { cva, type VariantProps } from "class-variance-authority"
import { X } from "lucide-react"

import { cn } from "../utils/utils"

const ToastProvider = ToastPrimitives.Provider

const ToastViewport = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Viewport>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Viewport>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Viewport
    ref={ref}
    className={cn(
      "fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 sm:bottom-0 sm:right-0 sm:top-auto sm:flex-col md:max-w-[420px]",
      className
    )}
    {...props}
  />
))
ToastViewport.displayName = ToastPrimitives.Viewport.displayName

const toastVariants = cva(
  "group pointer-events-auto relative flex w-full items-center justify-between space-x-2 overflow-hidden rounded-md border p-4 pr-6 shadow-lg transition-all data-[swipe=cancel]:translate-x-0 data-[swipe=end]:translate-x-[var(--radix-toast-swipe-end-x)] data-[swipe=move]:translate-x-[var(--radix-toast-swipe-move-x)] data-[swipe=move]:transition-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[swipe=end]:animate-out data-[state=closed]:fade-out-80 data-[state=closed]:slide-out-to-right-full data-[state=open]:slide-in-from-top-full data-[state=open]:sm:slide-in-from-bottom-full",
  {
    variants: {
      variant: {
        default: "border bg-background text-foreground",
        destructive:
          "destructive group border-destructive bg-destructive text-destructive-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

const Toast = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Root>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Root> &
    VariantProps<typeof toastVariants>
>(({ className, variant, ...props }, ref) => {
  return (
    <ToastPrimitives.Root
      ref={ref}
      className={cn(toastVariants({ variant }), className)}
      {...props}
    />
  )
})
Toast.displayName = ToastPrimitives.Root.displayName

const ToastAction = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Action>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Action>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Action
    ref={ref}
    className={cn(
      "inline-flex h-8 shrink-0 items-center justify-center rounded-md border bg-transparent px-3 text-sm font-medium transition-colors hover:bg-secondary focus:outline-none focus:ring-1 focus:ring-ring disabled:pointer-events-none disabled:opacity-50 group-[.destructive]:border-muted/40 group-[.destructive]:hover:border-destructive/30 group-[.destructive]:hover:bg-destructive group-[.destructive]:hover:text-destructive-foreground group-[.destructive]:focus:ring-destructive",
      className
    )}
    {...props}
  />
))
ToastAction.displayName = ToastPrimitives.Action.displayName

const ToastClose = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Close>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Close>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Close
    ref={ref}
    className={cn(
      "absolute right-1 top-1 rounded-md p-1 text-foreground/50 opacity-0 transition-opacity hover:text-foreground focus:opacity-100 focus:outline-none focus:ring-1 group-hover:opacity-100 group-[.destructive]:text-red-300 group-[.destructive]:hover:text-red-50 group-[.destructive]:focus:ring-red-400 group-[.destructive]:focus:ring-offset-red-600",
      className
    )}
    toast-close=""
    {...props}
  >
    <X className="h-4 w-4" />
  </ToastPrimitives.Close>
))
ToastClose.displayName = ToastPrimitives.Close.displayName

const ToastTitle = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Title>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Title>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Title
    ref={ref}
    className={cn("text-sm font-semibold [&+div]:text-xs", className)}
    {...props}
  />
))
ToastTitle.displayName = ToastPrimitives.Title.displayName

const ToastDescription = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Description>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Description>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Description
    ref={ref}
    className={cn("text-sm opacity-90", className)}
    {...props}
  />
))
ToastDescription.displayName = ToastPrimitives.Description.displayName

type ToastProps = React.ComponentPropsWithoutRef<typeof Toast>

type ToastActionElement = React.ReactElement<typeof ToastAction>

export {
  type ToastProps,
  type ToastActionElement,
  ToastProvider,
  ToastViewport,
  Toast,
  ToastTitle,
  ToastDescription,
  ToastClose,
  ToastAction,
}
----
src/ui/Card.tsx
import * as React from "react"

import { cn } from "../utils/utils" // Corrected path

const Card = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn(
      "rounded-lg border border-border bg-card text-card-foreground shadow-sm",
      className
    )}
    {...props}
  />
))
Card.displayName = "Card"

const CardHeader = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex flex-col space-y-1.5 p-6", className)}
    {...props}
  />
))
CardHeader.displayName = "CardHeader"

const CardTitle = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLHeadingElement>
>(({ className, ...props }, ref) => (
  <h3
    ref={ref}
    className={cn(
      "text-lg font-semibold leading-none tracking-tight",
      className
    )}
    {...props}
  />
))
CardTitle.displayName = "CardTitle"

const CardDescription = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLParagraphElement>
>(({ className, ...props }, ref) => (
  <p
    ref={ref}
    className={cn("text-sm text-muted-foreground", className)}
    {...props}
  />
))
CardDescription.displayName = "CardDescription"

const CardContent = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div ref={ref} className={cn("p-6 pt-0", className)} {...props} />
))
CardContent.displayName = "CardContent"

const CardFooter = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex items-center p-6 pt-0", className)}
    {...props}
  />
))
CardFooter.displayName = "CardFooter"

export { Card, CardHeader, CardFooter, CardTitle, CardDescription, CardContent }
----
src/ui/ThemeSelector.tsx
import React from 'react';
import { useTheme } from './ThemeProvider';
import { Button } from './Button';
import { Check } from 'lucide-react';

const ThemeSelector = () => {
  const { theme, setTheme } = useTheme();

  return (
    <div className="space-y-4">
      <div className="flex flex-col space-y-2">
        <h3 className="text-sm font-medium">Theme</h3>
        <div className="flex flex-wrap gap-2">
          <Button
            variant={theme === 'light' ? 'default' : 'outline'}
            size="sm"
            onClick={() => setTheme('light')}
            className="flex items-center"
          >
            Light
            {theme === 'light' && <Check className="h-3 w-3 ml-1" />}
          </Button>

          <Button
            variant={theme === 'dark' ? 'default' : 'outline'}
            size="sm"
            onClick={() => setTheme('dark')}
            className="flex items-center"
          >
            Dark
            {theme === 'dark' && <Check className="h-3 w-3 ml-1" />}
          </Button>

          <Button
            variant={theme === 'system' ? 'default' : 'outline'}
            size="sm"
            onClick={() => setTheme('system')}
            className="flex items-center"
          >
            System
            {theme === 'system' && <Check className="h-3 w-3 ml-1" />}
          </Button>
        </div>
      </div>

      <div className="mt-4 p-3 bg-muted rounded-md">
        <div className="text-sm text-muted-foreground">
          Theme changes are saved automatically and will persist between sessions.
        </div>
      </div>
    </div>
  );
};

export default ThemeSelector;
----
src/ui/Tooltip.tsx
import * as React from "react"
import * as TooltipPrimitive from "@radix-ui/react-tooltip"

import { cn } from "../utils/utils"

const TooltipProvider = TooltipPrimitive.Provider

const TooltipRoot = TooltipPrimitive.Root

const TooltipTrigger = TooltipPrimitive.Trigger

const TooltipContent = React.forwardRef<
  React.ElementRef<typeof TooltipPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof TooltipPrimitive.Content>
>(({ className, sideOffset = 4, ...props }, ref) => (
  <TooltipPrimitive.Content
    ref={ref}
    sideOffset={sideOffset}
    className={cn(
      "z-50 overflow-hidden rounded-md bg-primary px-3 py-1.5 text-xs text-primary-foreground animate-in fade-in-0 zoom-in-95 data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=closed]:zoom-out-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
      className
    )}
    {...props}
  />
))
TooltipContent.displayName = TooltipPrimitive.Content.displayName

// Custom Tooltip component that accepts children and content
interface TooltipProps {
  children: React.ReactNode;
  content: string;
  side?: "top" | "right" | "bottom" | "left";
  align?: "start" | "center" | "end";
}

const Tooltip = ({ children, content, side = "top", align = "center" }: TooltipProps) => {
  return (
    <TooltipRoot>
      <TooltipTrigger asChild>
        {children}
      </TooltipTrigger>
      <TooltipContent side={side} align={align}>
        {content}
      </TooltipContent>
    </TooltipRoot>
  );
};

export { TooltipRoot, TooltipTrigger, TooltipContent, TooltipProvider, Tooltip }

----
src/ui/Slider.tsx
import * as React from "react"
import * as SliderPrimitive from "@radix-ui/react-slider"

import { cn } from "../utils/utils" // Corrected path

const Slider = React.forwardRef<
  React.ElementRef<typeof SliderPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof SliderPrimitive.Root>
>(({ className, ...props }, ref) => (
  <SliderPrimitive.Root
    ref={ref}
    className={cn(
      "relative flex w-full touch-none select-none items-center",
      className
    )}
    {...props}
  >
    <SliderPrimitive.Track className="relative h-1.5 w-full grow overflow-hidden rounded-full bg-primary/20">
      <SliderPrimitive.Range className="absolute h-full bg-primary" />
    </SliderPrimitive.Track>
    <SliderPrimitive.Thumb className="block h-4 w-4 rounded-full border border-primary/50 bg-background shadow transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50" />
  </SliderPrimitive.Root>
))
Slider.displayName = SliderPrimitive.Root.displayName

export { Slider }
----
src/ui/Input.tsx
import * as React from "react"

import { cn } from "../utils/utils" // Corrected path

export interface InputProps
  extends React.InputHTMLAttributes<HTMLInputElement> {}

const Input = React.forwardRef<HTMLInputElement, InputProps>(
  ({ className, type, ...props }, ref) => {
    return (
      <input
        type={type}
        className={cn(
          "flex h-9 w-full rounded-md border border-input bg-transparent px-3 py-1 text-sm shadow-sm transition-colors file:border-0 file:bg-transparent file:text-sm file:font-medium placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:cursor-not-allowed disabled:opacity-50",
          className
        )}
        ref={ref}
        {...props}
      />
    )
  }
)
Input.displayName = "Input"

export { Input }
----
src/ui/Button.tsx
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "../utils/utils"

const buttonVariants = cva(
  "inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50",
  {
    variants: {
      variant: {
        default:
          "bg-primary text-primary-foreground shadow hover:bg-primary/90",
        destructive:
          "bg-destructive text-destructive-foreground shadow-sm hover:bg-destructive/90",
        outline:
          "border border-input bg-background shadow-sm hover:bg-accent hover:text-accent-foreground",
        secondary:
          "bg-secondary text-secondary-foreground shadow-sm hover:bg-secondary/80",
        ghost: "hover:bg-accent hover:text-accent-foreground",
        link: "text-primary underline-offset-4 hover:underline",
      },
      size: {
        default: "h-9 px-4 py-2",
        sm: "h-8 rounded-md px-3 text-xs",
        lg: "h-10 rounded-md px-8",
        icon: "h-9 w-9",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
    VariantProps<typeof buttonVariants> {
  asChild?: boolean
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : "button"
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    )
  }
)
Button.displayName = "Button"

export { Button, buttonVariants }
----
src/ui/Toaster.tsx
import {
  Toast,
  ToastClose,
  ToastDescription,
  ToastProvider,
  ToastTitle,
  ToastViewport,
} from "./Toast"
import { useToast } from "./useToast"

export function Toaster() {
  const { toasts } = useToast()

  return (
    <ToastProvider>
      {toasts.map(function ({ id, title, description, action, ...props }) {
        return (
          <Toast key={id} {...props}>
            <div className="grid gap-1">
              {title && <ToastTitle>{title}</ToastTitle>}
              {description && (
                <ToastDescription>{description}</ToastDescription>
              )}
            </div>
            {action}
            <ToastClose />
          </Toast>
        )
      })}
      <ToastViewport />
    </ToastProvider>
  )
}
----
src/ui/Switch.tsx
import * as React from "react"
import * as SwitchPrimitives from "@radix-ui/react-switch"

import { cn } from "../utils/utils" // Corrected path

const Switch = React.forwardRef<
  React.ElementRef<typeof SwitchPrimitives.Root>,
  React.ComponentPropsWithoutRef<typeof SwitchPrimitives.Root>
>(({ className, ...props }, ref) => (
  <SwitchPrimitives.Root
    className={cn(
      "peer inline-flex h-5 w-9 shrink-0 cursor-pointer items-center rounded-full border-2 border-transparent shadow-sm transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 focus-visible:ring-offset-background disabled:cursor-not-allowed disabled:opacity-50 data-[state=checked]:bg-primary data-[state=unchecked]:bg-input",
      className
    )}
    {...props}
    ref={ref}
  >
    <SwitchPrimitives.Thumb
      className={cn(
        "pointer-events-none block h-4 w-4 rounded-full bg-background shadow-lg ring-0 transition-transform data-[state=checked]:translate-x-4 data-[state=unchecked]:translate-x-0"
      )}
    />
  </SwitchPrimitives.Root>
))
Switch.displayName = SwitchPrimitives.Root.displayName

export { Switch }
----
src/ui/Collapsible.tsx
import * as React from "react"
import * as CollapsiblePrimitive from "@radix-ui/react-collapsible"

import { cn } from "../utils/utils" // Corrected path

const Collapsible = CollapsiblePrimitive.Root

const CollapsibleTrigger = CollapsiblePrimitive.CollapsibleTrigger

const CollapsibleContent = React.forwardRef<
  React.ElementRef<typeof CollapsiblePrimitive.CollapsibleContent>,
  React.ComponentPropsWithoutRef<typeof CollapsiblePrimitive.CollapsibleContent>
>(({ className, ...props }, ref) => (
  <CollapsiblePrimitive.CollapsibleContent
    ref={ref}
    className={cn(
      "data-[state=closed]:animate-collapsible-up data-[state=open]:animate-collapsible-down overflow-hidden transition-all",
      className
    )}
    {...props}
  />
))
CollapsibleContent.displayName = "CollapsibleContent"

export { Collapsible, CollapsibleTrigger, CollapsibleContent }
----
src/ui/Label.tsx
import * as React from "react"
import * as LabelPrimitive from "@radix-ui/react-label"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "../utils/utils" // Corrected path

const labelVariants = cva(
  "text-sm font-medium leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70"
)

const Label = React.forwardRef<
  React.ElementRef<typeof LabelPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof LabelPrimitive.Root> &
    VariantProps<typeof labelVariants>
>(({ className, ...props }, ref) => (
  <LabelPrimitive.Root
    ref={ref}
    className={cn(labelVariants(), className)}
    {...props}
  />
))
Label.displayName = "Label"

export { Label }
----
src/ui/Tabs.tsx
import React, { useState, ReactNode } from 'react';
import { cn } from '../utils/cn'; // Assuming you have a utility for class names

interface Tab {
  label: string;
  content: ReactNode;
  icon?: ReactNode; // Optional icon for the tab
}

interface TabsProps {
  tabs: Tab[];
  initialTab?: number;
  className?: string;
  tabListClassName?: string;
  tabButtonClassName?: string;
  activeTabButtonClassName?: string;
  tabContentClassName?: string;
}

const Tabs: React.FC<TabsProps> = ({
  tabs,
  initialTab = 0,
  className,
  tabListClassName,
  tabButtonClassName,
  activeTabButtonClassName,
  tabContentClassName,
}) => {
  const [activeTab, setActiveTab] = useState(initialTab);

  if (!tabs || tabs.length === 0) {
    return null; // Don't render anything if no tabs are provided
  }

  return (
    // Added default dark theme classes
    <div className={cn('flex flex-col h-full', className)}>
      {/* Tab List */}
      <div
        className={cn(
          'flex border-b border-border overflow-x-auto',
          tabListClassName
        )}
      >
        {tabs.map((tab, index) => (
          <button
            key={index}
            onClick={() => setActiveTab(index)}
            className={cn(
              // Base styles for dark theme button appearance
              'appearance-none border-none bg-transparent', // Remove default browser styling
              'flex items-center px-4 py-2', // Adjusted padding
              'text-sm font-medium', // Consistent font styling
              'text-muted-foreground hover:text-foreground', // Text colors
              'focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 focus:ring-offset-background', // Focus ring for accessibility
              'whitespace-nowrap transition-colors duration-150 ease-in-out', // Smooth transition
              // Remove default bottom border, apply only to active
              tabButtonClassName, // Allow overrides
              // Active tab styles
              activeTab === index && 'border-b-2 border-primary text-foreground',
              activeTab === index && activeTabButtonClassName // Allow overrides for active state
            )}
            aria-selected={activeTab === index}
            role="tab"
          >
            {tab.icon && <span className="mr-2">{tab.icon}</span>}
            {tab.label}
          </button>
        ))}
      </div>

      {/* Tab Content - Added default dark theme classes */}
      <div
        className={cn('flex-1 min-h-0 overflow-y-auto p-4 space-y-6', tabContentClassName)}
        role="tabpanel"
      >
        {tabs[activeTab]?.content}
      </div>
    </div>
  );
};

export default Tabs;

----
src/ui/useToast.tsx
import * as React from "react"

import type {
  ToastActionElement,
  ToastProps,
} from "./Toast" // Corrected path (assuming Toast.tsx is in the same directory)

const TOAST_LIMIT = 5
const TOAST_REMOVE_DELAY = 5000

type ToasterToast = ToastProps & {
  id: string
  title?: React.ReactNode
  description?: React.ReactNode
  action?: ToastActionElement
  duration?: number
}

const actionTypes = {
  ADD_TOAST: "ADD_TOAST",
  UPDATE_TOAST: "UPDATE_TOAST",
  DISMISS_TOAST: "DISMISS_TOAST",
  REMOVE_TOAST: "REMOVE_TOAST",
} as const

let count = 0

function genId() {
  count = (count + 1) % Number.MAX_VALUE
  return count.toString()
}

type ActionType = typeof actionTypes

type Action =
  | {
      type: ActionType["ADD_TOAST"]
      toast: ToasterToast
    }
  | {
      type: ActionType["UPDATE_TOAST"]
      toast: Partial<ToasterToast>
    }
  | {
      type: ActionType["DISMISS_TOAST"]
      toastId?: string
    }
  | {
      type: ActionType["REMOVE_TOAST"]
      toastId?: string
    }

interface State {
  toasts: ToasterToast[]
}

const toastTimeouts = new Map<string, ReturnType<typeof setTimeout>>()

const reducer = (state: State, action: Action): State => {
  switch (action.type) {
    case actionTypes.ADD_TOAST:
      return {
        ...state,
        toasts: [action.toast, ...state.toasts].slice(0, TOAST_LIMIT),
      }

    case actionTypes.UPDATE_TOAST:
      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === action.toast.id ? { ...t, ...action.toast } : t
        ),
      }

    case actionTypes.DISMISS_TOAST: {
      const { toastId } = action

      if (toastId) {
        toastTimeouts.forEach((_, id) => {
          if (id === toastId) {
            toastTimeouts.delete(id)
          }
        })

        return {
          ...state,
          toasts: state.toasts.map((t) =>
            t.id === toastId
              ? {
                  ...t,
                  open: false,
                }
              : t
          ),
        }
      }

      return {
        ...state,
        toasts: state.toasts.map((t) => ({
          ...t,
          open: false,
        })),
      }
    }
    
    case actionTypes.REMOVE_TOAST:
      if (action.toastId === undefined) {
        return {
          ...state,
          toasts: [],
        }
      }
      return {
        ...state,
        toasts: state.toasts.filter((t) => t.id !== action.toastId),
      }
  }
}

const listeners: Array<(state: State) => void> = []

let memoryState: State = { toasts: [] }

function dispatch(action: Action) {
  memoryState = reducer(memoryState, action)
  listeners.forEach((listener) => {
    listener(memoryState)
  })
}

type Toast = Omit<ToasterToast, "id">

function toast({ ...props }: Toast) {
  const id = genId()

  const update = (props: ToasterToast) =>
    dispatch({
      type: actionTypes.UPDATE_TOAST,
      toast: { ...props, id },
    })

  const dismiss = () => dispatch({ type: actionTypes.DISMISS_TOAST, toastId: id })

  dispatch({
    type: actionTypes.ADD_TOAST,
    toast: {
      ...props,
      id,
      open: true,
      onOpenChange: (open) => {
        if (!open) dismiss()
      },
    },
  })

  return {
    id,
    dismiss,
    update,
  }
}

function useToast() {
  const [state, setState] = React.useState<State>(memoryState)

  React.useEffect(() => {
    listeners.push(setState)
    return () => {
      const index = listeners.indexOf(setState)
      if (index > -1) {
        listeners.splice(index, 1)
      }
    }
  }, [state])

  return {
    ...state,
    toast,
    dismiss: (toastId?: string) => dispatch({ type: actionTypes.DISMISS_TOAST, toastId }),
    remove: (toastId?: string) => dispatch({ type: actionTypes.REMOVE_TOAST, toastId }),
  }
}

export { useToast, toast }
----
src/ui/RadioGroup.tsx
import * as React from "react"
import * as RadioGroupPrimitive from "@radix-ui/react-radio-group"
import { Circle } from "lucide-react"

import { cn } from "../utils/utils"

const RadioGroup = React.forwardRef<
  React.ElementRef<typeof RadioGroupPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof RadioGroupPrimitive.Root>
>(({ className, ...props }, ref) => {
  return (
    <RadioGroupPrimitive.Root
      className={cn("grid gap-2", className)}
      {...props}
      ref={ref}
    />
  )
})
RadioGroup.displayName = RadioGroupPrimitive.Root.displayName

const RadioGroupItem = React.forwardRef<
  React.ElementRef<typeof RadioGroupPrimitive.Item>,
  React.ComponentPropsWithoutRef<typeof RadioGroupPrimitive.Item>
>(({ className, ...props }, ref) => {
  return (
    <RadioGroupPrimitive.Item
      ref={ref}
      className={cn(
        "aspect-square h-4 w-4 rounded-full border border-primary text-primary ring-offset-background focus:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50",
        className
      )}
      {...props}
    >
      <RadioGroupPrimitive.Indicator className="flex items-center justify-center">
        <Circle className="h-2.5 w-2.5 fill-current text-current" />
      </RadioGroupPrimitive.Indicator>
    </RadioGroupPrimitive.Item>
  )
})
RadioGroupItem.displayName = RadioGroupPrimitive.Item.displayName

export { RadioGroup, RadioGroupItem }

----
src/ui/Select.tsx
import * as React from "react"
import * as SelectPrimitive from "@radix-ui/react-select"
import { Check, ChevronDown, ChevronUp } from "lucide-react"

import { cn } from "../utils/utils" // Corrected path

const Select = SelectPrimitive.Root

const SelectGroup = SelectPrimitive.Group

const SelectValue = SelectPrimitive.Value

const SelectTrigger = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Trigger>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Trigger>
>(({ className, children, ...props }, ref) => (
  <SelectPrimitive.Trigger
    ref={ref}
    className={cn(
      "flex h-9 w-full items-center justify-between rounded-md border border-input bg-transparent px-3 py-2 text-sm shadow-sm ring-offset-background placeholder:text-muted-foreground focus:outline-none focus:ring-1 focus:ring-ring disabled:cursor-not-allowed disabled:opacity-50 [&>span]:line-clamp-1",
      className
    )}
    {...props}
  >
    {children}
    <SelectPrimitive.Icon asChild>
      <ChevronDown className="h-4 w-4 opacity-50" />
    </SelectPrimitive.Icon>
  </SelectPrimitive.Trigger>
))
SelectTrigger.displayName = SelectPrimitive.Trigger.displayName

const SelectScrollUpButton = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.ScrollUpButton>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.ScrollUpButton>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.ScrollUpButton
    ref={ref}
    className={cn(
      "flex cursor-default items-center justify-center py-1",
      className
    )}
    {...props}
  >
    <ChevronUp className="h-4 w-4" />
  </SelectPrimitive.ScrollUpButton>
))
SelectScrollUpButton.displayName = SelectPrimitive.ScrollUpButton.displayName

const SelectScrollDownButton = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.ScrollDownButton>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.ScrollDownButton>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.ScrollDownButton
    ref={ref}
    className={cn(
      "flex cursor-default items-center justify-center py-1",
      className
    )}
    {...props}
  >
    <ChevronDown className="h-4 w-4" />
  </SelectPrimitive.ScrollDownButton>
))
SelectScrollDownButton.displayName =
  SelectPrimitive.ScrollDownButton.displayName

const SelectContent = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Content>
>(({ className, children, position = "popper", ...props }, ref) => (
  <SelectPrimitive.Portal>
    <SelectPrimitive.Content
      ref={ref}
      className={cn(
        "relative z-50 max-h-96 min-w-[8rem] overflow-hidden rounded-md border border-border bg-popover text-popover-foreground shadow-md data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
        position === "popper" &&
          "data-[side=bottom]:translate-y-1 data-[side=left]:-translate-x-1 data-[side=right]:translate-x-1 data-[side=top]:-translate-y-1",
        className
      )}
      position={position}
      {...props}
    >
      <SelectScrollUpButton />
      <SelectPrimitive.Viewport
        className={cn(
          "p-1",
          position === "popper" &&
            "h-[var(--radix-select-trigger-height)] w-full min-w-[var(--radix-select-trigger-width)]"
        )}
      >
        {children}
      </SelectPrimitive.Viewport>
      <SelectScrollDownButton />
    </SelectPrimitive.Content>
  </SelectPrimitive.Portal>
))
SelectContent.displayName = SelectPrimitive.Content.displayName

const SelectLabel = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Label>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Label>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.Label
    ref={ref}
    className={cn("py-1.5 pl-8 pr-2 text-sm font-semibold", className)}
    {...props}
  />
))
SelectLabel.displayName = SelectPrimitive.Label.displayName

const SelectItem = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Item>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Item>
>(({ className, children, ...props }, ref) => (
  <SelectPrimitive.Item
    ref={ref}
    className={cn(
      "relative flex w-full cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
      className
    )}
    {...props}
  >
    <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
      <SelectPrimitive.ItemIndicator>
        <Check className="h-4 w-4" />
      </SelectPrimitive.ItemIndicator>
    </span>

    <SelectPrimitive.ItemText>{children}</SelectPrimitive.ItemText>
  </SelectPrimitive.Item>
))
SelectItem.displayName = SelectPrimitive.Item.displayName

const SelectSeparator = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Separator>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Separator>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.Separator
    ref={ref}
    className={cn("-mx-1 my-1 h-px bg-muted", className)}
    {...props}
  />
))
SelectSeparator.displayName = SelectPrimitive.Separator.displayName

export {
  Select,
  SelectGroup,
  SelectValue,
  SelectTrigger,
  SelectContent,
  SelectLabel,
  SelectItem,
  SelectSeparator,
  SelectScrollUpButton,
  SelectScrollDownButton,
}
----
src/ui/markdown/MarkdownRenderer.tsx
import { useState } from 'react';
import ReactMarkdown from 'react-markdown';
import remarkGfm from 'remark-gfm';
import { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';
import { vscDarkPlus } from 'react-syntax-highlighter/dist/esm/styles/prism';
import { cn } from '@/utils/cn';
import { Button } from '@/ui/Button';
// Using icons available in types/lucide-react.d.ts
import { Download, Check, Settings, Terminal, Anchor } from 'lucide-react';

// Interactive code block component
const InteractiveCodeBlock = ({ language, code, className }) => {
  const [editable, setEditable] = useState(false);
  const [value, setValue] = useState(code);
  const [copied, setCopied] = useState(false);
  const [executing, setExecuting] = useState(false);
  const [output, setOutput] = useState(null);

  const handleEdit = () => {
    setEditable(true);
  };

  const handleSave = () => {
    setEditable(false);
  };

  const handleCopy = () => {
    navigator.clipboard.writeText(value);
    setCopied(true);
    setTimeout(() => setCopied(false), 2000);
  };

  const handleExecute = () => {
    setExecuting(true);
    // Simulate code execution
    setTimeout(() => {
      setOutput(`Executed ${language} code successfully!`);
      setExecuting(false);
    }, 1000);
  };

  const isExecutable = ['javascript', 'js', 'typescript', 'ts', 'python', 'py'].includes(language);

  return (
    <div className="relative group">
      {editable ? (
        <div className="relative">
          <textarea
            value={value}
            onChange={(e) => setValue(e.target.value)}
            className="w-full h-full p-4 bg-muted text-sm font-mono rounded-md"
            rows={value.split('\n').length + 1}
          />
          <div className="absolute top-2 right-2 flex space-x-1">
            <Button
              variant="ghost"
              size="icon"
              className="h-6 w-6 bg-background/80"
              onClick={handleSave}
              aria-label="Save"
            >
              {/* Using Check for Save */}
              <Check className="h-3 w-3" />
            </Button>
          </div>
        </div>
      ) : (
        <div className="relative">
          <SyntaxHighlighter
            style={vscDarkPlus}
            language={language}
            className={cn("rounded-md", className)}
            showLineNumbers={true}
          >
            {value}
          </SyntaxHighlighter>

          <div className="absolute top-2 right-2 flex space-x-1 opacity-0 group-hover:opacity-100 transition-opacity">
            <Button
              variant="ghost"
              size="icon"
              className="h-6 w-6 bg-background/80"
              onClick={handleCopy}
              aria-label="Copy code"
            >
              {/* Using Download for Copy */}
              {copied ? <Check className="h-3 w-3" /> : <Download className="h-3 w-3" />}
            </Button>
            <Button
              variant="ghost"
              size="icon"
              className="h-6 w-6 bg-background/80"
              onClick={handleEdit}
              aria-label="Edit code"
            >
              {/* Using Settings for Edit */}
              <Settings className="h-3 w-3" />
            </Button>
            {isExecutable && (
              <Button
                variant="ghost"
                size="icon"
                className="h-6 w-6 bg-background/80"
                onClick={handleExecute}
                aria-label="Execute code"
                disabled={executing}
              >
                {/* Using Terminal for Play */}
                <Terminal className="h-3 w-3" />
              </Button>
            )}
          </div>
        </div>
      )}

      {output && (
        <div className="mt-2 p-3 bg-muted/50 rounded-md border border-border">
          <div className="text-xs font-medium mb-1">Output:</div>
          <div className="text-sm font-mono">{output}</div>
        </div>
      )}
    </div>
  );
};

// Interactive link component
const InteractiveLink = ({ href, children }) => {
  const isExternal = href.startsWith('http');

  return (
    <a
      href={href}
      target={isExternal ? "_blank" : undefined}
      rel={isExternal ? "noopener noreferrer" : undefined}
      className="text-primary hover:underline inline-flex items-center"
    >
      {children}
      {/* Using Anchor for ExternalLink */}
      {isExternal && <Anchor className="ml-1 h-3 w-3" />}
    </a>
  );
};

const MarkdownRenderer = ({ content, className }) => {
  return (
    <div className={cn("markdown-content prose prose-invert max-w-none", className)}>
      <ReactMarkdown
        remarkPlugins={[remarkGfm]}
        components={{
          h1: ({ node, ...props }) => <h1 className="text-2xl font-bold mt-6 mb-4" {...props} />,
          h2: ({ node, ...props }) => <h2 className="text-xl font-bold mt-5 mb-3" {...props} />,
          h3: ({ node, ...props }) => <h3 className="text-lg font-bold mt-4 mb-2" {...props} />,
          h4: ({ node, ...props }) => <h4 className="text-base font-bold mt-3 mb-2" {...props} />,
          p: ({ node, ...props }) => <p className="my-2" {...props} />,
          a: ({ node, href, children, ...props }) => <InteractiveLink href={href} {...props}>{children}</InteractiveLink>,
          ul: ({ node, ...props }) => <ul className="list-disc pl-6 my-2" {...props} />,
          ol: ({ node, ...props }) => <ol className="list-decimal pl-6 my-2" {...props} />,
          li: ({ node, ...props }) => <li className="my-1" {...props} />,
          blockquote: ({ node, ...props }) => (
            <blockquote className="border-l-4 border-primary pl-4 italic my-4" {...props} />
          ),
          code: ({ node, className, children, ...props }) => { // Removed 'inline' from destructuring
            const match = /language-(\w+)/.exec(className || '');
            const language = match ? match[1] : '';
            const codeContent = String(children).replace(/\n$/, '');

            // Check for special comment to make code block interactive
            const isInteractive = codeContent.includes('// @interactive') ||
                                  codeContent.includes('# @interactive');

            const isBlock = className && /language-(\w+)/.test(className);

            return isBlock ? (
              isInteractive ? (
                <InteractiveCodeBlock
                  language={language}
                  code={codeContent.replace(/\/\/ @interactive|# @interactive/g, '')}
                  className="my-4"
                />
              ) : (
                <SyntaxHighlighter
                  style={vscDarkPlus}
                  language={language}
                  className="rounded-md my-4"
                  showLineNumbers={true}
                  {...props}
                >
                  {codeContent}
                </SyntaxHighlighter>
              )
            ) : (
              <code className="bg-muted px-1 py-0.5 rounded text-sm" {...props}>
                {children}
              </code>
            );
          },
          table: ({ node, ...props }) => (
            <div className="overflow-x-auto my-4">
              <table className="min-w-full divide-y divide-border" {...props} />
            </div>
          ),
          thead: ({ node, ...props }) => <thead className="bg-muted" {...props} />,
          tbody: ({ node, ...props }) => <tbody className="divide-y divide-border" {...props} />,
          tr: ({ node, ...props }) => <tr className="hover:bg-muted/50" {...props} />,
          th: ({ node, ...props }) => (
            <th className="px-4 py-2 text-left text-xs font-medium uppercase tracking-wider" {...props} />
          ),
          td: ({ node, ...props }) => <td className="px-4 py-2 text-sm" {...props} />,
          hr: ({ node, ...props }) => <hr className="my-6 border-border" {...props} />,
          img: ({ node, ...props }) => (
            <img
              className="max-w-full h-auto rounded-md my-4 hover:opacity-90 transition-opacity"
              loading="lazy"
              {...props}
              alt={props.alt || ''}
            />
          ),
        }}
      >
        {content}
      </ReactMarkdown>
    </div>
  );
};

export default MarkdownRenderer;
----
src/ui/formGroup/FormGroup.tsx
import { ReactNode } from 'react';
import { createLogger } from '../../utils/logger';

const logger = createLogger('FormGroup');

// Main Form Group Component
interface FormGroupProps {
  /** Form group label */
  label: string;
  
  /** Unique identifier for the form group */
  id?: string;
  
  /** Form group children (typically form controls) */
  children: ReactNode;
  
  /** Optional help text */
  helpText?: string;
  
  /** Error message to display */
  error?: string;
  
  /** Whether the field is required */
  required?: boolean;
  
  /** Whether this is an advanced setting */
  advanced?: boolean;
  
  /** Additional CSS classes */
  className?: string;
}

/** FormGroup provides consistent layout and styling for form controls */
const FormGroup = ({
  label,
  id,
  children,
  helpText,
  error,
  required = false,
  advanced = false,
  className = '',
}: FormGroupProps) => {
  return (
    <div 
      className={`form-group space-y-2 mb-4 ${advanced ? 'advanced-setting' : ''} ${className}`}
      data-testid={`form-group-${id || label.toLowerCase().replace(/\s+/g, '-')}`}
    >
      <div className="flex justify-between items-center">
        <label 
          htmlFor={id} 
          className={`text-sm font-medium ${error ? 'text-destructive' : ''}`}
        >
          {label}
          {required && <span className="text-destructive ml-1">*</span>}
          {advanced && <span className="text-muted-foreground ml-2 text-xs">(Advanced)</span>}
        </label>
      </div>
      
      <div className="control-wrapper">{children}</div>
      
      {(helpText || error) && (
        <div className="text-xs">
          {error ? (
            <p className="text-destructive">{error}</p>
          ) : helpText ? (
            <p className="text-muted-foreground">{helpText}</p>
          ) : null}
        </div>
      )}
    </div>
  );
};

// Subcomponents for specific form control types
interface FormGroupControlProps {
  /** Control children */
  children: ReactNode;
  
  /** Additional CSS classes */
  className?: string;
}

/** Container for form controls with consistent styling */
const FormGroupControl = ({ children, className = '' }: FormGroupControlProps) => (
  <div className={`w-full ${className}`}>{children}</div>
);

interface FormGroupRowProps {
  /** Row children */
  children: ReactNode;
  
  /** Additional CSS classes */
  className?: string;
}

/** Row layout for horizontal form controls */
const FormGroupRow = ({ children, className = '' }: FormGroupRowProps) => (
  <div className={`flex flex-wrap items-center gap-2 ${className}`}>{children}</div>
);

interface FormGroupColumnProps {
  /** Column children */
  children: ReactNode;
  
  /** Column width (12 = full width) */
  width?: 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12;
  
  /** Additional CSS classes */
  className?: string;
}

/** Column layout for vertical form controls */
const FormGroupColumn = ({ 
  children, 
  width = 12,
  className = '' 
}: FormGroupColumnProps) => {
  const widthClass = `w-${width}/12`;
  
  return (
    <div className={`${widthClass} ${className}`}>{children}</div>
  );
};

// Export the components
export { 
  FormGroup, 
  FormGroupControl,
  FormGroupRow,
  FormGroupColumn
};
----
src/features/auth/initAuth.ts
import { nostrAuth } from '../../services/nostrAuthService';
import { createLogger, createErrorMetadata } from '../../utils/logger';

const logger = createLogger('initAuth');

/**
 * Initialize the authentication system
 */
export async function initializeAuth(): Promise<void> {
  try {
    // Initialize Nostr auth service
    await nostrAuth.initialize();
    
    logger.info('Auth system initialized successfully');
  } catch (error) {
    logger.error('Failed to initialize auth system:', createErrorMetadata(error));
    throw error;
  }
}

----
src/features/auth/components/NostrAuthSection.tsx
import React, { useEffect } from 'react'
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '../../../ui/Card'
import AuthUIHandler from './AuthUIHandler'
import { initializeAuth } from '../initAuth'
import { createLogger, createErrorMetadata } from '../../../utils/logger'

const logger = createLogger('NostrAuthSection');

const NostrAuthSection: React.FC = () => {
  useEffect(() => {
    // Initialize auth system when component mounts
    initializeAuth().catch(error => {
      logger.error('Failed to initialize auth system:', createErrorMetadata(error));
    });
  }, []);

  return (
    // Explicitly set dark background and text for the card to ensure theme consistency
    <Card className="bg-card text-card-foreground border-border">
      <CardHeader>
        <CardTitle>Nostr Authentication</CardTitle>
        <CardDescription>Authenticate with your Nostr key to unlock advanced features.</CardDescription>
      </CardHeader>
      <CardContent className="flex flex-col space-y-2">
        <AuthUIHandler />
      </CardContent>
    </Card>
  )
}

export default NostrAuthSection

----
src/features/auth/components/AuthUIHandler.tsx
import React, { useEffect, useState } from 'react';
import { nostrAuth, AuthState } from '../../../services/nostrAuthService';
import { createLogger, createErrorMetadata } from '../../../utils/logger';
import { Button } from '../../../ui/Button';
import { Card, CardContent } from '../../../ui/Card';

const logger = createLogger('AuthUIHandler');

interface AuthUIHandlerProps {
  className?: string;
}

/**
 * AuthUIHandler component that handles the UI for authentication
 */
const AuthUIHandler: React.FC<AuthUIHandlerProps> = ({ className = '' }) => {
  const [authState, setAuthState] = useState<AuthState>({
    authenticated: false
  });
  const [isLoading, setIsLoading] = useState(false);

  useEffect(() => {
    // Subscribe to auth state changes
    const unsubscribe = nostrAuth.onAuthStateChanged((state) => {
      setAuthState(state);
    });

    // Cleanup subscription on unmount
    return () => {
      unsubscribe();
    };
  }, []);

  const handleLogin = async () => {
    try {
      setIsLoading(true);
      await nostrAuth.login();
    } catch (error) {
      logger.error('Login failed:', createErrorMetadata(error));
      // Error is already handled by the auth service and will be in authState
    } finally {
      setIsLoading(false);
    }
  };

  const handleLogout = async () => {
    try {
      setIsLoading(true);
      await nostrAuth.logout();
    } catch (error) {
      logger.error('Logout failed:', createErrorMetadata(error));
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className={`auth-ui-handler ${className}`}>
      {authState.authenticated && authState.user ? (
        <div className="user-info space-y-4">
          <div className="flex flex-col space-y-2">
            <div className="flex items-center justify-between">
              <span className="text-sm text-gray-400">Logged in as:</span>
              <span className="font-mono text-sm">
                {authState.user.pubkey.slice(0, 8)}...{authState.user.pubkey.slice(-8)}
              </span>
            </div>
            <div className="flex items-center justify-between">
              <span className="text-sm text-gray-400">Role:</span>
              <span className="text-sm font-medium">
                {authState.user.isPowerUser ? 'Power User' : 'Authenticated User'}
              </span>
            </div>
          </div>
          <Button 
            variant="destructive" 
            onClick={handleLogout} 
            disabled={isLoading}
            className="w-full"
          >
            {isLoading ? 'Logging out...' : 'Logout'}
          </Button>
        </div>
      ) : (
        <div className="space-y-4">
          <Button 
            onClick={handleLogin} 
            disabled={isLoading}
            className="w-full"
          >
            {isLoading ? 'Connecting...' : 'Login with Nostr'}
          </Button>
          {authState.error && (
            <div className="text-red-500 text-sm mt-2">{authState.error}</div>
          )}
        </div>
      )}
    </div>
  );
};

export default AuthUIHandler;

----
src/features/auth/hooks/useAuth.ts
import { useState, useEffect } from 'react';
import { useSettingsStore } from '../../../store/settingsStore';
import { createLogger, createErrorMetadata } from '../../../utils/logger';
import { nostrAuth, AuthState } from '../../../services/nostrAuthService';

const logger = createLogger('useAuth');

/**
 * Hook for accessing Nostr authentication functionality
 * This hook synchronizes the auth state with the settings store
 */
const useAuth = () => {
  const { setAuthenticated, setUser, authenticated, user } = useSettingsStore();
  const [authError, setAuthError] = useState<string | null>(null);
  const [isLoading, setIsLoading] = useState(false);

  // Listen for auth state changes and update the settings store
  useEffect(() => {
    const unsubscribe = nostrAuth.onAuthStateChanged((state: AuthState) => {
      if (state.authenticated && state.user) {
        setAuthenticated(true);
        setUser({
          isPowerUser: state.user.isPowerUser,
          pubkey: state.user.pubkey
        });
        setAuthError(null);
      } else {
        setAuthenticated(false);
        setUser(null);
        if (state.error) {
          setAuthError(state.error);
        }
      }
    });

    return () => {
      unsubscribe();
    };
  }, [setAuthenticated, setUser]);

  const login = async () => {
    try {
      setIsLoading(true);
      setAuthError(null);
      await nostrAuth.login();
      logger.info('Login successful');
    } catch (error) {
      logger.error('Login failed:', createErrorMetadata(error));
      setAuthError(error instanceof Error ? error.message : 'Login failed');
    } finally {
      setIsLoading(false);
    }
  };

  const logout = async () => {
    try {
      setIsLoading(true);
      setAuthError(null);
      await nostrAuth.logout();
      logger.info('Logout successful');
    } catch (error) {
      logger.error('Logout failed:', createErrorMetadata(error));
      setAuthError(error instanceof Error ? error.message : 'Logout failed');
    } finally {
      setIsLoading(false);
    }
  };

  return {
    authenticated,
    user,
    authError,
    isLoading,
    login,
    logout,
  };
};

export default useAuth;
----
src/features/visualisation/managers/sceneManager.ts
// Stub implementation of SceneManager to prevent conflicts with React Three Fiber
import { createLogger, createErrorMetadata } from '@/utils/logger';
import { debugState } from '@/utils/debugState';
import * as THREE from 'three';
import { XRSettings } from '@/features/xr/types/xr';

const logger = createLogger('SceneManager');

/**
 * IMPORTANT: This is a stub implementation of SceneManager
 * The application has been migrated to use React Three Fiber
 * This stub exists only to satisfy imports and prevent runtime errors
 */

export class SceneManager {
  private static instance: SceneManager;
  private scene: any = {};
  private camera: THREE.PerspectiveCamera | null = null;
  private renderer: THREE.WebGLRenderer | null = null;
  private running: boolean = false;
  private renderCallbacks: any[] = [];
  private resizeCallbacks: any[] = [];
  private disposeCallbacks: any[] = [];

  private constructor() {
    logger.info('Using React Three Fiber for rendering - SceneManager is in compatibility mode');
    
    // Create minimal THREE.js objects to prevent errors
    try {
      this.scene = new THREE.Scene();
      // Create perspective camera specifically since XR systems need it
      this.camera = new THREE.PerspectiveCamera(
        75, // FOV
        window.innerWidth / window.innerHeight, // Aspect ratio
        0.1, // Near plane
        1000 // Far plane
      );
      this.camera.position.z = 5;
    } catch (error) {
      logger.error('Error creating THREE.js objects:', createErrorMetadata(error));
      // Fall back to mock objects if THREE.js fails to initialize
    }
  }

  public static getInstance(canvas?: HTMLCanvasElement): SceneManager {
    if (!SceneManager.instance) {
      SceneManager.instance = new SceneManager();
    }
    return SceneManager.instance;
  }

  public static cleanup(): void {
    if (SceneManager.instance) {
      logger.info('SceneManager cleanup called');
    }
  }

  // Stub methods that do nothing
  private initRenderer(canvas: HTMLCanvasElement): void {
    // Only try to initialize if we don't already have a renderer
    if (this.renderer) return;
    
    try {
      logger.info('Attempting to create WebGLRenderer (compatibility mode)');
      
      // Verify that the canvas is valid
      if (!canvas || !canvas.getContext) {
        throw new Error('Invalid canvas element or getContext is not a function');
      }
      
      // Try to create a renderer with minimal settings
      this.renderer = new THREE.WebGLRenderer({
        canvas,
        alpha: true,
        antialias: true,
        powerPreference: 'default'
      });
      
      this.renderer.setSize(window.innerWidth, window.innerHeight);
      this.renderer.setPixelRatio(window.devicePixelRatio);
      
    } catch (error) {
      logger.error('Failed to initialize renderer:', createErrorMetadata(error));
      
      // Create a mock renderer to prevent further errors
      this.renderer = {
        domElement: canvas,
        setSize: () => {},
        render: () => {},
        dispose: () => {}
      } as unknown as THREE.WebGLRenderer;
    }
  }
  
  private setupResizeHandler(): void {}
  public handleSettingsUpdate(settings: XRSettings): void {
    if (debugState.isEnabled()) {
      logger.info('SceneManager.start() called but using React Three Fiber instead');
    }
  }

  public stop(): void {}
  private render = (): void => {};
  public addRenderCallback(callback: () => void): () => void {
    return () => {};
  }
  public addResizeCallback(callback: () => void): () => void {
    // Store callback in array but don't actually use it
    this.resizeCallbacks.push(callback);
    // Return remove function
    return () => {
      const index = this.resizeCallbacks.indexOf(callback);
      if (index !== -1) {
        this.resizeCallbacks.splice(index, 1);
      }
    };
  }
  
  public start(): void {
    logger.info('SceneManager.start() called (compatibility mode - no action taken)');
    this.running = true;
  }
  
  public dispose(): void {
    logger.info('SceneManager.dispose() called (compatibility mode)');
    this.running = false;
  }
  
  // Getters
  public getScene(): any {
    return this.scene;
  }
  public getCamera = (): THREE.PerspectiveCamera | null => this.camera;
  public getRenderer = (): THREE.WebGLRenderer | null => this.renderer;
  public isRunning(): boolean {
    return this.running;
  }
}
----
src/features/visualisation/utils/animations.ts
/**
 * Animation System
 * 
 * This file provides animation utilities and presets for UI components.
 * It's designed to create consistent animations throughout the application.
 */

import { useEffect, useState } from 'react';

// Common timing curves (easing functions)
export const timingFunctions = {
  linear: 'linear',
  easeIn: 'cubic-bezier(0.4, 0, 1, 1)',
  easeOut: 'cubic-bezier(0, 0, 0.2, 1)',
  easeInOut: 'cubic-bezier(0.4, 0, 0.2, 1)',
  // Custom spring-like curve for natural motion
  spring: 'cubic-bezier(0.175, 0.885, 0.32, 1.275)',
  // Bounce effect
  bounce: 'cubic-bezier(0.175, 0.885, 0.32, 1.5)',
};

// Animation timing presets (in milliseconds)
export const timingPresets = {
  fast: 150,
  normal: 250, 
  slow: 350,
  verySlow: 500,
};

// Animation variants for different UI elements
export const animationVariants = {
  // Fade animations
  fade: {
    in: {
      from: { opacity: 0 },
      to: { opacity: 1 },
    },
    out: {
      from: { opacity: 1 },
      to: { opacity: 0 },
    },
  },
  
  // Slide animations
  slideUp: {
    in: {
      from: { transform: 'translateY(10px)', opacity: 0 },
      to: { transform: 'translateY(0)', opacity: 1 },
    },
    out: {
      from: { transform: 'translateY(0)', opacity: 1 },
      to: { transform: 'translateY(-10px)', opacity: 0 },
    },
  },
  
  slideDown: {
    in: {
      from: { transform: 'translateY(-10px)', opacity: 0 },
      to: { transform: 'translateY(0)', opacity: 1 },
    },
    out: {
      from: { transform: 'translateY(0)', opacity: 1 },
      to: { transform: 'translateY(10px)', opacity: 0 },
    },
  },
  
  slideLeft: {
    in: {
      from: { transform: 'translateX(10px)', opacity: 0 },
      to: { transform: 'translateX(0)', opacity: 1 },
    },
    out: {
      from: { transform: 'translateX(0)', opacity: 1 },
      to: { transform: 'translateX(-10px)', opacity: 0 },
    },
  },
  
  slideRight: {
    in: {
      from: { transform: 'translateX(-10px)', opacity: 0 },
      to: { transform: 'translateX(0)', opacity: 1 },
    },
    out: {
      from: { transform: 'translateX(0)', opacity: 1 },
      to: { transform: 'translateX(10px)', opacity: 0 },
    },
  },
  
  // Scale animations
  scale: {
    in: {
      from: { transform: 'scale(0.95)', opacity: 0 },
      to: { transform: 'scale(1)', opacity: 1 },
    },
    out: {
      from: { transform: 'scale(1)', opacity: 1 },
      to: { transform: 'scale(0.95)', opacity: 0 },
    },
  },
  
  // Panel animations
  panel: {
    in: {
      from: { transform: 'translateX(100%)', opacity: 0 },
      to: { transform: 'translateX(0)', opacity: 1 },
    },
    out: {
      from: { transform: 'translateX(0)', opacity: 1 },
      to: { transform: 'translateX(100%)', opacity: 0 },
    },
  },
  
  // Shake animation for error or attention
  shake: {
    keyframes: [
      { transform: 'translateX(0)' },
      { transform: 'translateX(-5px)' },
      { transform: 'translateX(5px)' },
      { transform: 'translateX(-5px)' },
      { transform: 'translateX(5px)' },
      { transform: 'translateX(-5px)' },
      { transform: 'translateX(0)' }
    ],
  },
};

/**
 * CSS transition string creator for inline styles
 * @param properties CSS properties to animate
 * @param duration Animation duration in ms
 * @param timingFunction Easing function
 * @param delay Delay before animation starts (in ms)
 * @returns CSS transition string
 */
export function createTransition(
  properties: string[] = ['all'],
  duration: number = timingPresets.normal,
  timingFunction: string = timingFunctions.easeInOut,
  delay: number = 0
): string {
  return properties
    .map(prop => `${prop} ${duration}ms ${timingFunction} ${delay}ms`)
    .join(', ');
}

/**
 * Hook to create animated transitions on mount/unmount
 * @param visible Whether the element is visible
 * @param duration Animation duration in ms
 * @param delay Delay before animation starts (in ms)
 * @returns Whether to render the element at all
 */
export function useAnimatedVisibility(
  visible: boolean,
  duration: number = timingPresets.normal,
  delay: number = 0
): { shouldRender: boolean; animationState: 'entering' | 'entered' | 'exiting' | 'exited' } {
  const [shouldRender, setShouldRender] = useState(visible);
  const [animationState, setAnimationState] = useState<'entering' | 'entered' | 'exiting' | 'exited'>(
    visible ? 'entered' : 'exited'
  );
  
  useEffect(() => {
    let timeoutId: number;
    
    if (visible) {
      setShouldRender(true);
      // Wait one frame to trigger enter animation
      requestAnimationFrame(() => {
        setAnimationState('entering');
        timeoutId = window.setTimeout(() => {
          setAnimationState('entered');
        }, duration);
      });
    } else {
      setAnimationState('exiting');
      timeoutId = window.setTimeout(() => {
        setAnimationState('exited');
        setShouldRender(false);
      }, duration);
    }
    
    return () => {
      clearTimeout(timeoutId);
    };
  }, [visible, duration]);
  
  return { shouldRender, animationState };
}

/**
 * Hook to perform performance-aware animations
 * Reduces animation complexity on low-end devices
 */
export function usePerformanceAwareAnimation(
  preferredAnimation: 'fade' | 'slide' | 'scale' | 'none' = 'fade'
): 'fade' | 'slide' | 'scale' | 'none' {
  const [reducedMotion, setReducedMotion] = useState(false);
  const [lowPerformance, setLowPerformance] = useState(false);
  
  useEffect(() => {
    // Check for reduced motion preference
    const mediaQuery = window.matchMedia('(prefers-reduced-motion: reduce)');
    setReducedMotion(mediaQuery.matches);
    
    const handleChange = (e: MediaQueryListEvent) => {
      setReducedMotion(e.matches);
    };
    
    mediaQuery.addEventListener('change', handleChange);
    
    // Detect low performance devices (simple heuristic)
    if (
      navigator.hardwareConcurrency <= 2 || // CPU cores      
      ('deviceMemory' in navigator && (navigator as any).deviceMemory <= 2) // RAM in GB, not available in all browsers
    ) {
      // Set low performance mode to reduce animations and effects
      setLowPerformance(true);
    }
    
    return () => {
      mediaQuery.removeEventListener('change', handleChange);
    };
  }, []);
  
  // Return appropriate animation based on device capabilities
  if (reducedMotion) return 'none';
  if (lowPerformance) return 'fade'; // Simplest animation for low-end devices
  return preferredAnimation;
}
----
src/features/visualisation/renderers/TextRenderer.tsx
import React, { useRef, useEffect, useState, useMemo } from 'react';
import { useThree } from '@react-three/fiber';
import { Text, Billboard } from '@react-three/drei';
import { Vector3, Group, DoubleSide } from 'three';
import { useSettingsStore } from '@/store/settingsStore';
import { createLogger, createErrorMetadata } from '@/utils/logger';

// This interface should match the structure of `settings.visualisation.labels` from the store.
interface LabelSettings {
  enabled?: boolean; // Made optional to align with store type
  desktopFontSize: number;
  textColor: string;
  textOutlineColor?: string;
  textOutlineWidth?: number;
  textPadding?: number;
  textResolution?: number;
  billboardMode?: string;
  // Properties used by Label component's logic, not directly from store's main label config
  showDistance?: number;
  fadeDistance?: number;
  backgroundColor?: string;
}

const logger = createLogger('TextRenderer');

export interface LabelData {
  id: string;
  text: string;
  position: Vector3;
}

interface TextRendererProps {
  labels?: LabelData[];
}

export const TextRenderer: React.FC<TextRendererProps> = ({ labels = [] }) => {
  const { camera } = useThree();
  const groupRef = useRef<Group>(null);
  const settings = useSettingsStore(state => state.settings?.visualisation?.labels as LabelSettings | undefined);
  
  if (!settings || !settings.enabled) {
    return null;
  }

  return (
    <group ref={groupRef}>
      {labels.map((label) => (
        <Label
          key={label.id}
          text={label.text}
          position={label.position}
          settings={settings} // Pass the settings object from the store
        />
      ))}
    </group>
  );
};

interface LabelProps {
  text: string;
  position: Vector3;
  settings: LabelSettings; // This prop will receive the object from the store
}

const Label: React.FC<LabelProps> = ({ text, position, settings }) => {
  // Skip rendering empty labels
  if (!text.trim()) return null;
  
  const textColor = settings.textColor; // Use textColor from settings
  const fontSize = settings.desktopFontSize; // Use desktopFontSize from settings
  const showDistance = settings.showDistance || 0;
  const fadeDistance = settings.fadeDistance || 0;
  const backgroundColor = settings.backgroundColor;
  
  // Calculate distance to camera to handle fade effect
  const { camera } = useThree();
  const [opacity, setOpacity] = useState(1);
  
  useEffect(() => {
    if (!fadeDistance) return;
    
    const updateOpacity = () => {
      const distance = camera.position.distanceTo(position);
      
      if (distance > fadeDistance) {
        setOpacity(0);
      } else if (distance > showDistance) {
        // Linear fade from showDistance to fadeDistance
        const fadeRatio = 1 - ((distance - showDistance) / (fadeDistance - showDistance));
        setOpacity(Math.max(0, Math.min(1, fadeRatio)));
      } else {
        setOpacity(1);
      }
    };
    
    updateOpacity();
    
    // Add event listener for camera movements
    window.addEventListener('camerachange', updateOpacity);
    return () => {
      window.removeEventListener('camerachange', updateOpacity);
    };
  }, [camera, position, showDistance, fadeDistance]);
  
  // Don't render if fully transparent
  if (opacity <= 0) return null;
  
  return (
    <Billboard
      position={position}
      follow={true}
      lockX={false}
      lockY={false}
      lockZ={false}
    >
      <Text
        fontSize={fontSize}
        color={textColor}
        anchorX="center"
        anchorY="middle"
        outlineWidth={0.02}
        outlineColor="#000000"
        outlineOpacity={0.8}
        overflowWrap="normal"
        maxWidth={10}
        textAlign="center"
        renderOrder={10} // Ensure text renders on top of other objects
        material-depthTest={false} // Make sure text is always visible
        material-transparent={true}
        material-opacity={opacity}
      >
        {text}
        {backgroundColor && (
          <meshBasicMaterial 
            color={backgroundColor} 
            opacity={opacity * 0.7}
            transparent={true}
            side={DoubleSide}
          />
        )}
      </Text>
    </Billboard>
  );
};

// Class-based implementation that can be used outside React components
export class TextRendererManager {
  private static instance: TextRendererManager;
  private labels: Map<string, LabelData> = new Map();
  private updateCallback: (() => void) | null = null;
  
  private constructor() {
    // Private constructor for singleton
  }
  
  public static getInstance(): TextRendererManager {
    if (!TextRendererManager.instance) {
      TextRendererManager.instance = new TextRendererManager();
    }
    return TextRendererManager.instance;
  }
  
  public setUpdateCallback(callback: () => void): void {
    this.updateCallback = callback;
  }
  
  public updateLabel(id: string, text: string, position: Vector3, preserveText: boolean = false): void {
    try {
      const existingLabel = this.labels.get(id);
      
      // Skip processing if text is empty but preserveText is true and we already have a label
      if (text.trim() === '' && preserveText && existingLabel) {
        existingLabel.position.copy(position);
        this.triggerUpdate();
        return;
      }
      
      if (!existingLabel) {
        this.labels.set(id, {
          id,
          text: text || '',
          position: position.clone()
        });
      } else {
        // Only update text if non-empty text is provided
        if (text.trim() !== '') {
          existingLabel.text = text;
        }
        // Always update position
        existingLabel.position.copy(position);
      }
      
      this.triggerUpdate();
    } catch (error) {
      logger.error('Error updating label:', createErrorMetadata(error));
    }
  }
  
  public removeLabel(id: string): void {
    try {
      this.labels.delete(id);
      this.triggerUpdate();
    } catch (error) {
      logger.error('Error removing label:', createErrorMetadata(error));
    }
  }
  
  public getAllLabels(): LabelData[] {
    return Array.from(this.labels.values());
  }
  
  public clearLabels(): void {
    this.labels.clear();
    this.triggerUpdate();
  }
  
  private triggerUpdate(): void {
    if (this.updateCallback) {
      this.updateCallback();
    }
  }
}

// Create a hook for using the TextRendererManager in React components
export const useTextRenderer = () => {
  const textRendererManager = useMemo(() => TextRendererManager.getInstance(), []);
  const [labels, setLabels] = useState<LabelData[]>([]);
  
  useEffect(() => {
    textRendererManager.setUpdateCallback(() => {
      setLabels([...textRendererManager.getAllLabels()]);
    });
    
    return () => {
      textRendererManager.setUpdateCallback(null);
    };
  }, [textRendererManager]);
  
  return {
    labels,
    updateLabel: textRendererManager.updateLabel.bind(textRendererManager),
    removeLabel: textRendererManager.removeLabel.bind(textRendererManager),
    clearLabels: textRendererManager.clearLabels.bind(textRendererManager)
  };
};

export default TextRenderer;
----
src/features/visualisation/renderers/HologramManager.tsx
import React, { useRef, useEffect, useState } from 'react';
import * as THREE from 'three';
import { useFrame } from '@react-three/fiber';
import { useSettingsStore } from '@/store/settingsStore';
import { createLogger } from '@/utils/logger';
import { HologramMaterial } from './materials/HologramMaterial';

const logger = createLogger('HologramManager');

// Component for an individual hologram ring
export const HologramRing: React.FC<{
  size?: number;
  color?: string | THREE.Color | number;
  opacity?: number;
  rotationAxis?: readonly [number, number, number];
  rotationSpeed?: number;
  segments?: number;
}> = ({
  size = 1,
  color = '#00ffff',
  opacity = 0.7,
  rotationAxis = [0, 1, 0],
  rotationSpeed = 0.5,
  segments = 64
}) => {
  // Use state for rotation instead of imperatively updating refs
  const [rotation, setRotation] = useState<[number, number, number]>([0, 0, 0]);

  // Animate ring rotation
  useFrame((_, delta) => {
    if (rotationSpeed > 0) {
      setRotation(prev => [
        prev[0] + delta * rotationSpeed * rotationAxis[0],
        prev[1] + delta * rotationSpeed * rotationAxis[1],
        prev[2] + delta * rotationSpeed * rotationAxis[2]
      ]);
    }
  });

  return (
    <mesh rotation={rotation}>
      <ringGeometry args={[size * 0.8, size, segments]} />
      <meshBasicMaterial color={color} transparent={true} opacity={opacity} wireframe={true} />
    </mesh>
  );
};

// Component for a hologram sphere
export const HologramSphere: React.FC<{
  size?: number;
  color?: string | THREE.Color | number;
  opacity?: number;
  detail?: number;
  wireframe?: boolean;
  rotationSpeed?: number;
}> = ({
  size = 1,
  color = '#00ffff',
  opacity = 0.5,
  detail = 1,
  wireframe = true, // Always true for wireframe effect
  rotationSpeed = 0.2
}) => {
  // Use state for rotation instead of imperatively updating refs
  const [rotationY, setRotationY] = useState(0);

  // Animate sphere rotation
  useFrame((_, delta) => {
    if (rotationSpeed > 0) {
      setRotationY(prev => prev + delta * rotationSpeed);
    }
  });

  return (
    <mesh rotation={[0, rotationY, 0]}>
      <icosahedronGeometry args={[size, detail]} />
      <meshBasicMaterial
        color={color}
        transparent={true}
        opacity={opacity}
        wireframe={true}
        toneMapped={false}
      />
    </mesh>
  );
};

// Main HologramManager component that manages multiple hologram elements
export const HologramManager: React.FC<{
  position?: readonly [number, number, number];
  isXRMode?: boolean;
}> = ({
  position = [0, 0, 0],
  isXRMode = false
}) => {
  const settings = useSettingsStore(state => state.settings?.visualisation?.hologram);
  const groupRef = useRef<THREE.Group>(null);

  // Parse sphere sizes from settings
  const sphereSizes: number[] = React.useMemo(() => {
    const sizesSetting: unknown = settings?.sphereSizes; // Start with unknown

    if (typeof sizesSetting === 'string') {
      // Explicitly cast after check
      const strSetting = sizesSetting as string;
      return strSetting.split(',').map(s => parseFloat(s.trim())).filter(n => !isNaN(n));
    } else if (Array.isArray(sizesSetting)) {
      // Filter for numbers within the array
      const arrSetting = sizesSetting as unknown[]; // Cast to unknown array first
      return arrSetting.filter((n): n is number => typeof n === 'number' && !isNaN(n));
    }
    // Default value if setting is missing or invalid
    return [40, 80];
  }, [settings?.sphereSizes]);

  // Set layers for bloom effect
  useEffect(() => {
    const group = groupRef.current;
    if (group) {
      // Use type assertion to get around TypeScript issues
      (group as any).layers.set(0); // Default layer
      (group as any).layers.enable(1); // Bloom layer

      // Apply to all children
      (group as any).traverse((child: any) => {
        if (child.layers) {
          child.layers.set(0);
          child.layers.enable(1);
        }
      });
    }
  }, []);

  const quality = isXRMode ? 'high' : 'medium';
  const color: string | number = settings?.ringColor || '#00ffff'; // Use ringColor instead of color
  const opacity = settings?.ringOpacity !== undefined ? settings.ringOpacity : 0.7;
  const rotationSpeed = settings?.ringRotationSpeed !== undefined ? settings.ringRotationSpeed : 0.5;
  const enableTriangleSphere = settings?.enableTriangleSphere !== false;
  const triangleSphereSize = settings?.triangleSphereSize || 60;
  const triangleSphereOpacity = settings?.triangleSphereOpacity || 0.3;

  return (
    <group ref={groupRef} position={position as any}>
      {/* Render rings based on settings */}
      {sphereSizes.map((size, index) => (
        <HologramRing
          key={`ring-${index}`}
          size={size / 100} // Convert to meters
          color={color}
          opacity={opacity}
          rotationAxis={[
            Math.cos(index * Math.PI / 3),
            Math.sin(index * Math.PI / 3),
            0.5
          ]}
          rotationSpeed={rotationSpeed * (0.8 + index * 0.2)}
          segments={quality === 'high' ? 64 : 32}
        />
      ))}

      {/* Render triangle sphere if enabled */}
      {enableTriangleSphere && (
        <HologramSphere
          size={triangleSphereSize / 100} // Convert to meters
          color={color}
          opacity={triangleSphereOpacity}
          detail={quality === 'high' ? 2 : 1}
          wireframe={true}
        />
      )}
    </group>
  );
};

// A composite hologram component for easy use
export const Hologram: React.FC<{
  position?: readonly [number, number, number];
  color?: string | THREE.Color | number;
  size?: number;
  children?: React.ReactNode;
}> = ({
  position = [0, 0, 0],
  color = '#00ffff',
  size = 1,
  children
}) => {
  return (
    <group position={position as any} scale={size}>
      {children}
      <HologramManager />
    </group>
  );
};

// Class-based wrapper for non-React usage (for backward compatibility)
// Using 'any' types to avoid TypeScript errors with THREE.js
export class HologramManagerClass {
  private scene: any; // THREE.Scene
  private group: any; // THREE.Group
  private ringInstances: any[] = []; // THREE.Mesh[]
  private sphereInstances: any[] = []; // THREE.Mesh[]
  private isXRMode: boolean = false;
  private settings: any;

  constructor(scene: any, settings: any) {
    this.scene = scene;
    this.settings = settings;
    this.group = new THREE.Group();

    // Enable bloom layer
    this.group.layers.set(0);
    this.group.layers.enable(1);

    this.createHolograms();
    this.scene.add(this.group);
  }

  private createHolograms() {
    // Clear existing holograms
    const group = this.group;
    while (group.children.length > 0) {
      const child = group.children[0];
      group.remove(child);

      // Handle geometry and material disposal
      if (child.geometry) child.geometry.dispose();
      if (child.material) {
        if (Array.isArray(child.material)) {
          child.material.forEach((m: any) => m && m.dispose());
        } else {
          child.material.dispose();
        }
      }
    }

    this.ringInstances = [];
    this.sphereInstances = [];

    // Quality based on XR mode
    const quality = this.isXRMode ? 'high' : 'medium';
    const segments = quality === 'high' ? 64 : 32;

    // Extract settings
    const hologramSettings = this.settings?.visualisation?.hologram || {};
    const color = hologramSettings.color || 0x00ffff;
    const opacity = hologramSettings.ringOpacity !== undefined ? hologramSettings.ringOpacity : 0.7;
    const sphereSizes = Array.isArray(hologramSettings.sphereSizes)
      ? hologramSettings.sphereSizes
      : [40, 80];

    // Create ring instances using type assertions for THREE classes
    sphereSizes.forEach((size, index) => {
      // Use any type to bypass TypeScript checks
      const geometry = new (THREE as any).RingGeometry(size * 0.8 / 100, size / 100, segments);
      const material = new (THREE as any).MeshBasicMaterial({
        color: color,
        transparent: true,
        opacity: opacity,
        side: (THREE as any).DoubleSide,
        depthWrite: false
      });

      const ring = new (THREE as any).Mesh(geometry, material);

      // Set random rotation
      ring.rotation.x = Math.PI / 3 * index;
      ring.rotation.y = Math.PI / 6 * index;

      // Enable bloom layer
      ring.layers.set(0);
      ring.layers.enable(1);

      this.ringInstances.push(ring);
      group.add(ring);
    });

    // Create triangle sphere if enabled
    if (hologramSettings.enableTriangleSphere) {
      const size = hologramSettings.triangleSphereSize || 60;
      const sphereOpacity = hologramSettings.triangleSphereOpacity || 0.3;
      const detail = quality === 'high' ? 2 : 1;

      // Use any type to bypass TypeScript checks
      const geometry = new (THREE as any).IcosahedronGeometry(size / 100, detail);
      const material = new (THREE as any).MeshBasicMaterial({
        color: color,
        wireframe: true,
        transparent: true,
        opacity: sphereOpacity,
        side: (THREE as any).DoubleSide,
        depthWrite: false
      });

      const sphere = new (THREE as any).Mesh(geometry, material);

      // Enable bloom layer
      sphere.layers.set(0);
      sphere.layers.enable(1);

      this.sphereInstances.push(sphere);
      group.add(sphere);
    }
  }

  setXRMode(enabled: boolean) {
    this.isXRMode = enabled;
    this.createHolograms();
  }

  update(deltaTime: number) {
    // Get rotation speed from settings
    const rotationSpeed = this.settings?.visualisation?.hologram?.ringRotationSpeed || 0.5;

    // Update ring rotations
    this.ringInstances.forEach((ring: any, index: number) => {
      // Each ring rotates at a different speed
      const speed = rotationSpeed * (1.0 + index * 0.2);
      ring.rotation.y += deltaTime * speed;
    });

    // Update sphere rotations
    this.sphereInstances.forEach((sphere: any) => {
      sphere.rotation.y += deltaTime * rotationSpeed * 0.5;
    });
  }

  updateSettings(newSettings: any) {
    this.settings = newSettings;
    this.createHolograms();
  }

  getGroup() {
    return this.group;
  }

  dispose() {
    this.scene.remove(this.group);

    // Dispose geometries and materials
    this.ringInstances.forEach((ring: any) => {
      if (ring.geometry) ring.geometry.dispose();
      if (ring.material) {
        if (Array.isArray(ring.material)) {
          ring.material.forEach((m: any) => m && m.dispose());
        } else {
          ring.material.dispose();
        }
      }
    });

    this.sphereInstances.forEach((sphere: any) => {
      if (sphere.geometry) sphere.geometry.dispose();
      if (sphere.material) {
        if (Array.isArray(sphere.material)) {
          sphere.material.forEach((m: any) => m && m.dispose());
        } else {
          sphere.material.dispose();
        }
      }
    });

    this.ringInstances = [];
    this.sphereInstances = [];
  }
}

export default HologramManager;
----
src/features/visualisation/renderers/materials/HologramShaderMaterial.ts

----
src/features/visualisation/renderers/materials/HologramMaterial.tsx
// @ts-nocheck
import React, { useRef, useEffect, useState } from 'react';
import * as THREE from 'three';
import { useFrame } from '@react-three/fiber';

/**
 * HologramMaterial - A simplified implementation of hologram effects
 * with better compatibility with the latest Three.js and R3F versions
 * 
 * Note: Using ts-nocheck due to type compatibility issues between Three.js versions.
 * This component works correctly at runtime despite TypeScript errors.
 */
interface HologramMaterialProps {
  color?: string | number | THREE.Color;
  opacity?: number;
  pulseIntensity?: number;
  edgeOnly?: boolean;
  wireframe?: boolean;
  context?: 'desktop' | 'ar';
  onUpdate?: (material: any) => void;
}

export const HologramMaterial: React.FC<HologramMaterialProps> = ({
  color = '#00ffff',
  opacity = 0.7,
  pulseIntensity = 0.2,
  edgeOnly = false,
  wireframe = false,
  context = 'desktop',
  onUpdate
}) => {
  // Create separate refs for different material types
  const materialRef = useRef<any>(null);
  const [currentTime, setCurrentTime] = useState(0);
  
  // Update material each frame with animation effects
  useFrame((_, delta) => {
    setCurrentTime(prev => prev + delta);
    
    // Apply pulse effect
    const pulse = Math.sin(currentTime * 2.0) * 0.5 + 0.5;
    const pulseEffect = pulse * pulseIntensity;
    
    // Update material if it exists
    if (materialRef.current) {
      const mat = materialRef.current;
      
      // Update opacity with pulse
      if (mat.opacity !== undefined) {
        mat.opacity = opacity * (1.0 + pulseEffect * 0.3);
      }
      
      // Update color with pulse
      if (mat.color !== undefined) {
        const brightenFactor = edgeOnly 
          ? 0.5 + pulseEffect * 0.5
          : 0.8 + pulseEffect * 0.3;
        
        // Create pulsing color effect
        mat.color.setStyle(typeof color === 'string' ? color : '#00ffff');
        mat.color.r *= brightenFactor;
        mat.color.g *= brightenFactor;
        mat.color.b *= brightenFactor;
      }
      
      // Force material update
      mat.needsUpdate = true;
      
      // Notify parent about updates
      if (onUpdate) {
        onUpdate(mat);
      }
    }
  });
  
  if (edgeOnly || wireframe) {
    // For edge-only mode, use a simple material with wireframe
    return (
      <meshBasicMaterial 
        ref={materialRef}
        wireframe={true}
        transparent={true}
        opacity={opacity}
        side={context === 'ar' ? THREE.FrontSide : THREE.DoubleSide}
        depthWrite={false}
      >
        <color attach="color" args={[typeof color === 'string' ? color : '#00ffff']} />
      </meshBasicMaterial>
    );
  }
  
  // For full hologram mode, use standard material with custom properties
  return (
    <meshPhysicalMaterial
      ref={materialRef}
      transparent={true}
      opacity={opacity}
      metalness={0.2}
      roughness={0.2}
      transmission={0.9}
      ior={1.5}
      side={context === 'ar' ? THREE.FrontSide : THREE.DoubleSide}
      depthWrite={false}
    >
      <color attach="color" args={[typeof color === 'string' ? color : '#00ffff']} />
    </meshPhysicalMaterial>
  );
};

/**
 * Class-based wrapper for non-React usage
 * Simplified for better compatibility
 */
export class HologramMaterialClass {
  public material: any;
  private baseOpacity: number;
  private baseColor: string;
  private pulseIntensity: number;
  private currentTime: number = 0;
  private isEdgeOnlyMode: boolean;
  private updateCallback: (() => void) | null = null;
  
  // Provide compatible uniforms structure for backward compatibility
  public uniforms: {
    time: { value: number };
    opacity: { value: number };
    color: { value: any };
    pulseIntensity: { value: number };
    interactionPoint: { value: any };
    interactionStrength: { value: number };
    isEdgeOnly: { value: boolean };
  };
  
  constructor(settings?: any, context: 'ar' | 'desktop' = 'desktop') {
    // Extract settings
    const isAR = context === 'ar';
    const opacity = settings?.visualisation?.hologram?.opacity ?? 0.7;
    const colorValue = settings?.visualisation?.hologram?.color ?? '#00ffff';
    const colorObj = new THREE.Color().setStyle(typeof colorValue === 'string' ? colorValue : '#00ffff');
    const pulseIntensity = isAR ? 0.1 : 0.2; 
    const edgeOnly = false;
    
    this.baseOpacity = opacity;
    this.baseColor = typeof colorValue === 'string' ? colorValue : '#00ffff';
    this.pulseIntensity = pulseIntensity;
    this.isEdgeOnlyMode = edgeOnly;
    
    // Create appropriate material
    if (edgeOnly) {
      this.material = new THREE.MeshBasicMaterial();
      this.material.color.setStyle(this.baseColor);
      this.material.wireframe = true;
      this.material.transparent = true;
      this.material.opacity = opacity;
      this.material.side = isAR ? THREE.FrontSide : THREE.DoubleSide;
      this.material.depthWrite = false;
    } else {
      // Use MeshPhysicalMaterial
      this.material = new THREE.MeshPhysicalMaterial();
      this.material.color.setStyle(this.baseColor);
      this.material.metalness = 0.1;
      this.material.roughness = 0.2;
      this.material.transmission = 0.95;
      this.material.transparent = true;
      this.material.opacity = opacity;
      this.material.side = isAR ? THREE.FrontSide : THREE.DoubleSide;
      this.material.depthWrite = false;
      this.material.ior = 1.5;
    }
    
    // Initialize uniforms for API compatibility
    this.uniforms = {
      time: { value: 0 },
      opacity: { value: opacity },
      color: { value: colorObj },
      pulseIntensity: { value: pulseIntensity },
      interactionPoint: { value: new THREE.Vector3() },
      interactionStrength: { value: 0.0 },
      isEdgeOnly: { value: edgeOnly }
    };
  }
  
  public update(deltaTime: number): void {
    // Update time
    this.currentTime += deltaTime;
    this.uniforms.time.value = this.currentTime;
    
    // Apply pulse effect
    const pulse = Math.sin(this.currentTime * 2.0) * 0.5 + 0.5;
    const pulseEffect = pulse * this.pulseIntensity;
    
    // Update material properties
    if (this.material) {
      // Update opacity
      if (this.material.opacity !== undefined) {
        this.material.opacity = this.baseOpacity * (1.0 + pulseEffect * 0.3);
      }
      
      // Update color
      if (this.material.color !== undefined) {
        const brightenFactor = this.isEdgeOnlyMode 
          ? 0.5 + pulseEffect * 0.5
          : 0.8 + pulseEffect * 0.3;
        
        // Create pulsing color effect
        const color = new THREE.Color().setStyle(this.baseColor);
        color.r *= brightenFactor;
        color.g *= brightenFactor;
        color.b *= brightenFactor;
        this.material.color.copy(color);
      }
      
      // Force material update
      this.material.needsUpdate = true;
    }
    
    // Handle interaction effect
    if (this.uniforms.interactionStrength.value > 0.01) {
      this.uniforms.interactionStrength.value *= 0.95; // Decay interaction effect
    }
    
    // Trigger update callback if exists
    if (this.updateCallback) {
      this.updateCallback();
    }
  }
  
  public handleInteraction(position: THREE.Vector3): void {
    this.uniforms.interactionPoint.value.copy(position);
    this.uniforms.interactionStrength.value = 1.0;
  }
  
  public setEdgeOnly(enabled: boolean): void {
    // Store the state
    this.isEdgeOnlyMode = enabled;
    this.uniforms.isEdgeOnly.value = enabled;
    
    // Create a new material based on mode
    const oldMaterial = this.material;
    
    if (enabled) {
      // Switch to wireframe material
      const newMaterial = new THREE.MeshBasicMaterial();
      newMaterial.color.setStyle(this.baseColor);
      newMaterial.wireframe = true;
      newMaterial.transparent = true;
      newMaterial.opacity = this.baseOpacity * 0.8;
      newMaterial.side = oldMaterial.side;
      newMaterial.depthWrite = false;
      
      // Replace material
      if (oldMaterial && oldMaterial.dispose) {
        oldMaterial.dispose();
      }
      this.material = newMaterial;
      this.pulseIntensity = 0.15;
      
    } else {
      // Switch to physical material
      const newMaterial = new THREE.MeshPhysicalMaterial();
      newMaterial.color.setStyle(this.baseColor);
      newMaterial.metalness = 0.1;
      newMaterial.roughness = 0.2;
      newMaterial.transmission = 0.95;
      newMaterial.transparent = true;
      newMaterial.opacity = this.baseOpacity;
      newMaterial.side = oldMaterial.side;
      newMaterial.depthWrite = false;
      newMaterial.ior = 1.5;
      
      // Replace material
      if (oldMaterial && oldMaterial.dispose) {
        oldMaterial.dispose();
      }
      this.material = newMaterial;
      this.pulseIntensity = 0.1;
    }
    
    // Update uniform for API compatibility
    this.uniforms.pulseIntensity.value = this.pulseIntensity;
  }
  
  public getMaterial(): any {
    return this.material;
  }
  
  public setUpdateCallback(callback: () => void): void {
    this.updateCallback = callback;
  }
  
  public clone(): HologramMaterialClass {
    // Create settings object from current state
    const settings = {
      visualisation: {
        hologram: {
          opacity: this.baseOpacity,
          color: this.baseColor
        }
      }
    };
    
    // Create new instance
    const clone = new HologramMaterialClass(
      settings,
      this.material.side === THREE.FrontSide ? 'ar' : 'desktop'
    );
    
    // Copy current state
    clone.isEdgeOnlyMode = this.isEdgeOnlyMode;
    clone.setEdgeOnly(this.isEdgeOnlyMode);
    
    return clone;
  }
  
  public dispose(): void {
    if (this.material && this.material.dispose) {
      this.material.dispose();
    }
  }
}

// HologramComponent for use with React Three Fiber
export const HologramComponent: React.FC<{
  children?: React.ReactNode;
  position?: [number, number, number];
  rotation?: [number, number, number];
  scale?: number | [number, number, number];
  color?: string | number | THREE.Color;
  opacity?: number;
  edgeOnly?: boolean;
  rings?: boolean;
  rotationSpeed?: number;
}> = ({
  children,
  position = [0, 0, 0],
  rotation = [0, 0, 0],
  scale = 1,
  color = '#00ffff',
  opacity = 0.7,
  edgeOnly = false,
  rings = true,
  rotationSpeed = 0.5
}) => {
  // Ref for the group to apply rotation animation
  const groupRef = useRef<THREE.Group>(null);
  
  // Animate rotation
  useFrame((_, delta) => {
    if (groupRef.current && rotationSpeed > 0) {
      // Apply manual rotation to avoid type errors
      const rotation = groupRef.current.rotation;
      if (rotation) {
        rotation.y += delta * rotationSpeed;
      }
    }
  });
  
  return (
    <group position={position} rotation={rotation} scale={scale}>
      {/* Main hologram content */}
      <group ref={groupRef}>
        {children || (
          // Default sphere if no children provided
          <mesh>
            <icosahedronGeometry args={[1, 1]} />
            <HologramMaterial color={color} opacity={opacity} edgeOnly={edgeOnly} />
          </mesh>
        )}
        
        {/* Rings (optional) */}
        {rings && (
          <>
            <mesh rotation={[Math.PI/2, 0, 0]}>
              <ringGeometry args={[0.8, 1, 32]} />
              <HologramMaterial color={color} opacity={opacity * 0.8} pulseIntensity={0.3} />
            </mesh>
            <mesh rotation={[0, Math.PI/3, Math.PI/3]}>
              <ringGeometry args={[1.2, 1.4, 32]} />
              <HologramMaterial color={color} opacity={opacity * 0.6} pulseIntensity={0.2} />
            </mesh>
          </>
        )}
      </group>
    </group>
  );
};

export default HologramComponent;
----
src/features/visualisation/types/visualisationTypes.ts
import { XRSettings } from '../../xr/types/xr';

export interface VisualisationSettings {
  nodes: {
    color: string;
    defaultSize: number;
    opacity: number;
  };
  edges: {
    color: string;
    width: number;
    opacity: number;
  };
  xr: XRSettings;
}
----
src/features/visualisation/components/ActionButtons.tsx
import { useState } from 'react'
import { Button } from '../../../ui/Button' // Corrected path
import { Card, CardContent, CardHeader, CardTitle } from '../../../ui/Card' // Corrected path
import { createLogger } from '../../../utils/logger' // Corrected path from lib/utils to utils

const logger = createLogger('ActionButtons')

export function ActionButtons() {
  const [isRandomizing, setIsRandomizing] = useState(false)

  // Function to randomize node positions
  const handleRandomizeNodes = async () => {
    try {
      setIsRandomizing(true)
      
      // In the real implementation, this would call the visualisation controller
      // For now, we just simulate the action with a timeout
      logger.info('Randomizing node positions')
      
      // Simulate network request delay
      await new Promise(resolve => setTimeout(resolve, 1000))
      
      // Success message (in a real implementation, this would be after confirmation from the controller)
      logger.info('Node positions randomized successfully')
    } catch (error) {
      logger.error('Failed to randomize node positions:', error)
    } finally {
      setIsRandomizing(false)
    }
  }

  return (
    <Card className="settings-section mb-4">
      <CardHeader className="py-2 px-4">
        <CardTitle className="text-sm font-medium">Actions</CardTitle>
      </CardHeader>
      <CardContent className="p-2 pt-0">
        <div className="flex flex-wrap gap-2">
          <Button 
            variant="secondary" 
            size="sm"
            disabled={isRandomizing}
            onClick={handleRandomizeNodes}
          >
            {isRandomizing ? 'Randomizing...' : 'Randomly Distribute Nodes'}
          </Button>
          
          {/* More action buttons can be added here */}
        </div>
      </CardContent>
    </Card>
  )
}
----
src/features/visualisation/components/MetadataVisualizer.tsx
import React, { useRef, useEffect, useState, useMemo } from 'react';
import * as THREE from 'three'; // Use namespace import
import { useThree, useFrame } from '@react-three/fiber';
// import { Text, Billboard, useTexture } from '@react-three/drei'; // Commented out due to import errors
import { usePlatform } from '@/services/platformManager';
import { useSettingsStore } from '@/store/settingsStore';
import { createLogger } from '@/utils/logger';

const logger = createLogger('MetadataVisualizer');

// Type guard to check for Vector3 instance using instanceof
// Reverting to instanceof check as property check didn't resolve TS errors
function isVector3Instance(obj: any): obj is THREE.Vector3 {
  // Check if Vector3 constructor exists on THREE before using instanceof
  return typeof THREE.Vector3 === 'function' && obj instanceof THREE.Vector3;
}


// Types for metadata and labels
export interface NodeMetadata {
  id: string;
  position: [number, number, number] | { x: number; y: number; z: number } | THREE.Vector3;
  label?: string;
  description?: string;
  fileSize?: number;
  type?: string;
  color?: string | number;
  icon?: string;
  priority?: number;
  [key: string]: any; // Allow additional properties
}

interface MetadataVisualizerProps {
  children?: React.ReactNode;
  renderLabels?: boolean;
  renderIcons?: boolean;
  renderMetrics?: boolean;
}

/**
 * MetadataVisualizer component using React Three Fiber
 * This is a modernized version of the original MetadataVisualizer class
 */
export const MetadataVisualizer: React.FC<MetadataVisualizerProps> = ({
  children,
  renderLabels = true,
  renderIcons = true,
  renderMetrics = false
}) => {
  const { scene, camera } = useThree();
  // Use THREE.Object3D as Group might not be resolving correctly
  const groupRef = useRef<THREE.Group>(null);
  const { isXRMode } = usePlatform();
  const labelSettings = useSettingsStore(state => state.settings?.visualisation?.labels);

  // Layer management for XR mode
  useEffect(() => {
    if (!groupRef.current) return;

    // Set layers based on XR mode
    const group = groupRef.current;
    if (isXRMode) {
      // In XR mode, use layer 1 to ensure labels are visible in XR
      group.traverse(obj => {
        obj.layers.set(1);
      });
    } else {
      // In desktop mode, use default layer
      group.traverse(obj => {
        obj.layers.set(0);
      });
    }
  }, [isXRMode]);

  // Render optimization - only update label positions at 30fps
  useFrame((state, delta) => {
    // Potential optimization logic here
  }, 2); // Lower priority than regular rendering

  return (
    // Use THREE.Group directly in JSX if needed, or keep as <group>
    <group ref={groupRef} name="metadata-container">
      {children}
      {/* {renderLabels && <LabelSystem />} */} {/* Commented out LabelSystem usage */}
      {renderIcons && <IconSystem />}
      {renderMetrics && <MetricsDisplay />}
    </group>
  );
};

// Component to display node labels with proper positioning and formatting
const LabelSystem: React.FC = () => {
  const labelManagerRef = useTextLabelManager();
  const { labels } = labelManagerRef.current;
  const labelSettings = useSettingsStore(state => state.settings?.visualisation?.labels);

  // Don't render if labels are disabled
  // if (!labelSettings?.enabled) return null; // Commented out due to type error

  return (
    <group name="label-system">
      {labels.map(label => (
        <NodeLabel
          key={label.id}
          id={label.id}
          position={label.position}
          text={label.text}
          // color={labelSettings.color || '#ffffff'} // Commented out
          // size={labelSettings.size || 1} // Commented out
          // backgroundColor={labelSettings.backgroundColor} // Commented out
          // showDistance={labelSettings.showDistance} // Commented out
          // fadeDistance={labelSettings.fadeDistance} // Commented out
        />
      ))}
    </group>
  );
};

// Advanced label component with distance-based fading and billboarding
interface NodeLabelProps {
  id: string;
  position: [number, number, number] | { x: number; y: number; z: number } | THREE.Vector3;
  text: string;
  color?: string;
  size?: number;
  backgroundColor?: string;
  showDistance?: number;
  fadeDistance?: number;
}

const NodeLabel: React.FC<NodeLabelProps> = ({
  id,
  position,
  text,
  color = '#ffffff',
  size = 1,
  backgroundColor,
  showDistance = 0,
  fadeDistance = 0
}) => {
  // Skip rendering empty labels
  if (!text?.trim()) return null;

  const { camera } = useThree();
  const [opacity, setOpacity] = useState(1);

  // Convert position to tuple format with type guards
  const labelPos: [number, number, number] = useMemo(() => {
    if (isVector3Instance(position)) { // Use instanceof type guard
       // Explicit cast to help TS understand the type is narrowed
      const vec = position as THREE.Vector3;
      return [vec.x, vec.y, vec.z];
    } else if (Array.isArray(position)) {
      return position as [number, number, number]; // Assume it's a tuple if array
    } else if (typeof position === 'object' && position !== null && 'x' in position && 'y' in position && 'z' in position) {
      const posObj = position as { x: number; y: number; z: number };
      return [posObj.x, posObj.y, posObj.z];
    }
    logger.warn(`Invalid position format for label ${id}:`, position);
    return [0, 0, 0]; // Default position if format is unknown
  }, [position]);

  // Handle distance-based opacity
  useFrame(() => {
    if (!fadeDistance) return;

    // Calculate distance using tuple positions
    const dx = camera.position.x - labelPos[0];
    const dy = camera.position.y - labelPos[1];
    const dz = camera.position.z - labelPos[2];
    const distance = Math.sqrt(dx * dx + dy * dy + dz * dz);

    if (distance > fadeDistance) {
      setOpacity(0);
    } else if (distance > showDistance) {
      // Linear fade from showDistance to fadeDistance
      const fadeRatio = 1 - ((distance - showDistance) / (fadeDistance - showDistance));
      setOpacity(Math.max(0, Math.min(1, fadeRatio)));
    } else {
      setOpacity(1);
    }
  });

  // Don't render if fully transparent
  if (opacity <= 0) return null;

  // Commenting out Billboard and Text usage due to import errors
  return null;
  /*
  return (
    <Billboard
      position={labelPos}
      follow={true}
      lockX={false}
      lockY={false}
      lockZ={false}
    >
      <Text
        fontSize={size}
        color={color}
        anchorX="center"
        anchorY="middle"
        outlineWidth={0.02}
        outlineColor="#000000"
        outlineOpacity={0.8}
        overflowWrap="normal"
        maxWidth={10}
        textAlign="center"
        renderOrder={10} // Ensure text renders on top of other objects
        material-depthTest={false} // Make sure text is always visible
        material-transparent={true}
        material-opacity={opacity}
      >
        {text}
        {backgroundColor && (
          <meshBasicMaterial
            // color={backgroundColor} // Commented out due to type error
            opacity={opacity * 0.7}
            transparent={true}
            side={THREE.DoubleSide} // Use THREE namespace
          />
        )}
      </Text>
    </Billboard>
  );
  */
};

// System to display icons next to nodes
const IconSystem: React.FC = () => {
  // Implement if needed
  return null;
};

// System to display performance metrics
const MetricsDisplay: React.FC = () => {
  // Implement if needed
  return null;
};

// Hook to manage text labels
export function useTextLabelManager() {
  const labelManagerRef = useRef<{
    labels: Array<{
      id: string;
      text: string;
      position: [number, number, number];
    }>;
    updateLabel: (id: string, text: string, position: [number, number, number] | { x: number; y: number; z: number } | THREE.Vector3) => void;
    removeLabel: (id: string) => void;
    clearLabels: () => void;
  }>({
    labels: [],
    updateLabel: (id, text, position) => {
      const labels = labelManagerRef.current.labels;

      // Convert position to tuple format with type guards
      let pos: [number, number, number];
      if (isVector3Instance(position)) { // Use instanceof type guard
         // Explicit cast to help TS understand the type is narrowed
        const vec = position as THREE.Vector3;
        pos = [vec.x, vec.y, vec.z];
      } else if (Array.isArray(position)) {
        pos = position as [number, number, number];
      } else if (typeof position === 'object' && position !== null && 'x' in position && 'y' in position && 'z' in position) {
        const posObj = position as { x: number; y: number; z: number };
        pos = [posObj.x, posObj.y, posObj.z];
      } else {
        logger.warn(`Invalid position format for updateLabel ${id}:`, position);
        pos = [0, 0, 0]; // Default or handle error
      }

      const existingLabelIndex = labels.findIndex(label => label.id === id);

      if (existingLabelIndex >= 0) {
        // Update existing label
        labels[existingLabelIndex] = {
          ...labels[existingLabelIndex],
          text: text || labels[existingLabelIndex].text,
          position: pos
        };
      } else {
        // Add new label
        labels.push({ id, text, position: pos });
      }

      // Force update by creating a new array
      labelManagerRef.current.labels = [...labels];
    },
    removeLabel: (id) => {
      labelManagerRef.current.labels = labelManagerRef.current.labels.filter(
        label => label.id !== id
      );
    },
    clearLabels: () => {
      labelManagerRef.current.labels = [];
    }
  });

  return labelManagerRef;
}

// Factory function to create SDF font texture for high-quality text rendering
export const createSDFFont = async (fontUrl: string, fontSize: number = 64) => {
  // This would be an implementation of SDF font generation
  // For now, we use drei's Text component which provides high-quality text
  return null;
};

// Class-based API for backwards compatibility
export class MetadataVisualizerManager {
  private static instance: MetadataVisualizerManager;
  private labels: Map<string, { text: string; position: [number, number, number] }> = new Map();
  private updateCallback: (() => void) | null = null;

  private constructor() {}

  public static getInstance(): MetadataVisualizerManager {
    if (!MetadataVisualizerManager.instance) {
      MetadataVisualizerManager.instance = new MetadataVisualizerManager();
    }
    return MetadataVisualizerManager.instance;
  }

  public setUpdateCallback(callback: () => void): void {
    this.updateCallback = callback;
  }

  public updateNodeLabel(
    nodeId: string,
    text: string,
    position: [number, number, number] | { x: number; y: number; z: number } | THREE.Vector3
  ): void {
    try {
      // Convert position to tuple format with type guards
      let pos: [number, number, number];
      if (isVector3Instance(position)) { // Use instanceof type guard
         // Explicit cast to help TS understand the type is narrowed
        const vec = position as THREE.Vector3;
        pos = [vec.x, vec.y, vec.z];
      } else if (Array.isArray(position)) {
        pos = position as [number, number, number];
      } else if (typeof position === 'object' && position !== null && 'x' in position && 'y' in position && 'z' in position) {
        const posObj = position as { x: number; y: number; z: number };
        pos = [posObj.x, posObj.y, posObj.z];
      } else {
         logger.warn(`Invalid position format for updateNodeLabel ${nodeId}:`, position);
         pos = [0,0,0]; // Default or handle error
      }

      this.labels.set(nodeId, { text, position: pos });

      if (this.updateCallback) {
        this.updateCallback();
      }
    } catch (error) {
      logger.error('Error updating node label:', error);
    }
  }

  public clearLabel(nodeId: string): void {
    this.labels.delete(nodeId);

    if (this.updateCallback) {
      this.updateCallback();
    }
  }

  public clearAllLabels(): void {
    this.labels.clear();

    if (this.updateCallback) {
      this.updateCallback();
    }
  }

  public getAllLabels(): Array<{ id: string; text: string; position: [number, number, number] }> {
    return Array.from(this.labels.entries()).map(([id, label]) => ({
      id,
      text: label.text,
      position: label.position
    }));
  }

  public dispose(): void {
    this.labels.clear();
    this.updateCallback = null;

    // Reset singleton instance
    MetadataVisualizerManager.instance = null as any;
  }
}

// Export singleton instance for backwards compatibility
export const metadataVisualizer = MetadataVisualizerManager.getInstance();

export default MetadataVisualizer;
----
src/features/visualisation/components/CameraController.tsx
import { useEffect } from 'react';
import { useThree } from '@react-three/fiber';
import * as THREE from 'three'; // Use namespace import

interface CameraControllerProps {
  center: [number, number, number];
  size: number;
}

const CameraController: React.FC<CameraControllerProps> = ({ center, size }) => {
  const { camera } = useThree();

  useEffect(() => {
    // Ensure camera is PerspectiveCamera before accessing specific properties or methods
    if (camera instanceof THREE.PerspectiveCamera) {
        // Adjust position based on graph bounds
        camera.position.set(center[0], center[1] + 10, center[2] + size * 2);
        camera.lookAt(new THREE.Vector3(center[0], center[1], center[2])); // Use THREE.Vector3
        camera.updateProjectionMatrix();
    } else {
         console.warn("CameraController expects a PerspectiveCamera.");
         // Attempt basic adjustment anyway
         camera.position.set(center[0], center[1] + 10, center[2] + size * 2);
         camera.lookAt(new THREE.Vector3(center[0], center[1], center[2]));
    }
  }, [camera, center, size]);

  return null; // This component does not render anything itself
};

export default CameraController;

----
src/features/visualisation/components/HologramVisualisation.tsx
import React, { useRef, useEffect } from 'react';
import { Canvas } from '@react-three/fiber';
import { OrbitControls } from '@react-three/drei';
// THREE is used implicitly in the JSX
// Import only what we need
import { HologramManager } from '../renderers/HologramManager';
import { useSettingsStore } from '../../../store/settingsStore';

// Helper component to handle material properties imperatively to avoid TypeScript errors
const HologramMeshMaterial: React.FC<{
  color?: string | number;
  emissiveColor?: string | number;
  emissiveIntensity?: number;
  transparent?: boolean;
  opacity?: number;
}> = ({
  color = '#00ffff',
  emissiveColor = '#00ffff',
  emissiveIntensity = 0.5,
  transparent = true,
  opacity = 0.7
}) => {
  const materialRef = useRef<any>(); // Using any type to avoid TypeScript errors

  useEffect(() => {
    if (materialRef.current) {
      const material = materialRef.current;
      // Set properties imperatively to avoid TypeScript errors
      material.color.set(color as any);
      material.emissive.set(emissiveColor as any);
      material.emissiveIntensity = emissiveIntensity;
      material.transparent = transparent;
      material.opacity = opacity;
    }
  }, [color, emissiveColor, emissiveIntensity, transparent, opacity]);

  // Using any type to avoid TypeScript errors with newer Three.js properties
  return <meshStandardMaterial ref={materialRef as any} {...{ toneMapped: false, wireframe: true } as any} />;
};

interface HologramVisualisationProps {
  position?: readonly [number, number, number];
  size?: number;
  standalone?: boolean;
  children?: React.ReactNode;
}

/**
 * HologramVisualisation - A component that renders a hologram visualisation
 * using the modern approach based on @react-three/fiber and @react-three/drei
 *
 * Can be used in two ways:
 * 1. As a standalone component with its own canvas (standalone=true)
 * 2. As a component inside an existing canvas (standalone=false)
 */
export const HologramVisualisation: React.FC<HologramVisualisationProps> = ({
  position = [0, 0, 0],
  size = 1,
  standalone = true,
  children
}) => {
  const settings = useSettingsStore(state => state.settings?.visualisation?.hologram);

  // Content that's rendered inside the hologram
  const HologramContent = () => (
    <group position={position} scale={[size, size, size]}> {/* Use array for scale, remove 'as any' */}
      {children || (
        <>
          {/* Default content if no children provided */}
          <HologramManager />

          {/* Optional additional content */}
          <mesh position={[0, 0, 0]}>
            <icosahedronGeometry args={[0.4, 1]} />
            <HologramMeshMaterial
              color={settings?.ringColor || '#00ffff'} // Use ringColor
              emissiveColor={settings?.ringColor || '#00ffff'} // Use ringColor
              emissiveIntensity={0.5}
              transparent={true}
              opacity={0.7}
            />
          </mesh>
        </>
      )}
    </group>
  );

  // For standalone use, provide a Canvas
  if (standalone) {
    return (
      <div className="w-full h-full" style={{ minHeight: '300px' }}>
        <Canvas
          camera={{ position: [0, 0, 5], fov: 50 }}
          gl={{ antialias: true, alpha: true }}
        >
          <ambientLight intensity={0.5} />
          <directionalLight position={[10, 10, 5]} intensity={1} />
          <HologramContent />
          <OrbitControls enableDamping dampingFactor={0.1} />
        </Canvas>
      </div>
    );
  }

  // For embedded use, just render the content
  return <HologramContent />;
};

/**
 * Hologram Overlay - Creates a floating hologram effect for UI elements
 * This component provides a hologram-styled container for regular React components
 */
export const HologramOverlay: React.FC<{
  children: React.ReactNode;
  className?: string;
  glowColor?: string;
}> = ({
  children,
  className = '',
  glowColor = '#00ffff'
}) => {
  return (
    <div
      className={`relative rounded-lg overflow-hidden ${className}`}
      style={{
        background: 'rgba(0, 10, 20, 0.7)',
        boxShadow: `0 0 15px ${glowColor}, inset 0 0 8px ${glowColor}`,
        border: `1px solid ${glowColor}`,
      }}
    >
      {/* Scanline effect */}
      <div
        className="absolute inset-0 pointer-events-none z-10"
        style={{
          background: 'linear-gradient(transparent 50%, rgba(0, 255, 255, 0.05) 50%)',
          backgroundSize: '100% 4px',
          animation: 'hologramScanline 1s linear infinite',
        }}
      />

      {/* Flickering effect */}
      <div
        className="absolute inset-0 pointer-events-none opacity-20 z-20"
        style={{
          animation: 'hologramFlicker 4s linear infinite',
        }}
      />

      {/* Content */}
      <div className="relative z-30 p-4 text-cyan-400">
        {children}
      </div>

      {/* CSS for animations */}
      <style>
        {`
          @keyframes hologramScanline {
            0% {
              transform: translateY(0%);
            }
            100% {
              transform: translateY(100%);
            }
          }

          @keyframes hologramFlicker {
            0% { opacity: 0.1; }
            5% { opacity: 0.2; }
            10% { opacity: 0.1; }
            15% { opacity: 0.3; }
            20% { opacity: 0.1; }
            25% { opacity: 0.2; }
            30% { opacity: 0.1; }
            35% { opacity: 0.15; }
            40% { opacity: 0.2; }
            45% { opacity: 0.15; }
            50% { opacity: 0.1; }
            55% { opacity: 0.2; }
            60% { opacity: 0.25; }
            65% { opacity: 0.15; }
            70% { opacity: 0.2; }
            75% { opacity: 0.1; }
            80% { opacity: 0.15; }
            85% { opacity: 0.1; }
            90% { opacity: 0.2; }
            95% { opacity: 0.15; }
            100% { opacity: 0.1; }
          }
        `}
      </style>
    </div>
  );
};

// Example usage component to demonstrate both 3D and UI hologram effects
export const HologramExample: React.FC = () => {
  return (
    <div className="flex flex-col md:flex-row gap-6 p-6 min-h-screen bg-gray-900">
      {/* 3D Hologram */}
      <div className="flex-1 h-[500px] rounded-lg overflow-hidden">
        <HologramVisualisation standalone size={1.2} />
      </div>

      {/* UI Hologram */}
      <div className="flex-1 flex items-center justify-center">
        <HologramOverlay className="max-w-md">
          <h2 className="text-xl font-semibold mb-4">Hologram System Status</h2>
          <div className="space-y-3">
            <div className="flex justify-between">
              <span>Power Level:</span>
              <span>87%</span>
            </div>
            <div className="flex justify-between">
              <span>Signal Strength:</span>
              <span>Optimal</span>
            </div>
            <div className="flex justify-between">
              <span>Data Transmission:</span>
              <span>Active</span>
            </div>
            <div className="w-full h-2 bg-blue-900 mt-4 rounded-full overflow-hidden">
              <div
                className="h-full bg-cyan-400"
                style={{
                  width: '87%',
                  animation: 'hologramPulse 3s infinite'
                }}
              ></div>
            </div>
          </div>
        </HologramOverlay>
      </div>

      {/* Animation for progress bar */}
      <style>
        {`
          @keyframes hologramPulse {
            0% { opacity: 0.8; }
            50% { opacity: 1; }
            100% { opacity: 0.8; }
          }
        `}
      </style>
    </div>
  );
};

export default HologramVisualisation;
----
src/features/xr/managers/xrSessionManager.ts
import * as THREE from 'three';
import { VRButton } from 'three/examples/jsm/webxr/VRButton.js';
import { XRControllerModelFactory } from 'three/examples/jsm/webxr/XRControllerModelFactory.js';
import { createLogger, createErrorMetadata } from '@/utils/logger';
import { debugState } from '@/utils/debugState'; // Assuming debugState.ts exists in utils
import { SceneManager } from '@/features/visualisation/managers/sceneManager'; // Correct path
import { GestureRecognitionResult } from '@/features/xr/systems/HandInteractionSystem'; // Correct path
import { Settings } from '@/features/settings/config/settings'; // Correct path, assuming Settings is defined here

const logger = createLogger('XRSessionManager');

export interface XRControllerEvent {
  controller: THREE.XRTargetRaySpace;
  inputSource: XRInputSource;
  data?: any;
}

type XRControllerEventHandler = (event: XRControllerEvent) => void;

// New event handler types for hand interactions
type GestureEventHandler = (gesture: GestureRecognitionResult) => void;
type HandVisibilityHandler = (visible: boolean) => void;
type XRSessionStateHandler = (state: string) => void;
type HandTrackingHandler = (enabled: boolean) => void;

export class XRSessionManager {
  private static instance: XRSessionManager;
  private sceneManager: SceneManager;
  private renderer: THREE.WebGLRenderer | null = null;
  private camera: THREE.PerspectiveCamera | null = null;
  private scene: THREE.Scene | null = null;
  private controllers: THREE.XRTargetRaySpace[] = [];
  private controllerGrips: THREE.Object3D[] = [];
  private controllerModelFactory: XRControllerModelFactory | null = null;
  private vrButton: HTMLElement | null = null;
  private sessionActive: boolean = false;
  private settings: Settings | null = null;
  
  // Event handlers
  private selectStartHandlers: XRControllerEventHandler[] = [];
  private selectEndHandlers: XRControllerEventHandler[] = [];
  private squeezeStartHandlers: XRControllerEventHandler[] = [];
  private squeezeEndHandlers: XRControllerEventHandler[] = [];
  
  // New event handlers for hand interactions
  private gestureRecognizedHandlers: GestureEventHandler[] = [];
  private handsVisibilityChangedHandlers: HandVisibilityHandler[] = [];
  private handTrackingStateHandlers: HandTrackingHandler[] = [];
  
  private constructor(sceneManager: SceneManager, externalRenderer?: THREE.WebGLRenderer) {
    this.sceneManager = sceneManager;    
    // Allow using an external renderer (from React Three Fiber) or try to get one from SceneManager
    this.renderer = externalRenderer || sceneManager.getRenderer();
    
    // Get camera and ensure it's a PerspectiveCamera
    const camera = sceneManager.getCamera();
    if (!camera || !(camera instanceof THREE.PerspectiveCamera)) {
      logger.warn('PerspectiveCamera not available from SceneManager, creating default camera');
      this.camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
      this.camera.position.z = 5;
    } else {
      this.camera = camera as THREE.PerspectiveCamera;
    }
    
    // Get scene
    this.scene = sceneManager.getScene();
    if (!this.scene) {
      logger.warn('Scene not found in SceneManager, creating default scene');
      this.scene = new THREE.Scene();
    }
    
    // Log warning instead of throwing error so application can continue
    if (!this.renderer) {
      logger.warn('XRSessionManager: No renderer provided. XR functionality will be limited.');
    }
    
    try {
      // Initialize controller model factory
      this.controllerModelFactory = new XRControllerModelFactory();
    } catch (error) {
      logger.error('Failed to create XRControllerModelFactory:', createErrorMetadata(error));
      this.controllerModelFactory = null;
    }
  }
  
  public static getInstance(sceneManager: SceneManager, externalRenderer?: THREE.WebGLRenderer): XRSessionManager {
    if (!XRSessionManager.instance) {
      XRSessionManager.instance = new XRSessionManager(sceneManager, externalRenderer);
    } else if (externalRenderer && !XRSessionManager.instance.renderer) {
      // If instance exists but has no renderer, we can update it with the external renderer
      XRSessionManager.instance.renderer = externalRenderer;
      logger.info('Updated XRSessionManager with external renderer');
    }
    return XRSessionManager.instance;
  }
  
  public initialize(settings: Settings): void {
    if (!this.renderer || !this.scene) {
      logger.error('Cannot initialize XR: renderer or scene is missing');
      return;
    }
    
    this.settings = settings;
    
    try {
      // Check if WebXR is supported
      if ('xr' in navigator && this.renderer) {
        // Set up renderer for XR
        this.renderer.xr.enabled = true;
        
        // Set reference space type based on settings (assuming teleport implies room scale)
        const refSpace = settings.xr?.locomotionMethod === 'teleport' ? 'local-floor' : 'local';
        this.renderer.xr.setReferenceSpaceType(refSpace);
        
        if (debugState.isEnabled()) {
          logger.info(`Set XR reference space to ${refSpace}`);
        }
        
        // Create VR button
        this.createVRButton();
        
        // Create controllers
        this.setupControllers();
        
        if (debugState.isEnabled()) {
          logger.info('XR session manager initialized successfully');
        }
      } else if (debugState.isEnabled()) {
        logger.warn('WebXR not supported in this browser');
      }
    } catch (error) {
      logger.error('Failed to initialize XR:', createErrorMetadata(error));
    }
  }
  
  private createVRButton(): void {
    if (!this.renderer) return;
    
    try {
      // Create VR button and add to document
      this.vrButton = VRButton.createButton(this.renderer);
      
      // Style the button
      this.vrButton.style.position = 'absolute';
      this.vrButton.style.bottom = '20px';
      this.vrButton.style.right = '20px';
      this.vrButton.style.zIndex = '100';
      
      // Add button to document
      document.body.appendChild(this.vrButton);
      
      // Add session start/end listeners
      this.renderer.xr.addEventListener('sessionstart', () => {
        this.sessionActive = true;
        if (debugState.isEnabled()) {
          logger.info('XR session started');
        }
      });
      
      this.renderer.xr.addEventListener('sessionend', () => {
        this.sessionActive = false;
        if (debugState.isEnabled()) {
          logger.info('XR session ended');
        }
      });
    } catch (error) {
      logger.error('Failed to create VR button:', createErrorMetadata(error));
    }
  }
  
  private setupControllers(): void {
    if (!this.renderer || !this.scene) return;
    
    try {
      // Create controllers
      for (let i = 0; i < 2; i++) {
        // Controller
        const controller = this.renderer.xr.getController(i);
        controller.addEventListener('selectstart', (event) => this.handleSelectStart(event, i));
        controller.addEventListener('selectend', (event) => this.handleSelectEnd(event, i));
        controller.addEventListener('squeezestart', (event) => this.handleSqueezeStart(event, i));
        controller.addEventListener('squeezeend', (event) => this.handleSqueezeEnd(event, i));
        controller.addEventListener('connected', (event) => {
          if (debugState.isEnabled()) {
            logger.info(`Controller ${i} connected:`, { 
              handedness: (event as any).data?.handedness,
              targetRayMode: (event as any).data?.targetRayMode
            });
          }
        });
        controller.addEventListener('disconnected', () => {
          if (debugState.isEnabled()) {
            logger.info(`Controller ${i} disconnected`);
          }
        });
        
        this.scene.add(controller);
        this.controllers.push(controller as THREE.XRTargetRaySpace);
        
        // Controller grip
        const controllerGrip = this.renderer.xr.getControllerGrip(i);
        if (this.controllerModelFactory) {
          controllerGrip.add(this.controllerModelFactory.createControllerModel(controllerGrip));
        }
        this.scene.add(controllerGrip);
        this.controllerGrips.push(controllerGrip);
        
        // Add visual indicators for the controllers
        const geometry = new THREE.BufferGeometry().setFromPoints([
          new THREE.Vector3(0, 0, 0),
          new THREE.Vector3(0, 0, -1)
        ]);
        
        const line = new THREE.Line(geometry);
        line.name = 'controller-line';
        line.scale.z = 5;
        
        controller.add(line);
        controller.userData.selectPressed = false;
        controller.userData.squeezePressed = false;
      }
      
      if (debugState.isEnabled()) {
        logger.info('XR controllers set up successfully');
      }
    } catch (error) {
      logger.error('Failed to set up XR controllers:', createErrorMetadata(error));
    }
  }
  
  // Event handlers
  private handleSelectStart(event: any, controllerId: number): void {
    if (controllerId >= this.controllers.length) return;
    
    const controller = this.controllers[controllerId];
    controller.userData.selectPressed = true;
    
    const inputSource = event.data;
    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Controller ${controllerId} select start`);
    }
    
    this.selectStartHandlers.forEach(handler => {
      try {
        handler({ controller, inputSource, data: event.data });
      } catch (error) {
        logger.error('Error in selectStart handler:', createErrorMetadata(error));
      }
    });
  }
  
  private handleSelectEnd(event: any, controllerId: number): void {
    if (controllerId >= this.controllers.length) return;
    
    const controller = this.controllers[controllerId];
    controller.userData.selectPressed = false;
    
    const inputSource = event.data;
    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Controller ${controllerId} select end`);
    }
    
    this.selectEndHandlers.forEach(handler => {
      try {
        handler({ controller, inputSource, data: event.data });
      } catch (error) {
        logger.error('Error in selectEnd handler:', createErrorMetadata(error));
      }
    });
  }
  
  private handleSqueezeStart(event: any, controllerId: number): void {
    if (controllerId >= this.controllers.length) return;
    
    const controller = this.controllers[controllerId];
    controller.userData.squeezePressed = true;
    
    const inputSource = event.data;
    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Controller ${controllerId} squeeze start`);
    }
    
    this.squeezeStartHandlers.forEach(handler => {
      try {
        handler({ controller, inputSource, data: event.data });
      } catch (error) {
        logger.error('Error in squeezeStart handler:', createErrorMetadata(error));
      }
    });
  }
  
  private handleSqueezeEnd(event: any, controllerId: number): void {
    if (controllerId >= this.controllers.length) return;
    
    const controller = this.controllers[controllerId];
    controller.userData.squeezePressed = false;
    
    const inputSource = event.data;
    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Controller ${controllerId} squeeze end`);
    }
    
    this.squeezeEndHandlers.forEach(handler => {
      try {
        handler({ controller, inputSource, data: event.data });
      } catch (error) {
        logger.error('Error in squeezeEnd handler:', createErrorMetadata(error));
      }
    });
  }
  
  // Event subscription methods
  public onSelectStart(handler: XRControllerEventHandler): () => void {
    this.selectStartHandlers.push(handler);
    return () => {
      this.selectStartHandlers = this.selectStartHandlers.filter(h => h !== handler);
    };
  }
  
  public onSelectEnd(handler: XRControllerEventHandler): () => void {
    this.selectEndHandlers.push(handler);
    return () => {
      this.selectEndHandlers = this.selectEndHandlers.filter(h => h !== handler);
    };
  }
  
  public onSqueezeStart(handler: XRControllerEventHandler): () => void {
    this.squeezeStartHandlers.push(handler);
    return () => {
      this.squeezeStartHandlers = this.squeezeStartHandlers.filter(h => h !== handler);
    };
  }
  
  public onSqueezeEnd(handler: XRControllerEventHandler): () => void {
    this.squeezeEndHandlers.push(handler);
    return () => {
      this.squeezeEndHandlers = this.squeezeEndHandlers.filter(h => h !== handler);
    };
  }

  // New event subscription methods for hand interactions
  public onGestureRecognized(handler: GestureEventHandler): () => void {
    this.gestureRecognizedHandlers.push(handler);
    return () => {
      this.gestureRecognizedHandlers = this.gestureRecognizedHandlers.filter(h => h !== handler);
    };
  }
  
  public onHandsVisibilityChanged(handler: HandVisibilityHandler): () => void {
    this.handsVisibilityChangedHandlers.push(handler);
    return () => {
      this.handsVisibilityChangedHandlers = this.handsVisibilityChangedHandlers.filter(h => h !== handler);
    };
  }
  
  // Method to notify gesture events
  public notifyGestureRecognized(gesture: GestureRecognitionResult): void {
    this.gestureRecognizedHandlers.forEach(handler => {
      try {
        handler(gesture);
      } catch (error) {
        logger.error('Error in gesture recognition handler:', createErrorMetadata(error));
      }
    });
  }
  
  // Method to notify hand visibility changes
  public notifyHandsVisibilityChanged(visible: boolean): void {
    this.handsVisibilityChangedHandlers.forEach(handler => {
      try {
        handler(visible);
      } catch (error) {
        logger.error('Error in hand visibility handler:', createErrorMetadata(error));
      }
    });
  }
  
  // XR state methods
  public isSessionActive(): boolean {
    return this.sessionActive;
  }
  
  public getControllers(): THREE.XRTargetRaySpace[] {
    return this.controllers;
  }
  
  public getControllerGrips(): THREE.Object3D[] {
    return this.controllerGrips;
  }
  
  public updateSettings(settings: Settings): void {
    this.settings = settings;
    
    // Update reference space if settings changed
    if (this.renderer && settings.xr) {
      this.renderer.xr.setReferenceSpaceType(
        settings.xr.locomotionMethod === 'teleport' ? 'local-floor' : 'local'
      );
    }
  }
  
  public dispose(): void {
    // Remove controllers from scene
    this.controllers.forEach(controller => {
      controller.removeFromParent();
      // Remove all event listeners
      controller.removeEventListener('selectstart', () => {});
      controller.removeEventListener('selectend', () => {});
      controller.removeEventListener('squeezestart', () => {});
      controller.removeEventListener('squeezeend', () => {});
    });
    
    // Remove controller grips from scene
    this.controllerGrips.forEach(grip => {
      grip.removeFromParent();
    });
    
    // Remove VR button
    if (this.vrButton && this.vrButton.parentNode) {
      this.vrButton.parentNode.removeChild(this.vrButton);
    }
    
    // Clear arrays
    this.controllers = [];
    this.controllerGrips = [];
    this.selectStartHandlers = [];
    this.selectEndHandlers = [];
    this.squeezeStartHandlers = [];
    this.squeezeEndHandlers = [];
    this.gestureRecognizedHandlers = [];
    this.handsVisibilityChangedHandlers = [];
    this.handTrackingStateHandlers = [];
    
    // Clear factory
    this.controllerModelFactory = null;
    
    // Remove references
    this.renderer = null;
    this.camera = null;
    this.scene = null;
    this.vrButton = null;
    
    if (debugState.isEnabled()) {
      logger.info('XR session manager disposed');
    }
  }
}
----
src/features/xr/managers/xrInitializer.ts
import * as THREE from 'three';
import { createLogger, createErrorMetadata } from '@/utils/logger';
import { debugState } from '@/utils/debugState';
import { XRSessionManager, XRControllerEvent } from './xrSessionManager';
import { XRSettings } from '../types/xr';
import { SceneManager } from '../../visualisation/managers/sceneManager';

const logger = createLogger('XRInitializer');

export class XRInitializer {
  private static instance: XRInitializer;
  private xrSessionManager: XRSessionManager;
  private sceneManager: SceneManager;
  private scene: THREE.Scene;
  private camera: THREE.PerspectiveCamera;
  private teleportMarker: THREE.Mesh | null = null;
  private floorPlane: THREE.Mesh | null = null;
  private settings: XRSettings | null = null;
  private raycaster: THREE.Raycaster = new THREE.Raycaster();
  private controllerIntersections: Map<THREE.XRTargetRaySpace, THREE.Intersection[]> = new Map();
  
  // Teleportation state
  private isTeleporting: boolean = false;
  private teleportPosition: THREE.Vector3 = new THREE.Vector3();
  
  // Movement state
  private movementEnabled: boolean = true;
  private movementSpeed: number = 1.0;
  
  // Controller handlers
  private controllerSelectStartUnsubscribe: (() => void) | null = null;
  private controllerSelectEndUnsubscribe: (() => void) | null = null;
  private controllerSqueezeStartUnsubscribe: (() => void) | null = null;
  private controllerSqueezeEndUnsubscribe: (() => void) | null = null;
  
  private constructor(xrSessionManager: XRSessionManager) {
    this.xrSessionManager = xrSessionManager;
    this.sceneManager = SceneManager.getInstance();
    this.scene = this.sceneManager.getScene();
    
    // Get camera and ensure it's a PerspectiveCamera
    const camera = this.sceneManager.getCamera();
    
    if (!camera || !(camera instanceof THREE.PerspectiveCamera)) {
      logger.warn('PerspectiveCamera not available from SceneManager, creating default camera');
      this.camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
      this.camera.position.z = 5;
    } else {
      // We have a valid PerspectiveCamera
      this.camera = camera as THREE.PerspectiveCamera;
    }
    
    // Setup XR interactions
    this.setupXRInteractions();
  }
  
  public static getInstance(xrSessionManager: XRSessionManager): XRInitializer {
    if (!XRInitializer.instance) {
      XRInitializer.instance = new XRInitializer(xrSessionManager);
    }
    return XRInitializer.instance;
  }
  
  // Initialize XR capabilities with current settings
  public initialize(settings: XRSettings): void {
    this.settings = settings;
    
    // The XRSettings interface was updated, so we access properties directly.
    // We also need to check if settings itself is null before accessing its properties.
    if (settings) {
      this.movementEnabled = true; // Assuming movement is enabled if XR settings are present
      this.movementSpeed = settings.movementSpeed || 1.0;

      // Setup floor if enabled
      if (settings.showFloor) {
        this.createFloor();
      } else if (this.floorPlane) {
        this.scene.remove(this.floorPlane);
        this.floorPlane.geometry.dispose();
        (this.floorPlane.material as THREE.Material).dispose();
        this.floorPlane = null;
      }

      // Setup teleport marker if teleport is enabled
      if (settings.teleportEnabled) {
        this.createTeleportMarker();
      } else if (this.teleportMarker) {
        this.scene.remove(this.teleportMarker);
        this.teleportMarker.geometry.dispose();
        (this.teleportMarker.material as THREE.Material).dispose();
        this.teleportMarker = null;
      }
    }
    
    if (debugState.isEnabled()) {
      logger.info('XR initializer initialized with settings');
    }
  }
  
  // Setup all XR interactions
  private setupXRInteractions(): void {
    // Register for controller events
    this.controllerSelectStartUnsubscribe = this.xrSessionManager.onSelectStart(
      this.handleControllerSelectStart.bind(this)
    );
    
    this.controllerSelectEndUnsubscribe = this.xrSessionManager.onSelectEnd(
      this.handleControllerSelectEnd.bind(this)
    );
    
    this.controllerSqueezeStartUnsubscribe = this.xrSessionManager.onSqueezeStart(
      this.handleControllerSqueezeStart.bind(this)
    );
    
    this.controllerSqueezeEndUnsubscribe = this.xrSessionManager.onSqueezeEnd(
      this.handleControllerSqueezeEnd.bind(this)
    );
    
    // Add render callback for continuous interaction checks
    this.sceneManager.addRenderCallback(this.update.bind(this));
    
    if (debugState.isEnabled()) {
      logger.info('XR interactions setup complete');
    }
  }
  
  // Create floor plane for reference and teleportation
  private createFloor(): void {
    if (this.floorPlane) {
      return;
    }
    
    const geometry = new THREE.PlaneGeometry(20, 20);
    const material = new THREE.MeshBasicMaterial({
      color: 0x808080,
      transparent: true,
      opacity: 0.2,
      side: THREE.DoubleSide
    });
    
    this.floorPlane = new THREE.Mesh(geometry, material);
    this.floorPlane.rotation.x = -Math.PI / 2;
    this.floorPlane.position.y = 0;
    this.floorPlane.receiveShadow = true;
    this.floorPlane.name = 'xr-floor';
    
    this.scene.add(this.floorPlane);
    
    if (debugState.isEnabled()) {
      logger.info('XR floor plane created');
    }
  }
  
  // Create teleport marker for showing valid teleport locations
  private createTeleportMarker(): void {
    if (this.teleportMarker) {
      return;
    }
    
    const geometry = new THREE.RingGeometry(0.15, 0.2, 32);
    const material = new THREE.MeshBasicMaterial({
      color: 0x00ff00,
      transparent: true,
      opacity: 0.6,
      side: THREE.DoubleSide
    });
    
    this.teleportMarker = new THREE.Mesh(geometry, material);
    this.teleportMarker.rotation.x = -Math.PI / 2;
    this.teleportMarker.visible = false;
    this.teleportMarker.name = 'teleport-marker';
    
    this.scene.add(this.teleportMarker);
    
    if (debugState.isEnabled()) {
      logger.info('Teleport marker created');
    }
  }
  
  // Update loop for continuous interactions
  private update(): void {
    if (!this.xrSessionManager.isSessionActive()) {
      return;
    }
    
    // Get controllers
    const controllers = this.xrSessionManager.getControllers();
    
    // Update controller interactions
    controllers.forEach(controller => {
      this.updateControllerInteractions(controller);
    });
  }
  
  // Check for intersections with objects
  private updateControllerInteractions(controller: THREE.XRTargetRaySpace): void {
    // Skip if there's no session
    if (!this.xrSessionManager.isSessionActive()) {
      return;
    }
    
    // Initialize raycaster from controller
    const tempMatrix = new THREE.Matrix4();
    tempMatrix.identity().extractRotation(controller.matrixWorld);
    
    this.raycaster.ray.origin.setFromMatrixPosition(controller.matrixWorld);
    this.raycaster.ray.direction.set(0, 0, -1).applyMatrix4(tempMatrix);
    
    // Store intersections for this controller
    const intersections: THREE.Intersection[] = [];
    
    // Check for floor intersection if teleport is enabled
    if (this.floorPlane && this.settings?.teleportEnabled) {
      const floorIntersects = this.raycaster.intersectObject(this.floorPlane);
      
      if (floorIntersects.length > 0) {
        intersections.push(...floorIntersects);
        
        // Update teleport marker position if currently teleporting
        if (this.isTeleporting && this.teleportMarker) {
          this.teleportPosition.copy(floorIntersects[0].point);
          this.teleportMarker.position.copy(this.teleportPosition);
          this.teleportMarker.visible = true;
        }
      } else if (this.isTeleporting && this.teleportMarker) {
        // Hide marker if not pointing at floor
        this.teleportMarker.visible = false;
      }
    }
    
    // Store intersections for this controller
    this.controllerIntersections.set(controller, intersections);
  }
  
  // Handle controller select start event (trigger press)
  private handleControllerSelectStart(event: XRControllerEvent): void {
    const { controller } = event;
    
    // Start teleportation if enabled
    if (this.settings?.teleportEnabled) {
      this.isTeleporting = true;
      
      // Show teleport marker if there's a valid intersection
      const intersections = this.controllerIntersections.get(controller) || [];
      if (intersections.length > 0 && this.floorPlane && this.teleportMarker) {
        const floorIntersect = intersections.find(
          i => i.object === this.floorPlane
        );
        
        if (floorIntersect) {
          this.teleportPosition.copy(floorIntersect.point);
          this.teleportMarker.position.copy(this.teleportPosition);
          this.teleportMarker.visible = true;
        }
      }
    }
  }
  
  // Handle controller select end event (trigger release)
  private handleControllerSelectEnd(event: XRControllerEvent): void {
    // Complete teleportation if in progress
    if (this.isTeleporting && this.teleportMarker && this.teleportMarker.visible) {
      // Get camera position but keep y-height the same
      const cameraPosition = new THREE.Vector3();
      cameraPosition.setFromMatrixPosition(this.camera.matrixWorld);
      
      // Calculate teleport offset (where we want camera to end up)
      const offsetX = this.teleportPosition.x - cameraPosition.x;
      const offsetZ = this.teleportPosition.z - cameraPosition.z;
      
      // Find camera rig/offset parent - in WebXR the camera is often a child of a rig
      let cameraRig = this.camera.parent;
      if (cameraRig) {
        // Apply offset to camera rig's position
        cameraRig.position.x += offsetX;
        cameraRig.position.z += offsetZ;
      } else {
        // Fallback to moving camera directly if no rig
        this.camera.position.x += offsetX;
        this.camera.position.z += offsetZ;
      }
      
      // Hide teleport marker
      this.teleportMarker.visible = false;
      
      if (debugState.isDataDebugEnabled()) {
        logger.debug('Teleported to', { x: this.teleportPosition.x, z: this.teleportPosition.z });
      }
    }
    
    // Reset teleport state
    this.isTeleporting = false;
  }
  
  // Handle controller squeeze start event (grip press)
  private handleControllerSqueezeStart(event: XRControllerEvent): void {
    // Placeholder for future interactions
    // Could be used for grabbing objects, scaling the environment, etc.
  }
  
  // Handle controller squeeze end event (grip release)
  private handleControllerSqueezeEnd(event: XRControllerEvent): void {
    // Placeholder for future interactions
  }
  
  // Update settings for XR
  public updateSettings(settings: XRSettings): void {
    this.settings = settings;
    
    // The XRSettings interface was updated, so we access properties directly.
    // We also need to check if settings itself is null before accessing its properties.
    if (settings) {
      this.movementSpeed = settings.movementSpeed || 1.0;

      // Update floor visibility
      if (settings.showFloor) {
        if (!this.floorPlane) {
          this.createFloor();
        }
      } else if (this.floorPlane) {
        this.scene.remove(this.floorPlane);
        this.floorPlane.geometry.dispose();
        (this.floorPlane.material as THREE.Material).dispose();
        this.floorPlane = null;
      }

      // Update teleport marker
      if (settings.teleportEnabled) {
        if (!this.teleportMarker) {
          this.createTeleportMarker();
        }
      } else if (this.teleportMarker) {
        this.scene.remove(this.teleportMarker);
        this.teleportMarker.geometry.dispose();
        (this.teleportMarker.material as THREE.Material).dispose();
        this.teleportMarker = null;
      }
    }
  }
  
  // Clean up all XR-related resources
  public dispose(): void {
    // Unsubscribe from controller events
    if (this.controllerSelectStartUnsubscribe) {
      this.controllerSelectStartUnsubscribe();
      this.controllerSelectStartUnsubscribe = null;
    }
    
    if (this.controllerSelectEndUnsubscribe) {
      this.controllerSelectEndUnsubscribe();
      this.controllerSelectEndUnsubscribe = null;
    }
    
    if (this.controllerSqueezeStartUnsubscribe) {
      this.controllerSqueezeStartUnsubscribe();
      this.controllerSqueezeStartUnsubscribe = null;
    }
    
    if (this.controllerSqueezeEndUnsubscribe) {
      this.controllerSqueezeEndUnsubscribe();
      this.controllerSqueezeEndUnsubscribe = null;
    }
    
    // Remove floor and teleport marker
    if (this.floorPlane) {
      this.scene.remove(this.floorPlane);
      this.floorPlane.geometry.dispose();
      (this.floorPlane.material as THREE.Material).dispose();
      this.floorPlane = null;
    }
    
    if (this.teleportMarker) {
      this.scene.remove(this.teleportMarker);
      this.teleportMarker.geometry.dispose();
      (this.teleportMarker.material as THREE.Material).dispose();
      this.teleportMarker = null;
    }
    
    // Clear intersections map
    this.controllerIntersections.clear();
    
    if (debugState.isEnabled()) {
      logger.info('XR initializer disposed');
    }
  }
}
----
src/features/xr/systems/HandInteractionSystem.tsx
import React, { useRef, useEffect, useState } from 'react';
import * as THREE from 'three'; // Add this line
import { Group, Line, Raycaster, BufferGeometry, Vector3, Matrix4, LineBasicMaterial, Object3D } from 'three';
import { useFrame, useThree } from '@react-three/fiber';
import { Interactive } from '@react-three/xr';
import { usePlatform } from '../../../services/platformManager';
import { useSettingsStore } from '../../../store/settingsStore';
import { createLogger } from '../../../utils/logger';
import { GestureState, XRInteractionMode, InteractableObject } from '../types/xr';

const logger = createLogger('HandInteraction');

// Simplified XR handedness type
type XRHandedness = 'left' | 'right' | 'none';

// Interaction event types
type InteractionEventType = 'select' | 'hover' | 'unhover' | 'squeeze' | 'move';
type InteractionDistance = 'near' | 'far';
type InteractionEvent = { 
  type: InteractionEventType, 
  distance: InteractionDistance, 
  controller?: Object3D, 
  hand?: XRHandedness, 
  point?: [number, number, number] 
};

// Interface for recognized gesture
export interface GestureRecognitionResult {
  gesture: string;
  confidence: number;
  hand: XRHandedness;
}

// Props for the hand interaction system
interface HandInteractionSystemProps {
  children?: React.ReactNode;
  onGestureRecognized?: (gesture: GestureRecognitionResult) => void;
  onHandsVisible?: (visible: boolean) => void;
  enabled?: boolean;
  interactionMode?: XRInteractionMode;
  interactionDistance?: number;
  hapticFeedback?: boolean;
}

/**
 * Modern hand interaction system for WebXR
 * Uses React Three Fiber for Quest hand tracking
 */
export const HandInteractionSystem: React.FC<HandInteractionSystemProps> = ({
  children,
  onGestureRecognized,
  onHandsVisible,
  enabled = true,
  interactionMode = 'both',
  interactionDistance = 1.5,
  hapticFeedback = true
}) => {
  const { scene, gl, camera } = useThree();
  const { isPresenting, session, controllers, player } = useSafeXR();
  const platform = usePlatform();
  const settings = useSettingsStore(state => state.settings.xr);
  const handTrackingEnabled = settings.handTracking && enabled;
  
  // State for hands and interaction
  const [handsVisible, setHandsVisible] = useState(false);
  const [visualizeHands, setVisualizeHands] = useState(false);
  const [interactables, setInteractables] = useState<InteractableObject[]>([]);
  const [selectedObject, setSelectedObject] = useState<Object3D | null>(null);
  const [hoveredObject, setHoveredObject] = useState<Object3D | null>(null);

  // References for hand state
  const leftHandRef = useRef<Group | null>(null);
  const rightHandRef = useRef<Group | null>(null);
  const leftControllerRef = useRef<Group | null>(null);
  const rightControllerRef = useRef<Group | null>(null);
  const leftRayRef = useRef<Line | null>(null);
  const rightRayRef = useRef<Line | null>(null);
  
  // Gesture state reference
  const gestureStateRef = useRef<GestureState>({
    left: { pinch: false, grip: false, point: false, thumbsUp: false },
    right: { pinch: false, grip: false, point: false, thumbsUp: false }
  });

  // Raycaster for interaction
  const raycasterRef = useRef<Raycaster>(new Raycaster());
  
  // Initialize raycaster with proper settings
  useEffect(() => {
    if (raycasterRef.current) {
      raycasterRef.current.near = 0.01;
      raycasterRef.current.far = interactionDistance;
      (raycasterRef.current.params as any).Line = { threshold: 0.2 };
      (raycasterRef.current.params as any).Points = { threshold: 0.2 };
    }
  }, [interactionDistance]);

  // Collect all interactable objects in the scene
  useEffect(() => {
    // In a real implementation, this would scan the scene for objects with interactable components
    // For now, we'll just have an empty array that would be populated by components
  }, [scene]);
  
  // Map to store joint objects
  const jointsRef = useRef<Map<string, Object3D>>(new Map());

  // Initialize hand tracking
  useEffect(() => {
    if (!handTrackingEnabled) return;
    
    // Create hand groups if they don't exist
    if (!leftHandRef.current) {
      leftHandRef.current = new Group();
      (leftHandRef.current as any).name = 'left-hand';
      scene.add(leftHandRef.current);
    }

    // Create controller rays if they don't exist
    if (!leftRayRef.current) {
      const geometry = new BufferGeometry();
      // Manually create points instead of using Vector3 constructor
      const points = [
        { x: 0, y: 0, z: 0 },
        { x: 0, y: 0, z: -interactionDistance }
      ];
      const rayGeometry = (geometry as any).setFromPoints(
        points.map(p => new (THREE as any).Vector3(p.x, p.y, p.z))
      );
      const rayMaterial = new (THREE as any).LineBasicMaterial({ 
        color: settings.controllerRayColor || 0x00ff00,
        opacity: 0.7, 
        transparent: true 
      });
      leftRayRef.current = new (THREE as any).Line(rayGeometry, rayMaterial);
    }
    
    if (!rightHandRef.current) {
      rightHandRef.current = new Group();
      (rightHandRef.current as any).name = 'right-hand';
      scene.add(rightHandRef.current);
    }
    
    // Create right controller ray
    if (!rightRayRef.current) {
      const geometry = new BufferGeometry();
      // Manually create points instead of using Vector3 constructor
      const points = [
        { x: 0, y: 0, z: 0 },
        { x: 0, y: 0, z: -interactionDistance }
      ];
      const rayGeometry = (geometry as any).setFromPoints(
        points.map(p => new (THREE as any).Vector3(p.x, p.y, p.z))
      );
      const rayMaterial = new (THREE as any).LineBasicMaterial({ 
        color: settings.controllerRayColor || 0x00ff00,
        opacity: 0.7, 
        transparent: true 
      });
      rightRayRef.current = new (THREE as any).Line(rayGeometry, rayMaterial);
    }
    logger.info('Hand tracking system initialized');
    
    // Return cleanup function
    return () => {
      if (leftHandRef.current) {
        scene.remove(leftHandRef.current);
        leftHandRef.current = null;
      }
      
      if (rightHandRef.current) {
        scene.remove(rightHandRef.current);
        rightHandRef.current = null;
      }

      if (leftRayRef.current) {
        scene.remove(leftRayRef.current);
        leftRayRef.current = null;
      }
      
      if (rightRayRef.current) {
        scene.remove(rightHandRef.current);
        rightHandRef.current = null;
      }
      
      jointsRef.current.clear();
      logger.info('Hand tracking system disposed');
    };
  }, [handTrackingEnabled, scene, interactionDistance, settings.controllerRayColor]);
  
  // Update controller references when WebXR session changes
  useEffect(() => {
    if (!isPresenting || !platform.isWebXRSupported) return;
    
    // Attach to XR controllers if available
    if (controllers && controllers.length > 0) {
      controllers.forEach(controller => {
        if (controller.inputSource.handedness === 'left') {
          leftControllerRef.current = controller.controller;
          if (leftRayRef.current) {
            controller.controller.add(leftRayRef.current);
          }
        } else if (controller.inputSource.handedness === 'right') {
          rightControllerRef.current = controller.controller;
          if (rightRayRef.current) {
            controller.controller.add(rightRayRef.current);
          }
        }
      });
    }
    
    // Set up controller event listeners
    const handleControllerEvent = (event: any, type: InteractionEventType, hand: XRHandedness) => {
      handleInteractionEvent({
        type,
        distance: 'far',
        controller: hand === 'left' ? leftControllerRef.current as Object3D : rightControllerRef.current as Object3D,
        hand,
        point: event.intersections?.[0]?.point
      });
    };
    
    // Return cleanup function that removes event listeners
    return () => {
      // In a real implementation, we would remove event listeners here
    };
  }, [isPresenting, platform.isWebXRSupported, controllers, hapticFeedback]);
  
  // Handle various interaction events from controllers or hand tracking
  const handleInteractionEvent = (event: InteractionEvent) => {
    // Process different event types
    switch (event.type) {
      case 'select':
        // Handle selection (trigger press)
        if (hoveredObject) {
          setSelectedObject(hoveredObject);
          
          // Trigger haptic feedback if enabled
          if (hapticFeedback && event.controller && session) {
            const gamepad = (event.controller as any).inputSource?.gamepad;
            if (gamepad && gamepad.hapticActuators && gamepad.hapticActuators[0]) {
              gamepad.hapticActuators[0].pulse(0.5, 100);
            }
          }
          
          logger.info(`Selected object: ${hoveredObject.name}`);
        }
        break;
        
      case 'hover':
        // Handle hover state (ray pointing at object)
        if (event.point && event.controller) {
          setHoveredObject(event.controller);
          logger.debug(`Hovering object at ${event.point[0]}, ${event.point[1]}, ${event.point[2]}`);
        }
        break;
        
      case 'unhover':
        // Clear hover state
        setHoveredObject(null);
        break;
        
      case 'squeeze':
        // Handle grip button press
        if (selectedObject) {
          logger.info(`Squeezing object: ${selectedObject.name}`);
          
          // Trigger stronger haptic feedback for squeeze
          if (hapticFeedback && event.controller && session) {
            const gamepad = (event.controller as any).inputSource?.gamepad;
            if (gamepad && gamepad.hapticActuators && gamepad.hapticActuators[0]) {
              gamepad.hapticActuators[0].pulse(0.8, 150);
            }
          }
        }
        break;
        
      case 'move':
        // Handle movement of selected object
        if (selectedObject && event.controller) {
          // In a real implementation, this would update the position/rotation of the selected object
          logger.debug(`Moving selected object with controller`);
        }
        break;
    }
  };
  
  // Perform gesture recognition on hand joints
  const recognizeGestures = (handedness: XRHandedness, joints: Map<string, Object3D>) => {
    if (joints.size === 0) return;
    
    // Get key finger joints for gesture recognition
    const thumbTip = joints.get('thumb-tip');
    const indexTip = joints.get('index-finger-tip');
    const indexMiddle = joints.get('index-finger-phalanx-intermediate');
    const middleTip = joints.get('middle-finger-tip');
    const ringTip = joints.get('ring-finger-tip');
    const pinkyTip = joints.get('pinky-finger-tip');
    const wrist = joints.get('wrist');
    
    if (!thumbTip || !indexTip || !wrist) return;
    
    // Check thumb-index pinch
    // Calculate distance using tuple positions
    const thumbPos = [(thumbTip as any).position.x, (thumbTip as any).position.y, (thumbTip as any).position.z] as const;
    const indexPos = [(indexTip as any).position.x, (indexTip as any).position.y, (indexTip as any).position.z] as const;
    const dx = thumbPos[0] - indexPos[0];
    const dy = thumbPos[1] - indexPos[1];
    const dz = thumbPos[2] - indexPos[2];
    const thumbToIndexDistance = Math.sqrt(dx * dx + dy * dy + dz * dz);
    const isPinching = thumbToIndexDistance < 0.03; // 3cm threshold
    
    // Check point gesture (index extended, others curled)
    const isPointing = false; // Simplified - would check index extension and other fingers curled
    
    // Check grip gesture (all fingers curled)
    const isGripping = false; // Simplified - would check all fingers curled
    
    // Check thumbs up gesture
    const isThumbsUp = false; // Simplified - would check thumb orientation
    
    // Update gesture state
    const previousState = gestureStateRef.current[handedness];
    gestureStateRef.current[handedness] = {
      pinch: isPinching,
      grip: isGripping,
      point: isPointing,
      thumbsUp: isThumbsUp
    };
    
    // Notify about gesture changes
    if (isPinching && !previousState.pinch && onGestureRecognized) {
      onGestureRecognized({
        gesture: 'pinch',
        confidence: 0.9,
        hand: handedness
      });
      
      // Trigger interaction event for pinch
      handleInteractionEvent({ type: 'select', distance: 'near', hand: handedness });
    }
  };
  
  // Process hand data on each frame
  useFrame(({ clock }) => {
    if (!handTrackingEnabled || !isPresenting) return;
    
    // Process controller raycasting for far interaction
    if (interactionMode !== 'hands-only' && (leftControllerRef.current || rightControllerRef.current)) {
      // Perform raycasting from controllers to detect interactive objects
      if (leftControllerRef.current) {
        const origin = (raycasterRef.current.ray.origin as any);
        origin.setFromMatrixPosition((leftControllerRef.current as any).matrixWorld);
        
        const direction = (raycasterRef.current.ray.direction as any);
        direction.set(0, 0, -1);
        direction.applyMatrix4(
          new (THREE as any).Matrix4().extractRotation((leftControllerRef.current as any).matrixWorld)
        );
        
        const intersects = raycasterRef.current.intersectObjects(
          interactables.map(obj => obj.object), 
          false
        );
        
        if (intersects.length > 0) {
          handleInteractionEvent({
            type: 'hover',
            distance: 'far',
            controller: leftControllerRef.current as Object3D,
            hand: 'left',
            point: [
              (intersects[0].point as any).x,
              (intersects[0].point as any).y,
              (intersects[0].point as any).z
            ]
          });
        }
      }
      
      // Same for right controller
      if (rightControllerRef.current) {
        // Similar raycasting logic for right controller
      }
    }
    
    // Process hand tracking for near interaction
    if (interactionMode !== 'controllers-only' && (leftHandRef.current || rightHandRef.current)) {
      // Process joints and recognize gestures for left hand
      if (leftHandRef.current && (leftHandRef.current as any).children.length > 0) {
        const leftJoints = new Map<string, Object3D>();
        (leftHandRef.current as any).children.forEach((joint: any) => {
          leftJoints.set(joint.name, joint);
        });
        
        recognizeGestures('left', leftJoints);
      }
      
      // Process joints and recognize gestures for right hand
      if (rightHandRef.current && (rightHandRef.current as any).children.length > 0) {
        const rightJoints = new Map<string, Object3D>();
        (rightHandRef.current as any).children.forEach((joint: any) => {
          rightJoints.set(joint.name, joint);
        });
        
        recognizeGestures('right', rightJoints);
      }
    }
  });
  
  // Toggle hand visualisation for debugging
  const toggleHandVisualisation = () => {
    setVisualizeHands(!visualizeHands);
  };
  
  if (!handTrackingEnabled) return null;
  
  return (
    // Only the container group is rendered - the actual implementation is done in useFrame
    <group name="hand-interaction-system">
      {children}
    </group>
  );
};

// Hook for hand tracking in components
export const useHandTracking = () => {
  const { isPresenting } = useSafeXR();
  
  const [pinchState, setPinchState] = useState<{left: boolean, right: boolean}>({
    left: false,
    right: false
  });
  
  // Hand positions state
  const [handPositions, setHandPositions] = useState<{
    left: [number, number, number] | null,
    right: [number, number, number] | null
  }>({
    left: null,
    right: null
  });
  
  // Gesture state
  const [gestureState, setGestureState] = useState<GestureState>({
    left: { pinch: false, grip: false, point: false, thumbsUp: false },
    right: { pinch: false, grip: false, point: false, thumbsUp: false }
  });
  
  // Update hand positions and gestures state from the system
  useFrame(() => {
    // If we're not in XR mode, don't try to update anything
    if (!isPresenting) {
      return;
    }
    // This would be implemented to sync with the hand tracking system 
    // and update the hook's state based on the HandInteractionSystem
  });
  
  return {
    pinchState,
    handPositions,
    gestureState,
    isLeftHandVisible: !!handPositions.left,
    isRightHandVisible: !!handPositions.right
  };
};

// Interactable component that works with hand tracking
export const HandInteractable: React.FC<{
  children?: React.ReactNode,
  id?: string,
  onHover?: () => void,
  onUnhover?: () => void,
  onSelect?: () => void,
  position?: [number, number, number],
  scale?: [number, number, number]
}> = ({
  children,
  id,
  onHover,
  onUnhover,
  onSelect,
  position = [0, 0, 0],
  scale = [1, 1, 1]
}) => {
  const [isHovered, setIsHovered] = useState(false);
  
  const handlePointerOver = () => {
    setIsHovered(true);
    if (onHover) onHover();
  };
  
  const handlePointerOut = () => {
    setIsHovered(false);
    if (onUnhover) onUnhover();
  };
  
  const handleClick = () => {
    if (onSelect) onSelect();
  };
  
  return (
    <group
      position={position}
      name={id || 'interactable'}
      scale={scale}
      onPointerOver={handlePointerOver}
      onPointerOut={handlePointerOut}
      onClick={handleClick}
    >
      {children}
      {isHovered && (
        // Create a simpler hover indicator without material props
        <group name="hover-indicator" scale={[1.05, 1.05, 1.05]}>
          {/* Using a primitive mesh for hover effects to avoid TypeScript errors */}
          {React.createElement('mesh', {
            children: [React.createElement('sphereGeometry', { args: [1, 16, 16] })]
          })}
        </group>
      )}
    </group>
  );
};

/**
 * This is a stub implementation for the Quest-specific XR features.
 * In a real implementation, this would integrate with the WebXR API
 * and Quest hand tracking capabilities.
 * 
 * Key features that would be implemented:
 * 1. Hand tracking using WebXR Hand Input API
 * 2. Gesture recognition (pinch, grip, point)
 * 3. Proper integration with react-three/fiber and react-three/xr
 * 4. AR passthrough mode specific to Quest devices
 * 5. Performance optimizations for XR
 */

// Import the safe XR hooks to prevent errors outside XR context
import { useSafeXR, withSafeXR } from '../hooks/useSafeXRHooks';

// Export the wrapped version as the default, which is safe to use anywhere
const SafeHandInteractionSystem = withSafeXR(HandInteractionSystem, 'HandInteractionSystem');

// Default export is now the safe version
export default SafeHandInteractionSystem;

----
src/features/xr/providers/XRContextWrapper.tsx
import React from 'react';
import { useXR } from '@react-three/xr';
import { createLogger } from '@/utils/logger';

const logger = createLogger('XRContextWrapper');

/**
 * A higher-order component (HOC) that safely wraps components that use XR features.
 * This prevents "XR features can only be used inside the <XR> component" errors by
 * checking if we're in a valid XR context before rendering the wrapped component.
 */
export const withXRContext = <P extends object>(
  Component: React.ComponentType<P>,
  componentName: string = 'Component'
): React.FC<P> => {
  const WrappedComponent: React.FC<P> = (props) => {
    try {
      // This will throw an error if we're outside an XR context
      const xr = useXR();
      
      // If we get here, the XR context is valid
      return <Component {...props} />;
    } catch (error) {
      // If we're here, we're outside an XR context
      logger.debug(`Not rendering ${componentName} - outside XR context`);
      return null;
    }
  };
  
  // Set a display name for better debugging
  WrappedComponent.displayName = `withXRContext(${componentName})`;
  
  return WrappedComponent;
};

export default withXRContext;
----
src/features/xr/providers/SafeXRProvider.tsx
import React, { createContext, useContext, useEffect, useState, ReactNode } from 'react';
import { useSettingsStore } from '../../../store/settingsStore';
import { createLogger } from '../../../utils/logger';

const logger = createLogger('SafeXRProvider');

interface XRContextProps {
  isXRCapable: boolean;
  isXRSupported: boolean;
}

const XRContext = createContext<XRContextProps>({
  isXRCapable: false,
  isXRSupported: false,
});

export const useXR = () => useContext(XRContext);

interface SafeXRProviderProps {
  children: ReactNode;
}

const SafeXRProvider: React.FC<SafeXRProviderProps> = ({ children }) => {
  const [isXRCapable, setIsXRCapable] = useState(false);
  const [isXRSupported, setIsXRSupported] = useState(false);
  const { settings } = useSettingsStore();

  useEffect(() => {
    const checkXRSupport = async () => {
      try {
        if ('xr' in navigator) {
          const supported = await (navigator.xr as any).isSessionSupported('immersive-vr');
          setIsXRSupported(supported);
          setIsXRCapable(true);
          logger.info('XR is capable and immersive VR is supported.');
        } else {
          setIsXRCapable(false);
          setIsXRSupported(false);
          logger.warn('XR is not available in this browser.');
        }
      } catch (error) {
        setIsXRCapable(false);
        setIsXRSupported(false);
        logger.error('Error checking XR support:', error);
      }
    };

    checkXRSupport();
  }, []);

  useEffect(() => {
      const debugEnabled = settings?.system?.debug?.enabled === true
    if (debugEnabled) {
      logger.info(`XR capability changed: capable=${isXRCapable}, supported=${isXRSupported}`);
    }
  }, [isXRCapable, isXRSupported, settings?.system?.debug?.enabled]);

  return (
    <XRContext.Provider value={{ isXRCapable, isXRSupported }}>
      {children}
    </XRContext.Provider>
  );
};

export default SafeXRProvider;
----
src/features/xr/types/xr.ts
// XR-related type definitions
import { Object3D, Vector3, Quaternion } from 'three'; // Import specific types needed

// XR session state types
export type XRSessionState = 'inactive' | 'active' | 'ending' | 'cooldown';

// XR controller types
export type XRControllerType = 'none' | 'hands' | 'touch' | 'gamepad' | 'gaze';

// XR reference space types
export type XRReferenceSpaceType = 'local' | 'local-floor' | 'bounded-floor' | 'unbounded' | 'viewer';

// XR interaction types
export type XRInteractionType = 'select' | 'grab' | 'drag' | 'scale' | 'rotate' | 'pinch' | 'scroll';

// XR controller/hand interaction mode
export type XRInteractionMode = 'controllers-only' | 'hands-only' | 'both';

// XR interactable object interface
export interface InteractableObject {
  object: Object3D;
  id: string;
  interactable: boolean;
  handlers?: Record<string, (event: any) => void>;
}

// XR hand joint types (standard WebXR hand joints)
export type XRHandJoint = 
  | 'wrist'
  | 'thumb-metacarpal'
  | 'thumb-phalanx-proximal'
  | 'thumb-phalanx-distal'
  | 'thumb-tip'
  | 'index-finger-metacarpal'
  | 'index-finger-phalanx-proximal'
  | 'index-finger-phalanx-intermediate'
  | 'index-finger-phalanx-distal'
  | 'index-finger-tip'
  | 'middle-finger-metacarpal'
  | 'middle-finger-phalanx-proximal'
  | 'middle-finger-phalanx-intermediate'
  | 'middle-finger-phalanx-distal'
  | 'middle-finger-tip'
  | 'ring-finger-metacarpal'
  | 'ring-finger-phalanx-proximal'
  | 'ring-finger-phalanx-intermediate'
  | 'ring-finger-phalanx-distal'
  | 'ring-finger-tip'
  | 'pinky-finger-metacarpal'
  | 'pinky-finger-phalanx-proximal'
  | 'pinky-finger-phalanx-intermediate'
  | 'pinky-finger-phalanx-distal'
  | 'pinky-finger-tip';

// XR Input Source types (aligned with WebXR standards)
export interface XRInputSource {
  handedness: 'none' | 'left' | 'right';
  targetRayMode: 'gaze' | 'tracked-pointer' | 'screen';
  targetRaySpace: any; // XRSpace in WebXR
  gripSpace?: any; // XRSpace in WebXR
  gamepad?: Gamepad;
  profiles: string[];
  hand?: any; // XRHand in WebXR
}

// XR hit test result for AR interactions
export interface XRHitTestResult {
  hitMatrix: Float32Array;
  distance: number;
  objectId?: string;
}

// Gesture recognition types for hand tracking
export interface GestureState {
  left: {
    pinch: boolean;
    grip: boolean;
    point: boolean;
    thumbsUp: boolean;
  };
  right: {
    pinch: boolean;
    grip: boolean;
    point: boolean;
    thumbsUp: boolean;
  };
}

// XR controller state
export interface XRControllerState {
  isConnected: boolean;
  isTriggerPressed: boolean;
  isGripPressed: boolean;
  isThumbstickPressed: boolean;
  thumbstickX: number;
  thumbstickY: number;
  triggerValue: number;
  gripValue: number;
  position: Vector3;
  rotation: Quaternion;
  hapticActuator?: any;
}

// XR Settings (moved from settings feature)
export interface XRSettings {
  isAREnabled: boolean;
  interactionMode: 'grab' | 'point' | 'touch';
  scale: number;
  position: [number, number, number];
  rotation: [number, number, number];
  handTrackingEnabled?: boolean; // Added setting for hand tracking
  movementSpeed?: number;
  showFloor?: boolean;
  teleportEnabled?: boolean;
}
----
src/features/xr/types/webxr-extensions.d.ts
// Extended WebXR type definitions for hand tracking and related features

// Extend existing WebXR types
declare module '@react-three/xr' {
  import { Object3D, Group } from 'three';
  import { ReactNode } from 'react';

  // Event types
  export interface XREvent extends Event {
    target: any;
  }

  export type XRHandedness = 'left' | 'right' | 'none';

  // React hooks
  export function useXR(): {
    player: Group;
    isPresenting: boolean;
    session: XRSession | null;
    controllers: Array<XRController>;
    hands: { left: XRHand, right: XRHand } | null;
    hoverState: any;
  };

  // Interactive component
  export interface InteractiveProps {
    onHover?: (event: any) => void;
    onBlur?: (event: any) => void;
    onSelect?: (event: any) => void;
    onMove?: (event: any) => void;
    onSqueeze?: (event: any) => void;
    onSqueezeEnd?: (event: any) => void;
    onSelectEnd?: (event: any) => void;
    onSelectStart?: (event: any) => void;
    onSqueezeStart?: (event: any) => void;
    children?: ReactNode;
  }

  export const Interactive: React.FC<InteractiveProps>;
  export const Hands: React.FC<any>;
  export const XR: React.FC<any>;
  export const Controllers: React.FC<any>;
  export const useController: (handedness: XRHandedness) => XRController | null;
}

// Extended WebXR types for advanced hand tracking
interface XRHand extends Map<XRHandJoint, XRJointSpace> {
  // Additional methods and properties
  get(joint: XRHandJoint): XRJointSpace | undefined;
  keys(): IterableIterator<XRHandJoint>;
  values(): IterableIterator<XRJointSpace>;
}

interface XRJointSpace extends XRSpace {
  // Remove readonly modifier conflict
  jointName: XRHandJoint;
  space: XRSpace;
  // Remove readonly modifier conflict
  radius: number | undefined;
  pose?: XRPose;
}

// WebXR Hand Joint types
// Rename to avoid conflict with @types/webxr
type XRHandJointType = 
  | 'wrist'
  | 'thumb-metacarpal'
  | 'thumb-phalanx-proximal'
  | 'thumb-phalanx-distal'
  | 'thumb-tip'
  | 'index-finger-metacarpal'
  | 'index-finger-phalanx-proximal'
  | 'index-finger-phalanx-intermediate'
  | 'index-finger-phalanx-distal'
  | 'index-finger-tip'
  | 'middle-finger-metacarpal'
  | 'middle-finger-phalanx-proximal'
  | 'middle-finger-phalanx-intermediate'
  | 'middle-finger-phalanx-distal'
  | 'middle-finger-tip'
  | 'ring-finger-metacarpal'
  | 'ring-finger-phalanx-proximal'
  | 'ring-finger-phalanx-intermediate'
  | 'ring-finger-phalanx-distal'
  | 'ring-finger-tip'
  | 'pinky-finger-metacarpal'
  | 'pinky-finger-phalanx-proximal'
  | 'pinky-finger-phalanx-intermediate'
  | 'pinky-finger-phalanx-distal'
  | 'pinky-finger-tip';

// Extended WebXR session 
interface XRSession {
  // Avoid readonly modifier conflict
  supportedModules?: string[];
  // Match type signature from @types/webxr
  // updateTargetFrameRate(rate: number): Promise<void>;
}

// Extended XRFrame
interface XRFrame {
  // Match type signature from @types/webxr
  // getJointPose(joint: XRJointSpace, baseSpace: XRSpace): XRJointPose | undefined;
}

// Extended XRInputSource
interface XRInputSource {
  // Avoid readonly modifier conflict
}

// Extended controller type
interface XRController {
  grip: THREE.Group;
  controller: THREE.Group;
  inputSource: XRInputSource;
  targetRayMode: 'gaze' | 'tracked-pointer' | 'screen';
}

// Joint pose with radius
interface XRJointPose extends XRPose {
  // Avoid readonly modifier conflict
}

// Additional global interfaces for TS compatibility
interface XRInputSourceArray {
  length: number;
  [Symbol.iterator](): IterableIterator<XRInputSource>;
}
----
src/features/xr/components/XRController.tsx
import React, { useState, useCallback } from 'react'
import { useSafeXR, withSafeXR } from '../hooks/useSafeXRHooks'
import HandInteractionSystem, { GestureRecognitionResult } from '../systems/HandInteractionSystem'
import { debugState } from '../../../utils/debugState'
import { useSettingsStore } from '../../../store/settingsStore'
import { createLogger } from '../../../utils/logger'

const logger = createLogger('XRController')

/**
 * XRControllerInner component handles WebXR functionality through react-three/xr.
 * XRController component manages WebXR functionality through react-three/xr.
 * This version is simplified to avoid integration conflicts.
 */
const XRController: React.FC = () => {
  const { isPresenting, controllers } = useSafeXR()
  const settings = useSettingsStore(state => state.settings)
  const [handsVisible, setHandsVisible] = useState(false)
  const [handTrackingEnabled, setHandTrackingEnabled] = useState(settings?.xr?.handTracking !== false) // Use correct property name from settings.ts
  
  // Log session state changes
  React.useEffect(() => {
    if (debugState.isEnabled()) {
      if (isPresenting) {
        logger.info('XR session is now active')
      } else {
        logger.info('XR session is not active')
      }
    }
  }, [isPresenting])

  // Log controller information
  React.useEffect(() => {
    if (isPresenting && controllers && controllers.length > 0 && debugState.isEnabled()) {
      logger.info(`XR controllers active: ${controllers.length}`)
      controllers.forEach((controller, index) => {
        logger.info(`Controller ${index}: ${controller.inputSource.handedness}`)
      })
    }
  }, [controllers, isPresenting])

  // Handle gesture recognition
  const handleGestureRecognized = useCallback((gesture: GestureRecognitionResult) => {
    if (debugState.isEnabled()) {
      logger.info(`Gesture recognized: ${gesture.gesture} (${gesture.confidence.toFixed(2)}) with ${gesture.hand} hand`)
    }
  }, [])

  // Handle hand visibility changes
  const handleHandsVisible = useCallback((visible: boolean) => {
    setHandsVisible(visible)
    
    if (debugState.isEnabled()) {
      logger.info(`Hands visible: ${visible}`)
    }
  }, [])
  
  // Only render if enabled in settings
  if (settings?.xr?.enabled === false) {
    return null
  }
  
  return (
    <group name="xr-controller-root">
      <HandInteractionSystem 
        enabled={handTrackingEnabled}
        onGestureRecognized={handleGestureRecognized}
        onHandsVisible={handleHandsVisible}
      />
    </group>
  )
}

// Wrap with XR context safety check to prevent outside-XR-context errors
const SafeXRController = withSafeXR(XRController, 'XRController');
export default SafeXRController
----
src/features/xr/components/XRScene.tsx
import React from 'react'
import { Canvas } from '@react-three/fiber'
import { XR, Controllers, Hands } from '@react-three/xr'
import { Environment, OrbitControls } from '@react-three/drei'
import GraphManager from '../../graph/components/GraphManager'; // Changed to default import
import { useSettingsStore } from '../../../store/settingsStore'; // Corrected path

export const XRScene = () => {
  const settings = useSettingsStore(state => state.settings)
  const xrSettings = settings?.xr

  return (
    <Canvas
      camera={{ position: [0, 1.6, 3], fov: 50 }}
      shadows
    >
      <XR>
        <Controllers />
        <Hands />
        
        {/* AR-specific lighting */}
        <ambientLight intensity={0.5} />
        <directionalLight
          position={[10, 10, 5]}
          intensity={1}
          castShadow
        />
        
        {/* Environment for better AR visualisation */}
        <Environment preset="city" />
        
        {/* Main graph visualisation */}
        <GraphManager />
        
        {/* Optional orbit controls for non-AR mode */}
        {!xrSettings?.enabled && (
          <OrbitControls
            enablePan={true}
            enableZoom={true}
            enableRotate={true}
            target={[0, 0, 0]}
          />
        )}
      </XR>
    </Canvas>
  )
} 
----
src/features/xr/components/XRVisualisationConnector.tsx
import React, { useEffect, useState, useCallback } from 'react';
import { useSafeXR, withSafeXR } from '../hooks/useSafeXRHooks';
import { MetadataVisualizer, useTextLabelManager } from '../../visualisation/components/MetadataVisualizer';
import { useHandTracking } from '../systems/HandInteractionSystem';
import { useSettingsStore } from '../../../store/settingsStore';
import { createLogger } from '../../../utils/logger';

const logger = createLogger('XRVisualisationConnector');

/**
 * XRVisualisationConnector connects the XR hand interaction system
 * with the visualisation system and platform manager.
 * 
 * This component acts as the dependency injector between these systems.
 * It is wrapped with the XR context safety check to prevent errors.
 */
const XRVisualisationConnectorInner: React.FC = () => {
  const { isPresenting: isXRMode } = useSafeXR();
  const settings = useSettingsStore(state => state.settings);
  const handTracking = useHandTracking();
  const labelManager = useTextLabelManager();
  const [interactionEnabled, setInteractionEnabled] = useState(true);
  
  // Handle platform changes
  useEffect(() => {
    // Configure interactivity based on XR mode
    setInteractionEnabled(isXRMode && settings?.xr?.handTracking !== false); // Use correct property name
    
    // Debug logging
    if (isXRMode) {
      logger.info('XR mode active, configuring visualisation for hand interaction');
    }
  }, [isXRMode, settings?.xr?.handTracking]); // Use correct property name
  
  // Handle hand gesture interactions with visualisations
  useEffect(() => {
    if (!interactionEnabled) return;
    
    // Example: Use pinch gesture state to interact with labels
    const { pinchState, handPositions, isLeftHandVisible, isRightHandVisible } = handTracking;
    
    // Update visualisation system based on hand state using tuple positions
    // This is just a stub - real implementation would have more logic
    if (pinchState.left || pinchState.right) {
      // Use tuple based positions for hand interactions
      const leftPos = handPositions.left;
      const rightPos = handPositions.right;
      
      if (pinchState.left && leftPos) {
        logger.debug(`Left hand pinch at [${leftPos[0]}, ${leftPos[1]}, ${leftPos[2]}]`);
      }
      
      if (pinchState.right && rightPos) {
        logger.debug(`Right hand pinch at [${rightPos[0]}, ${rightPos[1]}, ${rightPos[2]}]`);
      }
    }
    
    return () => {
      // Cleanup if needed
    };
  }, [handTracking.pinchState, handTracking.handPositions, interactionEnabled]);
  
  // Render the visualisation system with the appropriate settings
  return (
    <MetadataVisualizer 
      renderLabels={settings?.visualisation?.labels?.enableLabels !== false} // Use correct property name
      // renderIcons={settings?.visualisation?.icons?.enabled !== false} // Property 'icons' does not exist
      // renderMetrics={settings?.visualisation?.metrics?.enabled} // Property 'metrics' does not exist
    />
  );
};

// Wrap with XR context safety check to prevent outside-XR-context errors
const XRVisualisationConnector = withSafeXR(XRVisualisationConnectorInner, 'XRVisualisationConnector');
export default XRVisualisationConnector;
----
src/features/xr/components/ui/XRControlPanel.tsx
import { useRef, useState, useEffect } from 'react';
import { Object3D, Group, Vector3 } from 'three';
import { useThree, useFrame } from '@react-three/fiber';
import { Interactive } from '@react-three/xr';
import { useSettingsStore } from '../../../../store/settingsStore';
import { createLogger } from '../../../../utils/logger';

const logger = createLogger('XRControlPanel');

interface XRControlPanelProps {
  /**
   * Distance from controller to position the panel
   * @default 0.3
   */
  distance?: number;
  
  /**
   * Size of the panel
   * @default {width: 0.3, height: 0.2}
   */
  size?: {
    width: number;
    height: number;
  };
  
  /**
   * Whether to show the panel
   * @default true
   */
  visible?: boolean;

  /**
   * Controller to attach the panel to (0 = right, 1 = left)
   * @default 0
   */
  controller?: number;

  /**
   * Whether the panel should face the user
   * @default true
   */
  faceUser?: boolean;
}

/**
 * XRControlPanel provides an interactive interface for controlling settings in XR mode.
 * It's attached to a controller and follows its movement while providing touch/pointer interaction.
 */
const XRControlPanel = ({
  distance = 0.3,
  size = { width: 0.3, height: 0.2 },
  visible = true,
  controller = 0,
  faceUser = true,
}: XRControlPanelProps) => {
  const groupRef = useRef<Group>(null);
  const { camera } = useThree();
  const [hovered, setHovered] = useState(false);
  const [selectedTab, setSelectedTab] = useState('visualisation');
  
  const { settings } = useSettingsStore();
  
  // Position the panel relative to the controller
  useFrame((state, delta) => {
    if (!groupRef.current) return;
    
    // If we have controller data, position the panel relative to it
    const controllers = (state as any).controllers;
    if (controllers && controllers[controller]) {
      const controllerObj = controllers[controller];
      
      // Get controller position and orientation
      const position = new Vector3();
      controllerObj.getWorldPosition(position);
      
      const quaternion = controllerObj.getWorldQuaternion();
      
      // Position the panel in front of the controller
      const forward = new Vector3(0, 0, -1).applyQuaternion(quaternion);
      position.addScaledVector(forward, distance);
      
      groupRef.current.position.copy(position);
      
      // Either match controller orientation or face the user
      if (faceUser) {
        // Make the panel face the user
        groupRef.current.lookAt(camera.position);
      } else {
        // Match controller orientation
        groupRef.current.quaternion.copy(quaternion);
      }
    }
  });
  
  // Handle tab selection
  const handleTabSelect = (tab: string) => {
    setSelectedTab(tab);
    logger.debug(`Selected XR panel tab: ${tab}`);
  };
  
  if (!visible) return null;
  
  return (
    <group ref={groupRef}>
      {/* Panel background */}
      <Interactive 
        onSelect={() => {}}
        onHover={() => setHovered(true)}
        onBlur={() => setHovered(false)}
      >
        <mesh position={[0, 0, 0]}>
          <planeGeometry args={[size.width, size.height]} />
          <meshStandardMaterial 
            color={hovered ? '#2a2a2a' : '#1a1a1a'} 
            transparent
            opacity={0.8}
          />
        </mesh>
      </Interactive>
      
      {/* Tab buttons at the top */}
      <group position={[0, size.height / 2 - 0.02, 0.001]}>
        {/* Visualisation tab */}
        <Interactive onSelect={() => handleTabSelect('visualisation')}>
          <mesh position={[-size.width / 4, 0, 0]}>
            <planeGeometry args={[size.width / 3.5, 0.03]} />
            <meshStandardMaterial 
              color={selectedTab === 'visualisation' ? '#4a86e8' : '#333333'} 
            />
          </mesh>
        </Interactive>
        
        {/* XR tab */}
        <Interactive onSelect={() => handleTabSelect('xr')}>
          <mesh position={[size.width / 4, 0, 0]}>
            <planeGeometry args={[size.width / 3.5, 0.03]} />
            <meshStandardMaterial 
              color={selectedTab === 'xr' ? '#4a86e8' : '#333333'} 
            />
          </mesh>
        </Interactive>
      </group>
      
      {/* Panel content - dynamically render based on selected tab */}
      <group position={[0, 0, 0.001]}>
        {selectedTab === 'visualisation' && (
          <group>
            {/* Simple visualisation controls */}
            <mesh position={[0, 0.05, 0]} scale={[0.9, 0.1, 1]}>
              <planeGeometry />
              <meshStandardMaterial color="#333333" />
            </mesh>
            <mesh position={[0, -0.05, 0]} scale={[0.9, 0.1, 1]}>
              <planeGeometry />
              <meshStandardMaterial color="#333333" />
            </mesh>
          </group>
        )}
        
        {selectedTab === 'xr' && (
          <group>
            {/* Simple XR controls */}
            <mesh position={[0, 0, 0]} scale={[0.9, 0.15, 1]}>
              <planeGeometry />
              <meshStandardMaterial color="#333333" />
            </mesh>
          </group>
        )}
      </group>
    </group>
  );
};

export default XRControlPanel;
----
src/features/xr/hooks/useXRContextCheck.tsx
import { useCallback, useEffect, useState } from 'react';
import { createLogger } from '../../../utils/logger';

const logger = createLogger('useXRContextCheck');

/**
 * A hook that safely checks if the current component is being rendered
 * within a valid XR context, without causing errors when outside it.
 * 
 * @returns {boolean} isInXRContext - True if in valid XR context, false otherwise
 */
export const useXRContextCheck = (): boolean => {
  const [isInXRContext, setIsInXRContext] = useState<boolean>(false);

  useEffect(() => {
    // Check if we're in an XR context by checking for the '__r3f' property
    // which is added by react-three-fiber to elements in its render tree
    try {
      // If we can access THREE.WebXRManager or find XR elements in the DOM,
      // we're likely in an XR context
      const isInContext = typeof window !== 'undefined' && 
        ((document.querySelector('[data-xr-canvas="true"]') !== null) ||
         (document.querySelector('canvas.__r3f') !== null));
      
      setIsInXRContext(isInContext);
    } catch (error) {
      // If any error occurs during detection, assume we're not in XR context
      setIsInXRContext(false);
      logger.debug('XR context detection error, assuming outside context');
    }
  }, []);

  return isInXRContext;
};

export default useXRContextCheck;
----
src/features/xr/hooks/useSafeXRHooks.tsx
import React from 'react';
import { createLogger } from '../../../utils/logger';

const logger = createLogger('safeXRHooks');

// Default empty values for XR-related state when outside XR context
const emptyXRState = {
  isPresenting: false,
  controllers: [],
  player: null,
  session: null,
  hoverState: {},
};

/**
 * A safe version of useXR that won't throw errors when used outside XR context
 * This allows XR components to be rendered anywhere without errors
 */
export function useSafeXR() {
  try {
    // Try to dynamically import @react-three/xr hooks
    // This is needed because direct import at the top level would still cause errors
    const { useXR } = require('@react-three/xr');
    
    // If we get here, we can safely use the hook
    return useXR();
  } catch (error) {
    // If accessing the XR hook fails, return default values
    // to prevent component errors
    logger.debug('Using safe XR fallback - component outside XR context');
    return emptyXRState;
  }
}

/**
 * A safe wrapper for creating XR-dependent components
 * that won't throw errors when used outside XR context
 */
export function withSafeXR<P extends object>(
  Component: React.ComponentType<P>,
  componentName: string = 'Component'
): React.FC<P> {
  const WrappedComponent: React.FC<P> = (props) => {
    try {
      // Try to render component normally
      return <Component {...props} />;
    } catch (error) {
      // If an XR-related error occurs, don't render the component
      logger.debug(`${componentName} not rendered - XR context error`);
      return null;
    }
  };
  
  // Set a display name for better debugging
  WrappedComponent.displayName = `withSafeXR(${componentName})`;
  
  return WrappedComponent;
}
----
src/features/settings/types/settingsTypes.ts
// Setting control types
export type SettingControlType = 'slider' | 'toggle' | 'color' | 'select' | 'number' | 'text';

// Setting control interface
export interface SettingControl {
  label: string;
  type: SettingControlType;
  options?: string[];
  min?: number;
  max?: number;
  step?: number;
  tooltip?: string;
}

// Setting value types
export type SettingValue = string | number | boolean | string[] | number[];

// Settings section props
export interface SettingsSectionProps {
  id: string;
  title: string;
  settings: Record<string, SettingControl | Record<string, SettingControl>>;
  advanced?: boolean;
}

// Settings subsection props
export interface SettingsSubsectionProps {
  title: string;
  path: string;
  settings: Record<string, SettingControl> | SettingControl;
}

// Setting control props
export interface SettingControlProps {
  path: string;
  setting: SettingControl;
  value: any;
  onChange: (value: any) => void;
}
----
src/features/settings/types/uiSetting.ts
/**
 * Type definitions for UI settings as actually used in components
 */

/**
 * Interface for settings that can be controlled through UI components
 * This represents the runtime structure of settings as they appear in the components
 */
export interface UISetting {
  type: string;
  id?: string;
  label?: string;
  description?: string;
  help?: string;
  value?: any;
  min?: number;
  max?: number;
  step?: number;
  unit?: string;
  placeholder?: string;
  options?: Array<{ value: string; label: string }>;
  advanced?: boolean;
}

/**
 * Type guard to check if an object is a valid setting control
 */
export function isUISetting(obj: any): obj is UISetting {
  return obj && typeof obj === 'object' && 'type' in obj;
}
----
src/features/settings/types/settingsSchema.ts
/**
 * This file defines the schema for the application settings.
 * It provides type definitions, validation rules, and default values
 * for all configurable settings.
 */

// Control Types
export type ControlType = 
  | 'text'
  | 'number'
  | 'checkbox'
  | 'select'
  | 'color'
  | 'slider'
  | 'button'
  | 'group';

// Basic Schema Types
export interface BaseSettingSchema {
  /** Unique identifier for this setting */
  id: string;
  
  /** Human-readable label */
  label: string;
  
  /** Optional detailed description */
  description?: string;
  
  /** Type of control used for this setting */
  controlType: ControlType;
  
  /** Whether this setting is advanced and should be hidden by default */
  advanced?: boolean;
  
  /** Whether this setting is read-only */
  readonly?: boolean;
  
  /** Tags for categorization and filtering */
  tags?: string[];
}

export interface TextSettingSchema extends BaseSettingSchema {
  controlType: 'text';
  defaultValue: string;
  placeholder?: string;
  validation?: {
    pattern?: string;
    minLength?: number;
    maxLength?: number;
    required?: boolean;
  };
}

export interface NumberSettingSchema extends BaseSettingSchema {
  controlType: 'number';
  defaultValue: number;
  min?: number;
  max?: number;
  step?: number;
  validation?: {
    required?: boolean;
    integer?: boolean;
  };
}

export interface CheckboxSettingSchema extends BaseSettingSchema {
  controlType: 'checkbox';
  defaultValue: boolean;
}

export interface SelectSettingSchema extends BaseSettingSchema {
  controlType: 'select';
  defaultValue: string | number;
  options: Array<{
    label: string;
    value: string | number;
    description?: string;
  }>;
  allowCustom?: boolean;
}

export interface ColorSettingSchema extends BaseSettingSchema {
  controlType: 'color';
  defaultValue: string;
  format?: 'hex' | 'rgb' | 'hsl';
  alpha?: boolean;
}

export interface SliderSettingSchema extends BaseSettingSchema {
  controlType: 'slider';
  defaultValue: number;
  min: number;
  max: number;
  step?: number;
  showValue?: boolean;
  unit?: string;
}

export interface ButtonSettingSchema extends BaseSettingSchema {
  controlType: 'button';
  action: string;
  variant?: 'default' | 'destructive' | 'outline' | 'secondary' | 'ghost' | 'link';
}

export interface GroupSettingSchema extends BaseSettingSchema {
  controlType: 'group';
  settings: SettingSchema[];
  collapsible?: boolean;
  defaultCollapsed?: boolean;
}

export type SettingSchema =
  | TextSettingSchema
  | NumberSettingSchema
  | CheckboxSettingSchema
  | SelectSettingSchema
  | ColorSettingSchema
  | SliderSettingSchema
  | ButtonSettingSchema
  | GroupSettingSchema;

// Define categories for organization
export interface SettingsCategory {
  id: string;
  label: string;
  description?: string;
  icon?: string;
  subcategories?: {
    id: string;
    label: string;
    description?: string;
    settings: SettingSchema[];
  }[];
}

// Helper function to format settings labels
export function formatSettingLabel(label: string): string {
  // Replace underscores with spaces
  let formatted = label.replace(/_/g, ' ');
  
  // Capitalize first letter
  formatted = formatted.charAt(0).toUpperCase() + formatted.slice(1);
  
  // Capitalize after spaces
  formatted = formatted.replace(/\s([a-z])/g, function(match) {
    return ' ' + match.toUpperCase();
  });
  
  return formatted;
}

// Helper for validating setting values against schema
export function validateSetting(schema: SettingSchema, value: any): { valid: boolean; error?: string } {
  switch (schema.controlType) {
    case 'text': {
      if (typeof value !== 'string') {
        return { valid: false, error: 'Value must be a string' };
      }
      
      const validation = (schema as TextSettingSchema).validation;
      
      if (validation?.required && value.trim() === '') {
        return { valid: false, error: 'This field is required' };
      }
      
      if (validation?.minLength !== undefined && value.length < validation.minLength) {
        return { valid: false, error: `Must be at least ${validation.minLength} characters` };
      }
      
      if (validation?.maxLength !== undefined && value.length > validation.maxLength) {
        return { valid: false, error: `Must be at most ${validation.maxLength} characters` };
      }
      
      if (validation?.pattern && !new RegExp(validation.pattern).test(value)) {
        return { valid: false, error: 'Invalid format' };
      }
      
      return { valid: true };
    }
    case 'number': {
      if (typeof value !== 'number' || isNaN(value)) {
        return { valid: false, error: 'Value must be a number' };
      }
      
      const { min, max, validation } = schema as NumberSettingSchema;
      
      if (validation?.integer && !Number.isInteger(value)) {
        return { valid: false, error: 'Value must be an integer' };
      }
      
      if (min !== undefined && value < min) {
        return { valid: false, error: `Value must be at least ${min}` };
      }
      
      if (max !== undefined && value > max) {
        return { valid: false, error: `Value must be at most ${max}` };
      }
      
      return { valid: true };
    }
    case 'checkbox': {
      if (typeof value !== 'boolean') {
        return { valid: false, error: 'Value must be a boolean' };
      }
      
      return { valid: true };
    }
    case 'select': {
      const { options, allowCustom } = schema as SelectSettingSchema;
      
      // If custom values are allowed, just check type
      if (allowCustom) {
        if (typeof value !== 'string' && typeof value !== 'number') {
          return { valid: false, error: 'Value must be a string or number' };
        }
        return { valid: true };
      }
      
      // Otherwise, check if value is in options
      const isValid = options.some(option => option.value === value);
      if (!isValid) {
        return { valid: false, error: 'Value must be one of the available options' };
      }
      
      return { valid: true };
    }
    case 'color': {
      if (typeof value !== 'string') {
        return { valid: false, error: 'Value must be a string' };
      }
      
      // Simple validation for hex color
      const { format } = schema as ColorSettingSchema;
      
      if (format === 'hex' || !format) {
        const hexRegex = /^#([0-9A-F]{3}){1,2}$/i;
        if (!hexRegex.test(value)) {
          return { valid: false, error: 'Invalid hex color format' };
        }
      }
      
      return { valid: true };
    }
    case 'slider': {
      if (typeof value !== 'number' || isNaN(value)) {
        return { valid: false, error: 'Value must be a number' };
      }
      
      const { min, max } = schema as SliderSettingSchema;
      
      if (value < min) {
        return { valid: false, error: `Value must be at least ${min}` };
      }
      
      if (value > max) {
        return { valid: false, error: `Value must be at most ${max}` };
      }
      
      return { valid: true };
    }
    case 'button':
    case 'group':
      // These types don't have values to validate
      return { valid: true };
    default:
      return { valid: false, error: 'Unknown control type' };
  }
}

// Helper to get default value from schema
export function getDefaultValue(schema: SettingSchema): any {
  if ('defaultValue' in schema) {
    return schema.defaultValue;
  }
  
  if (schema.controlType === 'group') {
    const groupSchema = schema as GroupSettingSchema;
    const defaults: Record<string, any> = {};
    
    groupSchema.settings.forEach(setting => {
      defaults[setting.id] = getDefaultValue(setting);
    });
    
    return defaults;
  }
  
  return undefined;
}

export interface WebSocketSettings {
  host: string;
  port: string;
  path: string;
  secure: boolean;
}

export interface SystemSettings {
  websocket: WebSocketSettings;
  debug: {
    enabled: boolean;
    logLevel: 'debug' | 'info' | 'warn' | 'error';
    showStats: boolean;
  };
}
----
src/features/settings/components/BackendUrlSetting.tsx
import React, { useState, useEffect } from 'react';
import { useSettingsStore } from '@/store/settingsStore';
import { Button } from '@/ui/Button';
import { Input } from '@/ui/Input';
import { Label } from '@/ui/Label';
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from '@/ui/Card';
import WebSocketService from '@/services/WebSocketService';
import { createLogger } from '@/utils/logger';

const logger = createLogger('BackendUrlSetting');

export function BackendUrlSetting() {
  const { get: getSetting, set: setSetting } = useSettingsStore();
  const [backendUrl, setBackendUrl] = useState<string>('');
  const [isConnected, setIsConnected] = useState<boolean>(false);
  
  // Initialize from settings
  useEffect(() => {
    const storedUrl = getSetting('system.customBackendUrl') as string;
    setBackendUrl(storedUrl || '');
    
    // Check connection status
    const websocketService = WebSocketService.getInstance();
    setIsConnected(websocketService.isReady());
    
    // Subscribe to connection status changes
    const unsubscribe = websocketService.onConnectionStatusChange((connected) => {
      setIsConnected(connected);
    });
    
    return () => {
      unsubscribe();
    };
  }, [getSetting]);
  
  const handleSave = () => {
    // Save to settings
    setSetting('system.customBackendUrl', backendUrl);
    
    // Update WebSocket service
    const websocketService = WebSocketService.getInstance();
    websocketService.setCustomBackendUrl(backendUrl || null);
    
    logger.info(`Backend URL set to: ${backendUrl || 'default'}`);
  };
  
  const handleReset = () => {
    setBackendUrl('');
    setSetting('system.customBackendUrl', '');
    
    // Reset WebSocket service to default URL
    const websocketService = WebSocketService.getInstance();
    websocketService.setCustomBackendUrl(null);
    
    logger.info('Backend URL reset to default');
  };
  
  return (
    <Card className="w-full">
      <CardHeader>
        <CardTitle>Backend Connection</CardTitle>
        <CardDescription>
          Configure the connection to the backend server
        </CardDescription>
      </CardHeader>
      <CardContent>
        <div className="grid gap-4">
          <div className="flex items-center gap-2">
            <div className={`w-3 h-3 rounded-full ${isConnected ? 'bg-green-500' : 'bg-red-500'}`}></div>
            <span>{isConnected ? 'Connected' : 'Disconnected'}</span>
          </div>
          
          <div className="grid gap-2">
            <Label htmlFor="backendUrl">Backend URL</Label>
            <Input
              id="backendUrl"
              placeholder="e.g., http://192.168.0.51:8000"
              value={backendUrl}
              onChange={(e) => setBackendUrl(e.target.value)}
            />
            <p className="text-sm text-muted-foreground">
              Leave empty to use the default backend URL. Changes require reconnection.
            </p>
          </div>
        </div>
      </CardContent>
      <CardFooter className="flex justify-between">
        <Button variant="outline" onClick={handleReset}>
          Reset to Default
        </Button>
        <Button onClick={handleSave}>
          Save & Reconnect
        </Button>
      </CardFooter>
    </Card>
  );
}

export default BackendUrlSetting;

----
src/features/settings/components/control-panel-context.tsx
import React, { createContext, useContext, useState, ReactNode } from 'react';

interface ControlPanelContextType {
  advancedMode: boolean;
  toggleAdvancedMode: () => void;
}

const defaultContext: ControlPanelContextType = {
  advancedMode: false,
  toggleAdvancedMode: () => {},
};

const ControlPanelContext = createContext<ControlPanelContextType>(defaultContext);

interface ControlPanelProviderProps {
  children: ReactNode;
}

export const ControlPanelProvider: React.FC<ControlPanelProviderProps> = ({ children }) => {
  const [advancedMode, setAdvancedMode] = useState(false);

  const toggleAdvancedMode = () => {
    setAdvancedMode(prev => !prev);
  };

  return (
    <ControlPanelContext.Provider value={{ advancedMode, toggleAdvancedMode }}>
      {children}
    </ControlPanelContext.Provider>
  );
};

export const useControlPanelContext = (): ControlPanelContextType => {
  const context = useContext(ControlPanelContext);
  if (!context) {
    // Return default context instead of throwing an error
    // This makes the hook more resilient when used outside the provider
    return defaultContext;
  }
  return context;
};

----
src/features/settings/components/SettingsSection.tsx
import React, { useState } from 'react'; // Added React import
import { Collapsible, CollapsibleContent, CollapsibleTrigger } from '@/ui/Collapsible';
import { Card, CardContent, CardHeader, CardTitle } from '@/ui/Card';
import { ChevronDown, ChevronUp, Minimize, Maximize } from 'lucide-react';
import { Button } from '@/ui/Button';
// Removed import for SettingsSectionProps from types
// Removed import for SettingsSubsection
import Draggable from 'react-draggable';
import { useControlPanelContext } from './control-panel-context';
import { UISettingDefinition } from '../config/settingsUIDefinition'; // Import the definition type
import { SettingControlComponent } from './SettingControlComponent'; // Import the control component
import { useSettingsStore } from '@/store/settingsStore'; // Adjust path if necessary

// Define props locally
interface SettingsSectionProps {
  id: string;
  title: string;
  subsectionSettings: Record<string, UISettingDefinition>;
}

export function SettingsSection({ id, title, subsectionSettings }: SettingsSectionProps) {
  const [isOpen, setIsOpen] = useState(true);
  const [isDetached, setIsDetached] = useState(false);
  const { advancedMode } = useControlPanelContext();
  const settingsStore = useSettingsStore.getState(); // Get store state once

  // Removed advanced prop check at the top level

  // Removed old subsection mapping logic

  const handleDetach = () => {
    setIsDetached(!isDetached);
  };

  const renderSettings = () => (
    <div className="space-y-4">
      {Object.entries(subsectionSettings).map(([settingKey, settingDef]) => {
        // Visibility check: Advanced
        if (settingDef.isAdvanced && !advancedMode) {
          return null;
        }

        // Visibility/Read-only check: Power User
        const isPowerUser = settingsStore.user?.isPowerUser ?? false;
        if (settingDef.isPowerUserOnly && !isPowerUser) {
          // Decide whether to hide or show as read-only. Hiding for now.
          // TODO: Implement read-only display if needed
          return null;
        }

        // Retrieve value and define onChange handler
        const value = settingsStore.get(settingDef.path);
        const handleChange = (newValue: any) => {
          settingsStore.set(settingDef.path, newValue);
        };

        return (
          <SettingControlComponent
            key={settingKey}
            path={settingDef.path}
            settingDef={settingDef}
            value={value}
            onChange={handleChange}
          />
        );
      })}
    </div>
  );

  if (isDetached) {
    return (
      <DetachedSection
        title={title}
        onReattach={handleDetach}
        sectionId={id}
      >
        <div className="p-2"> {/* Removed extra space-y-4, handled by renderSettings */}
          {renderSettings()}
        </div>
      </DetachedSection>
    );
  }

  return (
    <Card className="settings-section bg-card border border-border"> {/* Added background and border */}
      <CardHeader className="py-2 px-4">
        <Collapsible open={isOpen} onOpenChange={setIsOpen}>
          <div className="flex items-center justify-between">
            <CollapsibleTrigger asChild>
              <Button variant="ghost" size="sm" className="h-8 p-0 hover:bg-muted/50"> {/* Added hover effect */}
                <CardTitle className="text-sm font-medium text-card-foreground">{title}</CardTitle>
                {isOpen ? <ChevronUp className="ml-2 h-4 w-4 text-muted-foreground" /> : <ChevronDown className="ml-2 h-4 w-4 text-muted-foreground" />}
              </Button>
            </CollapsibleTrigger>
            <Button
              variant="ghost"
              size="icon"
              className="h-6 w-6 text-muted-foreground hover:text-card-foreground hover:bg-muted/50" // Added hover effect
              onClick={handleDetach}
              title="Detach section"
            >
              <Maximize className="h-3 w-3" />
            </Button>
          </div>

          <CollapsibleContent>
            <CardContent className="p-4 pt-3"> {/* Adjusted padding */}
              {renderSettings()}
            </CardContent>
          </CollapsibleContent>
        </Collapsible>
      </CardHeader>
    </Card>
  );
}

// Detached floating section component (Keep as is, but ensure it uses the new renderSettings)
function DetachedSection({
  children,
  title,
  onReattach,
  sectionId
}: {
  children: React.ReactNode;
  title: string;
  onReattach: () => void;
  sectionId: string;
}) {
  const [position, setPosition] = useState({ x: 100, y: 100 });

  const handleDrag = (e: any, data: { x: number; y: number }) => {
    setPosition({ x: data.x, y: data.y });
  };

  // Ensure the parent element for bounds exists and covers the intended area
  // If bounds="parent" doesn't work as expected, might need a specific selector or DOM element reference.

  return (
    <Draggable
      handle=".drag-handle" // Use a specific handle for dragging
      position={position}
      onDrag={handleDrag}
      bounds="body" // Changed bounds to body to allow freer movement
    >
      <div
        className="detached-panel absolute z-[3000] min-w-[300px] bg-card rounded-lg shadow-lg border border-border" // Added background, rounded corners
        data-section-id={sectionId}
      >
        <div className="drag-handle flex items-center justify-between border-b border-border p-2 cursor-move bg-muted/50 rounded-t-lg"> {/* Added handle class, background */}
          <div className="text-sm font-medium text-card-foreground">
            {title}
          </div>
          <Button
            variant="ghost"
            size="icon"
            className="h-6 w-6 text-muted-foreground hover:text-card-foreground hover:bg-muted/50" // Added hover effect
            onClick={onReattach}
            title="Reattach section"
          >
            <Minimize className="h-3 w-3" />
          </Button>
        </div>
        <div className="p-4 max-h-[400px] overflow-y-auto custom-scrollbar"> {/* Added padding, max-height and scroll */}
          {children}
        </div>
      </div>
    </Draggable>
  );
}
----
src/features/settings/components/SettingsSubsection.tsx
import { useSettingsStore } from '@/store/settingsStore'
import { SettingsSubsectionProps } from '../types/settingsTypes'
import { SettingControl } from '../types/settingsTypes'
import { formatSettingName } from '../config/settingsConfig'
import { SettingControlComponent } from './SettingControlComponent'

export function SettingsSubsection({ title, settings, path }: SettingsSubsectionProps) {
  const settingsStore = useSettingsStore()

  // Check if this is a single setting or a group of settings
  // Fix: Check if settings is an object before using 'in' operator
  const isObject = settings !== null && typeof settings === 'object';
  const isSingleSetting = isObject && 'type' in settings;
  
  // Format the title for display
  const formattedTitle = formatSettingName(title);
  
  return (
    <div className="settings-subsection">
      <h3 className="mb-2 text-sm font-medium text-muted-foreground">
        {formattedTitle}
      </h3>
      
      <div className="space-y-2">
        {isSingleSetting ? (
          // Render a single setting control
          <SettingControlComponent
            path={path}
            setting={settings as SettingControl}
            value={settingsStore.get(path)}
            onChange={(value) => settingsStore.set(path, value)}
          />
        ) : (
          // Render multiple setting controls
          Object.entries(settings as Record<string, SettingControl>).map(([key, setting]) => {
            const fullPath = `${path}.${key}`;
            return (
              <SettingControlComponent
                key={key}
                path={fullPath}
                setting={setting}
                value={settingsStore.get(fullPath)}
                onChange={(value) => settingsStore.set(fullPath, value)}
              />
            );
          })
        )}
      </div>
    </div>
  );
}
----
src/features/settings/components/SettingControlComponent.tsx
import React, { useState, useEffect, useCallback } from 'react';
import { UISettingDefinition } from '../config/settingsUIDefinition'; // Import the new definition type
import { Label } from '@/ui/Label';
import { Slider } from '@/ui/Slider';
import { Switch } from '@/ui/Switch';
import { Input } from '@/ui/Input';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/ui/Select';
import { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from '@/ui/Tooltip';
import { Button } from '@/ui/Button';
import { Info } from 'lucide-react';

// Simple inline useDebounce hook
function useDebounce<T>(value: T, delay: number): T {
  const [debouncedValue, setDebouncedValue] = useState<T>(value);

  useEffect(() => {
    const handler = setTimeout(() => {
      setDebouncedValue(value);
    }, delay);

    return () => {
      clearTimeout(handler);
    };
  }, [value, delay]);

  return debouncedValue;
}

// Define props based on the plan
export interface SettingControlProps {
  path: string;
  settingDef: UISettingDefinition;
  value: any;
  onChange: (value: any) => void;
}

export function SettingControlComponent({ path, settingDef, value, onChange }: SettingControlProps) {
  // State for debounced inputs
  const [inputValue, setInputValue] = useState(String(value ?? ''));
  const debouncedInputValue = useDebounce(inputValue, 300); // 300ms debounce

  // Update internal state when the external value changes
  useEffect(() => {
    // Only update if the debounced value isn't the source of the change
    // This prevents loops but might need refinement depending on useDebounce implementation
    if (String(value) !== inputValue) {
       if (settingDef.type === 'rangeSlider' || settingDef.type === 'dualColorPicker') {
         // For array types, handle string conversion carefully if needed, or maybe skip input state?
         // For now, let's assume direct value prop usage for sliders/pickers is better for arrays.
       } else {
         setInputValue(String(value ?? ''));
       }
    }
  // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [value, settingDef.type]); // Rerun if value or type changes

  // Effect to call onChange when debounced value changes
  useEffect(() => {
    if (settingDef.type === 'textInput' || settingDef.type === 'numberInput') {
      // Avoid calling onChange with the initial value or if it hasn't changed
      if (debouncedInputValue !== String(value ?? '')) {
        if (settingDef.type === 'numberInput') {
          const numValue = parseFloat(debouncedInputValue);
          if (!isNaN(numValue)) {
            onChange(numValue);
          }
        } else {
          onChange(debouncedInputValue);
        }
      }
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [debouncedInputValue, settingDef.type, onChange]); // Depend on debounced value

  // Handler for immediate input changes (updates local state)
  const handleInputChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    setInputValue(e.target.value);
  };

  // Render appropriate control based on settingDef.type
  const renderControl = () => {
    switch (settingDef.type) {
      case 'toggle':
        return (
          <Switch
            id={path}
            checked={Boolean(value)}
            onCheckedChange={onChange}
          />
        );

      case 'slider':
        return (
          <div className="flex w-full items-center gap-3">
            <Slider
              id={path}
              value={[value as number]} // Slider expects an array
              min={settingDef.min ?? 0}
              max={settingDef.max ?? 1}
              step={settingDef.step ?? 0.01} // Sensible default step
              onValueChange={([val]) => onChange(val)}
              className="flex-1"
            />
            <span className="text-xs font-mono w-12 text-right">
              {(value as number)?.toFixed ? (value as number).toFixed(settingDef.step && settingDef.step < 1 ? 2 : 0) : value}
              {settingDef.unit}
            </span>
          </div>
        );

      case 'numberInput':
        // If min and max are defined, prefer Slider for a more intuitive UI
        if (typeof settingDef.min === 'number' && typeof settingDef.max === 'number') {
          return (
            <div className="flex w-full items-center gap-3">
              <Slider
                id={path}
                value={[value as number]} // Slider expects an array
                min={settingDef.min}
                max={settingDef.max}
                step={settingDef.step ?? 0.01} // Default step for slider
                onValueChange={([val]) => onChange(val)} // Direct change
                className="flex-1"
              />
              <span className="text-xs font-mono w-12 text-right">
                {(value as number)?.toFixed ? (value as number).toFixed(settingDef.step && settingDef.step < 1 ? 2 : 0) : value}
                {settingDef.unit}
              </span>
            </div>
          );
        }
        // Fallback to Input if min/max not defined for slider behavior
        return (
          <div className="flex items-center w-full">
            <Input
              id={path}
              type="number"
              value={inputValue} // Use local state for debouncing
              onChange={handleInputChange} // Update local state immediately
              min={settingDef.min}
              max={settingDef.max}
              step={settingDef.step ?? 1} // Default step for input
              className="h-8 flex-1"
            />
            {settingDef.unit && <span className="text-xs text-muted-foreground pl-2">{settingDef.unit}</span>}
          </div>
        );

      case 'textInput':
        // Special handling for obscured fields like API keys
        const isSensitive = settingDef.label.toLowerCase().includes('key') || settingDef.label.toLowerCase().includes('secret');
        return (
          <div className="flex items-center w-full">
            <Input
              id={path}
              type={isSensitive ? "password" : "text"}
              value={inputValue} // Use local state for debouncing
              onChange={handleInputChange} // Update local state immediately
              className="h-8 flex-1" // Allow input to grow
            />
            {settingDef.unit && <span className="text-xs text-muted-foreground pl-2">{settingDef.unit}</span>}
          </div>
        );

      case 'colorPicker':
        return (
          <div className="flex items-center gap-2">
            <Input
              id={path}
              type="color"
              value={String(value ?? '#000000')} // Ensure value is a string, default if null/undefined
              onChange={(e) => {
                // Ensure a valid hex color is always passed
                const newValue = e.target.value;
                if (/^#[0-9A-Fa-f]{6}$/i.test(newValue)) {
                  onChange(newValue);
                } else {
                  onChange('#000000'); // Fallback if somehow invalid from color input
                }
              }}
              className="h-8 w-10 p-0.5 border-border cursor-pointer"
            />
            <Input
              type="text"
              value={String(value ?? '')} // Reflect current value, allow empty for typing
              onChange={(e) => {
                const newValue = e.target.value;
                if (/^#[0-9A-Fa-f]{6}$/i.test(newValue)) {
                  onChange(newValue);
                } else if (newValue === '') {
                  // If user clears the input, set to a default to avoid sending empty string
                  // Or, you could choose not to call onChange, making the text input temporarily invalid
                  // For now, let's set a default to prevent server errors.
                  onChange('#000000'); // Default if cleared
                }
                // For other invalid inputs, we don't call onChange,
                // so the store isn't updated with an invalid partial hex.
                // The visual input will show the invalid text until corrected or blurred.
              }}
              onBlur={(e) => { // Ensure on blur, if invalid, it reverts or uses a default
                const currentValue = e.target.value;
                if (!/^#[0-9A-Fa-f]{6}$/i.test(currentValue)) {
                    // If current store value is valid, revert to it, else default
                    if (typeof value === 'string' && /^#[0-9A-Fa-f]{6}$/i.test(value)) {
                        onChange(value); // Revert to last known good value from store
                    } else {
                        onChange('#000000'); // Fallback to black
                    }
                }
              }}
              className="h-8 flex-1 font-mono text-xs"
              placeholder="#rrggbb"
            />
          </div>
        );

      case 'select':
        return (
          <Select
            value={String(value)} // Ensure value is string for Select
            onValueChange={(val) => onChange(val)} // Pass the string value back
          >
            <SelectTrigger id={path} className="h-8 w-full">
              <SelectValue placeholder={settingDef.label} />
            </SelectTrigger>
            <SelectContent>
              {settingDef.options?.map(opt => (
                <SelectItem key={String(opt.value)} value={String(opt.value)}>
                  {opt.label}
                </SelectItem>
              ))}
            </SelectContent>
          </Select>
        );

      case 'rangeSlider': { // For [number, number] arrays
        const [minVal, maxVal] = Array.isArray(value) ? value : [settingDef.min ?? 0, settingDef.max ?? 1];
        const handleMinChange = (e: React.ChangeEvent<HTMLInputElement>) => {
          const newMin = parseFloat(e.target.value);
          if (!isNaN(newMin)) {
            onChange([newMin, maxVal]);
          }
        };
        const handleMaxChange = (e: React.ChangeEvent<HTMLInputElement>) => {
          const newMax = parseFloat(e.target.value);
          if (!isNaN(newMax)) {
            onChange([minVal, newMax]);
          }
        };
        return (
          <div className="flex flex-col gap-2">
            <div className="flex items-center gap-2">
              <Label htmlFor={`${path}-min`} className="text-xs w-10">Min:</Label>
              <Input id={`${path}-min`} type="number" value={minVal} onChange={handleMinChange} min={settingDef.min} max={maxVal} step={settingDef.step} className="h-8 flex-1" placeholder="Min" />
            </div>
            <div className="flex items-center gap-2">
              <Label htmlFor={`${path}-max`} className="text-xs w-10">Max:</Label>
              <Input id={`${path}-max`} type="number" value={maxVal} onChange={handleMaxChange} min={minVal} max={settingDef.max} step={settingDef.step} className="h-8 flex-1" placeholder="Max" />
            </div>
            {settingDef.unit && <span className="text-xs text-muted-foreground self-end">{settingDef.unit}</span>}
          </div>
        );
      }

      case 'dualColorPicker': { // For [string, string] color arrays
        const [color1 = '#ffffff', color2 = '#000000'] = Array.isArray(value) && value.length === 2 ? value : ['#ffffff', '#000000'];

        const createColorChangeHandler = (index: 0 | 1) => (e: React.ChangeEvent<HTMLInputElement>) => {
          const newColorValue = e.target.value;
          const currentColors = [color1, color2];
          
          if (/^#[0-9A-Fa-f]{6}$/i.test(newColorValue)) {
            currentColors[index] = newColorValue;
            onChange([...currentColors]);
          } else if (newColorValue === '') {
            currentColors[index] = '#000000'; // Default if cleared
            onChange([...currentColors]);
          }
          // For other invalid inputs, do not call onChange from text input
        };

        const createColorBlurHandler = (index: 0 | 1) => (e: React.ChangeEvent<HTMLInputElement>) => {
            const currentColors = [color1, color2];
            const blurredValue = e.target.value;
            if (!/^#[0-9A-Fa-f]{6}$/i.test(blurredValue)) {
                // Revert to original value for this specific color input if it was valid, else default
                const originalColorAtIndex = (Array.isArray(value) && value.length === 2 && typeof value[index] === 'string' && /^#[0-9A-Fa-f]{6}$/i.test(value[index])) ? value[index] : '#000000';
                currentColors[index] = originalColorAtIndex;
                onChange([...currentColors]);
            }
        };

        return (
          <div className="flex flex-col gap-2">
            <div className="flex items-center gap-2">
              <Label className="text-xs w-16">Start:</Label>
              <Input type="color" value={color1} onChange={createColorChangeHandler(0)} className="h-8 w-10 p-0.5 border-border cursor-pointer" title="Start Color" />
              <Input type="text" value={color1} onChange={createColorChangeHandler(0)} onBlur={createColorBlurHandler(0)} className="h-8 flex-1 font-mono text-xs" placeholder="#rrggbb" />
            </div>
            <div className="flex items-center gap-2">
              <Label className="text-xs w-16">End:</Label>
              <Input type="color" value={color2} onChange={createColorChangeHandler(1)} className="h-8 w-10 p-0.5 border-border cursor-pointer" title="End Color" />
              <Input type="text" value={color2} onChange={createColorChangeHandler(1)} onBlur={createColorBlurHandler(1)} className="h-8 flex-1 font-mono text-xs" placeholder="#rrggbb" />
            </div>
          </div>
        );
      }


      case 'buttonAction':
        return (
          <Button onClick={settingDef.action} size="sm" variant="outline">
            {settingDef.label} {/* Button text is the label */}
          </Button>
        );

      default:
        // Render value as string for unknown types
        return <span className="text-sm text-muted-foreground">{JSON.stringify(value)}</span>;
    }
  };

  // For button actions, the label is the button itself, so we don't need a separate label.
  if (settingDef.type === 'buttonAction') {
    return renderControl();
  }

  return (
    <div className="setting-control flex items-center justify-between gap-4 py-2 border-b border-border/50 last:border-b-0">
      <Label htmlFor={path} className="text-sm flex items-center gap-1 flex-shrink-0 max-w-[40%]"> {/* Limit label width */}
        <span>{settingDef.label}</span>
        {settingDef.description && (
          <TooltipProvider delayDuration={100}>
            <Tooltip content={settingDef.description} side="top" align="start">
              {/* The Info icon will be the trigger, Tooltip content is via prop */}
              <Info className="h-3 w-3 text-muted-foreground cursor-help" />
            </Tooltip>
          </TooltipProvider>
        )}
      </Label>
      <div className="flex-1 min-w-0"> {/* Allow control area to grow and shrink */}
        {renderControl()}
      </div>
    </div>
  );
}
----
src/features/settings/components/panels/XRPanel.tsx
import React from 'react'; // Removed useState
import { useSettingsStore } from '../../../../store/settingsStore'; // Keep for persisting preference if needed
import { createLogger } from '../../../../utils/logger';
import { SettingsSection } from '../SettingsSection';
import { UICategoryDefinition, UISettingDefinition } from '../../config/settingsUIDefinition';
import { useApplicationMode } from '../../../../contexts/ApplicationModeContext'; // For XR mode toggle
import { Switch } from '../../../../ui/Switch'; // For XR mode toggle
import { Label } from '../../../../ui/Label'; // For XR mode toggle label
import { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from '@/ui/Tooltip'; // For XR mode toggle tooltip
import { Info } from 'lucide-react'; // For XR mode toggle tooltip icon
import { FormGroup } from '@/ui/formGroup/FormGroup'; // For XR mode toggle styling

const logger = createLogger('XRPanel');

// Removed XR_SUBSECTIONS constant

export interface XRPanelProps { // Renamed interface
  settingsDef: UICategoryDefinition;
}

const XRPanel: React.FC<XRPanelProps> = ({ settingsDef }) => {
  const { mode: applicationMode, setMode: setApplicationMode } = useApplicationMode();
  const settingsStoreSet = useSettingsStore(state => state.set); // For persisting preference

  // Find the clientSideEnableXR definition for direct rendering
  let clientSideEnableXRDef: UISettingDefinition | undefined;
  for (const subsec of Object.values(settingsDef.subsections)) {
    if (subsec.settings['clientSideEnableXR']) {
      clientSideEnableXRDef = subsec.settings['clientSideEnableXR'];
      break;
    }
  }

  const handleXRModeToggle = (checked: boolean) => {
    setApplicationMode(checked ? 'xr' : 'desktop');
    // Optionally persist this preference to settings store if clientSideEnableXRDef.path is valid
    if (clientSideEnableXRDef?.path) {
      settingsStoreSet(clientSideEnableXRDef.path, checked);
      logger.info(`XR mode preference (${clientSideEnableXRDef.path}) set to: ${checked}`);
    }
  };

  const isClientXRModeEnabled = applicationMode === 'xr';

  return (
    <div className="p-4 space-y-6 overflow-y-auto h-full custom-scrollbar">
      {/* Special handling for clientSideEnableXR toggle */}
      {clientSideEnableXRDef && (
        <FormGroup
            label={clientSideEnableXRDef.label}
            id="client-xr-toggle"
            helpText={clientSideEnableXRDef.description}
            className="border-b border-border pb-4 mb-4"
        >
            <div className="flex items-center justify-between">
                <Label htmlFor="client-xr-toggle-switch" className="text-sm flex items-center gap-1">
                    <span>{clientSideEnableXRDef.label}</span>
                    {clientSideEnableXRDef.description && (
                    <TooltipProvider delayDuration={100}>
                        <Tooltip>
                            <TooltipTrigger asChild>
                                <Info className="h-3 w-3 text-muted-foreground cursor-help" />
                            </TooltipTrigger>
                            <TooltipContent side="top" align="start" className="max-w-xs z-[4000]">
                                <p>{clientSideEnableXRDef.description}</p>
                            </TooltipContent>
                        </Tooltip>
                    </TooltipProvider>
                    )}
                </Label>
                <Switch
                    id="client-xr-toggle-switch"
                    checked={isClientXRModeEnabled}
                    onCheckedChange={handleXRModeToggle}
                />
            </div>
        </FormGroup>
      )}

      {/* Iterate through subsections defined in settingsDef */}
      {Object.entries(settingsDef.subsections).map(([subsectionKey, subsectionDef]) => {
        // Filter out the clientSideEnableXR setting if it was handled above, to avoid rendering it twice
        const filteredSettings = { ...subsectionDef.settings };
        if (clientSideEnableXRDef && filteredSettings[clientSideEnableXRDef.path.split('.').pop()!]) {
             // Check if the current subsection contains the clientSideEnableXR setting
            if (clientSideEnableXRDef.path.startsWith(`${settingsDef.label.toLowerCase()}.${subsectionKey}`)) {
                delete filteredSettings[clientSideEnableXRDef.path.split('.').pop()!];
            }
        }

        // If after filtering, the subsection has no settings left (and it's not the one containing the special toggle),
        // or if it only contained the special toggle, don't render the section.
        if (Object.keys(filteredSettings).length === 0) {
            return null;
        }
        
        return (
          <SettingsSection
            key={subsectionKey}
            id={`settings-${settingsDef.label.toLowerCase()}-${subsectionKey}`}
            title={subsectionDef.label}
            subsectionSettings={filteredSettings} // Pass filtered settings
          />
        );
      })}

      {/* Retain custom informational text if needed */}
      <div className="space-y-6 pt-4 border-t border-border mt-6">
        <div className="bg-muted p-4 rounded-md text-sm shadow">
          <h4 className="font-medium mb-2 text-foreground">XR Control Information</h4>
          <p className="text-muted-foreground mb-2">
            These settings control how interaction works in VR and AR modes.
            When using a VR headset, you can use the controllers to interact with the visualisation.
          </p>
          <ul className="list-disc list-inside text-muted-foreground space-y-1">
            <li>Trigger button: Select</li>
            <li>Grip button: Grab and move</li>
            <li>Thumbstick: Navigate and rotate</li>
          </ul>
        </div>
        <div className="bg-muted p-4 rounded-md text-sm shadow">
          <h4 className="font-medium mb-2 text-foreground">XR Environment</h4>
          <p className="text-muted-foreground">
            These settings control the visual environment in VR and AR modes,
            including background, lighting, and scale.
          </p>
        </div>
      </div>
    </div>
  );
};

export default XRPanel;
----
src/features/settings/components/panels/AIPanel.tsx
import React from 'react';
// Removed Card, Label, Input, useSettingsStore, produce imports as they are handled by child components or not needed.
import { SettingsSection } from '../SettingsSection'; // Import SettingsSection
import { UICategoryDefinition } from '../../config/settingsUIDefinition'; // Import definition type

export interface AIPanelProps { // Renamed interface
  settingsDef: UICategoryDefinition;
}

const AIPanel: React.FC<AIPanelProps> = ({ settingsDef }) => {
  // Removed settings store access and handleChange function.
  // This will now be handled by SettingsSection and SettingControlComponent via settingsDef.

  return (
    <div className="p-4 space-y-6 overflow-y-auto h-full custom-scrollbar">
      {/* Iterate through AI service subsections defined in settingsDef */}
      {Object.entries(settingsDef.subsections).map(([subsectionKey, subsectionDef]) => (
        <SettingsSection
          key={subsectionKey}
          id={`settings-${settingsDef.label.toLowerCase().replace(/\s+/g, '-')}-${subsectionKey}`} // e.g., settings-ai-services-ragflow
          title={subsectionDef.label}
          subsectionSettings={subsectionDef.settings}
        />
      ))}
    </div>
  );
};

export default AIPanel;

----
src/features/settings/components/panels/VisualisationPanel.tsx
import React from 'react';
import { SettingsSection } from '../SettingsSection'; // Adjust path if necessary
import { UICategoryDefinition } from '../../config/settingsUIDefinition'; // Adjust path if necessary
// Removed unused imports like useState, useMemo, useSettingsStore, formatSettingLabel, createLogger, specific icons, UI components (Input, Switch, etc.), useTheme

// Removed logger initialization
// Removed VISUALIZATION_SUBSECTIONS constant

export interface VisualisationPanelProps { // Renamed interface for clarity
  settingsDef: UICategoryDefinition;
}

/**
 * VisualisationPanel renders settings controls for the 'Visualisation' category,
 * driven by the provided settings definition.
 */
const VisualisationPanel: React.FC<VisualisationPanelProps> = ({ settingsDef }) => {
  // Removed old state (activeSubsection) and settings retrieval logic (useSettingsStore, useMemo)
  // Removed updateSetting function (will be handled within SettingsSection/SettingControlComponent)
  // Removed theme logic (assuming handled by ThemeProvider globally)

  return (
    // Main container: Added padding, space between sections, overflow for scrolling, and full height
    <div className="p-4 space-y-6 overflow-y-auto h-full custom-scrollbar">
      {/* Iterate through subsections defined in settingsDef */}
      {Object.entries(settingsDef.subsections).map(([subsectionKey, subsectionDef]) => (
        <SettingsSection
          key={subsectionKey}
          // Generate a unique ID for accessibility/linking if needed
          id={`settings-${settingsDef.label.toLowerCase()}-${subsectionKey}`} // e.g., settings-visualisation-nodes
          title={subsectionDef.label}
          // Pass the specific settings definitions for this subsection
          subsectionSettings={subsectionDef.settings}
        />
      ))}
    </div>
  );
};

export default VisualisationPanel;

----
src/features/settings/components/panels/SystemPanel.tsx
import React, { useState, useEffect } from 'react'; // Added React
import { useSettingsStore } from '../../../../store/settingsStore';
import { createLogger } from '../../../../utils/logger';
import { graphDataManager } from '../../../graph/managers/graphDataManager';
import { SettingsSection } from '../SettingsSection'; // Import SettingsSection
import { UICategoryDefinition } from '../../config/settingsUIDefinition'; // Import definition type

const logger = createLogger('SystemPanel');

// Removed SYSTEM_SUBSECTIONS constant

export interface SystemPanelProps { // Renamed interface
  settingsDef: UICategoryDefinition;
}

const SystemPanel: React.FC<SystemPanelProps> = ({ settingsDef }) => {
  // Removed activeSubsection state
  const [apiStatus, setApiStatus] = useState({
    isConnected: false,
    lastFetchTime: null as string | null,
    nodesCount: 0,
    edgesCount: 0
  });

  // Removed settings and setSettings from useSettingsStore as they are handled by SettingsSection/SettingControlComponent

  // Removed old systemSettings retrieval and updateSetting/toggleSetting functions

  useEffect(() => {
    const updateApiStatus = () => {
      try {
        const currentData = graphDataManager.getGraphData();
        setApiStatus({
          isConnected: true,
          lastFetchTime: new Date().toLocaleTimeString(),
          nodesCount: currentData.nodes.length,
          edgesCount: currentData.edges.length
        });
      } catch (error) {
        logger.error('Failed to update API status:', error);
        setApiStatus(prev => ({
          ...prev,
          isConnected: false
        }));
      }
    };
    updateApiStatus();
    const unsubscribe = graphDataManager.onGraphDataChange(updateApiStatus);
    return () => unsubscribe();
  }, []);

  const handleClearConsole = () => {
    console.clear();
    logger.info('Console cleared');
  };

  const handleResetGraph = async () => {
    try {
      await graphDataManager.fetchInitialData();
      logger.info('Graph data reset successfully');
    } catch (error) {
      logger.error('Failed to reset graph:', error);
    }
  };

  const handleExportLogs = () => {
    const logs = logger.getLogs();
    const blob = new Blob([JSON.stringify(logs, null, 2)], { type: 'application/json' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `logs-${new Date().toISOString()}.json`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
  };

  const handleMemoryUsage = () => {
    try {
      // @ts-ignore - performance.memory is Chrome-specific
      const memory = window.performance.memory;
      if (memory) {
        logger.info('Memory usage:', {
          usedJSHeapSize: `${(memory.usedJSHeapSize / 1024 / 1024).toFixed(2)} MB`,
          totalJSHeapSize: `${(memory.totalJSHeapSize / 1024 / 1024).toFixed(2)} MB`,
          jsHeapSizeLimit: `${(memory.jsHeapSizeLimit / 1024 / 1024).toFixed(2)} MB`
        });
      } else {
        logger.warn('Memory usage information not available in this browser');
      }
    } catch (error) {
      logger.error('Failed to get memory usage:', error);
    }
  };

  return (
    <div className="p-4 space-y-6 overflow-y-auto h-full custom-scrollbar">
      {/* Iterate through subsections defined in settingsDef */}
      {Object.entries(settingsDef.subsections).map(([subsectionKey, subsectionDef]) => (
        <SettingsSection
          key={subsectionKey}
          id={`settings-${settingsDef.label.toLowerCase()}-${subsectionKey}`}
          title={subsectionDef.label}
          subsectionSettings={subsectionDef.settings}
        />
      ))}

      {/* Custom System Panel Content: API Status and Debug Actions */}
      <div className="space-y-6 pt-4 border-t border-border mt-6">
        <h3 className="text-lg font-semibold text-foreground">API Status & Diagnostics</h3>
        {/* API Connection Status */}
        <div className="p-4 bg-muted rounded-md shadow">
          <div className="flex items-center justify-between mb-2">
            <span className="text-sm font-medium text-foreground">API Status</span>
            <div className="flex items-center space-x-2">
              <span className={`inline-block w-2.5 h-2.5 rounded-full ${
                apiStatus.isConnected ? 'bg-green-500' : 'bg-red-500'
              }`}></span>
              <span className="text-sm text-muted-foreground">
                {apiStatus.isConnected ? 'Connected' : 'Disconnected'}
              </span>
            </div>
          </div>
          <div className="grid grid-cols-2 gap-x-4 gap-y-1 text-sm">
            <div className="text-muted-foreground">Last Fetch:</div>
            <div className="text-foreground">{apiStatus.lastFetchTime || 'N/A'}</div>
            <div className="text-muted-foreground">Nodes:</div>
            <div className="text-foreground">{apiStatus.nodesCount}</div>
            <div className="text-muted-foreground">Edges:</div>
            <div className="text-foreground">{apiStatus.edgesCount}</div>
          </div>
          <div className="mt-3 flex justify-end">
            <button
              className="px-3 py-1.5 text-xs bg-secondary text-secondary-foreground rounded-md hover:bg-secondary/80 transition-colors"
              onClick={() => graphDataManager.fetchInitialData()}
            >
              Refresh Data
            </button>
          </div>
        </div>

        {/* Debug Actions */}
        <div className="p-4 bg-muted rounded-md shadow">
          <h4 className="text-sm font-medium text-foreground mb-3">Debug Actions</h4>
          <div className="grid grid-cols-2 gap-2">
            <button
              className="px-3 py-2 bg-secondary text-secondary-foreground rounded-md hover:bg-secondary/80 text-sm transition-colors"
              onClick={handleClearConsole}
            >
              Clear Console
            </button>
            <button
              className="px-3 py-2 bg-secondary text-secondary-foreground rounded-md hover:bg-secondary/80 text-sm transition-colors"
              onClick={handleResetGraph}
            >
              Reset Graph
            </button>
            <button
              className="px-3 py-2 bg-secondary text-secondary-foreground rounded-md hover:bg-secondary/80 text-sm transition-colors"
              onClick={handleExportLogs}
            >
              Export Logs
            </button>
            <button
              className="px-3 py-2 bg-secondary text-secondary-foreground rounded-md hover:bg-secondary/80 text-sm transition-colors"
              onClick={handleMemoryUsage}
            >
              Memory Usage
            </button>
          </div>
        </div>
      </div>
    </div>
  );
};

export default SystemPanel;
----
src/features/settings/config/defaultSettings.ts
// Define a basic Settings interface based on usage
interface Settings {
  visualisation: any; // Replace 'any' with more specific types if known
  system: any;        // Replace 'any' with more specific types if known
  auth: any;          // Replace 'any' with more specific types if known
  xr: any;            // Replace 'any' with more specific types if known
}

export const defaultSettings: Settings = {
  visualisation: {
    sceneBackground: 0x000000, // Black
    rendering: {
      shadows: true,
      antialias: true,
      pixelRatio: window.devicePixelRatio > 1 ? 1.5 : 1, // Balance quality and performance
      enableBloom: true,
      bloomStrength: 1.5,
      bloomThreshold: 0.4,
      bloomRadius: 0.85
    },
    camera: {
      fov: 75,
      near: 0.1,
      far: 2000,
      position: { x: 0, y: 10, z: 50 },
      lookAt: { x: 0, y: 0, z: 0 }
    },
    bloom: {
      enabled: true,
      strength: 1.5,
      threshold: 0.4,
      radius: 0.85
    },
    labels: {
      enabled: true,
      desktopFontSize: 0.1,
      textColor: '#000000',
      textOutlineColor: '#ffffff',
      textOutlineWidth: 0.01,
      textPadding: 0.3,
      textResolution: 32,
      billboardMode: 'camera'
    },
    icons: {
      enabled: true,
      size: 1.0,
      opacity: 0.8,
      color: '#ffffff'
    },
    metrics: {
      enabled: false,
      refreshRate: 1000,
      position: 'top-right'
    },
    nodes: {
      defaultSize: 1.0,
      minSize: 0.5,
      maxSize: 3.0,
      color: '#ff4500',
      highlightColor: '#ffff00',
      outlineWidth: 0.1,
      outlineColor: '#ffffff',
      selectedColor: '#00ff00'
    },
    edges: {
      width: 1.0,
      color: '#ffffff',
      highlightColor: '#ffff00',
      opacity: 0.8,
      showLabels: false,
      arrowSize: 0.5,
      dashSize: 3.0,
      gapSize: 1.0
    },
    physics: {
      enabled: true,
      gravity: 0.0,
      friction: 0.9,
      attraction: 0.5,
      repulsion: 1.0,
      damping: 0.8,
      springLength: 30,
      iterations: 50
    },
    hologram: {
      color: 0x00ffff,
      opacity: 0.7,
      ringOpacity: 0.7,
      sphereSizes: [40, 80],
      enableTriangleSphere: true,
      triangleSphereSize: 60,
      triangleSphereOpacity: 0.3,
      ringRotationSpeed: 0.5,
      globalRotationSpeed: 0.2
    },
    showStats: false,
    showAxes: false,
    showGrid: false
  },
  system: {
    websocket: {
      reconnectInterval: 2000,
      maxReconnectAttempts: 10
    },
    debug: {
      enabled: false,
      enableDataDebug: false,
      enableWebsocketDebug: false,
      logBinaryHeaders: false,
      logFullJson: false,
      logLevel: 'info',
      logFormat: 'text',
      // Legacy fields for backward compatibility
      showPerformance: false,
      showDataUpdates: false
    },
    apiEndpoint: '/api',
    persistSettings: true,
    customBackendUrl: '' // Empty string means use default URL
  },
  auth: {
    enabled: true,
    provider: 'nostr',
    required: false
  },
  xr: {
    enabled: true,
    controllerModel: 'default',
    movementSpeed: 1.0,
    teleportEnabled: true,
    roomScale: true,
    showFloor: true,
    handInteraction: true,
    interactionDistance: 1.5,
    grabThreshold: 0.1,
    controllerRayColor: '#ffffff',
    controllerPointerSize: 0.01,
    hapticFeedback: true
  }
};
----
src/features/settings/config/settingsUIDefinition.ts
// client/src/features/settings/config/settingsUIDefinition.ts

export type SettingWidgetType =
  | 'toggle'
  | 'slider'
  | 'numberInput'
  | 'textInput'
  | 'colorPicker'
  | 'select'
  | 'rangeSlider' // For [number, number] arrays
  | 'buttonAction'
  | 'dualColorPicker'; // Custom type for [string, string] color arrays

export interface UISettingDefinition {
  label: string;
  type: SettingWidgetType;
  path: string; // Full path in the SettingsStore, e.g., "visualisation.nodes.baseColor"
  description?: string; // Tooltip text
  options?: Array<{ value: string | number; label: string }>; // For select
  min?: number; // For slider, numberInput, rangeSlider
  max?: number; // For slider, numberInput, rangeSlider
  step?: number; // For slider, numberInput, rangeSlider
  unit?: string; // e.g., "px", "ms"
  isAdvanced?: boolean; // To hide behind an "Advanced" toggle if needed
  isPowerUserOnly?: boolean; // Only visible/editable by power users
  action?: () => void; // For buttonAction type
}

export interface UISubsectionDefinition {
  label: string;
  settings: Record<string, UISettingDefinition>;
}

export interface UICategoryDefinition {
  label: string;
  icon?: string; // Lucide icon name
  subsections: Record<string, UISubsectionDefinition>;
}

export const settingsUIDefinition: Record<string, UICategoryDefinition> = {
  visualisation: {
    label: 'Visualisation',
    icon: 'Eye',
    subsections: {
      nodes: {
        label: 'Nodes',
        settings: {
          baseColor: { label: 'Base Color', type: 'colorPicker', path: 'visualisation.nodes.baseColor', description: 'Default color of graph nodes.' },
          metalness: { label: 'Metalness', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.nodes.metalness', description: 'How metallic nodes appear.' },
          opacity: { label: 'Opacity', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.nodes.opacity', description: 'Overall opacity of nodes.' },
          roughness: { label: 'Roughness', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.nodes.roughness', description: 'Surface roughness of nodes.' },
          sizeRange: { label: 'Size Range', type: 'rangeSlider', min: 0.1, max: 5, step: 0.1, path: 'visualisation.nodes.sizeRange', description: 'Minimum and maximum size for nodes.' },
          quality: { label: 'Quality', type: 'select', options: [{value: 'low', label: 'Low'}, {value: 'medium', label: 'Medium'}, {value: 'high', label: 'High'}], path: 'visualisation.nodes.quality', description: 'Render quality of nodes.' },
          enableInstancing: { label: 'Enable Instancing', type: 'toggle', path: 'visualisation.nodes.enableInstancing', description: 'Use instanced rendering for nodes (performance).' },
          enableHologram: { label: 'Enable Hologram Effect', type: 'toggle', path: 'visualisation.nodes.enableHologram', description: 'Apply hologram effect to nodes.' },
          enableMetadataShape: { label: 'Enable Metadata Shape', type: 'toggle', path: 'visualisation.nodes.enableMetadataShape', description: 'Use shapes based on metadata.' },
          enableMetadataVisualisation: { label: 'Enable Metadata Visualisation', type: 'toggle', path: 'visualisation.nodes.enableMetadataVisualisation', description: 'Show metadata as part of node visualisation.' },
        },
      },
      edges: {
        label: 'Edges',
        settings: {
          arrowSize: { label: 'Arrow Size', type: 'slider', min: 0.01, max: 0.5, step: 0.01, path: 'visualisation.edges.arrowSize', description: 'Size of the arrows on edges.' },
          baseWidth: { label: 'Base Width', type: 'slider', min: 0.01, max: 2, step: 0.01, path: 'visualisation.edges.baseWidth', description: 'Base width of edges.' },
          color: { label: 'Color', type: 'colorPicker', path: 'visualisation.edges.color', description: 'Default color of edges.' },
          enableArrows: { label: 'Enable Arrows', type: 'toggle', path: 'visualisation.edges.enableArrows', description: 'Show arrows on directed edges.' },
          opacity: { label: 'Opacity', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.edges.opacity', description: 'Overall opacity of edges.' },
          widthRange: { label: 'Width Range', type: 'rangeSlider', min: 0.1, max: 5, step: 0.1, path: 'visualisation.edges.widthRange', description: 'Minimum and maximum width for edges.' },
          quality: { label: 'Quality', type: 'select', options: [{value: 'low', label: 'Low'}, {value: 'medium', label: 'Medium'}, {value: 'high', label: 'High'}], path: 'visualisation.edges.quality', description: 'Render quality of edges.' },
          enableFlowEffect: { label: 'Enable Flow Effect', type: 'toggle', path: 'visualisation.edges.enableFlowEffect', description: 'Animate a flow effect along edges.', isAdvanced: true },
          flowSpeed: { label: 'Flow Speed', type: 'slider', min: 0.1, max: 5, step: 0.1, path: 'visualisation.edges.flowSpeed', description: 'Speed of the flow effect.', isAdvanced: true },
          flowIntensity: { label: 'Flow Intensity', type: 'slider', min: 0, max: 10, step: 0.1, path: 'visualisation.edges.flowIntensity', description: 'Intensity of the flow effect.' },
          glowStrength: { label: 'Glow Strength', type: 'slider', min: 0, max: 5, step: 0.1, path: 'visualisation.edges.glowStrength', description: 'Strength of the edge glow effect.' },
          distanceIntensity: { label: 'Distance Intensity', type: 'slider', min: 0, max: 10, step: 0.1, path: 'visualisation.edges.distanceIntensity', description: 'Intensity based on distance for some edge effects.' },
          useGradient: { label: 'Use Gradient', type: 'toggle', path: 'visualisation.edges.useGradient', description: 'Use a gradient for edge colors.' },
          gradientColors: { label: 'Gradient Colors', type: 'dualColorPicker', path: 'visualisation.edges.gradientColors', description: 'Start and end colors for edge gradient.' },
        },
      },
      physics: {
        label: 'Physics',
        settings: {
          enabled: { label: 'Enable Physics', type: 'toggle', path: 'visualisation.physics.enabled', description: 'Enable physics simulation for graph layout.' },
          attractionStrength: { label: 'Attraction Strength', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.physics.attractionStrength', description: 'Strength of attraction between connected nodes.' },
          boundsSize: { label: 'Bounds Size', type: 'slider', min: 1, max: 50, step: 0.5, path: 'visualisation.physics.boundsSize', description: 'Size of the simulation bounding box.' },
          collisionRadius: { label: 'Collision Radius', type: 'slider', min: 0.1, max: 5, step: 0.1, path: 'visualisation.physics.collisionRadius', description: 'Radius for node collision detection.' },
          damping: { label: 'Damping', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.physics.damping', description: 'Damping factor to slow down node movement.' },
          enableBounds: { label: 'Enable Bounds', type: 'toggle', path: 'visualisation.physics.enableBounds', description: 'Confine nodes within the bounds size.' },
          iterations: { label: 'Iterations', type: 'numberInput', min: 10, max: 500, step: 10, path: 'visualisation.physics.iterations', description: 'Number of physics iterations per step.' },
          maxVelocity: { label: 'Max Velocity', type: 'slider', min: 0.001, max: 0.5, step: 0.001, path: 'visualisation.physics.maxVelocity', description: 'Maximum velocity of nodes.' },
          repulsionStrength: { label: 'Repulsion Strength', type: 'slider', min: 0, max: 2, step: 0.01, path: 'visualisation.physics.repulsionStrength', description: 'Strength of repulsion between nodes.' },
          springStrength: { label: 'Spring Strength', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.physics.springStrength', description: 'Strength of springs (edges) pulling nodes together.' },
          repulsionDistance: { label: 'Repulsion Distance', type: 'slider', min: 0.1, max: 10, step: 0.1, path: 'visualisation.physics.repulsionDistance', description: 'Distance at which repulsion force acts.' },
          massScale: { label: 'Mass Scale', type: 'slider', min: 0.1, max: 10, step: 0.1, path: 'visualisation.physics.massScale', description: 'Scaling factor for node mass.' },
          boundaryDamping: { label: 'Boundary Damping', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.physics.boundaryDamping', description: 'Damping when nodes hit boundaries.' },
        },
      },
      rendering: {
        label: 'Rendering',
        settings: {
          backgroundColor: { label: 'Background Color', type: 'colorPicker', path: 'visualisation.rendering.backgroundColor', description: 'Color of the viewport background.' },
          enableAntialiasing: { label: 'Enable Antialiasing', type: 'toggle', path: 'visualisation.rendering.enableAntialiasing', description: 'Smooth jagged edges (MSAA/FXAA).' },
          ambientLightIntensity: { label: 'Ambient Light Intensity', type: 'slider', min: 0, max: 2, step: 0.05, path: 'visualisation.rendering.ambientLightIntensity', description: 'Intensity of ambient light.' },
          directionalLightIntensity: { label: 'Directional Light Intensity', type: 'slider', min: 0, max: 2, step: 0.05, path: 'visualisation.rendering.directionalLightIntensity', description: 'Intensity of directional light.' },
          enableAmbientOcclusion: { label: 'Enable Ambient Occlusion', type: 'toggle', path: 'visualisation.rendering.enableAmbientOcclusion', description: 'Enable screen-space ambient occlusion (SSAO).', isAdvanced: true },
          enableShadows: { label: 'Enable Shadows', type: 'toggle', path: 'visualisation.rendering.enableShadows', description: 'Enable dynamic shadows.', isAdvanced: true },
          environmentIntensity: { label: 'Environment Intensity', type: 'slider', min: 0, max: 2, step: 0.05, path: 'visualisation.rendering.environmentIntensity', description: 'Intensity of environment lighting (IBL).' },
          shadowMapSize: { label: 'Shadow Map Size', type: 'select', options: [{value: '512', label: '512px'}, {value: '1024', label: '1024px'}, {value: '2048', label: '2048px'}, {value: '4096', label: '4096px'}], path: 'visualisation.rendering.shadowMapSize', description: 'Resolution of shadow maps.', isAdvanced: true },
          shadowBias: { label: 'Shadow Bias', type: 'slider', min: -0.01, max: 0.01, step: 0.0001, path: 'visualisation.rendering.shadowBias', description: 'Bias to prevent shadow acne.', isAdvanced: true },
          context: { label: 'Rendering Context', type: 'select', options: [{value: 'desktop', label: 'Desktop'}, {value: 'ar', label: 'AR'}], path: 'visualisation.rendering.context', description: 'Current rendering context.' },
        },
      },
      labels: {
        label: 'Labels',
        settings: {
          enableLabels: { label: 'Enable Labels', type: 'toggle', path: 'visualisation.labels.enableLabels', description: 'Show text labels for nodes.' },
          desktopFontSize: { label: 'Desktop Font Size', type: 'slider', min: 0.05, max: 0.5, step: 0.01, path: 'visualisation.labels.desktopFontSize', description: 'Font size for labels in desktop mode.' },
          textColor: { label: 'Text Color', type: 'colorPicker', path: 'visualisation.labels.textColor', description: 'Color of label text.' },
          textOutlineColor: { label: 'Outline Color', type: 'colorPicker', path: 'visualisation.labels.textOutlineColor', description: 'Color of label text outline.' },
          textOutlineWidth: { label: 'Outline Width', type: 'slider', min: 0, max: 0.1, step: 0.001, path: 'visualisation.labels.textOutlineWidth', description: 'Width of label text outline.' },
          textResolution: { label: 'Text Resolution', type: 'numberInput', min: 8, max: 128, step: 1, path: 'visualisation.labels.textResolution', description: 'Resolution of text rendering texture.' },
          textPadding: { label: 'Text Padding', type: 'slider', min: 0, max: 1, step: 0.05, path: 'visualisation.labels.textPadding', description: 'Padding around text labels.' },
          billboardMode: { label: 'Billboard Mode', type: 'select', options: [{value: 'camera', label: 'Camera Facing'}, {value: 'vertical', label: 'Vertical Lock'}], path: 'visualisation.labels.billboardMode', description: 'How labels orient themselves.' },
        },
      },
      bloom: {
        label: 'Bloom Effect',
        settings: {
          enabled: { label: 'Enable Bloom', type: 'toggle', path: 'visualisation.bloom.enabled', description: 'Enable post-processing bloom effect.' },
          strength: { label: 'Strength', type: 'slider', min: 0, max: 3, step: 0.01, path: 'visualisation.bloom.strength', description: 'Overall strength of the bloom effect.' },
          edgeBloomStrength: { label: 'Edge Bloom Strength', type: 'slider', min: 0, max: 5, step: 0.05, path: 'visualisation.bloom.edgeBloomStrength', description: 'Bloom strength for edges.' },
          environmentBloomStrength: { label: 'Environment Bloom Strength', type: 'slider', min: 0, max: 5, step: 0.05, path: 'visualisation.bloom.environmentBloomStrength', description: 'Bloom strength from environment.' },
          nodeBloomStrength: { label: 'Node Bloom Strength', type: 'slider', min: 0, max: 5, step: 0.05, path: 'visualisation.bloom.nodeBloomStrength', description: 'Bloom strength for nodes.' },
          radius: { label: 'Radius', type: 'slider', min: 0, max: 5, step: 0.05, path: 'visualisation.bloom.radius', description: 'Radius of the bloom effect.' },
          threshold: { label: 'Threshold', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.bloom.threshold', description: 'Luminance threshold for bloom.' },
        },
      },
      hologram: {
        label: 'Hologram Effect',
        settings: {
          ringCount: { label: 'Ring Count', type: 'numberInput', min: 0, max: 10, step: 1, path: 'visualisation.hologram.ringCount', description: 'Number of rings in hologram effect.' },
          ringColor: { label: 'Ring Color', type: 'colorPicker', path: 'visualisation.hologram.ringColor', description: 'Color of hologram rings.' },
          ringOpacity: { label: 'Ring Opacity', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.hologram.ringOpacity', description: 'Opacity of hologram rings.' },
          sphereSizes: { label: 'Sphere Sizes (Min/Max)', type: 'rangeSlider', min: 0.1, max: 20, step: 0.1, path: 'visualisation.hologram.sphereSizes', description: 'Min/max sizes for hologram spheres.' },
          ringRotationSpeed: { label: 'Ring Rotation Speed', type: 'slider', min: 0, max: 50, step: 0.5, path: 'visualisation.hologram.ringRotationSpeed', description: 'Rotation speed of hologram rings.' },
          enableBuckminster: { label: 'Enable Buckminster', type: 'toggle', path: 'visualisation.hologram.enableBuckminster', description: 'Enable Buckminster fullerene style hologram.' },
          buckminsterSize: { label: 'Buckminster Size', type: 'slider', min: 1, max: 20, step: 0.5, path: 'visualisation.hologram.buckminsterSize', description: 'Size of Buckminster hologram.' },
          buckminsterOpacity: { label: 'Buckminster Opacity', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.hologram.buckminsterOpacity', description: 'Opacity of Buckminster hologram.' },
          enableGeodesic: { label: 'Enable Geodesic', type: 'toggle', path: 'visualisation.hologram.enableGeodesic', description: 'Enable geodesic dome style hologram.' },
          geodesicSize: { label: 'Geodesic Size', type: 'slider', min: 1, max: 20, step: 0.5, path: 'visualisation.hologram.geodesicSize', description: 'Size of geodesic hologram.' },
          geodesicOpacity: { label: 'Geodesic Opacity', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.hologram.geodesicOpacity', description: 'Opacity of geodesic hologram.' },
          enableTriangleSphere: { label: 'Enable Triangle Sphere', type: 'toggle', path: 'visualisation.hologram.enableTriangleSphere', description: 'Enable triangle sphere style hologram.' },
          triangleSphereSize: { label: 'Triangle Sphere Size', type: 'slider', min: 1, max: 20, step: 0.5, path: 'visualisation.hologram.triangleSphereSize', description: 'Size of triangle sphere hologram.' },
          triangleSphereOpacity: { label: 'Triangle Sphere Opacity', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.hologram.triangleSphereOpacity', description: 'Opacity of triangle sphere hologram.' },
          globalRotationSpeed: { label: 'Global Rotation Speed', type: 'slider', min: 0, max: 20, step: 0.1, path: 'visualisation.hologram.globalRotationSpeed', description: 'Global rotation speed for hologram effects.' },
        },
      },
      animations: {
        label: 'Animations',
        settings: {
          enableNodeAnimations: { label: 'Enable Node Animations', type: 'toggle', path: 'visualisation.animations.enableNodeAnimations', description: 'Enable generic node animations.' },
          enableMotionBlur: { label: 'Enable Motion Blur', type: 'toggle', path: 'visualisation.animations.enableMotionBlur', description: 'Enable motion blur effect.', isAdvanced: true },
          motionBlurStrength: { label: 'Motion Blur Strength', type: 'slider', min: 0, max: 1, step: 0.01, path: 'visualisation.animations.motionBlurStrength', description: 'Strength of motion blur.', isAdvanced: true },
          selectionWaveEnabled: { label: 'Enable Selection Wave', type: 'toggle', path: 'visualisation.animations.selectionWaveEnabled', description: 'Enable wave animation on selection.' },
          pulseEnabled: { label: 'Enable Pulse Animation', type: 'toggle', path: 'visualisation.animations.pulseEnabled', description: 'Enable pulsing animation on nodes.' },
          pulseSpeed: { label: 'Pulse Speed', type: 'slider', min: 0.1, max: 2, step: 0.05, path: 'visualisation.animations.pulseSpeed', description: 'Speed of pulse animation.' },
          pulseStrength: { label: 'Pulse Strength', type: 'slider', min: 0.1, max: 2, step: 0.05, path: 'visualisation.animations.pulseStrength', description: 'Strength of pulse animation.' },
          waveSpeed: { label: 'Wave Speed', type: 'slider', min: 0.1, max: 2, step: 0.05, path: 'visualisation.animations.waveSpeed', description: 'Speed of selection wave animation.' },
        },
      },
    },
  },
  system: {
    label: 'System',
    icon: 'Settings',
    subsections: {
      general: {
        label: 'General',
        settings: {
          persistSettings: { label: 'Persist Settings on Server', type: 'toggle', path: 'system.persistSettings', description: 'Save settings to your user profile on the server (if authenticated).'},
          customBackendUrl: { label: 'Custom Backend URL', type: 'textInput', path: 'system.customBackendUrl', description: 'Overrides the default backend URL. Requires app reload. Leave empty for default.', isPowerUserOnly: true },
        }
      },
      websocket: {
        label: 'WebSocket',
        settings: {
          updateRate: { label: 'Update Rate (Hz)', type: 'slider', min: 1, max: 60, step: 1, path: 'system.websocket.updateRate', description: 'Frequency of position updates from server.' },
          reconnectAttempts: { label: 'Reconnect Attempts', type: 'numberInput', min: 0, max: 10, step: 1, path: 'system.websocket.reconnectAttempts', description: 'Number of WebSocket reconnect attempts.' },
          reconnectDelay: { label: 'Reconnect Delay', type: 'numberInput', unit: 'ms', min: 500, max: 10000, step: 100, path: 'system.websocket.reconnectDelay', description: 'Delay between WebSocket reconnect attempts.' },
          binaryChunkSize: { label: 'Binary Chunk Size', type: 'numberInput', unit: 'bytes', min: 256, max: 8192, step: 256, path: 'system.websocket.binaryChunkSize', description: 'Chunk size for binary data transmission.' },
          compressionEnabled: { label: 'Compression Enabled', type: 'toggle', path: 'system.websocket.compressionEnabled', description: 'Enable WebSocket message compression.' },
          compressionThreshold: { label: 'Compression Threshold', type: 'numberInput', unit: 'bytes', min: 64, max: 4096, step: 64, path: 'system.websocket.compressionThreshold', description: 'Threshold for WebSocket compression.' },
        },
      },
      debug: {
        label: 'Client Debugging',
        settings: {
          enabled: { label: 'Enable Client Debug Mode', type: 'toggle', path: 'system.debug.enabled', description: 'Enable general client-side debug logging and features.' },
          logLevel: { label: 'Client Log Level', type: 'select', options: [{value: 'debug', label: 'Debug'}, {value: 'info', label: 'Info'}, {value: 'warn', label: 'Warn'}, {value: 'error', label: 'Error'}], path: 'system.debug.logLevel', description: 'Client console log level.', isPowerUserOnly: true },
          enableDataDebug: { label: 'Enable Data Debug', type: 'toggle', path: 'system.debug.enableDataDebug', description: 'Log detailed client data flow information.', isAdvanced: true },
          enableWebsocketDebug: { label: 'Enable WebSocket Debug', type: 'toggle', path: 'system.debug.enableWebsocketDebug', description: 'Log WebSocket communication details.', isAdvanced: true },
          logBinaryHeaders: { label: 'Log Binary Headers', type: 'toggle', path: 'system.debug.logBinaryHeaders', description: 'Log headers of binary messages.', isAdvanced: true },
          logFullJson: { label: 'Log Full JSON', type: 'toggle', path: 'system.debug.logFullJson', description: 'Log complete JSON payloads.', isAdvanced: true },
          enablePhysicsDebug: { label: 'Enable Physics Debug', type: 'toggle', path: 'system.debug.enablePhysicsDebug', description: 'Show physics debug visualizations.', isAdvanced: true },
          enableNodeDebug: { label: 'Enable Node Debug', type: 'toggle', path: 'system.debug.enableNodeDebug', description: 'Enable debug features for nodes.', isAdvanced: true },
          enableShaderDebug: { label: 'Enable Shader Debug', type: 'toggle', path: 'system.debug.enableShaderDebug', description: 'Enable shader debugging tools.', isAdvanced: true, isPowerUserOnly: true },
          enableMatrixDebug: { label: 'Enable Matrix Debug', type: 'toggle', path: 'system.debug.enableMatrixDebug', description: 'Log matrix transformations.', isAdvanced: true, isPowerUserOnly: true },
          enablePerformanceDebug: { label: 'Enable Performance Debug', type: 'toggle', path: 'system.debug.enablePerformanceDebug', description: 'Show performance metrics.', isAdvanced: true },
        },
      },
    },
  },
  xr: {
    label: 'XR',
    icon: 'Smartphone',
    subsections: {
      general: {
        label: 'General XR',
        settings: {
          clientSideEnableXR: { label: 'Enable XR Mode (Client)', type: 'toggle', path: 'xr.clientSideEnableXR', description: 'Toggle immersive XR mode. Requires a compatible headset and page reload.' },
          enabled: { label: 'XR Features Enabled (Server)', type: 'toggle', path: 'xr.enabled', description: 'Enable XR features on the server (requires server restart if changed).', isPowerUserOnly: true },
          displayMode: { label: 'XR Display Mode', type: 'select', options: [{value: 'inline', label: 'Inline (Desktop)'}, {value: 'immersive-vr', label: 'Immersive VR'}, {value: 'immersive-ar', label: 'Immersive AR'}], path: 'xr.displayMode', description: 'Preferred XR display mode.' },
          quality: { label: 'XR Quality', type: 'select', options: [{value: 'low', label: 'Low'}, {value: 'medium', label: 'Medium'}, {value: 'high', label: 'High'}], path: 'xr.quality', description: 'Overall rendering quality in XR.' },
          renderScale: { label: 'Render Scale', type: 'slider', min: 0.5, max: 2, step: 0.1, path: 'xr.renderScale', description: 'XR rendering resolution scale.' },
          interactionDistance: { label: 'Interaction Distance', type: 'slider', min: 0.1, max: 5, step: 0.1, path: 'xr.interactionDistance', description: 'Max distance for XR interactions.' },
          locomotionMethod: { label: 'Locomotion Method', type: 'select', options: [{value: 'teleport', label: 'Teleport'}, {value: 'continuous', label: 'Continuous'}], path: 'xr.locomotionMethod', description: 'Method for moving in XR.' },
          teleportRayColor: { label: 'Teleport Ray Color', type: 'colorPicker', path: 'xr.teleportRayColor', description: 'Color of the teleportation ray.' },
          controllerModel: { label: 'Controller Model Path', type: 'textInput', path: 'xr.controllerModel', description: 'Path to custom controller model (leave empty for default).', isAdvanced: true },
          roomScale: { label: 'Room Scale Factor', type: 'slider', min: 0.5, max: 2.0, step: 0.1, path: 'xr.roomScale', description: 'Scaling factor for room-scale XR experiences.'},
          spaceType: { label: 'Reference Space Type', type: 'select', options: [{value: 'local-floor', label: 'Local Floor'}, {value: 'bounded-floor', label: 'Bounded Floor'}, {value: 'unbounded', label: 'Unbounded'}], path: 'xr.spaceType', description: 'WebXR reference space type.'},
        },
      },
      handFeatures: {
        label: 'Hand Tracking & Interactions',
        settings: {
          handTracking: { label: 'Enable Hand Tracking', type: 'toggle', path: 'xr.handTracking', description: 'Enable hand tracking in XR.' },
          controllerRayColor: { label: 'Controller Ray Color', type: 'colorPicker', path: 'xr.controllerRayColor', description: 'Color of controller interaction rays.' },
          enableHaptics: { label: 'Enable Haptics', type: 'toggle', path: 'xr.enableHaptics', description: 'Enable haptic feedback in controllers.' },
          handMeshEnabled: { label: 'Show Hand Mesh', type: 'toggle', path: 'xr.handMeshEnabled', description: 'Render a mesh for tracked hands.', isAdvanced: true },
          handMeshColor: { label: 'Hand Mesh Color', type: 'colorPicker', path: 'xr.handMeshColor', description: 'Color of the hand mesh.', isAdvanced: true },
          handMeshOpacity: { label: 'Hand Mesh Opacity', type: 'slider', min: 0, max: 1, step: 0.01, path: 'xr.handMeshOpacity', description: 'Opacity of the hand mesh.', isAdvanced: true },
          handPointSize: { label: 'Hand Joint Point Size', type: 'slider', min: 0.001, max: 0.02, step: 0.001, path: 'xr.handPointSize', description: 'Size of points representing hand joints.', isAdvanced: true },
          handRayEnabled: { label: 'Enable Hand Rays', type: 'toggle', path: 'xr.handRayEnabled', description: 'Show rays originating from hands for interaction.', isAdvanced: true },
          handRayWidth: { label: 'Hand Ray Width', type: 'slider', min: 0.001, max: 0.01, step: 0.0005, path: 'xr.handRayWidth', description: 'Width of hand interaction rays.', isAdvanced: true },
          gestureSmoothing: { label: 'Gesture Smoothing', type: 'slider', min: 0, max: 1, step: 0.05, path: 'xr.gestureSmoothing', description: 'Smoothing factor for hand gestures.', isAdvanced: true },
          hapticIntensity: { label: 'Haptic Intensity', type: 'slider', min: 0, max: 1, step: 0.05, path: 'xr.hapticIntensity', description: 'Intensity of haptic feedback.' },
          dragThreshold: { label: 'Drag Threshold', type: 'slider', min: 0.01, max: 0.2, step: 0.01, path: 'xr.dragThreshold', description: 'Threshold for initiating a drag interaction.' },
          pinchThreshold: { label: 'Pinch Threshold', type: 'slider', min: 0.1, max: 0.9, step: 0.05, path: 'xr.pinchThreshold', description: 'Threshold for pinch gesture detection.' },
          rotationThreshold: { label: 'Rotation Threshold', type: 'slider', min: 0.01, max: 0.2, step: 0.01, path: 'xr.rotationThreshold', description: 'Threshold for rotation gestures.' },
          movementSpeed: { label: 'Movement Speed', type: 'slider', min: 0.01, max: 0.5, step: 0.01, path: 'xr.movementSpeed', description: 'Speed for continuous locomotion.' },
          deadZone: { label: 'Controller Dead Zone', type: 'slider', min: 0.01, max: 0.5, step: 0.01, path: 'xr.deadZone', description: 'Dead zone for controller analog sticks.' },
        }
      },
    },
  },
  ai: {
    label: 'AI Services',
    icon: 'Brain',
    subsections: {
      ragflow: {
        label: 'RAGFlow',
        settings: {
          apiKey: { label: 'API Key', type: 'textInput', path: 'ragflow.apiKey', description: 'Your RAGFlow API Key. Will be obscured.', isPowerUserOnly: true },
          agentId: { label: 'Agent ID', type: 'textInput', path: 'ragflow.agentId', description: 'RAGFlow Agent ID.', isPowerUserOnly: true },
          apiBaseUrl: { label: 'API Base URL', type: 'textInput', path: 'ragflow.apiBaseUrl', description: 'Custom RAGFlow API Base URL.', isPowerUserOnly: true, isAdvanced: true },
          timeout: { label: 'Timeout (s)', type: 'numberInput', unit: 's', min: 1, max: 300, step: 1, path: 'ragflow.timeout', description: 'API request timeout in seconds.' },
          maxRetries: { label: 'Max Retries', type: 'numberInput', min: 0, max: 10, step: 1, path: 'ragflow.maxRetries', description: 'Maximum retry attempts for API calls.' },
          chatId: { label: 'Chat ID', type: 'textInput', path: 'ragflow.chatId', description: 'Default RAGFlow Chat ID.', isPowerUserOnly: true, isAdvanced: true },
        },
      },
      perplexity: {
        label: 'Perplexity',
        settings: {
          apiKey: { label: 'API Key', type: 'textInput', path: 'perplexity.apiKey', description: 'Your Perplexity API Key. Will be obscured.', isPowerUserOnly: true },
          model: { label: 'Model', type: 'textInput', path: 'perplexity.model', description: 'Perplexity model name (e.g., llama-3.1-sonar-small-128k-online).' },
          apiUrl: { label: 'API URL', type: 'textInput', path: 'perplexity.apiUrl', description: 'Custom Perplexity API URL.', isPowerUserOnly: true, isAdvanced: true },
          maxTokens: { label: 'Max Tokens', type: 'numberInput', min: 1, max: 130000, step: 128, path: 'perplexity.maxTokens', description: 'Maximum tokens for API response.' }, // Adjusted max for sonar 128k
          temperature: { label: 'Temperature', type: 'slider', min: 0, max: 2, step: 0.1, path: 'perplexity.temperature', description: 'Sampling temperature.' },
          topP: { label: 'Top P', type: 'slider', min: 0, max: 1, step: 0.01, path: 'perplexity.topP', description: 'Nucleus sampling parameter.' },
          presencePenalty: { label: 'Presence Penalty', type: 'slider', min: -2, max: 2, step: 0.1, path: 'perplexity.presencePenalty', description: 'Penalty for new token presence.' },
          frequencyPenalty: { label: 'Frequency Penalty', type: 'slider', min: -2, max: 2, step: 0.1, path: 'perplexity.frequencyPenalty', description: 'Penalty for token frequency.' },
          timeout: { label: 'Timeout (s)', type: 'numberInput', unit: 's', min: 1, max: 300, step: 1, path: 'perplexity.timeout', description: 'API request timeout.' },
          rateLimit: { label: 'Rate Limit (req/min)', type: 'numberInput', min: 1, max: 1000, step: 1, path: 'perplexity.rateLimit', description: 'Requests per minute.', isAdvanced: true },
        },
      },
      openai: {
        label: 'OpenAI',
        settings: {
          apiKey: { label: 'API Key', type: 'textInput', path: 'openai.apiKey', description: 'Your OpenAI API Key. Will be obscured.', isPowerUserOnly: true },
          baseUrl: { label: 'Base URL', type: 'textInput', path: 'openai.baseUrl', description: 'Custom OpenAI Base URL (e.g., for Azure).', isPowerUserOnly: true, isAdvanced: true },
          timeout: { label: 'Timeout (s)', type: 'numberInput', unit: 's', min: 1, max: 300, step: 1, path: 'openai.timeout', description: 'API request timeout.' },
          rateLimit: { label: 'Rate Limit (req/min)', type: 'numberInput', min: 1, max: 1000, step: 1, path: 'openai.rateLimit', description: 'Requests per minute.', isAdvanced: true },
        },
      },
      kokoro: {
        label: 'Kokoro TTS',
        settings: {
          apiUrl: { label: 'API URL', type: 'textInput', path: 'kokoro.apiUrl', description: 'Kokoro TTS API URL.', isPowerUserOnly: true },
          defaultVoice: { label: 'Default Voice', type: 'textInput', path: 'kokoro.defaultVoice', description: 'Default voice for TTS.' },
          defaultFormat: { label: 'Default Format', type: 'select', options: [{value: 'mp3', label: 'MP3'}, {value: 'ogg', label: 'OGG Vorbis'}, {value: 'wav', label: 'WAV'}, {value: 'pcm', label: 'PCM'}], path: 'kokoro.defaultFormat', description: 'Default audio format.' },
          defaultSpeed: { label: 'Default Speed', type: 'slider', min: 0.25, max: 4.0, step: 0.05, path: 'kokoro.defaultSpeed', description: 'Default speech speed.' },
          timeout: { label: 'Timeout (s)', type: 'numberInput', unit: 's', min: 1, max: 300, step: 1, path: 'kokoro.timeout', description: 'API request timeout.' },
          stream: { label: 'Stream Audio', type: 'toggle', path: 'kokoro.stream', description: 'Enable audio streaming.' },
          returnTimestamps: { label: 'Return Timestamps', type: 'toggle', path: 'kokoro.returnTimestamps', description: 'Request word timestamps from TTS.', isAdvanced: true },
          sampleRate: { label: 'Sample Rate', type: 'select', options: [{value: '8000', label: '8000 Hz'}, {value: '16000', label: '16000 Hz'}, {value: '22050', label: '22050 Hz'}, {value: '24000', label: '24000 Hz'}, {value: '44100', label: '44100 Hz'}, {value: '48000', label: '48000 Hz'}], path: 'kokoro.sampleRate', description: 'Audio sample rate.' },
        },
      },
    },
  },
};
----
src/features/settings/config/settingsConfig.ts
/**
 * Utility function to format setting names for display
 * Converts camelCase or snake_case to Title Case with spaces
 */
export const formatSettingName = (name: string): string => {
  // Replace camelCase with spaces
  const spacedName = name.replace(/([A-Z])/g, ' $1')
    // Replace underscores with spaces
    .replace(/_/g, ' ')
    // Trim any extra spaces
    .trim();
  
  // Capitalize first letter of each word
  return spacedName
    .split(' ')
    .map(word => word.charAt(0).toUpperCase() + word.slice(1))
    .join(' ');
};
----
src/features/settings/config/settings.ts
// Type definitions for settings

export type SettingsPath = string | '';

// Node settings
export interface NodeSettings {
  baseColor: string;
  metalness: number;
  opacity: number;
  roughness: number;
  sizeRange: [number, number];
  quality: 'low' | 'medium' | 'high';
  enableInstancing: boolean;
  enableHologram: boolean;
  enableMetadataShape: boolean;
  enableMetadataVisualisation: boolean;
}

// Edge settings
export interface EdgeSettings {
  arrowSize: number;
  baseWidth: number;
  color: string;
  enableArrows: boolean;
  opacity: number;
  widthRange: [number, number];
  quality: 'low' | 'medium' | 'high';
  enableFlowEffect: boolean;
  flowSpeed: number;
  flowIntensity: number;
  glowStrength: number;
  distanceIntensity: number;
  useGradient: boolean;
  gradientColors: [string, string];
}

// Physics settings
export interface PhysicsSettings {
  attractionStrength: number;
  boundsSize: number;
  collisionRadius: number;
  damping: number;
  enableBounds: boolean;
  enabled: boolean;
  iterations: number;
  maxVelocity: number;
  repulsionStrength: number;
  springStrength: number;
  repulsionDistance: number;
  massScale: number;
  boundaryDamping: number;
}

// Rendering settings
export interface RenderingSettings {
  ambientLightIntensity: number;
  backgroundColor: string;
  directionalLightIntensity: number;
  enableAmbientOcclusion: boolean;
  enableAntialiasing: boolean;
  enableShadows: boolean;
  environmentIntensity: number;
  shadowMapSize: string;
  shadowBias: number;
  context: 'desktop' | 'ar';
}

// Animation settings
export interface AnimationSettings {
  enableMotionBlur: boolean;
  enableNodeAnimations: boolean;
  motionBlurStrength: number;
  selectionWaveEnabled: boolean;
  pulseEnabled: boolean;
  pulseSpeed: number;
  pulseStrength: number;
  waveSpeed: number;
}

// Label settings
export interface LabelSettings {
  desktopFontSize: number;
  enableLabels: boolean;
  textColor: string;
  textOutlineColor: string;
  textOutlineWidth: number;
  textResolution: number;
  textPadding: number;
  billboardMode: 'camera' | 'vertical';
}

// Bloom settings
export interface BloomSettings {
  edgeBloomStrength: number;
  enabled: boolean;
  environmentBloomStrength: number;
  nodeBloomStrength: number;
  radius: number;
  strength: number;
  threshold: number;
}

// Hologram settings
export interface HologramSettings {
  ringCount: number;
  ringColor: string;
  ringOpacity: number;
  sphereSizes: [number, number];
  ringRotationSpeed: number;
  enableBuckminster: boolean;
  buckminsterSize: number;
  buckminsterOpacity: number;
  enableGeodesic: boolean;
  geodesicSize: number;
  geodesicOpacity: number;
  enableTriangleSphere: boolean;
  triangleSphereSize: number;
  triangleSphereOpacity: number;
  globalRotationSpeed: number;
}

// WebSocket settings
export interface WebSocketSettings {
  reconnectAttempts: number;
  reconnectDelay: number;
  binaryChunkSize: number;
  compressionEnabled: boolean;
  compressionThreshold: number;
  updateRate: number;
}

// Debug settings
export interface DebugSettings {
  enabled: boolean;
  enableDataDebug: boolean;
  enableWebsocketDebug: boolean;
  logBinaryHeaders: boolean;
  logFullJson: boolean;
  enablePhysicsDebug: boolean;
  enableNodeDebug: boolean;
  enableShaderDebug: boolean;
  enableMatrixDebug: boolean;
  enablePerformanceDebug: boolean;
}

// XR settings
export interface XRSettings {
  enabled: boolean;
  handTracking: boolean;
  controllerModel: string;
  renderScale: number;
  interactionDistance: number;
  locomotionMethod: 'teleport' | 'continuous';
  teleportRayColor: string;
  enableHaptics: boolean;
  displayMode: 'stereo' | 'mono';
controllerRayColor?: string; // Add this line
}

// Visualisation settings
export interface CameraSettings {
  fov: number;
  near: number;
  far: number;
  position: { x: number; y: number; z: number };
  lookAt?: { x: number; y: number; z: number }; // lookAt is often dynamic
}
export interface VisualisationSettings {
  nodes: NodeSettings;
  edges: EdgeSettings;
  physics: PhysicsSettings;
  rendering: RenderingSettings;
  animations: AnimationSettings;
  labels: LabelSettings;
  bloom: BloomSettings;
  hologram: HologramSettings;
  camera?: CameraSettings;
}

// System settings
export interface SystemSettings {
  websocket: WebSocketSettings;
  debug: DebugSettings;
  persistSettings: boolean; // Added to control server-side persistence
  customBackendUrl?: string; // Add if missing
}

// RAGFlow settings
export interface RAGFlowSettings {
  api_key?: string;
  agent_id?: string;
  api_base_url?: string;
  timeout?: number;
  max_retries?: number;
  chat_id?: string;
}

// Perplexity settings
export interface PerplexitySettings {
  api_key?: string;
  model?: string;
  api_url?: string;
  max_tokens?: number;
  temperature?: number;
  top_p?: number;
  presence_penalty?: number;
  frequency_penalty?: number;
  timeout?: number;
  rate_limit?: number;
}

// OpenAI settings
export interface OpenAISettings {
  api_key?: string;
  base_url?: string;
  timeout?: number;
  rate_limit?: number;
}

// Kokoro TTS settings
export interface KokoroSettings {
  api_url?: string;
  default_voice?: string;
  default_format?: string;
  default_speed?: number;
  timeout?: number;
  stream?: boolean;
  return_timestamps?: boolean;
  sample_rate?: number;
}

// Auth settings
export interface AuthSettings {
  enabled: boolean;
  provider: 'nostr' | string; // Allow other providers potentially
  required: boolean;
}

// Main settings interface
export interface Settings {
  visualisation: VisualisationSettings;
  system: SystemSettings;
  xr: XRSettings;
  auth: AuthSettings; // Make auth required
  ragflow?: RAGFlowSettings; // Add optional AI settings
  perplexity?: PerplexitySettings;
  openai?: OpenAISettings;
  kokoro?: KokoroSettings;
}

----
src/features/graph/managers/graphDataManager.ts
import { createLogger, createErrorMetadata } from '../../../utils/logger';
import { debugState } from '../../../utils/debugState';
import { WebSocketAdapter } from '../../../services/WebSocketService';
import { BinaryNodeData, parseBinaryNodeData, createBinaryNodeData, Vec3, BINARY_NODE_SIZE } from '../../../types/binaryProtocol';

const logger = createLogger('GraphDataManager');

export interface Node {
  id: string;
  label: string;
  position: {
    x: number;
    y: number;
    z: number;
  };
  metadata?: Record<string, any>;
}

export interface Edge {
  id: string;
  source: string;
  target: string;
  label?: string;
  weight?: number;
  metadata?: Record<string, any>;
}

export interface GraphData {
  nodes: Node[];
  edges: Edge[];
}

type GraphDataChangeListener = (data: GraphData) => void;
type PositionUpdateListener = (positions: Float32Array) => void;

class GraphDataManager {
  private static instance: GraphDataManager;
  private data: GraphData = { nodes: [], edges: [] };
  private binaryUpdatesEnabled: boolean = false;
  private webSocketService: WebSocketAdapter | null = null;
  private graphDataListeners: GraphDataChangeListener[] = [];
  private positionUpdateListeners: PositionUpdateListener[] = [];
  private lastBinaryUpdateTime: number = 0;
  private retryTimeout: number | null = null;
  private nodeIdMap: Map<string, number> = new Map();
  private reverseNodeIdMap: Map<number, string> = new Map();

  private constructor() {
    // Private constructor for singleton
  }

  public static getInstance(): GraphDataManager {
    if (!GraphDataManager.instance) {
      GraphDataManager.instance = new GraphDataManager();
    }
    return GraphDataManager.instance;
  }

  // Set WebSocket service for sending binary updates
  public setWebSocketService(service: WebSocketAdapter): void {
    this.webSocketService = service;
    if (debugState.isDataDebugEnabled()) {
      logger.debug('WebSocket service set');
    }
  }

  // Fetch initial graph data from the API
  public async fetchInitialData(): Promise<GraphData> {
    try {
      if (debugState.isEnabled()) {
        logger.info('Fetching initial graph data');
      }

      const response = await fetch('/api/graph/data');
      if (!response.ok) {
        throw new Error(`API request failed with status ${response.status}`);
      }

      try {
        const data = await response.json();
        
        // Validate that the response has the expected structure
        if (!data || typeof data !== 'object') {
          throw new Error('Invalid graph data format: data is not an object');
        }
        
        // Ensure nodes and edges exist, even if empty
        const validatedData = {
          nodes: Array.isArray(data.nodes) ? data.nodes : [],
          edges: Array.isArray(data.edges) ? data.edges : []
        };
        
        if (debugState.isEnabled()) {
          logger.info(`Received initial graph data: ${validatedData.nodes.length} nodes, ${validatedData.edges.length} edges`);
          if (validatedData.nodes.length > 0) {
            logger.debug('Sample node data:', {
              id: validatedData.nodes[0].id,
              label: validatedData.nodes[0].label,
              position: validatedData.nodes[0].position,
              metadata: validatedData.nodes[0].metadata
            });
          }
          if (validatedData.edges.length > 0) {
            logger.debug('Sample edge data:', {
              id: validatedData.edges[0].id,
              source: validatedData.edges[0].source,
              target: validatedData.edges[0].target
            });
          }
        }
        
        this.setGraphData(validatedData);
        
        if (debugState.isEnabled()) {
          logger.info(`Loaded initial graph data: ${this.data.nodes.length} nodes, ${this.data.edges.length} edges`);
          logger.debug('Node ID mappings created:', {
            numericIds: Array.from(this.nodeIdMap.entries()).slice(0, 5),
            totalMappings: this.nodeIdMap.size
          });
        }
        
        return this.data;
      } catch (parseError) {
        throw new Error(`Failed to parse graph data: ${parseError}`);
      }
    } catch (error) {
      logger.error('Failed to fetch initial graph data:', createErrorMetadata(error));
      throw error;
    }
  }

  // Set graph data and notify listeners
  public setGraphData(data: GraphData): void {
    if (debugState.isEnabled()) {
      logger.info(`Setting graph data: ${data.nodes.length} nodes, ${data.edges.length} edges`);
    }

    // Ensure all nodes have valid positions before setting the data
    if (data && data.nodes) {
      const validatedNodes = data.nodes.map(node => this.ensureNodeHasValidPosition(node));
      this.data = {
        ...data,
        nodes: validatedNodes
      };
      
      if (debugState.isEnabled()) {
        logger.info(`Validated ${validatedNodes.length} nodes with positions`);
      }
    } else {
      // Initialize with empty arrays if data is invalid
      this.data = { nodes: [], edges: data?.edges || [] };
      logger.warn('Initialized with empty graph data');
    }
    
    // Reset ID maps
    this.nodeIdMap.clear();
    this.reverseNodeIdMap.clear();
    
    // Create mappings between string IDs and numeric IDs
    this.data.nodes.forEach((node, index) => {
      const numericId = parseInt(node.id, 10);
      if (!isNaN(numericId)) {
        // If the ID can be parsed as a number, use it directly
        this.nodeIdMap.set(node.id, numericId);
        this.reverseNodeIdMap.set(numericId, node.id);
      } else {
        // For non-numeric IDs, use the index + 1 as the numeric ID
        // We add 1 to avoid using 0 as an ID
        const mappedId = index + 1;
        this.nodeIdMap.set(node.id, mappedId);
        this.reverseNodeIdMap.set(mappedId, node.id);
      }
    });
    
    // Set up nodes and validate their positions
    this.setupNodesAndMapping();
    
    // Notify listeners
    this.notifyGraphDataListeners();
    
    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Graph data updated: ${data.nodes.length} nodes, ${data.edges.length} edges`);
    }
  }

  // Setup node IDs and validate positions
  private setupNodesAndMapping(): void {
    if (!this.data.nodes || !this.data.nodes.length) {
      return;
    }
    
    // Process each node to ensure valid positions and create ID mappings
    this.data.nodes.forEach((node, index) => {
      if (!node) {
        logger.warn(`Null or undefined node found at index ${index}, skipping`);
        return;
      }
      
      // Skip nodes without valid IDs
      if (!node.id) {
        logger.warn(`Node at index ${index} has no ID, skipping`);
        return;
      }
      
      // Ensure node has a valid position
      if (!node.position) {
        node.position = { x: 0, y: 0, z: 0 };
      }
      
      // Ensure all position values are numbers
      node.position.x = typeof node.position.x === 'number' ? node.position.x : 0;
      node.position.y = typeof node.position.y === 'number' ? node.position.y : 0;
      node.position.z = typeof node.position.z === 'number' ? node.position.z : 0;

      // Use the numeric ID from the map
      const numericId = this.nodeIdMap.get(node.id) || index + 1;
      
      if (debugState.isDataDebugEnabled() && index < 5) {
        // Log a sample of node data for debugging (just the first few nodes)
        logger.debug(`Node ${node.id} (numeric ID: ${numericId}) at position [${node.position.x.toFixed(2)}, ${node.position.y.toFixed(2)}, ${node.position.z.toFixed(2)}]`);
      }
    });
    
    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Prepared ${this.data.nodes.length} nodes with ID mapping`);
    }
  }

  // Enable binary updates and start the retry mechanism
  public enableBinaryUpdates(): void {
    if (!this.webSocketService) {
      logger.warn('Cannot enable binary updates: WebSocket service not set');
      return;
    }

    // If WebSocket is already ready, enable binary updates immediately
    if (this.webSocketService.isReady()) {
      this.setBinaryUpdatesEnabled(true);
      return;
    }

    // Otherwise, start a retry mechanism
    if (this.retryTimeout) {
      window.clearTimeout(this.retryTimeout);
    }

    this.retryTimeout = window.setTimeout(() => {
      if (this.webSocketService && this.webSocketService.isReady()) {
        this.setBinaryUpdatesEnabled(true);
        if (debugState.isEnabled()) {
          logger.info('WebSocket ready, binary updates enabled');
        }
      } else {
        if (debugState.isEnabled()) {
          logger.info('WebSocket not ready yet, retrying...');
        }
        this.enableBinaryUpdates();
      }
    }, 500);
  }

  public setBinaryUpdatesEnabled(enabled: boolean): void {
    this.binaryUpdatesEnabled = enabled;
    
    if (enabled) {
      this.setupNodesAndMapping();
    }
    
    if (debugState.isEnabled()) {
      logger.info(`Binary updates ${enabled ? 'enabled' : 'disabled'}`);
    }
  }

  // Get the current graph data
  public getGraphData(): GraphData {
    return this.data;
  }

  // Add a node to the graph
  public addNode(node: Node): void {
    // Check if node with this ID already exists
    const existingIndex = this.data.nodes.findIndex(n => n.id === node.id);
    
    if (existingIndex >= 0) {
      // Update existing node
      this.data.nodes[existingIndex] = {
        ...this.data.nodes[existingIndex],
        ...node
      };
    } else {
      // Add new node
      this.data.nodes.push(node);
      
      // Update node mappings
      const numericId = parseInt(node.id, 10);
      if (!isNaN(numericId)) {
        this.nodeIdMap.set(node.id, numericId);
        this.reverseNodeIdMap.set(numericId, node.id);
      } else {
        const mappedId = this.data.nodes.length;
        this.nodeIdMap.set(node.id, mappedId);
        this.reverseNodeIdMap.set(mappedId, node.id);
      }
    }
    
    this.notifyGraphDataListeners();
  }

  // Add an edge to the graph
  public addEdge(edge: Edge): void {
    // Check if edge with this ID already exists
    const existingIndex = this.data.edges.findIndex(e => e.id === edge.id);
    
    if (existingIndex >= 0) {
      // Update existing edge
      this.data.edges[existingIndex] = {
        ...this.data.edges[existingIndex],
        ...edge
      };
    } else {
      // Add new edge
      this.data.edges.push(edge);
    }
    
    this.notifyGraphDataListeners();
  }

  // Remove a node from the graph
  public removeNode(nodeId: string): void {
    // Get numeric ID before removing the node
    const numericId = this.nodeIdMap.get(nodeId);
    
    // Remove node
    this.data.nodes = this.data.nodes.filter(node => node.id !== nodeId);
    
    // Remove all edges connected to this node
    this.data.edges = this.data.edges.filter(
      edge => edge.source !== nodeId && edge.target !== nodeId
    );
    
    // Remove from ID maps
    if (numericId !== undefined) {
      this.nodeIdMap.delete(nodeId);
      this.reverseNodeIdMap.delete(numericId);
    }
    
    this.notifyGraphDataListeners();
  }

  // Remove an edge from the graph
  public removeEdge(edgeId: string): void {
    this.data.edges = this.data.edges.filter(edge => edge.id !== edgeId);
    this.notifyGraphDataListeners();
  }

  // Update node positions from binary data
  public updateNodePositions(positionData: ArrayBuffer): void {
    if (!positionData || positionData.byteLength === 0) {
      return;
    }

    // Check if this is a duplicate update (can happen with WebSocket)
    const now = Date.now();
    if (now - this.lastBinaryUpdateTime < 16) { // Less than 16ms (60fps)
      if (debugState.isDataDebugEnabled()) {
        logger.debug('Skipping duplicate position update');
      }
      return;
    }
    this.lastBinaryUpdateTime = now;

    try {
      // Add diagnostic information about the received data
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Received binary data: ${positionData.byteLength} bytes`);
        
        // Check if data length is a multiple of our expected node size
        const remainder = positionData.byteLength % BINARY_NODE_SIZE;
        if (remainder !== 0) {
          logger.warn(`Binary data size (${positionData.byteLength} bytes) is not a multiple of ${BINARY_NODE_SIZE}. Remainder: ${remainder} bytes`);
        }
      }
      
      // Parse binary data using our standardized binary protocol parser
      const nodeUpdates = parseBinaryNodeData(positionData);
      
      if (nodeUpdates.length === 0) {
        logger.warn(`No valid node updates parsed from ${positionData.byteLength} bytes of binary data`);
        return;
      }
      
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Processing ${nodeUpdates.length} node updates from binary data`);
      }

      // Create Float32Array for position updates (4 values per node: id, x, y, z)
      // This format is expected by the GraphManager component
      const positionArray = new Float32Array(nodeUpdates.length * 4);
      let updatedNodes = 0;
      
      // Process each node update
      nodeUpdates.forEach((nodeUpdate, index) => {
        const { nodeId, position, velocity } = nodeUpdate;
        
        // Convert numeric ID back to string ID using the reverse map
        const stringNodeId = this.reverseNodeIdMap.get(nodeId);
        
        if (stringNodeId) {
          // Find and update the node
          const nodeIndex = this.data.nodes.findIndex(node => node.id === stringNodeId);
          if (nodeIndex >= 0) {
            this.data.nodes[nodeIndex].position = position;
            // Store velocity in metadata if needed
            this.data.nodes[nodeIndex].metadata = {
              ...this.data.nodes[nodeIndex].metadata,
              velocity
            };
            updatedNodes++;
          } else if (debugState.isDataDebugEnabled()) {
            logger.debug(`Node with ID ${stringNodeId} (numeric: ${nodeId}) not found in data`);
          }
        } else if (debugState.isDataDebugEnabled()) {
          logger.debug(`No string ID mapping found for numeric ID ${nodeId}`);
        }
        
        // Update the position array for rendering (4 values per node: id, x, y, z)
        const arrayOffset = index * 4;
        positionArray[arrayOffset] = nodeId;
        positionArray[arrayOffset + 1] = position.x;
        positionArray[arrayOffset + 2] = position.y;
        positionArray[arrayOffset + 3] = position.z;
      });

      // Notify position update listeners with the Float32Array
      this.notifyPositionUpdateListeners(positionArray);

      // Also notify graph data listeners so components using graphData state get updated positions
      this.notifyGraphDataListeners();

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Updated positions for ${updatedNodes} out of ${nodeUpdates.length} nodes (${this.data.nodes.length} total nodes in graph)`);
      }
    } catch (error) {
      logger.error('Error processing binary position data:', createErrorMetadata(error));
      
      // Add additional diagnostic information
      if (debugState.isEnabled()) {
        try {
          // Try to display the first few bytes for debugging
          const view = new DataView(positionData);
          const byteArray = [];
          const maxBytesToShow = Math.min(64, positionData.byteLength);
          
          for (let i = 0; i < maxBytesToShow; i++) {
            byteArray.push(view.getUint8(i).toString(16).padStart(2, '0'));
          }
          
          logger.debug(`First ${maxBytesToShow} bytes of binary data: ${byteArray.join(' ')}${positionData.byteLength > maxBytesToShow ? '...' : ''}`);
        } catch (e) {
          logger.debug('Could not display binary data preview:', e);
        }
      }
    }
  }

  // Send node positions to the server via WebSocket
  public sendNodePositions(): void {
    if (!this.binaryUpdatesEnabled || !this.webSocketService) {
      return;
    }

    try {
      // Create binary node data array in the format expected by the server
      const binaryNodes: BinaryNodeData[] = this.data.nodes
        .filter(node => node && node.id) // Filter out invalid nodes
        .map(node => {
          // Ensure node has a valid position
          this.ensureNodeHasValidPosition(node);
          
          // Get numeric ID from map or create a new one
          const numericId = this.nodeIdMap.get(node.id) || 0;
          if (numericId === 0) {
            logger.warn(`No numeric ID found for node ${node.id}, skipping`);
            return null;
          }
          
          // Get velocity from metadata or default to zero
          const velocity: Vec3 = (node.metadata?.velocity as Vec3) || { x: 0, y: 0, z: 0 };
          
          return {
            nodeId: numericId,
            position: {
              x: node.position.x || 0,
              y: node.position.y || 0,
              z: node.position.z || 0
            },
            velocity
          };
        })
        .filter((node): node is BinaryNodeData => node !== null);

      // Create binary buffer using our protocol encoder
      const buffer = createBinaryNodeData(binaryNodes);
      
      // Send the buffer via WebSocket
      this.webSocketService.send(buffer);
      
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Sent positions for ${binaryNodes.length} nodes using binary protocol`);
      }
    } catch (error) {
      logger.error('Error sending node positions:', createErrorMetadata(error));
    }
  }

  // Add listener for graph data changes
  public onGraphDataChange(listener: GraphDataChangeListener): () => void {
    this.graphDataListeners.push(listener);
    
    // Call immediately with current data
    listener(this.data);
    
    // Return unsubscribe function
    return () => {
      this.graphDataListeners = this.graphDataListeners.filter(l => l !== listener);
    };
  }

  // Add listener for position updates
  public onPositionUpdate(listener: PositionUpdateListener): () => void {
    this.positionUpdateListeners.push(listener);
    
    // Return unsubscribe function
    return () => {
      this.positionUpdateListeners = this.positionUpdateListeners.filter(l => l !== listener);
    };
  }

  // Notify all graph data listeners
  private notifyGraphDataListeners(): void {
    this.graphDataListeners.forEach(listener => {
      try {
        listener(this.data);
      } catch (error) {
        logger.error('Error in graph data listener:', createErrorMetadata(error));
      }
    });
  }

  // Notify all position update listeners
  private notifyPositionUpdateListeners(positions: Float32Array): void {
    this.positionUpdateListeners.forEach(listener => {
      try {
        listener(positions);
      } catch (error) {
        logger.error('Error in position update listener:', createErrorMetadata(error));
      }
    });
  }

  // Initialize a node with default position if needed
  public ensureNodeHasValidPosition(node: Node): Node {
    if (!node.position) {
      // Provide a default position if none exists
      return {
        ...node,
        position: { x: 0, y: 0, z: 0 }
      };
    } else if (typeof node.position.x !== 'number' || 
               typeof node.position.y !== 'number' || 
               typeof node.position.z !== 'number') {
      // Fix any NaN or undefined coordinates
      node.position.x = typeof node.position.x === 'number' ? node.position.x : 0;
      node.position.y = typeof node.position.y === 'number' ? node.position.y : 0;
      node.position.z = typeof node.position.z === 'number' ? node.position.z : 0;
    }
    return node;
  }

  // Clean up resources
  public dispose(): void {
    if (this.retryTimeout) {
      window.clearTimeout(this.retryTimeout);
      this.retryTimeout = null;
    }
    
    this.graphDataListeners = [];
    this.positionUpdateListeners = [];
    this.webSocketService = null;
    this.nodeIdMap.clear();
    this.reverseNodeIdMap.clear();
    
    if (debugState.isEnabled()) {
      logger.info('GraphDataManager disposed');
    }
  }
}

// Create singleton instance
export const graphDataManager = GraphDataManager.getInstance();

----
src/features/graph/components/GraphManager.tsx
import React, { useRef, useEffect, useState, useMemo, useCallback } from 'react'
import { useThree, useFrame } from '@react-three/fiber'
import { Line } from '@react-three/drei/core/Line'
// Assuming Text and Billboard are still directly available, if not adjust path later
import { Text, Billboard } from '@react-three/drei'
// Use namespace import for THREE to access constructors
import * as THREE from 'three'
import { graphDataManager, type GraphData, type Node as GraphNode } from '../managers/graphDataManager'
import { createLogger, createErrorMetadata } from '../../../utils/logger'
import { debugState } from '../../../utils/debugState'
import { useSettingsStore } from '../../../store/settingsStore'

const logger = createLogger('GraphManager')

// Function to get random position if node is at origin
const getPositionForNode = (node: GraphNode, index: number): [number, number, number] => {
  if (!node.position ||
      (node.position.x === 0 && node.position.y === 0 && node.position.z === 0)) {
    // All nodes are at (0,0,0), so generate a random position in a sphere
    const radius = 10
    const phi = Math.acos(2 * Math.random() - 1)
    const theta = Math.random() * Math.PI * 2

    const x = radius * Math.sin(phi) * Math.cos(theta)
    const y = radius * Math.sin(phi) * Math.sin(theta)
    const z = radius * Math.cos(phi)

    // Update the original node position so edges will work
    if (node.position) {
      node.position.x = x
      node.position.y = y
      node.position.z = z
    } else {
      node.position = { x, y, z }
    }

    return [x, y, z]
  }

  return [node.position.x, node.position.y, node.position.z]
}

const GraphManager = () => {
  const meshRef = useRef<THREE.InstancedMesh>(null) // Initialize with null, use THREE namespace
  // Use useMemo for stable object references across renders
  const tempMatrix = useMemo(() => new THREE.Matrix4(), [])
  const tempPosition = useMemo(() => new THREE.Vector3(), [])
  const tempScale = useMemo(() => new THREE.Vector3(), [])
  const [graphData, setGraphData] = useState<GraphData>({ nodes: [], edges: [] })
  const [nodesAreAtOrigin, setNodesAreAtOrigin] = useState(false)
  const settings = useSettingsStore(state => state.settings)

  useEffect(() => {
    if (meshRef.current) {
      const count = graphData.nodes.length;
      const mesh = meshRef.current;
      mesh.count = count; // Set the count

      if (count > 0) {
        // Check if matrices need initialization (e.g., if they are identity)
        // This avoids re-initializing if positions are already set by useFrame
        let needsInitialization = false;
        const identityMatrix = new THREE.Matrix4(); // Re-use for comparison
        for (let i = 0; i < count; i++) {
          const currentMatrix = new THREE.Matrix4();
          // Ensure mesh has enough allocated matrices before calling getMatrixAt
          if (i < mesh.instanceMatrix.array.length / 16) { // 16 floats per matrix
            mesh.getMatrixAt(i, currentMatrix);
            if (currentMatrix.equals(identityMatrix)) {
              needsInitialization = true;
              break;
            }
          } else {
            // If count increased beyond allocated, it needs initialization
            needsInitialization = true;
            break;
          }
        }

        if (needsInitialization) {
          for (let i = 0; i < count; i++) {
            // Set to identity or a default non-zero position if appropriate
            mesh.setMatrixAt(i, tempMatrix.identity());
          }
        }
      }
      mesh.instanceMatrix.needsUpdate = true;
      if (debugState.isEnabled()) {
        logger.debug(`InstancedMesh count updated to: ${count}`);
      }
    }
  }, [graphData.nodes.length, tempMatrix]);

  // Separate matrix update function for better performance
  const updateInstanceMatrix = (
    index: number,
    x: number,
    y: number,
    z: number,
    scale: number
  ) => {
    if (!meshRef.current) return

    tempPosition.set(x, y, z)
    tempScale.set(scale, scale, scale)
    
    tempMatrix.makeScale(scale, scale, scale)
    tempMatrix.setPosition(tempPosition)
    
    meshRef.current.setMatrixAt(index, tempMatrix)
  }

  // Subscribe to graph data changes
  useEffect(() => {
    const handleGraphDataChange = (newData: GraphData) => {
      setGraphData(newData)

      // Check if nodes are all at origin
      const allAtOrigin = newData.nodes.every(node =>
        !node.position || (node.position.x === 0 && node.position.y === 0 && node.position.z === 0)
      )
      setNodesAreAtOrigin(allAtOrigin)
    }

    // Initial data load
    const initialData = graphDataManager.getGraphData()
    handleGraphDataChange(initialData)

    // Subscribe to updates
    const unsubscribeData = graphDataManager.onGraphDataChange(handleGraphDataChange)
    const unsubscribePositions = graphDataManager.onPositionUpdate((positions) => {
      updateNodePositions(positions)
    })

    return () => {
      unsubscribeData()
      unsubscribePositions()
    }
  }, [])

  // Update node positions from binary data
  // Update node positions - Modified to NOT directly update mesh matrices from WebSocket data
  const updateNodePositions = useCallback((positions: Float32Array) => {
    // This function is called by GraphDataManager when WebSocket binary data arrives.
    // GraphDataManager is responsible for updating the central 'graphData' state.
    // This component (GraphManager) re-renders when 'graphData' (from useState) changes.
    // The useFrame hook then uses the updated 'graphData' to set instance matrices.
    // Therefore, this callback doesn't need to directly manipulate meshRef.current.
    if (debugState.isEnabled()) {
      const sample = positions.slice(0, Math.min(12, positions.length)); // Log first few nodes
      logger.debug('GraphManager received raw position update data (sample):', sample);
    }
  }, []); // No dependencies needed if it's just logging or relying on external state updates.

  useFrame(() => {
    if (!meshRef.current) return

    let needsUpdate = false
    graphData.nodes.forEach((node, index) => {
      const pos = node.position // Access position directly, assuming it exists on GraphNode type
      if (pos && (pos.x !== 0 || pos.y !== 0 || pos.z !== 0)) {
        const scale = calculateNodeScale(node) // Implement this based on your needs
        updateInstanceMatrix(index, pos.x, pos.y, pos.z, scale)
        needsUpdate = true
      }
    })

    if (needsUpdate) {
      meshRef.current.instanceMatrix.needsUpdate = true
    }
  })

  // Memoize edge points
  const edgePoints = useMemo(() => {
    if (!graphData.nodes || !graphData.edges) return []

    const points: [number, number, number][] = []
    const { nodes, edges } = graphData

    edges.forEach(edge => {
      if (edge.source && edge.target) {
        const sourceNode = nodes.find(n => n.id === edge.source)
        const targetNode = nodes.find(n => n.id === edge.target)
        if (sourceNode?.position && targetNode?.position) {
          if (nodesAreAtOrigin) {
            points.push(
              getPositionForNode(sourceNode, nodes.indexOf(sourceNode)),
              getPositionForNode(targetNode, nodes.indexOf(targetNode))
            )
          } else {
            points.push(
              [sourceNode.position.x, sourceNode.position.y, sourceNode.position.z],
              [targetNode.position.x, targetNode.position.y, targetNode.position.z]
            )
          }
        }
      }
    })
    return points
  }, [graphData.nodes, graphData.edges, nodesAreAtOrigin])

  // Node labels component using settings from YAML
  const NodeLabels = () => {
    // Get label settings from the settings store (in camelCase)
    const labelSettings = settings?.visualisation?.labels || {
      enabled: true,
      desktopFontSize: 0.1, // Fallback to a small size if not specified
      textColor: '#000000',
      textOutlineColor: '#ffffff',
      textOutlineWidth: 0.01,
      textPadding: 0.3,
      textResolution: 32,
      billboardMode: 'camera'
    }

    // Don't render if labels are disabled
    // Type guard to safely access 'enabled' property
    const isEnabled = typeof labelSettings === 'object' && labelSettings !== null && 'enabled' in labelSettings ? labelSettings.enabled : true; // Default to true if structure is unexpected
    if (!isEnabled) return null

    // Use the desktopFontSize (camelCase) from settings
    // The settings are converted from snake_case to camelCase when loaded
    const fontSize = labelSettings.desktopFontSize || 0.1

    return (
      <group>
        {graphData.nodes.map(node => {
          // Skip nodes without position or label
          if (!node.position || !node.label) return null

          // Use the font size directly from settings without any scaling

          return (
            <Billboard
              key={node.id}
              position={[node.position.x, node.position.y + (labelSettings.textPadding || 0.3), node.position.z]} // Use textPadding from settings
              follow={labelSettings.billboardMode === 'camera'} // Use billboardMode from settings
            >
              <Text
                fontSize={fontSize}
                color={labelSettings.textColor || '#000000'}
                anchorX="center"
                anchorY="middle"
                outlineWidth={labelSettings.textOutlineWidth || 0.01}
                outlineColor={labelSettings.textOutlineColor || '#ffffff'}
                outlineOpacity={1.0} // Full opacity for outline
                renderOrder={10}
                material-depthTest={false}
                maxWidth={labelSettings.textResolution || 32} // Use textResolution for max width
              >
                {node.label}
              </Text>
            </Billboard>
          )
        })}
      </group>
    )
  }

  return (
    <>
      <instancedMesh
        ref={meshRef}
        args={[null, null, graphData.nodes.length]}
        frustumCulled={false}
      >
        <sphereGeometry args={[0.5, 16, 16]} />
        <meshStandardMaterial
          color={settings?.visualisation?.nodes?.baseColor || "#ffffff"}
          emissive={settings?.visualisation?.nodes?.baseColor || "#00ffff"}
          emissiveIntensity={0.8}
          metalness={settings?.visualisation?.nodes?.metalness || 0.2}
          roughness={settings?.visualisation?.nodes?.roughness || 0.3}
          opacity={settings?.visualisation?.nodes?.opacity || 1.0}
          transparent={true}
          toneMapped={false} // Important for bloom effect
        />
      </instancedMesh>

      {edgePoints.length > 0 && (
        <Line
          points={edgePoints}
          color={settings?.visualisation?.edges?.color || "#00ffff"}
          lineWidth={settings?.visualisation?.edges?.baseWidth || 1.0}
          transparent
          opacity={settings?.visualisation?.edges?.opacity || 0.6}
          toneMapped={false} // Important for bloom effect
        />
      )}

      <NodeLabels />
    </>
  )
}

// Helper function to calculate node scale based on metadata
const calculateNodeScale = (node: any) => {
  let scale = 1.0
  
  if (node.metadata?.fileSize) {
    // Logarithmic scale based on file size
    scale = Math.log10(parseInt(node.metadata.fileSize) + 1) * 0.1 + 0.5
  } else if (node.metadata?.size) {
    scale = parseFloat(node.metadata.size) / 100
  }
  
  // Clamp scale to reasonable values
  return Math.max(0.2, Math.min(scale, 2.0))
}

export default GraphManager

----
src/features/graph/components/GraphCanvas.tsx
import { useRef } from 'react';
import { Canvas, useThree } from '@react-three/fiber';
import { OrbitControls, Stats } from '@react-three/drei';

// Components
 import GraphManager from './GraphManager';
import XRController from '../../xr/components/XRController';
import XRVisualisationConnector from '../../xr/components/XRVisualisationConnector';

// Store and utils
import { useSettingsStore } from '../../../store/settingsStore';
import { createLogger } from '../../../utils/logger';
import { debugState } from '../../../utils/debugState';

const logger = createLogger('GraphCanvas');

// Scene setup with lighting and background
const SceneSetup = () => {
    const { scene } = useThree();
    const settings = useSettingsStore(state => state.settings?.visualisation);

    // Render lights using JSX
    return (
        <>
            <color attach="background" args={[0, 0, 0.8]} /> {/* Medium blue background */}
            <ambientLight intensity={0.6} />
            <directionalLight
                intensity={0.8}
                position={[1, 1, 1]}
            />
        </>
    );
};

// Main GraphCanvas component
const GraphCanvas = () => {
    const canvasRef = useRef<HTMLCanvasElement>(null);
    const { settings } = useSettingsStore();
    const showStats = settings?.system?.debug?.enablePerformanceDebug ?? false; // Use performance debug flag
    const xrEnabled = settings?.xr?.enabled !== false;
    const antialias = settings?.visualisation?.rendering?.enableAntialiasing !== false; // Correct property name

    // Removed the outer div wrapper
    return (
        <Canvas
            ref={canvasRef}
            className="r3f-canvas overflow-hidden" // Added overflow-hidden class here
            style={{
                width: '100%',
                height: '100%',
                minHeight: '0', // Ensure it can shrink
                display: 'block' // Revert to display: block
                // Removed flex properties from Canvas style
            }}
            gl={{
                antialias,
                alpha: true,
                powerPreference: 'high-performance',
                failIfMajorPerformanceCaveat: false
            }}
            camera={{
                fov: 75,
                near: 0.1,
                far: 2000, // Remove settings access, camera settings likely managed elsewhere
                position: [0, 10, 50]
            }}
            onCreated={({ gl }) => {
                if (debugState.isEnabled()) {
                    logger.debug('Canvas created with dimensions:', {
                        width: gl.domElement.width,
                        height: gl.domElement.height,
                        containerWidth: gl.domElement.parentElement?.clientWidth,
                        containerHeight: gl.domElement.parentElement?.clientHeight
                    });
                }
            }}
        >
            <SceneSetup />
            <GraphManager />
            {xrEnabled && <XRController />}
            {xrEnabled && <XRVisualisationConnector />}
            <OrbitControls
                enableDamping={true}
                dampingFactor={0.1}
                screenSpacePanning={true}
                minDistance={1}
                maxDistance={2000}
                enableRotate={true}
                enableZoom={true}
                enablePan={true}
                rotateSpeed={1.0}
                zoomSpeed={1.2}
                panSpeed={0.8}
            />
            {showStats && <Stats />}
        </Canvas>
    );
};

export default GraphCanvas;

----
src/features/graph/components/GraphViewport.tsx
import React, { Suspense, useEffect, useState, useCallback } from 'react';
import { Canvas } from '@react-three/fiber';
import { OrbitControls, Stats } from '@react-three/drei';
import { EffectComposer, Bloom } from '@react-three/postprocessing';
import { graphDataManager } from '../managers/graphDataManager';
import GraphManager from './GraphManager';
import CameraController from '../../visualisation/components/CameraController'; // Adjusted path
import { useSettingsStore } from '../../../store/settingsStore';
import { createLogger } from '../../../utils/logger';

// Ensure Three.js types are properly loaded if not globally done
// import '../../../types/react-three-fiber.d.ts';

const logger = createLogger('GraphViewport');

const GraphViewport: React.FC = () => {
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [graphCenter, setGraphCenter] = useState<[number, number, number]>([0, 0, 0]);
  const [graphSize, setGraphSize] = useState(50); // Default size

  // Settings for camera and visuals
  const settings = useSettingsStore(state => state.settings);
  const cameraSettings = settings.visualisation.camera;
  const renderingSettings = settings.visualisation.rendering;
  const bloomSettingsStore = settings.visualisation.bloom;
  const debugSettings = settings.system.debug;

  const fov = cameraSettings?.fov ?? 75;
  const near = cameraSettings?.near ?? 0.1;
  const far = cameraSettings?.far ?? 2000;
  const cameraPosition = cameraSettings?.position
    ? [cameraSettings.position.x, cameraSettings.position.y, cameraSettings.position.z]
    : [0, 10, 50]; // Default camera position

  const enableBloom = bloomSettingsStore?.enabled ?? true;
  // Using properties from BloomSettings in settings.ts
  const bloomStrength = bloomSettingsStore?.strength ?? 1.5;
  const bloomThreshold = bloomSettingsStore?.threshold ?? 0.2;
  const bloomRadius = bloomSettingsStore?.radius ?? 0.9;


  useEffect(() => {
    const initializeGraph = async () => {
      setIsLoading(true);
      setError(null);
      try {
        logger.debug('Fetching initial graph data...');
        await graphDataManager.fetchInitialData();
        logger.debug('Graph data fetched.');
        const data = graphDataManager.getGraphData();

        if (!data || !data.nodes || data.nodes.length === 0) {
          logger.warn('No graph data or empty nodes received.');
          setGraphCenter([0,0,0]);
          setGraphSize(50); // Default size for empty graph
          setIsLoading(false);
          return;
        }

        let minX = Infinity, minY = Infinity, minZ = Infinity;
        let maxX = -Infinity, maxY = -Infinity, maxZ = -Infinity;
        
        data.nodes.forEach((node) => {
          if (node.position) {
            minX = Math.min(minX, node.position.x);
            maxX = Math.max(maxX, node.position.x);
            minY = Math.min(minY, node.position.y);
            maxY = Math.max(maxY, node.position.y);
            minZ = Math.min(minZ, node.position.z);
            maxZ = Math.max(maxZ, node.position.z);
          }
        });

        const centerX = (minX === Infinity || maxX === -Infinity) ? 0 : (maxX + minX) / 2;
        const centerY = (minY === Infinity || maxY === -Infinity) ? 0 : (maxY + minY) / 2;
        const centerZ = (minZ === Infinity || maxZ === -Infinity) ? 0 : (maxZ + minZ) / 2;
        
        const width = (minX === Infinity || maxX === -Infinity) ? 0 : maxX - minX;
        const height = (minY === Infinity || maxY === -Infinity) ? 0 : maxY - minY;
        const depth = (minZ === Infinity || maxZ === -Infinity) ? 0 : maxZ - minZ;
        
        const maxDimension = Math.max(width, height, depth, 1); // Ensure maxDimension is at least 1

        setGraphCenter([centerX, centerY, centerZ]);
        setGraphSize(maxDimension > 0 ? maxDimension : 50);
        logger.debug('Graph initialized and centered.', { center: [centerX, centerY, centerZ], size: maxDimension });

      } catch (err) {
        logger.error('Failed to fetch initial graph data:', err);
        setError(err instanceof Error ? err.message : 'An unknown error occurred during data fetch.');
      } finally {
        setIsLoading(false);
      }
    };
    initializeGraph();
  }, []);

  if (isLoading) {
    return <div style={{ padding: '2rem', color: '#ccc', height: '100%', display: 'flex', alignItems: 'center', justifyContent: 'center' }}>Loading graph data...</div>;
  }

  if (error) {
    return <div style={{ padding: '2rem', color: 'red', height: '100%', display: 'flex', alignItems: 'center', justifyContent: 'center' }}>Error loading graph data: {error}</div>;
  }

  const backgroundColor = renderingSettings?.backgroundColor ?? '#000000';

  return (
    <div style={{ width: '100%', height: '100%', position: 'relative' }}>
      <Canvas
        style={{ display: 'block', width: '100%', height: '100%' }}
        camera={{
          fov: fov,
          near: near,
          far: far,
          position: cameraPosition as [number, number, number],
        }}
        gl={{ antialias: true, alpha: true, powerPreference: 'high-performance' }}
        dpr={[1, 2]} // Pixel ratio for sharpness
        shadows // Enable shadows
      >
        <color attach="background" args={[backgroundColor]} />
        <CameraController center={graphCenter} size={graphSize} />
        
        <ambientLight intensity={renderingSettings?.ambientLightIntensity ?? 0.6} />
        <directionalLight
          position={[10, 10, 5]} // Using hardcoded default as not in settings
          intensity={renderingSettings?.directionalLightIntensity ?? 1}
          castShadow
        />
        <pointLight
          position={[-10, -10, -5]} // Using hardcoded default as not in settings
          intensity={0.5} // Using hardcoded default as not in settings
        />

        <OrbitControls
          makeDefault
          enableDamping
          dampingFactor={0.05}
          minDistance={1}
          maxDistance={far / 2} // Max distance related to camera far plane
          target={graphCenter}
        />
        
        <Suspense fallback={null}>
          <GraphManager />
          {/* HologramVisualisation could be added here if it's part of the core graph view */}
          {/* <HologramVisualisation standalone={false} position={[0, 0, 0]} size={20} /> */}
        </Suspense>
        
        {/* Removed showAxesHelper and showStats as they are not in DebugSettings type from settings.ts */}
        {/* {debugSettings?.showAxesHelper && <axesHelper args={[graphSize > 0 ? graphSize / 10 : 2]} />} */}
        {/* {debugSettings?.showStats && <Stats />} */}
        {debugSettings?.enabled && <Stats />} {/* Show Stats if general debug is enabled, as a fallback */}


        {enableBloom && (
          <EffectComposer>
            <Bloom
              intensity={bloomStrength} // Mapped from BloomSettings.strength
              luminanceThreshold={bloomThreshold} // Mapped from BloomSettings.threshold
              luminanceSmoothing={bloomRadius} // Mapped from BloomSettings.radius (best guess)
            />
          </EffectComposer>
        )}
      </Canvas>
    </div>
  );
};

export default GraphViewport;
----
src/styles/globals.css
@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  :root {
    --background: 222.2 84% 4.9%;
    --foreground: 210 40% 98%;
    --card: 222.2 84% 4.9%;
    --card-foreground: 210 40% 98%;
    --popover: 222.2 84% 4.9%;
    --popover-foreground: 210 40% 98%;
    --primary: 217.2 91.2% 59.8%;
    --primary-foreground: 210 40% 98%;
    --secondary: 217.2 32.6% 17.5%;
    --secondary-foreground: 210 40% 98%;
    --muted: 217.2 32.6% 17.5%;
    --muted-foreground: 215 20.2% 65.1%;
    --accent: 217.2 32.6% 17.5%;
    --accent-foreground: 210 40% 98%;
    --destructive: 0 62.8% 30.6%;
    --destructive-foreground: 210 40% 98%;
    --border: 217.2 32.6% 17.5%;
    --input: 217.2 32.6% 17.5%;
    --ring: 224.3 76.3% 48%;
    --radius: 0.5rem;
  }
}

@layer base {
  * {
    @apply border-border;
    margin: 0;
    padding: 0;
    box-sizing: border-box;
  }

  html, body, #root {
    width: 100%;
    height: 100%;
    margin: 0;
    padding: 0;
    overflow: hidden;
  }

  body {
    @apply bg-background text-foreground;
    font-feature-settings: "rlig" 1, "calt" 1;
    min-height: 100%;
    display: flex;
    flex-direction: column;
  }

  #root {
    display: flex;
    flex-direction: column;
    min-height: 100%;
  }
}

/* Control Panel Styles */
.settings-panel {
  @apply fixed right-4 top-4 z-40 w-80 rounded-lg bg-card p-4 text-card-foreground shadow-lg;
}

.settings-section {
  @apply mb-4 rounded-md border border-border bg-card p-2;
}

.section-header {
  @apply flex items-center justify-between border-b border-border pb-2;
}

.section-content {
  @apply mt-2 space-y-2;
}

.settings-subsection {
  @apply pt-2;
}

.settings-subsection-header {
  @apply text-sm font-medium text-muted-foreground;
}

.setting-control {
  @apply flex items-center justify-between gap-2 py-1;
}

.detached-panel {
  @apply absolute cursor-move rounded-md border border-border bg-card shadow-lg;
}

/* Custom scrollbar styles */
@layer utilities {
  /* Hide scrollbar for Chrome, Safari and Opera */
  .no-scrollbar::-webkit-scrollbar {
    display: none;
  }

  /* Hide scrollbar for IE, Edge and Firefox */
  .no-scrollbar {
    -ms-overflow-style: none;  /* IE and Edge */
    scrollbar-width: none;  /* Firefox */
  }

  /* Custom scrollbar for settings panels */
  .settings-panel-scroll {
    scrollbar-width: thin;
    scrollbar-color: rgba(100, 116, 139, 0.5) transparent;
  }

  .settings-panel-scroll::-webkit-scrollbar {
    width: 6px;
  }

  .settings-panel-scroll::-webkit-scrollbar-track {
    background: transparent;
  }

  .settings-panel-scroll::-webkit-scrollbar-thumb {
    background-color: rgba(100, 116, 139, 0.5);
    border-radius: 20px;
  }
}
----
src/styles/tokens.css
/**
 * Design Tokens
 * 
 * This file contains the design tokens for the application.
 * These variables provide a consistent visual language across the UI.
 */

:root {
  /* Base Colors */
  --color-primary: hsl(222.2, 47.4%, 11.2%);
  --color-primary-foreground: hsl(210, 40%, 98%);
  
  --color-secondary: hsl(210, 40%, 96.1%);
  --color-secondary-foreground: hsl(222.2, 47.4%, 11.2%);
  
  --color-accent: hsl(210, 40%, 90%);
  --color-accent-foreground: hsl(222.2, 47.4%, 11.2%);
  
  --color-destructive: hsl(0, 84.2%, 60.2%);
  --color-destructive-foreground: hsl(210, 40%, 98%);
  
  --color-muted: hsl(210, 40%, 96.1%);
  --color-muted-foreground: hsl(215.4, 16.3%, 46.9%);
  
  --color-card: hsl(0, 0%, 100%);
  --color-card-foreground: hsl(222.2, 47.4%, 11.2%);
  
  --color-popover: hsl(0, 0%, 100%);
  --color-popover-foreground: hsl(222.2, 47.4%, 11.2%);
  
  --color-border: hsl(214.3, 31.8%, 91.4%);
  --color-input: hsl(214.3, 31.8%, 91.4%);
  
  --color-background: hsl(0, 0%, 100%);
  --color-foreground: hsl(222.2, 47.4%, 11.2%);
  
  /* Typography */
  --font-family-sans: ui-sans-serif, system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif;
  --font-family-mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
  
  --font-size-xs: 0.75rem;    /* 12px */
  --font-size-sm: 0.875rem;   /* 14px */
  --font-size-base: 1rem;     /* 16px */
  --font-size-lg: 1.125rem;   /* 18px */
  --font-size-xl: 1.25rem;    /* 20px */
  --font-size-2xl: 1.5rem;    /* 24px */
  --font-size-3xl: 1.875rem;  /* 30px */
  --font-size-4xl: 2.25rem;   /* 36px */
  
  --font-weight-light: 300;
  --font-weight-normal: 400;
  --font-weight-medium: 500;
  --font-weight-semibold: 600;
  --font-weight-bold: 700;
  
  --line-height-tight: 1.25;
  --line-height-normal: 1.5;
  --line-height-loose: 1.75;
  
  /* Spacing */
  --space-1: 0.25rem;  /* 4px */
  --space-2: 0.5rem;   /* 8px */
  --space-3: 0.75rem;  /* 12px */
  --space-4: 1rem;     /* 16px */
  --space-5: 1.25rem;  /* 20px */
  --space-6: 1.5rem;   /* 24px */
  --space-8: 2rem;     /* 32px */
  --space-10: 2.5rem;  /* 40px */
  --space-12: 3rem;    /* 48px */
  --space-16: 4rem;    /* 64px */
  --space-20: 5rem;    /* 80px */
  --space-24: 6rem;    /* 96px */
  
  /* Layout */
  --width-xs: 20rem;   /* 320px */
  --width-sm: 24rem;   /* 384px */
  --width-md: 28rem;   /* 448px */
  --width-lg: 32rem;   /* 512px */
  --width-xl: 36rem;   /* 576px */
  --width-2xl: 42rem;  /* 672px */
  --width-3xl: 48rem;  /* 768px */
  --width-4xl: 56rem;  /* 896px */
  --width-5xl: 64rem;  /* 1024px */
  --width-6xl: 72rem;  /* 1152px */
  --width-7xl: 80rem;  /* 1280px */
  
  /* Borders */
  --radius-sm: 0.125rem;  /* 2px */
  --radius-md: 0.25rem;   /* 4px */
  --radius-lg: 0.5rem;    /* 8px */
  --radius-xl: 0.75rem;   /* 12px */
  --radius-2xl: 1rem;     /* 16px */
  --radius-3xl: 1.5rem;   /* 24px */
  --radius-full: 9999px;
  
  /* Shadows */
  --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
  --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
  --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
  --shadow-xl: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
  --shadow-2xl: 0 25px 50px -12px rgba(0, 0, 0, 0.25);
  --shadow-inner: inset 0 2px 4px 0 rgba(0, 0, 0, 0.06);
  
  /* Z-index */
  --z-0: 0;
  --z-10: 10;
  --z-20: 20;
  --z-30: 30;
  --z-40: 40;
  --z-50: 50;
  --z-tooltip: 100;
  --z-fixed: 200;
  --z-modal: 300;
  
  /* Transitions */
  --transition-fast: 150ms;
  --transition-normal: 250ms;
  --transition-slow: 350ms;
  --transition-very-slow: 500ms;
  
  --ease-in-out: cubic-bezier(0.4, 0, 0.2, 1);
  --ease-in: cubic-bezier(0.4, 0, 1, 1);
  --ease-out: cubic-bezier(0, 0, 0.2, 1);
  --ease-linear: linear;
}

/* Dark Theme */
.dark {
  --color-primary: hsl(210, 40%, 98%);
  --color-primary-foreground: hsl(222.2, 47.4%, 11.2%);
  
  --color-secondary: hsl(217.2, 32.6%, 17.5%);
  --color-secondary-foreground: hsl(210, 40%, 98%);
  
  --color-accent: hsl(217.2, 32.6%, 17.5%);
  --color-accent-foreground: hsl(210, 40%, 98%);
  
  --color-destructive: hsl(0, 62.8%, 30.6%);
  --color-destructive-foreground: hsl(210, 40%, 98%);
  
  --color-muted: hsl(217.2, 32.6%, 17.5%);
  --color-muted-foreground: hsl(215, 20.2%, 65.1%);
  
  --color-card: hsl(222.2, 84%, 4.9%);
  --color-card-foreground: hsl(210, 40%, 98%);
  
  --color-popover: hsl(222.2, 84%, 4.9%);
  --color-popover-foreground: hsl(210, 40%, 98%);
  
  --color-border: hsl(217.2, 32.6%, 17.5%);
  --color-input: hsl(217.2, 32.6%, 17.5%);
  
  --color-background: hsl(222.2, 84%, 4.9%);
  --color-foreground: hsl(210, 40%, 98%);
}

/* High Contrast Theme */
.high-contrast {
  --color-primary: hsl(0, 0%, 100%);
  --color-primary-foreground: hsl(0, 0%, 0%);
  
  --color-secondary: hsl(0, 0%, 15%);
  --color-secondary-foreground: hsl(0, 0%, 100%);
  
  --color-accent: hsl(0, 0%, 20%);
  --color-accent-foreground: hsl(0, 0%, 100%);
  
  --color-destructive: hsl(0, 100%, 50%);
  --color-destructive-foreground: hsl(0, 0%, 100%);
  
  --color-muted: hsl(0, 0%, 15%);
  --color-muted-foreground: hsl(0, 0%, 80%);
  
  --color-card: hsl(0, 0%, 0%);
  --color-card-foreground: hsl(0, 0%, 100%);
  
  --color-popover: hsl(0, 0%, 0%);
  --color-popover-foreground: hsl(0, 0%, 100%);
  
  --color-border: hsl(0, 0%, 50%);
  --color-input: hsl(0, 0%, 30%);
  
  --color-background: hsl(0, 0%, 0%);
  --color-foreground: hsl(0, 0%, 100%);
}
----
src/types/node-env.d.ts
// This file provides TypeScript declarations for Node.js globals used in the client

declare const process: {
  env: {
    NODE_ENV: 'development' | 'production' | 'test';
    [key: string]: string | undefined;
  };
};

declare function require(id: string): any;
----
src/types/react-syntax-highlighter.d.ts
declare module 'react-syntax-highlighter' {
  import { ComponentType, ReactNode } from 'react';

  export interface SyntaxHighlighterProps {
    language?: string;
    style?: any;
    children?: string;
    className?: string;
    showLineNumbers?: boolean;
    [key: string]: any;
  }

  export const Prism: ComponentType<SyntaxHighlighterProps>;
  export const Light: ComponentType<SyntaxHighlighterProps>;
}

declare module 'react-syntax-highlighter/dist/esm/styles/prism' {
  const vscDarkPlus: any;
  const dracula: any;
  const atomDark: any;
  const materialDark: any;
  const materialLight: any;
  const nord: any;
  const okaidia: any;
  const solarizedlight: any;
  const tomorrow: any;
  const vs: any;
  const xonokai: any;
  
  export {
    vscDarkPlus,
    dracula,
    atomDark,
    materialDark,
    materialLight,
    nord,
    okaidia,
    solarizedlight,
    tomorrow,
    vs,
    xonokai
  };
}

----
src/types/react-three-libraries.d.ts
// declare module '@react-three/drei' {
//   import { ReactNode } from 'react';
//   
//   export const OrbitControls: React.FC<{
//     enableDamping?: boolean;
//     dampingFactor?: number;
//     screenSpacePanning?: boolean;
//     minDistance?: number;
//     maxDistance?: number;
//     enableRotate?: boolean;
//     enableZoom?: boolean;
//     enablePan?: boolean;
//     rotateSpeed?: number;
//     zoomSpeed?: number;
//     panSpeed?: number;
//     [key: string]: any;
//   }>;
//   
//   export const Stats: React.FC<any>;
// }
//
// declare module '@react-three/xr' {
//   import { ReactNode } from 'react';
//   
//   export const XR: React.FC<{
//     children?: ReactNode;
//     referenceSpace?: string;
//     [key: string]: any;
//   }>;
// }
//
// declare module 'three-stdlib' {
//   import * as THREE from 'three';
//   
//   export class EffectComposer {
//     constructor(renderer: any);
//     addPass(pass: any): void;
//     render(): void;
//     dispose?(): void;
//   }
//   
//   export class RenderPass {
//     constructor(scene: any, camera: any);
//   }
//   
//   export class UnrealBloomPass {
//     constructor(resolution: any, strength: any, radius: any, threshold: any);
//   }
// }
----
src/types/nip07.d.ts
// Type definitions for NIP-07 window.nostr based on the specification
// https://github.com/nostr-protocol/nips/blob/master/07.md

import type { Event as NostrEvent, UnsignedEvent } from 'nostr-tools';

// Define the structure of the event object passed to signEvent
// Note: NIP-07 specifies the input event lacks id, pubkey, sig.
// nostr-tools' UnsignedEvent fits this description.
type Nip07Event = Omit<UnsignedEvent, 'pubkey'>; // pubkey is added by the signer

// Define the interface for the window.nostr object
interface NostrProvider {
  getPublicKey(): Promise<string>; // Returns hex public key
  signEvent(event: Nip07Event): Promise<NostrEvent>; // Returns the full signed event

  // Optional NIP-44 methods
  nip44?: {
    encrypt(pubkey: string, plaintext: string): Promise<string>; // returns ciphertext
    decrypt(pubkey: string, ciphertext: string): Promise<string>; // returns plaintext
  };

  // Optional NIP-04 methods (Deprecated but might exist)
  nip04?: {
    encrypt(pubkey: string, plaintext: string): Promise<string>;
    decrypt(pubkey: string, ciphertext: string): Promise<string>;
  };

  // Optional: Get Relays method (Not in core NIP-07 spec but common)
  getRelays?(): Promise<{ [url: string]: { read: boolean; write: boolean } }>;
}

// Augment the global Window interface
declare global {
  interface Window {
    nostr?: NostrProvider;
  }
}

// Export an empty object to ensure this is treated as a module
export {};
----
src/types/three-extensions.d.ts
// import { Camera, Color, Light, Object3D, PerspectiveCamera, Scene, Vector3, WebGLRenderer } from 'three';
// import { EffectComposer } from 'three/examples/jsm/postprocessing/EffectComposer';
//
// declare module 'three' {
//     interface Color {
//         setHex(hex: number): this;
//     }
//
//     interface Vector2 {
//         new(x: number, y: number): this;
//     }
//
//     interface Vector3 {
//         new(x: number, y: number, z: number): this;
//         set(x: number, y: number, z: number): this;
//         normalize(): this;
//     }
//
//     interface Object3D {
//         position: Vector3;
//         lookAt(v: Vector3): void;
//         lookAt(x: number, y: number, z: number): void;
//     }
//
//     interface Light extends Object3D {
//         intensity: number;
//         color: Color;
//     }
//
//     interface AmbientLight extends Light {}
//     interface DirectionalLight extends Light {}
//
//     interface PerspectiveCamera extends Camera {
//         fov: number;
//         near: number;
//         far: number;
//         position: Vector3;
//         updateProjectionMatrix(): void;
//     }
//
//     interface WebGLRenderer {
//         xr: {
//             enabled: boolean;
//             setReferenceSpaceType(type: string): void;
//         };
//         setClearColor(color: Color): void;
//     }
// }
//
// declare module '@react-three/fiber' {
//     interface ThreeElements {
//         ambientLight: Object3D;
//         directionalLight: Object3D;
//         perspectiveCamera: PerspectiveCamera;
//     }
// }
//
// declare module 'three/examples/jsm/postprocessing/EffectComposer' {
//     export class EffectComposer {
//         constructor(renderer: WebGLRenderer);
//         addPass(pass: any): void;
//         setSize(width: number, height: number): void;
//         render(): void;
//         dispose(): void;
//     }
// }
//
// declare module 'three/examples/jsm/postprocessing/UnrealBloomPass' {
//     import { Vector2 } from 'three';
//     export class UnrealBloomPass {
//         constructor(resolution: Vector2, strength: number, radius: number, threshold: number);
//     }
// }
//
// declare module 'three/examples/jsm/postprocessing/RenderPass' {
//     import { Scene, Camera } from 'three';
//     export class RenderPass {
//         constructor(scene: Scene, camera: Camera);
//     }
// }
----
src/types/getalby-sdk.d.ts
declare module '@getalby/sdk' {
  export class WebLNProvider {
    constructor();
    getPublicKey(): Promise<string>;
    signEvent(event: any): Promise<any>;
  }
}
----
src/types/tailwind-merge.d.ts
declare module 'tailwind-merge' {
  /**
   * Merges multiple Tailwind CSS class lists into a single class list.
   * @param classLists - Array of class lists to merge.
   * @returns - Merged class list.
   */
  export function twMerge(...classLists: (string | undefined | null | false)[]): string;

  /**
   * Creates a custom instance of twMerge with custom configuration.
   * @param config - Configuration object.
   * @returns - A custom twMerge function.
   */
  export function twMergeConfig(config: Record<string, unknown>): typeof twMerge;
}
----
src/types/react-three-fiber.d.ts
// import * as THREE from 'three';
// import React from 'react';
// import { ReactThreeFiber, Object3DNode } from '@react-three/fiber'; // Import R3F namespace for types
//
// declare module '@react-three/fiber' {
//   // Core React Three Fiber hooks and components
//   export function Canvas(props: any): JSX.Element;
//   export function useThree(): {
//     gl: THREE.WebGLRenderer;
//     scene: THREE.Scene;
//     camera: THREE.Camera;
//     size: { width: number; height: number };
//     viewport: { width: number; height: number; factor: number };
//     raycaster: THREE.Raycaster;
//     mouse: THREE.Vector2;
//     clock: THREE.Clock;
//     // Add other context properties as needed
//   };
//   export function useFrame(callback: (state: any, delta: number) => void, renderPriority?: number): void;
//
//   // Extend mesh props for better TypeScript integration with jsx-runtime
//   export interface MeshProps {
//     color?: string | number | THREE.Color;
//     wireframe?: boolean;
//     transparent?: boolean;
//     opacity?: number;
//     side?: typeof THREE.FrontSide | typeof THREE.BackSide | typeof THREE.DoubleSide;
//     emissive?: string | number | THREE.Color;
//     emissiveIntensity?: number;
//     depthWrite?: boolean;
//     roughness?: number;
//     thickness?: number;
//     transmission?: number;
//     distortion?: number;
//     temporalDistortion?: number;
//     clearcoat?: number;
//     attenuationDistance?: number;
//     attenuationColor?: string | number | THREE.Color;
//     ref?: React.Ref<any>;
//   }
//
//   export interface ExtendedColors<T> {
//     color?: string | number | THREE.Color;
//     emissive?: string | number | THREE.Color;
//     // Add other color properties as needed
//   }
//
// }
//
// // Define MeshTransmissionMaterial props
// declare module '@react-three/drei' {
//   export interface MeshTransmissionMaterialProps {
//     transmissionSampler?: boolean;
//     backside?: boolean;
//     samples?: number;
//     resolution?: number;
//     transmission?: number;
//     roughness?: number;
//     thickness?: number;
//     ior?: number;
//     chromaticAberration?: number;
//     anisotropy?: number;
//     distortion?: number;
//     distortionScale?: number;
//     temporalDistortion?: number;
//     clearcoat?: number;
//     attenuationDistance?: number;
//     attenuationColor?: string | number | THREE.Color;
//     color?: string | number | THREE.Color;
//     bg?: string | number | THREE.Color;
//   }
//
//   export type MeshTransmissionMaterialType = THREE.Material & {
//     // Add specific props of the material implementation if needed
//   };
// }
//
// // Augment the global JSX namespace
// declare global {
//   namespace JSX {
//     interface IntrinsicElements {
//       // built-in three.js lights
//       ambientLight:    Object3DNode<THREE.AmbientLight,    typeof THREE.AmbientLight>
//       directionalLight: Object3DNode<THREE.DirectionalLight, typeof THREE.DirectionalLight>
//       pointLight:      Object3DNode<THREE.PointLight,      typeof THREE.PointLight>
//       // helper / misc
//       axesHelper:      Object3DNode<THREE.AxesHelper,      typeof THREE.AxesHelper>
//       color:           Object3DNode<THREE.Color,           typeof THREE.Color>
//       // Elements used in GraphManager.tsx & XR components
//       group:           Object3DNode<THREE.Group,           typeof THREE.Group>
//       instancedMesh:   Object3DNode<THREE.InstancedMesh,   typeof THREE.InstancedMesh>
//       sphereGeometry:  Object3DNode<THREE.SphereGeometry,  typeof THREE.SphereGeometry>
//       meshStandardMaterial: Object3DNode<THREE.MeshStandardMaterial, typeof THREE.MeshStandardMaterial>
//       // Added based on XR component errors
//       mesh:            Object3DNode<THREE.Mesh,            typeof THREE.Mesh>
//       planeGeometry:   Object3DNode<THREE.PlaneGeometry,   typeof THREE.PlaneGeometry>
//       // ...add any others you need (e.g. GridHelper, etc.)
//     }
//   }
// }

----
src/types/binaryProtocol.ts
/**
 * Binary protocol types for WebSocket communication
 * 
 * This aligns with the server's binary protocol format (src/utils/binary_protocol.rs)
 */

export interface Vec3 {
  x: number;
  y: number;
  z: number;
}

export interface BinaryNodeData {
  nodeId: number;
  position: Vec3;
  velocity: Vec3;
}

/**
 * Node binary format:
 * - Node ID: 2 bytes (uint16)
 * - Position: 12 bytes (3 float32 values)
 * - Velocity: 12 bytes (3 float32 values)
 * Total: 26 bytes per node
 */
export const BINARY_NODE_SIZE = 26;
export const BINARY_NODE_ID_OFFSET = 0;
export const BINARY_POSITION_OFFSET = 2;
export const BINARY_VELOCITY_OFFSET = 14;

/**
 * Parse binary data buffer into an array of BinaryNodeData objects
 */
export function parseBinaryNodeData(buffer: ArrayBuffer): BinaryNodeData[] {
  if (!buffer || buffer.byteLength === 0) {
    return [];
  }

  // Make a copy of the buffer to avoid any issues with shared references
  const safeBuffer = buffer.slice(0);
  const view = new DataView(safeBuffer);
  const nodes: BinaryNodeData[] = [];
  
  try {
    // Check if data length is not a multiple of the expected size
    if (safeBuffer.byteLength % BINARY_NODE_SIZE !== 0) {
      console.warn(`Binary data length (${safeBuffer.byteLength} bytes) is not a multiple of ${BINARY_NODE_SIZE}. This may indicate compressed data.`);
      console.warn(`First few bytes: ${new Uint8Array(safeBuffer.slice(0, Math.min(16, safeBuffer.byteLength))).join(', ')}`);
      
      // Check for zlib header (0x78 followed by compression level byte)
      const header = new Uint8Array(safeBuffer.slice(0, Math.min(4, safeBuffer.byteLength)));
      if (header[0] === 0x78 && (header[1] === 0x01 || header[1] === 0x5E || header[1] === 0x9C || header[1] === 0xDA)) {
        console.error("Data appears to be zlib compressed but decompression failed or wasn't attempted");
      }
    }
    
    // Calculate how many complete nodes we can process
    const completeNodes = Math.floor(safeBuffer.byteLength / BINARY_NODE_SIZE);
    
    if (completeNodes === 0) {
      console.warn(`Received binary data with insufficient length: ${safeBuffer.byteLength} bytes (needed at least ${BINARY_NODE_SIZE} bytes per node)`);
      return [];
    }
    
    for (let i = 0; i < completeNodes; i++) {
      const offset = i * BINARY_NODE_SIZE;
      
      // Bounds check to prevent errors on corrupted data
      if (offset + BINARY_NODE_SIZE > safeBuffer.byteLength) {
        break;
      }
      
      // Read node ID (uint16, 2 bytes)
      const nodeId = view.getUint16(offset + BINARY_NODE_ID_OFFSET, true);
      
      // Read position (3 float32 values, 12 bytes)
      const position: Vec3 = {
        x: view.getFloat32(offset + BINARY_POSITION_OFFSET, true),
        y: view.getFloat32(offset + BINARY_POSITION_OFFSET + 4, true),
        z: view.getFloat32(offset + BINARY_POSITION_OFFSET + 8, true)
      };
      
      // Read velocity (3 float32 values, 12 bytes)
      const velocity: Vec3 = {
        x: view.getFloat32(offset + BINARY_VELOCITY_OFFSET, true),
        y: view.getFloat32(offset + BINARY_VELOCITY_OFFSET + 4, true),
        z: view.getFloat32(offset + BINARY_VELOCITY_OFFSET + 8, true)
      };

      // Basic validation to detect corrupted data
      const isValid = 
        !isNaN(position.x) && isFinite(position.x) &&
        !isNaN(position.y) && isFinite(position.y) &&
        !isNaN(position.z) && isFinite(position.z) &&
        !isNaN(velocity.x) && isFinite(velocity.x) &&
        !isNaN(velocity.y) && isFinite(velocity.y) &&
        !isNaN(velocity.z) && isFinite(velocity.z);
      
      if (isValid) {
        nodes.push({ nodeId, position, velocity });
      } else {
        console.warn(`Skipping corrupted node data at offset ${offset} (nodeId: ${nodeId})`);
      }
    }
  } catch (error) {
    console.error('Error parsing binary data:', error);
    // Return any nodes we've successfully parsed
  }

  return nodes;
}

/**
 * Create a binary buffer from an array of BinaryNodeData objects
 */
export function createBinaryNodeData(nodes: BinaryNodeData[]): ArrayBuffer {
  const buffer = new ArrayBuffer(nodes.length * BINARY_NODE_SIZE);
  const view = new DataView(buffer);
  
  nodes.forEach((node, i) => {
    const offset = i * BINARY_NODE_SIZE;
    
    // Write node ID (uint16, 2 bytes)
    view.setUint16(offset + BINARY_NODE_ID_OFFSET, node.nodeId, true);
    
    // Write position (3 float32 values, 12 bytes)
    view.setFloat32(offset + BINARY_POSITION_OFFSET, node.position.x, true);
    view.setFloat32(offset + BINARY_POSITION_OFFSET + 4, node.position.y, true);
    view.setFloat32(offset + BINARY_POSITION_OFFSET + 8, node.position.z, true);
    
    // Write velocity (3 float32 values, 12 bytes)
    view.setFloat32(offset + BINARY_VELOCITY_OFFSET, node.velocity.x, true);
    view.setFloat32(offset + BINARY_VELOCITY_OFFSET + 4, node.velocity.y, true);
    view.setFloat32(offset + BINARY_VELOCITY_OFFSET + 8, node.velocity.z, true);
  });
  
  return buffer;
}
----
src/types/webxr-extensions.d.ts
// // Extend the THREE namespace with WebXR types that are missing from @types/three
// declare module 'three' {
//   // Import the THREE namespace itself to extend it
//   import * as THREE from 'three';
//
//   /**
//    * XRTargetRaySpace represents the space in which the target ray is positioned.
//    * This interface extends Object3D, allowing it to be used in the Three.js scene graph.
//    */
//   export interface XRTargetRaySpace extends Object3D {
//     // Add any specific properties or methods needed
//   }
//   
//   // WebGL renderer needs XR properties
//   export interface WebGLRenderer {
//     xr: {
//       enabled: boolean;
//       setReferenceSpaceType: (type: string) => void;
//       // Add other XR-related properties and methods as needed
//     };
//     setClearColor: (color: Color | string | number, alpha?: number) => void;
//   }
//
//   // Make sure all THREE exports are accessible
//   export namespace THREE {
//     export type XRTargetRaySpace = XRTargetRaySpace;
//     
//     // Core THREE classes
//     export type Vector2 = THREE.Vector2;
//     export type Vector3 = THREE.Vector3;
//     export type Color = THREE.Color;
//     export type Quaternion = THREE.Quaternion;
//     export type Group = THREE.Group;
//     export type Line = THREE.Line;
//     export type Material = THREE.Material;
//     export type Object3D = THREE.Object3D;
//     export type InstancedMesh = THREE.InstancedMesh;
//     export type Raycaster = THREE.Raycaster;
//     
//     // Geometries
//     export type BufferGeometry = THREE.BufferGeometry;
//     export type SphereGeometry = THREE.SphereGeometry;
//     
//     // Materials
//     export type MeshStandardMaterial = THREE.MeshStandardMaterial;
//     export type MeshBasicMaterial = THREE.MeshBasicMaterial;
//     export type MeshPhysicalMaterial = THREE.MeshPhysicalMaterial;
//     export type LineBasicMaterial = THREE.LineBasicMaterial;
//     
//     // Lights
//     export type AmbientLight = THREE.AmbientLight;
//     export type DirectionalLight = THREE.DirectionalLight;
//     
//     // Cameras
//     export type PerspectiveCamera = THREE.PerspectiveCamera;
//     
//     // Constants
//     export const FrontSide: typeof THREE.FrontSide;
//     export const BackSide: typeof THREE.BackSide;
//     export const DoubleSide: typeof THREE.DoubleSide;
//   }
//
//   // Make necessary Raycaster properties available
//   export interface Raycaster {
//     near: number;
//     far: number;
//     params: {
//       Line?: { threshold: number };
//       Points?: { threshold: number };
//       [key: string]: any;
//     };
//     intersectObjects: (objects: Object3D[], recursive?: boolean) => Intersection[];
//     ray: {
//       origin: Vector3;
//       direction: Vector3;
//     };
//   }
//
//   // Extend Object3D with properties used in the codebase
//   export interface Object3D {
//     position: Vector3;
//     name: string;
//   }
//
//   // Additional types for intersection testing
//   export interface Intersection {
//     distance: number;
//     point: Vector3;
//     object: Object3D;
//     // Add other intersection properties as needed
//   }
// }
//
// // Extend React Three Fiber component props
// declare module '@react-three/fiber' {
//   interface MeshProps {
//     color?: any;
//     side?: any;
//   }
// }
----
src/types/lucide-react.d.ts
declare module 'lucide-react' {
  import { FC, SVGProps } from 'react';

  export interface IconProps extends SVGProps<SVGSVGElement> {
    size?: string | number;
    color?: string;
    strokeWidth?: string | number;
  }

  export type Icon = FC<IconProps>;

  // Export all icons that are used in the project
  export const X: Icon;
  export const Minimize: Icon;
  export const Maximize: Icon;
  export const Check: Icon;
  export const ChevronDown: Icon;
  export const ChevronUp: Icon;
  export const Dock: Icon;
  export const Eye: Icon;
  export const Circle: Icon;
  export const CircleDashed: Icon;
  export const BrushIcon: Icon;
  export const MoveHorizontal: Icon;
  
  // Additional icons used in PanelManager
  export const Settings: Icon;
  export const LayoutGrid: Icon;
  export const RefreshCw: Icon;
  export const Terminal: Icon;
  export const Smartphone: Icon;
  export const MonitorSmartphone: Icon;
  export const Info: Icon;
  export const Home: Icon;
  export const ZoomIn: Icon;
  export const ZoomOut: Icon;
  export const RotateCw: Icon;
  export const PanelLeft: Icon;
  export const PanelRight: Icon;
  export const Trash: Icon;
  export const Send: Icon;
  export const Download: Icon;
  export const Anchor: Icon;
  
  // Add any other icons that might be used in your project
  // This is not an exhaustive list, just including the ones I've seen so far
}
----
src/services/nostrAuthService.ts
import { apiService } from './api';
import { createLogger, createErrorMetadata } from '../utils/logger';
import { Event, UnsignedEvent, nip19 } from 'nostr-tools';
import { v4 as uuidv4 } from 'uuid'; // Import uuid
import type {} from '../types/nip07'; // Import the types to ensure Window augmentation

const logger = createLogger('NostrAuthService');

// --- Interfaces ---

// User info stored locally and used in AuthState
export interface SimpleNostrUser {
  pubkey: string; // hex pubkey
  npub?: string; // npub format
  isPowerUser: boolean; // Keep for UI rendering decisions
}

// User info returned by backend
export interface BackendNostrUser {
  pubkey: string;
  npub?: string;
  isPowerUser: boolean; // Server determines this based on POWER_USER_PUBKEYS
  // Add other fields the backend might send if needed
}

// Response from POST /auth/nostr
export interface AuthResponse {
  user: BackendNostrUser;
  token: string;
  expiresAt: number; // Unix timestamp (seconds)
  features?: string[]; // Optional features list from backend
}

// Response from POST /auth/nostr/verify
export interface VerifyResponse {
  valid: boolean;
  user?: BackendNostrUser;
  features?: string[];
}

// Payload for POST /auth/nostr (signed NIP-42 event)
export interface AuthEventPayload {
  id: string;
  pubkey: string;
  content: string;
  sig: string;
  created_at: number; // Unix timestamp
  kind: number;
  tags: string[][];
}

// State exposed to the application
export interface AuthState {
  authenticated: boolean;
  user?: SimpleNostrUser;
  error?: string;
}

type AuthStateListener = (state: AuthState) => void;

// --- Service Implementation ---

class NostrAuthService {
  private static instance: NostrAuthService;
  private sessionToken: string | null = null;
  private currentUser: SimpleNostrUser | null = null;
  private authStateListeners: AuthStateListener[] = [];
  private initialized = false;

  private constructor() {}

  public static getInstance(): NostrAuthService {
    if (!NostrAuthService.instance) {
      NostrAuthService.instance = new NostrAuthService();
    }
    return NostrAuthService.instance;
  }

  /**
   * Checks if a NIP-07 provider (window.nostr) is available.
   */
  public hasNip07Provider(): boolean {
    return typeof window !== 'undefined' && window.nostr !== undefined;
  }

  /**
   * Initializes the service, checking for stored sessions.
   */
  public async initialize(): Promise<void> {
    if (this.initialized) return;
    logger.debug('Initializing NostrAuthService...');

    const storedToken = localStorage.getItem('nostr_session_token');
    const storedUserJson = localStorage.getItem('nostr_user'); // Stores SimpleNostrUser

    if (storedToken && storedUserJson) {
      let storedUser: SimpleNostrUser | null = null;
      try {
        storedUser = JSON.parse(storedUserJson);
      } catch (parseError) {
        logger.error('Failed to parse stored user data:', createErrorMetadata(parseError));
        this.clearSession();
      }

      if (storedUser) {
        logger.info(`Verifying stored session for pubkey: ${storedUser.pubkey}`);
        try {
          // Verify token with backend
          const verificationResponse = await apiService.post<VerifyResponse>('/auth/nostr/verify', {
            pubkey: storedUser.pubkey,
            token: storedToken
          });

          if (verificationResponse.valid && verificationResponse.user) {
            // Session is valid, restore state
            this.sessionToken = storedToken;
            this.currentUser = { // Use SimpleNostrUser for local state
              pubkey: verificationResponse.user.pubkey,
              npub: verificationResponse.user.npub || this.hexToNpub(verificationResponse.user.pubkey),
              isPowerUser: verificationResponse.user.isPowerUser,
            };
            // Re-store potentially updated user info
            this.storeCurrentUser();
            this.notifyListeners(this.getCurrentAuthState());
            logger.info('Restored and verified session from local storage.');
          } else {
            // Session invalid
            logger.warn('Stored session token is invalid or user mismatch, clearing session.');
            this.clearSession();
            this.notifyListeners({ authenticated: false });
          }
        } catch (error) {
          logger.error('Failed to verify stored session with backend:', createErrorMetadata(error));
          this.clearSession();
          this.notifyListeners({ authenticated: false, error: 'Session verification failed' });
        }
      }
    } else {
      logger.info('No stored session found.');
      this.notifyListeners({ authenticated: false });
    }
    this.initialized = true;
    logger.debug('NostrAuthService initialized.');
  }

  /**
   * Initiates the NIP-07 login flow.
   */
  public async login(): Promise<AuthState> {
    logger.info('Attempting NIP-07 login...');
    if (!this.hasNip07Provider()) {
      const errorMsg = 'Nostr NIP-07 provider (e.g., Alby) not found. Please install a compatible extension.';
      logger.error(errorMsg);
      this.notifyListeners({ authenticated: false, error: errorMsg });
      throw new Error(errorMsg);
    }

    try {
      // 1. Get public key from NIP-07 provider
      const pubkey = await window.nostr!.getPublicKey();
      if (!pubkey) {
        throw new Error('Could not get public key from NIP-07 provider.');
      }
      logger.info(`Got pubkey via NIP-07: ${pubkey}`);

      // 2. Construct NIP-42 Authentication Event (Kind 22242)
      const challenge = uuidv4(); // Use uuidv4 to generate the challenge
      // TODO: Make relayUrl configurable or obtained from the provider if possible
      const relayUrl = 'wss://relay.damus.io';

      // Prepare the unsigned event structure expected by NIP-07 signEvent
      const unsignedNip07Event = {
        created_at: Math.floor(Date.now() / 1000),
        kind: 22242,
        tags: [
          ['relay', relayUrl],
          ['challenge', challenge]
        ],
        content: 'Authenticate to LogseqSpringThing' // Customize as needed
      };

      // 3. Sign the event using NIP-07 provider
      logger.debug('Requesting signature via NIP-07 for event:', unsignedNip07Event);
      const signedEvent: Event = await window.nostr!.signEvent(unsignedNip07Event);
      logger.debug('Event signed successfully via NIP-07.');

      // 4. Prepare payload for backend
      const eventPayload: AuthEventPayload = {
        id: signedEvent.id,
        pubkey: signedEvent.pubkey, // pubkey is added by the signer
        content: signedEvent.content,
        sig: signedEvent.sig,
        created_at: signedEvent.created_at,
        kind: signedEvent.kind,
        tags: signedEvent.tags,
      };

      // 5. Send the signed event to the backend API
      logger.info(`Sending auth event to backend for pubkey: ${pubkey}`);
      const response = await apiService.post<AuthResponse>('/auth/nostr', eventPayload);
      logger.info(`Backend auth successful for pubkey: ${response.user.pubkey}`);

      // 6. Store session and update state
      this.sessionToken = response.token;
      this.currentUser = {
        pubkey: response.user.pubkey,
        npub: response.user.npub || this.hexToNpub(response.user.pubkey),
        isPowerUser: response.user.isPowerUser,
      };

      this.storeSessionToken(response.token);
      this.storeCurrentUser(); // Store SimpleNostrUser

      const newState = this.getCurrentAuthState();
      this.notifyListeners(newState);
      return newState;

    } catch (error: any) {
      const errorMeta = createErrorMetadata(error);
      logger.error(`NIP-07 login failed. Details: ${JSON.stringify(errorMeta, null, 2)}`);
      let errorMessage = 'Login failed';
      if (error?.response?.data?.error) { // Check for backend error structure
        errorMessage = error.response.data.error;
      } else if (error?.message) {
        errorMessage = error.message;
      } else if (typeof error === 'string') {
        errorMessage = error;
      }

      // Refine common error messages
      if (errorMessage.includes('User rejected') || errorMessage.includes('extension rejected')) {
        errorMessage = 'Login request rejected in Nostr extension.';
      } else if (errorMessage.includes('401') || errorMessage.includes('Invalid signature')) {
        errorMessage = 'Authentication failed: Invalid signature or credentials.';
      } else if (errorMessage.includes('Could not get public key')) {
        errorMessage = 'Failed to get public key from Nostr extension.';
      }

      const errorState: AuthState = { authenticated: false, error: errorMessage };
      this.notifyListeners(errorState);
      // Re-throw the error so UI components can potentially handle it too
      throw new Error(errorMessage);
    }
  }

  /**
   * Logs the user out.
   */
  public async logout(): Promise<void> {
    logger.info('Attempting logout...');
    const token = this.sessionToken;
    const user = this.currentUser;

    // Clear local state immediately for faster UI update
    const wasAuthenticated = this.isAuthenticated();
    this.clearSession();
    if (wasAuthenticated) {
        this.notifyListeners({ authenticated: false }); // Notify UI immediately only if state changed
    }


    if (token && user) {
      try {
        logger.info(`Calling server logout for pubkey: ${user.pubkey}`);
        // Server expects DELETE with pubkey and token in body
        await apiService.delete<any>('/auth/nostr', {
          pubkey: user.pubkey,
          token: token
        });
        logger.info('Server logout successful.');
      } catch (error) {
        // Log the error but don't re-throw, as client-side logout is already done
        logger.error('Server logout call failed:', createErrorMetadata(error));
        // Optionally notify listeners about the server error?
        // this.notifyListeners({ authenticated: false, error: 'Server logout failed but client session cleared' });
      }
    } else {
      logger.warn('Logout called but no active session found locally.');
    }
  }

  // --- State Management & Helpers ---

  private storeSessionToken(token: string): void {
    localStorage.setItem('nostr_session_token', token);
  }

  private storeCurrentUser(): void {
    if (this.currentUser) {
      localStorage.setItem('nostr_user', JSON.stringify(this.currentUser));
    } else {
      localStorage.removeItem('nostr_user');
    }
  }

  private clearSession(): void {
    this.sessionToken = null;
    this.currentUser = null;
    localStorage.removeItem('nostr_session_token');
    localStorage.removeItem('nostr_user');
  }

  public onAuthStateChanged(listener: AuthStateListener): () => void {
    this.authStateListeners.push(listener);
    if (this.initialized) { // Notify immediately if already initialized
      listener(this.getCurrentAuthState());
    }
    // Return unsubscribe function
    return () => {
      this.authStateListeners = this.authStateListeners.filter(l => l !== listener);
    };
  }

  private notifyListeners(state: AuthState): void {
    this.authStateListeners.forEach(listener => {
      try {
        listener(state);
      } catch (error) {
        logger.error('Error in auth state listener:', createErrorMetadata(error));
      }
    });
  }

  public getCurrentUser(): SimpleNostrUser | null {
    return this.currentUser;
  }

  public getSessionToken(): string | null {
    return this.sessionToken;
  }

  public isAuthenticated(): boolean {
    return !!this.sessionToken && !!this.currentUser;
  }

  public getCurrentAuthState(): AuthState {
    return {
      authenticated: this.isAuthenticated(),
      user: this.currentUser ? { ...this.currentUser } : undefined, // Return a copy
      error: undefined // Reset error on state check, or manage error state separately
    };
  }

  // --- NIP-19 Helpers ---

  public hexToNpub(pubkey: string): string | undefined {
    if (!pubkey) return undefined;
    try {
      return nip19.npubEncode(pubkey);
    } catch (error) {
      logger.warn(`Failed to convert hex to npub: ${pubkey}`, createErrorMetadata(error));
      return undefined;
    }
  }

  public npubToHex(npub: string): string | undefined {
    if (!npub) return undefined;
    try {
      const decoded = nip19.decode(npub);
      if (decoded.type === 'npub') {
        return decoded.data;
      }
      throw new Error('Invalid npub format');
    } catch (error) {
      logger.warn(`Failed to convert npub to hex: ${npub}`, createErrorMetadata(error));
      return undefined;
    }
  }
}

// Export a singleton instance
export const nostrAuth = NostrAuthService.getInstance();

----
src/services/WebSocketService.ts
import { createLogger, createErrorMetadata } from '../utils/logger';
import { debugState } from '../utils/debugState';
import { maybeDecompress, isZlibCompressed } from '../utils/binaryUtils';
import { useSettingsStore } from '../store/settingsStore'; // Keep alias here for now, fix later if needed

const logger = createLogger('WebSocketService');

export interface WebSocketAdapter {
  send: (data: ArrayBuffer) => void;
  isReady: () => boolean;
}

export interface WebSocketMessage {
  type: string;
  data?: any;
}

type MessageHandler = (message: WebSocketMessage) => void;
type BinaryMessageHandler = (data: ArrayBuffer) => void;
type ConnectionStatusHandler = (connected: boolean) => void;

class WebSocketService {
  private static instance: WebSocketService;
  private socket: WebSocket | null = null;
  private messageHandlers: MessageHandler[] = [];
  private binaryMessageHandlers: BinaryMessageHandler[] = [];
  private connectionStatusHandlers: ConnectionStatusHandler[] = [];
  private reconnectInterval: number = 2000;
  private maxReconnectAttempts: number = 10;
  private reconnectAttempts: number = 0;
  private reconnectTimeout: number | null = null;
  private isConnected: boolean = false;
  private isServerReady: boolean = false;
  private url: string;

  private constructor() {
    // Default WebSocket URL
    this.url = this.determineWebSocketUrl();

    // Update URL when settings change
    this.updateFromSettings();

    // Subscribe to store changes and manually check customBackendUrl
    let previousCustomBackendUrl = useSettingsStore.getState().settings.system.customBackendUrl;
    useSettingsStore.subscribe((state) => {
      const newCustomBackendUrl = state.settings.system.customBackendUrl;
      if (newCustomBackendUrl !== previousCustomBackendUrl) {
        if (debugState.isEnabled()) {
          logger.info(`customBackendUrl setting changed from "${previousCustomBackendUrl}" to "${newCustomBackendUrl}", re-evaluating WebSocket URL.`);
        }
        previousCustomBackendUrl = newCustomBackendUrl; // Update for next comparison
        this.updateFromSettings(); // Sets this.url based on the latest state
        if (this.isConnected || (this.socket && this.socket.readyState === WebSocket.CONNECTING)) {
          logger.info('Reconnecting WebSocket due to customBackendUrl change.');
          this.close();
          setTimeout(() => {
            this.connect().catch(error => {
              logger.error('Failed to reconnect WebSocket after URL change:', createErrorMetadata(error));
            });
          }, 100);
        }
      }
    });
  }

  private updateFromSettings(): void {
    const settings = useSettingsStore.getState().settings;
    let newUrl = this.determineWebSocketUrl(); // Default to relative path

    if (settings.system?.websocket) {
      this.reconnectInterval = settings.system.websocket.reconnectDelay || 2000;
      this.maxReconnectAttempts = settings.system.websocket.reconnectAttempts || 10;
    }

    if (settings.system?.customBackendUrl && settings.system.customBackendUrl.trim() !== '') {
      const customUrl = settings.system.customBackendUrl.trim();
      const protocol = customUrl.startsWith('https://') ? 'wss://' : 'ws://';
      const hostAndPath = customUrl.replace(/^(https?:\/\/)?/, '');
      newUrl = `${protocol}${hostAndPath.replace(/\/$/, '')}/wss`; // Ensure /wss and handle trailing slash
      if (debugState.isEnabled()) {
        logger.info(`Using custom backend WebSocket URL: ${newUrl}`);
      }
    } else {
      if (debugState.isEnabled()) {
        logger.info(`Using default WebSocket URL: ${newUrl}`);
      }
    }
    this.url = newUrl;
  }

  public static getInstance(): WebSocketService {
    if (!WebSocketService.instance) {
      WebSocketService.instance = new WebSocketService();
    }
    return WebSocketService.instance;
  }

  private determineWebSocketUrl(): string {
    // Always use a relative path. Nginx handles proxying in dev,
    // and the browser resolves it correctly in production.
    const url = '/wss'; // Changed from /ws to /wss
    if (debugState.isEnabled()) { // Log only if debug is enabled
        logger.info(`Determined WebSocket URL (relative): ${url}`);
    }
    return url;
  }

  /**
   * Set a custom backend URL for WebSocket connections
   * @param backendUrl The backend URL (e.g., 'http://192.168.0.51:8000' or just '192.168.0.51:8000')
   */
  public setCustomBackendUrl(backendUrl: string | null): void {
    if (!backendUrl) {
      // Reset to default URL
      this.url = this.determineWebSocketUrl();
      if (debugState.isEnabled()) {
        logger.info(`Reset to default WebSocket URL: ${this.url}`);
      }
      return;
    }

    // Determine protocol (ws or wss)
    const protocol = backendUrl.startsWith('https://') ? 'wss://' : 'ws://';
    // Extract host and port
    const hostWithProtocol = backendUrl.replace(/^(https?:\/\/)?/, '');
    // Set the WebSocket URL
    this.url = `${protocol}${hostWithProtocol}/wss`; // Changed from /ws to /wss

    if (debugState.isEnabled()) {
      logger.info(`Set custom WebSocket URL: ${this.url}`);
    }

    // If already connected, reconnect with new URL
    if (this.isConnected && this.socket) {
      if (debugState.isEnabled()) {
        logger.info('Reconnecting with new WebSocket URL');
      }
      this.close();
      this.connect().catch(error => {
        logger.error('Failed to reconnect with new URL:', createErrorMetadata(error));
      });
    }
  }

  public async connect(): Promise<void> {
    // Don't try to connect if already connecting or connected
    if (this.socket && (this.socket.readyState === WebSocket.CONNECTING || this.socket.readyState === WebSocket.OPEN)) {
      return;
    }

    try {
      if (debugState.isEnabled()) {
        logger.info(`Connecting to WebSocket at ${this.url}`);
      }

      // Create a new WebSocket connection
      this.socket = new WebSocket(this.url);

      // Handle WebSocket events
      this.socket.onopen = this.handleOpen.bind(this);
      this.socket.onmessage = this.handleMessage.bind(this);
      this.socket.onclose = this.handleClose.bind(this);
      this.socket.onerror = this.handleError.bind(this);

      // Create a promise that resolves when the connection opens or rejects on error
      return new Promise<void>((resolve, reject) => {
        if (!this.socket) {
          reject(new Error('Socket initialization failed'));
          return;
        }

        // Resolve when the socket successfully opens
        this.socket.addEventListener('open', () => resolve(), { once: true });

        // Reject if there's an error before the socket opens
        this.socket.addEventListener('error', (event) => {
          // Only reject if the socket hasn't opened yet
          if (this.socket && this.socket.readyState !== WebSocket.OPEN) {
            reject(new Error('WebSocket connection failed'));
          }
        }, { once: true });
      });
    } catch (error) {
      logger.error('Error establishing WebSocket connection:', createErrorMetadata(error));
      throw error;
    }
  }

  private handleOpen(event: Event): void {
    this.isConnected = true;
    this.reconnectAttempts = 0;
    if (debugState.isEnabled()) {
      logger.info('WebSocket connection established');
    }
    this.notifyConnectionStatusHandlers(true);
  }

  private handleMessage(event: MessageEvent): void {
    // Check for binary data first
    if (event.data instanceof Blob) {
      if (debugState.isDataDebugEnabled()) {
        logger.debug('Received binary blob data');
      }
      // Convert Blob to ArrayBuffer
      event.data.arrayBuffer().then(buffer => {
        // Process the ArrayBuffer, with possible decompression
        this.processBinaryData(buffer);
      }).catch(error => {
        logger.error('Error converting Blob to ArrayBuffer:', createErrorMetadata(error));
      });
      return;
    }

    if (event.data instanceof ArrayBuffer) {
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Received binary ArrayBuffer data: ${event.data.byteLength} bytes`);
      }
      // Process the ArrayBuffer directly, with possible decompression
      this.processBinaryData(event.data);
      return;
    }

    // If not binary, try to parse as JSON
    try {
      const message = JSON.parse(event.data) as WebSocketMessage;

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Received WebSocket message: ${message.type}`, message.data);
      }

      // Special handling for connection_established message
      if (message.type === 'connection_established') {
        this.isServerReady = true;
        if (debugState.isEnabled()) {
          logger.info('Server connection established and ready');
        }
      }

      // Notify all message handlers
      this.messageHandlers.forEach(handler => {
        try {
          handler(message);
        } catch (error) {
          logger.error('Error in message handler:', createErrorMetadata(error));
        }
      });
    } catch (error) {
      logger.error('Error parsing WebSocket message:', createErrorMetadata(error));
    }
  }

  // Make the function async to handle potential promise from decompression
  private async processBinaryData(data: ArrayBuffer): Promise<void> {
    try {
      // Check if data needs decompression
      if (isZlibCompressed(data)) {
        if (debugState.isDataDebugEnabled()) {
          logger.debug('Decompressing binary data');
        }
        // Await the result of decompression if it's a promise
        data = await maybeDecompress(data);
      }

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Processing binary data: ${data.byteLength} bytes`);
      }

      // Notify binary message handlers
      this.binaryMessageHandlers.forEach(handler => {
        try {
          handler(data);
        } catch (error) {
          logger.error('Error in binary message handler:', createErrorMetadata(error));
        }
      });
    } catch (error) {
      logger.error('Error processing binary data:', createErrorMetadata(error));
    }
  }

  private handleClose(event: CloseEvent): void {
    this.isConnected = false;
    this.isServerReady = false;

    if (debugState.isEnabled()) {
      logger.info(`WebSocket connection closed: ${event.code} ${event.reason}`);
    }

    this.notifyConnectionStatusHandlers(false);

    // Attempt to reconnect if it wasn't a normal closure
    if (event.code !== 1000 && event.code !== 1001) {
      this.attemptReconnect();
    }
  }

  private handleError(event: Event): void {
    logger.error('WebSocket error:', { event });
    // The close handler will be called after this, which will handle reconnection
  }

  private attemptReconnect(): void {
    // Clear any existing reconnect timeout
    if (this.reconnectTimeout) {
      window.clearTimeout(this.reconnectTimeout);
      this.reconnectTimeout = null;
    }

    if (this.reconnectAttempts < this.maxReconnectAttempts) {
      this.reconnectAttempts++;
      const delay = this.reconnectInterval * Math.pow(1.5, this.reconnectAttempts - 1);

      if (debugState.isEnabled()) {
        logger.info(`Attempting to reconnect in ${delay}ms (attempt ${this.reconnectAttempts}/${this.maxReconnectAttempts})`);
      }

      this.reconnectTimeout = window.setTimeout(() => {
        this.connect().catch(error => {
          logger.error('Reconnect attempt failed:', createErrorMetadata(error));
        });
      }, delay);
    } else { // Added missing else block
      logger.error(`Maximum reconnect attempts (${this.maxReconnectAttempts}) reached. Giving up.`);
    }
  }

  public sendMessage(type: string, data?: any): void {
    if (!this.isConnected || !this.socket) {
      logger.warn('Cannot send message: WebSocket not connected');
      return;
    }

    try {
      const message: WebSocketMessage = { type, data };
      this.socket.send(JSON.stringify(message));

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Sent message: ${type}`);
      }
    } catch (error) {
      logger.error('Error sending WebSocket message:', createErrorMetadata(error));
    }
  }

  public sendRawBinaryData(data: ArrayBuffer): void {
    if (!this.isConnected || !this.socket) {
      logger.warn('Cannot send binary data: WebSocket not connected');
      return;
    }

    try {
      this.socket.send(data);

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Sent binary data: ${data.byteLength} bytes`);
      }
    } catch (error) {
      logger.error('Error sending binary data:', createErrorMetadata(error));
    }
  }

  public onMessage(handler: MessageHandler): () => void {
    this.messageHandlers.push(handler);
    return () => {
      this.messageHandlers = this.messageHandlers.filter(h => h !== handler);
    };
  }

  public onBinaryMessage(handler: BinaryMessageHandler): () => void {
    this.binaryMessageHandlers.push(handler);
    return () => {
      this.binaryMessageHandlers = this.binaryMessageHandlers.filter(h => h !== handler);
    };
  }

  public onConnectionStatusChange(handler: ConnectionStatusHandler): () => void {
    this.connectionStatusHandlers.push(handler);
    // Immediately notify of current status
    handler(this.isConnected);
    return () => {
      this.connectionStatusHandlers = this.connectionStatusHandlers.filter(h => h !== handler);
    };
  }

  private notifyConnectionStatusHandlers(connected: boolean): void {
    this.connectionStatusHandlers.forEach(handler => {
      try {
        handler(connected);
      } catch (error) {
        logger.error('Error in connection status handler:', createErrorMetadata(error));
      }
    });
  }

  public isReady(): boolean {
    return this.isConnected && this.isServerReady;
  }

  public close(): void {
    if (this.socket) {
      // Clear reconnection timeout
      if (this.reconnectTimeout) {
        window.clearTimeout(this.reconnectTimeout);
        this.reconnectTimeout = null;
      }

      try {
        // Close the socket with a normal closure
        this.socket.close(1000, 'Normal closure');
        if (debugState.isEnabled()) {
          logger.info('WebSocket connection closed by client');
        }
      } catch (error) {
        logger.error('Error closing WebSocket:', createErrorMetadata(error));
      } finally {
        this.socket = null;
        this.isConnected = false;
        this.isServerReady = false;
        this.notifyConnectionStatusHandlers(false);
      }
    }
  }
}

export default WebSocketService;

----
src/services/platformManager.ts
import { create } from 'zustand';
import { createLogger } from '../utils/logger';
import { XRSessionState } from '../features/xr/types/xr';

const logger = createLogger('PlatformManager');

// Detectable platform types
export type PlatformType = 'desktop' | 'mobile' | 'quest' | 'quest2' | 'quest3' | 'pico' | 'unknown';
export type XRDeviceType = 'quest' | 'pico' | 'desktop-xr' | 'mobile-xr' | 'none';

// Interface for platform capabilities
export interface PlatformCapabilities {
  xrSupported: boolean;
  handTrackingSupported: boolean;
  arSupported: boolean;
  vrSupported: boolean;
  performanceTier: 'low' | 'medium' | 'high';
  maxTextureSize: number;
  hasTouchscreen: boolean;
  hasPointer: boolean;
  hasKeyboard: boolean;
  hasGamepad: boolean;
  memoryLimited: boolean;
}

// Event types for platform events
export type PlatformEventType = 
  | 'platformchange' 
  | 'xrmodechange' 
  | 'xrsessionstatechange' 
  | 'deviceorientationchange'
  | 'handtrackingavailabilitychange';

interface PlatformState {
  // Platform details
  platform: PlatformType;
  xrDeviceType: XRDeviceType;
  capabilities: PlatformCapabilities;
  userAgent: string;
  isXRMode: boolean;
  xrSessionState: XRSessionState;
  isWebXRSupported: boolean;
  
  // Event listeners storage
  listeners: Map<PlatformEventType, Set<Function>>;
  
  // Initialization
  initialized: boolean;
  initialize: () => Promise<void>;
  
  // Platform detection
  detectPlatform: () => void;
  isQuest: () => boolean;
  isPico: () => boolean;
  isDesktop: () => boolean;
  isMobile: () => boolean;
  isXRSupported: () => boolean;
  
  // XR mode management
  setXRMode: (enabled: boolean) => void;
  setXRSessionState: (state: XRSessionState) => void;
  
  // Event handling
  dispatchEvent: (event: PlatformEventType, data: any) => void;
  addEventListener: (event: PlatformEventType, callback: Function) => void;
  removeEventListener: (event: PlatformEventType, callback: Function) => void;
  removeAllListeners: (event?: PlatformEventType) => void;
}

export const usePlatformStore = create<PlatformState>()((set, get) => ({
  // Default initial state
  platform: 'unknown',
  xrDeviceType: 'none',
  capabilities: {
    xrSupported: false,
    handTrackingSupported: false,
    arSupported: false,
    vrSupported: false,
    performanceTier: 'medium',
    maxTextureSize: 2048,
    hasTouchscreen: false,
    hasPointer: true,
    hasKeyboard: true,
    hasGamepad: false,
    memoryLimited: false
  },
  userAgent: typeof navigator !== 'undefined' ? navigator.userAgent : '',
  isXRMode: false,
  xrSessionState: 'inactive',
  isWebXRSupported: typeof navigator !== 'undefined' && !!navigator.xr,
  initialized: false,
  
  // Event listeners
  listeners: new Map<PlatformEventType, Set<Function>>(),
  
  initialize: async () => {
    logger.info('Initializing platform manager');
    
    // Detect platform first
    get().detectPlatform();
    
    // Check for XR support
    if (typeof navigator !== 'undefined' && navigator.xr) {
      // Test for VR support
      try {
        const vrSupported = await navigator.xr.isSessionSupported('immersive-vr');
        // Test for AR support (Oculus Quest)
        const arSupported = await navigator.xr.isSessionSupported('immersive-ar');
        
        set(state => ({
          capabilities: {
            ...state.capabilities,
            xrSupported: vrSupported || arSupported,
            
            vrSupported,
            arSupported
          }
        }));
        
        logger.info('XR support detected', { vrSupported, arSupported });
      } catch (error) {
        logger.error('Error checking XR support:', error);
      }
    }
    
    // Check for hand tracking support
    if (typeof navigator !== 'undefined' && navigator.xr) {
      try {
        // Note: This might need further detection based on device
        const handTrackingSupported = get().isQuest();
        
        set(state => ({
          capabilities: {
            ...state.capabilities,
            handTrackingSupported
          }
        }));
      } catch (error) {
        logger.error('Error checking hand tracking support:', error);
      }
    }
    
    // Set up event listeners
    if (typeof window !== 'undefined') {
      window.addEventListener('resize', () => {
        get().detectPlatform();
      });
    }
    
    // Update WebXR support
    const isWebXRSupported = typeof navigator !== 'undefined' && !!navigator.xr;
    
    set({ 
      initialized: true,
      isWebXRSupported
    });
    
    logger.info('Platform manager initialized', {
      platform: get().platform,
      xrDeviceType: get().xrDeviceType,
      capabilities: get().capabilities
    });
  },
  
  detectPlatform: () => {
    const userAgent = typeof navigator !== 'undefined' ? navigator.userAgent : '';
    let platform: PlatformType = 'unknown';
    let xrDeviceType: XRDeviceType = 'none';
    
    // Check for Quest
    if (userAgent.includes('Quest')) {
      if (userAgent.includes('Quest 3')) {
        platform = 'quest3';
      } else if (userAgent.includes('Quest 2')) {
        platform = 'quest2';
      } else {
        platform = 'quest';
      }
      xrDeviceType = 'quest';
    }
    // Check for Pico
    else if (userAgent.includes('Pico') || userAgent.includes('PICO')) {
      platform = 'pico';
      xrDeviceType = 'pico';
    }
    // Check for mobile
    else if (/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(userAgent)) {
      platform = 'mobile';
      xrDeviceType = 'mobile-xr';
    }
    // Default to desktop
    else {
      platform = 'desktop';
      xrDeviceType = 'desktop-xr';
    }
    
    // Determine performance tier based on platform
    let performanceTier: 'low' | 'medium' | 'high' = 'medium';
    let maxTextureSize = 2048;
    let memoryLimited = false;
    
    switch (platform) {
      case 'quest3':
        performanceTier = 'high';
        maxTextureSize = 4096;
        memoryLimited = true;
        break;
      case 'quest2':
        performanceTier = 'medium';
        maxTextureSize = 2048;
        memoryLimited = true;
        break;
      case 'quest':
        performanceTier = 'low';
        maxTextureSize = 2048;
        memoryLimited = true;
        break;
      case 'pico':
        performanceTier = 'medium';
        maxTextureSize = 2048;
        memoryLimited = true;
        break;
      case 'mobile':
        performanceTier = 'low';
        maxTextureSize = 2048;
        memoryLimited = true;
        break;
      case 'desktop':
        performanceTier = 'high';
        maxTextureSize = 8192;
        memoryLimited = false;
        break;
    }
    
    // Detect features
    const hasTouchscreen = typeof navigator !== 'undefined' && 
      ('maxTouchPoints' in navigator ? navigator.maxTouchPoints > 0 : 'ontouchstart' in window);
    
    // Update state with detected platform
    const prevPlatform = get().platform;
    set(state => ({ 
      platform,
      xrDeviceType,
      userAgent,
      capabilities: {
        ...state.capabilities,
        performanceTier,
        maxTextureSize,
        memoryLimited,
        hasTouchscreen,
        hasPointer: platform === 'desktop' || platform === 'mobile',
        hasKeyboard: platform === 'desktop',
        hasGamepad: platform.startsWith('quest') || platform === 'pico'
      }
    }));
    
    // Emit platform change event if changed
    if (prevPlatform !== platform) {
      get().dispatchEvent('platformchange', { platform });
    }
    
    return platform;
  },
  
  isQuest: () => {
    const platform = get().platform;
    return platform === 'quest' || platform === 'quest2' || platform === 'quest3';
  },
  
  isPico: () => {
    return get().platform === 'pico';
  },
  
  isDesktop: () => {
    return get().platform === 'desktop';
  },
  
  isMobile: () => {
    return get().platform === 'mobile';
  },
  
  isXRSupported: () => {
    return get().capabilities.xrSupported;
  },
  
  setXRMode: (enabled: boolean) => {
    const prev = get().isXRMode;
    if (prev !== enabled) {
      set({ isXRMode: enabled });
      get().dispatchEvent('xrmodechange', { enabled });
      logger.info(`XR mode ${enabled ? 'enabled' : 'disabled'}`);
    }
  },
  
  setXRSessionState: (state: XRSessionState) => {
    const prev = get().xrSessionState;
    if (prev !== state) {
      set({ xrSessionState: state });
      get().dispatchEvent('xrsessionstatechange', { state });
      logger.info(`XR session state changed to ${state}`);
    }
  },
  
  // Internal helper to dispatch events
  dispatchEvent: (event: PlatformEventType, data: any) => {
    const listeners = get().listeners;
    if (!listeners.has(event)) return;
    
    listeners.get(event)?.forEach(callback => {
      try {
        callback(data);
      } catch (error) {
        logger.error(`Error in ${event} listener:`, error);
      }
    });
  },
  
  // Event handling
  addEventListener: (event: PlatformEventType, callback: Function) => {
    const listeners = get().listeners;
    
    if (!listeners.has(event)) {
      listeners.set(event, new Set());
    }
    
    listeners.get(event)?.add(callback);
    set({ listeners });
    
    // Immediately call the callback with current state for some events
    if (event === 'platformchange') {
      callback({ platform: get().platform });
    } else if (event === 'xrmodechange') {
      callback({ enabled: get().isXRMode });
    } else if (event === 'xrsessionstatechange') {
      callback({ state: get().xrSessionState });
    }
  },
  
  removeEventListener: (event: PlatformEventType, callback: Function) => {
    const listeners = get().listeners;
    if (listeners.has(event)) {
      listeners.get(event)?.delete(callback);
      set({ listeners });
    }
  },
  
  removeAllListeners: (event?: PlatformEventType) => {
    const listeners = get().listeners;
    
    if (event) {
      listeners.delete(event);
    } else {
      listeners.clear();
    }
    
    set({ listeners });
  }
}));

// Create a React hook to access the PlatformManager
export function usePlatform() {
  return usePlatformStore();
}

// Backwards compatibility adapter for old code
export class PlatformManager {
  private static instance: PlatformManager;
  
  private constructor() {}
  
  public static getInstance(): PlatformManager {
    if (!PlatformManager.instance) {
      PlatformManager.instance = new PlatformManager();
    }
    return PlatformManager.instance;
  }
  
  public get platform(): PlatformType {
    return usePlatformStore.getState().platform;
  }
  
  public get isXRMode(): boolean {
    return usePlatformStore.getState().isXRMode;
  }
  
  public get xrSessionState(): XRSessionState {
    return usePlatformStore.getState().xrSessionState;
  }
  
  public set xrSessionState(state: XRSessionState) {
    usePlatformStore.getState().setXRSessionState(state);
  }
  
  public async initialize(settings: any): Promise<void> {
    return usePlatformStore.getState().initialize();
  }
  
  public isQuest(): boolean {
    return usePlatformStore.getState().isQuest();
  }
  
  public isPico(): boolean {
    return usePlatformStore.getState().isPico();
  }
  
  public isDesktop(): boolean {
    return usePlatformStore.getState().isDesktop();
  }

  public isWebXRSupported(): boolean {
    return usePlatformStore.getState().isWebXRSupported;
  }
  
  public isMobile(): boolean {
    return usePlatformStore.getState().isMobile();
  }
  
  public isXRSupported(): boolean {
    return usePlatformStore.getState().isXRSupported();
  }
  
  public setXRMode(enabled: boolean): void {
    usePlatformStore.getState().setXRMode(enabled);
  }
  
  public getCapabilities(): PlatformCapabilities {
    return usePlatformStore.getState().capabilities;
  }
  
  public on(event: PlatformEventType, callback: Function): void {
    usePlatformStore.getState().addEventListener(event, callback);
  }
  
  public off(event: PlatformEventType, callback: Function): void {
    usePlatformStore.getState().removeEventListener(event, callback);
  }
  
  public removeAllListeners(event?: PlatformEventType): void {
    usePlatformStore.getState().removeAllListeners(event);
  }
}

// Export a singleton instance for backwards compatibility
export const platformManager = PlatformManager.getInstance();
----
src/services/api.ts
import { createLogger, createErrorMetadata } from '../utils/logger';
import { debugState } from '../utils/debugState';

const logger = createLogger('ApiService');

/**
 * API Service for making requests to the backend
 */
class ApiService {
  private static instance: ApiService;
  private baseUrl: string;

  private constructor() {
    this.baseUrl = '/api';
  }

  public static getInstance(): ApiService {
    if (!ApiService.instance) {
      ApiService.instance = new ApiService();
    }
    return ApiService.instance;
  }

  /**
   * Set the base URL for API requests
   * @param url The new base URL
   */
  public setBaseUrl(url: string): void {
    this.baseUrl = url;
    logger.info(`API base URL set to: ${url}`);
  }

  /**
   * Get the current base URL
   */
  public getBaseUrl(): string {
    return this.baseUrl;
  }

  /**
   * Make a GET request to the API
   * @param endpoint The API endpoint
   * @param headers Optional request headers
   * @returns The response data
   */
  public async get<T>(endpoint: string, headers: Record<string, string> = {}): Promise<T> {
    try {
      const url = `${this.baseUrl}${endpoint}`;

      if (debugState.isEnabled()) {
        logger.debug(`Making GET request to ${url}`);
      }

      const response = await fetch(url, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json',
          ...headers
        }
      });

      if (!response.ok) {
        throw new Error(`API request failed with status ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();

      if (debugState.isEnabled()) {
        logger.debug(`GET request to ${endpoint} succeeded`);
      }

      return data;
    } catch (error) {
      logger.error(`GET request to ${endpoint} failed:`, createErrorMetadata(error));
      throw error;
    }
  }

  /**
   * Make a POST request to the API
   * @param endpoint The API endpoint
   * @param data The request body data
   * @param headers Optional request headers
   * @returns The response data
   */
  public async post<T>(endpoint: string, data: any, headers: Record<string, string> = {}): Promise<T> {
    try {
      const url = `${this.baseUrl}${endpoint}`;

      if (debugState.isEnabled()) {
        logger.debug(`Making POST request to ${url}`);
      }

      const response = await fetch(url, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          ...headers
        },
        body: JSON.stringify(data)
      });

      if (!response.ok) {
        throw new Error(`API request failed with status ${response.status}: ${response.statusText}`);
      }

      const responseData = await response.json();

      if (debugState.isEnabled()) {
        logger.debug(`POST request to ${endpoint} succeeded`);
      }

      return responseData;
    } catch (error) {
      logger.error(`POST request to ${endpoint} failed:`, createErrorMetadata(error));
      throw error;
    }
  }

  /**
   * Make a PUT request to the API
   * @param endpoint The API endpoint
   * @param data The request body data
   * @param headers Optional request headers
   * @returns The response data
   */
  public async put<T>(endpoint: string, data: any, headers: Record<string, string> = {}): Promise<T> {
    try {
      const url = `${this.baseUrl}${endpoint}`;

      if (debugState.isEnabled()) {
        logger.debug(`Making PUT request to ${url}`);
      }

      const response = await fetch(url, {
        method: 'PUT',
        headers: {
          'Content-Type': 'application/json',
          ...headers
        },
        body: JSON.stringify(data)
      });

      if (!response.ok) {
        throw new Error(`API request failed with status ${response.status}: ${response.statusText}`);
      }

      const responseData = await response.json();

      if (debugState.isEnabled()) {
        logger.debug(`PUT request to ${endpoint} succeeded`);
      }

      return responseData;
    } catch (error) {
      logger.error(`PUT request to ${endpoint} failed:`, createErrorMetadata(error));
      throw error;
    }
  }

  /**
   * Make a DELETE request to the API
   * @param endpoint The API endpoint
   * @param headers Optional request headers
   * @returns The response data
   */
  public async delete<T>(endpoint: string, headers: Record<string, string> = {}): Promise<T> {
    try {
      const url = `${this.baseUrl}${endpoint}`;

      if (debugState.isEnabled()) {
        logger.debug(`Making DELETE request to ${url}`);
      }

      const response = await fetch(url, {
        method: 'DELETE',
        headers: {
          'Content-Type': 'application/json',
          ...headers
        }
      });

      if (!response.ok) {
        throw new Error(`API request failed with status ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();

      if (debugState.isEnabled()) {
        logger.debug(`DELETE request to ${endpoint} succeeded`);
      }

      return data;
    } catch (error) {
      logger.error(`DELETE request to ${endpoint} failed:`, createErrorMetadata(error));
      throw error;
    }
  }
}

export const apiService = ApiService.getInstance();

----
src/services/settingsService.ts
import { Settings } from '../features/settings/config/settings';
import { apiService } from './api';
import { createLogger, createErrorMetadata } from '../utils/logger';
import { convertSnakeToCamelCase, convertCamelToSnakeCase } from '../utils/caseConversion';
import { debugState } from '../utils/debugState';

const logger = createLogger('SettingsService');

/**
 * Service for managing settings API interactions
 */
class SettingsService {
  private static instance: SettingsService;

  private constructor() {}

  public static getInstance(): SettingsService {
    if (!SettingsService.instance) {
      SettingsService.instance = new SettingsService();
    }
    return SettingsService.instance;
  }

  /**
   * Fetch settings from the server
   * @returns The settings from the server, converted to camelCase
   */
  public async fetchSettings(): Promise<Settings | null> {
    try {
      // Fetch settings from the server
      const rawSettings = await apiService.get<Record<string, any>>('/user-settings');
      
      // Server sends camelCase for this endpoint, so no conversion needed here.
      const settings = rawSettings as Settings;
      
      if (debugState.isEnabled()) {
        logger.info('Fetched settings from server (already camelCase):', { settings });
      }
      
      return settings;
    } catch (error) {
      logger.error('Failed to fetch settings:', createErrorMetadata(error));
      return null;
    }
  }

  /**
   * Save settings to the server
   * @param settings The settings to save, in camelCase
   * @param authHeaders Optional authentication headers
   * @returns The updated settings from the server, converted to camelCase
   */
  public async saveSettings(
    settings: Settings,
    authHeaders: Record<string, string> = {}
  ): Promise<Settings | null> {
    try {
      // Convert settings to snake_case for the server
      const settingsToSend = settings; // Send camelCase directly as server expects it for this endpoint
      
      if (debugState.isEnabled()) {
        logger.info('Saving settings to server (camelCase):', { settingsToSend });
      }
      
      // Send settings to the server
      const rawUpdatedSettings = await apiService.post<Record<string, any>>(
        '/user-settings/sync',
        settingsToSend,
        authHeaders
      );
      
      // Server sends camelCase for this endpoint's response, so no conversion needed here.
      const updatedSettings = rawUpdatedSettings as Settings;
      
      if (debugState.isEnabled()) {
        logger.info('Settings saved successfully (response already camelCase):', { updatedSettings });
      }
      
      return updatedSettings;
    } catch (error) {
      logger.error('Failed to save settings:', createErrorMetadata(error));
      return null;
    }
  }

  /**
   * Clear the settings cache on the server
   * @param authHeaders Authentication headers
   * @returns Whether the operation was successful
   */
  public async clearSettingsCache(authHeaders: Record<string, string>): Promise<boolean> {
    try {
      await apiService.post('/user-settings/clear-cache', {}, authHeaders);
      logger.info('Settings cache cleared successfully');
      return true;
    } catch (error) {
      logger.error('Failed to clear settings cache:', createErrorMetadata(error));
      return false;
    }
  }
}

export const settingsService = SettingsService.getInstance();

----
src/store/settingsStore.ts
import { create } from 'zustand'
import { persist, createJSONStorage } from 'zustand/middleware'
import { defaultSettings } from '../features/settings/config/defaultSettings'
import { Settings, SettingsPath } from '../features/settings/config/settings'
import { createLogger, createErrorMetadata } from '../utils/logger'
import { debugState } from '../utils/debugState'
import { deepMerge } from '../utils/deepMerge';
import { settingsService } from '../services/settingsService';
import { produce } from 'immer';
import { toast } from '../ui/useToast'; // Import toast

const logger = createLogger('SettingsStore')

interface SettingsState {
  settings: Settings
  initialized: boolean
  authenticated: boolean
  user: { isPowerUser: boolean; pubkey: string } | null
  subscribers: Map<string, Set<() => void>>

  // Actions
  initialize: () => Promise<Settings>
  setAuthenticated: (authenticated: boolean) => void
  setUser: (user: { isPowerUser: boolean; pubkey: string } | null) => void
  get: <T>(path: SettingsPath) => T
  set: <T>(path: SettingsPath, value: T) => void
  subscribe: (path: SettingsPath, callback: () => void, immediate?: boolean) => () => void;
  unsubscribe: (path: SettingsPath, callback: () => void) => void;
  updateSettings: (updater: (draft: Settings) => void) => void; // Add updateSettings signature
}

export const useSettingsStore = create<SettingsState>()(
  persist(
    (set, get) => ({
      settings: defaultSettings,
      initialized: false,
      authenticated: false,
      user: null,
      subscribers: new Map(),

      initialize: async () => {
        try {
          if (debugState.isEnabled()) {
            logger.info('Initializing settings')
          }

          // Load settings from localStorage via zustand persist
          const currentSettings = get().settings

          // Fetch settings from server if available
          try {
            // Use the settings service to fetch settings
            const serverSettings = await settingsService.fetchSettings()

            if (serverSettings) {
              if (debugState.isEnabled()) {
                logger.info('Fetched settings from server:', { serverSettings })
              }

              // Merge server settings with defaults and current settings using deep merge
              // This ensures all nested objects are properly merged
              const mergedSettings = deepMerge(defaultSettings, currentSettings, serverSettings)

              if (debugState.isEnabled()) {
                logger.info('Deep merged settings:', { mergedSettings })
              }

              set({
                settings: mergedSettings,
                initialized: true
              })

              if (debugState.isEnabled()) {
                logger.info('Settings loaded from server and merged')
              }

              return mergedSettings
            }
          } catch (error) {
            logger.warn('Failed to fetch settings from server:', createErrorMetadata(error))
            // Continue with local settings if server fetch fails
          }

          // Mark as initialized
          set({ initialized: true })

          if (debugState.isEnabled()) {
            logger.info('Settings initialized from local storage')
          }

          return currentSettings
        } catch (error) {
          logger.error('Failed to initialize settings:', createErrorMetadata(error))

          // Fall back to default settings
          set({
            settings: defaultSettings,
            initialized: true
          })

          return defaultSettings
        }
      },

      setAuthenticated: (authenticated: boolean) => set({ authenticated }),

      setUser: (user: { isPowerUser: boolean; pubkey: string } | null) => set({ user }),

      get: <T>(path: SettingsPath): T => {
        const settings = get().settings

        if (!path || path === '') {
          return settings as unknown as T
        }

        // Navigate the settings object using the path
        let current: any = settings
        const pathParts = path.split('.')

        for (const part of pathParts) {
          if (current === undefined || current === null) {
            return undefined as unknown as T
          }
          current = current[part]
        }

        return current as T
      },

      set: <T>(path: SettingsPath, value: T) => {
        set(state => {
          // If setting the entire object
          if (!path || path === '') {
            return { settings: value as unknown as Settings }
          }

          // Create a deep copy of the settings object
          const newSettings = JSON.parse(JSON.stringify(state.settings))

          // Navigate to the correct location and update
          const pathParts = path.split('.')
          let current = newSettings

          // Navigate to the parent of the setting we want to update
          for (let i = 0; i < pathParts.length - 1; i++) {
            const part = pathParts[i]
            if (current[part] === undefined || current[part] === null) {
              // Create the path if it doesn't exist
              current[part] = {}
            }
            current = current[part]
          }

          // Update the value
          const finalPart = pathParts[pathParts.length - 1]
          current[finalPart] = value

          // Return the updated settings
          return { settings: newSettings }
        })

        // Notify subscribers
        const notifySubscribers = async () => {
          const state = get()

          // Build a list of paths to notify
          // e.g. for path 'visualisation.bloom.enabled':
          // '', 'visualisation', 'visualisation.bloom', 'visualisation.bloom.enabled'
          const pathsToNotify = ['']
          const pathParts = path.split('.')
          let currentPath = ''

          for (const part of pathParts) {
            currentPath = currentPath ? `${currentPath}.${part}` : part
            pathsToNotify.push(currentPath)
          }

          // Notify subscribers for each path
          for (const notifyPath of pathsToNotify) {
            const callbacks = state.subscribers.get(notifyPath)
            if (callbacks) {
              // Convert Set to Array to avoid TypeScript iteration issues
              Array.from(callbacks).forEach(callback => {
                try {
                  callback()
                } catch (error) {
                  logger.error(`Error in settings subscriber for path ${notifyPath}:`, createErrorMetadata(error))
                }
              })
            }
          }

          // Save to server if appropriate
          if (state.initialized && state.settings.system?.persistSettings !== false) {
            try {
              // Prepare authentication headers
              const headers: Record<string, string> = {};

              // Add Nostr authentication if available
              try {
                // Import nostrAuth dynamically to avoid circular dependencies
                const { nostrAuth } = await import('../services/nostrAuthService')

                if (nostrAuth.isAuthenticated()) {
                  const user = nostrAuth.getCurrentUser()
                  const token = nostrAuth.getSessionToken()

                  if (user && token) {
                    headers['X-Nostr-Pubkey'] = user.pubkey
                    headers['Authorization'] = `Bearer ${token}`
                    logger.info('Using Nostr authentication for settings sync')
                  } else {
                    logger.warn('Nostr auth is authenticated but missing user or token')
                  }
                } else {
                  logger.info('Not authenticated with Nostr, proceeding without auth')
                }
              } catch (error) {
                logger.warn('Error getting Nostr authentication:', createErrorMetadata(error))
                // Proceed without auth header if there's an error
              }

              // Use the settings service to save settings
              const updatedSettings = await settingsService.saveSettings(state.settings, headers);

              if (updatedSettings) { // Check if response is not null (success)
                if (debugState.isEnabled()) {
                  logger.info('Settings saved to server successfully');
                }
                toast({ title: "Settings Saved", description: "Your settings have been synced with the server." });
                // Optionally, merge serverResponse back into store if server can modify settings during save
                // For now, assume client is authoritative for UI settings it sends.
                // If server can modify settings, you might do:
                // set(s => ({ ...s, settings: deepMerge(s.settings, updatedSettings) }));
              } else {
                // saveSettings would have returned null or thrown an error handled by catch
                // throw new Error('Server responded with an error or no data.'); // This will be caught below
                // The toast for failure will be handled in the catch block
              }
            } catch (error) {
              const errorMeta = createErrorMetadata(error);
              logger.error('Failed to save settings to server:', errorMeta);
              toast({ variant: "destructive", title: "Save Failed", description: `Could not save settings to server. ${errorMeta.message || 'Check console.'}` });
            }
          }
        }

        // Debounce saving settings
        if (typeof window !== 'undefined') {
          if (window.settingsSaveTimeout) {
            clearTimeout(window.settingsSaveTimeout)
          }
          window.settingsSaveTimeout = setTimeout(notifySubscribers, 300)
        } else {
          // If running server-side, notify immediately
          notifySubscribers()
        }
      },

      subscribe: (path: SettingsPath, callback: () => void, immediate: boolean = true) => {
        set(state => {
          const subscribers = new Map(state.subscribers)

          if (!subscribers.has(path)) {
            subscribers.set(path, new Set())
          }

          subscribers.get(path)!.add(callback)

          return { subscribers }
        })

        // Call callback immediately if requested and initialized
        if (immediate && get().initialized) {
          callback()
        }

        // Return unsubscribe function
        return () => get().unsubscribe(path, callback)
      },

      unsubscribe: (path: SettingsPath, callback: () => void) => {
        set(state => {
          const subscribers = new Map(state.subscribers)

          if (subscribers.has(path)) {
            const callbacks = subscribers.get(path)!
            callbacks.delete(callback)

            if (callbacks.size === 0) {
              subscribers.delete(path)
            }
          }

          return { subscribers }
        })
      },

      // Corrected updateSettings implementation using Immer
      updateSettings: (updater) => {
        // Correct usage: produce takes the current state and the updater function
        set((state) => produce(state, (draft) => {
          // Apply the updater function to the draft state
          updater(draft.settings); // Pass only the settings part of the draft to the updater
        }));

        // Trigger save/notification logic (remains the same)
        const notifySubscribers = async () => {
          const state = get();
          // Notify all subscribers for simplicity, or refine later
          const allCallbacks = new Set<() => void>();
          state.subscribers.forEach(callbacks => {
            callbacks.forEach(cb => allCallbacks.add(cb));
          });

          Array.from(allCallbacks).forEach(callback => {
            try {
              callback();
            } catch (error) {
              logger.error(`Error in settings subscriber during updateSettings:`, createErrorMetadata(error));
            }
          });

          // Save to server if appropriate (copied from set, consider refactoring)
          if (state.initialized && state.settings.system?.persistSettings !== false) {
            try {
              const headers: Record<string, string> = {};
              try {
                const { nostrAuth } = await import('../services/nostrAuthService');
                if (nostrAuth.isAuthenticated()) {
                  const user = nostrAuth.getCurrentUser();
                  const token = nostrAuth.getSessionToken();
                  if (user && token) {
                    headers['X-Nostr-Pubkey'] = user.pubkey;
                    headers['Authorization'] = `Bearer ${token}`;
                  }
                }
              } catch (error) {
                logger.warn('Error getting Nostr authentication for updateSettings:', createErrorMetadata(error));
              }

              const updatedSettings = await settingsService.saveSettings(state.settings, headers);
              if (updatedSettings) {
                if (debugState.isEnabled()) {
                  logger.info('Settings saved to server successfully via updateSettings');
                }
                toast({ title: "Settings Saved", description: "Your settings have been synced with the server." });
              } else {
                // Failure toast handled in catch
              }
            } catch (error) {
              const errorMeta = createErrorMetadata(error);
              logger.error('Failed to save settings to server via updateSettings:', errorMeta);
              toast({ variant: "destructive", title: "Save Failed", description: `Could not save settings to server (updateSettings). ${errorMeta.message || 'Check console.'}` });
            }
          }
        };

        // Debounce saving settings (copied from set)
        if (typeof window !== 'undefined') {
          if (window.settingsSaveTimeout) {
            clearTimeout(window.settingsSaveTimeout);
          }
          window.settingsSaveTimeout = setTimeout(notifySubscribers, 300);
        } else {
          notifySubscribers();
        }
      },

      // The subscribe and unsubscribe functions below were duplicated and are removed by this change.
    }),
    {
      name: 'graph-viz-settings',
      storage: createJSONStorage(() => localStorage),
      partialize: (state) => ({
        settings: state.settings,
        authenticated: state.authenticated,
        user: state.user
      })
    }
  )
)

// Add to Window interface
declare global {
  interface Window {
    settingsSaveTimeout: ReturnType<typeof setTimeout>;
  }
}

----
src/components/layout/ViewportContainer.tsx
import React, { useRef, useEffect, useState, type ReactNode } from 'react';
import { useSettingsStore } from '../../store/settingsStore';
import { createLogger } from '../../utils/logger';

const logger = createLogger('ViewportContainer');

interface ViewportContainerProps {
  children: ReactNode;
  
  /** 
   * Optional callback for when the viewport size changes
   */
  onResize?: (width: number, height: number) => void;
}

/**
 * ViewportContainer serves as the main container for the Three.js visualisation.
 * It handles resize events and coordinates with the panel system to adjust its dimensions
 * when panels are docked/undocked.
 */
const ViewportContainer = ({
  children,
  onResize
}: ViewportContainerProps) => {
  const viewportRef = useRef<HTMLDivElement>(null);
  const [dimensions, setDimensions] = useState({ width: 0, height: 0 });
  // Select primitive values individually to ensure stable references
  const initialized = useSettingsStore(state => state.initialized);
  const debugEnabled = useSettingsStore(state => state.settings?.system?.debug?.enabled === true);

  // Only log if debug is enabled
  if (debugEnabled) {
    logger.debug("Rendering ViewportContainer");
  }

  // Track resize events to update viewport dimensions
  useEffect(() => {
    const updateDimensions = () => {
      if (viewportRef.current) {
        const { width, height } = viewportRef.current.getBoundingClientRect();
        
        // Only update dimensions if they've actually changed
        if (Math.abs(dimensions.width - width) > 1 || Math.abs(dimensions.height - height) > 1) {
          setDimensions({ width, height });
          
          if (onResize) {
            onResize(width, height);
          }
          
          if (debugEnabled && width > 0 && height > 0) {
            logger.debug('Viewport dimensions:', { 
              width: Math.round(width), 
              height: Math.round(height),
              containerElement: viewportRef.current.parentElement
            });
          }
        }
      }
    };
    
    // Enhance the measurement by forcing a layout recalculation
    const forceLayoutAndMeasure = () => {
      if (viewportRef.current) {
        // Force a layout recalculation
        void viewportRef.current.offsetHeight;
        // Now measure
        updateDimensions();
      }
    };
    
    // Initial size measurement
    forceLayoutAndMeasure();
    
    // Also measure after a slight delay to catch any post-render adjustments
    const initialMeasurementTimer = setTimeout(() => {
      forceLayoutAndMeasure();
    }, 100);
    
    // And another measurement after layout has fully settled
    const finalMeasurementTimer = setTimeout(() => {
      forceLayoutAndMeasure();
    }, 500);

    // Add resize event listener
    window.addEventListener('resize', updateDimensions);
    
    // Create ResizeObserver to track container size changes
    const resizeObserver = new ResizeObserver(updateDimensions);
    if (viewportRef.current) {
      resizeObserver.observe(viewportRef.current);
    }
    
    return () => {
      clearTimeout(initialMeasurementTimer);
      clearTimeout(finalMeasurementTimer);
      window.removeEventListener('resize', updateDimensions);
      resizeObserver.disconnect();
    };
  }, [onResize, dimensions, debugEnabled]);

  // Trigger resize notification when initialization completes
  useEffect(() => {
    if (initialized && viewportRef.current) {
      const { width, height } = viewportRef.current.getBoundingClientRect();
      
      if (debugEnabled) {
        logger.debug('Viewport initialized with dimensions:', { 
          width: Math.round(width), 
          height: Math.round(height) 
        });
      }

      if (onResize) {
        onResize(width, height);
      }
    }
  }, [initialized, onResize, debugEnabled]);

  return (
    <div 
      ref={viewportRef}
      className="viewport-container relative w-full h-full min-h-0 bg-background" // Removed flex-1 class
      data-testid="viewport-container"
      style={{
        // flex: '1 1 auto', // Removed inline flex grow, rely on h-full class
        minHeight: '0',
        display: 'flex', // Keep as flex column container
        flexDirection: 'column' // Keep as flex column container
      }}
    >
      {/* Render children directly, removing the intermediate div */}
      {children}
      
      {/* Viewport size indicator for debugging */}
      {debugEnabled && process.env.NODE_ENV === 'development' && (
        <div className="absolute bottom-2 right-2 text-xs text-muted-foreground bg-background/70 px-2 py-1 rounded-md z-10">
          {`${Math.round(dimensions.width)} × ${Math.round(dimensions.height)}`}
        </div>
      )}
    </div>
  );
}

export default ViewportContainer;

----
src/components/layout/ControlPanel.tsx
import React from 'react';
import Tabs from '../../ui/Tabs';
import NostrAuthSection from '../../features/auth/components/NostrAuthSection';
import SystemPanel from '../../features/settings/components/panels/SystemPanel';
import VisualisationPanel from '../../features/settings/components/panels/VisualisationPanel';
import XRPanel from '../../features/settings/components/panels/XRPanel';
import AIPanel from '../../features/settings/components/panels/AIPanel';
import MarkdownRenderer from '../../ui/markdown/MarkdownRenderer';
import { Button } from '../../ui/Button';
import { Settings, Eye, Smartphone, Send, Anchor } from 'lucide-react'; // Using Settings as universal placeholder
import { settingsUIDefinition } from '../../features/settings/config/settingsUIDefinition';

// Placeholder markdown content (can be moved to a separate file or constant)
const placeholderMarkdown = `
# Markdown Tab

This tab uses the \`MarkdownRenderer\` component.

*   Supports standard Markdown.
*   Includes syntax highlighting for code blocks.

\`\`\`javascript
// Example code block
function greet(name) {
  console.log(\`Hello, \${name}!\`);
}
greet('World');
\`\`\`

Visit [Narrative Gold Mine](https://narrativegoldmine.com/#/graph).

## Extra Content to Force Scrolling

${'- This is a repeated line to force scrolling\n'.repeat(20)}

### More Content

${'- Another repeated line with different text\n'.repeat(20)}
`;

const LowerControlPanel: React.FC = () => {
  // Define tabs for settings
  const settingsTabs = [
    { label: 'Auth', icon: <Settings size={16} />, content: <div className="p-4 overflow-y-auto h-full custom-scrollbar"><NostrAuthSection /></div> },
    { label: 'Visualisation', icon: <Eye size={16} />, content: <VisualisationPanel settingsDef={settingsUIDefinition.visualisation} /> },
    { label: 'System', icon: <Settings size={16} />, content: <SystemPanel settingsDef={settingsUIDefinition.system} /> },
    { label: 'XR', icon: <Smartphone size={16} />, content: <XRPanel settingsDef={settingsUIDefinition.xr} /> },
    { label: 'AI', icon: <Settings size={16} />, content: <AIPanel settingsDef={settingsUIDefinition.ai} /> }, // Placeholder icon for AI
  ];

  // Define tabs for tools (including NGM)
  const toolTabs = [
    { label: 'Narrative Gold Mine', icon: <Anchor size={16} />, content: (
        // Ensure the parent div allows the iframe to take full height
        <div className="w-full h-full flex flex-col overflow-hidden">
          <iframe
            src="https://narrativegoldmine.com" // This is the external website
            className="w-full h-full border-none flex-grow" // Use flex-grow to fill space
            title="Narrative Gold Mine"
            sandbox="allow-scripts allow-same-origin allow-popups allow-forms"
            loading="lazy"
            referrerPolicy="no-referrer"
          />
        </div>
      )
    },
    { label: 'Markdown', icon: <Settings size={16} />, content: <div className="p-4 overflow-y-auto h-full custom-scrollbar"><MarkdownRenderer content={placeholderMarkdown} className="" /></div> }, // Placeholder icon for Markdown
    { label: 'LLM Query', icon: <Send size={16} />, content: (
        <div className="p-4 flex flex-col h-full">
          <textarea
            className="flex-1 mb-2 p-2 border border-border rounded bg-input text-foreground resize-none focus:outline-none focus:ring-2 focus:ring-primary custom-scrollbar"
            placeholder="Enter your query..."
          />
          <Button className="self-end">Send Query</Button>
        </div>
      )
    },
  ];

  return (
    // Main container now stacks its children vertically and ensures full height.
    <div className="flex flex-col w-full h-full bg-card text-card-foreground overflow-hidden">
      {/* Top Section: Settings Tabs - Takes 60% of the available height */}
      <div className="h-[60%] border-b border-border flex flex-col overflow-hidden">
        <Tabs
          tabs={settingsTabs}
          tabListClassName="flex-shrink-0 bg-background border-b border-border" // Tab bar doesn't shrink
          tabContentClassName="flex-grow overflow-y-auto custom-scrollbar" // Tab content area scrolls
        />
      </div>

      {/* Bottom Section: Tools Tabs (including NGM iframe) - Takes 40% of the available height */}
      <div className="h-[40%] flex flex-col overflow-hidden">
        <Tabs
          tabs={toolTabs}
          tabListClassName="flex-shrink-0 bg-background border-b border-border" // Tab bar doesn't shrink
          tabContentClassName="flex-grow overflow-y-auto custom-scrollbar" // Tab content area scrolls
        />
      </div>
    </div>
  );
};

export default LowerControlPanel;
----
src/contexts/WindowSizeContext.tsx
import { createContext, useContext, ReactNode, FC } from 'react';
import { useWindowSize, WindowSize } from '../hooks/useWindowSize';

// Create context with a default value
const WindowSizeContext = createContext<WindowSize | undefined>(undefined);

// Props for the provider component
interface WindowSizeProviderProps {
  children: ReactNode;
}

/**
 * Provider component that wraps the app and provides window size information
 * to all child components that need it
 */
export const WindowSizeProvider: FC<WindowSizeProviderProps> = ({ children }) => {
  const windowSize = useWindowSize();
  
  return (
    <WindowSizeContext.Provider value={windowSize}>
      {children}
    </WindowSizeContext.Provider>
  );
};

/**
 * Hook to use the window size context
 * Throws an error if used outside of the WindowSizeProvider
 */
export function useWindowSizeContext(): WindowSize {
  const context = useContext(WindowSizeContext);
  
  if (context === undefined) {
    throw new Error('useWindowSizeContext must be used within a WindowSizeProvider');
  }
  
  return context;
}
----
src/contexts/ApplicationModeContext.tsx
import { jsx as _jsx } from "react/jsx-runtime";
import { createContext, useContext, useState, useEffect } from 'react';
import { createLogger } from '../utils/logger';
const logger = createLogger('ApplicationModeContext');
const defaultContext = {
    mode: 'desktop',
    previousMode: null,
    isXRMode: false,
    isMobileView: false,
    setMode: () => { },
    layoutSettings: {
        showPanels: true,
        showViewport: true,
        showControls: true
    }
};
// Create the context
const ApplicationModeContext = createContext(defaultContext);
/**
 * Provider component for application mode
 */
export const ApplicationModeProvider = ({ children }) => {
    const [mode, setMode] = useState('desktop');
    const [previousMode, setPreviousMode] = useState(null);
    const [isMobileView, setIsMobileView] = useState(false);
    // Check for mobile view on mount and resize
    useEffect(() => {
        const handleResize = () => {
            const isMobile = window.innerWidth < 768; // Breakpoint for mobile view
            setIsMobileView(isMobile);
            // Auto-switch to mobile mode based on screen size
            // but don't override XR mode
            if (isMobile && mode !== 'xr') {
                setMode('mobile');
            }
            else if (!isMobile && mode === 'mobile') {
                setMode('desktop');
            }
        };
        // Initial check
        handleResize();
        // Add event listener
        window.addEventListener('resize', handleResize);
        // Cleanup
        return () => {
            window.removeEventListener('resize', handleResize);
        };
    }, [mode]);
    // Handle mode change
    const handleModeChange = (newMode) => {
        logger.info(`Changing mode: ${mode} -> ${newMode}`);
        setPreviousMode(mode);
        setMode(newMode);
    };
    // Compute layout settings based on current mode
    const getLayoutSettings = () => {
        switch (mode) {
            case 'desktop':
                return {
                    showPanels: true,
                    showViewport: true,
                    showControls: true
                };
            case 'mobile':
                return {
                    showPanels: true,
                    showViewport: true,
                    showControls: true
                };
            case 'xr':
                return {
                    showPanels: false,
                    showViewport: true,
                    showControls: false
                };
            default:
                return {
                    showPanels: true,
                    showViewport: true,
                    showControls: true
                };
        }
    };
    const contextValue = {
        mode,
        previousMode,
        isXRMode: mode === 'xr',
        isMobileView,
        setMode: handleModeChange,
        layoutSettings: getLayoutSettings()
    };
    return (_jsx(ApplicationModeContext.Provider, { value: contextValue, children: children }));
};
/**
 * Hook to use the application mode context
 */
export const useApplicationMode = () => {
    const context = useContext(ApplicationModeContext);
    if (!context) {
        throw new Error('useApplicationMode must be used within an ApplicationModeProvider');
    }
    return context;
};

----
src/hooks/useWindowSize.ts
import { useState, useEffect } from 'react';

// Define the window size interface
export interface WindowSize {
  width: number;
  height: number;
  pixelRatio: number;
}

/**
 * Hook that tracks window dimensions and device pixel ratio.
 * This provides a centralized source of truth for window size used across the app.
 */
export function useWindowSize(): WindowSize {
  // Initialize with current window dimensions and pixel ratio
  const [windowSize, setWindowSize] = useState<WindowSize>({
    width: window.innerWidth,
    height: window.innerHeight,
    pixelRatio: window.devicePixelRatio || 1
  });

  useEffect(() => {
    // Handler to call on window resize
    function handleResize() {
      // Set window dimensions in state
      setWindowSize({
        width: window.innerWidth,
        height: window.innerHeight,
        pixelRatio: window.devicePixelRatio || 1
      });
    }
    
    // Add event listener
    window.addEventListener('resize', handleResize);
    
    // Call handler right away so state gets updated with initial window size
    handleResize();
    
    // Remove event listener on cleanup
    return () => window.removeEventListener('resize', handleResize);
  }, []); // Empty array ensures effect runs only on mount and unmount

  return windowSize;
}
----
src/hooks/useContainerSize.ts
import { useState, useLayoutEffect, RefObject } from 'react';

export function useContainerSize(ref: RefObject<HTMLElement>) {
  const [size, setSize] = useState({ width: 0, height: 0 });

  useLayoutEffect(() => {
    if (!ref.current) return;
    const updateSize = () => {
      const rect = ref.current.getBoundingClientRect();
      setSize({ width: rect.width, height: rect.height });
    };
    updateSize();
    const observer = new ResizeObserver(updateSize);
    observer.observe(ref.current);
    return () => observer.disconnect();
  }, [ref]);

  return size;
}
--END--

## Documentation

The following text represents a project with code. The structure of the text consists of sections beginning with ----, followed by a single line containing the file path and file name, and then a variable number of lines containing the file contents. The text representing the project ends when the symbols --END-- are encountered. Any further text beyond --END-- is meant to be interpreted as instructions using the aforementioned project as context.
----
contributing.md
# Contributing Guidelines

This document outlines the guidelines for contributing to the project. Following these guidelines helps ensure that your contributions are properly integrated into the codebase.

## How to Contribute

1. Fork the repository
2. Create a new branch
3. Make your changes
4. Submit a pull request
5. Wait for review and approval

## Code Standards

- Follow the existing code style
- Write clear commit messages
- Include tests for new features
- Update documentation for any changes
----
index.md
# Project Documentation

Welcome to the project documentation. This documentation provides comprehensive details about the client and server components of the system.

## Table of Contents

- [API Documentation](api/index.md)
- [Client Documentation](client/index.md)
- [Server Documentation](server/index.md)
- [Deployment](deployment/index.md)
- [Development](development/index.md)
- [Contributing](contributing.md)
----
technical/decoupled-graph-architecture.md
# Decoupled Graph Architecture

## Overview

The LogseqXR graph architecture has been modernized to decouple graph initialization and physics processing from client connections. This document outlines the new architecture and explains the key components and their interactions.

## Architecture Components

### Server-Side Components

- **GraphService**: Continuously maintains the force-directed graph independently of client connections
- **ClientManager**: Tracks all connected WebSocket clients and handles broadcasting updates
- **Force-Directed Physics**: Pre-computes node positioning with server-side physics processing
- **WebSocket Handler**: Manages bi-directional communication for synchronized graph state

### Client-Side Components

- **WebSocketService**: Handles WebSocket communication with the server
- **NodeManager**: Processes incoming node position updates and sends user interactions back to server
- **GraphRenderer**: Visualizes the graph with updated node positions

## Key Architectural Improvements

### 1. Independent Graph Initialization

The graph is now initialized once at server startup, regardless of client connections. Key benefits:

- Reduced resource utilization by avoiding redundant graph creation
- Consistent graph state across all clients
- Immediate graph availability for new client connections

```mermaid
sequenceDiagram
    participant Server
    participant GraphService
    participant Client
    
    Server->>GraphService: Initialize on startup
    GraphService->>GraphService: Pre-compute node positions
    GraphService->>GraphService: Continuously update physics
    
    Client->>Server: Connect via WebSocket
    Server->>Client: Send pre-computed graph state
    GraphService-->>Client: Stream position updates
```

### 2. Continuous Force-Directed Layout

The server now maintains a continuous physics simulation:

- Graph nodes find optimal positions before any client connects
- Reduced initial loading time for clients as layout is pre-calculated
- Physics simulation stabilizes over time, creating a more balanced visualisation

### 3. Bidirectional Synchronization

The new architecture supports true bidirectional updates:

- Server broadcasts position updates to all connected clients
- Any client can update node positions (e.g., during user interaction)
- All changes are synchronized across all clients in real-time
- Server maintains position authority for consistency

```mermaid
sequenceDiagram
    participant ClientA
    participant Server
    participant ClientB
    
    ClientA->>Server: Move node position
    Server->>Server: Apply to graph model
    Server->>ClientA: Confirm position update
    Server->>ClientB: Broadcast position update
```

### 4. Optimized Data Transfer

The system includes several optimizations:

- Selective updates: Only nodes that change significantly trigger updates
- Position deadbanding: Filters out minor position changes
- Automatic compression for larger messages
- Dynamic update rate based on graph activity level

## Implementation Details

### Server-Side Physics Processing

The server uses a hybrid approach to physics processing:

1. GPU-accelerated computing when available (CUDA/WebGPU)
2. CPU fallback for environments without GPU support
3. Physics parameters tuned for stability and performance

### Client Connection Lifecycle

When a client connects:
1. The server sends the complete, settled graph state (metadata, node positions, edge data)
2. The client renders the initial state
3. The server begins streaming position updates
4. The client can send position updates to the server
5. The server broadcasts these changes to all other clients

## Performance Benefits

- **Reduced CPU/GPU usage**: Physics calculations shared across all clients
- **Lower bandwidth usage**: Only changed positions are transmitted
- **Faster initialization**: Clients receive pre-computed positions
- **Better scalability**: Multiple clients supported with minimal additional resource usage

## Future Improvements

- Real-time collaborative editing of graph content
- Conflict resolution for simultaneous node edits
- Region-based updates for very large graphs
- Client-specific view customizations
----
server/config.md
# Configuration Architecture

## Overview
The configuration module manages application settings, environment variables, and feature flags.

## Settings Management

### Core Structure
```rust
pub struct Settings {
    pub server: ServerConfig,
    pub visualisation: VisualisationConfig,
    pub github: GitHubConfig,
    pub security: SecurityConfig,
}
```

### Environment Loading
```rust
impl Settings {
    pub fn from_env() -> Result<Self, ConfigError> {
        dotenv().ok();
        // Load configuration from environment
    }
}
```

## Feature Flags

### Configuration
```rust
pub struct FeatureFlags {
    pub gpu_enabled: bool,
    pub websocket_enabled: bool,
    pub metrics_enabled: bool,
}
```

### Dynamic Updates
```rust
impl FeatureFlags {
    pub fn update_from_env(&mut self)
    pub fn is_feature_enabled(&self, feature: &str) -> bool
}
```

## Environment Configuration

### Server Settings
```rust
pub struct ServerConfig {
    pub host: String,
    pub port: u16,
    pub workers: usize,
}
```

### API Configuration
```rust
pub struct APIConfig {
    pub base_url: String,
    pub timeout: Duration,
    pub retry_count: u32,
}
```

## Security Settings

### Authentication
```rust
pub struct AuthConfig {
    pub jwt_secret: String,
    pub token_expiry: Duration,
    pub refresh_enabled: bool,
}
```

### Rate Limiting
```rust
pub struct RateLimitConfig {
    pub requests_per_second: u32,
    pub burst_size: u32,
}
```

## Implementation Details

### Loading Hierarchy
1. Environment variables
2. Configuration files
3. Default values

### Validation Rules
```rust
impl Settings {
    pub fn validate(&self) -> Result<(), ValidationError>
}
```

### Hot Reload
```rust
pub async fn reload_config() -> Result<(), ConfigError>
----
server/models.md
# Models Architecture

## Overview
The models module defines the core data structures and their relationships within the application.

## Simulation Parameters

### Core Structure
```rust
pub struct SimulationParams {
    pub iterations: u32,
    pub spring_strength: f32,
    pub repulsion: f32,
    pub damping: f32,
    pub max_repulsion_distance: f32,
    pub viewport_bounds: f32,
    pub mass_scale: f32,
    pub boundary_damping: f32,
    pub enable_bounds: bool,
    pub time_step: f32,
    pub phase: SimulationPhase,
    pub mode: SimulationMode,
}
```

### Usage
- Physics simulation configuration
- Real-time parameter adjustment
- Boundary conditions

## UI Settings

### Configuration
```rust
pub struct UISettings {
    pub visualisation: VisualisationConfig,
    pub layout: LayoutConfig,
    pub theme: ThemeConfig,
}

pub struct VisualisationConfig {
    pub physics: PhysicsConfig,
    pub rendering: RenderingConfig,
}
```

### Features
- Theme customization
- Layout preferences
- Visualisation options

## User Settings

### Core Structure
```rust
pub struct UserSettings {
    pub preferences: HashMap<String, Value>,
    pub display: DisplaySettings,
    pub interaction: InteractionSettings,
}
```

### Persistence
- Local storage
- Profile sync
- Default values

## Protected Settings

### Security Configuration
```rust
pub struct ProtectedSettings {
    pub api_keys: HashMap<String, String>,
    pub security: SecurityConfig,
    pub rate_limits: RateLimitConfig,
}
```

### Features
- API key management
- Security policies
- Rate limiting

## Metadata Store

### Core Structure
```rust
pub struct MetadataStore {
    pub files: HashMap<String, FileMetadata>,
    pub relationships: Vec<Relationship>,
    pub statistics: Statistics,
}
```

### Operations
- CRUD operations
- Relationship management
- Statistics tracking

## Implementation Details

### Thread Safety
```rust
pub type SafeMetadataStore = Arc<RwLock<MetadataStore>>;
pub type SafeSettings = Arc<RwLock<Settings>>;
```

### Serialization
```rust
impl Serialize for MetadataStore {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
}
```

### Validation
```rust
impl SimulationParams {
    pub fn validate(&self) -> Result<(), ValidationError>
}
----
server/services.md
# Services Architecture

## Overview
The services layer provides core business logic, external integrations, and data processing capabilities.

## GitHub Service

### Client Configuration
```rust
pub struct GitHubConfig {
    pub api_token: String,
    pub repository: String,
    pub branch: String,
    pub owner: String,
}
```

### Content API
```rust
pub struct ContentAPI {
    client: Arc<GitHubClient>,
}

impl ContentAPI {
    pub async fn fetch_file_content(&self, url: &str) -> Result<String, GitHubError>
    pub async fn list_markdown_files(&self, path: &str) -> Result<Vec<GitHubFileMetadata>, GitHubError>
    pub async fn check_file_public(&self, url: &str) -> Result<bool, GitHubError>
}
```
- File content retrieval
- Markdown file listing
- Access control checks

### File Service
```rust
pub struct FileService {
    node_id_counter: AtomicU32,
}

impl FileService {
    pub async fn initialize_local_storage(settings: Arc<RwLock<Settings>>) -> Result<(), Box<dyn StdError>>
    pub async fn fetch_and_process_files(
        &self,
        content_api: Arc<ContentAPI>,
        settings: Arc<RwLock<Settings>>,
        metadata_store: &mut MetadataStore,
    ) -> Result<Vec<ProcessedFile>, Box<dyn StdError>>
}
```
- Local storage management
- File processing
- Metadata handling

### Graph Service
```rust
pub struct GraphService {
    settings: Arc<RwLock<Settings>>,
    graph_data: Arc<RwLock<GraphData>>,
    node_map: Arc<RwLock<HashMap<String, Node>>>,
    gpu_compute: Option<Arc<RwLock<GPUCompute>>>,
}

impl GraphService {
    pub async fn new(
        settings: Arc<RwLock<Settings>>,
        gpu_compute: Option<Arc<RwLock<GPUCompute>>>,
    ) -> Self

    pub async fn calculate_layout_with_retry(
        gpu_compute: &Arc<RwLock<GPUCompute>>,
        graph: &mut GraphData,
        node_map: &mut HashMap<String, Node>,
        params: &SimulationParams,
    ) -> std::io::Result<()>
}
```
- Graph management
- Physics simulation
- Layout calculation

## Error Handling

### Service Errors
```rust
pub enum ServiceError {
    GitHub(GitHubError),
    File(std::io::Error),
    Graph(String),
    Configuration(String),
}
```

### Retry Mechanisms
```rust
const MAX_RETRIES: u32 = 3;
const RETRY_DELAY: Duration = Duration::from_secs(1);
```
- Exponential backoff
- Error recovery
- Circuit breaking

## State Management

### Shared State
```rust
pub struct AppState {
    pub settings: Arc<RwLock<Settings>>,
    pub metadata: Arc<RwLock<MetadataStore>>,
    pub graph_service: GraphService,
    pub gpu_compute: Option<Arc<RwLock<GPUCompute>>>,
}
```
- Thread-safe access
- Service coordination
- Resource management

## Performance Optimization

### Caching
- In-memory caching
- File system caching
- Cache invalidation

### Batch Processing
```rust
const BATCH_SIZE: usize = 5;
for chunk in items.chunks(BATCH_SIZE) {
    // Process in batches
}
```

### Resource Management
- Connection pooling
- Memory optimization
- Resource cleanup
----
server/handlers.md
# Request Handlers Architecture

## Overview
The handler layer manages HTTP and WebSocket endpoints, providing API interfaces for client interactions.

## Core Handlers

### API Handler
```rust
pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/api")
            // Route configurations
    );
}
```
- REST API endpoints
- Request validation
- Response formatting

### WebSocket Handler
```rust
pub async fn socket_flow_handler(
    req: HttpRequest,
    stream: web::Payload,
    app_state: web::Data<AppState>,
) -> Result<HttpResponse, Error>
```
- Real-time communication
- Graph updates
- Client state management

### Health Handler
```rust
pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/health")
            .route("", web::get().to(health_check))
            .route("/ready", web::get().to(readiness_check))
    );
}
```
- System health monitoring
- Readiness checks
- Dependency status

### Pages Handler
```rust
pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/pages")
            // Static and dynamic page routes
    );
}
```
- Static content serving
- Dynamic page generation
- Asset management

## Middleware Integration

### CORS Configuration
```rust
let cors = Cors::default()
    .allow_any_origin()
    .allow_any_method()
    .allow_any_header()
    .max_age(3600)
    .supports_credentials();
```

### Compression
```rust
.wrap(middleware::Compress::default())
```

### Logging
```rust
.wrap(middleware::Logger::default())
```

## Error Handling

### Request Validation
- Input sanitization
- Parameter validation
- Type checking

### Response Formatting
- Error standardization
- Status codes
- Error messages

## Security

### Authentication
- Token validation
- Session management
- Access control

### Authorization
- Role-based access
- Permission checking
- Resource protection
----
server/architecture.md
# App State Architecture

## Overview
The app state module manages the application's shared state and provides thread-safe access to core services.

## Core Structure

### AppState
```rust
pub struct AppState {
    pub settings: Arc<RwLock<Settings>>,
    pub metadata: Arc<RwLock<MetadataStore>>,
    pub graph_service: GraphService,
    pub github_client: Arc<GitHubClient>,
    pub content_api: Arc<ContentAPI>,
    pub gpu_compute: Option<Arc<RwLock<GPUCompute>>>,
}
```

## Initialization

### Constructor
```rust
impl AppState {
    pub async fn new(
        settings: Arc<RwLock<Settings>>,
        github_client: Arc<GitHubClient>,
        content_api: Arc<ContentAPI>,
        gpu_compute: Option<Arc<RwLock<GPUCompute>>>,
        metadata: Option<MetadataStore>,
        graph_data: Option<GraphData>,
        conversation_id: String,
    ) -> Result<Self, Error>
}
```

### Service Setup
- GitHub client initialization
- Graph service setup
- GPU compute configuration

## State Management

### Thread Safety
```rust
pub type SafeState = Arc<AppState>;
pub type SafeMetadata = Arc<RwLock<MetadataStore>>;
```

### Access Patterns
```rust
impl AppState {
    pub async fn get_metadata(&self) -> RwLockReadGuard<MetadataStore>
    pub async fn update_metadata(&self, updates: MetadataUpdates)
}
```

## Service Integration

### Graph Service
```rust
impl AppState {
    pub async fn update_graph(&self, data: GraphData)
    pub async fn get_graph_data(&self) -> GraphData
}
```

### GitHub Integration
```rust
impl AppState {
    pub async fn fetch_content(&self, path: &str) -> Result<String>
    pub async fn update_content(&self, path: &str, content: &str)
}
```

## Error Handling

### State Errors
```rust
pub enum StateError {
    Initialization(String),
    ServiceUnavailable(String),
    InvalidState(String),
}
```

### Recovery
```rust
impl AppState {
    pub async fn recover_from_error(&self, error: StateError)
    pub async fn validate_state(&self) -> Result<(), StateError>
}
```

## Implementation Details

### Cleanup
```rust
impl Drop for AppState {
    fn drop(&mut self) {
        // Cleanup resources
    }
}
```

### State Validation
```rust
impl AppState {
    pub fn validate(&self) -> Result<(), ValidationError>
}
   - Zero-copy when possible

## Graph System

The graph system manages the core data structures and algorithms for the knowledge graph.

### Data Flow

```mermaid
flowchart TB
    subgraph Input
        MD[Markdown Files]
        Meta[Metadata]
        User[User Updates]
    end

    subgraph Processing
        Parser[Content Parser]
        GraphBuilder[Graph Builder]
        Layout[Layout Engine]
    end

    subgraph Storage
        DB[Graph Database]
        Cache[Memory Cache]
    end

    MD --> Parser
    Meta --> Parser
    Parser --> GraphBuilder
    User --> GraphBuilder
    GraphBuilder --> Layout
    Layout --> Cache
    Cache --> DB
```

### Optimization Strategies

1. Caching
   - In-memory graph structure
   - Computed layout positions
   - Frequently accessed metadata

2. Batch Processing
   - Grouped node updates
   - Batched layout calculations
   - Bulk metadata updates

3. Incremental Updates
   - Partial graph updates
   - Delta-based synchronization
   - Progressive loading

## Service Layer

The service layer provides high-level operations and business logic.

### Core Services

1. Graph Service
   - Graph construction
   - Layout calculations
   - Data validation

2. File Service
   - Content management
   - File system operations
   - Version control integration

3. WebSocket Service
   - Real-time updates
   - Binary protocol handling
   - Connection management

### Service Communication

```mermaid
sequenceDiagram
    participant Client
    participant WebSocket
    participant GraphService
    participant GPUCompute
    participant FileService

    Client->>WebSocket: Connect
    WebSocket->>GraphService: Request Initial Data
    GraphService->>GPUCompute: Calculate Layout
    GPUCompute-->>GraphService: Layout Complete
    GraphService-->>WebSocket: Send Graph Data
    WebSocket-->>Client: Binary Update

    loop Real-time Updates
        Client->>WebSocket: Position Update
        WebSocket->>GraphService: Process Update
        GraphService->>GPUCompute: Recalculate
        GPUCompute-->>GraphService: New Positions
        GraphService-->>WebSocket: Broadcast Update
        WebSocket-->>Client: Binary Update
    end
```

## Next Steps

For detailed information about specific components, refer to:
- [Configuration](config.md)
- [Request Handlers](handlers.md)
- [Data Models](models.md)
- [Services](services.md)
- [Type Definitions](types.md)
- [Utilities](utils.md)
----
server/types.md
# Types Architecture

## Overview
The types module defines core data structures, type aliases, and common enums used throughout the application.

## Core Types

### Graph Types
```rust
pub struct GraphData {
    pub nodes: Vec<Node>,
    pub edges: Vec<Edge>,
    pub metadata: HashMap<String, Metadata>,
}

pub struct Node {
    pub id: String,
    pub data: NodeData,
}

pub struct Edge {
    pub source: String,
    pub target: String,
    pub weight: f32,
}
```

### Simulation Types
```rust
pub enum SimulationPhase {
    Dynamic,
    Static,
    Paused,
}

pub enum SimulationMode {
    Local,
    Remote,
    Hybrid,
}
```

## Models

### Settings Models
```rust
pub struct UISettings {
    pub theme: String,
    pub layout: LayoutConfig,
    pub visualisation: VisualisationConfig,
}

pub struct UserSettings {
    pub preferences: HashMap<String, Value>,
    pub customizations: Vec<CustomSetting>,
}

pub struct ProtectedSettings {
    pub api_keys: HashMap<String, String>,
    pub security_config: SecurityConfig,
}
```

### Metadata Models
```rust
pub struct MetadataStore {
    pub files: HashMap<String, FileMetadata>,
    pub relationships: Vec<Relationship>,
}

pub struct FileMetadata {
    pub name: String,
    pub size: usize,
    pub node_id: String,
    pub last_modified: DateTime<Utc>,
}
```

## Error Types

### Service Errors
```rust
pub enum ServiceError {
    IO(std::io::Error),
    Graph(String),
    Config(String),
}

impl From<std::io::Error> for ServiceError {
    fn from(err: std::io::Error) -> Self {
        ServiceError::IO(err)
    }
}
```

### API Errors
```rust
pub enum APIError {
    NotFound(String),
    Unauthorized,
    RateLimit,
    Internal(String),
}
```

## Type Aliases

### Common Aliases
```rust
pub type Result<T> = std::result::Result<T, Error>;
pub type NodeMap = HashMap<String, Node>;
pub type MetadataMap = HashMap<String, Metadata>;
```

## Constants

### System Constants
```rust
pub const MAX_NODES: usize = 10000;
pub const DEFAULT_BATCH_SIZE: usize = 100;
pub const CACHE_DURATION: Duration = Duration::from_secs(3600);
```

### Configuration Constants
```rust
pub const DEFAULT_PORT: u16 = 8080;
pub const DEFAULT_HOST: &str = "127.0.0.1";
pub const API_VERSION: &str = "v1";
----
server/index.md
# Server Documentation

This section contains documentation for the server-side components of the system.

## Components

- [Architecture](architecture.md)
- [Configuration](config.md)
- [Request Handlers](handlers.md)
- [Data Models](models.md)
- [Services](services.md)
- [Type Definitions](types.md)
- [Utilities](utils.md)
----
server/utils.md
# Utilities Architecture

## Overview
The utilities layer provides common functionality, helper methods, and shared tools across the application.

## GPU Compute

### Initialization
```rust
pub struct GPUCompute {
    compute_device: Arc<RwLock<Option<ComputeDevice>>>,
    simulation_params: Arc<RwLock<SimulationParams>>,
}

impl GPUCompute {
    pub async fn new(graph_data: &GraphData) -> Result<Self, Error>
    pub async fn test_gpu_at_startup(gpu_compute: Option<Arc<RwLock<GPUCompute>>>)
}
```
- Device detection
- Resource allocation
- Capability testing

### Simulation Parameters
```rust
pub struct SimulationParams {
    pub iterations: u32,
    pub spring_strength: f32,
    pub repulsion: f32,
    pub damping: f32,
    pub time_step: f32,
    pub phase: SimulationPhase,
    pub mode: SimulationMode,
}
```

## Logging

### Configuration
```rust
pub struct LogConfig {
    pub console_level: String,
    pub file_level: String,
}

pub fn init_logging_with_config(config: LogConfig) -> Result<(), Error>
```
- Log levels
- Output formatting
- File rotation

### Usage Patterns
```rust
info!("Starting operation: {}", operation_name);
debug!("Processing data: {:?}", data);
error!("Operation failed: {}", error);
```

## WebSocket Messages

### Message Types
```rust
pub enum SocketMessage {
    GraphUpdate(GraphData),
    StateUpdate(StateData),
    Error(ErrorData),
}
```
- Binary messages
- Text messages
- Control frames

### Flow Control
```rust
pub async fn socket_flow_handler(
    req: HttpRequest,
    stream: web::Payload,
    app_state: web::Data<AppState>,
) -> Result<HttpResponse, Error>
```
- Message queuing
- Rate limiting
- Connection management

## Security

### Token Management
```rust
pub fn generate_token() -> String
pub fn validate_token(token: &str) -> Result<Claims, TokenError>
```
- Token generation
- Validation
- Expiration

### Encryption
```rust
pub fn encrypt_data(data: &[u8], key: &[u8]) -> Result<Vec<u8>, CryptoError>
pub fn decrypt_data(encrypted: &[u8], key: &[u8]) -> Result<Vec<u8>, CryptoError>
```
- Data encryption
- Key management
- Secure storage

## Helper Functions

### String Manipulation
```rust
pub fn sanitize_filename(name: &str) -> String
pub fn generate_slug(title: &str) -> String
```
- Text formatting
- Sanitization
- Normalization

### File Operations
```rust
pub async fn ensure_directory(path: &Path) -> Result<(), Error>
pub async fn atomic_write(path: &Path, content: &[u8]) -> Result<(), Error>
```
- Safe writes
- Directory management
- Path handling

## Error Handling

### Custom Errors
```rust
pub enum UtilError {
    IO(std::io::Error),
    Format(String),
    Validation(String),
}
```
- Error types
- Error conversion
- Error context

### Recovery Strategies
- Retry logic
- Fallback mechanisms
- Error reporting
----
development/setup.md
# Development Setup

This document provides instructions for setting up the development environment.
----
development/index.md
# Development Documentation

This section contains documentation for setting up and developing the system.

## Development Topics

- [Development Setup](setup.md)
- [Debugging](debugging.md)
----
development/debugging.md
# Debugging Guide

This document provides guidance for debugging the system.
----
deployment/docker.md
# Docker Deployment

This document describes how to deploy the system using Docker.
----
deployment/index.md
# Deployment Documentation

This section contains documentation for deploying the system.

## Deployment Options

- [Docker Deployment](docker.md)
----
api/websocket.md
# WebSocket API Reference

## Overview
The WebSocket implementation in LogseqXR provides real-time graph updates using an optimized binary protocol.

## Connection

Connect to: `wss://your-domain/wss`

### Connection Flow
1. Client connects to WebSocket endpoint (`/wss`)
2. Server sends: `{"type": "connection_established"}`
3. Client sends authentication (if required)
4. Client sends: `{"type": "requestInitialData"}`
5. Server begins binary updates (configured by `binary_update_rate`)
6. Server sends: `{"type": "updatesStarted"}`

## Authentication

Send authentication message immediately after connection:

```json
{
  "type": "auth",
  "token": "your_nostr_token"
}
```

## Message Types

### Control Messages

1. Connection Established
```json
{
  "type": "connection_established"
}
```

2. Request Initial Data
```json
{
  "type": "requestInitialData"
}
```

3. Updates Started
```json
{
  "type": "updatesStarted"
}
```

### Binary Protocol Format

Node position updates are sent as binary messages. Each binary message consists of node updates, where each node update is exactly 26 bytes:

| Field    | Type      | Size (bytes) | Description                       |
|----------|-----------|--------------|-----------------------------------|
| Node ID  | uint16    | 2            | Unique identifier for the node    |
| Position | float32[3]| 12           | X, Y, Z coordinates               |
| Velocity | float32[3]| 12           | X, Y, Z velocity components       |

### Settings Synchronization

```json
{
  "type": "settings_update",
  "category": "visualisation",
  "settings": {
    "edges": {
      "scaleFactor": 2.0
    }
  }
}
```

## Optimization Features

- Zlib compression for messages >1KB
- Fixed-size format for efficient parsing
- No message headers to minimize overhead
- Consistent use of THREE.Vector3 throughout

## Error Handling

### Error Message Format

1. Connection Error
```json
{
  "type": "error",
  "code": "connection_error",
  "message": "Connection failed"
}
```

2. Authentication Error
```json
{
  "type": "error",
  "code": "auth_error",
  "message": "Invalid token"
}
```

### Error Handling Features
- Connection failures trigger automatic reconnection
- Invalid messages are logged and skipped
- Server-side validation prevents corrupt data transmission

## Rate Limiting

- 60 messages per minute per connection
- Binary updates don't count towards rate limit

## Diagnostics

### Common Issues

1. Connection Issues
   - Mixed Content: Ensure WebSocket uses WSS with HTTPS
   - CORS: Check server configuration for cross-origin
   - Proxy/Firewall: Verify WebSocket ports are open

2. Binary Protocol Issues
   - Message Size: Verify 26 bytes per node
   - Data Integrity: Validate Vector3 data

### Diagnostic Tools

```typescript
// Run comprehensive diagnostics
WebSocketDiagnostics.runDiagnostics();

// Test API connectivity
WebSocketDiagnostics.testApiConnectivity();

// Validate vector data
WebSocketDiagnostics.validateVectorData();
----
api/websocket-updated.md
# WebSocket API Reference (Updated)

## Connection

Connect to: `wss://your-domain/wss`

## Authentication

Send authentication message immediately after connection:

```json
{
  "type": "auth",
  "token": "your_nostr_token"
}
```

## Message Types

### Control Messages

#### 1. Connection Established
```json
{
  "type": "connection_established",
  "timestamp": 1679417762000
}
```

#### 2. Request Initial Data
```json
{
  "type": "requestInitialData"
}
```

#### 3. Updates Started
```json
{
  "type": "updatesStarted",
  "timestamp": 1679417763000
}
```

#### 4. Loading State
```json
{
  "type": "loading",
  "message": "Calculating initial layout..."
}
```

### Binary Messages - Position Updates

Position updates are transmitted as binary messages in both directions:

- Each node update is 26 bytes
- Format: [Node ID (2 bytes)][Position (12 bytes)][Velocity (12 bytes)]
- Position and Velocity are three consecutive float32 values (x,y,z)
- Messages are compressed with zlib if size > 1KB

#### Server → Client Updates

The server continuously sends position updates to all connected clients:

1. Updates are pre-computed by the server's continuous physics engine
2. Only nodes that changed significantly are included
3. Update frequency varies based on graph activity (5-60 updates/sec)
4. Each update can contain multiple node positions in a single binary message
5. When the physics simulation stabilizes, update frequency is reduced

#### Client → Server Updates

Clients can send position updates back to the server:

1. Position updates use the same binary format as server messages
2. Updates are processed by the server's physics system
3. Changes are validated and broadcast to all other connected clients
4. Modifications that violate physics constraints may be adjusted by the server

### Position Synchronization Protocol

The bidirectional synchronization protocol ensures consistent graph state:

1. Server maintains the authoritative graph state
2. Any client can send position updates during user interaction
3. Server processes updates and applies physics constraints
4. All clients receive the same set of position updates
5. Late-joining clients receive the complete current graph state

### Settings Synchronization

```json
{
  "type": "settings_update",
  "category": "visualisation",
  "settings": {
    "edges": {
      "scaleFactor": 2.0
    }
  }
}
```

## Error Handling

#### 1. Connection Error
```json
{
  "type": "error",
  "code": "connection_error",
  "message": "Connection failed"
}
```

#### 2. Authentication Error
```json
{
  "type": "error",
  "code": "auth_error",
  "message": "Invalid token"
}
```

#### 3. Position Update Error
```json
{
  "type": "error",
  "code": "position_update_error",
  "message": "Invalid node position data"
}
```

## Rate Limiting

- 60 JSON messages per minute per connection
- Binary position updates don't count towards the rate limit
- Server-side throttling applies for high-frequency position updates
----
api/index.md
# API Documentation

This section contains documentation for the API endpoints used by the system.

## API Types

- [REST API](rest.md)
- [WebSocket API](websocket.md)
----
api/rest.md
# REST API Reference

## Overview
The REST API provides endpoints for graph data management, content operations, and system status.

## Base URL
```
https://api.webxr.dev/v1
```

## Authentication

All API requests require authentication. There are two methods:

### JWT Token
Include the token in the Authorization header:
```
Authorization: Bearer <token>
```

### Nostr Authentication

#### Login
```http
POST /api/auth/nostr
```

**Request Body:**
```json
{
  "pubkey": "your_public_key",
  "signature": "signed_challenge"
}
```

**Response:**
```json
{
  "user": {
    "pubkey": "user_public_key",
    "npub": "user_npub",
    "is_power_user": boolean,
    "last_seen": 1234567890
  },
  "token": "session_token",
  "expires_at": 1234567890,
  "features": ["feature1", "feature2"]
}
```

#### Verify Token
```http
POST /api/auth/nostr/verify
```

**Request Body:**
```json
{
  "pubkey": "your_public_key",
  "token": "your_token"
}
```

#### Logout
```http
DELETE /api/auth/nostr
```

## Graph API

### Get Graph Data
```http
GET /api/graph/data
```

Returns complete graph structure:
```json
{
  "nodes": [...],
  "edges": [...],
  "metadata": {...}
}
```

### Get Specific Node
```http
GET /graph/nodes/{nodeId}
```

**Response:**
```json
{
  "id": "string",
  "metadata": {...},
  "connections": [...]
}
```

### Get Paginated Graph Data
```http
GET /api/graph/data/paginated
```

**Query Parameters:**
- `page`: Page number (default: 1)
- `page_size`: Items per page (default: 100)
- `sort`: Sort field
- `filter`: Filter expression

### Update Graph
```http
POST /api/graph/update
```

**Request Body:**
```json
{
  "nodes": [
    {
      "id": "string",
      "position": {"x": 0, "y": 0, "z": 0},
      "mass": 1.0
    }
  ],
  "edges": [...]
}
```

### Refresh Graph
```http
POST /api/graph/refresh
```

## Files API

### Process Files
```http
POST /api/files/process
```

Triggers fetching and processing of Markdown files.

**Response:**
```json
{
  "status": "success",
  "processed_files": ["file1.md", "file2.md"]
}
```

### Get File Content
```http
GET /api/files/get_content/{filename}
```

### Upload Content
```http
POST /content/upload
```

**Request Body:**
```json
{
  "path": "string",
  "content": "string",
  "metadata": {...}
}
```

## Settings API

### Get Visualisation Settings
```http
GET /api/user-settings/visualisation
```

### Update API Keys
```http
POST /api/auth/nostr/api-keys
```

**Request Body:**
```json
{
  "perplexity": "api_key",
  "openai": "api_key",
  "ragflow": "api_key"
}
```

## AI Services

### Perplexity Query
```http
POST /api/perplexity
```

**Request Body:**
```json
{
  "query": "Your question here",
  "conversation_id": "optional-previous-conversation-id"
}
```

**Response:**
```json
{
  "answer": "The response from Perplexity AI",
  "conversation_id": "conversation-id-for-follow-up-queries"
}
```

## System Status

### Health Check
```http
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "services": {
    "gpu": "active",
    "github": "connected"
  }
}
```

## Error Responses

All endpoints may return the following error responses:

### Standard Error Format
```json
{
  "error": {
    "code": "string",
    "message": "string",
    "details": {...}
  }
}
```

### Common Error Codes
- `400`: Bad Request - Invalid parameters or request
- `401`: Unauthorized - Invalid or missing authentication token
- `403`: Forbidden - Valid token but insufficient permissions
- `404`: Not Found - Resource not found
- `429`: Too Many Requests - Rate limit exceeded
- `500`: Internal Server Error - Server-side error

## Related Documentation
- [WebSocket API](./websocket.md)
- [Development Setup](../development/setup.md)
----
client/core.md
# Client Core

This document describes the core utilities and functionality in the client.
----
client/websocket.md
# WebSocket Communication

This document describes the WebSocket communication system used in the client.

## Overview

The client uses WebSocket connections for real-time communication with the server, particularly for:
- Binary position updates for graph nodes
- Graph data synchronization
- Event notifications
- Connection status management

## Architecture

```mermaid
flowchart TB
    subgraph Client
        WebSocketService[WebSocket Service]
        GraphDataManager[Graph Data Manager]
        VisualisationManager[Visualisation Manager]
        BinaryProtocol[Binary Protocol Handler]
    end
    
    subgraph Server
        WSServer[WebSocket Server]
        Physics[Physics Engine]
        DataSync[Data Sync]
    end
    
    WebSocketService <--> WSServer
    WebSocketService --> BinaryProtocol
    BinaryProtocol --> GraphDataManager
    GraphDataManager --> VisualisationManager
    Physics --> WSServer
    DataSync --> WSServer
```

## WebSocket Service

The WebSocket service (`client/websocket/websocketService.ts`) is implemented as a singleton that manages:
- Connection establishment and maintenance
- Message handling
- Binary protocol processing
- Error handling and recovery

### Key Features

- Automatic reconnection with exponential backoff
- Binary message support
- Connection status monitoring
- Event-based message handling

## Binary Protocol

The binary protocol is used for efficient transmission of node position updates.

### Message Format

Position updates use a binary format where each node's data is packed as follows:

```
| Field    | Type        | Size (bytes) | Description           |
|----------|-------------|--------------|------------------------|
| Node ID  | uint16      | 2           | Unique node identifier |
| Position | float32[3]  | 12          | X, Y, Z coordinates    |
| Velocity | float32[3]  | 12          | VX, VY, VZ components |
```

Total bytes per node: 26 bytes

### Processing Flow

```mermaid
sequenceDiagram
    participant Server
    participant WebSocket
    participant BinaryHandler
    participant GraphManager
    participant Visualisation
    
    Server->>WebSocket: Binary Message
    WebSocket->>BinaryHandler: Process ArrayBuffer
    BinaryHandler->>GraphManager: Update Node Positions
    GraphManager->>Visualisation: Trigger Update
```

## Message Types

The WebSocket service handles several types of messages:

1. **Binary Position Updates**
   - Format: ArrayBuffer
   - Handler: `onBinaryMessage`
   - Used for real-time node position updates

2. **Connection Status**
   - Format: JSON
   - Handler: `onConnectionStatusChange`
   - Used for connection state management

3. **Graph Updates**
   - Format: JSON
   - Handler: `onGraphUpdate`
   - Used for graph structure changes

## Error Handling

The WebSocket service implements robust error handling:

```typescript
enum WebSocketErrorType {
    CONNECTION_ERROR = 'CONNECTION_ERROR',
    CONNECTION_LOST = 'CONNECTION_LOST',
    TIMEOUT = 'TIMEOUT',
    BINARY_FORMAT_ERROR = 'BINARY_FORMAT_ERROR',
}
```

### Recovery Strategy

```mermaid
stateDiagram-v2
    [*] --> Connected
    Connected --> Disconnected: Connection Lost
    Disconnected --> Retrying: Auto Reconnect
    Retrying --> Connected: Success
    Retrying --> Failed: Max Retries
    Failed --> [*]: Fatal Error
    Retrying --> Disconnected: Retry Failed
```

## Configuration

WebSocket behavior can be configured through settings:

```typescript
interface WebSocketSettings {
    reconnectAttempts: number;    // Maximum reconnection attempts
    reconnectDelay: number;       // Base delay between retries (ms)
    binaryChunkSize: number;      // Size of binary message chunks
    compressionEnabled: boolean;  // Enable/disable compression
    compressionThreshold: number; // Minimum size for compression
    updateRate: number;          // Update rate in Hz
}
```

## Performance Considerations

1. **Binary Protocol**
   - Reduces message size by ~60% compared to JSON
   - Minimizes parsing overhead
   - Enables efficient batch updates

2. **Message Batching**
   - Position updates are batched for efficiency
   - Configurable batch size and update rate
   - Automatic throttling under high load

3. **Connection Management**
   - Heartbeat mechanism for connection health
   - Automatic reconnection with backoff
   - Connection status monitoring

## Usage Example

```typescript
// Initialize WebSocket service
const ws = WebSocketService.getInstance();

// Subscribe to binary updates
ws.onBinaryMessage((data) => {
    if (data instanceof ArrayBuffer) {
        graphDataManager.updateNodePositions(new Float32Array(data));
    }
});

// Handle connection status
ws.onConnectionStatusChange((connected) => {
    if (connected) {
        graphDataManager.setBinaryUpdatesEnabled(true);
    }
});

// Connect to server
await ws.connect();
```

## Related Documentation

- [State Management](state.md) - State management integration
- [Graph Data](graph.md) - Graph data structure and updates
- [Performance](performance.md) - Performance optimization details
----
client/websocket-readiness.md
# WebSocket Readiness Protocol

This document describes the improvements made to the WebSocket communication system to ensure proper connection establishment and binary data flow.

## Problem Statement

The original implementation encountered issues where:

1. Binary updates were enabled before the WebSocket connection was fully established
2. The GraphDataManager attempted to send data before the WebSocket service was ready
3. The WebSocket service didn't track its readiness state properly
4. Connection retry mechanisms didn't account for full readiness

## Improved Implementation

### WebSocket Readiness States

The WebSocket connection now has three distinct states:

1. **Disconnected**: No connection established
2. **Connected**: Socket connection is open but not fully established with server
3. **Ready**: Connection is open AND server has sent "connection_established" message

```mermaid
stateDiagram-v2
    [*] --> Disconnected
    Disconnected --> Connecting: connect()
    Connecting --> Connected: onopen
    Connected --> Ready: connection_established
    Ready --> Connected: server reset
    Connected --> Disconnected: onclose
    Ready --> Disconnected: onclose
```

### WebSocketService Readiness Tracking

The WebSocketService now includes:

- `isReadyFlag`: Boolean tracking if "connection_established" message has been received
- `isReady()`: Method that checks both connection state and readiness flag
- Readiness reset on reconnection or close events

```typescript
public isReady(): boolean {
    return this.connectionState === ConnectionState.CONNECTED && this.isReadyFlag;
}
```

### GraphDataManager Enhancements

The GraphDataManager now:

1. Checks for WebSocket readiness before enabling binary updates
2. Uses an enhanced retry mechanism that verifies both connection and readiness
3. Includes an improved interface for WebSocketService integration

```typescript
// Check if WebSocket service is configured AND ready before sending update
const isDefaultService = this.wsService.send.toString().includes('WebSocket service not configured');
const isReady = typeof this.wsService.isReady === 'function' && this.wsService.isReady();

if (!isDefaultService && isReady) {
    // Service is configured and ready, send initial update
    this.updatePositions(new Float32Array());
    debugState.setBinaryProtocolStatus('active');
}
```

### Adapter Pattern for Service Integration

An adapter pattern is used to connect GraphVisualisation with GraphDataManager's WebSocket requirements:

```typescript
// Configure GraphDataManager with WebSocket service (adapter pattern)
if (this.websocketService) {
    const wsAdapter = {
        send: (data: ArrayBuffer) => {
            this.websocketService?.sendRawBinaryData(data);
        },
        isReady: () => this.websocketService?.isReady() || false
    };
    graphDataManager.setWebSocketService(wsAdapter);
}
```

## Benefits of Improved Implementation

1. **Reliability**: Binary updates are only enabled when the WebSocket connection is truly ready
2. **Error Prevention**: Avoids attempting to send data before the connection is established
3. **Diagnostic**: Better logging identifies exact state of connection
4. **Recovery**: Enhanced retry mechanisms handle reconnection scenarios better

## Connection Sequence

```mermaid
sequenceDiagram
    participant Client
    participant WSService as WebSocketService
    participant GraphMgr as GraphDataManager
    participant Server
    
    Client->>WSService: connect()
    WSService->>Server: WebSocket connection
    Server-->>WSService: onopen
    WSService->>Client: onConnectionStatusChange(true)
    Server-->>WSService: connection_established
    WSService->>WSService: isReadyFlag = true
    WSService->>Client: notifyReadiness()
    Client->>GraphMgr: enableBinaryUpdates()
    GraphMgr->>WSService: isReady() check
    WSService-->>GraphMgr: true
    GraphMgr->>WSService: send binary data
    WSService->>Server: binary data
    Server-->>WSService: binary position updates
    WSService->>GraphMgr: updateNodePositions()
----
client/xr.md
# WebXR Integration

This document describes the WebXR integration and functionality in the client.
----
client/visualization.md
# Visualisation

This document describes the visualisation components and systems used in the client.
----
client/rendering.md
# Rendering

This document describes the rendering system used in the client.
----
client/state.md
# State Management

This document details the state management patterns and mechanisms used throughout the client application. The application uses several complementary approaches to state management to handle different types of state.

## State Management Overview

The client application manages several types of state:

1. **Application Settings** - User preferences and application configuration
2. **Graph Data** - Nodes, edges, and metadata for the visualisation
3. **UI State** - Control panel state, selected items, and UI configuration
4. **Rendering State** - Camera position, visibility settings, and rendering options
5. **XR State** - XR session status, controller positions, and interaction state

```mermaid
flowchart TB
    subgraph ApplicationState
        Settings[Settings Store]
        GraphData[Graph Data]
        UIState[UI State]
        RenderState[Rendering State]
        XRState[XR State]
    end
    
    subgraph StateConsumers
        RenderManager
        NodeManager
        EdgeManager
        ControlPanel
        XRManager
    end
    
    Settings --> RenderManager
    Settings --> NodeManager
    Settings --> EdgeManager
    Settings --> ControlPanel
    
    GraphData --> NodeManager
    GraphData --> EdgeManager
    
    UIState --> ControlPanel
    RenderState --> RenderManager
    XRState --> XRManager
```

## Key State Management Components

### Settings Store (`client/state/SettingsStore.ts`)

The Settings Store manages application settings with validation, persistence, and observation.

**Key Features:**
- Schema-based validation of settings
- Persistence to local storage and server
- Observable changes through subscribers
- Default values for all settings

**Implementation Pattern:**
```typescript
class SettingsStore {
  private settings: Settings;
  private observers: Set<Observer>;
  
  updateSetting(path: string, value: any): boolean {
    // Validate against schema
    // Update if valid
    // Notify observers
    // Persist to storage
  }
  
  subscribe(observer: Observer): () => void {
    // Add observer to set
    // Return unsubscribe function
  }
}
```

### Graph Data Manager (`client/state/graphData.ts`)

The Graph Data Manager maintains the state of the graph visualisation data.

**Key Features:**
- Loads and processes graph data from server
- Manages node and edge collections
- Handles real-time position updates via binary protocol
- Provides subscription mechanism for changes

**State Transitions:**
```mermaid
stateDiagram-v2
    [*] --> Empty
    Empty --> Loading: fetchInitialData()
    Loading --> PartiallyLoaded: First page loaded
    PartiallyLoaded --> FullyLoaded: All pages loaded
    FullyLoaded --> LiveUpdates: WebSocket connected
    LiveUpdates --> FullyLoaded: WebSocket disconnected
    LiveUpdates --> LiveUpdates: Position update
    FullyLoaded --> Empty: clear()
    LiveUpdates --> Empty: clear()
```

### Settings Observer (`client/state/SettingsObserver.ts`)

The Settings Observer implements the Observer pattern to propagate settings changes.

**Key Features:**
- Subscribes to Settings Store
- Filters and transforms settings updates
- Distributes settings to appropriate components

**Observer Pattern Implementation:**
```mermaid
sequenceDiagram
    participant SettingsStore
    participant SettingsObserver
    participant Component
    
    Component->>SettingsObserver: subscribe(path, callback)
    SettingsObserver->>SettingsStore: subscribe()
    
    Note over SettingsStore: Setting changes
    
    SettingsStore->>SettingsObserver: notifyUpdate(path, value)
    SettingsObserver->>SettingsObserver: filterRelevantUpdates()
    SettingsObserver->>Component: callback(value)
```

## State Persistence

The application persists state in several ways:

1. **Local Storage** - User preferences and UI state
2. **Server Storage** - User settings synchronized to server
3. **URL Parameters** - Shareable state in URL

### Persistence Flow

```mermaid
flowchart TD
    StateChange[State Change] --> ValidState{Is Valid?}
    ValidState -->|Yes| LocalStorage[Store in Local Storage]
    ValidState -->|Yes| SyncToServer{Sync to Server?}
    ValidState -->|No| LogError[Log Error]
    
    SyncToServer -->|Yes| APICall[POST to API]
    SyncToServer -->|No| Complete[Complete]
    
    APICall --> ServerResponse{Success?}
    ServerResponse -->|Yes| Complete
    ServerResponse -->|No| RetryStrategy[Apply Retry Strategy]
    
    RetryStrategy --> APICall
```

## State Change Propagation

The application uses several mechanisms to propagate state changes:

### Event Emitter (`client/utils/eventEmitter.ts`)

A publish-subscribe system for loose coupling between components.

**Key Features:**
- Named events with typed payloads
- Multiple subscribers per event
- Ability to unsubscribe
- Debugging and tracing capabilities

**Usage Pattern:**
```typescript
// Publisher
eventEmitter.emit('settings:changed', { path: 'visualisation.rendering.quality', value: 'high' });

// Subscriber
const unsubscribe = eventEmitter.on('settings:changed', (data) => {
  // Handle event
});

// Later
unsubscribe();
```

### Direct Subscriptions

Components can subscribe directly to state stores.

**Example:**
```typescript
// Subscribe to graph data changes
const unsubscribe = graphDataManager.subscribe((data) => {
  // Update component based on new data
});

// Subscribe to settings changes
const unsubscribe = settingsStore.subscribe((settings) => {
  // Update component based on new settings
});
```

## Settings Structure

The settings are organized hierarchically by domain:

```typescript
interface Settings {
  visualisation: {
    nodes: {
      quality: 'low' | 'medium' | 'high';
      enableInstancing: boolean;
      enableHologram: boolean;
      enableMetadataShape: boolean;
      sizeRange: [number, number];
      baseColor: string;
      opacity: number;
      // ...
    };
    edges: {
      color: string;
      opacity: number;
      arrowSize: number;
      baseWidth: number;
      enableArrows: boolean;
      widthRange: [number, number];
      quality: 'low' | 'medium' | 'high';
      // ...
    };
    physics: {
      enabled: boolean;
      attractionStrength: number;
      repulsionStrength: number;
      springStrength: number;
      damping: number;
      // ...
    };
    rendering: {
      ambientLightIntensity: number;
      directionalLightIntensity: number;
      environmentIntensity: number;
      backgroundColor: string;
      enableAmbientOcclusion: boolean;
      enableAntialiasing: boolean;
      enableShadows: boolean;
      // ...
    };
    animations: {
      enableNodeAnimations: boolean;
      enableMotionBlur: boolean;
      motionBlurStrength: number;
      // ...
    };
    labels: {
      enableLabels: boolean;
      desktopFontSize: number;
      textColor: string;
      textOutlineColor: string;
      // ...
    };
    bloom: {
      enabled: boolean;
      strength: number;
      radius: number;
      threshold: number;
      // ...
    };
    hologram: {
      ringCount: number;
      sphereSizes: number[];
      ringRotationSpeed: number;
      globalRotationSpeed: number;
      // ...
    };
  };
  system: {
    websocket: {
      reconnectAttempts: number;
      reconnectDelay: number;
      binaryChunkSize: number;
      compressionEnabled: boolean;
      // ...
    };
    debug: {
      enabled: boolean;
      enableDataDebug: boolean;
      enableWebsocketDebug: boolean;
      logBinaryHeaders: boolean;
      // ...
    };
  };
  xr: {
    mode: 'immersive-ar';
    roomScale: number;
    spaceType: 'local-floor';
    quality: 'low' | 'medium' | 'high';
    enableHandTracking: boolean;
    handMeshEnabled: boolean;
    handMeshColor: string;
    handMeshOpacity: number;
    // ...
  };
}
```

### Settings Validation

Settings are validated against schemas that define:
- Type constraints
- Range constraints
- Required properties
- Default values

Invalid settings are rejected with error messages.

## State Immutability

The application uses immutability patterns to prevent unexpected state changes:

1. Creating new objects or arrays when updating state
2. Using spread operators for shallow copies
3. Using deep copy functions for nested structures
4. Using getters without setters for read-only access

**Example of Immutable Update:**
```typescript
// Instead of modifying state directly
this.state.user.name = "New Name"; // BAD

// Create a new state object
this.state = {
  ...this.state,
  user: {
    ...this.state.user,
    name: "New Name"
  }
}; // GOOD
```

## Related Documentation

- [Components](components.md) - Component relationships and dependencies
- [Architecture](architecture.md) - Overall system architecture
- [WebSocket Communication](websocket.md) - Real-time state updates
----
client/architecture.md
# Client Architecture Overview

This document provides a high-level overview of the LogseqSpringThing client architecture, its major components, and their interactions.

## System Architecture

The client is built as a modern TypeScript application that follows a component-based architecture. It integrates with Three.js for 3D rendering, WebXR for VR/AR capabilities, and communicates with the Rust backend server through REST APIs and WebSocket connections.

```mermaid
graph TB
    subgraph Client Architecture
        UI[User Interface Layer]
        State[State Management]
        API[API Layer]
        Rendering[Rendering Engine]
        WebSocket[WebSocket Client]
        XR[XR Module]
        
        UI --> State
        State --> Rendering
        State --> API
        API --> WebSocket
        XR --> Rendering
        XR --> State
        WebSocket --> State
    end
    
    subgraph Server Interface
        REST[REST API]
        WS[WebSocket Server]
        Auth[Authentication]
        
        API --> REST
        WebSocket --> WS
        API --> Auth
        WebSocket --> Auth
    end
```

## Key Components

### User Interface Layer
The UI layer consists of modular components for controlling the application, configuring settings, and interacting with the 3D visualisation. It includes the Modular Control Panel, settings interfaces, and visualisation controls.

### State Management
State management is handled through a combination of state stores, event emitters, and observers. The primary state components include:
- `SettingsStore` - Manages application settings with validation
- `GraphData` - Manages the graph data structure
- Various observers for state changes

### API Layer
The API layer handles communication with the server through REST endpoints, providing abstracted access to server functionality:
- Authentication and authorization
- Graph data retrieval and updates
- File and settings management

### Rendering Engine
The rendering engine is built on Three.js and provides high-performance visualisation of graph data:
- Node and edge rendering with instancing for performance
- Text rendering with SDF fonts
- Metadata visualisation
- Camera controls and scene management

### WebSocket Client
The WebSocket client provides real-time communication with the server for:
- Live position updates using binary protocol
- Graph data synchronization
- Event notifications

### XR Module
The XR module integrates WebXR capabilities for VR/AR experiences:
- Hand tracking and interaction
- XR session management
- Spatial UI elements
- XR-specific rendering optimizations

## High-Level Data Flow

```mermaid
flowchart TB
    subgraph Input
        UserInput[User Input]
        ServerData[Server Data]
        XRInput[XR Input]
    end
    
    subgraph Processing
        State[State Management]
        GraphCalculation[Graph Calculation]
        PhysicsUpdate[Physics Update]
    end
    
    subgraph Output
        Rendering[Rendering]
        ServerUpdate[Server Update]
        UIUpdate[UI Update]
    end
    
    UserInput --> State
    ServerData --> State
    XRInput --> State
    
    State --> GraphCalculation
    State --> PhysicsUpdate
    
    GraphCalculation --> Rendering
    PhysicsUpdate --> Rendering
    State --> UIUpdate
    State --> ServerUpdate
```

## Core Technology Stack

- **TypeScript** - Primary development language
- **Three.js** - 3D rendering engine
- **WebGL** - Hardware-accelerated graphics
- **WebXR** - VR/AR integration
- **WebSockets** - Real-time communication
- **Custom Shaders** - GLSL shaders for specialized rendering effects

## Key Architectural Patterns

1. **Singleton Pattern** - Used for manager classes to ensure single instance
2. **Observer Pattern** - Used for state change notifications
3. **Facade Pattern** - Used to simplify complex subsystems (e.g., NodeManagerFacade)
4. **Factory Pattern** - Used for creating complex objects
5. **Composition** - Used to build complex behaviors from simpler components

## Cross-Cutting Concerns

- **Logging** - Centralized logging system with multiple levels
- **Error Handling** - Comprehensive error capture and recovery
- **Performance Monitoring** - Resource and performance monitoring
- **Caching** - Strategic caching of data and assets

## Application Lifecycle

```mermaid
stateDiagram-v2
    [*] --> Initialization
    Initialization --> Loading: Configure
    Loading --> Running: Assets Loaded
    Running --> XR: Enter XR Mode
    XR --> Running: Exit XR Mode
    Running --> [*]: Shutdown
    
    Running --> Error: Exception
    Error --> Running: Recover
    Error --> Shutdown: Fatal Error
    Shutdown --> [*]
```

## Communication with Server

The client communicates with the server through two primary channels:

1. **REST API** - For configuration, authentication, and data operations
2. **WebSocket** - For real-time updates and streaming data

This dual-channel approach allows for efficient communication patterns based on the nature of the data being exchanged.

## Related Documentation

- [Components](components.md) - Detailed component relationships
- [State Management](state.md) - State management approach
- [WebSocket Communication](websocket.md) - WebSocket protocol details
- [XR Integration](xr.md) - WebXR implementation details
----
client/types.md
# Type Definitions

This document describes the TypeScript type definitions used throughout the client.
----
client/index.md
# Client Documentation

This section contains documentation for the client-side components of the system.

## Components

- [Architecture](architecture.md)
- [Components](components.md)
- [Core](core.md)
- [Rendering](rendering.md)
- [State Management](state.md)
- [Types](types.md)
- [Visualisation](visualisation.md)
- [WebSocket Communication](websocket.md)
- [WebXR Integration](xr.md)
----
client/components.md
# Client Components

This document details the client component architecture, describing the relationships between major components, their responsibilities, and dependencies.

## Component Overview

The client is organized into a modular component architecture with clear separation of concerns. Each component has well-defined responsibilities and interfaces.

```mermaid
flowchart TB
    subgraph Core
        API[API Client]
        State[State Store]
        Events[Event Emitter]
        Logger[Logger]
        Constants[Constants]
        Types[Types]
        Utils[Utilities]
    end
    
    subgraph Rendering
        RenderManager[Render Manager]
        Scene[Scene]
        NodeManager[Node Manager]
        EdgeManager[Edge Manager]
        TextRenderer[Text Renderer]
        MetadataViz[Metadata Visualizer]
        Materials[Materials]
        Factories[Factories]
    end
    
    subgraph UI
        ControlPanel[Control Panel]
        Settings[Settings UI]
        Styles[Styles]
    end
    
    subgraph XR
        XRInit[XR Initializer]
        Hands[Hand Interaction]
        XRSession[XR Session Manager]
    end
    
    subgraph Network
        WSService[WebSocket Service]
        GraphDataManager[Graph Data Manager]
    end
    
    API <--> State
    State --> Events
    Events --> RenderManager
    Events --> NodeManager
    Events --> EdgeManager
    Events --> ControlPanel
    
    WSService --> GraphDataManager
    GraphDataManager --> State
    
    NodeManager --> MetadataViz
    NodeManager --> TextRenderer
    
    RenderManager --> Scene
    RenderManager --> NodeManager
    RenderManager --> EdgeManager
    
    XRInit --> XRSession
    XRSession --> Hands
    Hands --> NodeManager
    
    Settings --> State
    
    Logger -.-> API
    Logger -.-> WSService
    Logger -.-> RenderManager
    Logger -.-> NodeManager
    Logger -.-> XRSession
    
    Utils -.-> API
    Utils -.-> WSService
    Utils -.-> RenderManager
    Utils -.-> NodeManager
```

## Core Components

### API Client (`client/core/api.ts`)
Provides a centralized interface for communicating with the server REST API.

**Responsibilities:**
- Build API URLs for different endpoints
- Handle authentication headers
- Provide helper functions for API requests

**Key Dependencies:**
- Constants for API endpoints
- Types for request/response formats

### State Management
Manages application state and provides reactive updates.

**Key Components:**
- `SettingsStore` (`client/state/SettingsStore.ts`) - Manages application settings
- `GraphData` (`client/state/graphData.ts`) - Manages graph data state
- `SettingsObserver` (`client/state/SettingsObserver.ts`) - Observes setting changes

**Responsibilities:**
- Store and validate application settings
- Track graph data and node positions
- Propagate state changes to subscribers

### Event Emitter (`client/utils/eventEmitter.ts`)
Provides a pub/sub mechanism for cross-component communication.

**Responsibilities:**
- Register event listeners
- Dispatch events to listeners
- Unregister listeners when no longer needed

### Logger (`client/core/logger.ts`)
Provides centralized logging with different levels.

**Responsibilities:**
- Log messages with appropriate severity
- Add metadata to log messages
- Control log output based on debug settings

## Rendering Components

### Render Manager (`client/rendering/renderManager.ts`)
Orchestrates the rendering pipeline and manages Three.js integration.

**Responsibilities:**
- Initialize Three.js scene, camera, and renderer
- Manage render loop and animation frame requests
- Coordinate between different rendering components

**Key Dependencies:**
- Three.js
- Node Manager
- Edge Manager
- Scene setup

### Node Manager Facade (`client/rendering/node/NodeManagerFacade.ts`)
Provides a unified interface to the node management subsystem.

**Responsibilities:**
- Coordinate between node geometry, instance, metadata, and interaction managers
- Update node positions and states
- Handle XR interactions with nodes

**Component Structure:**
```mermaid
flowchart TB
    NodeManagerFacade --> NodeGeometryManager
    NodeManagerFacade --> NodeInstanceManager
    NodeManagerFacade --> NodeMetadataManager
    NodeManagerFacade --> NodeInteractionManager
    NodeManagerFacade --> NodeIdentityManager
    
    NodeInstanceManager --> THREE.InstancedMesh
    NodeMetadataManager --> TextRenderer
    NodeInteractionManager --> XRHandInteraction
```

### Edge Manager (`client/rendering/EdgeManager.ts`)
Manages the visual representation of edges connecting nodes.

**Responsibilities:**
- Create and update edge geometries
- Manage edge materials and appearance
- Update edge positions based on connected nodes

### Text Renderer (`client/rendering/textRenderer.ts`)
Renders text labels in 3D space.

**Responsibilities:**
- Create and position text elements
- Manage text appearance and visibility
- Handle SDF font rendering for crisp text

## Network Components

### WebSocket Service (`client/websocket/websocketService.ts`)
Manages WebSocket connection and communication with the server.

**Responsibilities:**
- Establish and maintain WebSocket connection
- Send and receive WebSocket messages
- Handle binary protocol for position updates
- Manage reconnection on connection loss

### Graph Data Manager (`client/state/graphData.ts`)
Manages graph data loading, updates, and state.

**Responsibilities:**
- Load initial graph data
- Process graph updates
- Track node and edge data
- Manage binary position updates

## XR Components

### XR Initializer (`client/xr/xrInitializer.ts`)
Initializes WebXR capabilities and sessions.

**Responsibilities:**
- Check WebXR availability
- Initialize WebXR sessions
- Set up XR reference space

### XR Session Manager (`client/xr/xrSessionManager.ts`)
Manages WebXR sessions and state.

**Responsibilities:**
- Start and end XR sessions
- Track XR session state
- Manage XR reference spaces

### Hand Interaction (`client/xr/handInteraction.ts`)
Handles XR hand tracking and interactions.

**Responsibilities:**
- Track hand positions
- Handle grabbing and manipulation gestures
- Interact with nodes and UI elements in XR

## UI Components

### Control Panel (`client/ui/ModularControlPanel.ts`)
Provides user interface controls for the application.

**Responsibilities:**
- Display control panels
- Handle user input
- Update application state based on input

### Settings UI
Provides interfaces for configuring application settings.

**Responsibilities:**
- Display settings options
- Validate user input
- Update settings in Settings Store

## Component Initialization Sequence

```mermaid
sequenceDiagram
    participant App
    participant API
    participant WSService
    participant RenderManager
    participant NodeManager
    participant GraphDataManager
    
    App->>API: Initialize
    App->>WSService: Initialize
    App->>RenderManager: Initialize
    RenderManager->>NodeManager: Initialize
    App->>GraphDataManager: Initialize
    GraphDataManager->>API: Fetch initial data
    GraphDataManager->>WSService: Register for updates
    WSService-->>GraphDataManager: Real-time updates
    GraphDataManager-->>NodeManager: Node position updates
    NodeManager-->>RenderManager: Render updates
```

## Component Communication Patterns

The application uses several communication patterns:

1. **Direct method calls** - For tightly coupled components
2. **Event-based communication** - For loosely coupled components
3. **State subscriptions** - For components that need to react to state changes
4. **WebSocket messages** - For server-client communication

## Interface Contracts

Key interface contracts between components:

### Node Manager Interface
```typescript
interface NodeManagerInterface {
  updateNodes(nodes: { id: string, data: NodeData }[]): void;
  updateNodePositions(nodes: { id: string, data: { position: Vector3, velocity?: Vector3 } }[]): void;
  handleHandInteraction(hand: XRHandWithHaptics): void;
  update(deltaTime: number): void;
  setXRMode(enabled: boolean): void;
  handleSettingsUpdate(settings: Settings): void;
  dispose(): void;
}
```

### WebSocket Service Interface
```typescript
interface WebSocketServiceInterface {
  connect(): Promise<void>;
  sendMessage(message: any): void;
  onBinaryMessage(callback: BinaryMessageCallback): void;
  onConnectionStatusChange(handler: (status: boolean) => void): void;
  enableRandomization(enabled: boolean): void;
  sendNodeUpdates(updates: NodeUpdate[]): void;
  getConnectionStatus(): ConnectionState;
  dispose(): void;
}
```

### Graph Data Manager Interface
```typescript
interface GraphDataManagerInterface {
  fetchInitialData(): Promise<void>;
  updateGraphData(data: any): void;
  enableBinaryUpdates(): void;
  updateNodePositions(positions: Float32Array): void;
  getGraphData(): GraphData;
  getNode(id: string): Node | undefined;
  subscribe(listener: (data: GraphData) => void): () => void;
  subscribeToPositionUpdates(listener: (positions: Float32Array) => void): () => void;
  clear(): void;
}
```

## Dependency Injection

The application uses a mix of dependency injection patterns:

1. **Singleton Registry** - Most manager classes provide static getInstance() methods
2. **Constructor Injection** - Some components take dependencies in constructors
3. **Method Injection** - Some methods accept dependencies as parameters

## Related Documentation

- [Architecture Overview](architecture.md)
- [State Management](state.md)
- [Rendering System](rendering.md)
- [XR Integration](xr.md)
----
overview/architecture.md
# Technical Architecture

LogseqXR is built on a robust and scalable architecture that combines a Rust-based backend server with a TypeScript-based frontend client.

## Core System Architecture

The following diagram illustrates the core components of the LogseqXR system and their interactions:

```mermaid
graph TB
    subgraph Frontend
        UI[User Interface Layer]
        VR[WebXR Controller]
        WS[WebSocket Client]
        GPU[GPU Compute Layer]
        ThreeJS[Three.js Renderer]
        ChatUI[Chat Interface]
        GraphUI[Graph Interface]
        ControlPanel[Modular Control Panel]
        VRControls[VR Control System]
        WSService[WebSocket Service]
        DataManager[Graph Data Manager]
        LayoutEngine[Layout Engine]
        SpaceMouse[SpaceMouse Controller]
        NostrAuth[Nostr Authentication]
        SettingsStore[Settings Store]
    end

    subgraph Backend
        PhysicsEngine[Continuous Physics Engine]
        Server[Actix Web Server]
        FileH[File Handler]
        GraphH[Graph Handler]
        WSH[WebSocket Handler]
        PerplexityH[Perplexity Handler]
        RagFlowH[RagFlow Handler]
        VisualisationH[Visualisation Handler]
        NostrH[Nostr Handler]
        FileS[File Service]
        GraphS[Graph Service]
        GPUS[GPU Compute Service]
        PerplexityS[Perplexity Service]
        RagFlowS[RagFlow Service]
        SpeechS[Speech Service]
        NostrS[Nostr Service]
        WSManager[WebSocket Manager]
        ClientManager[Client Manager]
        GPUCompute[GPU Compute]
        Compression[Compression Utils]
        AudioProc[Audio Processor]
        Node[Node Model]
        Edge[Edge Model]
        Graph[Graph Model]
        Metadata[Metadata Model]
        Position[Position Update Model]
        SimParams[Simulation Parameters]
    end

    subgraph External
        GitHub[GitHub API]
        Perplexity[Perplexity AI]
        RagFlow[RagFlow API]
        OpenAI[OpenAI API]
        Nostr[Nostr API]
    end

    UI --> ChatUI
    UI --> GraphUI
    UI --> ControlPanel
    UI --> VRControls
    UI --> NostrAuth

    VR --> ThreeJS
    WS --> WSService
    WSService --> Server

    Server --> FileH
    Server --> GraphH
    Server --> WSH
    Server --> PerplexityH
    Server --> RagFlowH
    Server --> VisualisationH
    Server --> NostrH

    FileH --> FileS
    GraphH --> GraphS
    WSH --> ClientManager
    ClientManager --> WSManager
    PerplexityH --> PerplexityS
    RagFlowH --> RagFlowS
    NostrH --> NostrS
    
    GraphS --> PhysicsEngine --> ClientManager

    FileS --> GitHub
    PerplexityS --> Perplexity
    RagFlowS --> RagFlow
    SpeechS --> OpenAI
    NostrS --> Nostr
```

## Component Breakdown

### Frontend Components

- **UI (User Interface Layer)**: Handles user interactions, displays information, and manages UI elements.
- **VR (WebXR Controller)**: Manages WebXR sessions, input, and rendering for VR/AR devices.
- **WS (WebSocket Client)**: Establishes and maintains a WebSocket connection with the backend server.
- **GPU (GPU Compute Layer)**: Performs GPU-accelerated computations using CUDA.
- **ThreeJS (Three.js Renderer)**: Renders the 3D graph visualisation using WebGL.
- **ChatUI**: Handles the chat interface for interacting with the AI.
- **GraphUI**: Manages the graph visualisation, including nodes, edges, and layout.
- **ControlPanel**: Modular control panel with dockable sections, Nostr authentication, and real-time settings management.
- **VRControls**: Handles VR-specific controls and interactions.
- **WSService**: Manages the WebSocket connection and message handling.
- **DataManager**: Manages the graph data structure and updates.
- **LayoutEngine**: Computes the force-directed layout of the graph.
- **SpaceMouse**: Handles input from Spacemouse devices.
- **NostrAuth**: Manages Nostr-based authentication and user sessions.
- **SettingsStore**: Centralized settings management with persistence and validation.

### Backend Components

- **Server (Actix Web Server)**: The core backend server built with the Actix web framework.
- **FileH (File Handler)**: Handles file-related operations, such as fetching and processing Markdown files.
- **GraphH (Graph Handler)**: Manages graph data and operations, such as building and updating the graph.
- **WSH (WebSocket Handler)**: Handles WebSocket connections and messages.
- **PerplexityH (Perplexity Handler)**: Interfaces with the Perplexity AI service.
- **RagFlowH (RagFlow Handler)**: Interfaces with the RAGFlow service.
- **VisualisationH (Visualisation Handler)**: Handles visualisation-related requests.
- **ClientManager**: Manages all connected WebSocket clients and broadcasts updates.
- **NostrH (Nostr Handler)**: Manages Nostr authentication and user sessions.
- **PhysicsEngine**: Continuously calculates force-directed layout independent of client connections.
- **FileS (File Service)**: Provides file-related services.
- **GraphS (Graph Service)**: Provides graph-related services.
- **GPUS (GPU Compute Service)**: Manages GPU-accelerated computations.
- **PerplexityS (Perplexity Service)**: Provides an interface to the Perplexity AI service.
- **RagFlowS (RagFlow Service)**: Provides an interface to the RAGFlow service.
- **SpeechS (Speech Service)**: Manages text-to-speech functionality.
- **NostrS (Nostr Service)**: Provides Nostr-related services and user management.
- **WSManager (WebSocket Manager)**: Manages WebSocket connections and message routing.

### External Services

- **GitHub API**: Provides access to the GitHub API for fetching and updating files.
- **Perplexity AI**: Provides AI-powered question answering and content analysis.
- **RagFlow API**: Provides AI-powered conversational capabilities.
- **OpenAI API**: Provides text-to-speech functionality.
- **Nostr API**: Provides decentralized authentication and user management.

For more detailed technical information, please refer to:
- [Binary Protocol](../technical/binary-protocol.md)
- [Decoupled Graph Architecture](../technical/decoupled-graph-architecture.md)
- [Performance Optimizations](../technical/performance.md)
- [Class Diagrams](../technical/class-diagrams.md)
- [WebSockets Implementation](../api/websocket-updated.md)
- [Graph Node Stacking Fix](../technical/graph-node-stacking-fix.md)

## Server Architecture

The server now uses a continuous physics simulation system that pre-computes node positions independent of client connections. When clients connect, they receive the complete graph state and any ongoing updates. This architecture enables bidirectional synchronization of graph state between all connected clients.
--END--