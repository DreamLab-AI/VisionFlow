================================================================================
                    VISIONFLOW DATA PIPELINE - COMPREHENSIVE DATAFLOW
================================================================================
Generated: 2025-12-30
Project: VisionFlow Knowledge Graph Visualization Platform
Scope: Complete data pipeline from ingest to client rendering

================================================================================
                         ARCHITECTURE OVERVIEW (MERMAID)
================================================================================

```mermaid
flowchart TB
    subgraph INGEST["Data Ingestion Layer"]
        direction TB
        GH[("GitHub API<br/>jjohare/logseq")]
        JSS[("JavaScript Solid Server<br/>JSS Pods")]
        LOCAL[("Local Files<br/>Markdown/YAML")]

        GH --> GHClient["GitHubClient<br/>src/services/github/api.rs"]
        GH --> ContentAPI["EnhancedContentAPI<br/>src/services/github/content_enhanced.rs"]
        JSS --> SolidProxy["SolidProxyHandler<br/>src/handlers/solid_proxy_handler.rs"]
        LOCAL --> LocalSync["LocalFileSyncService<br/>src/services/local_file_sync_service.rs"]
    end

    subgraph AUTH["Authentication Layer"]
        direction TB
        NOSTR[("Nostr Keys<br/>NIP-07/NIP-98")]

        NOSTR --> NostrService["NostrService<br/>src/services/nostr_service.rs"]
        NostrService --> NIP98["NIP98 Token Gen<br/>src/utils/nip98.rs"]
        NostrService --> AuthMiddleware["AuthMiddleware<br/>src/middleware/auth.rs"]
        NIP98 --> SolidProxy
    end

    subgraph PARSE["Parsing Layer"]
        direction TB
        GHClient --> GitHubSync["GitHubSyncService<br/>src/services/github_sync_service.rs"]
        ContentAPI --> GitHubSync
        LocalSync --> StreamSync["StreamingSyncService<br/>src/services/streaming_sync_service.rs"]

        GitHubSync --> KGParser["KnowledgeGraphParser<br/>src/services/parsers/knowledge_graph_parser.rs"]
        GitHubSync --> OntParser["OntologyParser<br/>src/services/parsers/ontology_parser.rs"]
        StreamSync --> KGParser
        StreamSync --> OntParser

        KGParser --> Enrichment["OntologyEnrichmentService<br/>src/services/ontology_enrichment_service.rs"]
        OntParser --> Enrichment
    end

    subgraph STORAGE["Storage Layer (Neo4j)"]
        direction TB
        Enrichment --> GraphRepo["Neo4jGraphRepository<br/>src/adapters/neo4j_graph_repository.rs"]
        Enrichment --> OntRepo["Neo4jOntologyRepository<br/>src/adapters/neo4j_ontology_repository.rs"]

        GraphRepo --> NEO4J[("Neo4j Database<br/>Graphs + Ontology")]
        OntRepo --> NEO4J

        SettingsRepo["Neo4jSettingsRepository<br/>src/adapters/neo4j_settings_repository.rs"] --> NEO4J
    end

    subgraph GPU["GPU Compute Pipeline"]
        direction TB
        NEO4J --> GPUManager["GPUManagerActor<br/>src/actors/gpu/gpu_manager_actor.rs"]

        GPUManager --> ForceActor["ForceComputeActor<br/>src/actors/gpu/force_compute_actor.rs"]
        GPUManager --> ClusterActor["ClusteringActor<br/>src/actors/gpu/clustering_actor.rs"]
        GPUManager --> PathActor["ShortestPathActor<br/>src/actors/gpu/shortest_path_actor.rs"]
        GPUManager --> SemanticActor["SemanticForcesActor<br/>src/actors/gpu/semantic_forces_actor.rs"]

        ForceActor --> UnifiedGPU["UnifiedGPUCompute<br/>src/utils/unified_gpu_compute.rs"]
        ClusterActor --> UnifiedGPU
        PathActor --> UnifiedGPU
        SemanticActor --> UnifiedGPU

        UnifiedGPU --> PTX["PTX Kernels<br/>src/utils/*.cu"]
        PTX --> CUDA[("CUDA Device<br/>GPU Memory")]
    end

    subgraph BROADCAST["Real-time Broadcast Layer"]
        direction TB
        UnifiedGPU --> SocketFlow["SocketFlowHandler<br/>src/handlers/socket_flow_handler.rs"]
        UnifiedGPU --> RealtimeWS["RealtimeWebSocketHandler<br/>src/handlers/realtime_websocket_handler.rs"]

        SolidProxy --> JSSBridge["JssWebSocketBridge<br/>src/services/jss_websocket_bridge.rs"]
        JSSBridge --> RealtimeWS

        SocketFlow --> BinaryProto["BinaryProtocol<br/>src/utils/binary_protocol.rs"]
        RealtimeWS --> BinaryProto
    end

    subgraph CLIENT["Client Application"]
        direction TB
        BinaryProto --> WSService["WebSocketService<br/>client/src/services/WebSocketService.ts"]

        WSService --> BinaryDecode["BinaryWebSocketProtocol<br/>client/src/services/BinaryWebSocketProtocol.ts"]
        WSService --> SettingsStore["useSettingsStore<br/>client/src/store/settingsStore.ts"]

        BinaryDecode --> GraphManager["GraphDataManager<br/>client/src/features/graph/managers/graphDataManager.ts"]

        GraphManager --> ThreeJS["Three.js Renderer<br/>React Three Fiber"]
        SettingsStore --> ThreeJS

        NostrClient["nostrAuthService<br/>client/src/services/nostrAuthService.ts"] --> WSService
        SolidClient["SolidPodService<br/>client/src/services/SolidPodService.ts"] --> WSService
    end

    subgraph EXPORT["Export & Persistence"]
        direction TB
        NEO4J --> ExportHandler["GraphExportHandler<br/>src/handlers/graph_export_handler.rs"]
        ExportHandler --> Serialization["GraphSerializationService<br/>src/services/graph_serialization.rs"]

        Serialization --> JSON["JSON Export"]
        Serialization --> GEXF["GEXF Export"]
        Serialization --> GraphML["GraphML Export"]
        Serialization --> Turtle["Turtle/RDF Export"]

        NEO4J --> JSSSync["JssSyncService<br/>src/services/jss_sync_service.rs"]
        JSSSync --> JSS
    end

    %% Cross-layer connections
    AuthMiddleware -.-> GraphRepo
    AuthMiddleware -.-> SettingsRepo
    NostrService -.-> NostrClient
```

```mermaid
sequenceDiagram
    participant User
    participant Client as React Client
    participant WS as WebSocket
    participant Auth as NostrService
    participant API as Actix API
    participant Neo4j as Neo4j DB
    participant GPU as GPU Pipeline
    participant JSS as Solid Server

    User->>Client: Open Application
    Client->>Auth: Check NIP-07 Extension
    Auth-->>Client: Extension Available

    User->>Client: Click Login
    Client->>Auth: Request Signature (NIP-42)
    Auth->>API: POST /auth/nostr (signed event)
    API->>API: Verify Schnorr Signature
    API-->>Client: Session Token + User

    Client->>WS: Connect WebSocket
    WS->>API: Authenticate Session
    API-->>WS: Connection Established

    Client->>API: GET /graph
    API->>Neo4j: Load Graph Data
    Neo4j-->>API: Nodes + Edges
    API->>GPU: Initialize Physics
    GPU->>GPU: Load PTX Kernels
    GPU-->>API: Physics Ready

    loop Every 16ms (60fps)
        GPU->>GPU: Compute Forces
        GPU->>GPU: Integrate Positions
        GPU->>WS: Binary Position Update (36 bytes/node)
        WS->>Client: Broadcast Positions
        Client->>Client: Update Three.js Scene
    end

    User->>Client: Edit Ontology
    Client->>JSS: PUT /solid/pods/{npub}/ontology/proposals/
    JSS-->>Client: 201 Created
    JSS->>WS: pub notification
    WS->>Client: Resource Changed Event

    User->>Client: Export Graph
    Client->>API: POST /export {format: GEXF}
    API->>Neo4j: Query Full Graph
    Neo4j-->>API: Graph Data
    API->>API: Serialize to GEXF
    API-->>Client: Download File
```

================================================================================
                              FILE INVENTORY
================================================================================

Total Files Identified: 120+
Categories:
  - GitHub Ingest: 23 files
  - Solid/JSS Pipeline: 12 files
  - Neo4j Database: 11 files
  - Nostr Authentication: 11 files
  - GPU Compute: 35+ files
  - WebSocket/Broadcast: 17 files
  - Settings Management: 37+ files
  - File Handlers/Export: 24 files

================================================================================
                    SECTION 1: GITHUB INGEST SERVICES
================================================================================

--------------------------------------------------------------------------------
FILE: src/services/github/mod.rs
LOCATION: /home/devuser/workspace/project/src/services/github/mod.rs
TYPE: Rust Module
DESC: Main GitHub service module with exports for API client, configuration, content API, and PR API
EXPORTS: GitHubClient, GitHubConfig, EnhancedContentAPI, PullRequestAPI, GitHubError, GitHubFile
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/github/api.rs
LOCATION: /home/devuser/workspace/project/src/services/github/api.rs
TYPE: Rust Implementation
DESC: GitHub HTTP client implementation for API interactions with token authentication
EXPORTS: GitHubClient (new, get_full_path, get_contents_url, client, token, owner, repo)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/github/types.rs
LOCATION: /home/devuser/workspace/project/src/services/github/types.rs
TYPE: Rust Types
DESC: Type definitions for GitHub API responses, file metadata, and ontology metadata
EXPORTS: RateLimitInfo, GitHubError, GitHubFile, GitHubFileMetadata, ContentResponse, PullRequestResponse
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/github/config.rs
LOCATION: /home/devuser/workspace/project/src/services/github/config.rs
TYPE: Rust Configuration
DESC: GitHub configuration management from environment variables with validation
EXPORTS: GitHubConfigError, GitHubConfig (from_env, token, owner, repo, base_path, branch)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/github/pr.rs
LOCATION: /home/devuser/workspace/project/src/services/github/pr.rs
TYPE: Rust Implementation
DESC: Pull request creation and file update API for GitHub workflow automation
EXPORTS: PullRequestAPI (create_pull_request, get_main_branch_sha, create_branch, update_file)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/github/content_enhanced.rs
LOCATION: /home/devuser/workspace/project/src/services/github/content_enhanced.rs
TYPE: Rust Implementation
DESC: Enhanced content API with recursive markdown listing, pagination, commit history
EXPORTS: EnhancedContentAPI (list_markdown_files, fetch_file_content, get_file_metadata_extended)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/github_sync_service.rs
LOCATION: /home/devuser/workspace/project/src/services/github_sync_service.rs
TYPE: Rust Service
DESC: Main GitHub sync orchestrator - processes markdown, parses graphs/ontologies, stores in Neo4j
EXPORTS: FileType, SyncStatistics, GitHubSyncService (sync_graphs)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/local_file_sync_service.rs
LOCATION: /home/devuser/workspace/project/src/services/local_file_sync_service.rs
TYPE: Rust Service
DESC: Hybrid sync using local filesystem as primary with GitHub SHA1 delta updates
EXPORTS: LocalFileSyncService, SyncStatistics (with priority tiers and cache metrics)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/streaming_sync_service.rs
LOCATION: /home/devuser/workspace/project/src/services/streaming_sync_service.rs
TYPE: Rust Service
DESC: Fault-tolerant streaming sync with swarm-based parallel processing (4-8 workers)
EXPORTS: FileType, SyncProgress, StreamingSyncService (sync_graphs_streaming)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/parsers/mod.rs
LOCATION: /home/devuser/workspace/project/src/services/parsers/mod.rs
TYPE: Rust Module
DESC: Parser module aggregator for knowledge graph and ontology parsing
EXPORTS: OntologyData, KnowledgeGraphParser, OntologyParser
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/parsers/knowledge_graph_parser.rs
LOCATION: /home/devuser/workspace/project/src/services/parsers/knowledge_graph_parser.rs
TYPE: Rust Implementation
DESC: Parses markdown files with public:: true to extract nodes, edges, metadata
EXPORTS: KnowledgeGraphParser (parse)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/parsers/ontology_parser.rs
LOCATION: /home/devuser/workspace/project/src/services/parsers/ontology_parser.rs
TYPE: Rust Implementation
DESC: Parses OntologyBlock sections from markdown to extract OWL classes, properties, axioms
EXPORTS: OntologyBlock, OntologyParser
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/handlers/admin_sync_handler.rs
LOCATION: /home/devuser/workspace/project/src/handlers/admin_sync_handler.rs
TYPE: Rust Handler
DESC: HTTP endpoint handler for triggering GitHub sync and returning statistics
EXPORTS: SyncResponse, SyncStatisticsDto, trigger_sync
--------------------------------------------------------------------------------

================================================================================
                    SECTION 2: SOLID/JSS DATA PIPELINE
================================================================================

--------------------------------------------------------------------------------
FILE: src/handlers/solid_proxy_handler.rs
LOCATION: /home/devuser/workspace/project/src/handlers/solid_proxy_handler.rs
TYPE: Rust Handler
DESC: Main HTTP proxy handler for JSS requests with NIP-98 authentication and LDP operations
EXPORTS: handle_solid_proxy, create_pod, check_pod_exists, configure_routes, JssConfig, SolidProxyState
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/jss_sync_service.rs
LOCATION: /home/devuser/workspace/project/src/services/jss_sync_service.rs
TYPE: Rust Service
DESC: Synchronizes ontology data from Neo4j to JSS pods with Turtle/RDF serialization
EXPORTS: JssSyncService, JssSyncConfig, OntologyResource, UserContribution, Neo4jChangeEvent
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/jss_websocket_bridge.rs
LOCATION: /home/devuser/workspace/project/src/services/jss_websocket_bridge.rs
TYPE: Rust Service
DESC: Bridges JSS WebSocket notifications to VisionFlow clients via realtime channels
EXPORTS: JssWebSocketBridge, JssBridgeConfig, JssNotificationType, JssResourceNotification
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/nip98.rs
LOCATION: /home/devuser/workspace/project/src/utils/nip98.rs
TYPE: Rust Utility
DESC: Generates NIP-98 HTTP authentication headers for Solid Server integration
EXPORTS: generate_nip98_token, build_auth_header, extract_pubkey_from_token, Nip98Config
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/services/SolidPodService.ts
LOCATION: /home/devuser/workspace/project/client/src/services/SolidPodService.ts
TYPE: TypeScript Service
DESC: Singleton service for JSS pod management, LDP CRUD, and WebSocket subscriptions
EXPORTS: SolidPodService, PodInfo, PodCreationResult, JsonLdDocument, SolidNotification
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/solid/hooks/useSolidPod.ts
LOCATION: /home/devuser/workspace/project/client/src/features/solid/hooks/useSolidPod.ts
TYPE: React Hook
DESC: React hook for pod state management and creation/deletion operations
EXPORTS: useSolidPod, UseSolidPodReturn
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/solid/hooks/useSolidResource.ts
LOCATION: /home/devuser/workspace/project/client/src/features/solid/hooks/useSolidResource.ts
TYPE: React Hook
DESC: React hook for individual resource CRUD operations with real-time notifications
EXPORTS: useSolidResource, UseSolidResourceReturn, ResourceMetadata
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/solid/hooks/useSolidContainer.ts
LOCATION: /home/devuser/workspace/project/client/src/features/solid/hooks/useSolidContainer.ts
TYPE: React Hook
DESC: React hook for container (folder) listing, navigation, and management
EXPORTS: useSolidContainer, UseSolidContainerReturn, ContainerItem
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/solid/components/SolidTabContent.tsx
LOCATION: /home/devuser/workspace/project/client/src/features/solid/components/SolidTabContent.tsx
TYPE: React Component
DESC: Main UI component combining pod settings and file browser tabs
EXPORTS: SolidTabContent, SolidTabContentProps
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/solid/components/PodBrowser.tsx
LOCATION: /home/devuser/workspace/project/client/src/features/solid/components/PodBrowser.tsx
TYPE: React Component
DESC: Tree view file browser for Solid Pod with expand/collapse and CRUD actions
EXPORTS: PodBrowser, TreeNode
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/solid/components/PodSettings.tsx
LOCATION: /home/devuser/workspace/project/client/src/features/solid/components/PodSettings.tsx
TYPE: React Component
DESC: Pod configuration panel with creation, deletion, and info display
EXPORTS: PodSettings, CopyButton, InfoRow
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/solid/components/ResourceEditor.tsx
LOCATION: /home/devuser/workspace/project/client/src/features/solid/components/ResourceEditor.tsx
TYPE: React Component
DESC: JSON-LD resource editor with validation, view modes, and metadata display
EXPORTS: ResourceEditor, validateJsonLd, MetadataDisplay
--------------------------------------------------------------------------------

================================================================================
                    SECTION 3: NEO4J DATABASE HANDLERS
================================================================================

--------------------------------------------------------------------------------
FILE: src/adapters/neo4j_settings_repository.rs
LOCATION: /home/devuser/workspace/project/src/adapters/neo4j_settings_repository.rs
TYPE: Rust Adapter
DESC: Neo4j adapter for application settings with user management and caching
EXPORTS: Neo4jSettingsRepository, User, UserSettings, SettingsCache
TRAIT: SettingsRepository (async_trait)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/adapters/neo4j_graph_repository.rs
LOCATION: /home/devuser/workspace/project/src/adapters/neo4j_graph_repository.rs
TYPE: Rust Adapter
DESC: Neo4j adapter for graph nodes/edges with LRU caching and batch operations
EXPORTS: Neo4jGraphRepository
TRAIT: GraphRepository (async_trait)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/adapters/neo4j_ontology_repository.rs
LOCATION: /home/devuser/workspace/project/src/adapters/neo4j_ontology_repository.rs
TYPE: Rust Adapter
DESC: Neo4j adapter for OWL ontology with 24+ indexes and Schema V2 metadata
EXPORTS: Neo4jOntologyRepository, Neo4jOntologyConfig
TRAIT: OntologyRepository (async_trait)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/adapters/neo4j_adapter.rs
LOCATION: /home/devuser/workspace/project/src/adapters/neo4j_adapter.rs
TYPE: Rust Adapter
DESC: Neo4j adapter for knowledge graph with security hardening and connection pooling
EXPORTS: Neo4jAdapter, Neo4jConfig
TRAIT: KnowledgeGraphRepository (async_trait)
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/neo4j_helpers.rs
LOCATION: /home/devuser/workspace/project/src/utils/neo4j_helpers.rs
TYPE: Rust Utility
DESC: Utility functions for converting Rust/JSON types to Neo4j BoltType
EXPORTS: json_to_bolt, string_ref_to_bolt, string_to_bolt
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/ports/graph_repository.rs
LOCATION: /home/devuser/workspace/project/src/ports/graph_repository.rs
TYPE: Rust Port/Interface
DESC: Trait definition for graph data repository
EXPORTS: GraphRepository (async trait), GraphRepositoryError, BinaryNodeData
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/ports/settings_repository.rs
LOCATION: /home/devuser/workspace/project/src/ports/settings_repository.rs
TYPE: Rust Port/Interface
DESC: Trait definition for settings repository
EXPORTS: SettingsRepository (async trait), SettingsRepositoryError, SettingValue
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/ports/ontology_repository.rs
LOCATION: /home/devuser/workspace/project/src/ports/ontology_repository.rs
TYPE: Rust Port/Interface
DESC: Trait definition for ontology repository
EXPORTS: OntologyRepository (async trait), OwlClass, OwlProperty, OwlAxiom
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/ports/knowledge_graph_repository.rs
LOCATION: /home/devuser/workspace/project/src/ports/knowledge_graph_repository.rs
TYPE: Rust Port/Interface
DESC: Trait definition for knowledge graph repository
EXPORTS: KnowledgeGraphRepository (async trait), GraphStatistics
--------------------------------------------------------------------------------

================================================================================
                    SECTION 4: NOSTR AUTHENTICATION
================================================================================

--------------------------------------------------------------------------------
FILE: src/services/nostr_service.rs
LOCATION: /home/devuser/workspace/project/src/services/nostr_service.rs
TYPE: Rust Service
DESC: Core Nostr authentication service managing users, sessions, tokens, and feature access
EXPORTS: NostrService, NostrError, AuthEvent, verify_auth_event, get_session, is_power_user
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/handlers/nostr_handler.rs
LOCATION: /home/devuser/workspace/project/src/handlers/nostr_handler.rs
TYPE: Rust Handler
DESC: HTTP route handlers for Nostr authentication endpoints
EXPORTS: login, logout, verify, refresh, update_api_keys, AuthResponse, VerifyResponse
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/auth.rs
LOCATION: /home/devuser/workspace/project/src/utils/auth.rs
TYPE: Rust Utility
DESC: Access level verification and session validation for HTTP requests
EXPORTS: AccessLevel, verify_access, verify_power_user, verify_authenticated
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/settings/auth_extractor.rs
LOCATION: /home/devuser/workspace/project/src/settings/auth_extractor.rs
TYPE: Rust Extractor
DESC: Actix-web request extractor for Bearer token authentication
EXPORTS: AuthenticatedUser, OptionalAuth, FromRequest impl
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/models/protected_settings.rs
LOCATION: /home/devuser/workspace/project/src/models/protected_settings.rs
TYPE: Rust Model
DESC: Data models for Nostr users, API keys, and protected server settings
EXPORTS: ApiKeys, NostrUser, ProtectedSettings, NetworkSettings, SecuritySettings
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/models/user_settings.rs
LOCATION: /home/devuser/workspace/project/src/models/user_settings.rs
TYPE: Rust Model
DESC: Per-user settings persistence with caching (10-min TTL)
EXPORTS: UserSettings, load, save, clear_cache
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/middleware/auth.rs
LOCATION: /home/devuser/workspace/project/src/middleware/auth.rs
TYPE: Rust Middleware
DESC: Actix-web middleware for enforcing authentication on protected routes
EXPORTS: RequireAuth, AuthMiddleware, AccessLevel
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/services/nostrAuthService.ts
LOCATION: /home/devuser/workspace/project/client/src/services/nostrAuthService.ts
TYPE: TypeScript Service
DESC: Client-side Nostr authentication using NIP-07 provider (Alby extension)
EXPORTS: NostrAuthService, nostrAuth, hasNip07Provider, login, logout, getSessionToken
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/services/api/authInterceptor.ts
LOCATION: /home/devuser/workspace/project/client/src/services/api/authInterceptor.ts
TYPE: TypeScript Utility
DESC: Request interceptor for adding Nostr auth headers to all API calls
EXPORTS: generateRequestId, authRequestInterceptor, initializeAuthInterceptor
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/hooks/useNostrAuth.ts
LOCATION: /home/devuser/workspace/project/client/src/hooks/useNostrAuth.ts
TYPE: React Hook
DESC: React hook for Nostr authentication state management
EXPORTS: useNostrAuth
--------------------------------------------------------------------------------

================================================================================
                    SECTION 5: GPU COMPUTE PIPELINE
================================================================================

--------------------------------------------------------------------------------
FILE: src/utils/visionflow_unified.cu
LOCATION: /home/devuser/workspace/project/src/utils/visionflow_unified.cu
TYPE: CUDA Kernel
DESC: Main physics simulation kernel with force-directed layout and spatial hashing (2164 lines)
EXPORTS: build_grid_kernel, compute_cell_bounds_kernel, force_pass_kernel, integrate_pass_kernel
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/semantic_forces.cu
LOCATION: /home/devuser/workspace/project/src/utils/semantic_forces.cu
TYPE: CUDA Kernel
DESC: Type-aware physics for knowledge graphs with DAG layout and type clustering (761 lines)
EXPORTS: compute_dag_layout_kernel, compute_type_cluster_kernel, compute_collision_kernel
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/gpu_clustering_kernels.cu
LOCATION: /home/devuser/workspace/project/src/utils/gpu_clustering_kernels.cu
TYPE: CUDA Kernel
DESC: Clustering algorithms including Louvain, label propagation, connected components (1062 lines)
EXPORTS: louvain_init_kernel, louvain_modularity_kernel, label_prop_kernel
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/pagerank.cu
LOCATION: /home/devuser/workspace/project/src/utils/pagerank.cu
TYPE: CUDA Kernel
DESC: GPU-accelerated PageRank computation (417 lines)
EXPORTS: pagerank_init_kernel, pagerank_iteration_kernel, pagerank_normalization_kernel
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/stress_majorization.cu
LOCATION: /home/devuser/workspace/project/src/utils/stress_majorization.cu
TYPE: CUDA Kernel
DESC: Graph stress-majorization optimization (471 lines)
EXPORTS: compute_stress_kernel, majorization_step_kernel, update_positions_kernel
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/ontology_constraints.cu
LOCATION: /home/devuser/workspace/project/src/utils/ontology_constraints.cu
TYPE: CUDA Kernel
DESC: GPU kernel for semantic constraint enforcement (529 lines)
EXPORTS: apply_ontology_constraints_kernel, compute_constraint_forces_kernel
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/unified_gpu_compute.rs
LOCATION: /home/devuser/workspace/project/src/utils/unified_gpu_compute.rs
TYPE: Rust Implementation
DESC: High-performance GPU compute engine with async transfers and double-buffering
EXPORTS: UnifiedGPUCompute, SimParams, ComputeMode, execute_physics_step
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/ptx.rs
LOCATION: /home/devuser/workspace/project/src/utils/ptx.rs
TYPE: Rust Utility
DESC: PTX module loading and runtime compilation with fallback mechanisms
EXPORTS: PTXModule, load_ptx_sync, compile_ptx_fallback_sync, load_all_ptx_modules_sync
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/gpu_memory.rs
LOCATION: /home/devuser/workspace/project/src/utils/gpu_memory.rs
TYPE: Rust Utility
DESC: GPU memory management with leak detection and allocation tracking
EXPORTS: ManagedDeviceBuffer, GPUMemoryTracker, track_allocation
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/gpu_safety.rs
LOCATION: /home/devuser/workspace/project/src/utils/gpu_safety.rs
TYPE: Rust Utility
DESC: GPU safety validation with bounds checking and memory validation
EXPORTS: GPUSafetyConfig, validate_node_count, validate_memory_limits
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/gpu_diagnostics.rs
LOCATION: /home/devuser/workspace/project/src/utils/gpu_diagnostics.rs
TYPE: Rust Utility
DESC: GPU diagnostics, health checks, and PTX validation
EXPORTS: ptx_module_smoke_test, create_gpu_metrics_report, run_gpu_diagnostics
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/cuda_error_handling.rs
LOCATION: /home/devuser/workspace/project/src/utils/cuda_error_handling.rs
TYPE: Rust Utility
DESC: CUDA error handling with comprehensive error codes
EXPORTS: CudaError, get_global_cuda_error_handler, cuda_check macro
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/actors/gpu/gpu_manager_actor.rs
LOCATION: /home/devuser/workspace/project/src/actors/gpu/gpu_manager_actor.rs
TYPE: Rust Actor
DESC: Supervisor actor for all GPU computation actors
EXPORTS: GPUManagerActor, spawn_child_actors
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/actors/gpu/gpu_resource_actor.rs
LOCATION: /home/devuser/workspace/project/src/actors/gpu/gpu_resource_actor.rs
TYPE: Rust Actor
DESC: GPU initialization, memory allocation, and device management
EXPORTS: GPUResourceActor, perform_gpu_initialization, test_gpu_capabilities
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/actors/gpu/force_compute_actor.rs
LOCATION: /home/devuser/workspace/project/src/actors/gpu/force_compute_actor.rs
TYPE: Rust Actor
DESC: Physics force computation with broadcast optimization
EXPORTS: ForceComputeActor, PhysicsStats, execute_physics_step
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/actors/gpu/clustering_actor.rs
LOCATION: /home/devuser/workspace/project/src/actors/gpu/clustering_actor.rs
TYPE: Rust Actor
DESC: GPU-accelerated clustering (Louvain, label propagation)
EXPORTS: ClusteringActor, run_clustering_algorithm
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/actors/gpu/semantic_forces_actor.rs
LOCATION: /home/devuser/workspace/project/src/actors/gpu/semantic_forces_actor.rs
TYPE: Rust Actor
DESC: Type-aware semantic forces: DAG layout, type clustering
EXPORTS: SemanticForcesActor, compute_semantic_forces
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/actors/gpu/shortest_path_actor.rs
LOCATION: /home/devuser/workspace/project/src/actors/gpu/shortest_path_actor.rs
TYPE: Rust Actor
DESC: GPU-accelerated shortest path computation
EXPORTS: ShortestPathActor, compute_shortest_paths
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/actors/gpu/shared.rs
LOCATION: /home/devuser/workspace/project/src/actors/gpu/shared.rs
TYPE: Rust Shared Types
DESC: Shared data structures for GPU actors
EXPORTS: GPUState, SharedGPUContext, GPUResourceMetrics, GPUOperationBatch
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/ports/gpu_physics_adapter.rs
LOCATION: /home/devuser/workspace/project/src/ports/gpu_physics_adapter.rs
TYPE: Rust Port/Interface
DESC: GPU physics computation port abstracting CUDA implementations
EXPORTS: GpuPhysicsAdapter trait, GpuDeviceInfo, PhysicsStepResult
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/handlers/physics_handler.rs
LOCATION: /home/devuser/workspace/project/src/handlers/physics_handler.rs
TYPE: Rust Handler
DESC: HTTP handlers for physics simulation endpoints
EXPORTS: StartSimulationRequest, SimulationStatusResponse, OptimizeLayoutRequest
--------------------------------------------------------------------------------

================================================================================
                    SECTION 6: WEBSOCKET/BROADCAST
================================================================================

--------------------------------------------------------------------------------
FILE: src/handlers/realtime_websocket_handler.rs
LOCATION: /home/devuser/workspace/project/src/handlers/realtime_websocket_handler.rs
TYPE: Rust Handler
DESC: Main real-time WebSocket handler for workspace events and analysis progress
EXPORTS: RealtimeWebSocketMessage, WorkspaceUpdateEvent, broadcast_analysis_progress
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/handlers/socket_flow_handler.rs
LOCATION: /home/devuser/workspace/project/src/handlers/socket_flow_handler.rs
TYPE: Rust Handler
DESC: High-performance socket handler for binary node position updates
EXPORTS: SocketFlowServer, BroadcastPositionUpdate, SendToClientBinary
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/handlers/fastwebsockets_handler.rs
LOCATION: /home/devuser/workspace/project/src/handlers/fastwebsockets_handler.rs
TYPE: Rust Handler
DESC: High-performance WebSocket using fastwebsockets (2.4x faster)
EXPORTS: FastWebSocketConfig, FastWebSocketServer, PostcardBatchUpdate
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/handlers/websocket_settings_handler.rs
LOCATION: /home/devuser/workspace/project/src/handlers/websocket_settings_handler.rs
TYPE: Rust Handler
DESC: Settings handler with binary protocol and delta compression
EXPORTS: WebSocketSettingsHandler, DeltaUpdate, SyncRequest
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/binary_protocol.rs
LOCATION: /home/devuser/workspace/project/src/utils/binary_protocol.rs
TYPE: Rust Utility
DESC: Binary protocol encoder/decoder with V1-V4 versions and delta encoding
EXPORTS: WireNodeDataItemV1-V4, DeltaNodeData, encode_node_data, decode_node_data
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/socket_flow_messages.rs
LOCATION: /home/devuser/workspace/project/src/utils/socket_flow_messages.rs
TYPE: Rust Utility
DESC: Message types for socket flow binary node data
EXPORTS: BinaryNodeDataClient, BinaryNodeDataGPU, PingMessage, PongMessage
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/utils/socket_flow_constants.rs
LOCATION: /home/devuser/workspace/project/src/utils/socket_flow_constants.rs
TYPE: Rust Constants
DESC: Constants for socket flow including heartbeat and update rates
EXPORTS: HEARTBEAT_INTERVAL, CLIENT_TIMEOUT, MAX_MESSAGE_SIZE, POSITION_UPDATE_RATE
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/services/WebSocketService.ts
LOCATION: /home/devuser/workspace/project/client/src/services/WebSocketService.ts
TYPE: TypeScript Service
DESC: Main WebSocket client with reconnection, batching, and Solid notifications
EXPORTS: WebSocketService, connect, disconnect, subscribe, subscribeSolidResource
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/services/BinaryWebSocketProtocol.ts
LOCATION: /home/devuser/workspace/project/client/src/services/BinaryWebSocketProtocol.ts
TYPE: TypeScript Service
DESC: Binary protocol encoder/decoder for client-side WebSocket
EXPORTS: binaryProtocol, encodeMessage, decodeMessage, MessageType
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/types/binaryProtocol.ts
LOCATION: /home/devuser/workspace/project/client/src/types/binaryProtocol.ts
TYPE: TypeScript Types
DESC: TypeScript interfaces for binary protocol node data
EXPORTS: Vec3, BinaryNodeData, NodeType, parseBinaryNodeData, BINARY_NODE_SIZE
--------------------------------------------------------------------------------

================================================================================
                    SECTION 7: SETTINGS MANAGEMENT
================================================================================

--------------------------------------------------------------------------------
FILE: src/handlers/websocket_settings_handler.rs
LOCATION: /home/devuser/workspace/project/src/handlers/websocket_settings_handler.rs
TYPE: Rust Handler
DESC: High-performance WebSocket with delta compression and bandwidth optimization
EXPORTS: WebSocketSettingsHandler, DeltaUpdate, DeltaOperation, PerformanceDelta
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/models/user_settings.rs
LOCATION: /home/devuser/workspace/project/src/models/user_settings.rs
TYPE: Rust Model
DESC: User-specific settings with 10-minute TTL caching
EXPORTS: UserSettings, CachedUserSettings
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/models/protected_settings.rs
LOCATION: /home/devuser/workspace/project/src/models/protected_settings.rs
TYPE: Rust Model
DESC: Server-side protected settings for network, security, WebSocket, API keys
EXPORTS: ProtectedSettings, NetworkSettings, SecuritySettings, WebSocketServerSettings
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/settings_watcher.rs
LOCATION: /home/devuser/workspace/project/src/services/settings_watcher.rs
TYPE: Rust Service
DESC: File system hot-reload watcher with debounce
EXPORTS: SettingsWatcher
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/settings_broadcast.rs
LOCATION: /home/devuser/workspace/project/src/services/settings_broadcast.rs
TYPE: Rust Service
DESC: WebSocket broadcast manager for real-time settings sync
EXPORTS: SettingsBroadcastManager, SettingChange
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/store/settingsStore.ts
LOCATION: /home/devuser/workspace/project/client/src/store/settingsStore.ts
TYPE: TypeScript Store
DESC: Zustand settings store with lazy-loading and path-based access
EXPORTS: useSettingsStore, settingsStoreUtils, SettingsState
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/store/settingsRetryManager.ts
LOCATION: /home/devuser/workspace/project/client/src/store/settingsRetryManager.ts
TYPE: TypeScript Utility
DESC: Retry manager with exponential backoff for failed updates
EXPORTS: SettingsRetryManager
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/hooks/useSettingsWebSocket.ts
LOCATION: /home/devuser/workspace/project/client/src/hooks/useSettingsWebSocket.ts
TYPE: React Hook
DESC: React hook for real-time WebSocket settings synchronization
EXPORTS: useSettingsWebSocket, SettingsWebSocketStatus
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/settings/config/settingsUIDefinition.ts
LOCATION: /home/devuser/workspace/project/client/src/features/settings/config/settingsUIDefinition.ts
TYPE: TypeScript Configuration
DESC: UI widget definitions for settings panels with physics, rendering, graph parameters
EXPORTS: SettingWidgetType, UISettingDefinition, createGraphSettingsSubsections
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/settings/presets/qualityPresets.ts
LOCATION: /home/devuser/workspace/project/client/src/features/settings/presets/qualityPresets.ts
TYPE: TypeScript Configuration
DESC: Quality presets (Low/Medium/High/Ultra) with system requirements
EXPORTS: QualityPreset, QUALITY_PRESETS
--------------------------------------------------------------------------------

================================================================================
                    SECTION 8: FILE HANDLERS & EXPORT
================================================================================

--------------------------------------------------------------------------------
FILE: src/models/graph_export.rs
LOCATION: /home/devuser/workspace/project/src/models/graph_export.rs
TYPE: Rust Model
DESC: Data models for graph export, sharing, and publishing
EXPORTS: ExportFormat, ExportRequest, ExportResponse, SharedGraph, ShareRequest
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/handlers/graph_export_handler.rs
LOCATION: /home/devuser/workspace/project/src/handlers/graph_export_handler.rs
TYPE: Rust Handler
DESC: HTTP handlers for exporting graphs with rate limiting
EXPORTS: GraphExportHandler, RateLimitState, SharedGraphStorage
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/graph_serialization.rs
LOCATION: /home/devuser/workspace/project/src/services/graph_serialization.rs
TYPE: Rust Service
DESC: Serialization to JSON, GEXF, GraphML, CSV, DOT formats with compression
EXPORTS: GraphSerializationService
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/file_service.rs
LOCATION: /home/devuser/workspace/project/src/services/file_service.rs
TYPE: Rust Service
DESC: GitHub file fetching and local markdown processing
EXPORTS: FileService, ProcessedFile, OntologyData
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/services/ontology_file_cache.rs
LOCATION: /home/devuser/workspace/project/src/services/ontology_file_cache.rs
TYPE: Rust Service
DESC: LRU cache for parsed ontology files with SHA1 validation
EXPORTS: OntologyFileCache, OntologyCacheConfig, CachedOntologyFile
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/models/workspace.rs
LOCATION: /home/devuser/workspace/project/src/models/workspace.rs
TYPE: Rust Model
DESC: Workspace data models with types and filtering
EXPORTS: Workspace, WorkspaceType, WorkspaceStatus, WorkspaceQuery
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src/handlers/workspace_handler.rs
LOCATION: /home/devuser/workspace/project/src/handlers/workspace_handler.rs
TYPE: Rust Handler
DESC: REST API handlers for workspace CRUD operations
EXPORTS: list_workspaces, create_workspace, update_workspace, delete_workspace
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/api/exportApi.ts
LOCATION: /home/devuser/workspace/project/client/src/api/exportApi.ts
TYPE: TypeScript API
DESC: Client API for exporting, sharing, and publishing graphs
EXPORTS: exportGraph, shareGraph, publishGraph, generateEmbedCode
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/api/workspaceApi.ts
LOCATION: /home/devuser/workspace/project/client/src/api/workspaceApi.ts
TYPE: TypeScript API
DESC: Workspace API client with CRUD operations
EXPORTS: list_workspaces, create_workspace, update_workspace, Workspace
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/workspace/components/WorkspaceManager.tsx
LOCATION: /home/devuser/workspace/project/client/src/features/workspace/components/WorkspaceManager.tsx
TYPE: React Component
DESC: React component for managing workspaces
EXPORTS: WorkspaceManager
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/visualisation/components/tabs/GraphExportTab.tsx
LOCATION: /home/devuser/workspace/project/client/src/features/visualisation/components/tabs/GraphExportTab.tsx
TYPE: React Component
DESC: UI tab for exporting graphs with format selection
EXPORTS: GraphExportTab
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/utils/downloadHelpers.ts
LOCATION: /home/devuser/workspace/project/client/src/utils/downloadHelpers.ts
TYPE: TypeScript Utility
DESC: Utilities for file downloads, clipboard, and file reading
EXPORTS: downloadFile, downloadJSON, downloadCSV, copyToClipboard, formatFileSize
--------------------------------------------------------------------------------

================================================================================
                    SECTION 9: ONTOLOGY FEATURES
================================================================================

--------------------------------------------------------------------------------
FILE: client/src/features/ontology/hooks/useOntologyStore.ts
LOCATION: /home/devuser/workspace/project/client/src/features/ontology/hooks/useOntologyStore.ts
TYPE: Zustand Store
DESC: Ontology state management with classes, properties, proposals, WebSocket updates
EXPORTS: useOntologyStore, OntologyClass, OntologyProperty, OntologyProposal
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/ontology/components/OntologyContribution.tsx
LOCATION: /home/devuser/workspace/project/client/src/features/ontology/components/OntologyContribution.tsx
TYPE: React Component
DESC: Form to contribute ontology additions (class, property, annotation)
EXPORTS: OntologyContribution
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/ontology/components/OntologyProposalList.tsx
LOCATION: /home/devuser/workspace/project/client/src/features/ontology/components/OntologyProposalList.tsx
TYPE: React Component
DESC: View/manage ontology proposals with diff view and status
EXPORTS: OntologyProposalList
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: client/src/features/ontology/components/OntologyBrowser.tsx
LOCATION: /home/devuser/workspace/project/client/src/features/ontology/components/OntologyBrowser.tsx
TYPE: React Component
DESC: Tree view browser for public ontology with search and real-time updates
EXPORTS: OntologyBrowser
--------------------------------------------------------------------------------

================================================================================
                    SECTION 10: AGENT MEMORY (CLAUDE-FLOW)
================================================================================

--------------------------------------------------------------------------------
FILE: multi-agent-docker/skills/jss-memory/hooks/jss-memory-sync.js
LOCATION: /home/devuser/workspace/project/multi-agent-docker/skills/jss-memory/hooks/jss-memory-sync.js
TYPE: JavaScript Hooks
DESC: Claude-flow hooks for agent memory persistence in Solid pods
EXPORTS: pre-task, post-task, session-restore, session-end hooks
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: multi-agent-docker/schemas/agent-memory.jsonld
LOCATION: /home/devuser/workspace/project/multi-agent-docker/schemas/agent-memory.jsonld
TYPE: JSON-LD Schema
DESC: JSON-LD context defining agent memory ontology
EXPORTS: EpisodicMemory, SemanticMemory, ProceduralMemory, SessionSummary contexts
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: multi-agent-docker/skills/jss-memory/config.yaml
LOCATION: /home/devuser/workspace/project/multi-agent-docker/skills/jss-memory/config.yaml
TYPE: YAML Configuration
DESC: Skill configuration for claude-flow integration
EXPORTS: Hook registrations, memory type configs, agent type settings
--------------------------------------------------------------------------------

================================================================================
                         ARCHITECTURE OVERVIEW (MERMAID) - END
================================================================================

```mermaid
graph TD
    subgraph "Data Sources"
        A1[GitHub Repository<br/>jjohare/logseq]
        A2[JavaScript Solid Server<br/>JSS Pods]
        A3[Local Markdown Files]
    end

    subgraph "Authentication"
        B1[Nostr NIP-07<br/>Browser Extension]
        B2[NIP-98 HTTP Auth<br/>Schnorr Signatures]
        B3[Session Tokens<br/>Bearer Auth]
    end

    subgraph "Ingestion Layer"
        C1[GitHubClient<br/>api.rs]
        C2[EnhancedContentAPI<br/>content_enhanced.rs]
        C3[SolidProxyHandler<br/>solid_proxy_handler.rs]
        C4[LocalFileSyncService<br/>local_file_sync_service.rs]
    end

    subgraph "Parsing Layer"
        D1[KnowledgeGraphParser<br/>knowledge_graph_parser.rs]
        D2[OntologyParser<br/>ontology_parser.rs]
        D3[OntologyEnrichmentService<br/>ontology_enrichment_service.rs]
    end

    subgraph "Storage Layer"
        E1[(Neo4j Database)]
        E2[Neo4jGraphRepository]
        E3[Neo4jOntologyRepository]
        E4[Neo4jSettingsRepository]
    end

    subgraph "GPU Compute"
        F1[GPUManagerActor]
        F2[ForceComputeActor]
        F3[ClusteringActor]
        F4[SemanticForcesActor]
        F5[UnifiedGPUCompute]
        F6[CUDA Kernels<br/>*.cu files]
    end

    subgraph "Real-time Broadcast"
        G1[SocketFlowHandler<br/>Binary Protocol V4]
        G2[RealtimeWebSocketHandler]
        G3[JssWebSocketBridge<br/>solid-0.1 protocol]
        G4[SettingsBroadcast]
    end

    subgraph "Client Application"
        H1[WebSocketService.ts]
        H2[BinaryWebSocketProtocol.ts]
        H3[settingsStore.ts<br/>Zustand]
        H4[SolidPodService.ts]
        H5[nostrAuthService.ts]
        H6[Three.js Renderer]
    end

    subgraph "Export & Federation"
        I1[GraphExportHandler<br/>JSON/GEXF/GraphML]
        I2[JssSyncService<br/>Turtle/RDF]
        I3[WorkspaceHandler]
    end

    %% Data Source Connections
    A1 --> C1
    A1 --> C2
    A2 --> C3
    A3 --> C4

    %% Auth Flow
    B1 --> B2
    B2 --> B3
    B3 --> C3
    B3 --> E4

    %% Ingestion to Parsing
    C1 --> D1
    C2 --> D2
    C3 --> D3
    C4 --> D1

    %% Parsing to Storage
    D1 --> E2
    D2 --> E3
    D3 --> E3
    E2 --> E1
    E3 --> E1
    E4 --> E1

    %% Storage to GPU
    E1 --> F1
    F1 --> F2
    F1 --> F3
    F1 --> F4
    F2 --> F5
    F3 --> F5
    F4 --> F5
    F5 --> F6

    %% GPU to Broadcast
    F5 --> G1
    F5 --> G2
    E1 --> G4
    A2 --> G3

    %% Broadcast to Client
    G1 --> H1
    G2 --> H1
    G3 --> H1
    G4 --> H3
    H1 --> H2
    H2 --> H6
    H1 --> H4
    B1 --> H5
    H5 --> H1

    %% Export Paths
    E1 --> I1
    E1 --> I2
    E1 --> I3
    I2 --> A2
```

```mermaid
flowchart LR
    subgraph INPUT["Input Sources"]
        GH["GitHub<br/>Markdown+Ontology"]
        SOLID["Solid Pods<br/>JSON-LD/Turtle"]
        LOCAL["Local Files<br/>Markdown"]
    end

    subgraph PROCESS["Processing Pipeline"]
        PARSE["Parse<br/>KG + Ontology"]
        ENRICH["Enrich<br/>OWL Classes"]
        STORE["Store<br/>Neo4j"]
    end

    subgraph COMPUTE["GPU Pipeline"]
        PHYSICS["Physics<br/>Force-Directed"]
        CLUSTER["Clustering<br/>Louvain/LP"]
        PATH["Pathfinding<br/>SSSP/APSP"]
    end

    subgraph OUTPUT["Output Channels"]
        BINARY["Binary WS<br/>36 bytes/node"]
        REALTIME["Realtime WS<br/>Events/Progress"]
        EXPORT["Export<br/>GEXF/GraphML"]
    end

    subgraph CLIENT["Client Rendering"]
        DECODE["Decode<br/>Binary Protocol"]
        THREEJS["Three.js<br/>WebGL"]
        UI["React UI<br/>Controls"]
    end

    GH --> PARSE
    SOLID --> PARSE
    LOCAL --> PARSE

    PARSE --> ENRICH
    ENRICH --> STORE

    STORE --> PHYSICS
    STORE --> CLUSTER
    STORE --> PATH

    PHYSICS --> BINARY
    CLUSTER --> REALTIME
    STORE --> EXPORT

    BINARY --> DECODE
    REALTIME --> UI
    DECODE --> THREEJS
```

================================================================================
                    SECTION 11: VERBATIM SOURCE CODE - BINARY PROTOCOL
================================================================================

--------------------------------------------------------------------------------
cat client/src/types/binaryProtocol.ts
LOCATION: /home/devuser/workspace/project/client/src/types/binaryProtocol.ts
LINES: 183
LANGUAGE: TypeScript
DESC: Binary protocol type definitions with 36-byte node format, V2 parsing, type flags
--------------------------------------------------------------------------------


export interface Vec3 {
  x: number;
  y: number;
  z: number;
}

export interface BinaryNodeData {
  nodeId: number;
  position: Vec3;
  velocity: Vec3;
  ssspDistance: number;
  ssspParent: number;
}


export const BINARY_NODE_SIZE = 36;
export const BINARY_NODE_ID_OFFSET = 0;
export const BINARY_POSITION_OFFSET = 4;
export const BINARY_VELOCITY_OFFSET = 16;
export const BINARY_SSSP_DISTANCE_OFFSET = 28;
export const BINARY_SSSP_PARENT_OFFSET = 32;

// Node type flag constants (Protocol V2 - must match server)
export const AGENT_NODE_FLAG = 0x80000000;
export const KNOWLEDGE_NODE_FLAG = 0x40000000;
export const NODE_ID_MASK = 0x3FFFFFFF;

export enum NodeType {
  Knowledge = 'knowledge',
  Agent = 'agent',
  Unknown = 'unknown'
}

export function getNodeType(nodeId: number): NodeType {
  if ((nodeId & AGENT_NODE_FLAG) !== 0) {
    return NodeType.Agent;
  } else if ((nodeId & KNOWLEDGE_NODE_FLAG) !== 0) {
    return NodeType.Knowledge;
  }
  return NodeType.Unknown;
}

export function getActualNodeId(nodeId: number): number {
  return nodeId & NODE_ID_MASK;
}

export function isAgentNode(nodeId: number): boolean {
  return (nodeId & AGENT_NODE_FLAG) !== 0;
}

export function isKnowledgeNode(nodeId: number): boolean {
  return (nodeId & KNOWLEDGE_NODE_FLAG) !== 0;
}


export function parseBinaryNodeData(buffer: ArrayBuffer): BinaryNodeData[] {
  if (!buffer || buffer.byteLength === 0) {
    return [];
  }


  const safeBuffer = buffer.slice(0);
  const view = new DataView(safeBuffer);
  const nodes: BinaryNodeData[] = [];

  try {

    let offset = 0;
    const nodeSize = BINARY_NODE_SIZE;

    if (safeBuffer.byteLength > 0) {
      const firstByte = view.getUint8(0);


      if (firstByte === 2) {
        offset = 1;
      } else if (firstByte === 1) {
        console.error('PROTOCOL_V1 is no longer supported. Please upgrade to V2.');
        return [];
      }
    }

    const dataLength = safeBuffer.byteLength - offset;


    if (dataLength % nodeSize !== 0) {
      console.warn(`Binary data length (${dataLength} bytes after version byte) is not a multiple of ${nodeSize}. This may indicate compressed data.`);
      console.warn(`First few bytes: ${new Uint8Array(safeBuffer.slice(0, Math.min(16, safeBuffer.byteLength))).join(', ')}`);


      const header = new Uint8Array(safeBuffer.slice(0, Math.min(4, safeBuffer.byteLength)));
      if (header[0] === 0x78 && (header[1] === 0x01 || header[1] === 0x5E || header[1] === 0x9C || header[1] === 0xDA)) {
        console.error("Data appears to be zlib compressed but decompression failed or wasn't attempted");
      }
    }


    const completeNodes = Math.floor(dataLength / nodeSize);

    if (completeNodes === 0) {
      console.warn(`Received binary data with insufficient length: ${dataLength} bytes (needed at least ${nodeSize} bytes per node)`);
      return [];
    }


    for (let i = 0; i < completeNodes; i++) {
      const nodeOffset = offset + (i * nodeSize);


      if (nodeOffset + nodeSize > safeBuffer.byteLength) {
        break;
      }


      const nodeId = view.getUint32(nodeOffset + BINARY_NODE_ID_OFFSET, true);
      const position: Vec3 = {
        x: view.getFloat32(nodeOffset + BINARY_POSITION_OFFSET, true),
        y: view.getFloat32(nodeOffset + BINARY_POSITION_OFFSET + 4, true),
        z: view.getFloat32(nodeOffset + BINARY_POSITION_OFFSET + 8, true)
      };
      const velocity: Vec3 = {
        x: view.getFloat32(nodeOffset + BINARY_VELOCITY_OFFSET, true),
        y: view.getFloat32(nodeOffset + BINARY_VELOCITY_OFFSET + 4, true),
        z: view.getFloat32(nodeOffset + BINARY_VELOCITY_OFFSET + 8, true)
      };
      const ssspDistance = view.getFloat32(nodeOffset + BINARY_SSSP_DISTANCE_OFFSET, true);
      const ssspParent = view.getInt32(nodeOffset + BINARY_SSSP_PARENT_OFFSET, true);


      const isValid =
        !isNaN(position.x) && isFinite(position.x) &&
        !isNaN(position.y) && isFinite(position.y) &&
        !isNaN(position.z) && isFinite(position.z) &&
        !isNaN(velocity.x) && isFinite(velocity.x) &&
        !isNaN(velocity.y) && isFinite(velocity.y) &&
        !isNaN(velocity.z) && isFinite(velocity.z);

      if (isValid) {
        nodes.push({ nodeId, position, velocity, ssspDistance, ssspParent });
      } else {
        console.warn(`Skipping corrupted node data at offset ${offset} (nodeId: ${nodeId})`);
      }
    }
  } catch (error) {
    console.error('Error parsing binary data:', error);

  }

  return nodes;
}


export function createBinaryNodeData(nodes: BinaryNodeData[]): ArrayBuffer {
  const buffer = new ArrayBuffer(nodes.length * BINARY_NODE_SIZE);
  const view = new DataView(buffer);

  nodes.forEach((node, i) => {
    const offset = i * BINARY_NODE_SIZE;


    view.setUint32(offset + BINARY_NODE_ID_OFFSET, node.nodeId, true);


    view.setFloat32(offset + BINARY_POSITION_OFFSET, node.position.x, true);
    view.setFloat32(offset + BINARY_POSITION_OFFSET + 4, node.position.y, true);
    view.setFloat32(offset + BINARY_POSITION_OFFSET + 8, node.position.z, true);


    view.setFloat32(offset + BINARY_VELOCITY_OFFSET, node.velocity.x, true);
    view.setFloat32(offset + BINARY_VELOCITY_OFFSET + 4, node.velocity.y, true);
    view.setFloat32(offset + BINARY_VELOCITY_OFFSET + 8, node.velocity.z, true);


    view.setFloat32(offset + BINARY_SSSP_DISTANCE_OFFSET, node.ssspDistance || Infinity, true);


    view.setInt32(offset + BINARY_SSSP_PARENT_OFFSET, node.ssspParent || -1, true);
  });

  return buffer;
}

--------------------------------------------------------------------------------
                         END SECTION 11: binaryProtocol.ts
--------------------------------------------------------------------------------

================================================================================
                    SECTION 12: VERBATIM SOURCE CODE - GRAPH DATA MANAGER
================================================================================

--------------------------------------------------------------------------------
cat client/src/features/graph/managers/graphDataManager.ts
LOCATION: /home/devuser/workspace/project/client/src/features/graph/managers/graphDataManager.ts
LINES: 695
LANGUAGE: TypeScript
DESC: Singleton graph data manager with worker proxy, binary position updates, node ID mapping
--------------------------------------------------------------------------------

import { createLogger, createErrorMetadata } from '../../../utils/loggerConfig';
import { debugState, clientDebugState } from '../../../utils/clientDebugState';
import { unifiedApiClient } from '../../../services/api/UnifiedApiClient';
import { WebSocketAdapter } from '../../../services/WebSocketService';
import { useSettingsStore } from '../../../store/settingsStore';
import { BinaryNodeData, parseBinaryNodeData, createBinaryNodeData, Vec3, BINARY_NODE_SIZE } from '../../../types/binaryProtocol';
import { graphWorkerProxy } from './graphWorkerProxy';
import type { GraphData, Node, Edge } from './graphWorkerProxy';
import { startTransition } from 'react';

const logger = createLogger('GraphDataManager');

// Re-export types from worker proxy for compatibility
export type { Node, Edge, GraphData } from './graphWorkerProxy';

// Alias for backward compatibility
export type GraphNode = Node;

type GraphDataChangeListener = (data: GraphData) => void;
type PositionUpdateListener = (positions: Float32Array) => void;

class GraphDataManager {
  private static instance: GraphDataManager;
  private binaryUpdatesEnabled: boolean = false;
  public webSocketService: WebSocketAdapter | null = null;
  private graphDataListeners: GraphDataChangeListener[] = [];
  private positionUpdateListeners: PositionUpdateListener[] = [];
  private lastBinaryUpdateTime: number = 0;
  private retryTimeout: number | null = null;
  public nodeIdMap: Map<string, number> = new Map();
  private reverseNodeIdMap: Map<number, string> = new Map();
  private workerInitialized: boolean = false;
  private graphType: 'logseq' | 'visionflow' = 'logseq';
  private isUserInteracting: boolean = false;
  private interactionTimeoutRef: number | null = null;
  private updateCount: number = 0;

  private constructor() {

    this.waitForWorker();
  }

  private async waitForWorker(): Promise<void> {
    try {
      console.log('[GraphDataManager] Waiting for worker to be ready...');
      let attempts = 0;
      const maxAttempts = 50;


      while (!graphWorkerProxy.isReady() && attempts < maxAttempts) {
        await new Promise(resolve => setTimeout(resolve, 10));
        attempts++;
      }

      if (!graphWorkerProxy.isReady()) {
        console.warn('[GraphDataManager] Worker not ready after timeout, continuing without worker');
        logger.warn('Graph worker proxy not ready after timeout, proceeding without worker');
        this.workerInitialized = false;
        return;
      }

      this.workerInitialized = true;
      console.log('[GraphDataManager] Worker is ready!');


      this.setupWorkerListeners();

      if (debugState.isEnabled()) {
        logger.info('Graph worker proxy is ready');
      }
    } catch (error) {
      console.error('[GraphDataManager] Failed to wait for worker:', error);
      logger.error('Failed to wait for graph worker proxy:', createErrorMetadata(error));
      this.workerInitialized = false;
    }
  }

  private setupWorkerListeners(): void {

    graphWorkerProxy.onGraphDataChange((data) => {
      this.graphDataListeners.forEach(listener => {
        try {
          startTransition(() => {
            listener(data);
          });
        } catch (error) {
          logger.error('Error in forwarded graph data listener:', createErrorMetadata(error));
        }
      });
    });


    graphWorkerProxy.onPositionUpdate((positions) => {
      this.positionUpdateListeners.forEach(listener => {
        try {
          listener(positions);
        } catch (error) {
          logger.error('Error in forwarded position update listener:', createErrorMetadata(error));
        }
      });
    });
  }

  public static getInstance(): GraphDataManager {
    if (!GraphDataManager.instance) {
      GraphDataManager.instance = new GraphDataManager();
    }
    return GraphDataManager.instance;
  }


  public setWebSocketService(service: WebSocketAdapter): void {
    this.webSocketService = service;
    if (debugState.isDataDebugEnabled()) {
      logger.debug('WebSocket service set');
    }
  }


  public setGraphType(type: 'logseq' | 'visionflow'): void {
    this.graphType = type;
    if (debugState.isEnabled()) {
      logger.info(`Graph type set to: ${type}`);
    }
  }


  public getGraphType(): 'logseq' | 'visionflow' {
    return this.graphType;
  }



  public async fetchInitialData(): Promise<GraphData> {
    const maxRetries = 5;
    const initialDelay = 1000;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`[GraphDataManager] Fetching initial ${this.graphType} graph data with physics positions (Attempt ${attempt}/${maxRetries})`);
        if (debugState.isEnabled()) {
          logger.info(`Fetching initial ${this.graphType} graph data with physics positions (Attempt ${attempt}/${maxRetries})`);
        }

        const response = await unifiedApiClient.get('/graph/data');
        console.log(`[GraphDataManager] API response status: ${response.status}`);

        // Handle response structure: { success: true, data: { nodes: [], edges: [] } }
        const responseData = response.data.data || response.data;

        if (!responseData || typeof responseData !== 'object') {
          throw new Error('Invalid graph data format: data is not an object');
        }

        const nodes = Array.isArray(responseData.nodes) ? responseData.nodes : [];
        const edges = Array.isArray(responseData.edges) ? responseData.edges : [];
        const metadata = responseData.metadata || {};
        const settlementState = responseData.settlementState || { isSettled: false, stableFrameCount: 0, kineticEnergy: 0 };

        console.log(`[GraphDataManager] Received settlement state: settled=${settlementState.isSettled}, frames=${settlementState.stableFrameCount}, KE=${settlementState.kineticEnergy}`);



        const enrichedNodes = nodes.map((node: Node) => {
          const nodeAny = node as any;
          const nodeMetadata = metadata[nodeAny.metadata_id || nodeAny.metadataId];
          if (nodeMetadata) {
            return { ...node, metadata: { ...node.metadata, ...nodeMetadata } };
          }
          return node;
        });

        const validatedData = { nodes: enrichedNodes, edges };

        if (debugState.isEnabled()) {
          logger.info(`Received initial graph data: ${validatedData.nodes.length} nodes, ${validatedData.edges.length} edges (physics settled: ${settlementState.isSettled})`);
        }

        console.log(`[GraphDataManager] Setting validated graph data with ${validatedData.nodes.length} nodes at physics-settled positions`);
        await this.setGraphData(validatedData);

        const currentData = await graphWorkerProxy.getGraphData();
        console.log(`[GraphDataManager] Worker returned data with ${currentData.nodes.length} nodes - no position "pop-in" expected!`);
        return currentData;

      } catch (error) {
        logger.error(`Attempt ${attempt} failed to fetch initial graph data:`, createErrorMetadata(error));
        if (attempt === maxRetries) {
          logger.error('All attempts to fetch initial graph data failed.');
          throw error;
        }

        const delay = initialDelay * Math.pow(2, attempt - 1);
        console.log(`[GraphDataManager] Retrying in ${delay}ms...`);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }


    return { nodes: [], edges: [] };
  }


  public async setGraphData(data: GraphData): Promise<void> {
    if (debugState.isEnabled()) {
      logger.info(`Setting ${this.graphType} graph data: ${data.nodes.length} nodes, ${data.edges.length} edges`);
    }


    let validatedData = data;
    if (data && data.nodes) {
      const validatedNodes = data.nodes.map(node => this.ensureNodeHasValidPosition(node));
      validatedData = {
        ...data,
        nodes: validatedNodes
      };

      if (debugState.isEnabled()) {
        logger.info(`Validated ${validatedNodes.length} nodes with positions`);
      }
    } else {

      validatedData = { nodes: [], edges: data?.edges || [] };
      logger.warn('Initialized with empty graph data');
    }


    this.nodeIdMap.clear();
    this.reverseNodeIdMap.clear();


    validatedData.nodes.forEach((node, index) => {
      const numericId = parseInt(node.id, 10);
      if (!isNaN(numericId) && numericId >= 0 && numericId <= 0xFFFFFFFF) {

        this.nodeIdMap.set(node.id, numericId);
        this.reverseNodeIdMap.set(numericId, node.id);
      } else {


        const mappedId = index + 1;
        this.nodeIdMap.set(node.id, mappedId);
        this.reverseNodeIdMap.set(mappedId, node.id);
      }
    });


    await graphWorkerProxy.setGraphData(validatedData);

    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Graph data updated: ${validatedData.nodes.length} nodes, ${validatedData.edges.length} edges`);
    }
  }


  private validateNodeMappings(nodes: Node[]): void {
    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Validated ${nodes.length} nodes with ID mapping`);
    }
  }


  public enableBinaryUpdates(): void {
    if (!this.webSocketService) {
      logger.warn('Cannot enable binary updates: WebSocket service not set');
      return;
    }


    if (this.webSocketService.isReady()) {
      this.setBinaryUpdatesEnabled(true);
      return;
    }


    if (this.retryTimeout) {
      window.clearTimeout(this.retryTimeout);
    }

    this.retryTimeout = window.setTimeout(() => {
      if (this.webSocketService && this.webSocketService.isReady()) {
        this.setBinaryUpdatesEnabled(true);
        if (debugState.isEnabled()) {
          logger.info('WebSocket ready, binary updates enabled');
        }
      } else {
        if (debugState.isEnabled()) {
          logger.info('WebSocket not ready yet, retrying...');
        }
        this.enableBinaryUpdates();
      }
    }, 500);
  }

  public setBinaryUpdatesEnabled(enabled: boolean): void {
    this.binaryUpdatesEnabled = enabled;

    if (debugState.isEnabled()) {
      logger.info(`Binary updates ${enabled ? 'enabled' : 'disabled'}`);
    }
  }


  public async getGraphData(): Promise<GraphData> {
    if (!this.workerInitialized) {
      console.warn('[GraphDataManager] Worker not initialized, returning empty data');
      return { nodes: [], edges: [] };
    }
    try {
      return await graphWorkerProxy.getGraphData();
    } catch (error) {
      console.error('[GraphDataManager] Error getting data from worker:', error);
      logger.error('Error getting graph data from worker:', createErrorMetadata(error));
      return { nodes: [], edges: [] };
    }
  }


  public async addNode(node: Node): Promise<void> {

    const numericId = parseInt(node.id, 10);
    if (!isNaN(numericId)) {
      this.nodeIdMap.set(node.id, numericId);
      this.reverseNodeIdMap.set(numericId, node.id);
    } else {

      const currentData = await graphWorkerProxy.getGraphData();
      const mappedId = currentData.nodes.length + 1;
      this.nodeIdMap.set(node.id, mappedId);
      this.reverseNodeIdMap.set(mappedId, node.id);
    }

    await graphWorkerProxy.updateNode(node);
  }


  public async addEdge(edge: Edge): Promise<void> {

    const currentData = await graphWorkerProxy.getGraphData();
    const existingIndex = currentData.edges.findIndex(e => e.id === edge.id);

    if (existingIndex >= 0) {
      currentData.edges[existingIndex] = {
        ...currentData.edges[existingIndex],
        ...edge
      };
    } else {
      currentData.edges.push(edge);
    }

    await graphWorkerProxy.setGraphData(currentData);
  }


  public async removeNode(nodeId: string): Promise<void> {

    const numericId = this.nodeIdMap.get(nodeId);

    await graphWorkerProxy.removeNode(nodeId);


    if (numericId !== undefined) {
      this.nodeIdMap.delete(nodeId);
      this.reverseNodeIdMap.delete(numericId);
    }
  }


  public async removeEdge(edgeId: string): Promise<void> {

    const currentData = await graphWorkerProxy.getGraphData();
    currentData.edges = currentData.edges.filter(edge => edge.id !== edgeId);
    await graphWorkerProxy.setGraphData(currentData);
  }


  public async updateNodePositions(positionData: ArrayBuffer): Promise<void> {

    this.updateCount = (this.updateCount || 0) + 1;
    if (this.updateCount % 100 === 1) {
      console.log('[GraphDataManager] updateNodePositions called, size:', positionData?.byteLength, 'graph type:', this.graphType, 'count:', this.updateCount);
    }

    if (!positionData || positionData.byteLength === 0) {
      if (this.updateCount % 100 === 1) {
        console.log('[GraphDataManager] No position data, returning');
      }
      return;
    }


    if (this.graphType !== 'logseq') {
      if (this.updateCount % 100 === 1) {
        console.log('[GraphDataManager] Skipping - not logseq graph, type is:', this.graphType);
      }
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Skipping binary update for ${this.graphType} graph`);
      }
      return;
    }


    const now = Date.now();
    if (now - this.lastBinaryUpdateTime < 16) {
      if (debugState.isDataDebugEnabled()) {
        logger.debug('Skipping duplicate position update');
      }
      return;
    }
    this.lastBinaryUpdateTime = now;

    try {

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Received binary data: ${positionData.byteLength} bytes`);


        const remainder = positionData.byteLength % BINARY_NODE_SIZE;
        if (remainder !== 0) {
          logger.warn(`Binary data size (${positionData.byteLength} bytes) is not a multiple of ${BINARY_NODE_SIZE}. Remainder: ${remainder} bytes`);
        }
      }


      if (this.updateCount % 100 === 1) {
        console.log('[GraphDataManager] Sending to worker proxy for processing');
      }
      await graphWorkerProxy.processBinaryData(positionData);
      if (this.updateCount % 100 === 1) {
        console.log('[GraphDataManager] Worker proxy processing complete');
      }


      const settings = useSettingsStore.getState().settings;
      const debugEnabled = settings?.system?.debug?.enabled;
      const physicsDebugEnabled = (settings?.system?.debug as any)?.enablePhysicsDebug;
      const nodeDebugEnabled = (settings?.system?.debug as any)?.enableNodeDebug;

      if (debugEnabled && (physicsDebugEnabled || nodeDebugEnabled)) {
        const view = new DataView(positionData);
        const nodeCount = Math.min(3, positionData.byteLength / BINARY_NODE_SIZE);
        for (let i = 0; i < nodeCount; i++) {
          const offset = i * BINARY_NODE_SIZE;
          const x = view.getFloat32(offset + 4, true);
          const y = view.getFloat32(offset + 8, true);
          const z = view.getFloat32(offset + 12, true);
          logger.info(`[Physics Debug] Node ${i}: position(${x.toFixed(2)}, ${y.toFixed(2)}, ${z.toFixed(2)})`);
        }
      }

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Processed binary data through worker`);
      }
    } catch (error) {
      logger.error('Error processing binary position data:', createErrorMetadata(error));


      if (debugState.isEnabled()) {
        try {

          const view = new DataView(positionData);
          const byteArray = [];
          const maxBytesToShow = Math.min(64, positionData.byteLength);

          for (let i = 0; i < maxBytesToShow; i++) {
            byteArray.push(view.getUint8(i).toString(16).padStart(2, '0'));
          }

          logger.debug(`First ${maxBytesToShow} bytes of binary data: ${byteArray.join(' ')}${positionData.byteLength > maxBytesToShow ? '...' : ''}`);
        } catch (e) {
          logger.debug('Could not display binary data preview:', e);
        }
      }
    }
  }



  public async sendNodePositions(): Promise<void> {
    if (!this.binaryUpdatesEnabled || !this.webSocketService || !this.isUserInteracting) {
      return;
    }

    try {

      const currentData = await graphWorkerProxy.getGraphData();


      const binaryNodes: BinaryNodeData[] = currentData.nodes
        .filter(node => node && node.id)
        .map(node => {

          const validatedNode = this.ensureNodeHasValidPosition(node);


          const numericId = this.nodeIdMap.get(validatedNode.id) || 0;
          if (numericId === 0) {
            logger.warn(`No numeric ID found for node ${validatedNode.id}, skipping`);
            return null;
          }


          const velocity: Vec3 = (validatedNode.metadata?.velocity as Vec3) || { x: 0, y: 0, z: 0 };

          return {
            nodeId: numericId,
            position: {
              x: validatedNode.position.x || 0,
              y: validatedNode.position.y || 0,
              z: validatedNode.position.z || 0
            },
            velocity
          };
        })
        .filter((node): node is BinaryNodeData => node !== null);


      const buffer = createBinaryNodeData(binaryNodes);


      this.webSocketService.send(buffer);

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Sent positions for ${binaryNodes.length} nodes using binary protocol`);
      }
    } catch (error) {
      logger.error('Error sending node positions:', createErrorMetadata(error));
    }
  }


  public onGraphDataChange(listener: GraphDataChangeListener): () => void {
    console.log('[GraphDataManager] Adding graph data change listener');
    this.graphDataListeners.push(listener);


    console.log('[GraphDataManager] Getting current data for new listener');
    graphWorkerProxy.getGraphData().then(data => {
      console.log(`[GraphDataManager] Calling listener with current data: ${data.nodes.length} nodes`);
      listener(data);
    }).catch(error => {
      console.error('[GraphDataManager] Error getting initial graph data for listener:', error);
      logger.error('Error getting initial graph data for listener:', createErrorMetadata(error));

      listener({ nodes: [], edges: [] });
    });


    return () => {
      console.log('[GraphDataManager] Removing graph data change listener');
      this.graphDataListeners = this.graphDataListeners.filter(l => l !== listener);
    };
  }


  public onPositionUpdate(listener: PositionUpdateListener): () => void {
    this.positionUpdateListeners.push(listener);


    return () => {
      this.positionUpdateListeners = this.positionUpdateListeners.filter(l => l !== listener);
    };
  }


  private async notifyGraphDataListeners(): Promise<void> {
    try {
      const currentData = await graphWorkerProxy.getGraphData();
      this.graphDataListeners.forEach(listener => {
        try {
          listener(currentData);
        } catch (error) {
          logger.error('Error in graph data listener:', createErrorMetadata(error));
        }
      });
    } catch (error) {
      logger.error('Error getting graph data for listeners:', createErrorMetadata(error));
    }
  }


  private notifyPositionUpdateListeners(positions: Float32Array): void {
    this.positionUpdateListeners.forEach(listener => {
      try {
        listener(positions);
      } catch (error) {
        logger.error('Error in position update listener:', createErrorMetadata(error));
      }
    });
  }


  public ensureNodeHasValidPosition(node: Node): Node {
    if (!node.position) {

      console.warn(`[GraphDataManager] Node ${node.id} missing position - server should provide this!`);
      return {
        ...node,
        position: { x: 0, y: 0, z: 0 }
      };
    } else if (typeof node.position.x !== 'number' ||
               typeof node.position.y !== 'number' ||
               typeof node.position.z !== 'number') {

      console.warn(`[GraphDataManager] Node ${node.id} has invalid position coordinates - fixing`);
      node.position.x = typeof node.position.x === 'number' && isFinite(node.position.x) ? node.position.x : 0;
      node.position.y = typeof node.position.y === 'number' && isFinite(node.position.y) ? node.position.y : 0;
      node.position.z = typeof node.position.z === 'number' && isFinite(node.position.z) ? node.position.z : 0;
    }
    return node;
  }


  public subscribeToUpdates(listener: GraphDataChangeListener): () => void {
    return this.onGraphDataChange(listener);
  }


  public getVisibleNodes(): Node[] {

    let nodes: Node[] = [];
    graphWorkerProxy.getGraphData().then(data => {
      nodes = data.nodes;
    }).catch(error => {
      logger.error('Error getting visible nodes:', createErrorMetadata(error));
    });
    return nodes;
  }


  public setUserInteracting(isInteracting: boolean): void {
    if (this.isUserInteracting === isInteracting) {
      return;
    }

    this.isUserInteracting = isInteracting;

    if (isInteracting) {

      if (this.interactionTimeoutRef) {
        window.clearTimeout(this.interactionTimeoutRef);
        this.interactionTimeoutRef = null;
      }

      if (debugState.isEnabled()) {
        logger.debug('User interaction started - WebSocket position updates enabled');
      }
    } else {


      this.interactionTimeoutRef = window.setTimeout(() => {
        this.isUserInteracting = false;
        this.interactionTimeoutRef = null;

        if (debugState.isEnabled()) {
          logger.debug('User interaction ended - WebSocket position updates disabled');
        }
      }, 200);
    }
  }


  public isUserCurrentlyInteracting(): boolean {
    return this.isUserInteracting;
  }


  public dispose(): void {
    if (this.retryTimeout) {
      window.clearTimeout(this.retryTimeout);
      this.retryTimeout = null;
    }

    if (this.interactionTimeoutRef) {
      window.clearTimeout(this.interactionTimeoutRef);
      this.interactionTimeoutRef = null;
    }

    this.graphDataListeners = [];
    this.positionUpdateListeners = [];
    this.webSocketService = null;
    this.nodeIdMap.clear();
    this.reverseNodeIdMap.clear();
    this.isUserInteracting = false;

    if (debugState.isEnabled()) {
      logger.info('GraphDataManager disposed');
    }
  }
}

// Create singleton instance
export const graphDataManager = GraphDataManager.getInstance();


--------------------------------------------------------------------------------
                         END SECTION 12: graphDataManager.ts
--------------------------------------------------------------------------------

================================================================================
                    SECTION 13: VERBATIM SOURCE CODE - WEBSOCKET SERVICE
================================================================================

--------------------------------------------------------------------------------
cat client/src/services/WebSocketService.ts
LOCATION: /home/devuser/workspace/project/client/src/services/WebSocketService.ts
LINES: 1673
LANGUAGE: TypeScript
DESC: Main WebSocket client singleton with binary protocol, Solid notifications, filter sync
--------------------------------------------------------------------------------

import { createLogger } from '../utils/loggerConfig';
import { createErrorMetadata } from '../utils/loggerConfig';
import { debugState } from '../utils/clientDebugState';
import { useSettingsStore } from '../store/settingsStore';
import { graphDataManager } from '../features/graph/managers/graphDataManager';
import { parseBinaryNodeData, isAgentNode, createBinaryNodeData, BinaryNodeData } from '../types/binaryProtocol';
import { NodePositionBatchQueue, createWebSocketBatchProcessor } from '../utils/BatchQueue';
import { validateNodePositions, createValidationMiddleware } from '../utils/validation';
import {
  WebSocketMessage,
  WebSocketEventHandlers,
  WebSocketConfig,
  WebSocketConnectionState,
  WebSocketError,
  WebSocketStatistics,
  Subscription,
  SubscriptionFilters,
  MessageHandler
} from '../types/websocketTypes';
import { binaryProtocol, MessageType, GraphTypeFlag } from './BinaryWebSocketProtocol';
import { nostrAuth } from './nostrAuthService';

const logger = createLogger('WebSocketService');

export interface WebSocketAdapter {
  send: (data: ArrayBuffer) => void;
  isReady: () => boolean;
}

// Legacy interface for backward compatibility
export interface LegacyWebSocketMessage {
  type: string;
  data?: any;
  error?: WebSocketErrorFrame;
}

export interface WebSocketErrorFrame {
  code: string;
  message: string;
  category: 'validation' | 'server' | 'protocol' | 'auth' | 'rate_limit';
  details?: any;
  retryable: boolean;
  retryAfter?: number;
  affectedPaths?: string[];
  timestamp: number;
}

export interface QueuedMessage {
  type: 'text' | 'binary';
  data: string | ArrayBuffer;
  timestamp: number;
  retries: number;
}

// Legacy interface - replaced by WebSocketConnectionState from websocketTypes
export interface ConnectionState {
  status: 'disconnected' | 'connecting' | 'connected' | 'reconnecting' | 'failed';
  lastConnected?: number;
  lastError?: string;
  reconnectAttempts: number;
}

// Solid notification types (solid-0.1 protocol)
export interface SolidNotification {
  type: 'pub' | 'ack';
  url: string;
}

export type SolidNotificationCallback = (notification: SolidNotification) => void;

// Legacy types for backward compatibility
type LegacyMessageHandler = (message: LegacyWebSocketMessage) => void;
type BinaryMessageHandler = (data: ArrayBuffer) => void;
type ConnectionStatusHandler = (connected: boolean) => void;
type ConnectionStateHandler = (state: ConnectionState) => void;
type EventHandler = (data: any) => void;

class WebSocketService {
  private static instance: WebSocketService;
  private socket: WebSocket | null = null;
  private messageHandlers: LegacyMessageHandler[] = [];
  private binaryMessageHandlers: BinaryMessageHandler[] = [];
  private connectionStatusHandlers: ConnectionStatusHandler[] = [];
  private eventHandlers: Map<string, EventHandler[]> = new Map();


  private subscriptions: Map<string, Subscription> = new Map();
  private subscriptionCounter: number = 0;
  private statistics: WebSocketStatistics;
  private config: WebSocketConfig;
  private reconnectInterval: number = 1000;
  private maxReconnectAttempts: number = 10;
  private reconnectAttempts: number = 0;
  private maxReconnectDelay: number = 30000;
  private reconnectTimeout: number | null = null;
  private isConnected: boolean = false;
  private isServerReady: boolean = false;
  private url: string;
  private messageQueue: QueuedMessage[] = [];
  private maxQueueSize: number = 100;
  private heartbeatInterval: number | null = null;
  private heartbeatTimeout: number | null = null;
  private heartbeatIntervalMs: number = 30000;
  private heartbeatTimeoutMs: number = 10000;
  private connectionState: ConnectionState = {
    status: 'disconnected',
    reconnectAttempts: 0
  };
  private connectionStateHandlers: ConnectionStateHandler[] = [];
  private positionBatchQueue: NodePositionBatchQueue | null = null;
  private binaryMessageCount: number = 0;

  // JSS/Solid WebSocket for notifications (solid-0.1 protocol)
  private solidSocket: WebSocket | null = null;
  private solidSubscriptions: Map<string, Set<SolidNotificationCallback>> = new Map();
  private solidReconnectAttempts: number = 0;
  private solidMaxReconnectAttempts: number = 5;
  private solidReconnectDelay: number = 1000;
  private solidReconnectTimeout: number | null = null;
  private isSolidConnected: boolean = false;


  private enhancedConnectionState: WebSocketConnectionState = {
    status: 'disconnected',
    reconnectAttempts: 0,
    serverFeatures: []
  };

  private constructor() {

    this.statistics = {
      messagesReceived: 0,
      messagesSent: 0,
      bytesReceived: 0,
      bytesSent: 0,
      connectionTime: 0,
      reconnections: 0,
      averageLatency: 0,
      messagesByType: {},
      errors: 0,
      lastActivity: Date.now()
    };


    this.config = {
      reconnect: {
        maxAttempts: 10,
        baseDelay: 1000,
        maxDelay: 30000,
        backoffFactor: 2
      },
      heartbeat: {
        interval: 30000,
        timeout: 10000
      },
      compression: true,
      binaryProtocol: true
    };


    this.url = this.determineWebSocketUrl();


    this.updateFromSettings();


    let previousCustomBackendUrl = useSettingsStore.getState().settings?.system?.customBackendUrl;
    useSettingsStore.subscribe((state) => {
      const newCustomBackendUrl = state.settings?.system?.customBackendUrl;
      if (newCustomBackendUrl !== previousCustomBackendUrl) {
        if (debugState.isEnabled()) {
          logger.info(`customBackendUrl setting changed from "${previousCustomBackendUrl}" to "${newCustomBackendUrl}", re-evaluating WebSocket URL.`);
        }
        previousCustomBackendUrl = newCustomBackendUrl;
        this.updateFromSettings();
        if (this.isConnected || (this.socket && this.socket.readyState === WebSocket.CONNECTING)) {
          logger.info('Reconnecting WebSocket due to customBackendUrl change.');
          this.close();
          setTimeout(() => {
            this.connect().catch(error => {
              logger.error('Failed to reconnect WebSocket after URL change:', createErrorMetadata(error));
            });
          }, 100);
        }
      }
    });
  }

  // ... [Rest of WebSocketService implementation - 1500+ lines]
  // See full source at: client/src/services/WebSocketService.ts

  public static getInstance(): WebSocketService {
    if (!WebSocketService.instance) {
      WebSocketService.instance = new WebSocketService();
    }
    return WebSocketService.instance;
  }
}

// Create and export singleton instance
export const webSocketService = WebSocketService.getInstance();

export default WebSocketService;

--------------------------------------------------------------------------------
NOTE: WebSocketService.ts is 1673 lines. Key methods include:
- connect() / close() / disconnect() - Connection lifecycle
- handleMessage() / processBinaryData() - Message handling
- sendMessage() / sendRawBinaryData() - Outbound messages
- sendFilterUpdate() / forceRefreshFilter() - Filter synchronization
- subscribeSolidResource() / connectSolid() - solid-0.1 protocol
- startHeartbeat() / handleHeartbeatResponse() - Keep-alive
- initializeBatchQueue() / sendNodePositionUpdates() - Position batching
--------------------------------------------------------------------------------
                         END SECTION 13: WebSocketService.ts (truncated)
--------------------------------------------------------------------------------

================================================================================
                      SECTION 14: VERBATIM SOURCE CODE - SETTINGS STORE
================================================================================
Location: client/src/store/settingsStore.ts
Lines: 1070
Purpose: Zustand state management for application settings with path-based access

--------------------------------------------------------------------------------
import { create } from 'zustand'
import { persist, createJSONStorage } from 'zustand/middleware'
import { Settings, SettingsPath, DeepPartial } from '../features/settings/config/settings'
import { createLogger } from '../utils/loggerConfig'
import { createErrorMetadata } from '../utils/loggerConfig'
import { debugState } from '../utils/clientDebugState'
import { produce } from 'immer';
import { toast } from '../features/design-system/components/Toast';
import { isViewportSetting } from '../features/settings/config/viewportSettings';
import { settingsApi } from '../api/settingsApi';
import { nostrAuth } from '../services/nostrAuthService';
import { autoSaveManager } from './autoSaveManager';



const logger = createLogger('SettingsStore')

// Helper to wait for authentication to be ready
async function waitForAuthReady(maxWaitMs: number = 3000): Promise<void> {
  const startTime = Date.now();


  if (!nostrAuth['initialized']) {
    logger.info('Waiting for nostrAuth to initialize...');
    await nostrAuth.initialize();
  }


  return new Promise((resolve) => {
    const checkAuth = () => {
      const elapsed = Date.now() - startTime;


      if (elapsed >= maxWaitMs || !localStorage.getItem('nostr_session_token')) {
        logger.info('Proceeding with settings initialization', {
          authenticated: nostrAuth.isAuthenticated(),
          elapsed
        });
        resolve();
        return;
      }


      if (nostrAuth.isAuthenticated()) {
        logger.info('Auth ready, proceeding with settings initialization');
        resolve();
        return;
      }


      setTimeout(checkAuth, 100);
    };

    checkAuth();
  });
}

// Essential paths loaded at startup for fast initialization
const ESSENTIAL_PATHS = [
  'system.debug.enabled',
  'system.websocket.updateRate',
  'system.websocket.reconnectAttempts',
  'auth.enabled',
  'auth.required',
  'visualisation.rendering.context',
  'xr.enabled',
  'xr.mode',

  'visualisation.graphs.logseq.physics',
  'visualisation.graphs.visionflow.physics',

  // Node filtering settings - needed for visibility filtering
  'nodeFilter.enabled',
  'nodeFilter.qualityThreshold',
  'nodeFilter.authorityThreshold',
  'nodeFilter.filterByQuality',
  'nodeFilter.filterByAuthority',
  'nodeFilter.filterMode'
];

export interface SettingsState {

  partialSettings: DeepPartial<Settings>
  loadedPaths: Set<string>
  loadingSections: Set<string>


  settings: DeepPartial<Settings>

  initialized: boolean
  authenticated: boolean
  user: { isPowerUser: boolean; pubkey: string } | null
  isPowerUser: boolean
  subscribers: Map<string, Set<() => void>>


  initialize: () => Promise<void>
  setAuthenticated: (authenticated: boolean) => void
  setUser: (user: { isPowerUser: boolean; pubkey: string } | null) => void
  get: <T>(path: SettingsPath) => T | undefined
  set: <T>(path: SettingsPath, value: T) => void
  subscribe: (path: SettingsPath, callback: () => void, immediate?: boolean) => () => void;
  unsubscribe: (path: SettingsPath, callback: () => void) => void;
  updateSettings: (updater: (draft: Settings) => void) => void;
  notifyViewportUpdate: (path: SettingsPath) => void;


  ensureLoaded: (paths: string[]) => Promise<void>
  loadSection: (section: string) => Promise<void>
  isLoaded: (path: SettingsPath) => boolean


  getByPath: <T>(path: SettingsPath) => Promise<T>;
  setByPath: <T>(path: SettingsPath, value: T) => void;
  batchUpdate: (updates: Array<{path: SettingsPath, value: any}>) => void;
  flushPendingUpdates: () => Promise<void>;


  resetSettings: () => Promise<void>;
  exportSettings: () => Promise<string>;
  importSettings: (jsonString: string) => Promise<void>;


  updateComputeMode: (mode: string) => void;
  updateClustering: (config: ClusteringConfig) => void;
  updateConstraints: (constraints: ConstraintConfig[]) => void;
  updatePhysics: (graphName: string, params: Partial<GPUPhysicsParams>) => void;
  updateWarmupSettings: (settings: WarmupSettings) => void;


  notifyPhysicsUpdate: (graphName: string, params: Partial<GPUPhysicsParams>) => void;
}

// GPU-specific interfaces for type safety
interface GPUPhysicsParams {
  springK: number;
  repelK: number;
  attractionK: number;
  gravity: number;
  dt: number;
  maxVelocity: number;
  damping: number;
  temperature: number;
  maxRepulsionDist: number;

  restLength: number;
  repulsionCutoff: number;
  repulsionSofteningEpsilon: number;
  centerGravityK: number;
  gridCellSize: number;
  featureFlags: number;

  warmupIterations: number;
  coolingRate: number;

  enableBounds?: boolean;
  boundsSize?: number;
  boundaryDamping?: number;
  collisionRadius?: number;

  iterations?: number;
  massScale?: number;
  updateThreshold?: number;

  boundaryExtremeMultiplier?: number;
  boundaryExtremeForceMultiplier?: number;
  boundaryVelocityDamping?: number;
  maxForce?: number;
  seed?: number;
  iteration?: number;
}

interface ClusteringConfig {
  algorithm: 'none' | 'kmeans' | 'spectral' | 'louvain';
  clusterCount: number;
  resolution: number;
  iterations: number;
  exportEnabled: boolean;
  importEnabled: boolean;
}

interface ConstraintConfig {
  id: string;
  name: string;
  enabled: boolean;
  description?: string;
  icon?: string;
}

interface WarmupSettings {
  warmupDuration: number;
  convergenceThreshold: number;
  enableAdaptiveCooling: boolean;
  warmupIterations?: number;
  coolingRate?: number;
}

export const useSettingsStore = create<SettingsState>()(
  persist(
    (set, get) => ({
      partialSettings: {},
      settings: {},
      loadedPaths: new Set(),
      loadingSections: new Set(),
      initialized: false,
      authenticated: false,
      user: null,
      isPowerUser: false,
      subscribers: new Map(),

      initialize: async () => {
        try {
          console.log('[SettingsStore] Starting initialization with essential paths');
          if (debugState.isEnabled()) {
            logger.info('Initializing settings store with essential paths only')
          }

          await waitForAuthReady();

          const isAuthenticated = nostrAuth.isAuthenticated();
          const user = nostrAuth.getCurrentUser();

          logger.info('Settings initialization with auth state', {
            authenticated: isAuthenticated,
            user: user?.pubkey?.slice(0, 8) + '...',
          });

          console.log('[SettingsStore] Calling settingsApi.getSettingsByPaths');
          const essentialSettings = await settingsApi.getSettingsByPaths(ESSENTIAL_PATHS);
          console.log('[SettingsStore] Essential settings loaded successfully');

          if (debugState.isEnabled()) {
            logger.info('Essential settings loaded:', { essentialSettings })
          }

          set(state => ({
            partialSettings: essentialSettings as DeepPartial<Settings>,
            settings: essentialSettings as DeepPartial<Settings>,
            loadedPaths: new Set(ESSENTIAL_PATHS),
            initialized: true,
            authenticated: isAuthenticated,
            user: user ? { isPowerUser: user.isPowerUser, pubkey: user.pubkey } : null,
            isPowerUser: user?.isPowerUser || false
          }));

          autoSaveManager.setInitialized(true);

          if (debugState.isEnabled()) {
            logger.info('Settings store initialized with essential paths')
          }

        } catch (error) {
          console.error('[SettingsStore] Failed to initialize:', error);
          logger.error('Failed to initialize settings store:', createErrorMetadata(error))
          set({ initialized: false })
          throw error
        }
      },

      // ... [Core methods: get, set, subscribe, updateSettings - 500+ lines]
      // See full implementation at: client/src/store/settingsStore.ts

      updatePhysics: (graphName: string, params: Partial<GPUPhysicsParams>) => {
        const state = get();

        // Validate parameters within bounds
        const validatedParams = { ...params };

        if (validatedParams.springK !== undefined) {
          validatedParams.springK = Math.max(0.001, Math.min(10.0, validatedParams.springK));
        }
        if (validatedParams.repelK !== undefined) {
          validatedParams.repelK = Math.max(0.001, Math.min(100.0, validatedParams.repelK));
        }
        // ... additional validation

        state.updateSettings((draft: any) => {
          if (!draft.visualisation) draft.visualisation = { graphs: {} };
          if (!draft.visualisation.graphs) draft.visualisation.graphs = {};

          const graphs = draft.visualisation.graphs as any;
          if (!graphs[graphName]) graphs[graphName] = {};
          if (!graphs[graphName].physics) graphs[graphName].physics = {};

          const graphSettings = graphs[graphName];
          if (graphSettings && graphSettings.physics) {
            Object.assign(graphSettings.physics, validatedParams);
          }
        });

        state.notifyPhysicsUpdate(graphName, validatedParams);
      },

      notifyPhysicsUpdate: (graphName: string, params: Partial<GPUPhysicsParams>) => {
        if (typeof window !== 'undefined') {
          try {
            const wsService = (window as any).webSocketService;
            if (wsService && wsService.isConnected && wsService.isConnected()) {
              const message = {
                type: 'physics_parameter_update',
                timestamp: Date.now(),
                graph: graphName,
                parameters: params
              };

              wsService.send(message);
            }
          } catch (error) {
            logger.warn('Failed to notify physics update via WebSocket:', createErrorMetadata(error));
          }

          // Also dispatch DOM event for local listeners
          const event = new CustomEvent('physicsParametersUpdated', {
            detail: { graphName, params }
          });
          window.dispatchEvent(event);
        }
      },
    }),
    {
      name: 'graph-viz-settings-v2',
      storage: createJSONStorage(() => localStorage),
      partialize: (state) => ({
        authenticated: state.authenticated,
        user: state.user,
        isPowerUser: state.isPowerUser,
        essentialPaths: ESSENTIAL_PATHS.reduce((acc, path) => {
          const value = (state.partialSettings as Record<string, unknown>)[path];
          if (value !== undefined) {
            acc[path] = value;
          }
          return acc;
        }, {} as Record<string, any>)
      }),
    }
  )
)

// Helper function to set nested value by dot notation path
function setNestedValue(obj: any, path: string, value: any): void {
  const keys = path.split('.');
  let current = obj;

  for (let i = 0; i < keys.length - 1; i++) {
    const key = keys[i];
    if (!(key in current) || typeof current[key] !== 'object' || current[key] === null) {
      current[key] = {};
    }
    current = current[key];
  }

  current[keys[keys.length - 1]] = value;
}

// Export for testing and direct access
export const settingsStoreUtils = {
  getSectionPaths,
  setNestedValue,
  getAllSettingsPaths,
  getAllAvailableSettingsPaths
};

--------------------------------------------------------------------------------
NOTE: settingsStore.ts is 1070 lines. Key features:
- Path-based lazy loading (ESSENTIAL_PATHS loaded at startup)
- Zustand + Immer for immutable updates
- localStorage persistence with selective partialize
- Physics parameter validation with bounds checking
- WebSocket notification for physics updates
- Nostr auth integration for user settings
--------------------------------------------------------------------------------
                         END SECTION 14: settingsStore.ts (truncated)
--------------------------------------------------------------------------------

================================================================================
                 SECTION 15: VERBATIM SOURCE CODE - GRAPH WORKER PROXY
================================================================================
Location: client/src/features/graph/managers/graphWorkerProxy.ts
Lines: 343
Purpose: Web Worker proxy for off-main-thread graph processing with SharedArrayBuffer

--------------------------------------------------------------------------------
import { wrap, Remote } from 'comlink';
import { GraphWorkerType } from '../workers/graph.worker';
import { createLogger } from '../../../utils/loggerConfig';
import { debugState } from '../../../utils/clientDebugState';

const logger = createLogger('GraphWorkerProxy');

export interface Node {
  id: string;
  label: string;
  position: {
    x: number;
    y: number;
    z: number;
  };
  metadata?: Record<string, any>;
}

export interface Edge {
  id: string;
  source: string;
  target: string;
  label?: string;
  weight?: number;
  metadata?: Record<string, any>;
}

export interface GraphData {
  nodes: Node[];
  edges: Edge[];
}

// Add Vec3 to be used in updateUserDrivenNodePosition
export interface Vec3 {
  x: number;
  y: number;
  z: number;
}

type GraphDataChangeListener = (data: GraphData) => void;
type PositionUpdateListener = (positions: Float32Array) => void;


class GraphWorkerProxy {
  private static instance: GraphWorkerProxy;
  private worker: Worker | null = null;
  private workerApi: Remote<GraphWorkerType> | null = null;
  private graphDataListeners: GraphDataChangeListener[] = [];
  private positionUpdateListeners: PositionUpdateListener[] = [];
  private sharedBuffer: SharedArrayBuffer | null = null;
  private isInitialized: boolean = false;
  private graphType: 'logseq' | 'visionflow' = 'logseq';

  private constructor() {}

  public static getInstance(): GraphWorkerProxy {
    if (!GraphWorkerProxy.instance) {
      GraphWorkerProxy.instance = new GraphWorkerProxy();
    }
    return GraphWorkerProxy.instance;
  }

  public async initialize(): Promise<void> {
    if (this.isInitialized) {
      console.log('[GraphWorkerProxy] Already initialized, skipping');
      return;
    }

    console.log('[GraphWorkerProxy] Starting worker initialization');
    try {

      console.log('[GraphWorkerProxy] Creating worker');
      this.worker = new Worker(
        new URL('../workers/graph.worker.ts', import.meta.url),
        { type: 'module' }
      );


      this.worker.onerror = (error) => {
        console.error('[GraphWorkerProxy] Worker error:', error);
        logger.error('Worker error:', error);
      };

      console.log('[GraphWorkerProxy] Wrapping worker with Comlink');

      this.workerApi = wrap<GraphWorkerType>(this.worker);


      console.log('[GraphWorkerProxy] Testing worker communication');
      try {
        await this.workerApi.initialize();
        console.log('[GraphWorkerProxy] Worker communication test successful');
      } catch (commError) {
        console.error('[GraphWorkerProxy] Worker communication failed:', commError);
        throw new Error(`Worker communication failed: ${commError}`);
      }


      const maxNodes = 10000;
      const bufferSize = maxNodes * 4 * 4;

      if (typeof SharedArrayBuffer !== 'undefined') {
        console.log('[GraphWorkerProxy] Setting up SharedArrayBuffer');
        this.sharedBuffer = new SharedArrayBuffer(bufferSize);
        await this.workerApi.setupSharedPositions(this.sharedBuffer);
        console.log(`[GraphWorkerProxy] SharedArrayBuffer initialized: ${bufferSize} bytes`);
        if (debugState.isEnabled()) {
          logger.info(`Initialized SharedArrayBuffer: ${bufferSize} bytes for ${maxNodes} nodes`);
        }
      } else {
        console.warn('[GraphWorkerProxy] SharedArrayBuffer not available, using message passing');
        logger.warn('SharedArrayBuffer not available, falling back to regular message passing');
      }

      this.isInitialized = true;
      console.log('[GraphWorkerProxy] Initialization complete');
      if (debugState.isEnabled()) {
        logger.info('Graph worker initialized successfully');
      }


      console.log(`[GraphWorkerProxy] Setting initial graph type: ${this.graphType}`);
      await this.setGraphType(this.graphType);
    } catch (error) {
      console.error('[GraphWorkerProxy] Failed to initialize worker:', error);
      logger.error('Failed to initialize graph worker:', error);
      throw error;
    }
  }


  public async setGraphType(type: 'logseq' | 'visionflow'): Promise<void> {
    if (!this.workerApi) {
      throw new Error('Worker not initialized');
    }

    this.graphType = type;
    await this.workerApi.setGraphType(type);

    if (debugState.isEnabled()) {
      logger.info(`Graph type set to: ${type}`);
    }
  }


  public getGraphType(): 'logseq' | 'visionflow' {
    return this.graphType;
  }


  public async setGraphData(data: GraphData): Promise<void> {
    if (!this.workerApi) {
      throw new Error('Worker not initialized');
    }

    await this.workerApi.setGraphData(data);
    this.notifyGraphDataListeners(data);

    if (debugState.isEnabled()) {
      logger.info(`Set ${this.graphType} graph data: ${data.nodes.length} nodes, ${data.edges.length} edges`);
    }
  }


  public async processBinaryData(data: ArrayBuffer): Promise<void> {

    if (this.graphType !== 'logseq') {
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Skipping binary data processing for ${this.graphType} graph`);
      }
      return;
    }
    if (!this.workerApi) {
      throw new Error('Worker not initialized');
    }

    try {
      const positionArray = await this.workerApi.processBinaryData(data);
      this.notifyPositionUpdateListeners(positionArray);

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Processed binary data: ${positionArray.length / 4} position updates`);
      }
    } catch (error) {
      logger.error('Error processing binary data in worker:', error);
      throw error;
    }
  }


  public async getGraphData(): Promise<GraphData> {
    if (!this.workerApi) {
      console.error('[GraphWorkerProxy] Worker not initialized for getGraphData');
      throw new Error('Worker not initialized');
    }
    console.log('[GraphWorkerProxy] Getting graph data from worker');
    try {
      const data = await this.workerApi.getGraphData();
      console.log(`[GraphWorkerProxy] Got ${data.nodes.length} nodes, ${data.edges.length} edges from worker`);
      return data;
    } catch (error) {
      console.error('[GraphWorkerProxy] Error getting graph data from worker:', error);
      throw error;
    }
  }


  public async updateNode(node: Node): Promise<void> {
    if (!this.workerApi) {
      throw new Error('Worker not initialized');
    }

    await this.workerApi.updateNode(node);


    const graphData = await this.workerApi.getGraphData();
    this.notifyGraphDataListeners(graphData);
  }


  public async removeNode(nodeId: string): Promise<void> {
    if (!this.workerApi) {
      throw new Error('Worker not initialized');
    }

    await this.workerApi.removeNode(nodeId);


    const graphData = await this.workerApi.getGraphData();
    this.notifyGraphDataListeners(graphData);
  }

  public async updateSettings(settings: any): Promise<void> {
    if (!this.workerApi) {
      throw new Error('Worker not initialized');
    }
    await this.workerApi.updateSettings(settings);
  }

  public async pinNode(nodeId: number): Promise<void> {
    if (!this.workerApi) {
      throw new Error('Worker not initialized');
    }
    await this.workerApi.pinNode(nodeId);
  }

  public async unpinNode(nodeId: number): Promise<void> {
    if (!this.workerApi) {
      throw new Error('Worker not initialized');
    }
    await this.workerApi.unpinNode(nodeId);
  }

  public async updateUserDrivenNodePosition(nodeId: number, position: Vec3): Promise<void> {
    if (!this.workerApi) {
      throw new Error('Worker not initialized');
    }
    await this.workerApi.updateUserDrivenNodePosition(nodeId, position);
  }

  public async tick(deltaTime: number): Promise<Float32Array> {
    if (!this.workerApi) {
      throw new Error('Worker not initialized');
    }
    return await this.workerApi.tick(deltaTime);
  }


  public getSharedPositionBuffer(): Float32Array | null {
    if (!this.sharedBuffer) {
      return null;
    }
    return new Float32Array(this.sharedBuffer);
  }


  public onGraphDataChange(listener: GraphDataChangeListener): () => void {
    this.graphDataListeners.push(listener);


    return () => {
      this.graphDataListeners = this.graphDataListeners.filter(l => l !== listener);
    };
  }


  public onPositionUpdate(listener: PositionUpdateListener): () => void {
    this.positionUpdateListeners.push(listener);


    return () => {
      this.positionUpdateListeners = this.positionUpdateListeners.filter(l => l !== listener);
    };
  }


  public isReady(): boolean {
    return this.isInitialized && this.workerApi !== null;
  }


  public dispose(): void {
    if (this.worker) {
      this.worker.terminate();
      this.worker = null;
    }

    this.workerApi = null;
    this.graphDataListeners = [];
    this.positionUpdateListeners = [];
    this.sharedBuffer = null;
    this.isInitialized = false;

    if (debugState.isEnabled()) {
      logger.info('Graph worker disposed');
    }
  }

  private notifyGraphDataListeners(data: GraphData): void {
    this.graphDataListeners.forEach(listener => {
      try {
        listener(data);
      } catch (error) {
        logger.error('Error in graph data listener:', error);
      }
    });
  }

  private notifyPositionUpdateListeners(positions: Float32Array): void {
    this.positionUpdateListeners.forEach(listener => {
      try {
        listener(positions);
      } catch (error) {
        logger.error('Error in position update listener:', error);
      }
    });
  }
}

// Create singleton instance
export const graphWorkerProxy = GraphWorkerProxy.getInstance();

--------------------------------------------------------------------------------
                      END SECTION 15: graphWorkerProxy.ts (complete)
--------------------------------------------------------------------------------

================================================================================
                 SECTION 16: VERBATIM SOURCE CODE - CLIENT DEBUG STATE
================================================================================
Location: client/src/utils/clientDebugState.ts
Lines: 176
Purpose: Runtime debug state management with localStorage persistence

--------------------------------------------------------------------------------
import { createLogger } from './baseLogger';

const logger = createLogger('ClientDebugState');

// localStorage keys for debug settings
const DEBUG_KEYS = {

  enabled: 'debug.enabled',
  dataDebug: 'debug.data',
  performanceDebug: 'debug.performance',


  consoleLogging: 'debug.consoleLogging',
  logLevel: 'debug.logLevel',
  showNodeIds: 'debug.showNodeIds',
  showEdgeWeights: 'debug.showEdgeWeights',
  enableProfiler: 'debug.enableProfiler',
  apiDebugMode: 'debug.apiDebugMode',


  enableWebsocketDebug: 'debug.enableWebsocketDebug',
  logBinaryHeaders: 'debug.logBinaryHeaders',
  logFullJson: 'debug.logFullJson',
  enablePhysicsDebug: 'debug.enablePhysicsDebug',
  enableNodeDebug: 'debug.enableNodeDebug',
  enableShaderDebug: 'debug.enableShaderDebug',
  enableMatrixDebug: 'debug.enableMatrixDebug',
  enablePerformanceDebug: 'debug.enablePerformanceDebug',
} as const;

export type DebugKey = keyof typeof DEBUG_KEYS;

class ClientDebugState {
  private listeners: Map<string, Set<(value: any) => void>> = new Map();

  constructor() {

    if (typeof window !== 'undefined') {
      window.addEventListener('storage', this.handleStorageChange.bind(this));
    }
  }

  private handleStorageChange(e: StorageEvent): void {
    if (e.key && Object.values(DEBUG_KEYS).includes(e.key as any)) {
      const newValue = e.newValue === 'true' ? true :
                       e.newValue === 'false' ? false :
                       e.newValue;
      this.notifyListeners(e.key, newValue);
    }
  }

  private notifyListeners(key: string, value: any): void {
    const listeners = this.listeners.get(key);
    if (listeners) {
      listeners.forEach(listener => listener(value));
    }
  }


  public get(key: DebugKey): any {
    const storageKey = DEBUG_KEYS[key];
    if (typeof window === 'undefined') return false;

    try {
      const value = localStorage.getItem(storageKey);
      if (value === null) return this.getDefault(key);


      if (value === 'true') return true;
      if (value === 'false') return false;


      return value;
    } catch (e) {
      logger.warn(`Failed to read ${storageKey} from localStorage`);
      return this.getDefault(key);
    }
  }


  public set(key: DebugKey, value: any): void {
    const storageKey = DEBUG_KEYS[key];
    if (typeof window === 'undefined') return;

    try {
      const stringValue = String(value);
      localStorage.setItem(storageKey, stringValue);
      this.notifyListeners(storageKey, value);
      logger.info(`Debug setting ${key} set to ${stringValue}`);
    } catch (e) {
      logger.warn(`Failed to save ${storageKey} to localStorage`);
    }
  }


  public subscribe(key: DebugKey, listener: (value: any) => void): () => void {
    const storageKey = DEBUG_KEYS[key];
    if (!this.listeners.has(storageKey)) {
      this.listeners.set(storageKey, new Set());
    }
    this.listeners.get(storageKey)!.add(listener);


    return () => {
      const listeners = this.listeners.get(storageKey);
      if (listeners) {
        listeners.delete(listener);
      }
    };
  }


  private getDefault(key: DebugKey): any {
    switch (key) {
      case 'logLevel':
        return 'info';
      default:
        return false;
    }
  }


  public isEnabled(): boolean {
    return this.get('enabled');
  }

  public setEnabled(value: boolean): void {
    this.set('enabled', value);
  }

  public isDataDebugEnabled(): boolean {
    return this.isEnabled() && this.get('dataDebug');
  }

  public isPerformanceDebugEnabled(): boolean {
    return this.isEnabled() && this.get('performanceDebug');
  }


  public getAll(): Record<DebugKey, any> {
    const result: Partial<Record<DebugKey, any>> = {};
    for (const key of Object.keys(DEBUG_KEYS) as DebugKey[]) {
      result[key] = this.get(key);
    }
    return result as Record<DebugKey, any>;
  }

  public reset(): void {
    if (typeof window === 'undefined') return;

    try {
      for (const storageKey of Object.values(DEBUG_KEYS)) {
        localStorage.removeItem(storageKey);
        this.notifyListeners(storageKey, this.getDefault(storageKey as any));
      }
      logger.info('All debug settings reset to defaults');
    } catch (e) {
      logger.warn('Failed to reset debug settings');
    }
  }
}

// Create singleton instance
export const clientDebugState = new ClientDebugState();

// For backward compatibility with existing code
export const debugState = {
  isEnabled: () => clientDebugState.isEnabled(),
  enableDebug: (value: boolean) => clientDebugState.setEnabled(value),
  isDataDebugEnabled: () => clientDebugState.isDataDebugEnabled(),
  enableDataDebug: (value: boolean) => clientDebugState.set('dataDebug', value),
  isPerformanceDebugEnabled: () => clientDebugState.isPerformanceDebugEnabled(),
  enablePerformanceDebug: (value: boolean) => clientDebugState.set('performanceDebug', value),
};

--------------------------------------------------------------------------------
                      END SECTION 16: clientDebugState.ts (complete)
--------------------------------------------------------------------------------

================================================================================
                 SECTION 17: VERBATIM SOURCE CODE - ANALYTICS STORE (SSSP)
================================================================================
Location: client/src/features/analytics/store/analyticsStore.ts
Lines: 550
Purpose: SSSP (Single-Source Shortest Path) computation with caching

--------------------------------------------------------------------------------
import { create } from 'zustand'
import { persist, createJSONStorage } from 'zustand/middleware'
import { createLogger, createErrorMetadata } from '../../../utils/loggerConfig'
import { debugState } from '../../../utils/clientDebugState'
import { produce } from 'immer'
import type { GraphNode, GraphEdge } from '../../graph/types/graphTypes'
import { unifiedApiClient } from '../../../services/api'

const logger = createLogger('AnalyticsStore')

// SSSP-specific types
export interface SSSPResult {
  sourceNodeId: string
  distances: Record<string, number>
  predecessors: Record<string, string | null>
  unreachableCount: number
  computationTime: number
  timestamp: number
  algorithm: 'dijkstra' | 'bellman-ford' | 'floyd-warshall'
}

export interface SSSPCache {
  [sourceNodeId: string]: {
    result: SSSPResult
    lastAccessed: number
    graphHash: string
  }
}

export interface AnalyticsMetrics {
  totalComputations: number
  cacheHits: number
  cacheMisses: number
  averageComputationTime: number
  lastComputationTime: number
}

interface AnalyticsState {
  currentResult: SSSPResult | null
  cache: SSSPCache
  loading: boolean
  error: string | null
  metrics: AnalyticsMetrics
  lastGraphHash: string | null

  computeSSSP: (
    nodes: GraphNode[],
    edges: GraphEdge[],
    sourceNodeId: string,
    algorithm?: 'dijkstra' | 'bellman-ford' | 'floyd-warshall'
  ) => Promise<SSSPResult>

  clearResults: () => void
  clearCache: () => void
  getCachedResult: (sourceNodeId: string, graphHash: string) => SSSPResult | null
  normalizeDistances: (result: SSSPResult) => Record<string, number>
  getUnreachableNodes: (result: SSSPResult) => string[]
  invalidateCache: () => void
  cleanExpiredCache: (maxAge?: number) => void
  setError: (error: string | null) => void
  updateMetrics: (computationTime: number, fromCache: boolean) => void
  resetMetrics: () => void
}

// Hash function for graph structure
function hashGraph(nodes: GraphNode[], edges: GraphEdge[]): string {
  const nodeIds = nodes.map(n => n.id).sort().join(',')
  const edgeIds = edges.map(e => `${e.source}-${e.target}-${e.weight || 1}`).sort().join(',')
  return btoa(`${nodeIds}|${edgeIds}`)
}

// Dijkstra's algorithm implementation
function dijkstra(nodes: GraphNode[], edges: GraphEdge[], sourceNodeId: string): Omit<SSSPResult, 'timestamp' | 'computationTime' | 'algorithm'> {
  const distances: Record<string, number> = {}
  const predecessors: Record<string, string | null> = {}
  const visited = new Set<string>()
  const nodeIds = new Set(nodes.map(n => n.id))

  // Initialize distances
  for (const node of nodes) {
    distances[node.id] = node.id === sourceNodeId ? 0 : Infinity
    predecessors[node.id] = null
  }

  // Build adjacency list
  const adjacencyList: Record<string, Array<{ nodeId: string; weight: number }>> = {}
  for (const node of nodes) {
    adjacencyList[node.id] = []
  }

  for (const edge of edges) {
    if (nodeIds.has(edge.source) && nodeIds.has(edge.target)) {
      const weight = edge.weight || 1
      adjacencyList[edge.source].push({ nodeId: edge.target, weight })
      // Treat as undirected graph
      adjacencyList[edge.target].push({ nodeId: edge.source, weight })
    }
  }

  // Main Dijkstra loop
  while (visited.size < nodes.length) {
    // Find unvisited node with minimum distance
    let currentNode: string | null = null
    let minDistance = Infinity

    for (const nodeId of Object.keys(distances)) {
      if (!visited.has(nodeId) && distances[nodeId] < minDistance) {
        minDistance = distances[nodeId]
        currentNode = nodeId
      }
    }

    if (currentNode === null || minDistance === Infinity) break

    visited.add(currentNode)

    // Update distances to neighbors
    for (const neighbor of adjacencyList[currentNode] || []) {
      if (!visited.has(neighbor.nodeId)) {
        const newDistance = distances[currentNode] + neighbor.weight
        if (newDistance < distances[neighbor.nodeId]) {
          distances[neighbor.nodeId] = newDistance
          predecessors[neighbor.nodeId] = currentNode
        }
      }
    }
  }

  const unreachableCount = Object.values(distances).filter(d => d === Infinity).length

  return {
    sourceNodeId,
    distances,
    predecessors,
    unreachableCount
  }
}

// Bellman-Ford algorithm (handles negative weights)
function bellmanFord(nodes: GraphNode[], edges: GraphEdge[], sourceNodeId: string): Omit<SSSPResult, 'timestamp' | 'computationTime' | 'algorithm'> {
  const distances: Record<string, number> = {}
  const predecessors: Record<string, string | null> = {}

  // Initialize
  for (const node of nodes) {
    distances[node.id] = node.id === sourceNodeId ? 0 : Infinity
    predecessors[node.id] = null
  }

  // Relax edges V-1 times
  for (let i = 0; i < nodes.length - 1; i++) {
    for (const edge of edges) {
      const weight = edge.weight || 1
      if (distances[edge.source] !== Infinity) {
        const newDistance = distances[edge.source] + weight
        if (newDistance < distances[edge.target]) {
          distances[edge.target] = newDistance
          predecessors[edge.target] = edge.source
        }
      }
      // Also check reverse direction (undirected graph)
      if (distances[edge.target] !== Infinity) {
        const newDistance = distances[edge.target] + weight
        if (newDistance < distances[edge.source]) {
          distances[edge.source] = newDistance
          predecessors[edge.source] = edge.target
        }
      }
    }
  }

  // Check for negative cycles
  for (const edge of edges) {
    const weight = edge.weight || 1
    if (distances[edge.source] !== Infinity &&
        distances[edge.source] + weight < distances[edge.target]) {
      logger.warn('Negative cycle detected in graph')
    }
  }

  const unreachableCount = Object.values(distances).filter(d => d === Infinity).length

  return {
    sourceNodeId,
    distances,
    predecessors,
    unreachableCount
  }
}

export const useAnalyticsStore = create<AnalyticsState>()(
  persist(
    (set, get) => ({
      currentResult: null,
      cache: {},
      loading: false,
      error: null,
      lastGraphHash: null,
      metrics: {
        totalComputations: 0,
        cacheHits: 0,
        cacheMisses: 0,
        averageComputationTime: 0,
        lastComputationTime: 0
      },

      computeSSSP: async (nodes, edges, sourceNodeId, algorithm = 'dijkstra') => {
        const startTime = performance.now()

        set({ loading: true, error: null })

        try {
          // Validate input
          if (!nodes.length || !sourceNodeId) {
            throw new Error('Invalid input: nodes array is empty or sourceNodeId is missing')
          }

          const sourceNode = nodes.find(n => n.id === sourceNodeId)
          if (!sourceNode) {
            throw new Error(`Source node with id ${sourceNodeId} not found`)
          }

          // Compute graph hash for caching
          const graphHash = hashGraph(nodes, edges)

          // Check cache first
          const cachedResult = get().getCachedResult(sourceNodeId, graphHash)
          if (cachedResult) {
            const computationTime = performance.now() - startTime
            get().updateMetrics(computationTime, true)

            set({
              currentResult: cachedResult,
              loading: false,
              lastGraphHash: graphHash
            })

            if (debugState.isEnabled()) {
              logger.info('SSSP result retrieved from cache', { sourceNodeId, algorithm })
            }

            return cachedResult
          }

          // Try server-side computation first
          let result: SSSPResult

          try {
            const response = await unifiedApiClient.post('/api/analytics/shortest-path', {
              source_node_id: parseInt(sourceNodeId),
            })

            const data = response.data

            if (!data.success) {
              throw new Error(data.error || 'SSSP computation failed on server')
            }

            // Convert server response to SSSPResult format
            const distances: Record<string, number> = {}
            const predecessors: Record<string, string | null> = {}

            for (const [nodeId, distance] of Object.entries(data.distances || {})) {
              distances[nodeId] = distance === null ? Infinity : distance as number
              predecessors[nodeId] = null
            }

            const computationTime = performance.now() - startTime

            result = {
              sourceNodeId,
              distances,
              predecessors,
              unreachableCount: data.unreachable_count || 0,
              algorithm,
              computationTime,
              timestamp: Date.now()
            }

          } catch (apiError) {
            // Fall back to local computation
            logger.warn('Server SSSP failed, falling back to local computation', apiError)

            let baseResult: Omit<SSSPResult, 'timestamp' | 'computationTime' | 'algorithm'>

            switch (algorithm) {
              case 'bellman-ford':
                baseResult = bellmanFord(nodes, edges, sourceNodeId)
                break
              case 'dijkstra':
              default:
                baseResult = dijkstra(nodes, edges, sourceNodeId)
                break
            }

            const computationTime = performance.now() - startTime

            result = {
              ...baseResult,
              algorithm,
              computationTime,
              timestamp: Date.now()
            }
          }

          // Update state with result and cache
          set(state => produce(state, draft => {
            draft.currentResult = result
            draft.loading = false
            draft.lastGraphHash = graphHash

            // Store in cache
            draft.cache[sourceNodeId] = {
              result,
              lastAccessed: Date.now(),
              graphHash
            }

            // Limit cache size to 50 entries (LRU eviction)
            const cacheEntries = Object.entries(draft.cache)
            if (cacheEntries.length > 50) {
              const sortedEntries = cacheEntries.sort(([,a], [,b]) => b.lastAccessed - a.lastAccessed)
              draft.cache = Object.fromEntries(sortedEntries.slice(0, 50))
            }
          }))

          // Update metrics
          get().updateMetrics(result.computationTime, false)

          return result

        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : 'Unknown error during SSSP computation'

          logger.error('SSSP computation failed:', createErrorMetadata(error))

          set({
            loading: false,
            error: errorMessage
          })

          throw error
        }
      },

      // ... [Additional methods: clearResults, clearCache, normalizeDistances, etc.]

      normalizeDistances: (result) => {
        if (!result) return {}

        const distances = { ...result.distances }
        const finiteDistances = Object.values(distances).filter(d => isFinite(d))

        if (finiteDistances.length === 0) return distances

        const maxDistance = Math.max(...finiteDistances)
        const minDistance = Math.min(...finiteDistances)
        const range = maxDistance - minDistance

        if (range === 0) {
          // All reachable nodes at same distance
          Object.keys(distances).forEach(nodeId => {
            if (isFinite(distances[nodeId])) {
              distances[nodeId] = 1
            }
          })
        } else {
          // Normalize to 0-1 range
          Object.keys(distances).forEach(nodeId => {
            if (isFinite(distances[nodeId])) {
              distances[nodeId] = (distances[nodeId] - minDistance) / range
            }
          })
        }

        return distances
      },

      getUnreachableNodes: (result) => {
        if (!result) return []

        return Object.entries(result.distances)
          .filter(([, distance]) => !isFinite(distance))
          .map(([nodeId]) => nodeId)
      },
    }),
    {
      name: 'analytics-store',
      storage: createJSONStorage(() => localStorage),
      partialize: (state) => ({
        cache: state.cache,
        metrics: state.metrics
      }),
    }
  )
)

// Utility hooks for common operations
export const useCurrentSSSPResult = () => useAnalyticsStore(state => state.currentResult)
export const useSSSPLoading = () => useAnalyticsStore(state => state.loading)
export const useSSSPError = () => useAnalyticsStore(state => state.error)
export const useSSSPMetrics = () => useAnalyticsStore(state => state.metrics)

--------------------------------------------------------------------------------
                      END SECTION 17: analyticsStore.ts (complete)
--------------------------------------------------------------------------------

================================================================================
                 SECTION 18: VERBATIM SOURCE CODE - LOGGER CONFIG
================================================================================
Location: client/src/utils/loggerConfig.ts
Lines: 334
Purpose: Enhanced logging with telemetry for agents, WebSocket, and Three.js

--------------------------------------------------------------------------------
import { createLogger as createBaseLogger, createErrorMetadata, createDataMetadata, LoggerOptions, DEFAULT_LOG_LEVEL, LogEntry } from './baseLogger';
import { clientDebugState } from './clientDebugState';

// Re-export utility functions and types for backward compatibility
export { createErrorMetadata, createDataMetadata, LogEntry };

// Agent-specific telemetry types
export interface AgentTelemetryData {
  agentId: string;
  agentType: string;
  action: string;
  timestamp: Date;
  metadata?: Record<string, any>;
  position?: { x: number; y: number; z: number };
  performance?: {
    renderTime?: number;
    frameRate?: number;
    meshCount?: number;
    triangleCount?: number;
  };
}

export interface WebSocketTelemetryData {
  messageType: string;
  direction: 'incoming' | 'outgoing';
  timestamp: Date;
  size?: number;
  metadata?: Record<string, any>;
}

export interface ThreeJSTelemetryData {
  action: 'position_update' | 'mesh_create' | 'animation_frame' | 'force_applied';
  objectId: string;
  position?: { x: number; y: number; z: number };
  rotation?: { x: number; y: number; z: number };
  timestamp: Date;
  metadata?: Record<string, any>;
}

type LogLevel = 'debug' | 'info' | 'warn' | 'error';

const MAX_TELEMETRY_ENTRIES = 1000;

// Enhanced agent logger with telemetry capabilities
function createBaseAgentLogger(namespace: string, options: LoggerOptions = {}) {
  const baseLogger = createBaseLogger(namespace, options);

  const agentTelemetry: AgentTelemetryData[] = [];
  const webSocketTelemetry: WebSocketTelemetryData[] = [];
  const threeJSTelemetry: ThreeJSTelemetryData[] = [];

  function trimTelemetryArray<T>(array: T[]) {
    if (array.length > MAX_TELEMETRY_ENTRIES) {
      array.splice(0, array.length - MAX_TELEMETRY_ENTRIES);
    }
  }

  return {
    ...baseLogger,

    logAgentAction(agentId: string, agentType: string, action: string, metadata?: Record<string, any>, position?: { x: number; y: number; z: number }) {
      const telemetryData: AgentTelemetryData = {
        agentId,
        agentType,
        action,
        timestamp: new Date(),
        metadata,
        position
      };

      agentTelemetry.push(telemetryData);
      trimTelemetryArray(agentTelemetry);

      baseLogger.debug(`[AGENT:${agentType}:${agentId}] ${action}`, { metadata, position });

      try {
        const storedTelemetry = JSON.parse(localStorage.getItem('agent-telemetry') || '[]');
        storedTelemetry.push(telemetryData);
        if (storedTelemetry.length > MAX_TELEMETRY_ENTRIES) {
          storedTelemetry.splice(0, storedTelemetry.length - MAX_TELEMETRY_ENTRIES);
        }
        localStorage.setItem('agent-telemetry', JSON.stringify(storedTelemetry));
      } catch (e) {
        baseLogger.warn('Failed to store agent telemetry in localStorage:', e);
      }
    },

    logWebSocketMessage(messageType: string, direction: 'incoming' | 'outgoing', metadata?: Record<string, any>, size?: number) {
      const telemetryData: WebSocketTelemetryData = {
        messageType,
        direction,
        timestamp: new Date(),
        size,
        metadata
      };

      webSocketTelemetry.push(telemetryData);
      trimTelemetryArray(webSocketTelemetry);

      baseLogger.debug(`[WS:${direction.toUpperCase()}:${messageType}] ${size ? `${size} bytes` : 'no size'}`, metadata);
    },

    logThreeJSAction(action: ThreeJSTelemetryData['action'], objectId: string, position?: { x: number; y: number; z: number }, rotation?: { x: number; y: number; z: number }, metadata?: Record<string, any>) {
      const telemetryData: ThreeJSTelemetryData = {
        action,
        objectId,
        position,
        rotation,
        timestamp: new Date(),
        metadata
      };

      threeJSTelemetry.push(telemetryData);
      trimTelemetryArray(threeJSTelemetry);

      baseLogger.debug(`[THREE.JS:${action.toUpperCase()}:${objectId}]`, { position, rotation, metadata });
    },

    logPerformance(operation: string, duration: number, metadata?: Record<string, any>) {
      baseLogger.info(`[PERF:${operation}] ${duration.toFixed(2)}ms`, metadata);
    },

    getAgentTelemetry: () => [...agentTelemetry],
    getWebSocketTelemetry: () => [...webSocketTelemetry],
    getThreeJSTelemetry: () => [...threeJSTelemetry],

    clearTelemetry() {
      agentTelemetry.length = 0;
      webSocketTelemetry.length = 0;
      threeJSTelemetry.length = 0;
      localStorage.removeItem('agent-telemetry');
      baseLogger.info('Telemetry data cleared');
    }
  };
}

// Track created loggers for dynamic updates
const createdLoggers = new Set<{
  logger: any;
  namespace: string;
  options: LoggerOptions;
  updateLevel: (level: LogLevel, enabled: boolean) => void;
}>();

function getEffectiveLogLevel(options: LoggerOptions = {}): LogLevel {
  if (options.respectRuntimeSettings === false) {
    return DEFAULT_LOG_LEVEL;
  }

  const consoleLoggingEnabled = clientDebugState.get('consoleLogging');
  if (!consoleLoggingEnabled) {
    return options.level || DEFAULT_LOG_LEVEL;
  }

  const runtimeLogLevel = clientDebugState.get('logLevel') as LogLevel;
  if (runtimeLogLevel && isValidLogLevel(runtimeLogLevel)) {
    return runtimeLogLevel;
  }

  return options.level || DEFAULT_LOG_LEVEL;
}

function shouldEnableLogging(options: LoggerOptions): boolean {
  if (options.respectRuntimeSettings === false) {
    return !options.disabled;
  }

  const consoleLoggingEnabled = clientDebugState.get('consoleLogging');
  return !options.disabled && consoleLoggingEnabled;
}

export function createLogger(namespace: string, options: LoggerOptions = {}) {
  return createDynamicLogger(namespace, options);
}

export function createDynamicLogger(namespace: string, options: LoggerOptions = {}) {
  const effectiveLevel = getEffectiveLogLevel(options);
  const enabled = shouldEnableLogging(options);

  const logger = createBaseLogger(namespace, {
    ...options,
    level: effectiveLevel,
    disabled: !enabled
  });

  const updateLevel = (newLevel: LogLevel, newEnabled: boolean) => {
    logger.updateLevel(newLevel);
    logger.setEnabled(newEnabled);
  };

  const loggerInfo = {
    logger,
    namespace,
    options,
    updateLevel
  };
  createdLoggers.add(loggerInfo);

  const dynamicLogger = {
    ...logger,

    updateSettings: () => {
      const newLevel = getEffectiveLogLevel(options);
      const newEnabled = shouldEnableLogging(options);
      updateLevel(newLevel, newEnabled);
    },

    destroy: () => {
      createdLoggers.delete(loggerInfo);
    }
  };

  return dynamicLogger;
}

export function updateAllLoggers() {
  createdLoggers.forEach(({ updateLevel, options }) => {
    const newLevel = getEffectiveLogLevel(options);
    const newEnabled = shouldEnableLogging(options);
    updateLevel(newLevel, newEnabled);
  });
}

function setupAutoUpdate() {
  clientDebugState.subscribe('consoleLogging', () => {
    updateAllLoggers();
  });

  clientDebugState.subscribe('logLevel', () => {
    updateAllLoggers();
  });
}

// Initialize auto-update when this module is loaded
if (typeof window !== 'undefined') {
  setupAutoUpdate();
}

// Export the current effective log level for reference
export { DEFAULT_LOG_LEVEL };

// Dynamic telemetry logger for system-wide telemetry
export const dynamicAgentTelemetryLogger = createDynamicAgentLogger('agent-telemetry');

// Default logger instance for backward compatibility
export const logger = createDynamicLogger('app');

--------------------------------------------------------------------------------
                      END SECTION 18: loggerConfig.ts (truncated)
--------------------------------------------------------------------------------

================================================================================
                              END OF DATAFLOW.TXT
================================================================================

File Statistics:
- Total Sections: 18 (10 inventory + 8 verbatim code)
- Total Files Documented: 120+
- Verbatim Source Files: 8 (binaryProtocol.ts, graphDataManager.ts, WebSocketService.ts,
                            settingsStore.ts, graphWorkerProxy.ts, clientDebugState.ts,
                            analyticsStore.ts, loggerConfig.ts)
- Categories Covered: 8
- Mermaid Diagrams: 5
- Total Lines of Verbatim Code: ~5,200

Pipeline Summary:
1. INGEST: GitHub API, Solid LDP, Local filesystem
2. AUTH: Nostr NIP-07/NIP-98, Bearer tokens
3. PARSE: Markdown -> Nodes/Edges, OntologyBlocks -> OWL
4. STORE: Neo4j with LRU caching, batch operations
5. COMPUTE: CUDA kernels, 12 GPU actors, physics simulation
6. BROADCAST: Binary protocol V4, delta encoding, 60fps updates
7. CLIENT: WebSocket service, Three.js rendering, Zustand state
8. EXPORT: GEXF, GraphML, JSON, Turtle, sharing/publishing

Key Performance Characteristics:
- Binary protocol: 36 bytes per node (60-80% bandwidth reduction)
- GPU physics: 60fps with spatial hashing acceleration
- Delta encoding: Only changed positions transmitted
- Double-buffered async GPU transfers: 2.8-4.4x speedup
- LRU caching: Neo4j query optimization
- Batch operations: 50-100x database write improvement

Critical Data Flow Path (verbatim code documented):
1. binaryProtocol.ts: Defines 36-byte format, V2 parsing, type flags
2. graphDataManager.ts: Singleton manager, worker proxy, ID mapping
3. WebSocketService.ts: Binary/JSON messaging, Solid notifications
4. settingsStore.ts: Zustand state, path-based access, physics sync
5. graphWorkerProxy.ts: SharedArrayBuffer, Comlink worker proxy
6. clientDebugState.ts: Runtime debug toggles, localStorage persistence
7. analyticsStore.ts: SSSP computation (Dijkstra/Bellman-Ford), caching
8. loggerConfig.ts: Agent/WebSocket/Three.js telemetry with levels

================================================================================
