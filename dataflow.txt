================================================================================
                    VISIONFLOW DATA PIPELINE - COMPREHENSIVE DATAFLOW
================================================================================
Generated: 2026-01-01
Project: VisionFlow Knowledge Graph Visualization Platform
Scope: Complete data pipeline from ingest to client rendering
Total Rust Files: 382 | Total TypeScript Files: 363 | Total Lines: 200,000+

================================================================================
                         ARCHITECTURE OVERVIEW (MERMAID)
================================================================================

```mermaid
flowchart TB
    subgraph INGEST["Data Ingestion Layer"]
        direction TB
        GH[("GitHub API<br/>jjohare/logseq")]
        JSS[("JavaScript Solid Server<br/>JSS Pods")]
        LOCAL[("Local Files<br/>Markdown/YAML")]

        GH --> GHClient["GitHubClient<br/>src/services/github/api.rs"]
        GH --> ContentAPI["EnhancedContentAPI<br/>src/services/github/content_enhanced.rs"]
        JSS --> SolidProxy["SolidProxyHandler<br/>src/handlers/solid_proxy_handler.rs"]
        LOCAL --> LocalSync["LocalFileSyncService<br/>src/services/local_file_sync_service.rs"]
    end

    subgraph AUTH["Authentication Layer"]
        direction TB
        NOSTR[("Nostr Keys<br/>NIP-07/NIP-98")]

        NOSTR --> NostrService["NostrService<br/>src/services/nostr_service.rs"]
        NostrService --> NIP98["NIP98 Token Gen<br/>src/utils/nip98.rs"]
        NostrService --> AuthMiddleware["AuthMiddleware<br/>src/middleware/auth.rs"]
        NIP98 --> SolidProxy
    end

    subgraph PARSE["Parsing Layer"]
        direction TB
        GHClient --> GitHubSync["GitHubSyncService<br/>src/services/github_sync_service.rs"]
        ContentAPI --> GitHubSync
        LocalSync --> StreamSync["StreamingSyncService<br/>src/services/streaming_sync_service.rs"]

        GitHubSync --> KGParser["KnowledgeGraphParser<br/>src/services/parsers/knowledge_graph_parser.rs"]
        GitHubSync --> OntParser["OntologyParser<br/>src/services/parsers/ontology_parser.rs"]
        StreamSync --> KGParser
        StreamSync --> OntParser

        KGParser --> Enrichment["OntologyEnrichmentService<br/>src/services/ontology_enrichment_service.rs"]
        OntParser --> Enrichment
    end

    subgraph REASONING["OWL Reasoning Layer"]
        direction TB
        Enrichment --> WhelkEngine["WhelkInferenceEngine<br/>src/adapters/whelk_inference_engine.rs"]
        WhelkEngine --> ReasoningService["OntologyReasoningService<br/>src/services/ontology_reasoning_service.rs"]
        ReasoningService --> InferenceCache["InferenceCache<br/>src/inference/cache.rs"]
        ReasoningService --> AxiomMapper["AxiomMapper<br/>src/constraints/axiom_mapper.rs"]
    end

    subgraph STORAGE["Storage Layer (Neo4j)"]
        direction TB
        Enrichment --> GraphRepo["Neo4jGraphRepository<br/>src/adapters/neo4j_graph_repository.rs"]
        Enrichment --> OntRepo["Neo4jOntologyRepository<br/>src/adapters/neo4j_ontology_repository.rs"]
        ReasoningService --> OntRepo

        GraphRepo --> NEO4J[("Neo4j Database<br/>Graphs + Ontology")]
        OntRepo --> NEO4J

        SettingsRepo["Neo4jSettingsRepository<br/>src/adapters/neo4j_settings_repository.rs"] --> NEO4J
    end

    subgraph CQRS["CQRS Application Layer"]
        direction TB
        NEO4J --> CommandBus["CommandBus<br/>src/cqrs/bus.rs"]
        CommandBus --> GraphHandlers["GraphHandlers<br/>src/cqrs/handlers/graph_handlers.rs"]
        CommandBus --> OntologyHandlers["OntologyHandlers<br/>src/cqrs/handlers/ontology_handlers.rs"]
        CommandBus --> SettingsHandlers["SettingsHandlers<br/>src/cqrs/handlers/settings_handlers.rs"]

        QueryBus["QueryBus<br/>src/cqrs/bus.rs"] --> GraphHandlers
        QueryBus --> OntologyHandlers
        QueryBus --> SettingsHandlers
    end

    subgraph EVENTS["Event-Driven System"]
        direction TB
        GraphHandlers --> EventBus["EventBus<br/>src/events/bus.rs"]
        OntologyHandlers --> EventBus
        EventBus --> GraphEventHandler["GraphEventHandler<br/>src/events/handlers/graph_handler.rs"]
        EventBus --> OntologyEventHandler["OntologyEventHandler<br/>src/events/handlers/ontology_handler.rs"]
        EventBus --> InferenceTrigger["InferenceTriggerHandler<br/>src/events/inference_triggers.rs"]
    end

    subgraph GPU["GPU Compute Pipeline"]
        direction TB
        NEO4J --> GPUManager["GPUManagerActor<br/>src/actors/gpu/gpu_manager_actor.rs"]
        AxiomMapper --> ConstraintActor["ConstraintActor<br/>src/actors/gpu/constraint_actor.rs"]

        subgraph PHYSICS["Physics Subsystem"]
            ForceActor["ForceComputeActor<br/>src/actors/gpu/force_compute_actor.rs"]
            StressActor["StressMajorizationActor<br/>src/actors/gpu/stress_majorization_actor.rs"]
            SemanticActor["SemanticForcesActor<br/>src/actors/gpu/semantic_forces_actor.rs"]
        end

        subgraph ANALYTICS["Analytics Subsystem"]
            ClusterActor["ClusteringActor<br/>src/actors/gpu/clustering_actor.rs"]
            AnomalyActor["AnomalyDetectionActor<br/>src/actors/gpu/anomaly_detection_actor.rs"]
            PageRankActor["PageRankActor<br/>src/actors/gpu/pagerank_actor.rs"]
        end

        subgraph GRAPH_ALGO["Graph Algorithms Subsystem"]
            PathActor["ShortestPathActor<br/>src/actors/gpu/shortest_path_actor.rs"]
            ComponentsActor["ConnectedComponentsActor<br/>src/actors/gpu/connected_components_actor.rs"]
            OntConstraintActor["OntologyConstraintActor<br/>src/actors/gpu/ontology_constraint_actor.rs"]
        end

        GPUManager --> PHYSICS
        GPUManager --> ANALYTICS
        GPUManager --> GRAPH_ALGO
        ConstraintActor --> PHYSICS

        PHYSICS --> UnifiedGPU["UnifiedGPUCompute<br/>src/utils/unified_gpu_compute.rs"]
        ANALYTICS --> UnifiedGPU
        GRAPH_ALGO --> UnifiedGPU

        UnifiedGPU --> MemoryManager["GpuMemoryManager<br/>src/gpu/memory_manager.rs"]
        MemoryManager --> PTX["PTX Kernels<br/>src/utils/ptx.rs"]
        PTX --> CUDA[("CUDA Device<br/>GPU Memory")]
    end

    subgraph BROADCAST["Real-time Broadcast Layer"]
        direction TB
        UnifiedGPU --> StreamingPipeline["StreamingPipeline<br/>src/gpu/streaming_pipeline.rs"]
        StreamingPipeline --> BroadcastOpt["BroadcastOptimizer<br/>src/gpu/broadcast_optimizer.rs"]
        BroadcastOpt --> Backpressure["NetworkBackpressure<br/>src/gpu/backpressure.rs"]

        Backpressure --> SocketFlow["SocketFlowHandler<br/>src/handlers/socket_flow_handler.rs"]
        Backpressure --> RealtimeWS["RealtimeWebSocketHandler<br/>src/handlers/realtime_websocket_handler.rs"]
        Backpressure --> FastWS["FastWebSocketServer<br/>src/handlers/fastwebsockets_handler.rs"]
        Backpressure --> QUIC["QuicTransportServer<br/>src/handlers/quic_transport_handler.rs"]

        SolidProxy --> JSSBridge["JssWebSocketBridge<br/>src/services/jss_websocket_bridge.rs"]
        JSSBridge --> RealtimeWS

        SocketFlow --> BinaryProto["BinaryProtocol<br/>src/utils/binary_protocol.rs"]
        RealtimeWS --> BinaryProto
    end

    subgraph CLIENT["Client Application"]
        direction TB
        BinaryProto --> WSService["WebSocketService<br/>client/src/services/WebSocketService.ts"]

        WSService --> BinaryDecode["BinaryWebSocketProtocol<br/>client/src/services/BinaryWebSocketProtocol.ts"]
        WSService --> SettingsStore["useSettingsStore<br/>client/src/store/settingsStore.ts"]
        WSService --> MultiUserStore["useMultiUserStore<br/>client/src/store/multiUserStore.ts"]

        BinaryDecode --> GraphManager["GraphDataManager<br/>client/src/features/graph/managers/graphDataManager.ts"]
        BinaryDecode --> BotsManager["BotsDataContext<br/>client/src/features/bots/contexts/BotsDataContext.tsx"]

        subgraph FEATURES["Feature Modules"]
            GraphModule["Graph Feature<br/>client/src/features/graph/"]
            OntologyModule["Ontology Feature<br/>client/src/features/ontology/"]
            BotsModule["Bots Feature<br/>client/src/features/bots/"]
            SettingsModule["Settings Feature<br/>client/src/features/settings/"]
            SolidModule["Solid Feature<br/>client/src/features/solid/"]
            PhysicsModule["Physics Feature<br/>client/src/features/physics/"]
            AnalyticsModule["Analytics Feature<br/>client/src/features/analytics/"]
        end

        GraphManager --> FEATURES
        SettingsStore --> FEATURES

        FEATURES --> ThreeJS["Three.js Renderer<br/>React Three Fiber"]
        ThreeJS --> Hologram["HolographicDataSphere<br/>client/src/features/visualisation/"]
        ThreeJS --> VRCanvas["VRGraphCanvas<br/>client/src/immersive/threejs/"]

        NostrClient["nostrAuthService<br/>client/src/services/nostrAuthService.ts"] --> WSService
        SolidClient["SolidPodService<br/>client/src/services/SolidPodService.ts"] --> WSService
        VoiceService["VoiceWebSocketService<br/>client/src/services/VoiceWebSocketService.ts"] --> WSService
    end

    subgraph AGENTS["Multi-Agent Coordination"]
        direction TB
        McpRelay["McpRelayManager<br/>src/services/mcp_relay_manager.rs"]
        AgentDiscovery["MultiMcpAgentDiscovery<br/>src/services/multi_mcp_agent_discovery.rs"]
        AgentVizProc["AgentVisualizationProcessor<br/>src/services/agent_visualization_processor.rs"]

        McpRelay --> AgentDiscovery
        AgentDiscovery --> AgentVizProc
        AgentVizProc --> BotsModule
    end

    subgraph VOICE["Voice & Speech"]
        direction TB
        SpeechService["SpeechService<br/>src/services/speech_service.rs"]
        VoiceContext["VoiceContextManager<br/>src/services/voice_context_manager.rs"]
        SpeechSocket["SpeechSocketHandler<br/>src/handlers/speech_socket_handler.rs"]

        VoiceService --> SpeechSocket
        SpeechSocket --> SpeechService
        SpeechService --> VoiceContext
    end

    subgraph EXPORT["Export & Persistence"]
        direction TB
        NEO4J --> ExportHandler["GraphExportHandler<br/>src/handlers/graph_export_handler.rs"]
        ExportHandler --> Serialization["GraphSerializationService<br/>src/services/graph_serialization.rs"]

        Serialization --> JSON["JSON Export"]
        Serialization --> GEXF["GEXF Export"]
        Serialization --> GraphML["GraphML Export"]
        Serialization --> Turtle["Turtle/RDF Export"]

        NEO4J --> JSSSync["JssSyncService<br/>src/services/jss_sync_service.rs"]
        JSSSync --> JSS
    end

    subgraph EXTERNAL["External Integrations"]
        direction TB
        PerplexityService["PerplexityService<br/>src/services/perplexity_service.rs"]
        RagflowService["RAGFlowService<br/>src/services/ragflow_service.rs"]
        NLQuery["NaturalLanguageQueryService<br/>src/services/natural_language_query_service.rs"]

        PerplexityService --> NLQuery
        RagflowService --> NLQuery
    end

    %% Cross-layer connections
    AuthMiddleware -.-> GraphRepo
    AuthMiddleware -.-> SettingsRepo
    NostrService -.-> NostrClient
    InferenceTrigger -.-> WhelkEngine
    AGENTS -.-> BROADCAST
    VOICE -.-> BROADCAST
```

```mermaid
sequenceDiagram
    participant User
    participant Client as React Client
    participant WS as WebSocket
    participant Auth as NostrService
    participant API as Actix API
    participant CQRS as CQRS Bus
    participant Neo4j as Neo4j DB
    participant GPU as GPU Pipeline
    participant JSS as Solid Server

    User->>Client: Open Application
    Client->>Auth: Check NIP-07 Extension
    Auth-->>Client: Extension Available

    User->>Client: Click Login
    Client->>Auth: Request Signature (NIP-42)
    Auth->>API: POST /auth/nostr (signed event)
    API->>API: Verify Schnorr Signature
    API-->>Client: Session Token + User

    Client->>WS: Connect WebSocket
    WS->>API: Authenticate Session
    API-->>WS: Connection Established

    Client->>API: GET /graph
    API->>CQRS: Query: GetGraphData
    CQRS->>Neo4j: Load Graph Data
    Neo4j-->>CQRS: Nodes + Edges
    CQRS-->>API: GraphData
    API->>GPU: Initialize Physics
    GPU->>GPU: Load PTX Kernels
    GPU-->>API: Physics Ready

    loop Every 16ms (60fps)
        GPU->>GPU: Compute Forces (CUDA)
        GPU->>GPU: Apply Constraints
        GPU->>GPU: Integrate Positions
        GPU->>WS: Binary Position Update (36 bytes/node)
        WS->>Client: Broadcast Positions
        Client->>Client: Update Three.js Scene
    end

    User->>Client: Edit Ontology
    Client->>JSS: PUT /solid/pods/{npub}/ontology/proposals/
    JSS-->>Client: 201 Created
    JSS->>WS: pub notification
    WS->>Client: Resource Changed Event

    User->>Client: Trigger Inference
    Client->>API: POST /inference/run
    API->>CQRS: Command: RunInference
    CQRS->>GPU: Whelk OWL Reasoning
    GPU-->>CQRS: InferredAxioms
    CQRS->>Neo4j: Store Inferences
    CQRS-->>API: InferenceResult
    API-->>Client: New Constraints Applied

    User->>Client: Export Graph
    Client->>API: POST /export {format: GEXF}
    API->>CQRS: Query: ExportGraph
    CQRS->>Neo4j: Query Full Graph
    Neo4j-->>CQRS: Graph Data
    CQRS->>CQRS: Serialize to GEXF
    CQRS-->>API: ExportResult
    API-->>Client: Download File
```

```mermaid
classDiagram
    class Node {
        +u32 id
        +String metadata_id
        +String label
        +BinaryNodeData data
        +Option~f32~ x, y, z
        +Option~f32~ vx, vy, vz
        +Option~f32~ mass
        +Option~String~ owl_class_iri
        +HashMap~String, String~ metadata
    }

    class Edge {
        +String id
        +u32 source
        +u32 target
        +f32 weight
        +Option~String~ edge_type
        +Option~String~ owl_property_iri
    }

    class GraphData {
        +Vec~Node~ nodes
        +Vec~Edge~ edges
        +MetadataStore metadata
    }

    class NostrUser {
        +String pubkey
        +String npub
        +bool is_power_user
        +ApiKeys api_keys
        +i64 last_seen
    }

    class OWLClass {
        +String iri
        +Option~String~ label
        +Option~String~ parent_class_iri
    }

    class PhysicsConstraint {
        +ConstraintKind kind
        +Vec~u32~ node_indices
        +Vec~f32~ params
        +f32 weight
    }

    class SimParams {
        +f32 dt
        +f32 damping
        +f32 spring_k
        +f32 repel_k
        +u32 feature_flags
        +f32 temperature
    }

    class AgentStatus {
        +String agent_id
        +String status
        +Option~Vec3~ position
        +f32 health
        +f32 activity
        +TokenUsage token_usage
    }

    GraphData "1" *-- "*" Node
    GraphData "1" *-- "*" Edge
    Node "0..1" --> OWLClass : owl_class_iri
    Edge "0..1" --> OWLClass : owl_property_iri
    PhysicsConstraint --> Node : node_indices
    AgentStatus --> Node : position
```

================================================================================
                              FILE INVENTORY
================================================================================

Total Files Identified: 855+
Categories:
  - Backend Rust Source: 382 files (169,000+ lines)
  - Client TypeScript: 363 files
  - Documentation: 50+ files
  - Configuration: 60+ files

Backend Modules:
  - src/actors/: 47 files (GPU actors, messaging, supervision)
  - src/adapters/: 12 files (Neo4j, GPU, repositories)
  - src/application/: 15 files (CQRS application layer)
  - src/config/: 4 files (configuration management)
  - src/constraints/: 10 files (OWL axiom to physics constraints)
  - src/cqrs/: 15 files (command/query handlers)
  - src/events/: 12 files (event-driven system)
  - src/gpu/: 10 files (GPU compute, memory, streaming)
  - src/handlers/: 50+ files (HTTP/WebSocket handlers)
  - src/inference/: 5 files (OWL reasoning with whelk-rs)
  - src/middleware/: 5 files (auth, rate limiting)
  - src/models/: 14 files (data types)
  - src/ontology/: 8 files (OWL parsing, physics)
  - src/physics/: 5 files (stress majorization, constraints)
  - src/ports/: 10 files (trait definitions)
  - src/services/: 50+ files (business logic)
  - src/settings/: 5 files (settings management)
  - src/telemetry/: 3 files (logging, observability)
  - src/types/: 5 files (type definitions)
  - src/utils/: 70+ files (helpers, GPU, validation)

Client Modules:
  - client/src/api/: 8 files (API endpoints)
  - client/src/app/: 5 files (main application)
  - client/src/components/: 20 files (UI components)
  - client/src/contexts/: 3 files (React contexts)
  - client/src/features/analytics/: 8 files
  - client/src/features/bots/: 20 files (agent visualization)
  - client/src/features/command-palette/: 6 files
  - client/src/features/design-system/: 25 files
  - client/src/features/graph/: 25 files (graph visualization)
  - client/src/features/help/: 5 files
  - client/src/features/monitoring/: 4 files
  - client/src/features/onboarding/: 8 files
  - client/src/features/ontology/: 15 files
  - client/src/features/physics/: 8 files
  - client/src/features/settings/: 25 files
  - client/src/features/solid/: 8 files
  - client/src/features/visualisation/: 40 files
  - client/src/features/workspace/: 2 files
  - client/src/hooks/: 25 files
  - client/src/immersive/: 5 files (VR/AR)
  - client/src/rendering/: 5 files (materials, bloom)
  - client/src/services/: 25 files (WebSocket, auth, audio)
  - client/src/store/: 5 files (Zustand stores)
  - client/src/telemetry/: 4 files
  - client/src/types/: 10 files
  - client/src/utils/: 15 files
  - client/src/xr/: 10 files (WebXR)

================================================================================
                    SECTION 1: CORE DATA MODELS (RUST)
================================================================================


--------------------------------------------------------------------------------
FILE: src/models/mod.rs
PURPOSE: Module exports for all data models
--------------------------------------------------------------------------------
pub mod constraints;
pub mod edge;
pub mod graph;
pub mod graph_export;
pub mod graph_types;
pub mod metadata;
pub mod node;
pub mod pagination;
pub mod protected_settings;
pub mod ragflow_chat;
pub mod simulation_params;
pub mod user_settings;
pub mod workspace;

pub use metadata::MetadataStore;
pub use pagination::PaginationParams;
pub use protected_settings::ProtectedSettings;
pub use simulation_params::SimulationParams;
pub use user_settings::UserSettings;
pub use workspace::{
    CreateWorkspaceRequest, UpdateWorkspaceRequest, Workspace, WorkspaceListResponse,
    WorkspaceResponse,
};

--------------------------------------------------------------------------------
FILE: src/models/node.rs
PURPOSE: Graph node data structure with physics properties and OWL class IRI
--------------------------------------------------------------------------------
use crate::config::dev_config;
use crate::utils::socket_flow_messages::BinaryNodeData;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::atomic::{AtomicU32, Ordering};

// Static counter for generating unique numeric IDs
static NEXT_NODE_ID: AtomicU32 = AtomicU32::new(1); 

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct Node {
    
    pub id: u32,
    pub metadata_id: String, 
    pub label: String,
    pub data: BinaryNodeData,

    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub x: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub y: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub z: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub vx: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub vy: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub vz: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub mass: Option<f32>,

    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub owl_class_iri: Option<String>,

    
    #[serde(skip_serializing_if = "HashMap::is_empty")]
    pub metadata: HashMap<String, String>,
    #[serde(skip)]
    pub file_size: u64,

    
    #[serde(rename = "type")]
    #[serde(skip_serializing_if = "Option::is_none")]
    pub node_type: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub size: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub color: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub weight: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub group: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub user_data: Option<HashMap<String, String>>,
}

impl Node {
    pub fn new(metadata_id: String) -> Self {
        Self::new_with_id(metadata_id, None)
    }

    pub fn new_with_id(metadata_id: String, provided_id: Option<u32>) -> Self {
        
        
        let id = match provided_id {
            Some(id) if id != 0 => {
                
                id
            }
            _ => NEXT_NODE_ID.fetch_add(1, Ordering::SeqCst),
        };

        
        
        use rand::Rng;
        let mut rng = rand::thread_rng();
        let physics = dev_config::physics();

        
        let theta = rng.gen::<f32>() * 2.0 * std::f32::consts::PI; 
        let phi = rng.gen::<f32>() * std::f32::consts::PI; 

        
        let radius = physics.initial_radius_min + rng.gen::<f32>() * physics.initial_radius_range;

        let pos_x = radius * phi.sin() * theta.cos();
        let pos_y = radius * phi.sin() * theta.sin();
        let pos_z = radius * phi.cos();

        Self {
            id,
            metadata_id: metadata_id.clone(),
            label: String::new(), 
            data: BinaryNodeData {
                node_id: id,
                
                x: pos_x,
                y: pos_y,
                z: pos_z,
                vx: 0.0, 
                vy: 0.0, 
                vz: 0.0,
            },
            
            x: Some(pos_x),
            y: Some(pos_y),
            z: Some(pos_z),
            vx: Some(0.0),
            vy: Some(0.0),
            vz: Some(0.0),
            mass: Some(1.0), 
            owl_class_iri: None,
            metadata: HashMap::new(),
            file_size: 0,
            node_type: None,
            size: None,
            color: None,
            weight: None,
            group: None,
            user_data: None,
        }
    }

    pub fn set_file_size(&mut self, size: u64) {
        self.file_size = size;
        

        
        
        if size > 0 {
            self.metadata
                .insert("fileSize".to_string(), size.to_string());
        }
    }

    pub fn with_position(mut self, x: f32, y: f32, z: f32) -> Self {
        self.data.x = x;
        self.data.y = y;
        self.data.z = z;
        self.x = Some(x);
        self.y = Some(y);
        self.z = Some(z);
        self
    }

    pub fn with_velocity(mut self, vx: f32, vy: f32, vz: f32) -> Self {
        self.data.vx = vx;
        self.data.vy = vy;
        self.data.vz = vz;
        self.vx = Some(vx);
        self.vy = Some(vy);
        self.vz = Some(vz);
        self
    }

    pub fn with_mass(mut self, mass: f32) -> Self {
        self.mass = Some(mass);
        self
    }

    pub fn with_owl_class_iri(mut self, iri: String) -> Self {
        self.owl_class_iri = Some(iri);
        self
    }

    pub fn with_label(mut self, label: String) -> Self {
        self.label = label;
        self
    }

    pub fn with_metadata(mut self, key: String, value: String) -> Self {
        self.metadata.insert(key, value);
        self
    }

    pub fn with_type(mut self, node_type: String) -> Self {
        self.node_type = Some(node_type);
        self
    }

    pub fn with_size(mut self, size: f32) -> Self {
        self.size = Some(size);
        self
    }

    pub fn with_color(mut self, color: String) -> Self {
        self.color = Some(color);
        self
    }

    pub fn with_weight(mut self, weight: f32) -> Self {
        self.weight = Some(weight);
        self
    }

    pub fn with_group(mut self, group: String) -> Self {
        self.group = Some(group);
        self
    }

    
    pub fn new_with_stored_id(metadata_id: String, stored_node_id: Option<u32>) -> Self {
        
        let id = match stored_node_id {
            Some(stored_id) => stored_id,
            None => NEXT_NODE_ID.fetch_add(1, Ordering::SeqCst),
        };

        
        let id_hash = id as f32;
        let angle = id_hash * 0.618033988749895; 
        let radius = (id_hash * 0.1).min(100.0); 

        let pos_x = radius * angle.cos() * 2.0;
        let pos_y = radius * angle.sin() * 2.0;
        let pos_z = (id_hash * 0.01 - 50.0).max(-100.0).min(100.0);

        Self {
            id,
            metadata_id: metadata_id.clone(),
            label: metadata_id,
            data: BinaryNodeData {
                node_id: id,
                x: pos_x,
                y: pos_y,
                z: pos_z,
                vx: 0.0,
                vy: 0.0,
                vz: 0.0,
            },
            
            x: Some(pos_x),
            y: Some(pos_y),
            z: Some(pos_z),
            vx: Some(0.0),
            vy: Some(0.0),
            vz: Some(0.0),
            mass: Some(1.0), 
            owl_class_iri: None,
            metadata: HashMap::new(),
            file_size: 0,
            node_type: None,
            size: None,
            color: None,
            weight: None,
            group: None,
            user_data: None,
        }
    }

    pub fn calculate_mass(file_size: u64) -> u8 {
        
        
        let base_mass = ((file_size + 1) as f32).log10() / 4.0;
        
        let mass = base_mass.max(0.1).min(10.0);
        (mass * 255.0 / 10.0) as u8
    }

    
    pub fn x(&self) -> f32 {
        self.data.x
    }
    pub fn y(&self) -> f32 {
        self.data.y
    }
    pub fn z(&self) -> f32 {
        self.data.z
    }
    pub fn vx(&self) -> f32 {
        self.data.vx
    }
    pub fn vy(&self) -> f32 {
        self.data.vy
    }
    pub fn vz(&self) -> f32 {
        self.data.vz
    }

    pub fn set_x(&mut self, val: f32) {
        self.data.x = val;
        self.x = Some(val);
    }
    pub fn set_y(&mut self, val: f32) {
        self.data.y = val;
        self.y = Some(val);
    }
    pub fn set_z(&mut self, val: f32) {
        self.data.z = val;
        self.z = Some(val);
    }
    pub fn set_vx(&mut self, val: f32) {
        self.data.vx = val;
        self.vx = Some(val);
    }
    pub fn set_vy(&mut self, val: f32) {
        self.data.vy = val;
        self.vy = Some(val);
    }
    pub fn set_vz(&mut self, val: f32) {
        self.data.vz = val;
        self.vz = Some(val);
    }

    pub fn set_mass(&mut self, val: f32) {
        self.mass = Some(val);
    }

    pub fn get_mass(&self) -> f32 {
        self.mass.unwrap_or(1.0)
    }

    
    pub fn id_as_string(&self) -> String {
        self.id.to_string()
    }

    
    pub fn from_string_id(
        id_str: &str,
        metadata_id: String,
    ) -> Result<Self, std::num::ParseIntError> {
        let id: u32 = id_str.parse()?;
        Ok(Self::new_with_stored_id(metadata_id, Some(id)))
    }
}

impl Default for Node {
    fn default() -> Self {
        Self::new("default".to_string())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::atomic::Ordering;

    #[test]
    fn test_numeric_id_generation() {
        
        let start_value = NEXT_NODE_ID.load(Ordering::SeqCst);

        
        let node1 = Node::new("test-file-1.md".to_string());
        let node2 = Node::new("test-file-2.md".to_string());

        
        assert_ne!(node1.id, node2.id);

        
        assert_eq!(node1.metadata_id, "test-file-1.md");
        assert_eq!(node2.metadata_id, "test-file-2.md");

        
        assert_eq!(node1.id + 1, node2.id);

        
        let end_value = NEXT_NODE_ID.load(Ordering::SeqCst);
        assert_eq!(end_value, start_value + 2);
    }

    #[test]
    fn test_node_creation() {
        let node = Node::new("test".to_string())
            .with_label("Test Node".to_string())
            .with_position(1.0, 2.0, 3.0)
            .with_velocity(0.1, 0.2, 0.3)
            .with_type("test_type".to_string())
            .with_size(1.5)
            .with_color("#FF0000".to_string())
            .with_weight(2.0)
            .with_group("group1".to_string());

        
        assert!(node.id > 0, "ID should be positive, got: {}", node.id);
        assert_eq!(node.metadata_id, "test");
        assert_eq!(node.label, "Test Node");
        assert_eq!(node.data.x, 1.0);
        assert_eq!(node.data.y, 2.0);
        assert_eq!(node.data.z, 3.0);
        assert_eq!(node.data.vx, 0.1);
        assert_eq!(node.data.vy, 0.2);
        assert_eq!(node.data.vz, 0.3);
        assert_eq!(node.node_type, Some("test_type".to_string()));
        assert_eq!(node.size, Some(1.5));
        assert_eq!(node.color, Some("#FF0000".to_string()));
        assert_eq!(node.weight, Some(2.0));
        assert_eq!(node.group, Some("group1".to_string()));
    }

    #[test]
    fn test_position_velocity_getters_setters() {
        let mut node = Node::new("test".to_string());

        node.set_x(1.0);
        node.set_y(2.0);
        node.set_z(3.0);
        node.set_vx(0.1);
        node.set_vy(0.2);
        node.set_vz(0.3);

        assert_eq!(node.x(), 1.0);
        assert_eq!(node.y(), 2.0);
        assert_eq!(node.z(), 3.0);
        assert_eq!(node.vx(), 0.1);
        assert_eq!(node.vy(), 0.2);
        assert_eq!(node.vz(), 0.3);
    }

    
    
    
    
    
    
    
}

--------------------------------------------------------------------------------
FILE: src/models/edge.rs
PURPOSE: Graph edge data structure with weight and OWL property IRI
--------------------------------------------------------------------------------
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

///
#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct Edge {
    pub id: String, 
    pub source: u32,
    pub target: u32,
    pub weight: f32,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub edge_type: Option<String>,

    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub owl_property_iri: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub metadata: Option<HashMap<String, String>>,
}

impl Edge {
    pub fn new(source: u32, target: u32, weight: f32) -> Self {
        
        let id = format!("{}-{}", source, target);
        Self {
            id,
            source,
            target,
            weight,
            edge_type: None,
            owl_property_iri: None,
            metadata: None,
        }
    }

    
    pub fn with_owl_property_iri(mut self, iri: String) -> Self {
        self.owl_property_iri = Some(iri);
        self
    }

    
    pub fn with_edge_type(mut self, edge_type: String) -> Self {
        self.edge_type = Some(edge_type);
        self
    }

    
    pub fn with_metadata(mut self, metadata: HashMap<String, String>) -> Self {
        self.metadata = Some(metadata);
        self
    }

    
    pub fn add_metadata(mut self, key: String, value: String) -> Self {
        if let Some(ref mut map) = self.metadata {
            map.insert(key, value);
        } else {
            let mut map = HashMap::new();
            map.insert(key, value);
            self.metadata = Some(map);
        }
        self
    }
}

--------------------------------------------------------------------------------
FILE: src/models/graph.rs
PURPOSE: GraphData container for nodes, edges, and metadata
--------------------------------------------------------------------------------
use super::edge::Edge;
use super::metadata::MetadataStore;
use crate::models::node::Node;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

///
///
#[derive(Default, Serialize, Deserialize, Clone, Debug)]
#[serde(rename_all = "camelCase")]
pub struct GraphData {
    
    pub nodes: Vec<Node>,
    
    pub edges: Vec<Edge>,
    
    pub metadata: MetadataStore,
    
    #[serde(skip)]
    pub id_to_metadata: HashMap<String, String>,
}

impl GraphData {
    pub fn new() -> Self {
        Self {
            nodes: Vec::new(),
            edges: Vec::new(),
            metadata: MetadataStore::new(),
            id_to_metadata: HashMap::new(),
        }
    }
}

--------------------------------------------------------------------------------
FILE: src/models/graph_types.rs
PURPOSE: Type aliases and graph-related type conversions
--------------------------------------------------------------------------------
//! Graph type definitions for multi-agent systems and semantic forces

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum GraphType {

    Standard,

    MultiAgent,

    ForceDirected,

    Hierarchical,

    Network,

    Ontology,
}

/// Semantic node types for type-aware physics and pathfinding
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum NodeType {
    /// Generic untyped node
    Generic,
    /// Person or individual entity
    Person,
    /// Organization or group
    Organization,
    /// Project or initiative
    Project,
    /// Task or action item
    Task,
    /// Concept or abstract idea
    Concept,
    /// OWL class definition
    Class,
    /// OWL individual instance
    Individual,
    /// Custom user-defined type
    Custom(String),
}

/// Semantic edge types for relationship-aware algorithms
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum EdgeType {
    /// Generic untyped edge
    Generic,
    /// Dependency relationship
    Dependency,
    /// Hierarchical parent-child relationship
    Hierarchy,
    /// General association
    Association,
    /// Sequential ordering
    Sequence,
    /// OWL subClassOf relationship
    SubClassOf,
    /// OWL instanceOf relationship
    InstanceOf,
    /// Custom user-defined type
    Custom(String),
}

impl Default for GraphType {
    fn default() -> Self {
        GraphType::Standard
    }
}

impl std::fmt::Display for GraphType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            GraphType::Standard => write!(f, "standard"),
            GraphType::MultiAgent => write!(f, "multi-agent"),
            GraphType::ForceDirected => write!(f, "force-directed"),
            GraphType::Hierarchical => write!(f, "hierarchical"),
            GraphType::Network => write!(f, "network"),
            GraphType::Ontology => write!(f, "ontology"),
        }
    }
}

impl std::str::FromStr for GraphType {
    type Err = String;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_lowercase().as_str() {
            "standard" => Ok(GraphType::Standard),
            "multi-agent" | "multiagent" => Ok(GraphType::MultiAgent),
            "force-directed" | "forcedirected" => Ok(GraphType::ForceDirected),
            "hierarchical" => Ok(GraphType::Hierarchical),
            "network" => Ok(GraphType::Network),
            "ontology" => Ok(GraphType::Ontology),
            _ => Err(format!("Unknown graph type: {}", s)),
        }
    }
}

impl Default for NodeType {
    fn default() -> Self {
        NodeType::Generic
    }
}

impl std::fmt::Display for NodeType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            NodeType::Generic => write!(f, "generic"),
            NodeType::Person => write!(f, "person"),
            NodeType::Organization => write!(f, "organization"),
            NodeType::Project => write!(f, "project"),
            NodeType::Task => write!(f, "task"),
            NodeType::Concept => write!(f, "concept"),
            NodeType::Class => write!(f, "class"),
            NodeType::Individual => write!(f, "individual"),
            NodeType::Custom(s) => write!(f, "{}", s),
        }
    }
}

impl std::str::FromStr for NodeType {
    type Err = String;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_lowercase().as_str() {
            "generic" => Ok(NodeType::Generic),
            "person" => Ok(NodeType::Person),
            "organization" | "org" => Ok(NodeType::Organization),
            "project" => Ok(NodeType::Project),
            "task" => Ok(NodeType::Task),
            "concept" => Ok(NodeType::Concept),
            "class" => Ok(NodeType::Class),
            "individual" => Ok(NodeType::Individual),
            _ => Ok(NodeType::Custom(s.to_string())),
        }
    }
}

impl Default for EdgeType {
    fn default() -> Self {
        EdgeType::Generic
    }
}

impl std::fmt::Display for EdgeType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            EdgeType::Generic => write!(f, "generic"),
            EdgeType::Dependency => write!(f, "dependency"),
            EdgeType::Hierarchy => write!(f, "hierarchy"),
            EdgeType::Association => write!(f, "association"),
            EdgeType::Sequence => write!(f, "sequence"),
            EdgeType::SubClassOf => write!(f, "subClassOf"),
            EdgeType::InstanceOf => write!(f, "instanceOf"),
            EdgeType::Custom(s) => write!(f, "{}", s),
        }
    }
}

impl std::str::FromStr for EdgeType {
    type Err = String;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_lowercase().as_str() {
            "generic" => Ok(EdgeType::Generic),
            "dependency" | "depends" => Ok(EdgeType::Dependency),
            "hierarchy" | "parent-child" => Ok(EdgeType::Hierarchy),
            "association" | "assoc" => Ok(EdgeType::Association),
            "sequence" | "seq" => Ok(EdgeType::Sequence),
            "subclassof" | "subclass" => Ok(EdgeType::SubClassOf),
            "instanceof" | "instance" => Ok(EdgeType::InstanceOf),
            _ => Ok(EdgeType::Custom(s.to_string())),
        }
    }
}

--------------------------------------------------------------------------------
FILE: src/models/user_settings.rs
PURPOSE: User settings and preferences data structure
--------------------------------------------------------------------------------
use log::{debug, error, info, warn};
use once_cell::sync::Lazy;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs;
use std::path::PathBuf;
use std::sync::{Arc, RwLock};
use std::time::{Duration, Instant};
use tracing::{debug as trace_debug, info as trace_info};
use uuid::Uuid;

use crate::config::AppFullSettings;
use crate::utils::time;

// Global cache for user settings
static USER_SETTINGS_CACHE: Lazy<Arc<RwLock<HashMap<String, CachedUserSettings>>>> =
    Lazy::new(|| Arc::new(RwLock::new(HashMap::new())));

// Cache expiration time (10 minutes)
const CACHE_EXPIRATION: Duration = Duration::from_secs(10 * 60);

// Cache entry with timestamp
struct CachedUserSettings {
    settings: UserSettings,
    timestamp: Instant,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UserSettings {
    pub pubkey: String,
    pub settings: AppFullSettings,
    pub last_modified: i64,
}

impl UserSettings {
    pub fn new(pubkey: &str, settings: AppFullSettings) -> Self {
        Self {
            pubkey: pubkey.to_string(),
            settings,
            last_modified: time::timestamp_seconds(),
        }
    }

    pub fn load(pubkey: &str) -> Option<Self> {
        let request_id = Uuid::new_v4();

        
        {
            let cache = match USER_SETTINGS_CACHE.read() {
                Ok(cache) => cache,
                Err(e) => {
                    error!("Failed to read user settings cache: {}", e);
                    return None;
                }
            };
            if let Some(cached) = cache.get(pubkey) {
                
                if cached.timestamp.elapsed() < CACHE_EXPIRATION {
                    debug!("Using cached settings for user {}", pubkey);
                    trace_debug!(
                        request_id = %request_id,
                        user_id = %pubkey,
                        cache_hit = true,
                        cache_age_secs = cached.timestamp.elapsed().as_secs(),
                        "Loading user settings - cache hit"
                    );
                    return Some(cached.settings.clone());
                }
                
                debug!("Cache expired for user {}, reloading from disk", pubkey);
                trace_debug!(
                    request_id = %request_id,
                    user_id = %pubkey,
                    cache_hit = false,
                    cache_age_secs = cached.timestamp.elapsed().as_secs(),
                    reason = "cache_expired",
                    "Cache expired, reloading from disk"
                );
            } else {
                trace_debug!(
                    request_id = %request_id,
                    user_id = %pubkey,
                    cache_hit = false,
                    reason = "not_in_cache",
                    "User not in cache, loading from disk"
                );
            }
        }

        
        let path = Self::get_settings_path(pubkey);
        match fs::read_to_string(&path) {
            Ok(content) => {
                match serde_yaml::from_str::<UserSettings>(&content) {
                    Ok(settings) => {
                        
                        let settings_clone = settings.clone();
                        {
                            let mut cache = match USER_SETTINGS_CACHE.write() {
                                Ok(cache) => cache,
                                Err(e) => {
                                    error!("Failed to write to user settings cache: {}", e);
                                    
                                    return Some(settings);
                                }
                            };
                            cache.insert(
                                pubkey.to_string(),
                                CachedUserSettings {
                                    settings: settings_clone,
                                    timestamp: Instant::now(),
                                },
                            );
                        }
                        info!("Loaded settings for user {} and added to cache", pubkey);
                        Some(settings)
                    }
                    Err(e) => {
                        error!("Failed to parse settings for user {}: {}", pubkey, e);
                        None
                    }
                }
            }
            Err(e) => {
                debug!("No settings file found for user {}: {}", pubkey, e);
                None
            }
        }
    }

    pub fn save(&self) -> Result<(), String> {
        let path = Self::get_settings_path(&self.pubkey);

        
        {
            let mut cache = match USER_SETTINGS_CACHE.write() {
                Ok(cache) => cache,
                Err(e) => {
                    warn!("Failed to write to user settings cache during save: {}", e);
                    
                    return self.save_to_disk();
                }
            };
            cache.insert(
                self.pubkey.clone(),
                CachedUserSettings {
                    settings: self.clone(),
                    timestamp: Instant::now(),
                },
            );
            debug!("Updated cache for user {}", self.pubkey);
        }

        
        if let Some(parent) = path.parent() {
            if let Err(e) = fs::create_dir_all(parent) {
                warn!("Failed to create settings directory: {}", e);
                return Err(format!("Failed to create settings directory: {}", e));
            }
        }

        
        
        let pubkey = self.pubkey.clone();
        let settings_clone = self.clone();

        std::thread::spawn(move || {
            debug!("Background thread saving settings for user {}", pubkey);
            match serde_yaml::to_string(&settings_clone) {
                Ok(yaml) => match fs::write(&path, yaml) {
                    Ok(_) => info!("Saved settings for user {} to disk", pubkey),
                    Err(e) => error!("Failed to write settings file for {}: {}", pubkey, e),
                },
                Err(e) => error!("Failed to serialize settings for {}: {}", pubkey, e),
            }
        });

        
        Ok(())
    }

    fn save_to_disk(&self) -> Result<(), String> {
        let path = Self::get_settings_path(&self.pubkey);

        
        if let Some(parent) = path.parent() {
            if let Err(e) = std::fs::create_dir_all(parent) {
                return Err(format!("Failed to create settings directory: {}", e));
            }
        }

        
        match serde_yaml::to_string(self) {
            Ok(content) => match std::fs::write(&path, content) {
                Ok(_) => {
                    debug!("Saved settings to disk for user {}", self.pubkey);
                    Ok(())
                }
                Err(e) => Err(format!("Failed to write settings file: {}", e)),
            },
            Err(e) => Err(format!("Failed to serialize settings: {}", e)),
        }
    }

    fn get_settings_path(pubkey: &str) -> PathBuf {
        PathBuf::from("/app/user_settings").join(format!("{}.yaml", pubkey))
    }

    
    pub fn clear_cache(pubkey: &str) {
        let mut cache = match USER_SETTINGS_CACHE.write() {
            Ok(cache) => cache,
            Err(e) => {
                error!(
                    "Failed to write to cache for clearing user {}: {}",
                    pubkey, e
                );
                return;
            }
        };
        if cache.remove(pubkey).is_some() {
            debug!("Cleared cache for user {}", pubkey);
            trace_info!(
                user_id = %pubkey,
                "User settings cache invalidated"
            );
        }
    }

    
    pub fn clear_all_cache() {
        let mut cache = match USER_SETTINGS_CACHE.write() {
            Ok(cache) => cache,
            Err(e) => {
                error!("Failed to write to cache for clearing all settings: {}", e);
                return;
            }
        };
        let count = cache.len();
        cache.clear();
        debug!("Cleared all cached settings ({} entries)", count);
        trace_info!(entries_cleared = count, "All user settings cache cleared");
    }

    
    pub fn invalidate_user_cache(pubkey: &str) {
        Self::clear_cache(pubkey);
        trace_info!(
            user_id = %pubkey,
            "User cache invalidated due to auth state change"
        );
    }

    
    pub fn get_cache_stats() -> (usize, Vec<(String, Duration)>) {
        let cache = match USER_SETTINGS_CACHE.read() {
            Ok(cache) => cache,
            Err(_) => return (0, Vec::new()),
        };

        let entries = cache.len();
        let ages: Vec<(String, Duration)> = cache
            .iter()
            .map(|(key, value)| (key.clone(), value.timestamp.elapsed()))
            .collect();

        (entries, ages)
    }
}

--------------------------------------------------------------------------------
FILE: src/models/protected_settings.rs
PURPOSE: Protected settings with API keys and Nostr user management
--------------------------------------------------------------------------------
use chrono::Utc;
use serde::{Deserialize, Serialize};
use crate::utils::json::{from_json, to_json};
use crate::utils::time;

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ApiKeys {
    pub perplexity: Option<String>,
    pub openai: Option<String>,
    pub ragflow: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct NostrUser {
    pub pubkey: String,
    pub npub: String,
    pub is_power_user: bool,
    pub api_keys: ApiKeys,
    pub last_seen: i64,
    pub session_token: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ProtectedSettings {
    pub network: NetworkSettings,
    pub security: SecuritySettings,
    pub websocket_server: WebSocketServerSettings,
    pub users: std::collections::HashMap<String, NostrUser>,
    pub default_api_keys: ApiKeys,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct NetworkSettings {
    pub bind_address: String,
    pub domain: String,
    pub port: u16,
    pub enable_http2: bool,
    pub enable_tls: bool,
    pub min_tls_version: String,
    pub max_request_size: usize,
    pub enable_rate_limiting: bool,
    pub rate_limit_requests: u32,
    pub rate_limit_window: u32,
    pub tunnel_id: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct SecuritySettings {
    pub allowed_origins: Vec<String>,
    pub audit_log_path: String,
    pub cookie_httponly: bool,
    pub cookie_samesite: String,
    pub cookie_secure: bool,
    pub csrf_token_timeout: u32,
    pub enable_audit_logging: bool,
    pub enable_request_validation: bool,
    pub session_timeout: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct WebSocketServerSettings {
    pub max_connections: usize,
    pub max_message_size: usize,
    pub url: String,
}

impl Default for ApiKeys {
    fn default() -> Self {
        Self {
            perplexity: None,
            openai: None,
            ragflow: None,
        }
    }
}

impl Default for ProtectedSettings {
    fn default() -> Self {
        Self {
            network: NetworkSettings {
                bind_address: "127.0.0.1".to_string(),
                domain: "localhost".to_string(),
                port: 3000,
                enable_http2: true,
                enable_tls: false,
                min_tls_version: "TLS1.2".to_string(),
                max_request_size: 10 * 1024 * 1024, 
                enable_rate_limiting: true,
                rate_limit_requests: 100,
                rate_limit_window: 60,
                tunnel_id: String::new(),
            },
            security: SecuritySettings {
                allowed_origins: vec!["http://localhost:3000".to_string()],
                audit_log_path: "./audit.log".to_string(),
                cookie_httponly: true,
                cookie_samesite: "Lax".to_string(),
                cookie_secure: false,
                csrf_token_timeout: 3600,
                enable_audit_logging: true,
                enable_request_validation: true,
                session_timeout: 86400,
            },
            websocket_server: WebSocketServerSettings {
                max_connections: 100,
                max_message_size: 32 * 1024 * 1024, 
                url: String::new(),
            },
            users: std::collections::HashMap::new(),
            default_api_keys: ApiKeys::default(),
        }
    }
}

impl ProtectedSettings {
    pub fn merge(&mut self, other: serde_json::Value) -> Result<(), String> {
        if let Some(network) = other.get("network") {
            if let Ok(network_settings) = serde_json::from_value(network.clone()) {
                self.network = network_settings;
            }
        }

        if let Some(security) = other.get("security") {
            if let Ok(security_settings) = serde_json::from_value(security.clone()) {
                self.security = security_settings;
            }
        }

        if let Some(websocket) = other.get("websocketServer") {
            if let Ok(websocket_settings) = serde_json::from_value(websocket.clone()) {
                self.websocket_server = websocket_settings;
            }
        }

        if let Some(users) = other.get("users") {
            if let Ok(user_settings) = serde_json::from_value(users.clone()) {
                self.users = user_settings;
            }
        }

        if let Some(api_keys) = other.get("defaultApiKeys") {
            if let Ok(keys) = serde_json::from_value(api_keys.clone()) {
                self.default_api_keys = keys;
            }
        }

        Ok(())
    }

    pub fn get_api_keys(&self, pubkey: &str) -> ApiKeys {
        if let Some(user) = self.users.get(pubkey) {
            if user.is_power_user {
                
                ApiKeys {
                    perplexity: std::env::var("PERPLEXITY_API_KEY").ok(),
                    openai: std::env::var("OPENAI_API_KEY").ok(),
                    ragflow: std::env::var("RAGFLOW_API_KEY").ok(),
                }
            } else {
                
                user.api_keys.clone()
            }
        } else {
            
            self.default_api_keys.clone()
        }
    }

    pub fn validate_client_token(&self, pubkey: &str, token: &str) -> bool {
        if let Some(user) = self.users.get(pubkey) {
            if let Some(session_token) = &user.session_token {
                return session_token == token;
            }
        }
        false
    }

    pub fn store_client_token(&mut self, pubkey: String, token: String) {
        if let Some(user) = self.users.get_mut(&pubkey) {
            user.session_token = Some(token);
            user.last_seen = time::timestamp_seconds();
        }
    }

    pub fn cleanup_expired_tokens(&mut self, max_age_hours: i64) {
        let now = time::timestamp_seconds();
        let max_age_secs = max_age_hours * 3600;

        self.users
            .retain(|_, user| now - user.last_seen < max_age_secs);
    }

    pub fn update_user_api_keys(
        &mut self,
        pubkey: &str,
        api_keys: ApiKeys,
    ) -> Result<NostrUser, String> {
        if let Some(user) = self.users.get_mut(pubkey) {
            if !user.is_power_user {
                user.api_keys = api_keys;
                user.last_seen = time::timestamp_seconds();
                Ok(user.clone())
            } else {
                Err("Cannot update API keys for power users".to_string())
            }
        } else {
            Err("User not found".to_string())
        }
    }

    pub fn load(path: &str) -> Result<Self, String> {
        let content = std::fs::read_to_string(path)
            .map_err(|e| format!("Failed to read protected settings: {}", e))?;

        from_json(&content)
            .map_err(|e| format!("Failed to parse protected settings: {}", e))
    }

    pub fn save(&self, path: &str) -> Result<(), String> {
        let content = crate::utils::json::to_json_pretty(self)
            .map_err(|e| format!("Failed to serialize protected settings: {}", e))?;

        std::fs::write(path, content)
            .map_err(|e| format!("Failed to write protected settings: {}", e))
    }
}

--------------------------------------------------------------------------------
FILE: src/models/constraints.rs
PURPOSE: Physics constraint definitions and types
--------------------------------------------------------------------------------
//! Constraint and physics parameter models for advanced force-directed layout
//!
//! Provides constraint types for GPU-accelerated physics simulation:
//! - Spatial constraints (FixedPosition, Separation, Alignment)
//! - Clustering and hierarchy constraints
//! - Boundary and directional flow constraints
//! - **Semantic constraints** (ConstraintKind::Semantic = 10) for ontology-based forces
//!
//! Semantic constraints are generated from OWL axioms by OntologyPipelineService
//! and processed by ontology_constraints.cu CUDA kernels.
use serde::{Deserialize, Serialize};

/// Constraint types for GPU physics simulation
///
/// Each constraint type maps to a specific CUDA kernel in visionflow_unified.cu.
/// ConstraintKind::Semantic is processed by ontology_constraints.cu for OWL-based forces.
#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, Hash)]
#[repr(C)]
pub enum ConstraintKind {
    /// Fix node at specific (x, y, z) position
    FixedPosition = 0,
    /// Maintain minimum distance between nodes
    Separation = 1,
    /// Align nodes horizontally at fixed y-coordinate
    AlignmentHorizontal = 2,
    /// Align nodes vertically at fixed x-coordinate
    AlignmentVertical = 3,
    /// Align nodes at fixed z-depth
    AlignmentDepth = 4,
    /// Group nodes into spatial clusters
    Clustering = 5,
    /// Constrain nodes within bounding box
    Boundary = 6,
    /// Apply directional flow forces
    DirectionalFlow = 7,
    /// Maintain radial distance from center
    RadialDistance = 8,
    /// Hierarchical layer separation
    LayerDepth = 9,
    /// **Semantic constraint based on ontology relationships**
    ///
    /// Generated by OntologyPipelineService from CustomReasoner inferred axioms:
    /// - SubClassOf(A, B)  Attraction forces (child  parent clustering)
    /// - DisjointWith(A, B)  Repulsion forces (separate disjoint classes)
    /// - EquivalentTo(A, B)  Strong attraction (align equivalent classes)
    ///
    /// Processed by ontology_constraints.cu with priority blending.
    Semantic = 10,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Constraint {
    
    pub kind: ConstraintKind,
    
    pub node_indices: Vec<u32>,
    
    
    
    
    
    
    
    
    
    
    
    pub params: Vec<f32>,
    
    pub weight: f32,
    
    pub active: bool,
}

impl Constraint {
    
    pub fn fixed_position(node_idx: u32, x: f32, y: f32, z: f32) -> Self {
        Self {
            kind: ConstraintKind::FixedPosition,
            node_indices: vec![node_idx],
            params: vec![x, y, z],
            weight: 1.0,
            active: true,
        }
    }

    
    pub fn separation(node_a: u32, node_b: u32, min_distance: f32) -> Self {
        Self {
            kind: ConstraintKind::Separation,
            node_indices: vec![node_a, node_b],
            params: vec![min_distance],
            weight: 0.8,
            active: true,
        }
    }

    
    pub fn align_horizontal(node_indices: Vec<u32>, y_coord: f32) -> Self {
        Self {
            kind: ConstraintKind::AlignmentHorizontal,
            node_indices,
            params: vec![y_coord],
            weight: 0.6,
            active: true,
        }
    }

    
    pub fn cluster(node_indices: Vec<u32>, cluster_id: f32, strength: f32) -> Self {
        Self {
            kind: ConstraintKind::Clustering,
            node_indices,
            params: vec![cluster_id, strength],
            weight: 0.7,
            active: true,
        }
    }

    
    pub fn boundary(
        node_indices: Vec<u32>,
        min_x: f32,
        max_x: f32,
        min_y: f32,
        max_y: f32,
        min_z: f32,
        max_z: f32,
    ) -> Self {
        Self {
            kind: ConstraintKind::Boundary,
            node_indices,
            params: vec![min_x, max_x, min_y, max_y, min_z, max_z],
            weight: 0.9,
            active: true,
        }
    }

    
    pub fn to_gpu_format(&self) -> ConstraintData {
        let mut gpu_constraint = ConstraintData {
            kind: self.kind as i32,
            count: self.node_indices.len().min(4) as i32,
            node_idx: [0, 0, 0, 0],
            params: [0.0; 8],
            weight: self.weight,
            activation_frame: 0, 
        };

        
        for (i, &node_idx) in self.node_indices.iter().take(4).enumerate() {
            gpu_constraint.node_idx[i] = node_idx as i32;
        }

        
        for (i, &param) in self.params.iter().take(8).enumerate() {
            gpu_constraint.params[i] = param;
        }

        gpu_constraint
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AdvancedParams {
    
    pub semantic_force_weight: f32,
    
    pub temporal_force_weight: f32,
    
    pub structural_force_weight: f32,
    
    pub constraint_force_weight: f32,
    
    pub stress_step_interval_frames: u32,
    
    pub separation_factor: f32,
    
    pub boundary_force_weight: f32,
    
    pub knowledge_force_weight: f32,
    
    pub agent_communication_weight: f32,
    
    pub adaptive_force_scaling: bool,
    
    pub target_edge_length: f32,
    
    pub max_velocity: f32,
    
    pub collision_threshold: f32,
    
    pub hierarchical_mode: bool,
    
    pub layer_separation: f32,
}

impl Default for AdvancedParams {
    fn default() -> Self {
        Self {
            semantic_force_weight: 0.6,
            temporal_force_weight: 0.3,
            structural_force_weight: 0.5,
            constraint_force_weight: 0.8,
            stress_step_interval_frames: 600, 
            separation_factor: 1.5,
            boundary_force_weight: 0.7,
            knowledge_force_weight: 0.4,
            agent_communication_weight: 0.5,
            adaptive_force_scaling: true,
            target_edge_length: 150.0,
            max_velocity: 50.0,
            collision_threshold: 30.0,
            hierarchical_mode: false,
            layer_separation: 200.0,
        }
    }
}

impl AdvancedParams {
    
    pub fn semantic_optimized() -> Self {
        Self {
            semantic_force_weight: 0.9,
            knowledge_force_weight: 0.8,
            temporal_force_weight: 0.4,
            ..Default::default()
        }
    }

    
    pub fn agent_swarm_optimized() -> Self {
        Self {
            agent_communication_weight: 0.9,
            temporal_force_weight: 0.7,
            separation_factor: 2.0,
            collision_threshold: 50.0,
            ..Default::default()
        }
    }

    
    pub fn hierarchical_optimized() -> Self {
        Self {
            hierarchical_mode: true,
            structural_force_weight: 0.9,
            layer_separation: 250.0,
            constraint_force_weight: 0.95,
            ..Default::default()
        }
    }
}

///
#[repr(C)]
#[derive(Debug, Clone, Copy, PartialEq, bytemuck::Pod, bytemuck::Zeroable)]
pub struct ConstraintData {
    
    pub kind: i32,
    
    pub count: i32,
    
    pub node_idx: [i32; 4],
    
    pub params: [f32; 8],
    
    pub weight: f32,
    
    pub activation_frame: i32,
}

impl Default for ConstraintData {
    fn default() -> Self {
        Self {
            kind: 0,
            count: 0,
            node_idx: [0; 4],
            params: [0.0; 8],
            weight: 0.0,
            activation_frame: 0,
        }
    }
}

// Manual implementation of DeviceCopy for ConstraintData (GPU is always enabled)
unsafe impl cust::memory::DeviceCopy for ConstraintData {}

impl ConstraintData {
    
    pub fn from_constraint(constraint: &Constraint) -> Self {
        let mut node_idx = [-1i32; 4];
        for (i, &idx) in constraint.node_indices.iter().take(4).enumerate() {
            node_idx[i] = idx as i32;
        }

        let mut params = [0.0f32; 8];
        for (i, &param) in constraint.params.iter().take(8).enumerate() {
            params[i] = param;
        }

        Self {
            kind: constraint.kind as i32,
            count: constraint.node_indices.len().min(4) as i32,
            node_idx,
            params,
            weight: constraint.weight,
            activation_frame: 0, 
        }
    }
}

///
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct ConstraintSet {
    
    pub constraints: Vec<Constraint>,
    
    pub groups: std::collections::HashMap<String, Vec<usize>>,
}

impl ConstraintSet {

    pub fn new() -> Self {
        Self {
            constraints: Vec::new(),
            groups: std::collections::HashMap::new(),
        }
    }

    pub fn add(&mut self, constraint: Constraint) -> usize {
        let idx = self.constraints.len();
        self.constraints.push(constraint);
        idx
    }

    
    pub fn add_to_group(&mut self, group_name: &str, constraint: Constraint) {
        let idx = self.add(constraint);
        self.groups
            .entry(group_name.to_string())
            .or_insert_with(Vec::new)
            .push(idx);
    }

    
    pub fn set_group_active(&mut self, group_name: &str, active: bool) {
        if let Some(indices) = self.groups.get(group_name) {
            for &idx in indices {
                if let Some(constraint) = self.constraints.get_mut(idx) {
                    constraint.active = active;
                }
            }
        }
    }

    
    pub fn active_constraints(&self) -> Vec<&Constraint> {
        self.constraints.iter().filter(|c| c.active).collect()
    }

    
    pub fn to_gpu_data(&self) -> Vec<ConstraintData> {
        self.active_constraints()
            .into_iter()
            .map(ConstraintData::from_constraint)
            .collect()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_constraint_creation() {
        let fixed = Constraint::fixed_position(0, 100.0, 200.0, 300.0);
        assert_eq!(fixed.kind, ConstraintKind::FixedPosition);
        assert_eq!(fixed.node_indices, vec![0]);
        assert_eq!(fixed.params, vec![100.0, 200.0, 300.0]);

        let sep = Constraint::separation(1, 2, 50.0);
        assert_eq!(sep.kind, ConstraintKind::Separation);
        assert_eq!(sep.node_indices, vec![1, 2]);
        assert_eq!(sep.params, vec![50.0]);
    }

    #[test]
    fn test_constraint_to_gpu_data() {
        let constraint = Constraint::cluster(vec![1, 2, 3], 1.0, 0.8);
        let gpu_data = ConstraintData::from_constraint(&constraint);

        assert_eq!(gpu_data.kind, ConstraintKind::Clustering as i32);
        assert_eq!(gpu_data.count, 3);
        assert_eq!(gpu_data.node_idx[0], 1);
        assert_eq!(gpu_data.node_idx[1], 2);
        assert_eq!(gpu_data.node_idx[2], 3);
        assert_eq!(gpu_data.params[0], 1.0);
        assert_eq!(gpu_data.params[1], 0.8);
    }

    #[test]
    fn test_constraint_set() {
        let mut set = ConstraintSet::default();

        set.add_to_group("fixed", Constraint::fixed_position(0, 0.0, 0.0, 0.0));
        set.add_to_group("fixed", Constraint::fixed_position(1, 100.0, 0.0, 0.0));
        set.add_to_group("separation", Constraint::separation(2, 3, 75.0));

        assert_eq!(set.constraints.len(), 3);
        assert_eq!(set.groups.get("fixed").expect("Missing required key: fixed").len(), 2);

        set.set_group_active("fixed", false);
        assert_eq!(set.active_constraints().len(), 1);
    }
}

--------------------------------------------------------------------------------
FILE: src/models/metadata.rs
PURPOSE: File and node metadata with ontology fields
--------------------------------------------------------------------------------
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

///
///
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
#[serde(rename_all = "camelCase")]
pub struct Metadata {
    #[serde(default)]
    pub file_name: String,
    #[serde(default)]
    pub file_size: usize,
    #[serde(default)]
    pub node_size: f64,
    #[serde(default)]
    pub hyperlink_count: usize,
    #[serde(default)]
    pub sha1: String,
    #[serde(default = "default_node_id")]
    pub node_id: String,
    #[serde(default = "Utc::now")]
    pub last_modified: DateTime<Utc>,
    #[serde(default)]
    pub last_content_change: Option<DateTime<Utc>>,
    #[serde(default)]
    pub last_commit: Option<DateTime<Utc>>,
    #[serde(default)]
    pub change_count: Option<u32>,
    #[serde(default)]
    pub file_blob_sha: Option<String>,
    #[serde(default)]
    pub perplexity_link: String,
    #[serde(default)]
    pub last_perplexity_process: Option<DateTime<Utc>>,
    #[serde(default)]
    pub topic_counts: HashMap<String, usize>,
    // Ontology fields from new header format
    #[serde(default)]
    pub term_id: Option<String>,
    #[serde(default)]
    pub preferred_term: Option<String>,
    #[serde(default)]
    pub source_domain: Option<String>,
    #[serde(default)]
    pub ontology_status: Option<String>,
    #[serde(default)]
    pub owl_class: Option<String>,
    #[serde(default)]
    pub owl_physicality: Option<String>,
    #[serde(default)]
    pub owl_role: Option<String>,
    #[serde(default)]
    pub quality_score: Option<f64>,
    #[serde(default)]
    pub authority_score: Option<f64>,
    #[serde(default)]
    pub belongs_to_domain: Vec<String>,
    #[serde(default)]
    pub maturity: Option<String>,
    #[serde(default)]
    pub is_subclass_of: Vec<String>,
    #[serde(default)]
    pub definition: Option<String>,
}

// Default function for node_id to ensure backward compatibility
fn default_node_id() -> String {
    
    "0".to_string()
}

///
pub type MetadataStore = HashMap<String, Metadata>;

///
pub type FileMetadata = Metadata;

// Implement helper methods directly on HashMap<String, Metadata>
pub trait MetadataOps {
    fn validate_files(&self, markdown_dir: &str) -> bool;
    fn get_max_node_id(&self) -> u32;
}

impl MetadataOps for MetadataStore {
    fn get_max_node_id(&self) -> u32 {
        
        self.values()
            .map(|m| m.node_id.parse::<u32>().unwrap_or(0))
            .max()
            .unwrap_or(0)
    }

    fn validate_files(&self, markdown_dir: &str) -> bool {
        if self.is_empty() {
            return false;
        }

        
        for filename in self.keys() {
            let file_path = format!("{}/{}", markdown_dir, filename);
            if !std::path::Path::new(&file_path).exists() {
                return false;
            }
        }

        true
    }
}

--------------------------------------------------------------------------------
FILE: src/models/simulation_params.rs
PURPOSE: GPU physics simulation parameters
--------------------------------------------------------------------------------
use crate::config::{AutoBalanceConfig, AutoPauseConfig, PhysicsSettings};
use bytemuck::{Pod, Zeroable};
use cudarc::driver::DeviceRepr;
use cust_core::DeviceCopy;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "camelCase")]
pub enum SimulationMode {
    Remote, 
    Local,  
}

impl Default for SimulationMode {
    fn default() -> Self {
        SimulationMode::Remote
    }
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "camelCase")]
pub enum SimulationPhase {
    Initial,  
    Dynamic,  
    Finalize, 
}

impl Default for SimulationPhase {
    fn default() -> Self {
        SimulationPhase::Initial
    }
}

// GPU-compatible simulation parameters, matching the new CUDA kernel design.
#[repr(C)]
#[derive(Debug, Clone, Copy, Pod, Zeroable)]
pub struct SimParams {
    
    pub dt: f32,
    pub damping: f32,
    pub warmup_iterations: u32,
    pub cooling_rate: f32,

    
    pub spring_k: f32,
    pub rest_length: f32,

    
    pub repel_k: f32,
    pub repulsion_cutoff: f32,
    pub repulsion_softening_epsilon: f32,

    
    pub center_gravity_k: f32,
    pub max_force: f32,
    pub max_velocity: f32,

    
    pub grid_cell_size: f32,

    
    pub feature_flags: u32,
    pub seed: u32,
    pub iteration: i32,

    
    pub separation_radius: f32,
    pub cluster_strength: f32,
    pub alignment_strength: f32,
    pub temperature: f32,
    pub viewport_bounds: f32,
    pub sssp_alpha: f32,       
    pub boundary_damping: f32, 

    
    pub constraint_ramp_frames: u32, 
    pub constraint_max_force_per_node: f32, 

    
    pub stability_threshold: f32, 
    pub min_velocity_threshold: f32, 

    
    pub world_bounds_min: f32,         
    pub world_bounds_max: f32,         
    pub cell_size_lod: f32,            
    pub k_neighbors_max: u32,          
    pub anomaly_detection_radius: f32, 
    pub learning_rate_default: f32,    

    
    pub norm_delta_cap: f32,
    pub position_constraint_attraction: f32,
    pub lof_score_min: f32,
    pub lof_score_max: f32,
    pub weight_precision_multiplier: f32,

    // Stress Majorization Parameters
    pub stress_optimization_enabled: u32,        // Enable/disable stress majorization (0 or 1)
    pub stress_optimization_frequency: u32,      // Run every N frames (e.g., 60 = once per second at 60fps)
    pub stress_learning_rate: f32,               // Learning rate for gradient descent (0.01-0.1)
    pub stress_momentum: f32,                    // Momentum factor (0.0-0.9)
    pub stress_max_displacement: f32,            // Maximum displacement per iteration
    pub stress_convergence_threshold: f32,       // Convergence threshold for early stopping
    pub stress_max_iterations: u32,              // Maximum iterations per optimization call
    pub stress_blend_factor: f32,                // Blend factor with local forces (0.1-0.3)
}

// SAFETY: SimParams is repr(C) with only POD types, safe for GPU transfer
// All fields are primitives (f32, u32, i32) with well-defined memory layout
unsafe impl DeviceRepr for SimParams {}

// SAFETY: SimParams is repr(C) with only POD types, safe for GPU transfer
// All fields are primitives (f32, u32, i32) with well-defined memory layout
unsafe impl DeviceCopy for SimParams {}

///
pub struct FeatureFlags;
impl FeatureFlags {
    pub const ENABLE_REPULSION: u32 = 1 << 0;
    pub const ENABLE_SPRINGS: u32 = 1 << 1;
    pub const ENABLE_CENTERING: u32 = 1 << 2;
    pub const ENABLE_TEMPORAL_COHERENCE: u32 = 1 << 3;
    pub const ENABLE_CONSTRAINTS: u32 = 1 << 4; 
    pub const ENABLE_STRESS_MAJORIZATION: u32 = 1 << 5;
    pub const ENABLE_SSSP_SPRING_ADJUST: u32 = 1 << 6; 
}

#[derive(Default, Serialize, Deserialize, Clone, Debug)]
#[serde(rename_all = "camelCase")]
pub struct SimulationParams {
    
    pub enabled: bool, 

    
    pub auto_balance: bool,                     
    pub auto_balance_interval_ms: u32,          
    pub auto_balance_config: AutoBalanceConfig, 

    
    pub auto_pause_config: AutoPauseConfig, 
    pub is_physics_paused: bool,            
    pub equilibrium_stability_counter: u32, 

    
    pub iterations: u32, 
    pub dt: f32,         

    
    pub spring_k: f32, 
    pub repel_k: f32,  

    
    pub mass_scale: f32,       
    pub damping: f32,          
    pub boundary_damping: f32, 

    
    pub viewport_bounds: f32, 
    pub enable_bounds: bool,  

    
    pub max_velocity: f32,      
    pub max_force: f32,         
    pub separation_radius: f32, 
    pub temperature: f32,       
    pub center_gravity_k: f32,  

    
    pub stress_weight: f32,
    pub stress_alpha: f32,
    pub boundary_limit: f32,
    pub alignment_strength: f32,
    pub cluster_strength: f32,
    pub compute_mode: i32,
    pub min_distance: f32,
    pub max_repulsion_dist: f32,
    pub boundary_margin: f32,
    pub boundary_force_strength: f32,
    pub warmup_iterations: u32,
    pub cooling_rate: f32,

    
    pub use_sssp_distances: bool, 
    pub sssp_alpha: Option<f32>,  

    
    pub constraint_ramp_frames: u32, 
    pub constraint_max_force_per_node: f32, 

    
    pub phase: SimulationPhase, 
    pub mode: SimulationMode,   
}

impl SimulationParams {
    pub fn new() -> Self {
        
        let default_physics = PhysicsSettings::default();
        Self::from(&default_physics)
    }

    pub fn with_phase(phase: SimulationPhase) -> Self {
        let mut params = Self::new();
        params.phase = phase;

        
        
        match phase {
            SimulationPhase::Initial => {
                
                params.iterations = params.iterations.max(500);
                params.warmup_iterations = params.warmup_iterations.max(300);
            }
            SimulationPhase::Dynamic => {
                
            }
            SimulationPhase::Finalize => {
                
                params.iterations = params.iterations.max(300);
            }
        }

        params
    }

    
    pub fn to_sim_params(&self) -> SimParams {
        
        let mut feature_flags = 0;
        if self.repel_k > 0.0 {
            feature_flags |= FeatureFlags::ENABLE_REPULSION;
        }
        if self.spring_k > 0.0 {
            feature_flags |= FeatureFlags::ENABLE_SPRINGS;
        }
        
        if self.center_gravity_k > 0.0 {
            feature_flags |= FeatureFlags::ENABLE_CENTERING;
        }
        
        if self.use_sssp_distances {
            feature_flags |= FeatureFlags::ENABLE_SSSP_SPRING_ADJUST;
        }
        

        SimParams {
            dt: self.dt,
            damping: self.damping,
            warmup_iterations: self.warmup_iterations,
            cooling_rate: self.cooling_rate,
            spring_k: self.spring_k,
            rest_length: self.separation_radius * 2.0, 
            repel_k: self.repel_k,
            repulsion_cutoff: self.max_repulsion_dist,
            repulsion_softening_epsilon: 1e-4, 
            center_gravity_k: self.center_gravity_k, 
            max_force: self.max_force,
            max_velocity: self.max_velocity,
            grid_cell_size: self.max_repulsion_dist, 
            feature_flags,
            seed: 1337,
            iteration: 0, 
            separation_radius: self.separation_radius,
            cluster_strength: self.cluster_strength,
            alignment_strength: self.alignment_strength,
            temperature: self.temperature,
            viewport_bounds: self.viewport_bounds,
            sssp_alpha: self.sssp_alpha.unwrap_or(0.0),
            boundary_damping: self.boundary_damping,
            constraint_ramp_frames: self.constraint_ramp_frames,
            constraint_max_force_per_node: self.constraint_max_force_per_node,
            
            stability_threshold: crate::config::dev_config::physics().stability_threshold,
            min_velocity_threshold: crate::config::dev_config::physics().min_velocity_threshold,

            
            world_bounds_min: crate::config::dev_config::physics().world_bounds_min,
            world_bounds_max: crate::config::dev_config::physics().world_bounds_max,
            cell_size_lod: crate::config::dev_config::physics().cell_size_lod,
            k_neighbors_max: crate::config::dev_config::physics().k_neighbors_max,
            anomaly_detection_radius: crate::config::dev_config::physics().anomaly_detection_radius,
            learning_rate_default: crate::config::dev_config::physics().learning_rate_default,

            
            norm_delta_cap: crate::config::dev_config::physics().norm_delta_cap,
            position_constraint_attraction: crate::config::dev_config::physics()
                .position_constraint_attraction,
            lof_score_min: crate::config::dev_config::physics().lof_score_min,
            lof_score_max: crate::config::dev_config::physics().lof_score_max,
            weight_precision_multiplier: crate::config::dev_config::physics()
                .weight_precision_multiplier,

            // Stress Majorization defaults
            stress_optimization_enabled: 0,
            stress_optimization_frequency: 100,
            stress_learning_rate: 0.05,
            stress_momentum: 0.5,
            stress_max_displacement: 10.0,
            stress_convergence_threshold: 0.01,
            stress_max_iterations: 50,
            stress_blend_factor: 0.2,
        }
    }
}

// Implementation for SimParams (GPU-aligned struct)
impl Default for SimParams {
    fn default() -> Self {
        Self::new()
    }
}

impl SimParams {
    pub fn new() -> Self {
        
        let params = SimulationParams::new();
        params.to_sim_params()
    }

    
    pub fn set_iteration(&mut self, iteration: i32) {
        self.iteration = iteration;
    }

    
    pub fn to_simulation_params(&self) -> SimulationParams {
        SimulationParams {
            enabled: true,
            auto_balance: false,
            auto_balance_interval_ms: 100,
            auto_balance_config: AutoBalanceConfig::default(),
            auto_pause_config: AutoPauseConfig::default(),
            equilibrium_stability_counter: 0,
            is_physics_paused: false,
            iterations: 100,
            dt: self.dt,
            repel_k: self.repel_k,
            mass_scale: 1.0,
            damping: self.damping,
            boundary_damping: 0.9,
            viewport_bounds: self.viewport_bounds,
            enable_bounds: true,
            max_velocity: self.max_velocity,
            max_force: self.max_force,
            spring_k: 0.0, 
            separation_radius: self.separation_radius,
            center_gravity_k: self.center_gravity_k, 
            temperature: self.temperature,
            stress_weight: 1.0,
            stress_alpha: 0.1,
            boundary_limit: 1000.0,
            alignment_strength: self.alignment_strength,
            cluster_strength: self.cluster_strength,
            compute_mode: 0,
            min_distance: 1.0,
            max_repulsion_dist: self.repulsion_cutoff,
            boundary_margin: 50.0,
            boundary_force_strength: 1.0,
            warmup_iterations: self.warmup_iterations,
            cooling_rate: self.cooling_rate,
            use_sssp_distances: false, 
            sssp_alpha: Some(self.sssp_alpha),
            constraint_ramp_frames: self.constraint_ramp_frames,
            constraint_max_force_per_node: self.constraint_max_force_per_node,
            phase: SimulationPhase::Dynamic,
            mode: SimulationMode::Remote,
        }
    }
}

// Conversion from SimulationParams to SimParams
impl From<&SimulationParams> for SimParams {
    fn from(params: &SimulationParams) -> Self {
        params.to_sim_params()
    }
}

// Conversion from SimParams to SimulationParams
impl From<&SimParams> for SimulationParams {
    fn from(params: &SimParams) -> Self {
        params.to_simulation_params()
    }
}

// Direct conversion from PhysicsSettings to SimParams for the new CUDA kernel
impl From<&PhysicsSettings> for SimParams {
    fn from(physics: &PhysicsSettings) -> Self {
        let mut feature_flags = 0;
        if physics.repel_k > 0.0 {
            feature_flags |= FeatureFlags::ENABLE_REPULSION;
        }
        if physics.spring_k > 0.0 {
            feature_flags |= FeatureFlags::ENABLE_SPRINGS;
        }
        if physics.center_gravity_k > 0.0 {
            feature_flags |= FeatureFlags::ENABLE_CENTERING;
        }

        SimParams {
            dt: physics.dt,
            damping: physics.damping,
            warmup_iterations: physics.warmup_iterations,
            cooling_rate: physics.cooling_rate,
            spring_k: physics.spring_k,
            rest_length: physics.rest_length,
            repel_k: physics.repel_k,
            repulsion_cutoff: physics.max_repulsion_dist,
            repulsion_softening_epsilon: physics.repulsion_softening_epsilon,
            center_gravity_k: physics.center_gravity_k,
            max_force: physics.max_force,
            max_velocity: physics.max_velocity,
            grid_cell_size: physics.grid_cell_size,
            feature_flags,
            seed: 1337,
            iteration: 0,
            separation_radius: physics.separation_radius,
            cluster_strength: physics.cluster_strength,
            alignment_strength: physics.alignment_strength,
            temperature: physics.temperature,
            viewport_bounds: physics.bounds_size,
            sssp_alpha: 0.0,
            boundary_damping: physics.boundary_damping,
            constraint_ramp_frames: physics.constraint_ramp_frames,
            constraint_max_force_per_node: physics.constraint_max_force_per_node,

            stability_threshold: crate::config::dev_config::physics().stability_threshold,
            min_velocity_threshold: crate::config::dev_config::physics().min_velocity_threshold,


            world_bounds_min: crate::config::dev_config::physics().world_bounds_min,
            world_bounds_max: crate::config::dev_config::physics().world_bounds_max,
            cell_size_lod: crate::config::dev_config::physics().cell_size_lod,
            k_neighbors_max: crate::config::dev_config::physics().k_neighbors_max,
            anomaly_detection_radius: crate::config::dev_config::physics().anomaly_detection_radius,
            learning_rate_default: crate::config::dev_config::physics().learning_rate_default,


            norm_delta_cap: crate::config::dev_config::physics().norm_delta_cap,
            position_constraint_attraction: crate::config::dev_config::physics()
                .position_constraint_attraction,
            lof_score_min: crate::config::dev_config::physics().lof_score_min,
            lof_score_max: crate::config::dev_config::physics().lof_score_max,
            weight_precision_multiplier: crate::config::dev_config::physics()
                .weight_precision_multiplier,

            // Stress Majorization defaults
            stress_optimization_enabled: 0,      // Disabled by default
            stress_optimization_frequency: 60,   // Once per second at 60fps
            stress_learning_rate: 0.05,          // Conservative learning rate
            stress_momentum: 0.7,                // Moderate momentum
            stress_max_displacement: 50.0,       // Maximum node displacement per step
            stress_convergence_threshold: 0.01,  // Convergence threshold
            stress_max_iterations: 50,           // Maximum iterations per optimization
            stress_blend_factor: 0.2,            // 20% blend with global optimization
        }
    }
}

// Conversion from PhysicsSettings to SimulationParams
impl From<&PhysicsSettings> for SimulationParams {
    fn from(physics: &PhysicsSettings) -> Self {
        Self {
            enabled: physics.enabled,
            auto_balance: physics.auto_balance,
            auto_balance_interval_ms: physics.auto_balance_interval_ms,
            auto_balance_config: physics.auto_balance_config.clone(),
            auto_pause_config: physics.auto_pause.clone(),
            is_physics_paused: false, 
            equilibrium_stability_counter: 0,
            iterations: physics.iterations,
            dt: physics.dt,
            spring_k: physics.spring_k,
            repel_k: physics.repel_k,
            mass_scale: physics.mass_scale,
            damping: physics.damping,
            boundary_damping: physics.boundary_damping,
            viewport_bounds: physics.bounds_size,
            enable_bounds: physics.enable_bounds,
            max_velocity: physics.max_velocity,
            max_force: physics.max_force, 
            separation_radius: physics.separation_radius,
            temperature: physics.temperature,
            center_gravity_k: physics.center_gravity_k,
            
            stress_weight: physics.stress_weight,
            stress_alpha: physics.stress_alpha,
            boundary_limit: physics.boundary_limit,
            alignment_strength: physics.alignment_strength,
            cluster_strength: physics.cluster_strength,
            compute_mode: physics.compute_mode,
            min_distance: physics.min_distance,
            max_repulsion_dist: physics.max_repulsion_dist,
            boundary_margin: physics.boundary_margin,
            boundary_force_strength: physics.boundary_force_strength,
            warmup_iterations: physics.warmup_iterations,
            cooling_rate: physics.cooling_rate,
            use_sssp_distances: false, 
            sssp_alpha: None,          
            constraint_ramp_frames: physics.constraint_ramp_frames,
            constraint_max_force_per_node: physics.constraint_max_force_per_node,
            phase: SimulationPhase::Dynamic,
            mode: SimulationMode::Remote,
        }
    }
}

--------------------------------------------------------------------------------
FILE: src/models/workspace.rs
PURPOSE: Workspace management types
--------------------------------------------------------------------------------
//! Workspace model definitions and related structures

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use specta::Type;
use std::collections::HashMap;
use uuid::Uuid;
use validator::Validate;
use crate::utils::time;

///
#[derive(Debug, Clone, Serialize, Deserialize, Type, PartialEq)]
pub enum WorkspaceType {
    #[serde(rename = "personal")]
    Personal,
    #[serde(rename = "team")]
    Team,
    #[serde(rename = "public")]
    Public,
}

impl Default for WorkspaceType {
    fn default() -> Self {
        WorkspaceType::Personal
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize, Type, PartialEq)]
pub enum WorkspaceStatus {
    #[serde(rename = "active")]
    Active,
    #[serde(rename = "archived")]
    Archived,
}

impl Default for WorkspaceStatus {
    fn default() -> Self {
        WorkspaceStatus::Active
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize, Type, Validate)]
pub struct Workspace {
    
    pub id: String,

    
    #[validate(length(
        min = 1,
        max = 100,
        message = "Name must be between 1 and 100 characters"
    ))]
    pub name: String,

    
    #[validate(length(max = 500, message = "Description cannot exceed 500 characters"))]
    pub description: Option<String>,

    
    pub workspace_type: WorkspaceType,

    
    pub status: WorkspaceStatus,

    
    pub member_count: u32,

    
    pub is_favorite: bool,

    
    pub owner_id: Option<String>,

    
    #[serde(skip_serializing_if = "HashMap::is_empty")]
    #[specta(skip)]
    pub metadata: HashMap<String, serde_json::Value>,

    
    #[specta(type = String)]
    pub created_at: DateTime<Utc>,

    
    #[specta(type = String)]
    pub updated_at: DateTime<Utc>,
}

impl Default for Workspace {
    fn default() -> Self {
        let now = time::now();
        Self {
            id: Uuid::new_v4().to_string(),
            name: "New Workspace".to_string(),
            description: None,
            workspace_type: WorkspaceType::default(),
            status: WorkspaceStatus::default(),
            member_count: 1,
            is_favorite: false,
            owner_id: None,
            metadata: HashMap::new(),
            created_at: now,
            updated_at: now,
        }
    }
}

impl Workspace {
    
    pub fn new(name: String, description: Option<String>, workspace_type: WorkspaceType) -> Self {
        let now = time::now();
        Self {
            id: Uuid::new_v4().to_string(),
            name,
            description,
            workspace_type,
            status: WorkspaceStatus::Active,
            member_count: 1,
            is_favorite: false,
            owner_id: None,
            metadata: HashMap::new(),
            created_at: now,
            updated_at: now,
        }
    }

    
    pub fn update(
        &mut self,
        name: Option<String>,
        description: Option<String>,
        workspace_type: Option<WorkspaceType>,
    ) {
        if let Some(new_name) = name {
            self.name = new_name;
        }
        if let Some(new_description) = description {
            self.description = Some(new_description);
        }
        if let Some(new_type) = workspace_type {
            self.workspace_type = new_type;
        }
        self.updated_at = time::now();
    }

    
    pub fn toggle_favorite(&mut self) -> bool {
        self.is_favorite = !self.is_favorite;
        self.updated_at = time::now();
        self.is_favorite
    }

    
    pub fn archive(&mut self) {
        self.status = WorkspaceStatus::Archived;
        self.updated_at = time::now();
    }

    
    pub fn unarchive(&mut self) {
        self.status = WorkspaceStatus::Active;
        self.updated_at = time::now();
    }

    
    pub fn is_archived(&self) -> bool {
        self.status == WorkspaceStatus::Archived
    }

    
    pub fn set_metadata(&mut self, key: String, value: serde_json::Value) {
        self.metadata.insert(key, value);
        self.updated_at = time::now();
    }

    
    pub fn remove_metadata(&mut self, key: &str) -> Option<serde_json::Value> {
        let result = self.metadata.remove(key);
        if result.is_some() {
            self.updated_at = time::now();
        }
        result
    }

    
    pub fn set_member_count(&mut self, count: u32) {
        self.member_count = count;
        self.updated_at = time::now();
    }

    
    pub fn set_owner(&mut self, owner_id: String) {
        self.owner_id = Some(owner_id);
        self.updated_at = time::now();
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize, Type, Validate)]
pub struct CreateWorkspaceRequest {
    #[validate(length(
        min = 1,
        max = 100,
        message = "Name must be between 1 and 100 characters"
    ))]
    pub name: String,

    #[validate(length(max = 500, message = "Description cannot exceed 500 characters"))]
    pub description: Option<String>,

    pub workspace_type: Option<WorkspaceType>,
    pub owner_id: Option<String>,

    #[specta(skip)]
    pub metadata: Option<HashMap<String, serde_json::Value>>,
}

///
#[derive(Debug, Clone, Serialize, Deserialize, Type, Validate)]
pub struct UpdateWorkspaceRequest {
    #[validate(length(
        min = 1,
        max = 100,
        message = "Name must be between 1 and 100 characters"
    ))]
    pub name: Option<String>,

    #[validate(length(max = 500, message = "Description cannot exceed 500 characters"))]
    pub description: Option<String>,

    pub workspace_type: Option<WorkspaceType>,

    #[specta(skip)]
    pub metadata: Option<HashMap<String, serde_json::Value>>,
}

///
#[derive(Debug, Clone, Serialize, Deserialize, Type)]
pub struct WorkspaceResponse {
    pub success: bool,
    pub message: String,
    pub workspace: Option<Workspace>,
}

impl WorkspaceResponse {
    pub fn success(workspace: Workspace, message: impl Into<String>) -> Self {
        Self {
            success: true,
            message: message.into(),
            workspace: Some(workspace),
        }
    }

    pub fn success_no_data(message: impl Into<String>) -> Self {
        Self {
            success: true,
            message: message.into(),
            workspace: None,
        }
    }

    pub fn error(message: impl Into<String>) -> Self {
        Self {
            success: false,
            message: message.into(),
            workspace: None,
        }
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize, Type)]
pub struct WorkspaceListResponse {
    pub success: bool,
    pub message: String,
    pub workspaces: Vec<Workspace>,
    pub total_count: usize,
    pub page: usize,
    pub page_size: usize,
}

impl WorkspaceListResponse {
    pub fn success(
        workspaces: Vec<Workspace>,
        total_count: usize,
        page: usize,
        page_size: usize,
    ) -> Self {
        Self {
            success: true,
            message: "Workspaces retrieved successfully".to_string(),
            workspaces,
            total_count,
            page,
            page_size,
        }
    }

    pub fn error(message: impl Into<String>) -> Self {
        Self {
            success: false,
            message: message.into(),
            workspaces: Vec::new(),
            total_count: 0,
            page: 0,
            page_size: 0,
        }
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize, Type)]
pub struct WorkspaceFilter {
    
    pub status: Option<WorkspaceStatus>,
    
    pub workspace_type: Option<WorkspaceType>,
    
    pub is_favorite: Option<bool>,
    
    pub owner_id: Option<String>,
    
    pub search: Option<String>,
}

///
#[derive(Debug, Clone, Serialize, Deserialize, Type)]
pub enum WorkspaceSortBy {
    #[serde(rename = "name")]
    Name,
    #[serde(rename = "created_at")]
    CreatedAt,
    #[serde(rename = "updated_at")]
    UpdatedAt,
    #[serde(rename = "member_count")]
    MemberCount,
}

impl Default for WorkspaceSortBy {
    fn default() -> Self {
        WorkspaceSortBy::UpdatedAt
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize, Type)]
pub enum SortDirection {
    #[serde(rename = "asc")]
    Ascending,
    #[serde(rename = "desc")]
    Descending,
}

impl Default for SortDirection {
    fn default() -> Self {
        SortDirection::Descending
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize, Type, Validate)]
pub struct WorkspaceQuery {
    #[validate(range(min = 1, max = 1000, message = "Page size must be between 1 and 1000"))]
    pub page_size: Option<usize>,

    #[validate(range(min = 0, message = "Page must be non-negative"))]
    pub page: Option<usize>,

    pub sort_by: Option<WorkspaceSortBy>,
    pub sort_direction: Option<SortDirection>,
    pub filter: Option<WorkspaceFilter>,
}

impl Default for WorkspaceQuery {
    fn default() -> Self {
        Self {
            page_size: Some(20),
            page: Some(0),
            sort_by: Some(WorkspaceSortBy::default()),
            sort_direction: Some(SortDirection::default()),
            filter: None,
        }
    }
}

================================================================================
                    SECTION 2: PORTS (Trait Definitions)
================================================================================

--------------------------------------------------------------------------------
FILE: src/ports/mod.rs
PURPOSE: Module exports for hexagonal architecture ports
--------------------------------------------------------------------------------
// src/ports/mod.rs
//! Hexagonal Architecture Ports
//!
//! This module defines the port interfaces (traits) that represent
//! the core application boundaries. These are technology-agnostic
//! interfaces that the domain logic depends on.

// Legacy ports (to be refactored)
pub mod graph_repository;
pub mod physics_simulator;
pub mod semantic_analyzer;

// New hexser-based ports
pub mod inference_engine;
pub mod knowledge_graph_repository;
pub mod ontology_repository;
pub mod settings_repository;

// GPU port trait definitions
pub mod gpu_physics_adapter;
pub mod gpu_semantic_analyzer;

// Legacy exports
pub use graph_repository::GraphRepository;
pub use physics_simulator::PhysicsSimulator;
pub use semantic_analyzer::SemanticAnalyzer;

// New hexser-based exports
pub use inference_engine::InferenceEngine;
pub use knowledge_graph_repository::KnowledgeGraphRepository;
pub use ontology_repository::OntologyRepository;
pub use settings_repository::SettingsRepository;

// GPU port trait exports (these are the TRAITS, not the implementations)
pub use gpu_physics_adapter::{
    GpuDeviceInfo, GpuPhysicsAdapter, GpuPhysicsAdapterError, NodeForce, PhysicsParameters,
    PhysicsStatistics, PhysicsStepResult,
};
pub use gpu_semantic_analyzer::{
    ClusteringAlgorithm, CommunityDetectionResult, GpuSemanticAnalyzer, GpuSemanticAnalyzerError,
    ImportanceAlgorithm, OptimizationResult, PathfindingResult, SemanticConstraintConfig,
    SemanticStatistics,
};

--------------------------------------------------------------------------------
FILE: src/ports/graph_repository.rs
PURPOSE: GraphRepository trait for graph data access abstraction
--------------------------------------------------------------------------------
// src/ports/graph_repository.rs
//! Graph Repository Port
//!
//! Defines the interface for graph data access and manipulation.
//! This port abstracts away the concrete implementation (actor-based, direct access, etc.)

use async_trait::async_trait;
use std::collections::{HashMap, HashSet};
use std::sync::Arc;

use crate::actors::graph_actor::{AutoBalanceNotification, PhysicsState};
use crate::models::constraints::ConstraintSet;
use crate::models::edge::Edge;
use crate::models::graph::GraphData;
use crate::models::node::Node;
use glam::Vec3;

/// Binary node data with position and velocity (6-DOF)
/// Format: (x, y, z, vx, vy, vz)
/// This preserves the full physics state including velocities
pub type BinaryNodeData = (f32, f32, f32, f32, f32, f32);

pub type Result<T> = std::result::Result<T, GraphRepositoryError>;

#[derive(Debug, thiserror::Error)]
pub enum GraphRepositoryError {
    #[error("Graph not found")]
    NotFound,

    #[error("Graph access error: {0}")]
    AccessError(String),

    #[error("Invalid data: {0}")]
    InvalidData(String),

    #[error("Deserialization error: {0}")]
    DeserializationError(String),

    #[error("Serialization error: {0}")]
    SerializationError(String),

    #[error("Operation not implemented")]
    NotImplemented,
}

///
#[derive(Debug, Clone)]
pub struct PathfindingParams {
    pub start_node: u32,
    pub end_node: u32,
    pub max_depth: Option<usize>,
}

///
#[derive(Debug, Clone)]
pub struct PathfindingResult {
    pub path: Vec<u32>,
    pub total_distance: f32,
}

///
#[async_trait]
pub trait GraphRepository: Send + Sync {
    

    
    async fn add_nodes(&self, nodes: Vec<Node>) -> Result<Vec<u32>>;

    
    async fn add_edges(&self, edges: Vec<Edge>) -> Result<Vec<String>>;

    
    async fn update_positions(&self, updates: Vec<(u32, BinaryNodeData)>) -> Result<()>;

    
    async fn clear_dirty_nodes(&self) -> Result<()>;

    

    
    async fn get_graph(&self) -> Result<Arc<GraphData>>;

    
    async fn get_node_map(&self) -> Result<Arc<HashMap<u32, Node>>>;

    
    async fn get_physics_state(&self) -> Result<PhysicsState>;

    
    async fn get_node_positions(&self) -> Result<Vec<(u32, Vec3)>>;

    
    async fn get_bots_graph(&self) -> Result<Arc<GraphData>>;

    
    async fn get_constraints(&self) -> Result<ConstraintSet>;

    
    async fn get_auto_balance_notifications(&self) -> Result<Vec<AutoBalanceNotification>>;

    
    async fn get_equilibrium_status(&self) -> Result<bool>;

    
    async fn compute_shortest_paths(&self, params: PathfindingParams) -> Result<PathfindingResult>;

    
    async fn get_dirty_nodes(&self) -> Result<HashSet<u32>>;
}

--------------------------------------------------------------------------------
FILE: src/ports/settings_repository.rs
PURPOSE: SettingsRepository trait for configuration persistence
--------------------------------------------------------------------------------
// src/ports/settings_repository.rs
//! Settings Repository Port
//!
//! Provides access to application, user, and developer configuration settings.
//! This port abstracts database operations for all settings management.

use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

use crate::config::PhysicsSettings;

pub type Result<T> = std::result::Result<T, SettingsRepositoryError>;

#[derive(Debug, thiserror::Error)]
pub enum SettingsRepositoryError {
    #[error("Setting not found: {0}")]
    NotFound(String),

    #[error("Database error: {0}")]
    DatabaseError(String),

    #[error("Serialization error: {0}")]
    SerializationError(String),

    #[error("Invalid value: {0}")]
    InvalidValue(String),

    #[error("Cache error: {0}")]
    CacheError(String),
}

///
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(untagged)]
pub enum SettingValue {
    String(String),
    Integer(i64),
    Float(f64),
    Boolean(bool),
    Json(serde_json::Value),
}

impl SettingValue {
    pub fn as_string(&self) -> Option<&str> {
        match self {
            SettingValue::String(s) => Some(s),
            _ => None,
        }
    }

    pub fn as_i64(&self) -> Option<i64> {
        match self {
            SettingValue::Integer(i) => Some(*i),
            _ => None,
        }
    }

    pub fn as_f64(&self) -> Option<f64> {
        match self {
            SettingValue::Float(f) => Some(*f),
            _ => None,
        }
    }

    pub fn as_bool(&self) -> Option<bool> {
        match self {
            SettingValue::Boolean(b) => Some(*b),
            _ => None,
        }
    }

    pub fn as_json(&self) -> Option<&serde_json::Value> {
        match self {
            SettingValue::Json(j) => Some(j),
            _ => None,
        }
    }
}

// Re-export AppFullSettings from config module (single source of truth)
pub use crate::config::AppFullSettings;

///
#[async_trait]
pub trait SettingsRepository: Send + Sync {
    
    async fn get_setting(&self, key: &str) -> Result<Option<SettingValue>>;

    
    async fn set_setting(
        &self,
        key: &str,
        value: SettingValue,
        description: Option<&str>,
    ) -> Result<()>;

    
    async fn delete_setting(&self, key: &str) -> Result<()>;

    
    async fn has_setting(&self, key: &str) -> Result<bool>;

    
    async fn get_settings_batch(&self, keys: &[String]) -> Result<HashMap<String, SettingValue>>;

    
    async fn set_settings_batch(&self, updates: HashMap<String, SettingValue>) -> Result<()>;

    
    async fn list_settings(&self, prefix: Option<&str>) -> Result<Vec<String>>;

    
    async fn load_all_settings(&self) -> Result<Option<AppFullSettings>>;

    
    async fn save_all_settings(&self, settings: &AppFullSettings) -> Result<()>;

    
    async fn get_physics_settings(&self, profile_name: &str) -> Result<PhysicsSettings>;

    
    async fn save_physics_settings(
        &self,
        profile_name: &str,
        settings: &PhysicsSettings,
    ) -> Result<()>;

    
    async fn list_physics_profiles(&self) -> Result<Vec<String>>;

    
    async fn delete_physics_profile(&self, profile_name: &str) -> Result<()>;

    
    async fn export_settings(&self) -> Result<serde_json::Value>;

    
    async fn import_settings(&self, settings_json: &serde_json::Value) -> Result<()>;

    
    async fn clear_cache(&self) -> Result<()>;

    
    async fn health_check(&self) -> Result<bool>;
}

--------------------------------------------------------------------------------
FILE: src/ports/ontology_repository.rs
PURPOSE: OntologyRepository trait for OWL/semantic data access
--------------------------------------------------------------------------------
// src/ports/ontology_repository.rs
//! Ontology Repository Port
//!
//! Manages the ontology graph structure parsed from GitHub markdown files,
//! including OWL classes, properties, axioms, and inference results.

use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;

use crate::models::graph::GraphData;

pub type Result<T> = std::result::Result<T, OntologyRepositoryError>;

#[derive(Debug, thiserror::Error)]
pub enum OntologyRepositoryError {
    #[error("Ontology not found")]
    NotFound,

    #[error("OWL class not found: {0}")]
    ClassNotFound(String),

    #[error("OWL property not found: {0}")]
    PropertyNotFound(String),

    #[error("Database error: {0}")]
    DatabaseError(String),

    #[error("Invalid OWL data: {0}")]
    InvalidData(String),

    #[error("Validation failed: {0}")]
    ValidationFailed(String),

    #[error("Serialization error: {0}")]
    SerializationError(String),

    #[error("Deserialization error: {0}")]
    DeserializationError(String),
}

/// OWL Class with rich metadata support (Schema V2)
///
/// Supports comprehensive ontology metadata including:
/// - Core identification (term_id, preferred_term)
/// - Classification (source_domain, version, type)
/// - Quality metrics (quality_score, authority_score, status, maturity)
/// - OWL2 properties (owl_physicality, owl_role)
/// - Domain relationships (belongs_to_domain, bridges_to_domain)
/// - Source tracking (file_sha1, markdown_content, last_synced)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OwlClass {
    // Core identification
    pub iri: String,
    pub term_id: Option<String>,
    pub preferred_term: Option<String>,

    // Basic metadata
    pub label: Option<String>,
    pub description: Option<String>,
    pub parent_classes: Vec<String>,

    // Classification metadata
    pub source_domain: Option<String>,
    pub version: Option<String>,
    pub class_type: Option<String>,

    // Quality metrics
    pub status: Option<String>,
    pub maturity: Option<String>,
    pub quality_score: Option<f32>,
    pub authority_score: Option<f32>,
    pub public_access: Option<bool>,
    pub content_status: Option<String>,

    // OWL2 properties
    pub owl_physicality: Option<String>,
    pub owl_role: Option<String>,

    // Domain relationships
    pub belongs_to_domain: Option<String>,
    pub bridges_to_domain: Option<String>,

    // Source tracking
    pub source_file: Option<String>,
    pub file_sha1: Option<String>,
    pub markdown_content: Option<String>,
    pub last_synced: Option<chrono::DateTime<chrono::Utc>>,

    // Additional metadata (JSON for extensibility)
    pub properties: HashMap<String, String>,
    pub additional_metadata: Option<String>,
}

impl Default for OwlClass {
    fn default() -> Self {
        Self {
            iri: String::new(),
            term_id: None,
            preferred_term: None,
            label: None,
            description: None,
            parent_classes: Vec::new(),
            source_domain: None,
            version: None,
            class_type: None,
            status: None,
            maturity: None,
            quality_score: None,
            authority_score: None,
            public_access: None,
            content_status: None,
            owl_physicality: None,
            owl_role: None,
            belongs_to_domain: None,
            bridges_to_domain: None,
            source_file: None,
            file_sha1: None,
            markdown_content: None,
            last_synced: None,
            properties: HashMap::new(),
            additional_metadata: None,
        }
    }
}

/// Semantic relationship between OWL classes
///
/// Supports relationship types: has-part, uses, enables, requires, subclass-of, etc.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OwlRelationship {
    pub source_class_iri: String,
    pub relationship_type: String,
    pub target_class_iri: String,
    pub confidence: f32,
    pub is_inferred: bool,
}

/// Cross-reference (e.g., WikiLink) from an OWL class to external resources
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OwlCrossReference {
    pub source_class_iri: String,
    pub target_reference: String,
    pub reference_type: String, // wiki, external, doi, etc.
}

///
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum PropertyType {
    ObjectProperty,
    DataProperty,
    AnnotationProperty,
}

/// OWL Property with quality metrics (Schema V2)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OwlProperty {
    pub iri: String,
    pub label: Option<String>,
    pub property_type: PropertyType,
    pub domain: Vec<String>,
    pub range: Vec<String>,

    // Quality metrics (Schema V2)
    pub quality_score: Option<f32>,
    pub authority_score: Option<f32>,

    // Source tracking
    pub source_file: Option<String>,
}

impl Default for OwlProperty {
    fn default() -> Self {
        Self {
            iri: String::new(),
            label: None,
            property_type: PropertyType::ObjectProperty,
            domain: Vec::new(),
            range: Vec::new(),
            quality_score: None,
            authority_score: None,
            source_file: None,
        }
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum AxiomType {
    SubClassOf,
    EquivalentClass,
    DisjointWith,
    ObjectPropertyAssertion,
    DataPropertyAssertion,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OwlAxiom {
    pub id: Option<u64>,
    pub axiom_type: AxiomType,
    pub subject: String,
    pub object: String,
    pub annotations: HashMap<String, String>,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceResults {
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub inferred_axioms: Vec<OwlAxiom>,
    pub inference_time_ms: u64,
    pub reasoner_version: String,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ValidationReport {
    pub is_valid: bool,
    pub errors: Vec<String>,
    pub warnings: Vec<String>,
    pub timestamp: chrono::DateTime<chrono::Utc>,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OntologyMetrics {
    pub class_count: usize,
    pub property_count: usize,
    pub axiom_count: usize,
    pub max_depth: usize,
    pub average_branching_factor: f32,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PathfindingCacheEntry {
    pub source_node_id: u32,
    pub target_node_id: Option<u32>,
    pub distances: Vec<f32>,
    pub paths: HashMap<u32, Vec<u32>>,
    pub computed_at: chrono::DateTime<chrono::Utc>,
    pub computation_time_ms: f32,
}

///
#[async_trait]
pub trait OntologyRepository: Send + Sync {
    
    async fn load_ontology_graph(&self) -> Result<Arc<GraphData>>;

    
    async fn save_ontology_graph(&self, graph: &GraphData) -> Result<()>;

    
    
    
    async fn save_ontology(
        &self,
        classes: &[OwlClass],
        properties: &[OwlProperty],
        axioms: &[OwlAxiom],
    ) -> Result<()>;

    
    
    async fn add_owl_class(&self, class: &OwlClass) -> Result<String>;

    
    async fn get_owl_class(&self, iri: &str) -> Result<Option<OwlClass>>;

    
    async fn list_owl_classes(&self) -> Result<Vec<OwlClass>>;

    
    
    async fn add_owl_property(&self, property: &OwlProperty) -> Result<String>;

    
    async fn get_owl_property(&self, iri: &str) -> Result<Option<OwlProperty>>;

    
    async fn list_owl_properties(&self) -> Result<Vec<OwlProperty>>;

    
    async fn get_classes(&self) -> Result<Vec<OwlClass>>;

    
    async fn get_axioms(&self) -> Result<Vec<OwlAxiom>>;

    
    
    async fn add_axiom(&self, axiom: &OwlAxiom) -> Result<u64>;

    
    async fn get_class_axioms(&self, class_iri: &str) -> Result<Vec<OwlAxiom>>;


    /// Default: No-op (not all implementations support inference)
    async fn store_inference_results(&self, _results: &InferenceResults) -> Result<()> {
        Ok(())
    }


    /// Default: None (not all implementations support inference)
    async fn get_inference_results(&self) -> Result<Option<InferenceResults>> {
        Ok(None)
    }


    /// Default: Valid report (override for actual validation)
    async fn validate_ontology(&self) -> Result<ValidationReport> {
        Ok(ValidationReport {
            is_valid: true,
            errors: Vec::new(),
            warnings: Vec::new(),
            timestamp: chrono::Utc::now(),
        })
    }


    /// Default: Empty results (override when query support added)
    async fn query_ontology(&self, _query: &str) -> Result<Vec<HashMap<String, String>>> {
        Ok(Vec::new())
    }


    async fn get_metrics(&self) -> Result<OntologyMetrics>;




    /// Default: No-op (not all implementations support caching)
    async fn cache_sssp_result(&self, _entry: &PathfindingCacheEntry) -> Result<()> {
        Ok(())
    }


    /// Default: None (not all implementations support caching)
    async fn get_cached_sssp(&self, _source_node_id: u32) -> Result<Option<PathfindingCacheEntry>> {
        Ok(None)
    }


    /// Default: No-op (not all implementations support caching)
    async fn cache_apsp_result(&self, _distance_matrix: &Vec<Vec<f32>>) -> Result<()> {
        Ok(())
    }


    /// Default: None (not all implementations support caching)
    async fn get_cached_apsp(&self) -> Result<Option<Vec<Vec<f32>>>> {
        Ok(None)
    }


    /// Default: No-op (not all implementations support caching)
    async fn invalidate_pathfinding_caches(&self) -> Result<()> {
        Ok(())
    }
}

--------------------------------------------------------------------------------
FILE: src/ports/knowledge_graph_repository.rs
PURPOSE: KnowledgeGraphRepository trait with GraphStatistics
--------------------------------------------------------------------------------
// src/ports/knowledge_graph_repository.rs
//! Knowledge Graph Repository Port
//!
//! Manages the main knowledge graph structure parsed from local markdown files.
//! This port provides comprehensive graph data access and manipulation.

use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;

use crate::models::edge::Edge;
use crate::models::graph::GraphData;
use crate::models::node::Node;

pub type Result<T> = std::result::Result<T, KnowledgeGraphRepositoryError>;

#[derive(Debug, thiserror::Error)]
pub enum KnowledgeGraphRepositoryError {
    #[error("Graph not found")]
    NotFound,

    #[error("Node not found: {0}")]
    NodeNotFound(u32),

    #[error("Edge not found: {0}")]
    EdgeNotFound(String),

    #[error("Database error: {0}")]
    DatabaseError(String),

    #[error("Invalid data: {0}")]
    InvalidData(String),

    #[error("Concurrent modification detected")]
    ConcurrentModification,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GraphStatistics {
    pub node_count: usize,
    pub edge_count: usize,
    pub average_degree: f32,
    pub connected_components: usize,
    pub last_updated: chrono::DateTime<chrono::Utc>,
}

///
#[async_trait]
pub trait KnowledgeGraphRepository: Send + Sync {
    
    async fn load_graph(&self) -> Result<Arc<GraphData>>;

    
    async fn save_graph(&self, graph: &GraphData) -> Result<()>;

    
    
    async fn add_node(&self, node: &Node) -> Result<u32>;

    
    
    async fn batch_add_nodes(&self, nodes: Vec<Node>) -> Result<Vec<u32>>;

    
    async fn update_node(&self, node: &Node) -> Result<()>;

    
    async fn batch_update_nodes(&self, nodes: Vec<Node>) -> Result<()>;

    
    async fn remove_node(&self, node_id: u32) -> Result<()>;

    
    async fn batch_remove_nodes(&self, node_ids: Vec<u32>) -> Result<()>;

    
    async fn get_node(&self, node_id: u32) -> Result<Option<Node>>;

    
    async fn get_nodes(&self, node_ids: Vec<u32>) -> Result<Vec<Node>>;


    async fn get_nodes_by_metadata_id(&self, metadata_id: &str) -> Result<Vec<Node>>;

    /// Get all nodes with a specific OWL class IRI
    /// Used by semantic physics to resolve ontology class IRIs to actual node IDs
    async fn get_nodes_by_owl_class_iri(&self, owl_class_iri: &str) -> Result<Vec<Node>>;


    async fn search_nodes_by_label(&self, label: &str) -> Result<Vec<Node>>;

    
    
    async fn add_edge(&self, edge: &Edge) -> Result<String>;

    
    
    async fn batch_add_edges(&self, edges: Vec<Edge>) -> Result<Vec<String>>;

    
    async fn update_edge(&self, edge: &Edge) -> Result<()>;

    
    async fn remove_edge(&self, edge_id: &str) -> Result<()>;

    
    async fn batch_remove_edges(&self, edge_ids: Vec<String>) -> Result<()>;

    
    async fn get_node_edges(&self, node_id: u32) -> Result<Vec<Edge>>;

    
    async fn get_edges_between(&self, source_id: u32, target_id: u32) -> Result<Vec<Edge>>;

    /// Batch update positions for multiple nodes (simulation -> database)
    /// Used to persist simulation results back to source of truth
    async fn batch_update_positions(&self, positions: Vec<(u32, f32, f32, f32)>) -> Result<()>;

    /// Get all node positions from database (database -> simulation)
    /// Returns HashMap<node_id, (x, y, z)> for position preservation during reload
    async fn get_all_positions(&self) -> Result<HashMap<u32, (f32, f32, f32)>>;

    async fn query_nodes(&self, query: &str) -> Result<Vec<Node>>;

    
    async fn get_neighbors(&self, node_id: u32) -> Result<Vec<Node>>;

    
    async fn get_statistics(&self) -> Result<GraphStatistics>;

    
    async fn clear_graph(&self) -> Result<()>;


    /// Default: No-op (transactions managed by execute_transaction)
    async fn begin_transaction(&self) -> Result<()> {
        Ok(())
    }


    /// Default: No-op (transactions managed by execute_transaction)
    async fn commit_transaction(&self) -> Result<()> {
        Ok(())
    }


    /// Default: No-op (transactions managed by execute_transaction)
    async fn rollback_transaction(&self) -> Result<()> {
        Ok(())
    }


    async fn health_check(&self) -> Result<bool>;
}

--------------------------------------------------------------------------------
FILE: src/ports/inference_engine.rs
PURPOSE: InferenceEngine trait for OWL reasoning
--------------------------------------------------------------------------------
// src/ports/inference_engine.rs
//! Inference Engine Port
//!
//! Provides ontology reasoning and inference capabilities using whelk-rs or similar reasoners.
//! This port abstracts the specific reasoning engine implementation.

use async_trait::async_trait;
use serde::{Deserialize, Serialize};

use crate::ports::ontology_repository::{InferenceResults, OwlAxiom, OwlClass};

pub type Result<T> = std::result::Result<T, InferenceEngineError>;

#[derive(Debug, thiserror::Error)]
pub enum InferenceEngineError {
    #[error("Inference error: {0}")]
    InferenceError(String),

    #[error("Ontology not loaded")]
    OntologyNotLoaded,

    #[error("Inconsistent ontology: {0}")]
    InconsistentOntology(String),

    #[error("Unsupported operation: {0}")]
    UnsupportedOperation(String),

    #[error("Reasoner error: {0}")]
    ReasonerError(String),
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceStatistics {
    pub loaded_classes: usize,
    pub loaded_axioms: usize,
    pub inferred_axioms: usize,
    pub last_inference_time_ms: u64,
    pub total_inferences: u64,
}

///
#[async_trait]
pub trait InferenceEngine: Send + Sync {
    
    async fn load_ontology(&mut self, classes: Vec<OwlClass>, axioms: Vec<OwlAxiom>) -> Result<()>;

    
    async fn infer(&mut self) -> Result<InferenceResults>;

    
    async fn is_entailed(&self, axiom: &OwlAxiom) -> Result<bool>;

    
    
    async fn get_subclass_hierarchy(&self) -> Result<Vec<(String, String)>>;

    
    
    async fn classify_instance(&self, instance_iri: &str) -> Result<Vec<String>>;

    
    async fn check_consistency(&self) -> Result<bool>;

    
    
    async fn explain_entailment(&self, axiom: &OwlAxiom) -> Result<Vec<OwlAxiom>>;

    
    async fn clear(&mut self) -> Result<()>;

    
    async fn get_statistics(&self) -> Result<InferenceStatistics>;
}

--------------------------------------------------------------------------------
FILE: src/ports/gpu_physics_adapter.rs
PURPOSE: GpuPhysicsAdapter trait for GPU-accelerated physics
--------------------------------------------------------------------------------
// src/ports/gpu_physics_adapter.rs
//! GPU Physics Adapter Port
//!
//! Provides GPU-accelerated physics simulation for knowledge graph layout.
//! This port abstracts CUDA/OpenCL implementations for physics computations.

use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use std::sync::Arc;

use crate::models::graph::GraphData;

pub type Result<T> = std::result::Result<T, GpuPhysicsAdapterError>;

#[derive(Debug, thiserror::Error, Serialize)]
pub enum GpuPhysicsAdapterError {
    #[error("GPU not available")]
    GpuNotAvailable,

    #[error("Physics computation error: {0}")]
    ComputationError(String),

    #[error("Invalid parameters: {0}")]
    InvalidParameters(String),

    #[error("CUDA error: {0}")]
    CudaError(String),

    #[error("Memory allocation error: {0}")]
    MemoryError(String),

    #[error("Graph not loaded")]
    GraphNotLoaded,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GpuDeviceInfo {
    pub device_id: u32,
    pub device_name: String,
    pub compute_capability: (u32, u32),
    pub total_memory_mb: usize,
    pub free_memory_mb: usize,
    pub multiprocessor_count: u32,
    pub warp_size: u32,
    pub max_threads_per_block: u32,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NodeForce {
    pub node_id: u32,
    pub force_x: f32,
    pub force_y: f32,
    pub force_z: f32,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PhysicsStepResult {
    pub nodes_updated: usize,
    pub total_energy: f32,
    pub max_displacement: f32,
    pub converged: bool,
    pub computation_time_ms: f32,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PhysicsStatistics {
    pub total_steps: u64,
    pub average_step_time_ms: f32,
    pub average_energy: f32,
    pub gpu_memory_used_mb: f32,
    pub cache_hit_rate: f32,
    pub last_convergence_iterations: u32,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PhysicsParameters {
    pub time_step: f32,
    pub damping: f32,
    pub spring_constant: f32,
    pub repulsion_strength: f32,
    pub attraction_strength: f32,
    pub max_velocity: f32,
    pub convergence_threshold: f32,
    pub max_iterations: u32,
}

impl Default for PhysicsParameters {
    fn default() -> Self {
        Self {
            time_step: 0.016, 
            damping: 0.8,
            spring_constant: 0.01,
            repulsion_strength: 100.0,
            attraction_strength: 0.1,
            max_velocity: 10.0,
            convergence_threshold: 0.01,
            max_iterations: 1000,
        }
    }
}

///
#[async_trait]
pub trait GpuPhysicsAdapter: Send + Sync {
    
    async fn initialize(&mut self, graph: Arc<GraphData>, params: PhysicsParameters) -> Result<()>;

    
    
    async fn compute_forces(&mut self) -> Result<Vec<NodeForce>>;

    
    
    async fn update_positions(&mut self, forces: &[NodeForce])
        -> Result<Vec<(u32, f32, f32, f32)>>;

    
    
    async fn step(&mut self) -> Result<PhysicsStepResult>;

    
    
    async fn simulate_until_convergence(&mut self) -> Result<PhysicsStepResult>;

    
    
    async fn apply_external_forces(&mut self, forces: Vec<(u32, f32, f32, f32)>) -> Result<()>;

    
    
    async fn pin_nodes(&mut self, nodes: Vec<(u32, f32, f32, f32)>) -> Result<()>;

    
    async fn unpin_nodes(&mut self, node_ids: Vec<u32>) -> Result<()>;

    
    async fn update_parameters(&mut self, params: PhysicsParameters) -> Result<()>;

    
    async fn update_graph_data(&mut self, graph: Arc<GraphData>) -> Result<()>;

    
    async fn get_gpu_status(&self) -> Result<GpuDeviceInfo>;

    
    async fn get_statistics(&self) -> Result<PhysicsStatistics>;

    
    async fn reset(&mut self) -> Result<()>;

    
    async fn cleanup(&mut self) -> Result<()>;
}

--------------------------------------------------------------------------------
FILE: src/ports/gpu_semantic_analyzer.rs
PURPOSE: GpuSemanticAnalyzer trait for GPU semantic analysis
--------------------------------------------------------------------------------
// src/ports/gpu_semantic_analyzer.rs
//! GPU Semantic Analyzer Port
//!
//! Provides GPU-accelerated semantic analysis, clustering, and pathfinding.
//! This port abstracts CUDA/OpenCL implementations for graph algorithms.

use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;

use crate::models::constraints::ConstraintSet;
use crate::models::graph::GraphData;

pub type Result<T> = std::result::Result<T, GpuSemanticAnalyzerError>;

#[derive(Debug, thiserror::Error, Serialize)]
pub enum GpuSemanticAnalyzerError {
    #[error("GPU not available")]
    GpuNotAvailable,

    #[error("Analysis error: {0}")]
    AnalysisError(String),

    #[error("Invalid graph: {0}")]
    InvalidGraph(String),

    #[error("Algorithm not supported: {0}")]
    UnsupportedAlgorithm(String),

    #[error("CUDA error: {0}")]
    CudaError(String),
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ClusteringAlgorithm {
    Louvain,
    LabelPropagation,
    ConnectedComponents,
    HierarchicalClustering { min_cluster_size: usize },
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CommunityDetectionResult {
    pub clusters: HashMap<u32, usize>,        
    pub cluster_sizes: HashMap<usize, usize>, 
    pub modularity: f32,
    pub computation_time_ms: f32,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PathfindingResult {
    pub source_node: u32,
    pub distances: HashMap<u32, f32>,  
    pub paths: HashMap<u32, Vec<u32>>, 
    pub computation_time_ms: f32,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SemanticConstraintConfig {
    pub similarity_threshold: f32,
    pub enable_clustering_constraints: bool,
    pub enable_importance_constraints: bool,
    pub enable_topic_constraints: bool,
    pub max_constraints: usize,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OptimizationResult {
    pub converged: bool,
    pub iterations: u32,
    pub final_stress: f32,
    pub convergence_delta: f32,
    pub computation_time_ms: f32,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ImportanceAlgorithm {
    PageRank { damping: f32, max_iterations: usize },
    Betweenness,
    Closeness,
    Eigenvector,
    Degree,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SemanticStatistics {
    pub total_analyses: u64,
    pub average_clustering_time_ms: f32,
    pub average_pathfinding_time_ms: f32,
    pub cache_hit_rate: f32,
    pub gpu_memory_used_mb: f32,
}

///
#[async_trait]
pub trait GpuSemanticAnalyzer: Send + Sync {
    
    async fn initialize(&mut self, graph: Arc<GraphData>) -> Result<()>;

    
    async fn detect_communities(
        &mut self,
        algorithm: ClusteringAlgorithm,
    ) -> Result<CommunityDetectionResult>;

    
    
    async fn compute_shortest_paths(&mut self, source_node_id: u32) -> Result<PathfindingResult>;

    
    
    async fn compute_sssp_distances(&mut self, source_node_id: u32) -> Result<Vec<f32>>;

    
    
    
    async fn compute_all_pairs_shortest_paths(&mut self) -> Result<HashMap<(u32, u32), Vec<u32>>>;

    
    
    
    async fn compute_landmark_apsp(&mut self, num_landmarks: usize) -> Result<Vec<Vec<f32>>>;

    
    async fn generate_semantic_constraints(
        &mut self,
        config: SemanticConstraintConfig,
    ) -> Result<ConstraintSet>;

    
    async fn optimize_layout(
        &mut self,
        constraints: &ConstraintSet,
        max_iterations: usize,
    ) -> Result<OptimizationResult>;

    
    async fn analyze_node_importance(
        &mut self,
        algorithm: ImportanceAlgorithm,
    ) -> Result<HashMap<u32, f32>>;

    
    async fn update_graph_data(&mut self, graph: Arc<GraphData>) -> Result<()>;

    
    async fn get_statistics(&self) -> Result<SemanticStatistics>;

    
    async fn invalidate_pathfinding_cache(&mut self) -> Result<()>;
}

================================================================================
                    SECTION 3: ADAPTERS (Neo4j, GPU Implementations)
================================================================================

--------------------------------------------------------------------------------
FILE: src/adapters/mod.rs
PURPOSE: Module exports for hexagonal architecture adapters
--------------------------------------------------------------------------------
// src/adapters/mod.rs
//! Hexagonal Architecture Adapters
//!
//! This module contains adapters that implement the port interfaces
//! using concrete technologies (actors, GPU compute, Neo4j, etc.)

// CQRS Phase 1: Actor-based adapter for gradual migration
pub mod actor_graph_repository;

// CQRS Phase 2: Neo4j direct query adapter (professional, scalable)
pub mod neo4j_graph_repository;

// Legacy adapters
// pub mod gpu_physics_adapter;
#[cfg(feature = "gpu")]
pub mod gpu_semantic_analyzer;

// New hexser-based adapters (legacy removed, using unified repositories)
pub mod whelk_inference_engine;

// Neo4j integration adapters
pub mod neo4j_adapter;

// Phase 2.2: Actor system adapter wrappers
#[cfg(feature = "gpu")]
pub mod actix_physics_adapter;
pub mod actix_semantic_adapter;
pub mod messages;

// Compatibility alias for physics orchestrator adapter
pub mod physics_orchestrator_adapter;

// CQRS Phase 1: Actor-based adapter exports
pub use actor_graph_repository::ActorGraphRepository;

// CQRS Phase 2: Neo4j direct query adapter exports
pub use neo4j_graph_repository::Neo4jGraphRepository;

// GPU adapter implementation exports (these implement the traits from crate::ports)
// pub use gpu_physics_adapter::GpuPhysicsAdapter as GpuPhysicsAdapterImpl;
#[cfg(feature = "gpu")]
pub use gpu_semantic_analyzer::GpuSemanticAnalyzerAdapter;

// Settings repository adapters
// REMOVED: sqlite_settings_repository - migrated to Neo4j
pub mod neo4j_settings_repository;
pub mod neo4j_ontology_repository;

pub use neo4j_settings_repository::{Neo4jSettingsRepository, Neo4jSettingsConfig};
pub use neo4j_ontology_repository::{Neo4jOntologyRepository, Neo4jOntologyConfig};

// Inference engine exports
pub use whelk_inference_engine::WhelkInferenceEngine;

// Neo4j integration exports
pub use neo4j_adapter::{Neo4jAdapter, Neo4jConfig};

// Phase 2.2: Actor wrapper adapter exports
#[cfg(feature = "gpu")]
pub use actix_physics_adapter::ActixPhysicsAdapter;
pub use actix_semantic_adapter::ActixSemanticAdapter;

--------------------------------------------------------------------------------
FILE: src/adapters/neo4j_adapter.rs
PURPOSE: Main Neo4j integration with connection pooling and security
--------------------------------------------------------------------------------
// src/adapters/neo4j_adapter.rs
//! Neo4j Graph Repository Adapter
//!
//! Implements KnowledgeGraphRepository trait using Neo4j graph database.
//! Provides native Cypher query support for multi-hop reasoning and path analysis.
//!
//! Database schema:
//! - Nodes: (:GraphNode {id, metadata_id, label, owl_class_iri, ...})
//! - Relationships: [:EDGE {weight, relation_type, owl_property_iri}]
//!
//! This adapter enables:
//! - Complex graph traversals with Cypher
//! - Multi-hop path analysis
//! - Semantic reasoning via OWL enrichment
//! - High-performance graph queries

use async_trait::async_trait;
use log::{debug, info, warn};
use neo4rs::{Graph, Query, Node as Neo4jNode, ConfigBuilder};
use std::collections::HashMap;
use std::sync::Arc;
use tracing::instrument;

use crate::models::edge::Edge;
use crate::models::graph::GraphData;
use crate::models::node::Node;
use crate::utils::json::{to_json, from_json};
use crate::ports::knowledge_graph_repository::{
    GraphStatistics, KnowledgeGraphRepository, KnowledgeGraphRepositoryError,
    Result as RepoResult,
};
use crate::utils::network::circuit_breaker::{CircuitBreaker, CircuitBreakerConfig, CircuitBreakerError};
use crate::utils::time;

/// Neo4j configuration with security and performance settings
#[derive(Debug, Clone)]
pub struct Neo4jConfig {
    pub uri: String,
    pub user: String,
    pub password: String,
    pub database: Option<String>,
    /// Maximum number of connections in the pool (default: 50)
    pub max_connections: usize,
    /// Query timeout in seconds (default: 30)
    pub query_timeout_secs: u64,
    /// Connection timeout in seconds (default: 10)
    pub connection_timeout_secs: u64,
}

impl Default for Neo4jConfig {
    fn default() -> Self {
        // SECURITY: NEO4J_PASSWORD is REQUIRED - no insecure defaults
        let password = std::env::var("NEO4J_PASSWORD").unwrap_or_else(|_| {
            // In development/test mode, allow default only if explicitly set
            if std::env::var("ALLOW_INSECURE_DEFAULTS").is_ok() {
                log::warn!("  NEO4J_PASSWORD not set - using insecure default (ALLOW_INSECURE_DEFAULTS=1)");
                "password".to_string()
            } else {
                log::error!(" CRITICAL: NEO4J_PASSWORD environment variable is REQUIRED!");
                log::error!("   Set NEO4J_PASSWORD=<your-secure-password> or");
                log::error!("   Set ALLOW_INSECURE_DEFAULTS=1 for development only");
                panic!("NEO4J_PASSWORD must be set. See logs for details.");
            }
        });

        // Reject obviously insecure passwords in production
        if password == "password" || password == "neo4j" || password.len() < 8 {
            if std::env::var("ALLOW_INSECURE_DEFAULTS").is_err() {
                log::error!(" CRITICAL: NEO4J_PASSWORD is too weak or uses a default value!");
                panic!("NEO4J_PASSWORD must be at least 8 characters and not a default value");
            }
        }

        Self {
            uri: std::env::var("NEO4J_URI").unwrap_or_else(|_| "bolt://localhost:7687".to_string()),
            user: std::env::var("NEO4J_USER").unwrap_or_else(|_| "neo4j".to_string()),
            password,
            database: std::env::var("NEO4J_DATABASE").ok(),
            max_connections: std::env::var("NEO4J_MAX_CONNECTIONS")
                .ok()
                .and_then(|v| v.parse().ok())
                .unwrap_or(50),
            query_timeout_secs: std::env::var("NEO4J_QUERY_TIMEOUT")
                .ok()
                .and_then(|v| v.parse().ok())
                .unwrap_or(30),
            connection_timeout_secs: std::env::var("NEO4J_CONNECTION_TIMEOUT")
                .ok()
                .and_then(|v| v.parse().ok())
                .unwrap_or(10),
        }
    }
}

/// Repository for knowledge graph data in Neo4j
///
/// Provides high-performance graph operations with native Cypher support.
/// All node positions and velocities are persisted and can be queried with
/// complex graph patterns.
pub struct Neo4jAdapter {
    graph: Arc<Graph>,
    config: Neo4jConfig,
    circuit_breaker: CircuitBreaker,
}

impl Neo4jAdapter {
    /// Create a new Neo4jAdapter with security hardening
    ///
    /// # Arguments
    /// * `config` - Neo4j connection configuration
    ///
    /// # Security
    /// - Uses connection pooling (configured via config.max_connections)
    /// - Enforces query timeouts (configured via config.query_timeout_secs)
    /// - Logs warning if default password is used
    ///
    /// # Returns
    /// Initialized adapter ready for graph operations
    pub async fn new(config: Neo4jConfig) -> Result<Self, KnowledgeGraphRepositoryError> {
        // SECURITY: Validate configuration
        if config.password == "password" {
            log::error!(" CRITICAL: Using default password 'password' for Neo4j!");
            log::error!(" Set NEO4J_PASSWORD environment variable immediately!");
        }

        if config.max_connections == 0 {
            return Err(KnowledgeGraphRepositoryError::DatabaseError(
                "Invalid configuration: max_connections must be > 0".to_string()
            ));
        }

        info!("Connecting to Neo4j at {} (max_connections: {}, query_timeout: {}s)",
              config.uri, config.max_connections, config.query_timeout_secs);

        // PERF: Configure connection pool for high-throughput graph operations
        let neo4j_config = ConfigBuilder::default()
            .uri(&config.uri)
            .user(&config.user)
            .password(&config.password)
            .max_connections(config.max_connections)
            .build()
            .map_err(|e| {
                KnowledgeGraphRepositoryError::DatabaseError(format!(
                    "Failed to build Neo4j config: {}",
                    e
                ))
            })?;

        let graph = Graph::connect(neo4j_config)
            .map_err(|e| {
                KnowledgeGraphRepositoryError::DatabaseError(format!(
                    "Failed to connect to Neo4j: {}",
                    e
                ))
            })?;

        info!("Connected to Neo4j successfully with {} connection pool", config.max_connections);

        let adapter = Self {
            graph: Arc::new(graph),
            config,
            circuit_breaker: CircuitBreaker::new(CircuitBreakerConfig::tcp_connection()),
        };

        // Create indexes and constraints
        adapter.create_schema().await?;

        Ok(adapter)
    }

    /// Get access to underlying Graph for direct queries
    pub fn graph(&self) -> &Arc<Graph> {
        &self.graph
    }

    /// Create Neo4j schema (indexes and constraints)
    async fn create_schema(&self) -> RepoResult<()> {
        info!("Creating Neo4j schema...");

        // Create uniqueness constraint on GraphNode.id
        let constraint_query = Query::new("CREATE CONSTRAINT graph_node_id IF NOT EXISTS FOR (n:GraphNode) REQUIRE n.id IS UNIQUE".to_string());

        if let Err(e) = self.graph.run(constraint_query).await {
            warn!("Failed to create constraint (may already exist): {}", e);
        }

        // Create index on metadata_id for faster lookups
        let index_query = Query::new("CREATE INDEX graph_node_metadata_id IF NOT EXISTS FOR (n:GraphNode) ON (n.metadata_id)".to_string());

        if let Err(e) = self.graph.run(index_query).await {
            warn!("Failed to create index (may already exist): {}", e);
        }

        // Create index on owl_class_iri for semantic queries
        let owl_index_query = Query::new("CREATE INDEX graph_node_owl_class IF NOT EXISTS FOR (n:GraphNode) ON (n.owl_class_iri)".to_string());

        if let Err(e) = self.graph.run(owl_index_query).await {
            warn!("Failed to create OWL index (may already exist): {}", e);
        }

        // Create index on node_type for semantic force filtering
        let node_type_index_query = Query::new("CREATE INDEX graph_node_type IF NOT EXISTS FOR (n:GraphNode) ON (n.node_type)".to_string());

        if let Err(e) = self.graph.run(node_type_index_query).await {
            warn!("Failed to create node_type index (may already exist): {}", e);
        }

        // Create index on edge relation_type for semantic pathfinding
        let edge_type_index_query = Query::new("CREATE INDEX edge_relation_type IF NOT EXISTS FOR ()-[r:EDGE]-() ON (r.relation_type)".to_string());

        if let Err(e) = self.graph.run(edge_type_index_query).await {
            warn!("Failed to create edge relation_type index (may already exist): {}", e);
        }

        info!(" Neo4j schema created successfully with semantic type indexes");
        Ok(())
    }

    /// Convert Node to Neo4j properties
    fn node_to_properties(node: &Node) -> HashMap<String, neo4rs::BoltType> {
        let mut props = HashMap::new();

        props.insert("id".to_string(), neo4rs::BoltType::Integer(neo4rs::BoltInteger::new(node.id as i64)));
        props.insert("metadata_id".to_string(), neo4rs::BoltType::String(neo4rs::BoltString::from(node.metadata_id.clone())));
        props.insert("label".to_string(), neo4rs::BoltType::String(neo4rs::BoltString::from(node.label.clone())));
        props.insert("x".to_string(), neo4rs::BoltType::Float(neo4rs::BoltFloat::new(node.data.x as f64)));
        props.insert("y".to_string(), neo4rs::BoltType::Float(neo4rs::BoltFloat::new(node.data.y as f64)));
        props.insert("z".to_string(), neo4rs::BoltType::Float(neo4rs::BoltFloat::new(node.data.z as f64)));
        props.insert("vx".to_string(), neo4rs::BoltType::Float(neo4rs::BoltFloat::new(node.data.vx as f64)));
        props.insert("vy".to_string(), neo4rs::BoltType::Float(neo4rs::BoltFloat::new(node.data.vy as f64)));
        props.insert("vz".to_string(), neo4rs::BoltType::Float(neo4rs::BoltFloat::new(node.data.vz as f64)));
        props.insert("mass".to_string(), neo4rs::BoltType::Float(neo4rs::BoltFloat::new(node.mass.unwrap_or(1.0) as f64)));

        if let Some(ref iri) = node.owl_class_iri {
            props.insert("owl_class_iri".to_string(), neo4rs::BoltType::String(neo4rs::BoltString::from(iri.clone())));
        }

        if let Some(ref color) = node.color {
            props.insert("color".to_string(), neo4rs::BoltType::String(neo4rs::BoltString::from(color.clone())));
        }

        if let Some(size) = node.size {
            props.insert("size".to_string(), neo4rs::BoltType::Float(neo4rs::BoltFloat::new(size as f64)));
        }

        if let Some(ref node_type) = node.node_type {
            props.insert("node_type".to_string(), neo4rs::BoltType::String(neo4rs::BoltString::from(node_type.clone())));
        }

        if let Some(weight) = node.weight {
            props.insert("weight".to_string(), neo4rs::BoltType::Float(neo4rs::BoltFloat::new(weight as f64)));
        }

        if let Some(ref group) = node.group {
            props.insert("group_name".to_string(), neo4rs::BoltType::String(neo4rs::BoltString::from(group.clone())));
        }

        // Serialize metadata as JSON string
        if !node.metadata.is_empty() {
            if let Ok(json) = to_json(&node.metadata) {
                props.insert("metadata".to_string(), neo4rs::BoltType::String(neo4rs::BoltString::from(json)));
            }
        }

        props
    }

    /// Convert Neo4j node to our Node model
    /// Prioritizes sim_* properties for physics coordinates (GPU-calculated positions)
    fn neo4j_node_to_node(neo4j_node: &Neo4jNode) -> RepoResult<Node> {
        let id: i64 = neo4j_node.get("id").map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Missing id: {}", e))
        })?;

        let metadata_id: String = neo4j_node.get("metadata_id").map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Missing metadata_id: {}", e))
        })?;

        let label: String = neo4j_node.get("label").unwrap_or_else(|_| String::new());

        // Prefer sim_* properties (GPU physics state) over x/y/z (initial/content positions)
        // This preserves the calculated layout during content sync
        let x: f64 = neo4j_node.get("sim_x").or_else(|_| neo4j_node.get("x")).unwrap_or(0.0);
        let y: f64 = neo4j_node.get("sim_y").or_else(|_| neo4j_node.get("y")).unwrap_or(0.0);
        let z: f64 = neo4j_node.get("sim_z").or_else(|_| neo4j_node.get("z")).unwrap_or(0.0);
        let vx: f64 = neo4j_node.get("vx").unwrap_or(0.0);
        let vy: f64 = neo4j_node.get("vy").unwrap_or(0.0);
        let vz: f64 = neo4j_node.get("vz").unwrap_or(0.0);
        let mass: f64 = neo4j_node.get("mass").unwrap_or(1.0);

        let owl_class_iri: Option<String> = neo4j_node.get("owl_class_iri").ok();
        let color: Option<String> = neo4j_node.get("color").ok();
        let size: Option<f64> = neo4j_node.get("size").ok();
        let node_type: Option<String> = neo4j_node.get("node_type").ok();
        let weight: Option<f64> = neo4j_node.get("weight").ok();
        let group_name: Option<String> = neo4j_node.get("group_name").ok();

        let mut metadata: HashMap<String, String> = neo4j_node
            .get::<String>("metadata")
            .ok()
            .and_then(|json| from_json(&json).ok())
            .unwrap_or_default();

        // Read quality_score and authority_score from Neo4j node properties
        // These are stored as top-level properties, not inside metadata JSON
        if let Ok(quality_score) = neo4j_node.get::<f64>("quality_score") {
            metadata.insert("quality_score".to_string(), quality_score.to_string());
        }
        if let Ok(authority_score) = neo4j_node.get::<f64>("authority_score") {
            metadata.insert("authority_score".to_string(), authority_score.to_string());
        }

        let mut node = Node::new_with_id(metadata_id, Some(id as u32));
        node.label = label;
        node.data.x = x as f32;
        node.data.y = y as f32;
        node.data.z = z as f32;
        node.data.vx = vx as f32;
        node.data.vy = vy as f32;
        node.data.vz = vz as f32;
        node.mass = Some(mass as f32);
        node.owl_class_iri = owl_class_iri;
        node.color = color;
        node.size = size.map(|s| s as f32);
        node.node_type = node_type;
        node.weight = weight.map(|w| w as f32);
        node.group = group_name;
        node.metadata = metadata;

        Ok(node)
    }

    /// Execute a parameterized Cypher query (SAFE - use this for user input)
    ///
    /// # Security
    /// This method enforces parameterization to prevent Cypher injection attacks.
    /// DO NOT concatenate user input into the query string - use parameters instead.
    ///
    /// # Example
    /// ```ignore
    /// // SAFE - Uses parameters
    /// let params = hashmap!{"name" => BoltType::String("Alice".into())};
    /// adapter.execute_cypher_safe("MATCH (n:User {name: $name}) RETURN n", params).await?;
    ///
    /// // UNSAFE - Don't do this!
    /// // let query = format!("MATCH (n:User {{name: '{}'}}) RETURN n", user_input);
    /// ```
    pub async fn execute_cypher_safe(
        &self,
        query: &str,
        params: HashMap<String, neo4rs::BoltType>,
    ) -> RepoResult<Vec<HashMap<String, serde_json::Value>>> {
        self.execute_cypher_internal(query, params, true).await
    }

    /// Execute a Cypher query (DEPRECATED - use execute_cypher_safe)
    ///
    /// # Security Warning
    /// This method is deprecated in favor of execute_cypher_safe.
    /// Only use this for trusted, static queries. Never concatenate user input!
    #[deprecated(since = "0.1.0", note = "Use execute_cypher_safe instead")]
    pub async fn execute_cypher(
        &self,
        query: &str,
        params: HashMap<String, neo4rs::BoltType>,
    ) -> RepoResult<Vec<HashMap<String, serde_json::Value>>> {
        log::warn!("execute_cypher is deprecated - use execute_cypher_safe instead");
        self.execute_cypher_internal(query, params, false).await
    }

    /// Internal method for executing Cypher queries
    async fn execute_cypher_internal(
        &self,
        query: &str,
        params: HashMap<String, neo4rs::BoltType>,
        _safe_mode: bool,
    ) -> RepoResult<Vec<HashMap<String, serde_json::Value>>> {
        // SECURITY: Log query execution (without sensitive data)
        debug!("Executing Cypher query with {} parameters", params.len());

        let mut query_obj = Query::new(query.to_string());

        for (key, value) in params {
            query_obj = query_obj.param(&key, value);
        }

        // Apply query timeout at application level (neo4rs doesn't support query-level timeouts)
        // Default timeout: 30 seconds for complex graph queries
        let query_timeout = std::time::Duration::from_secs(
            std::env::var("NEO4J_QUERY_TIMEOUT_SECS")
                .ok()
                .and_then(|s| s.parse().ok())
                .unwrap_or(30)
        );

        // Clone graph Arc for use in closure
        let graph = self.graph.clone();

        // Wrap query execution with circuit breaker for network resilience
        let execute_result = self.circuit_breaker.execute(async {
            let result = tokio::time::timeout(
                query_timeout,
                graph.execute(query_obj)
            ).await;

            match result {
                Ok(Ok(r)) => Ok(r),
                Ok(Err(e)) => {
                    log::error!("Cypher query failed: {}", e);
                    Err(KnowledgeGraphRepositoryError::DatabaseError(format!("Cypher query failed: {}", e)))
                }
                Err(_) => {
                    log::error!("Cypher query timed out after {:?}", query_timeout);
                    Err(KnowledgeGraphRepositoryError::DatabaseError(
                        format!("Query timed out after {:?}", query_timeout)
                    ))
                }
            }
        }).await;

        let mut result = match execute_result {
            Ok(r) => r,
            Err(CircuitBreakerError::CircuitOpen) => {
                log::warn!("Circuit breaker is open - Neo4j queries temporarily blocked");
                return Err(KnowledgeGraphRepositoryError::DatabaseError(
                    "Circuit breaker open: Neo4j service temporarily unavailable".to_string()
                ));
            }
            Err(CircuitBreakerError::OperationFailed(e)) => {
                return Err(e);
            }
        };

        let mut results = Vec::new();
        while let Ok(Some(_row)) = result.next().await {
            // Note: Neo4rs Row API doesn't provide direct access to all keys
            // For now, returning empty map - users should use specific field access
            let row_map = HashMap::new();
            results.push(row_map);
        }

        Ok(results)
    }
}

#[async_trait]
impl KnowledgeGraphRepository for Neo4jAdapter {
    #[instrument(skip(self), level = "debug")]
    async fn load_graph(&self) -> RepoResult<Arc<GraphData>> {
        // Load all nodes
        let nodes_query = Query::new("MATCH (n:GraphNode) RETURN n ORDER BY n.id".to_string());

        let mut nodes = Vec::new();
        let mut result = self.graph.execute(nodes_query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to load nodes: {}", e))
        })?;

        while let Ok(Some(row)) = result.next().await {
            if let Ok(neo4j_node) = row.get::<Neo4jNode>("n") {
                nodes.push(Self::neo4j_node_to_node(&neo4j_node)?);
            }
        }

        debug!("Loaded {} nodes from Neo4j", nodes.len());

        // Load all edges
        let edges_query = Query::new("MATCH (s:GraphNode)-[r:EDGE]->(t:GraphNode) RETURN s.id AS source, t.id AS target, r.weight AS weight, r.relation_type AS relation_type, r.owl_property_iri AS owl_property_iri, r.metadata AS metadata".to_string());

        let mut edges = Vec::new();
        let mut result = self.graph.execute(edges_query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to load edges: {}", e))
        })?;

        while let Ok(Some(row)) = result.next().await {
            let source: i64 = row.get("source").unwrap_or(0);
            let target: i64 = row.get("target").unwrap_or(0);
            let weight: f64 = row.get("weight").unwrap_or(1.0);
            let relation_type: Option<String> = row.get("relation_type").ok();
            let owl_property_iri: Option<String> = row.get("owl_property_iri").ok();
            let metadata_json: Option<String> = row.get("metadata").ok();

            let metadata = metadata_json
                .and_then(|json| from_json(&json).ok());

            let mut edge = Edge::new(source as u32, target as u32, weight as f32);
            edge.edge_type = relation_type;
            edge.owl_property_iri = owl_property_iri;
            edge.metadata = metadata;

            edges.push(edge);
        }

        debug!("Loaded {} edges from Neo4j", edges.len());

        let mut graph = GraphData::new();
        graph.nodes = nodes;
        graph.edges = edges;

        Ok(Arc::new(graph))
    }

    async fn save_graph(&self, graph: &GraphData) -> RepoResult<()> {
        // Save nodes in batch - PRESERVING physics state (sim_x/y/z, vx/vy/vz)
        // Content sync should NEVER reset GPU-calculated layout positions
        for node in &graph.nodes {
            // Use COALESCE to preserve existing physics coordinates
            // Physics state is stored in sim_* properties, content coords in x/y/z
            let query = Query::new(
                "MERGE (n:GraphNode {id: $id})
                 ON CREATE SET
                     n.metadata_id = $metadata_id,
                     n.label = $label,
                     n.x = $x,
                     n.y = $y,
                     n.z = $z,
                     n.sim_x = $x,
                     n.sim_y = $y,
                     n.sim_z = $z,
                     n.vx = $vx,
                     n.vy = $vy,
                     n.vz = $vz,
                     n.mass = $mass,
                     n.owl_class_iri = $owl_class_iri,
                     n.color = $color,
                     n.size = $size,
                     n.node_type = $node_type,
                     n.weight = $weight,
                     n.group_name = $group_name,
                     n.metadata = $metadata
                 ON MATCH SET
                     n.metadata_id = $metadata_id,
                     n.label = $label,
                     n.owl_class_iri = COALESCE($owl_class_iri, n.owl_class_iri),
                     n.color = COALESCE($color, n.color),
                     n.size = COALESCE($size, n.size),
                     n.node_type = COALESCE($node_type, n.node_type),
                     n.weight = COALESCE($weight, n.weight),
                     n.group_name = COALESCE($group_name, n.group_name),
                     n.metadata = $metadata
                 // NEVER overwrite sim_x/sim_y/sim_z or vx/vy/vz on MATCH
                 // These are the GPU-calculated physics positions
                ".to_string()
            )
            .param("id", node.id as i64)
            .param("metadata_id", node.metadata_id.clone())
            .param("label", node.label.clone())
            .param("x", node.data.x as f64)
            .param("y", node.data.y as f64)
            .param("z", node.data.z as f64)
            .param("vx", node.data.vx as f64)
            .param("vy", node.data.vy as f64)
            .param("vz", node.data.vz as f64)
            .param("mass", node.mass.unwrap_or(1.0) as f64)
            .param("owl_class_iri", node.owl_class_iri.clone().unwrap_or_default())
            .param("color", node.color.clone().unwrap_or_default())
            .param("size", node.size.unwrap_or(1.0) as f64)
            .param("node_type", node.node_type.clone().unwrap_or_default())
            .param("weight", node.weight.unwrap_or(1.0) as f64)
            .param("group_name", node.group.clone().unwrap_or_default())
            .param("metadata", serde_json::to_string(&node.metadata).unwrap_or_default());

            self.graph.run(query).await.map_err(|e| {
                KnowledgeGraphRepositoryError::DatabaseError(format!(
                    "Failed to save node {}: {}",
                    node.id, e
                ))
            })?;
        }

        // Save edges in batch
        for edge in &graph.edges {
            let mut query = Query::new("MATCH (s:GraphNode {id: $source}) MATCH (t:GraphNode {id: $target}) MERGE (s)-[r:EDGE]->(t) SET r.weight = $weight, r.relation_type = $relation_type, r.owl_property_iri = $owl_property_iri, r.metadata = $metadata".to_string());

            query = query.param("source", edge.source as i64);
            query = query.param("target", edge.target as i64);
            query = query.param("weight", edge.weight as f64);
            query = query.param("relation_type", edge.edge_type.clone().unwrap_or_default());
            query = query.param("owl_property_iri", edge.owl_property_iri.clone().unwrap_or_default());

            let metadata_json = edge.metadata.as_ref()
                .and_then(|m| to_json(m).ok())
                .unwrap_or_default();
            query = query.param("metadata", metadata_json);

            self.graph.run(query).await.map_err(|e| {
                KnowledgeGraphRepositoryError::DatabaseError(format!(
                    "Failed to save edge {}: {}",
                    edge.id, e
                ))
            })?;
        }

        info!("Saved graph to Neo4j: {} nodes, {} edges", graph.nodes.len(), graph.edges.len());
        Ok(())
    }

    async fn add_node(&self, node: &Node) -> RepoResult<u32> {
        let props = Self::node_to_properties(node);

        let mut query = Query::new("CREATE (n:GraphNode) SET n = $props RETURN n.id AS id".to_string());

        query = query.param("props", props);

        let mut result = self.graph.execute(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to add node: {}", e))
        })?;

        if let Ok(Some(row)) = result.next().await {
            let id: i64 = row.get("id").unwrap_or(node.id as i64);
            Ok(id as u32)
        } else {
            Ok(node.id)
        }
    }

    async fn batch_add_nodes(&self, nodes: Vec<Node>) -> RepoResult<Vec<u32>> {
        let mut ids = Vec::new();
        for node in nodes {
            let id = self.add_node(&node).await?;
            ids.push(id);
        }
        Ok(ids)
    }

    async fn update_node(&self, node: &Node) -> RepoResult<()> {
        let props = Self::node_to_properties(node);

        let mut query = Query::new("MATCH (n:GraphNode {id: $id}) SET n = $props".to_string());

        query = query.param("id", node.id as i64);
        query = query.param("props", props);

        self.graph.run(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to update node: {}", e))
        })?;

        Ok(())
    }

    async fn batch_update_nodes(&self, nodes: Vec<Node>) -> RepoResult<()> {
        for node in nodes {
            self.update_node(&node).await?;
        }
        Ok(())
    }

    async fn remove_node(&self, node_id: u32) -> RepoResult<()> {
        let query = Query::new("MATCH (n:GraphNode {id: $id}) DETACH DELETE n".to_string()).param("id", node_id as i64);

        self.graph.run(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to remove node: {}", e))
        })?;

        Ok(())
    }

    async fn batch_remove_nodes(&self, node_ids: Vec<u32>) -> RepoResult<()> {
        for id in node_ids {
            self.remove_node(id).await?;
        }
        Ok(())
    }

    async fn get_node(&self, node_id: u32) -> RepoResult<Option<Node>> {
        let query = Query::new("MATCH (n:GraphNode {id: $id}) RETURN n".to_string()).param("id", node_id as i64);

        let mut result = self.graph.execute(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to get node: {}", e))
        })?;

        if let Ok(Some(row)) = result.next().await {
            if let Ok(neo4j_node) = row.get::<Neo4jNode>("n") {
                return Ok(Some(Self::neo4j_node_to_node(&neo4j_node)?));
            }
        }

        Ok(None)
    }

    async fn get_nodes(&self, node_ids: Vec<u32>) -> RepoResult<Vec<Node>> {
        let ids: Vec<i64> = node_ids.iter().map(|&id| id as i64).collect();

        let query = Query::new("MATCH (n:GraphNode) WHERE n.id IN $ids RETURN n".to_string()).param("ids", ids);

        let mut nodes = Vec::new();
        let mut result = self.graph.execute(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to get nodes: {}", e))
        })?;

        while let Ok(Some(row)) = result.next().await {
            if let Ok(neo4j_node) = row.get::<Neo4jNode>("n") {
                nodes.push(Self::neo4j_node_to_node(&neo4j_node)?);
            }
        }

        Ok(nodes)
    }

    async fn get_nodes_by_metadata_id(&self, metadata_id: &str) -> RepoResult<Vec<Node>> {
        let query = Query::new("MATCH (n:GraphNode {metadata_id: $metadata_id}) RETURN n".to_string()).param("metadata_id", metadata_id.to_string());

        let mut nodes = Vec::new();
        let mut result = self.graph.execute(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to get nodes: {}", e))
        })?;

        while let Ok(Some(row)) = result.next().await {
            if let Ok(neo4j_node) = row.get::<Neo4jNode>("n") {
                nodes.push(Self::neo4j_node_to_node(&neo4j_node)?);
            }
        }

        Ok(nodes)
    }

    async fn search_nodes_by_label(&self, label: &str) -> RepoResult<Vec<Node>> {
        let query = Query::new("MATCH (n:GraphNode) WHERE n.label CONTAINS $label RETURN n".to_string()).param("label", label.to_string());

        let mut nodes = Vec::new();
        let mut result = self.graph.execute(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to search nodes: {}", e))
        })?;

        while let Ok(Some(row)) = result.next().await {
            if let Ok(neo4j_node) = row.get::<Neo4jNode>("n") {
                nodes.push(Self::neo4j_node_to_node(&neo4j_node)?);
            }
        }

        Ok(nodes)
    }

    async fn add_edge(&self, edge: &Edge) -> RepoResult<String> {
        let mut query = Query::new("MATCH (s:GraphNode {id: $source}) MATCH (t:GraphNode {id: $target}) CREATE (s)-[r:EDGE {weight: $weight, relation_type: $relation_type, owl_property_iri: $owl_property_iri, metadata: $metadata}]->(t) RETURN elementId(r) AS id".to_string());

        query = query.param("source", edge.source as i64);
        query = query.param("target", edge.target as i64);
        query = query.param("weight", edge.weight as f64);
        query = query.param("relation_type", edge.edge_type.clone().unwrap_or_default());
        query = query.param("owl_property_iri", edge.owl_property_iri.clone().unwrap_or_default());

        let metadata_json = edge.metadata.as_ref()
            .and_then(|m| to_json(m).ok())
            .unwrap_or_default();
        query = query.param("metadata", metadata_json);

        self.graph.run(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to add edge: {}", e))
        })?;

        Ok(edge.id.clone())
    }

    async fn batch_add_edges(&self, edges: Vec<Edge>) -> RepoResult<Vec<String>> {
        let mut ids = Vec::new();
        for edge in edges {
            let id = self.add_edge(&edge).await?;
            ids.push(id);
        }
        Ok(ids)
    }

    async fn update_edge(&self, edge: &Edge) -> RepoResult<()> {
        let mut query = Query::new("MATCH (s:GraphNode {id: $source})-[r:EDGE]->(t:GraphNode {id: $target}) SET r.weight = $weight, r.relation_type = $relation_type, r.owl_property_iri = $owl_property_iri, r.metadata = $metadata".to_string());

        query = query.param("source", edge.source as i64);
        query = query.param("target", edge.target as i64);
        query = query.param("weight", edge.weight as f64);
        query = query.param("relation_type", edge.edge_type.clone().unwrap_or_default());
        query = query.param("owl_property_iri", edge.owl_property_iri.clone().unwrap_or_default());

        let metadata_json = edge.metadata.as_ref()
            .and_then(|m| to_json(m).ok())
            .unwrap_or_default();
        query = query.param("metadata", metadata_json);

        self.graph.run(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to update edge: {}", e))
        })?;

        Ok(())
    }

    async fn remove_edge(&self, edge_id: &str) -> RepoResult<()> {
        // Parse edge_id format "source-target"
        let parts: Vec<&str> = edge_id.split('-').collect();
        if parts.len() != 2 {
            return Err(KnowledgeGraphRepositoryError::InvalidData(
                format!("Invalid edge_id format: {}", edge_id)
            ));
        }

        let source: u32 = parts[0].parse().map_err(|_| {
            KnowledgeGraphRepositoryError::InvalidData(format!("Invalid source id: {}", parts[0]))
        })?;

        let target: u32 = parts[1].parse().map_err(|_| {
            KnowledgeGraphRepositoryError::InvalidData(format!("Invalid target id: {}", parts[1]))
        })?;

        let query = Query::new("MATCH (s:GraphNode {id: $source})-[r:EDGE]->(t:GraphNode {id: $target}) DELETE r".to_string())
            .param("source", source as i64)
            .param("target", target as i64);

        self.graph.run(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to remove edge: {}", e))
        })?;

        Ok(())
    }

    async fn batch_remove_edges(&self, edge_ids: Vec<String>) -> RepoResult<()> {
        for id in edge_ids {
            self.remove_edge(&id).await?;
        }
        Ok(())
    }

    async fn get_node_edges(&self, node_id: u32) -> RepoResult<Vec<Edge>> {
        let query = Query::new("MATCH (s:GraphNode {id: $id})-[r:EDGE]-(t:GraphNode) RETURN s.id AS source, t.id AS target, r.weight AS weight, r.relation_type AS relation_type, r.owl_property_iri AS owl_property_iri, r.metadata AS metadata".to_string()).param("id", node_id as i64);

        let mut edges = Vec::new();
        let mut result = self.graph.execute(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to get node edges: {}", e))
        })?;

        while let Ok(Some(row)) = result.next().await {
            let source: i64 = row.get("source").unwrap_or(0);
            let target: i64 = row.get("target").unwrap_or(0);
            let weight: f64 = row.get("weight").unwrap_or(1.0);
            let relation_type: Option<String> = row.get("relation_type").ok();
            let owl_property_iri: Option<String> = row.get("owl_property_iri").ok();
            let metadata_json: Option<String> = row.get("metadata").ok();

            let metadata = metadata_json
                .and_then(|json| from_json(&json).ok());

            let mut edge = Edge::new(source as u32, target as u32, weight as f32);
            edge.edge_type = relation_type;
            edge.owl_property_iri = owl_property_iri;
            edge.metadata = metadata;

            edges.push(edge);
        }

        Ok(edges)
    }

    async fn get_edges_between(&self, source_id: u32, target_id: u32) -> RepoResult<Vec<Edge>> {
        let query = Query::new("MATCH (s:GraphNode {id: $source})-[r:EDGE]-(t:GraphNode {id: $target}) RETURN s.id AS source, t.id AS target, r.weight AS weight, r.relation_type AS relation_type, r.owl_property_iri AS owl_property_iri, r.metadata AS metadata".to_string())
            .param("source", source_id as i64)
            .param("target", target_id as i64);

        let mut edges = Vec::new();
        let mut result = self.graph.execute(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to get edges between: {}", e))
        })?;

        while let Ok(Some(row)) = result.next().await {
            let source: i64 = row.get("source").unwrap_or(0);
            let target: i64 = row.get("target").unwrap_or(0);
            let weight: f64 = row.get("weight").unwrap_or(1.0);
            let relation_type: Option<String> = row.get("relation_type").ok();
            let owl_property_iri: Option<String> = row.get("owl_property_iri").ok();
            let metadata_json: Option<String> = row.get("metadata").ok();

            let metadata = metadata_json
                .and_then(|json| from_json(&json).ok());

            let mut edge = Edge::new(source as u32, target as u32, weight as f32);
            edge.edge_type = relation_type;
            edge.owl_property_iri = owl_property_iri;
            edge.metadata = metadata;

            edges.push(edge);
        }

        Ok(edges)
    }

    async fn batch_update_positions(
        &self,
        positions: Vec<(u32, f32, f32, f32)>,
    ) -> RepoResult<()> {
        // Update sim_* properties (physics state) - these are the GPU-calculated positions
        // x/y/z remain as initial/content positions and are not overwritten by physics
        for (node_id, x, y, z) in positions {
            let query = Query::new(
                "MATCH (n:GraphNode {id: $id})
                 SET n.sim_x = $x, n.sim_y = $y, n.sim_z = $z".to_string()
            )
                .param("id", node_id as i64)
                .param("x", x as f64)
                .param("y", y as f64)
                .param("z", z as f64);

            self.graph.run(query).await.map_err(|e| {
                KnowledgeGraphRepositoryError::DatabaseError(format!(
                    "Failed to update position for node {}: {}",
                    node_id, e
                ))
            })?;
        }

        Ok(())
    }

    async fn query_nodes(&self, query: &str) -> RepoResult<Vec<Node>> {
        warn!("query_nodes with custom query not yet implemented for Neo4j");
        Ok(Vec::new())
    }

    async fn get_neighbors(&self, node_id: u32) -> RepoResult<Vec<Node>> {
        let query = Query::new("MATCH (n:GraphNode {id: $id})-[:EDGE]-(neighbor:GraphNode) RETURN DISTINCT neighbor AS n".to_string()).param("id", node_id as i64);

        let mut nodes = Vec::new();
        let mut result = self.graph.execute(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to get neighbors: {}", e))
        })?;

        while let Ok(Some(row)) = result.next().await {
            if let Ok(neo4j_node) = row.get::<Neo4jNode>("n") {
                nodes.push(Self::neo4j_node_to_node(&neo4j_node)?);
            }
        }

        Ok(nodes)
    }

    async fn get_statistics(&self) -> RepoResult<GraphStatistics> {
        let query = Query::new("MATCH (n:GraphNode) OPTIONAL MATCH (n)-[r:EDGE]-() RETURN count(DISTINCT n) AS node_count, count(r) AS edge_count".to_string());

        let mut result = self.graph.execute(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to get statistics: {}", e))
        })?;

        if let Ok(Some(row)) = result.next().await {
            let node_count: i64 = row.get("node_count").unwrap_or(0);
            let edge_count: i64 = row.get("edge_count").unwrap_or(0);

            let average_degree = if node_count > 0 {
                (edge_count as f32 * 2.0) / node_count as f32
            } else {
                0.0
            };

            // Calculate connected components using Cypher
            let components_query = Query::new(
                "MATCH (n:GraphNode)
                 WITH COLLECT(DISTINCT n) AS nodes
                 UNWIND nodes AS node
                 OPTIONAL MATCH path = (node)-[*]-(connected)
                 WITH node, COLLECT(DISTINCT connected) AS component
                 RETURN COUNT(DISTINCT component) AS component_count"
                    .to_string()
            );

            let mut component_count = 1; // Default to 1 if query fails
            if let Ok(mut result) = self.graph.execute(components_query).await {
                if let Some(row) = result.next().await.ok().flatten() {
                    if let Ok(count) = row.get::<i64>("component_count") {
                        component_count = count as usize;
                    }
                }
            }

            return Ok(GraphStatistics {
                node_count: node_count as usize,
                edge_count: edge_count as usize,
                average_degree,
                connected_components: component_count,
                last_updated: time::now(),
            });
        }

        Ok(GraphStatistics {
            node_count: 0,
            edge_count: 0,
            average_degree: 0.0,
            connected_components: 0,
            last_updated: time::now(),
        })
    }

    async fn clear_graph(&self) -> RepoResult<()> {
        let query = Query::new("MATCH (n:GraphNode) DETACH DELETE n".to_string());

        self.graph.run(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to clear graph: {}", e))
        })?;

        info!("Cleared all graph data from Neo4j");
        Ok(())
    }

    async fn begin_transaction(&self) -> RepoResult<()> {
        // Neo4j handles transactions internally
        Ok(())
    }

    async fn commit_transaction(&self) -> RepoResult<()> {
        // Neo4j handles transactions internally
        Ok(())
    }

    async fn rollback_transaction(&self) -> RepoResult<()> {
        // Neo4j handles transactions internally
        Ok(())
    }

    async fn health_check(&self) -> RepoResult<bool> {
        let query = Query::new("RETURN 1 AS health".to_string());

        match self.graph.run(query).await {
            Ok(_) => Ok(true),
            Err(_) => Ok(false),
        }
    }

    async fn get_all_positions(&self) -> RepoResult<HashMap<u32, (f32, f32, f32)>> {
        // Return sim_* positions (GPU physics state) when available, fallback to x/y/z
        let query = Query::new(
            "MATCH (n:GraphNode)
             WHERE n.sim_x IS NOT NULL OR n.x IS NOT NULL
             RETURN n.id AS id,
                    COALESCE(n.sim_x, n.x, 0.0) AS x,
                    COALESCE(n.sim_y, n.y, 0.0) AS y,
                    COALESCE(n.sim_z, n.z, 0.0) AS z".to_string()
        );

        let mut positions = HashMap::new();
        let mut result = self.graph.execute(query).await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to get all positions: {}", e))
        })?;

        while let Ok(Some(row)) = result.next().await {
            let id: i64 = row.get("id").unwrap_or(0);
            let x: f64 = row.get("x").unwrap_or(0.0);
            let y: f64 = row.get("y").unwrap_or(0.0);
            let z: f64 = row.get("z").unwrap_or(0.0);

            positions.insert(id as u32, (x as f32, y as f32, z as f32));
        }

        debug!("Retrieved {} node positions from Neo4j (using sim_* where available)", positions.len());
        Ok(positions)
    }

    async fn get_nodes_by_owl_class_iri(&self, owl_class_iri: &str) -> RepoResult<Vec<Node>> {
        let query = Query::new("MATCH (n:GraphNode) WHERE n.owl_class_iri = $iri RETURN n".to_string()).param("iri", owl_class_iri);

        let mut result = self.graph
            .execute(query)
            .await
            .map_err(|e| {
                KnowledgeGraphRepositoryError::DatabaseError(format!(
                    "Failed to query nodes by owl_class_iri: {}",
                    e
                ))
            })?;

        let mut nodes = Vec::new();

        while let Some(row) = result.next().await.map_err(|e| {
            KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
        })? {
            let neo_node: Neo4jNode = row.get("n").map_err(|e| {
                KnowledgeGraphRepositoryError::DatabaseError(format!("Failed to get node: {}", e))
            })?;

            let node = Self::neo4j_node_to_node(&neo_node)?;
            nodes.push(node);
        }

        Ok(nodes)
    }
}

--------------------------------------------------------------------------------
FILE: src/adapters/neo4j_graph_repository.rs
PURPOSE: Neo4j implementation of GraphRepository trait
--------------------------------------------------------------------------------
//! Neo4j Graph Repository - Direct queries with intelligent caching
//!
//! Professional architecture:
//! - Neo4j as single source of truth
//! - Read-through LRU cache for performance
//! - Lazy loading with pagination
//! - Batch operations for efficiency

use async_trait::async_trait;
use lru::LruCache;
use neo4rs::{Graph, query, BoltInteger, BoltFloat};
use std::collections::{HashMap, HashSet};
use std::num::NonZeroUsize;
use std::sync::Arc;
use tokio::sync::RwLock;
use tracing::{debug, info, warn, error, instrument};

use crate::actors::graph_actor::{AutoBalanceNotification, PhysicsState};
use crate::models::constraints::ConstraintSet;
use crate::models::edge::Edge;
use crate::models::graph::GraphData;
use crate::models::metadata::Metadata;
use crate::models::node::Node;
use crate::ports::graph_repository::{
    GraphRepository, GraphRepositoryError, PathfindingParams, PathfindingResult, Result,
};
use crate::ports::settings_repository::{SettingsRepository, SettingValue};
use crate::settings::models::NodeFilterSettings;
use crate::types::vec3::Vec3Data;
use glam::Vec3;

const CACHE_SIZE: usize = 10_000;
const BATCH_SIZE: usize = 1000;

/// Neo4j-backed graph repository with intelligent caching
pub struct Neo4jGraphRepository {
    graph: Arc<Graph>,

    /// LRU cache for nodes (id -> Node)
    node_cache: Arc<RwLock<LruCache<u32, Node>>>,

    /// LRU cache for edges (id -> Edge)
    edge_cache: Arc<RwLock<LruCache<String, Edge>>>,

    /// Cached graph snapshot (refreshed periodically or on demand)
    graph_snapshot: Arc<RwLock<Option<Arc<GraphData>>>>,

    /// Track if full graph is loaded
    is_loaded: Arc<RwLock<bool>>,

    /// Settings repository for reading node filter settings
    settings_repository: Option<Arc<dyn SettingsRepository>>,

    /// Cached node filter settings
    node_filter_settings: Arc<RwLock<NodeFilterSettings>>,
}

impl Neo4jGraphRepository {
    pub fn new(graph: Arc<Graph>) -> Self {
        Self {
            graph,
            node_cache: Arc::new(RwLock::new(
                LruCache::new(NonZeroUsize::new(CACHE_SIZE).unwrap())
            )),
            edge_cache: Arc::new(RwLock::new(
                LruCache::new(NonZeroUsize::new(CACHE_SIZE).unwrap())
            )),
            graph_snapshot: Arc::new(RwLock::new(None)),
            is_loaded: Arc::new(RwLock::new(false)),
            settings_repository: None,
            node_filter_settings: Arc::new(RwLock::new(NodeFilterSettings::default())),
        }
    }

    /// Create repository with settings support for node filtering
    pub fn with_settings(graph: Arc<Graph>, settings_repository: Arc<dyn SettingsRepository>) -> Self {
        Self {
            graph,
            node_cache: Arc::new(RwLock::new(
                LruCache::new(NonZeroUsize::new(CACHE_SIZE).unwrap())
            )),
            edge_cache: Arc::new(RwLock::new(
                LruCache::new(NonZeroUsize::new(CACHE_SIZE).unwrap())
            )),
            graph_snapshot: Arc::new(RwLock::new(None)),
            is_loaded: Arc::new(RwLock::new(false)),
            settings_repository: Some(settings_repository),
            node_filter_settings: Arc::new(RwLock::new(NodeFilterSettings::default())),
        }
    }

    /// Update node filter settings (called from settings actor when settings change)
    pub async fn set_node_filter_settings(&self, settings: NodeFilterSettings) {
        info!("Updating node filter settings: enabled={}, quality_threshold={}",
              settings.enabled, settings.quality_threshold);
        *self.node_filter_settings.write().await = settings;
        // Invalidate graph cache to force reload with new filters
        self.invalidate_cache().await;
    }

    /// Get current node filter settings
    pub async fn get_node_filter_settings(&self) -> NodeFilterSettings {
        self.node_filter_settings.read().await.clone()
    }

    /// Load node filter settings from repository
    async fn load_node_filter_settings(&self) -> NodeFilterSettings {
        if let Some(ref repo) = self.settings_repository {
            match repo.get_setting("node_filter").await {
                Ok(Some(SettingValue::Json(json))) => {
                    match serde_json::from_value::<NodeFilterSettings>(json) {
                        Ok(settings) => {
                            info!("Loaded node filter settings: enabled={}, threshold={}",
                                  settings.enabled, settings.quality_threshold);
                            return settings;
                        }
                        Err(e) => {
                            warn!("Failed to parse node filter settings: {}", e);
                        }
                    }
                }
                Ok(_) => {
                    debug!("No node filter settings found, using defaults");
                }
                Err(e) => {
                    warn!("Failed to load node filter settings: {}", e);
                }
            }
        }
        NodeFilterSettings::default()
    }

    /// Load full graph from Neo4j (called on startup or refresh)
    #[instrument(skip(self))]
    pub async fn load_graph(&self) -> Result<()> {
        info!("Loading full graph from Neo4j...");

        // Load and cache node filter settings first
        let filter_settings = self.load_node_filter_settings().await;
        *self.node_filter_settings.write().await = filter_settings.clone();

        info!("Node filter: enabled={}, quality_threshold={}, filter_by_quality={}",
              filter_settings.enabled, filter_settings.quality_threshold, filter_settings.filter_by_quality);

        // Load nodes with filter applied
        let nodes = self.load_all_nodes_filtered(&filter_settings).await?;
        let edges = self.load_all_edges().await?;
        let metadata = self.load_all_metadata().await?;

        info!("Loaded {} nodes (filtered), {} edges, {} metadata entries",
              nodes.len(), edges.len(), metadata.len());

        // Update cache
        {
            let mut node_cache = self.node_cache.write().await;
            for node in &nodes {
                node_cache.put(node.id, node.clone());
            }
        }

        {
            let mut edge_cache = self.edge_cache.write().await;
            for edge in &edges {
                edge_cache.put(edge.id.clone(), edge.clone());
            }
        }

        // Create snapshot
        let graph_data = Arc::new(GraphData {
            nodes,
            edges,
            metadata,
            id_to_metadata: HashMap::new(),
        });

        *self.graph_snapshot.write().await = Some(graph_data);
        *self.is_loaded.write().await = true;

        Ok(())
    }

    /// Load all nodes from Neo4j with optional quality/authority filtering
    async fn load_all_nodes_filtered(&self, filter: &NodeFilterSettings) -> Result<Vec<Node>> {
        // Build WHERE clause based on filter settings
        let where_clause = if filter.enabled {
            let mut conditions = Vec::new();

            if filter.filter_by_quality {
                conditions.push(format!(
                    "(n.quality_score IS NULL OR n.quality_score >= {})",
                    filter.quality_threshold
                ));
            }

            if filter.filter_by_authority {
                conditions.push(format!(
                    "(n.authority_score IS NULL OR n.authority_score >= {})",
                    filter.authority_threshold
                ));
            }

            if conditions.is_empty() {
                String::new()
            } else {
                let join_op = if filter.filter_mode == "and" { " AND " } else { " OR " };
                format!("WHERE {}", conditions.join(join_op))
            }
        } else {
            String::new()
        };

        // Use COALESCE to prefer sim_* (GPU physics state) over x/y/z (initial positions)
        // This preserves the calculated layout during content sync
        let query_str = format!("
            MATCH (n:GraphNode)
            {}
            RETURN n.id as id,
                   n.metadata_id as metadata_id,
                   n.label as label,
                   COALESCE(n.sim_x, n.x) as x,
                   COALESCE(n.sim_y, n.y) as y,
                   COALESCE(n.sim_z, n.z) as z,
                   n.vx as vx,
                   n.vy as vy,
                   n.vz as vz,
                   n.mass as mass,
                   n.size as size,
                   n.color as color,
                   n.weight as weight,
                   n.node_type as node_type,
                   n.cluster as cluster,
                   n.cluster_id as cluster_id,
                   n.anomaly_score as anomaly_score,
                   n.community_id as community_id,
                   n.hierarchy_level as hierarchy_level,
                   n.quality_score as quality_score,
                   n.authority_score as authority_score,
                   n.metadata as metadata_json
            ORDER BY id
        ", where_clause);

        info!("Executing node query with filter: {}", if filter.enabled { &where_clause } else { "disabled" });

        let mut result = self.graph
            .execute(query(&query_str))
            .await
            .map_err(|e| GraphRepositoryError::AccessError(format!("Failed to query nodes: {}", e)))?;

        let mut nodes = Vec::new();

        while let Some(row) = result.next().await
            .map_err(|e| GraphRepositoryError::AccessError(format!("Failed to fetch row: {}", e)))?
        {
            let id: BoltInteger = row.get("id")
                .map_err(|e| GraphRepositoryError::DeserializationError(format!("Missing id: {}", e)))?;

            let metadata_id: String = row.get("metadata_id").unwrap_or_default();
            let label: String = row.get("label").unwrap_or_default();

            // Position
            let x: BoltFloat = row.get("x").unwrap_or(BoltFloat { value: 0.0 });
            let y: BoltFloat = row.get("y").unwrap_or(BoltFloat { value: 0.0 });
            let z: BoltFloat = row.get("z").unwrap_or(BoltFloat { value: 0.0 });

            // Velocity
            let vx: BoltFloat = row.get("vx").unwrap_or(BoltFloat { value: 0.0 });
            let vy: BoltFloat = row.get("vy").unwrap_or(BoltFloat { value: 0.0 });
            let vz: BoltFloat = row.get("vz").unwrap_or(BoltFloat { value: 0.0 });

            // Properties
            let mass: BoltFloat = row.get("mass").unwrap_or(BoltFloat { value: 1.0 });
            let size: BoltFloat = row.get("size").unwrap_or(BoltFloat { value: 1.0 });
            let color: String = row.get("color").unwrap_or_else(|_| "#888888".to_string());
            let weight: BoltFloat = row.get("weight").unwrap_or(BoltFloat { value: 1.0 });
            let node_type: String = row.get("node_type").unwrap_or_else(|_| "default".to_string());
            let cluster: Option<i64> = row.get("cluster").ok();

            // Analytics fields (P0-4)
            let cluster_id: Option<BoltInteger> = row.get("cluster_id").ok();
            let anomaly_score: Option<BoltFloat> = row.get("anomaly_score").ok();
            let community_id: Option<BoltInteger> = row.get("community_id").ok();
            let hierarchy_level: Option<BoltInteger> = row.get("hierarchy_level").ok();

            // Quality/authority scores for filtering
            let quality_score: Option<BoltFloat> = row.get("quality_score").ok();
            let authority_score: Option<BoltFloat> = row.get("authority_score").ok();

            // Metadata JSON
            let metadata_json: String = row.get("metadata_json").unwrap_or_else(|_| "{}".to_string());
            let mut metadata: HashMap<String, String> = serde_json::from_str(&metadata_json)
                .unwrap_or_default();

            // Store analytics in metadata for now (Node struct doesn't have dedicated fields yet)
            if let Some(cid) = cluster_id {
                metadata.insert("cluster_id".to_string(), cid.value.to_string());
            }
            if let Some(score) = anomaly_score {
                metadata.insert("anomaly_score".to_string(), score.value.to_string());
            }
            if let Some(cid) = community_id {
                metadata.insert("community_id".to_string(), cid.value.to_string());
            }
            if let Some(level) = hierarchy_level {
                metadata.insert("hierarchy_level".to_string(), level.value.to_string());
            }
            // Store quality/authority scores in metadata
            if let Some(qs) = quality_score {
                metadata.insert("quality_score".to_string(), qs.value.to_string());
            }
            if let Some(as_score) = authority_score {
                metadata.insert("authority_score".to_string(), as_score.value.to_string());
            }

            let node = Node {
                id: id.value as u32,
                metadata_id,
                label,
                data: crate::utils::socket_flow_messages::BinaryNodeData {
                    node_id: id.value as u32,
                    x: x.value as f32,
                    y: y.value as f32,
                    z: z.value as f32,
                    vx: vx.value as f32,
                    vy: vy.value as f32,
                    vz: vz.value as f32,
                },
                x: Some(x.value as f32),
                y: Some(y.value as f32),
                z: Some(z.value as f32),
                vx: Some(vx.value as f32),
                vy: Some(vy.value as f32),
                vz: Some(vz.value as f32),
                mass: Some(mass.value as f32),
                size: Some(size.value as f32),
                color: Some(color),
                weight: Some(weight.value as f32),
                node_type: Some(node_type),
                group: cluster.map(|c| c.to_string()),
                metadata,
                owl_class_iri: None,
                file_size: 0,
                user_data: None,
            };

            nodes.push(node);
        }

        Ok(nodes)
    }

    /// Load all edges from Neo4j
    async fn load_all_edges(&self) -> Result<Vec<Edge>> {
        let query_str = "
            MATCH (source:GraphNode)-[r:EDGE]->(target:GraphNode)
            RETURN source.id as source_id,
                   target.id as target_id,
                   r.weight as weight,
                   r.edge_type as edge_type
        ";

        let mut result = self.graph
            .execute(query(query_str))
            .await
            .map_err(|e| GraphRepositoryError::AccessError(format!("Failed to query edges: {}", e)))?;

        let mut edges = Vec::new();

        while let Some(row) = result.next().await
            .map_err(|e| GraphRepositoryError::AccessError(format!("Failed to fetch row: {}", e)))?
        {
            let source_id: BoltInteger = row.get("source_id")
                .map_err(|e| GraphRepositoryError::DeserializationError(format!("Missing source_id: {}", e)))?;
            let target_id: BoltInteger = row.get("target_id")
                .map_err(|e| GraphRepositoryError::DeserializationError(format!("Missing target_id: {}", e)))?;

            let weight: BoltFloat = row.get("weight").unwrap_or(BoltFloat { value: 1.0 });
            let edge_type: String = row.get("edge_type").unwrap_or_else(|_| "default".to_string());

            let edge = Edge {
                id: format!("{}-{}", source_id.value, target_id.value),
                source: source_id.value as u32,
                target: target_id.value as u32,
                weight: weight.value as f32,
                edge_type: Some(edge_type),
                owl_property_iri: None,
                metadata: None,
            };

            edges.push(edge);
        }

        Ok(edges)
    }

    /// Load all metadata from Neo4j
    async fn load_all_metadata(&self) -> Result<HashMap<String, Metadata>> {
        // For now, extract from nodes
        // Could be separate MATCH query if metadata is stored separately
        Ok(HashMap::new())
    }

    /// Invalidate cache (call after mutations)
    pub async fn invalidate_cache(&self) {
        *self.is_loaded.write().await = false;
        *self.graph_snapshot.write().await = None;
        self.node_cache.write().await.clear();
        self.edge_cache.write().await.clear();
    }
}

#[async_trait]
impl GraphRepository for Neo4jGraphRepository {
    async fn add_nodes(&self, nodes: Vec<Node>) -> Result<Vec<u32>> {
        if nodes.is_empty() {
            return Ok(Vec::new());
        }

        // PERF: Use UNWIND for batch insert - 50-100x faster than sequential inserts
        // CRITICAL: Preserve physics state (sim_x/y/z, vx/vy/vz) during content sync
        // ON CREATE: Initialize all positions (content AND physics)
        // ON MATCH: Only update content properties, NEVER touch sim_* or velocity
        let query_str = "
            UNWIND range(0, size($ids)-1) AS i
            MERGE (n:GraphNode {id: $ids[i]})
            ON CREATE SET
                n.created_at = datetime(),
                n.metadata_id = $metadata_ids[i],
                n.label = $labels[i],
                n.x = $xs[i],
                n.y = $ys[i],
                n.z = $zs[i],
                n.sim_x = $xs[i],
                n.sim_y = $ys[i],
                n.sim_z = $zs[i],
                n.vx = $vxs[i],
                n.vy = $vys[i],
                n.vz = $vzs[i],
                n.mass = $masses[i],
                n.size = $sizes[i],
                n.color = $colors[i],
                n.weight = $weights[i],
                n.node_type = $node_types[i],
                n.quality_score = $quality_scores[i],
                n.authority_score = $authority_scores[i],
                n.metadata = $metadatas[i]
            ON MATCH SET
                n.updated_at = datetime(),
                n.metadata_id = $metadata_ids[i],
                n.label = $labels[i],
                n.mass = $masses[i],
                n.size = COALESCE($sizes[i], n.size),
                n.color = COALESCE($colors[i], n.color),
                n.weight = COALESCE($weights[i], n.weight),
                n.node_type = COALESCE($node_types[i], n.node_type),
                n.quality_score = $quality_scores[i],
                n.authority_score = $authority_scores[i],
                n.metadata = $metadatas[i]
            RETURN n.id AS id
        ";

        // Prepare parallel arrays for UNWIND (neo4rs native type support)
        let mut ids: Vec<i64> = Vec::with_capacity(nodes.len());
        let mut metadata_ids: Vec<String> = Vec::with_capacity(nodes.len());
        let mut labels: Vec<String> = Vec::with_capacity(nodes.len());
        let mut xs: Vec<f64> = Vec::with_capacity(nodes.len());
        let mut ys: Vec<f64> = Vec::with_capacity(nodes.len());
        let mut zs: Vec<f64> = Vec::with_capacity(nodes.len());
        let mut vxs: Vec<f64> = Vec::with_capacity(nodes.len());
        let mut vys: Vec<f64> = Vec::with_capacity(nodes.len());
        let mut vzs: Vec<f64> = Vec::with_capacity(nodes.len());
        let mut masses: Vec<f64> = Vec::with_capacity(nodes.len());
        let mut sizes: Vec<f64> = Vec::with_capacity(nodes.len());
        let mut colors: Vec<String> = Vec::with_capacity(nodes.len());
        let mut weights: Vec<f64> = Vec::with_capacity(nodes.len());
        let mut node_types: Vec<String> = Vec::with_capacity(nodes.len());
        let mut quality_scores: Vec<f64> = Vec::with_capacity(nodes.len());
        let mut authority_scores: Vec<f64> = Vec::with_capacity(nodes.len());
        let mut metadatas: Vec<String> = Vec::with_capacity(nodes.len());
        let mut added_ids = Vec::with_capacity(nodes.len());

        for node in &nodes {
            let metadata_json = serde_json::to_string(&node.metadata)
                .map_err(|e| GraphRepositoryError::SerializationError(format!("Failed to serialize metadata: {}", e)))?;

            let quality_score: f64 = node.metadata
                .get("quality_score")
                .and_then(|s| s.parse::<f64>().ok())
                .unwrap_or(1.0);

            let authority_score: f64 = node.metadata
                .get("authority_score")
                .and_then(|s| s.parse::<f64>().ok())
                .unwrap_or(1.0);

            ids.push(node.id as i64);
            metadata_ids.push(node.metadata_id.clone());
            labels.push(node.label.clone());
            xs.push(node.data.position().x as f64);
            ys.push(node.data.position().y as f64);
            zs.push(node.data.position().z as f64);
            vxs.push(node.data.velocity().x as f64);
            vys.push(node.data.velocity().y as f64);
            vzs.push(node.data.velocity().z as f64);
            masses.push(node.data.mass() as f64);
            sizes.push(node.size.unwrap_or(1.0) as f64);
            colors.push(node.color.clone().unwrap_or_else(|| "#888888".to_string()));
            weights.push(node.weight.unwrap_or(1.0) as f64);
            node_types.push(node.node_type.clone().unwrap_or_else(|| "default".to_string()));
            quality_scores.push(quality_score);
            authority_scores.push(authority_score);
            metadatas.push(metadata_json);
            added_ids.push(node.id);
        }

        // Execute single batch query with parallel arrays
        self.graph
            .run(query(query_str)
                .param("ids", ids)
                .param("metadata_ids", metadata_ids)
                .param("labels", labels)
                .param("xs", xs)
                .param("ys", ys)
                .param("zs", zs)
                .param("vxs", vxs)
                .param("vys", vys)
                .param("vzs", vzs)
                .param("masses", masses)
                .param("sizes", sizes)
                .param("colors", colors)
                .param("weights", weights)
                .param("node_types", node_types)
                .param("quality_scores", quality_scores)
                .param("authority_scores", authority_scores)
                .param("metadatas", metadatas))
            .await
            .map_err(|e| GraphRepositoryError::AccessError(format!("Failed to batch add nodes: {}", e)))?;

        // Update cache for all nodes
        {
            let mut cache = self.node_cache.write().await;
            for node in nodes {
                cache.put(node.id, node);
            }
        }

        // Invalidate full graph snapshot
        self.invalidate_cache().await;

        Ok(added_ids)
    }

    async fn add_edges(&self, edges: Vec<Edge>) -> Result<Vec<String>> {
        if edges.is_empty() {
            return Ok(Vec::new());
        }

        // PERF: Use UNWIND with parallel arrays - neo4rs native type support
        let query_str = "
            UNWIND range(0, size($edge_ids)-1) AS i
            MATCH (source:GraphNode {id: $source_ids[i]})
            MATCH (target:GraphNode {id: $target_ids[i]})
            MERGE (source)-[r:EDGE]->(target)
            ON CREATE SET r.created_at = datetime()
            ON MATCH SET r.updated_at = datetime()
            SET r.weight = $weights[i],
                r.edge_type = $edge_types[i],
                r.edge_id = $edge_ids[i]
            RETURN $edge_ids[i] AS id
        ";

        // Prepare parallel arrays for UNWIND (neo4rs native type support)
        let mut edge_ids: Vec<String> = Vec::with_capacity(edges.len());
        let mut source_ids: Vec<i64> = Vec::with_capacity(edges.len());
        let mut target_ids: Vec<i64> = Vec::with_capacity(edges.len());
        let mut weights: Vec<f64> = Vec::with_capacity(edges.len());
        let mut edge_types: Vec<String> = Vec::with_capacity(edges.len());
        let mut added_ids = Vec::with_capacity(edges.len());

        for edge in &edges {
            edge_ids.push(edge.id.clone());
            source_ids.push(edge.source as i64);
            target_ids.push(edge.target as i64);
            weights.push(edge.weight as f64);
            edge_types.push(edge.edge_type.clone().unwrap_or_else(|| "default".to_string()));
            added_ids.push(edge.id.clone());
        }

        // Execute single batch query with parallel arrays
        self.graph
            .run(query(query_str)
                .param("edge_ids", edge_ids)
                .param("source_ids", source_ids)
                .param("target_ids", target_ids)
                .param("weights", weights)
                .param("edge_types", edge_types))
            .await
            .map_err(|e| GraphRepositoryError::AccessError(format!("Failed to batch add edges: {}", e)))?;

        // Update cache for all edges
        {
            let mut cache = self.edge_cache.write().await;
            for edge in edges {
                cache.put(edge.id.clone(), edge);
            }
        }

        // Invalidate full graph snapshot
        self.invalidate_cache().await;

        Ok(added_ids)
    }

    async fn get_graph(&self) -> Result<Arc<GraphData>> {
        // Check if loaded
        if !*self.is_loaded.read().await {
            self.load_graph().await?;
        }

        // Return cached snapshot
        self.graph_snapshot.read().await
            .clone()
            .ok_or_else(|| GraphRepositoryError::AccessError("Graph not loaded".to_string()))
    }

    async fn get_node_map(&self) -> Result<Arc<HashMap<u32, Node>>> {
        let graph = self.get_graph().await?;
        let map: HashMap<u32, Node> = graph.nodes.iter()
            .map(|n| (n.id, n.clone()))
            .collect();
        Ok(Arc::new(map))
    }

    async fn get_physics_state(&self) -> Result<PhysicsState> {
        // Physics state would be managed separately by PhysicsActor
        Ok(PhysicsState::default())
    }

    async fn update_positions(
        &self,
        updates: Vec<(u32, crate::ports::graph_repository::BinaryNodeData)>,
    ) -> Result<()> {
        // Update sim_* properties (GPU physics state) and velocities
        // x/y/z remain as initial/content positions - NEVER overwritten by physics
        // BinaryNodeData format: (x, y, z, vx, vy, vz)
        for (node_id, data) in updates {
            let query_str = "
                MATCH (n:GraphNode {id: $id})
                SET n.sim_x = $x,
                    n.sim_y = $y,
                    n.sim_z = $z,
                    n.vx = $vx,
                    n.vy = $vy,
                    n.vz = $vz
            ";

            self.graph
                .run(query(query_str)
                    .param("id", node_id as i64)
                    .param("x", data.0 as f64)
                    .param("y", data.1 as f64)
                    .param("z", data.2 as f64)
                    .param("vx", data.3 as f64)
                    .param("vy", data.4 as f64)
                    .param("vz", data.5 as f64))
                .await
                .map_err(|e| GraphRepositoryError::AccessError(format!("Failed to update position/velocity: {}", e)))?;
        }

        Ok(())
    }

    async fn clear_dirty_nodes(&self) -> Result<()> {
        // Not applicable for Neo4j-backed repo
        Ok(())
    }

    // Implement remaining trait methods with Neo4j queries...
    async fn get_auto_balance_notifications(&self) -> Result<Vec<AutoBalanceNotification>> {
        Ok(Vec::new())
    }

    async fn get_constraints(&self) -> Result<ConstraintSet> {
        Ok(ConstraintSet::default())
    }

    async fn compute_shortest_paths(&self, _params: PathfindingParams) -> Result<PathfindingResult> {
        Err(GraphRepositoryError::NotImplemented)
    }

    async fn get_dirty_nodes(&self) -> Result<HashSet<u32>> {
        Ok(HashSet::new())
    }

    async fn get_node_positions(&self) -> Result<Vec<(u32, Vec3)>> {
        // The graph already uses sim_* positions via COALESCE in load query
        // So this returns GPU physics state when available
        let graph = self.get_graph().await?;
        let positions = graph.nodes.iter()
            .map(|n| (n.id, Vec3::new(
                n.x.unwrap_or(0.0),
                n.y.unwrap_or(0.0),
                n.z.unwrap_or(0.0)
            )))
            .collect();
        Ok(positions)
    }

    async fn get_bots_graph(&self) -> Result<Arc<GraphData>> {
        // For now, return the same graph
        // In the future, this could filter for bot nodes
        self.get_graph().await
    }

    async fn get_equilibrium_status(&self) -> Result<bool> {
        // This would check physics equilibrium state
        // For now, always return false (not in equilibrium)
        Ok(false)
    }
}

--------------------------------------------------------------------------------
FILE: src/adapters/neo4j_settings_repository.rs
PURPOSE: Neo4j implementation of SettingsRepository trait
--------------------------------------------------------------------------------
// src/adapters/neo4j_settings_repository.rs
//! Neo4j Settings Repository Adapter
//!
//! Implements the SettingsRepository port using Neo4j graph database with
//! category-based schema modeling, caching, and comprehensive error handling.
//!
//! ## Schema Design
//!
//! The settings are organized using a hierarchical node structure:
//! - `:SettingsRoot` - Root node (singleton, id: "default")
//! - Category nodes: `:PhysicsSettings`, `:RenderingSettings`, `:SystemSettings`, etc.
//! - Settings stored as properties on category nodes
//! - Relationships: `(:SettingsRoot)-[:HAS_PHYSICS_SETTINGS]->(:PhysicsSettings)`

use async_trait::async_trait;
use neo4rs::{Graph, query, ConfigBuilder};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use tracing::{debug, info, warn, instrument, error};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};

use crate::config::PhysicsSettings;
use crate::ports::settings_repository::{
    AppFullSettings, Result as RepoResult, SettingValue, SettingsRepository,
    SettingsRepositoryError,
};
use crate::utils::json::{from_json, to_json};
use crate::utils::neo4j_helpers::{json_to_bolt, string_ref_to_bolt};

/// User node - Nostr pubkey-based user identity
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct User {
    pub pubkey: String,
    pub is_power_user: bool,
    pub created_at: DateTime<Utc>,
    pub last_seen: DateTime<Utc>,
    pub display_name: Option<String>,
}

/// UserSettings node - user's personal settings (full AppFullSettings)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UserSettingsNode {
    pub pubkey: String,
    pub settings_json: String,
    pub updated_at: DateTime<Utc>,
}

/// UserFilter node - user's graph filter preferences
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UserFilter {
    pub pubkey: String,
    pub enabled: bool,
    pub quality_threshold: f64,
    pub authority_threshold: f64,
    pub filter_by_quality: bool,
    pub filter_by_authority: bool,
    pub filter_mode: String,
    pub max_nodes: Option<i32>,
    pub updated_at: DateTime<Utc>,
}

impl Default for UserFilter {
    fn default() -> Self {
        Self {
            pubkey: String::new(),
            enabled: true,
            quality_threshold: 0.7,
            authority_threshold: 0.5,
            filter_by_quality: true,
            filter_by_authority: false,
            filter_mode: "or".to_string(),
            max_nodes: Some(10000),
            updated_at: Utc::now(),
        }
    }
}

/// Neo4j configuration for settings repository
#[derive(Debug, Clone)]
pub struct Neo4jSettingsConfig {
    pub uri: String,
    pub user: String,
    pub password: String,
    pub database: Option<String>,
    pub fetch_size: usize,
    pub max_connections: usize,
}

impl Default for Neo4jSettingsConfig {
    fn default() -> Self {
        Self {
            uri: std::env::var("NEO4J_URI").unwrap_or_else(|_| "bolt://localhost:7687".to_string()),
            user: std::env::var("NEO4J_USER").unwrap_or_else(|_| "neo4j".to_string()),
            password: std::env::var("NEO4J_PASSWORD").unwrap_or_else(|_| "password".to_string()),
            database: std::env::var("NEO4J_DATABASE").ok(),
            fetch_size: 500,
            max_connections: 10,
        }
    }
}

/// Cache entry with TTL support
struct CachedSetting {
    value: SettingValue,
    timestamp: std::time::Instant,
}

/// Settings cache with TTL
struct SettingsCache {
    settings: HashMap<String, CachedSetting>,
    last_updated: std::time::Instant,
    ttl_seconds: u64,
}

impl SettingsCache {
    fn new(ttl_seconds: u64) -> Self {
        Self {
            settings: HashMap::new(),
            last_updated: std::time::Instant::now(),
            ttl_seconds,
        }
    }

    fn get(&self, key: &str) -> Option<SettingValue> {
        if let Some(cached) = self.settings.get(key) {
            if cached.timestamp.elapsed().as_secs() < self.ttl_seconds {
                return Some(cached.value.clone());
            }
        }
        None
    }

    fn insert(&mut self, key: String, value: SettingValue) {
        self.settings.insert(
            key,
            CachedSetting {
                value,
                timestamp: std::time::Instant::now(),
            },
        );
    }

    fn remove(&mut self, key: &str) {
        self.settings.remove(key);
    }

    fn clear(&mut self) {
        self.settings.clear();
        self.last_updated = std::time::Instant::now();
    }
}

/// Neo4j Settings Repository implementation
pub struct Neo4jSettingsRepository {
    graph: Arc<Graph>,
    cache: Arc<RwLock<SettingsCache>>,
    config: Neo4jSettingsConfig,
}

impl Neo4jSettingsRepository {
    /// Create a new Neo4j settings repository with configuration
    pub async fn new(config: Neo4jSettingsConfig) -> RepoResult<Self> {
        info!("Initializing Neo4jSettingsRepository with URI: {}", config.uri);

        // Build Neo4j configuration
        let mut builder = ConfigBuilder::default()
            .uri(&config.uri)
            .user(&config.user)
            .password(&config.password)
            .fetch_size(config.fetch_size)
            .max_connections(config.max_connections);

        if let Some(ref db) = config.database {
            builder = builder.db(neo4rs::Database::from(db.as_str()));
        }

        let neo4j_config = builder.build()
            .map_err(|e| SettingsRepositoryError::DatabaseError(
                format!("Failed to build Neo4j config: {}", e)
            ))?;

        // Connect to Neo4j
        let graph = Graph::connect(neo4j_config)
            .map_err(|e| SettingsRepositoryError::DatabaseError(
                format!("Failed to connect to Neo4j: {}", e)
            ))?;

        let repository = Self {
            graph: Arc::new(graph),
            cache: Arc::new(RwLock::new(SettingsCache::new(300))), // 5 min TTL
            config,
        };

        // Initialize schema
        repository.initialize_schema().await?;

        info!(" Neo4jSettingsRepository initialized successfully");
        Ok(repository)
    }

    /// Initialize the Neo4j schema for settings storage
    async fn initialize_schema(&self) -> RepoResult<()> {
        info!("Initializing Neo4j settings schema");

        // Create constraints for unique settings root
        let constraints = vec![
            "CREATE CONSTRAINT settings_root_id IF NOT EXISTS FOR (s:SettingsRoot) REQUIRE s.id IS UNIQUE",
            "CREATE CONSTRAINT user_pubkey_unique IF NOT EXISTS FOR (u:User) REQUIRE u.pubkey IS UNIQUE",
        ];

        for constraint_query in constraints {
            self.graph.run(query(constraint_query))
                .await
                .map_err(|e| SettingsRepositoryError::DatabaseError(
                    format!("Failed to create constraint: {}", e)
                ))?;
        }

        // Create indices for performance
        let indices = vec![
            "CREATE INDEX settings_key_idx IF NOT EXISTS FOR (s:Setting) ON (s.key)",
            "CREATE INDEX physics_profile_idx IF NOT EXISTS FOR (p:PhysicsProfile) ON (p.name)",
            "CREATE INDEX user_settings_pubkey_idx IF NOT EXISTS FOR (us:UserSettings) ON (us.pubkey)",
            "CREATE INDEX user_filter_pubkey_idx IF NOT EXISTS FOR (uf:UserFilter) ON (uf.pubkey)",
        ];

        for index_query in indices {
            self.graph.run(query(index_query))
                .await
                .map_err(|e| SettingsRepositoryError::DatabaseError(
                    format!("Failed to create index: {}", e)
                ))?;
        }

        // Create root settings node if it doesn't exist
        let init_query = query(
            "MERGE (s:SettingsRoot {id: 'default'})
             ON CREATE SET s.created_at = datetime(), s.version = '1.0.0'
             RETURN s"
        );

        self.graph.run(init_query)
            .await
            .map_err(|e| SettingsRepositoryError::DatabaseError(
                format!("Failed to initialize settings root: {}", e)
            ))?;

        info!(" Neo4j settings schema initialized with user support");
        Ok(())
    }

    /// Get setting from cache
    async fn get_from_cache(&self, key: &str) -> Option<SettingValue> {
        let cache = self.cache.read().await;
        if let Some(value) = cache.get(key) {
            debug!("Cache hit for setting: {}", key);
            return Some(value);
        }
        None
    }

    /// Update cache
    async fn update_cache(&self, key: String, value: SettingValue) {
        let mut cache = self.cache.write().await;
        cache.insert(key, value);
    }

    /// Invalidate cache entry
    async fn invalidate_cache(&self, key: &str) {
        let mut cache = self.cache.write().await;
        cache.remove(key);
    }

    /// Clear entire cache
    async fn clear_cache_internal(&self) -> RepoResult<()> {
        let mut cache = self.cache.write().await;
        cache.clear();
        Ok(())
    }

    /// Convert SettingValue to Cypher parameter value
    fn setting_value_to_param(&self, value: &SettingValue) -> serde_json::Value {
        match value {
            SettingValue::String(s) => serde_json::json!({"type": "string", "value": s}),
            SettingValue::Integer(i) => serde_json::json!({"type": "integer", "value": i}),
            SettingValue::Float(f) => serde_json::json!({"type": "float", "value": f}),
            SettingValue::Boolean(b) => serde_json::json!({"type": "boolean", "value": b}),
            SettingValue::Json(j) => serde_json::json!({"type": "json", "value": to_json(j).unwrap_or_default()}),
        }
    }

    /// Parse setting value from Neo4j result
    fn parse_setting_value(&self, value_type: &str, value: &serde_json::Value) -> Option<SettingValue> {
        match value_type {
            "string" => value.as_str().map(|s| SettingValue::String(s.to_string())),
            "integer" => value.as_i64().map(SettingValue::Integer),
            "float" => value.as_f64().map(SettingValue::Float),
            "boolean" => value.as_bool().map(SettingValue::Boolean),
            "json" => {
                if let Some(json_str) = value.as_str() {
                    from_json(json_str).ok().map(SettingValue::Json)
                } else {
                    Some(SettingValue::Json(value.clone()))
                }
            }
            _ => None,
        }
    }

    /// Get or create a user node
    #[instrument(skip(self), level = "debug")]
    pub async fn get_or_create_user(&self, pubkey: &str) -> RepoResult<User> {
        let query_str =
            "MERGE (u:User {pubkey: $pubkey})
             ON CREATE SET
                u.is_power_user = false,
                u.created_at = datetime(),
                u.last_seen = datetime()
             ON MATCH SET
                u.last_seen = datetime()
             RETURN u.pubkey AS pubkey, u.is_power_user AS is_power_user,
                    u.created_at AS created_at, u.last_seen AS last_seen,
                    u.display_name AS display_name";

        let mut result = self.graph.execute(
            query(query_str).param("pubkey", pubkey)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to get or create user: {}", e)
        ))?;

        if let Some(row) = result.next().await.map_err(|e|
            SettingsRepositoryError::DatabaseError(format!("Failed to fetch user row: {}", e))
        )? {
            let pubkey: String = row.get("pubkey").map_err(|e|
                SettingsRepositoryError::DatabaseError(format!("Failed to get pubkey: {}", e))
            )?;

            let is_power_user: bool = row.get("is_power_user").unwrap_or(false);
            let display_name: Option<String> = row.get("display_name").ok();

            Ok(User {
                pubkey,
                is_power_user,
                created_at: Utc::now(),
                last_seen: Utc::now(),
                display_name,
            })
        } else {
            Err(SettingsRepositoryError::DatabaseError(
                "Failed to create or retrieve user".to_string()
            ))
        }
    }

    /// Update user's last seen timestamp
    #[instrument(skip(self), level = "debug")]
    pub async fn update_user_last_seen(&self, pubkey: &str) -> RepoResult<()> {
        let query_str =
            "MATCH (u:User {pubkey: $pubkey})
             SET u.last_seen = datetime()
             RETURN u";

        self.graph.run(
            query(query_str).param("pubkey", pubkey)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to update user last seen: {}", e)
        ))?;

        Ok(())
    }

    /// Get user settings (full AppFullSettings)
    #[instrument(skip(self), level = "debug")]
    pub async fn get_user_settings(&self, pubkey: &str) -> RepoResult<Option<AppFullSettings>> {
        let query_str =
            "MATCH (u:User {pubkey: $pubkey})-[:HAS_SETTINGS]->(us:UserSettings)
             RETURN us.settings_json AS settings_json";

        let mut result = self.graph.execute(
            query(query_str).param("pubkey", pubkey)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to query user settings: {}", e)
        ))?;

        if let Some(row) = result.next().await.map_err(|e|
            SettingsRepositoryError::DatabaseError(format!("Failed to fetch settings row: {}", e))
        )? {
            let settings_json: String = row.get("settings_json").map_err(|e|
                SettingsRepositoryError::DatabaseError(format!("Failed to get settings_json: {}", e))
            )?;

            let settings: AppFullSettings = from_json(&settings_json)
                .map_err(|e| SettingsRepositoryError::SerializationError(e.to_string()))?;

            return Ok(Some(settings));
        }

        Ok(None)
    }

    /// Save user settings (full AppFullSettings)
    #[instrument(skip(self, settings), level = "debug")]
    pub async fn save_user_settings(&self, pubkey: &str, settings: &AppFullSettings) -> RepoResult<()> {
        let settings_json = to_json(settings)
            .map_err(|e| SettingsRepositoryError::SerializationError(e.to_string()))?;

        let query_str =
            "MATCH (u:User {pubkey: $pubkey})
             MERGE (u)-[:HAS_SETTINGS]->(us:UserSettings {pubkey: $pubkey})
             ON CREATE SET
                us.settings_json = $settings_json,
                us.updated_at = datetime()
             ON MATCH SET
                us.settings_json = $settings_json,
                us.updated_at = datetime()
             RETURN us";

        self.graph.run(
            query(query_str)
                .param("pubkey", pubkey)
                .param("settings_json", settings_json)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to save user settings: {}", e)
        ))?;

        info!("Saved user settings for pubkey: {}", pubkey);
        Ok(())
    }

    /// Get user's filter settings
    #[instrument(skip(self), level = "debug")]
    pub async fn get_user_filter(&self, pubkey: &str) -> RepoResult<Option<UserFilter>> {
        let query_str =
            "MATCH (u:User {pubkey: $pubkey})-[:HAS_FILTER]->(uf:UserFilter)
             RETURN uf.enabled AS enabled, uf.quality_threshold AS quality_threshold,
                    uf.authority_threshold AS authority_threshold, uf.filter_by_quality AS filter_by_quality,
                    uf.filter_by_authority AS filter_by_authority, uf.filter_mode AS filter_mode,
                    uf.max_nodes AS max_nodes";

        let mut result = self.graph.execute(
            query(query_str).param("pubkey", pubkey)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to query user filter: {}", e)
        ))?;

        if let Some(row) = result.next().await.map_err(|e|
            SettingsRepositoryError::DatabaseError(format!("Failed to fetch filter row: {}", e))
        )? {
            let filter = UserFilter {
                pubkey: pubkey.to_string(),
                enabled: row.get("enabled").unwrap_or(true),
                quality_threshold: row.get("quality_threshold").unwrap_or(0.7),
                authority_threshold: row.get("authority_threshold").unwrap_or(0.5),
                filter_by_quality: row.get("filter_by_quality").unwrap_or(true),
                filter_by_authority: row.get("filter_by_authority").unwrap_or(false),
                filter_mode: row.get("filter_mode").unwrap_or_else(|_| "or".to_string()),
                max_nodes: row.get("max_nodes").ok(),
                updated_at: Utc::now(),
            };

            return Ok(Some(filter));
        }

        Ok(None)
    }

    /// Save user's filter settings
    #[instrument(skip(self, filter), level = "debug")]
    pub async fn save_user_filter(&self, pubkey: &str, filter: &UserFilter) -> RepoResult<()> {
        let query_str =
            "MATCH (u:User {pubkey: $pubkey})
             MERGE (u)-[:HAS_FILTER]->(uf:UserFilter {pubkey: $pubkey})
             ON CREATE SET
                uf.enabled = $enabled,
                uf.quality_threshold = $quality_threshold,
                uf.authority_threshold = $authority_threshold,
                uf.filter_by_quality = $filter_by_quality,
                uf.filter_by_authority = $filter_by_authority,
                uf.filter_mode = $filter_mode,
                uf.max_nodes = $max_nodes,
                uf.updated_at = datetime()
             ON MATCH SET
                uf.enabled = $enabled,
                uf.quality_threshold = $quality_threshold,
                uf.authority_threshold = $authority_threshold,
                uf.filter_by_quality = $filter_by_quality,
                uf.filter_by_authority = $filter_by_authority,
                uf.filter_mode = $filter_mode,
                uf.max_nodes = $max_nodes,
                uf.updated_at = datetime()
             RETURN uf";

        self.graph.run(
            query(query_str)
                .param("pubkey", pubkey)
                .param("enabled", filter.enabled)
                .param("quality_threshold", filter.quality_threshold)
                .param("authority_threshold", filter.authority_threshold)
                .param("filter_by_quality", filter.filter_by_quality)
                .param("filter_by_authority", filter.filter_by_authority)
                .param("filter_mode", filter.filter_mode.as_str())
                .param("max_nodes", filter.max_nodes.unwrap_or(10000))
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to save user filter: {}", e)
        ))?;

        info!("Saved user filter for pubkey: {}", pubkey);
        Ok(())
    }

    /// Check if user is a power user
    #[instrument(skip(self), level = "debug")]
    pub async fn is_power_user(&self, pubkey: &str) -> RepoResult<bool> {
        let query_str =
            "MATCH (u:User {pubkey: $pubkey})
             RETURN u.is_power_user AS is_power_user";

        let mut result = self.graph.execute(
            query(query_str).param("pubkey", pubkey)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to query power user status: {}", e)
        ))?;

        if let Some(row) = result.next().await.map_err(|e|
            SettingsRepositoryError::DatabaseError(format!("Failed to fetch power user row: {}", e))
        )? {
            return Ok(row.get("is_power_user").unwrap_or(false));
        }

        Ok(false)
    }

    /// Set user as power user (or revoke)
    #[instrument(skip(self), level = "debug")]
    pub async fn set_power_user(&self, pubkey: &str, is_power: bool) -> RepoResult<()> {
        let query_str =
            "MATCH (u:User {pubkey: $pubkey})
             SET u.is_power_user = $is_power
             RETURN u";

        self.graph.run(
            query(query_str)
                .param("pubkey", pubkey)
                .param("is_power", is_power)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to set power user status: {}", e)
        ))?;

        info!("Set power user status for pubkey {}: {}", pubkey, is_power);
        Ok(())
    }
}

#[async_trait]
impl SettingsRepository for Neo4jSettingsRepository {
    #[instrument(skip(self), level = "debug")]
    async fn get_setting(&self, key: &str) -> RepoResult<Option<SettingValue>> {
        // Check cache first
        if let Some(cached_value) = self.get_from_cache(key).await {
            return Ok(Some(cached_value));
        }

        // Query Neo4j
        let query_str =
            "MATCH (s:Setting {key: $key})
             RETURN s.value_type AS value_type, s.value AS value";

        let mut result = self.graph.execute(
            query(query_str).param("key", key)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to query setting: {}", e)
        ))?;

        if let Some(row) = result.next().await.map_err(|e|
            SettingsRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
        )? {
            let value_type: String = row.get("value_type").map_err(|e|
                SettingsRepositoryError::DatabaseError(format!("Failed to get value_type: {}", e))
            )?;

            let value: serde_json::Value = row.get("value").map_err(|e|
                SettingsRepositoryError::DatabaseError(format!("Failed to get value: {}", e))
            )?;

            if let Some(setting_value) = self.parse_setting_value(&value_type, &value) {
                // Update cache
                self.update_cache(key.to_string(), setting_value.clone()).await;
                return Ok(Some(setting_value));
            }
        }

        Ok(None)
    }

    #[instrument(skip(self, value), level = "debug")]
    async fn set_setting(
        &self,
        key: &str,
        value: SettingValue,
        description: Option<&str>,
    ) -> RepoResult<()> {
        let value_param = self.setting_value_to_param(&value);
        let value_type = value_param["type"].as_str().unwrap_or("unknown");
        let value_data = &value_param["value"];

        let query_str =
            "MERGE (s:Setting {key: $key})
             ON CREATE SET
                s.created_at = datetime(),
                s.value_type = $value_type,
                s.value = $value,
                s.description = $description
             ON MATCH SET
                s.updated_at = datetime(),
                s.value_type = $value_type,
                s.value = $value,
                s.description = COALESCE($description, s.description)
             RETURN s";

        self.graph.run(
            query(query_str)
                .param("key", key)
                .param("value_type", value_type)
                .param("value", json_to_bolt(value_data.clone()))
                .param("description", description.unwrap_or(""))
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to set setting: {}", e)
        ))?;

        // Invalidate cache
        self.invalidate_cache(key).await;

        Ok(())
    }

    async fn get_settings_batch(
        &self,
        keys: &[String],
    ) -> RepoResult<HashMap<String, SettingValue>> {
        let mut results = HashMap::new();

        // Try to get from cache first
        for key in keys {
            if let Some(value) = self.get_from_cache(key).await {
                results.insert(key.clone(), value);
            }
        }

        // Get remaining keys from database
        let remaining_keys: Vec<String> = keys.iter()
            .filter(|k| !results.contains_key(*k))
            .cloned()
            .collect();

        if !remaining_keys.is_empty() {
            let query_str =
                "MATCH (s:Setting)
                 WHERE s.key IN $keys
                 RETURN s.key AS key, s.value_type AS value_type, s.value AS value";

            let mut result = self.graph.execute(
                query(query_str).param("keys", remaining_keys)
            ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
                format!("Failed to query batch settings: {}", e)
            ))?;

            while let Some(row) = result.next().await.map_err(|e|
                SettingsRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
            )? {
                let key: String = row.get("key").unwrap_or_default();
                let value_type: String = row.get("value_type").unwrap_or_default();
                let value: serde_json::Value = row.get("value").unwrap_or_default();

                if let Some(setting_value) = self.parse_setting_value(&value_type, &value) {
                    self.update_cache(key.clone(), setting_value.clone()).await;
                    results.insert(key, setting_value);
                }
            }
        }

        Ok(results)
    }

    async fn set_settings_batch(&self, updates: HashMap<String, SettingValue>) -> RepoResult<()> {
        // Use transaction for batch updates
        let mut txn = self.graph.start_txn().await.map_err(|e|
            SettingsRepositoryError::DatabaseError(format!("Failed to start transaction: {}", e))
        )?;

        for (key, value) in &updates {
            let value_param = self.setting_value_to_param(value);
            let value_type = value_param["type"].as_str().unwrap_or("unknown");
            let value_data = &value_param["value"];

            let query_str =
                "MERGE (s:Setting {key: $key})
                 ON CREATE SET
                    s.created_at = datetime(),
                    s.value_type = $value_type,
                    s.value = $value
                 ON MATCH SET
                    s.updated_at = datetime(),
                    s.value_type = $value_type,
                    s.value = $value";

            txn.run_queries(vec![
                query(query_str)
                    .param("key", key.as_str())
                    .param("value_type", value_type)
                    .param("value", json_to_bolt(value_data.clone()))
            ]).await.map_err(|e| SettingsRepositoryError::DatabaseError(
                format!("Failed to execute batch update: {}", e)
            ))?;
        }

        txn.commit().await.map_err(|e|
            SettingsRepositoryError::DatabaseError(format!("Failed to commit transaction: {}", e))
        )?;

        // Clear cache after batch update
        self.clear_cache_internal().await?;

        Ok(())
    }

    #[instrument(skip(self), level = "debug")]
    async fn load_all_settings(&self) -> RepoResult<Option<AppFullSettings>> {
        // For now, return default settings
        // In a full implementation, this would reconstruct AppFullSettings from Neo4j
        info!("Loading all settings from Neo4j (returning defaults for now)");

        Ok(Some(AppFullSettings {
            visualisation: Default::default(),
            system: Default::default(),
            xr: Default::default(),
            auth: Default::default(),
            ragflow: None,
            perplexity: None,
            openai: None,
            kokoro: None,
            whisper: None,
            version: "1.0.0".to_string(),
            user_preferences: Default::default(),
            physics: Default::default(),
            feature_flags: Default::default(),
            developer_config: Default::default(),
        }))
    }

    #[instrument(skip(self, settings), level = "debug")]
    async fn save_all_settings(&self, settings: &AppFullSettings) -> RepoResult<()> {
        info!("Saving all settings to Neo4j");

        // Serialize settings to JSON
        let settings_json = serde_json::to_value(settings)
            .map_err(|e| SettingsRepositoryError::SerializationError(e.to_string()))?;

        // Store as JSON on root node for now
        let query_str =
            "MERGE (s:SettingsRoot {id: 'default'})
             SET s.full_settings = $settings,
                 s.updated_at = datetime(),
                 s.version = $version
             RETURN s";

        self.graph.run(
            query(query_str)
                .param("settings", to_json(&settings_json).unwrap_or_default())
                .param("version", settings.version.as_str())
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to save all settings: {}", e)
        ))?;

        // Clear cache
        self.clear_cache_internal().await?;

        Ok(())
    }

    #[instrument(skip(self), level = "debug")]
    async fn get_physics_settings(&self, profile_name: &str) -> RepoResult<PhysicsSettings> {
        let query_str =
            "MATCH (p:PhysicsProfile {name: $profile_name})
             RETURN p.settings AS settings";

        let mut result = self.graph.execute(
            query(query_str).param("profile_name", profile_name)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to query physics settings: {}", e)
        ))?;

        if let Some(row) = result.next().await.map_err(|e|
            SettingsRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
        )? {
            let settings_json: String = row.get("settings").unwrap_or_default();
            let settings: PhysicsSettings = from_json(&settings_json)
                .map_err(|e| SettingsRepositoryError::SerializationError(e.to_string()))?;
            return Ok(settings);
        }

        // Return default if not found
        Ok(PhysicsSettings::default())
    }

    #[instrument(skip(self, settings), level = "debug")]
    async fn save_physics_settings(
        &self,
        profile_name: &str,
        settings: &PhysicsSettings,
    ) -> RepoResult<()> {
        let settings_json = to_json(settings)
            .map_err(|e| SettingsRepositoryError::SerializationError(e.to_string()))?;

        let query_str =
            "MERGE (p:PhysicsProfile {name: $profile_name})
             ON CREATE SET
                p.created_at = datetime(),
                p.settings = $settings
             ON MATCH SET
                p.updated_at = datetime(),
                p.settings = $settings
             RETURN p";

        self.graph.run(
            query(query_str)
                .param("profile_name", profile_name)
                .param("settings", settings_json)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to save physics settings: {}", e)
        ))?;

        Ok(())
    }

    async fn delete_setting(&self, key: &str) -> RepoResult<()> {
        let query_str = "MATCH (s:Setting {key: $key}) DELETE s";

        self.graph.run(
            query(query_str).param("key", key)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to delete setting: {}", e)
        ))?;

        self.invalidate_cache(key).await;
        Ok(())
    }

    async fn has_setting(&self, key: &str) -> RepoResult<bool> {
        Ok(self.get_setting(key).await?.is_some())
    }

    async fn list_settings(&self, prefix: Option<&str>) -> RepoResult<Vec<String>> {
        let query_str = if let Some(p) = prefix {
            "MATCH (s:Setting) WHERE s.key STARTS WITH $prefix RETURN s.key AS key ORDER BY s.key"
        } else {
            "MATCH (s:Setting) RETURN s.key AS key ORDER BY s.key"
        };

        let mut query_obj = query(query_str);
        if let Some(p) = prefix {
            query_obj = query_obj.param("prefix", p);
        }

        let mut result = self.graph.execute(query_obj)
            .await.map_err(|e| SettingsRepositoryError::DatabaseError(
                format!("Failed to list settings: {}", e)
            ))?;

        let mut keys = Vec::new();
        while let Some(row) = result.next().await.map_err(|e|
            SettingsRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
        )? {
            if let Ok(key) = row.get::<String>("key") {
                keys.push(key);
            }
        }

        Ok(keys)
    }

    async fn list_physics_profiles(&self) -> RepoResult<Vec<String>> {
        let query_str = "MATCH (p:PhysicsProfile) RETURN p.name AS name ORDER BY p.name";

        let mut result = self.graph.execute(query(query_str))
            .await.map_err(|e| SettingsRepositoryError::DatabaseError(
                format!("Failed to list physics profiles: {}", e)
            ))?;

        let mut profiles = Vec::new();
        while let Some(row) = result.next().await.map_err(|e|
            SettingsRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
        )? {
            if let Ok(name) = row.get::<String>("name") {
                profiles.push(name);
            }
        }

        Ok(profiles)
    }

    async fn delete_physics_profile(&self, profile_name: &str) -> RepoResult<()> {
        let query_str = "MATCH (p:PhysicsProfile {name: $name}) DELETE p";

        self.graph.run(
            query(query_str).param("name", profile_name)
        ).await.map_err(|e| SettingsRepositoryError::DatabaseError(
            format!("Failed to delete physics profile: {}", e)
        ))?;

        Ok(())
    }

    async fn export_settings(&self) -> RepoResult<serde_json::Value> {
        let query_str =
            "MATCH (s:Setting)
             RETURN s.key AS key, s.value_type AS value_type, s.value AS value, s.description AS description";

        let mut result = self.graph.execute(query(query_str))
            .await.map_err(|e| SettingsRepositoryError::DatabaseError(
                format!("Failed to export settings: {}", e)
            ))?;

        let mut settings = serde_json::Map::new();
        while let Some(row) = result.next().await.map_err(|e|
            SettingsRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
        )? {
            let key: String = row.get("key").unwrap_or_default();
            let value_type: String = row.get("value_type").unwrap_or_default();
            let value: serde_json::Value = row.get("value").unwrap_or_default();
            let description: String = row.get("description").unwrap_or_default();

            settings.insert(key, serde_json::json!({
                "type": value_type,
                "value": value,
                "description": description
            }));
        }

        Ok(serde_json::Value::Object(settings))
    }

    async fn import_settings(&self, settings_json: &serde_json::Value) -> RepoResult<()> {
        if let Some(settings_map) = settings_json.as_object() {
            let mut updates = HashMap::new();

            for (key, value_obj) in settings_map {
                if let Some(obj) = value_obj.as_object() {
                    let value_type = obj.get("type").and_then(|v| v.as_str()).unwrap_or("string");
                    let value = obj.get("value").cloned().unwrap_or(serde_json::Value::Null);

                    if let Some(setting_value) = self.parse_setting_value(value_type, &value) {
                        updates.insert(key.clone(), setting_value);
                    }
                }
            }

            self.set_settings_batch(updates).await?;
        }

        Ok(())
    }

    async fn clear_cache(&self) -> RepoResult<()> {
        self.clear_cache_internal().await
    }

    async fn health_check(&self) -> RepoResult<bool> {
        let query_str = "RETURN 1 AS health";

        self.graph.run(query(query_str))
            .await
            .map_err(|e| SettingsRepositoryError::DatabaseError(
                format!("Health check failed: {}", e)
            ))?;

        Ok(true)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    #[ignore] // Requires Neo4j instance
    async fn test_neo4j_settings_repository() {
        let config = Neo4jSettingsConfig::default();
        let repo = Neo4jSettingsRepository::new(config).await.unwrap();

        // Test set and get
        repo.set_setting("test.key", SettingValue::String("test_value".to_string()), Some("Test setting"))
            .await.unwrap();

        let value = repo.get_setting("test.key").await.unwrap();
        assert_eq!(value, Some(SettingValue::String("test_value".to_string())));

        // Test delete
        repo.delete_setting("test.key").await.unwrap();
        let value = repo.get_setting("test.key").await.unwrap();
        assert_eq!(value, None);

        // Test health check
        assert!(repo.health_check().await.unwrap());
    }

    #[tokio::test]
    #[ignore] // Requires Neo4j instance
    async fn test_user_management() {
        let config = Neo4jSettingsConfig::default();
        let repo = Neo4jSettingsRepository::new(config).await.unwrap();
        let test_pubkey = "test_pubkey_12345";

        // Test get or create user
        let user = repo.get_or_create_user(test_pubkey).await.unwrap();
        assert_eq!(user.pubkey, test_pubkey);
        assert!(!user.is_power_user);

        // Test set power user
        repo.set_power_user(test_pubkey, true).await.unwrap();
        assert!(repo.is_power_user(test_pubkey).await.unwrap());

        // Test update last seen
        repo.update_user_last_seen(test_pubkey).await.unwrap();
    }

    #[tokio::test]
    #[ignore] // Requires Neo4j instance
    async fn test_user_settings() {
        let config = Neo4jSettingsConfig::default();
        let repo = Neo4jSettingsRepository::new(config).await.unwrap();
        let test_pubkey = "test_pubkey_settings";

        // Create user first
        repo.get_or_create_user(test_pubkey).await.unwrap();

        // Test save and get user settings
        let settings = AppFullSettings::default();
        repo.save_user_settings(test_pubkey, &settings).await.unwrap();

        let loaded_settings = repo.get_user_settings(test_pubkey).await.unwrap();
        assert!(loaded_settings.is_some());
    }

    #[tokio::test]
    #[ignore] // Requires Neo4j instance
    async fn test_user_filter() {
        let config = Neo4jSettingsConfig::default();
        let repo = Neo4jSettingsRepository::new(config).await.unwrap();
        let test_pubkey = "test_pubkey_filter";

        // Create user first
        repo.get_or_create_user(test_pubkey).await.unwrap();

        // Test save and get user filter
        let mut filter = UserFilter::default();
        filter.pubkey = test_pubkey.to_string();
        filter.quality_threshold = 0.8;
        filter.max_nodes = Some(5000);

        repo.save_user_filter(test_pubkey, &filter).await.unwrap();

        let loaded_filter = repo.get_user_filter(test_pubkey).await.unwrap();
        assert!(loaded_filter.is_some());
        let loaded = loaded_filter.unwrap();
        assert_eq!(loaded.quality_threshold, 0.8);
        assert_eq!(loaded.max_nodes, Some(5000));
    }
}

--------------------------------------------------------------------------------
FILE: src/adapters/neo4j_ontology_repository.rs
PURPOSE: Neo4j implementation of OntologyRepository trait with 24+ indexes
--------------------------------------------------------------------------------
// src/adapters/neo4j_ontology_repository.rs
//! Neo4j Ontology Repository Adapter
//!
//! Implements OntologyRepository trait using Neo4j graph database.
//! Stores OWL classes, properties, axioms, and hierarchies in Neo4j.
//!
//! This replaces UnifiedOntologyRepository (SQLite-based) as part of the
//! SQL deprecation effort. See ADR-001 for architectural decision rationale.

use async_trait::async_trait;
use neo4rs::{Graph, query, Node as Neo4jNode};
use std::collections::HashMap;
use std::sync::Arc;
use tracing::{debug, info, warn, instrument, error};

use crate::models::edge::Edge;
use crate::models::graph::GraphData;
use crate::models::node::Node;
use crate::ports::ontology_repository::{
    AxiomType, InferenceResults, OntologyMetrics, OntologyRepository,
    OntologyRepositoryError, OwlAxiom, OwlClass, OwlProperty,
    PathfindingCacheEntry, PropertyType, Result as RepoResult,
    ValidationReport,
};
use crate::utils::json::{to_json, from_json};

/// Neo4j configuration for ontology repository
#[derive(Debug, Clone)]
pub struct Neo4jOntologyConfig {
    pub uri: String,
    pub user: String,
    pub password: String,
    pub database: Option<String>,
}

impl Default for Neo4jOntologyConfig {
    fn default() -> Self {
        Self {
            uri: std::env::var("NEO4J_URI")
                .unwrap_or_else(|_| "bolt://localhost:7687".to_string()),
            user: std::env::var("NEO4J_USER")
                .unwrap_or_else(|_| "neo4j".to_string()),
            password: std::env::var("NEO4J_PASSWORD")
                .unwrap_or_else(|_| "password".to_string()),
            database: std::env::var("NEO4J_DATABASE").ok(),
        }
    }
}

/// Repository for OWL ontology data in Neo4j
///
/// Provides full OntologyRepository implementation with:
/// - OWL class storage and hierarchy
/// - OWL property management
/// - OWL axiom storage (including inferred axioms)
/// - Ontology metrics and validation
/// - Pathfinding cache
pub struct Neo4jOntologyRepository {
    graph: Arc<Graph>,
    config: Neo4jOntologyConfig,
}

impl Neo4jOntologyRepository {
    /// Create a new Neo4jOntologyRepository
    ///
    /// # Arguments
    /// * `config` - Neo4j connection configuration
    ///
    /// # Returns
    /// Initialized repository with schema created
    pub async fn new(config: Neo4jOntologyConfig) -> RepoResult<Self> {
        let graph = Graph::new(&config.uri, &config.user, &config.password)
            .map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!(
                    "Failed to connect to Neo4j: {}",
                    e
                ))
            })?;

        info!("Connected to Neo4j ontology database at {}", config.uri);

        let repo = Self {
            graph: Arc::new(graph),
            config,
        };

        // Create schema
        repo.create_schema().await?;

        Ok(repo)
    }

    /// Create Neo4j schema (constraints and indexes) - Schema V2
    ///
    /// Creates 24+ indexes matching the SQLite schema for optimal query performance
    async fn create_schema(&self) -> RepoResult<()> {
        info!("Creating Neo4j ontology schema V2 with rich metadata indexes...");

        let queries = vec![
            // OWL Class constraints and core indexes
            "CREATE CONSTRAINT owl_class_iri IF NOT EXISTS FOR (c:OwlClass) REQUIRE c.iri IS UNIQUE",
            "CREATE INDEX owl_class_label IF NOT EXISTS FOR (c:OwlClass) ON (c.label)",
            "CREATE INDEX owl_class_ontology_id IF NOT EXISTS FOR (c:OwlClass) ON (c.ontology_id)",

            // Schema V2: Core identification indexes
            "CREATE INDEX owl_class_term_id IF NOT EXISTS FOR (c:OwlClass) ON (c.term_id)",
            "CREATE INDEX owl_class_preferred_term IF NOT EXISTS FOR (c:OwlClass) ON (c.preferred_term)",

            // Schema V2: Classification indexes
            "CREATE INDEX owl_class_source_domain IF NOT EXISTS FOR (c:OwlClass) ON (c.source_domain)",
            "CREATE INDEX owl_class_version IF NOT EXISTS FOR (c:OwlClass) ON (c.version)",
            "CREATE INDEX owl_class_type IF NOT EXISTS FOR (c:OwlClass) ON (c.class_type)",

            // Schema V2: Quality metrics indexes (critical for filtering)
            "CREATE INDEX owl_class_status IF NOT EXISTS FOR (c:OwlClass) ON (c.status)",
            "CREATE INDEX owl_class_maturity IF NOT EXISTS FOR (c:OwlClass) ON (c.maturity)",
            "CREATE INDEX owl_class_quality_score IF NOT EXISTS FOR (c:OwlClass) ON (c.quality_score)",
            "CREATE INDEX owl_class_authority_score IF NOT EXISTS FOR (c:OwlClass) ON (c.authority_score)",
            "CREATE INDEX owl_class_content_status IF NOT EXISTS FOR (c:OwlClass) ON (c.content_status)",

            // Schema V2: OWL2 property indexes
            "CREATE INDEX owl_class_physicality IF NOT EXISTS FOR (c:OwlClass) ON (c.owl_physicality)",
            "CREATE INDEX owl_class_role IF NOT EXISTS FOR (c:OwlClass) ON (c.owl_role)",

            // Schema V2: Domain relationship indexes
            "CREATE INDEX owl_class_belongs_to_domain IF NOT EXISTS FOR (c:OwlClass) ON (c.belongs_to_domain)",
            "CREATE INDEX owl_class_bridges_to_domain IF NOT EXISTS FOR (c:OwlClass) ON (c.bridges_to_domain)",

            // Schema V2: Source tracking indexes
            "CREATE INDEX owl_class_file_sha1 IF NOT EXISTS FOR (c:OwlClass) ON (c.file_sha1)",
            "CREATE INDEX owl_class_source_file IF NOT EXISTS FOR (c:OwlClass) ON (c.source_file)",

            // OWL Property constraints and indexes
            "CREATE CONSTRAINT owl_property_iri IF NOT EXISTS FOR (p:OwlProperty) REQUIRE p.iri IS UNIQUE",
            "CREATE INDEX owl_property_label IF NOT EXISTS FOR (p:OwlProperty) ON (p.label)",
            "CREATE INDEX owl_property_type IF NOT EXISTS FOR (p:OwlProperty) ON (p.property_type)",
            "CREATE INDEX owl_property_quality_score IF NOT EXISTS FOR (p:OwlProperty) ON (p.quality_score)",
            "CREATE INDEX owl_property_authority_score IF NOT EXISTS FOR (p:OwlProperty) ON (p.authority_score)",

            // OWL Axiom constraints and indexes
            "CREATE CONSTRAINT owl_axiom_id IF NOT EXISTS FOR (a:OwlAxiom) REQUIRE a.id IS UNIQUE",
            "CREATE INDEX owl_axiom_type IF NOT EXISTS FOR (a:OwlAxiom) ON (a.axiom_type)",
            "CREATE INDEX owl_axiom_inferred IF NOT EXISTS FOR (a:OwlAxiom) ON (a.is_inferred)",
            "CREATE INDEX owl_axiom_subject IF NOT EXISTS FOR (a:OwlAxiom) ON (a.subject)",
            "CREATE INDEX owl_axiom_object IF NOT EXISTS FOR (a:OwlAxiom) ON (a.object)",

            // Schema V2: Relationship indexes
            "CREATE INDEX owl_rel_type IF NOT EXISTS FOR ()-[r:RELATES]-() ON (r.relationship_type)",
            "CREATE INDEX owl_rel_confidence IF NOT EXISTS FOR ()-[r:RELATES]-() ON (r.confidence)",
            "CREATE INDEX owl_rel_inferred IF NOT EXISTS FOR ()-[r:RELATES]-() ON (r.is_inferred)",
        ];

        let query_count = queries.len();

        for query_str in queries {
            if let Err(e) = self.graph.run(query(query_str)).await {
                warn!("Failed to create schema element (may already exist): {}", e);
            }
        }

        info!(" Neo4j ontology schema V2 created with {} indexes", query_count);
        Ok(())
    }

    /// Convert Neo4j node to OwlClass with rich metadata (Schema V2)
    fn node_to_owl_class(&self, node: Neo4jNode) -> RepoResult<OwlClass> {
        let iri: String = node.get("iri")
            .map_err(|_| OntologyRepositoryError::DeserializationError(
                "Missing iri field".to_string()
            ))?;

        // Core identification
        let term_id: Option<String> = node.get("term_id").ok();
        let preferred_term: Option<String> = node.get("preferred_term").ok();

        // Basic metadata
        let label: Option<String> = node.get("label").ok();
        let description: Option<String> = node.get("description").ok();

        // Classification metadata
        let source_domain: Option<String> = node.get("source_domain").ok();
        let version: Option<String> = node.get("version").ok();
        let class_type: Option<String> = node.get("class_type").ok();

        // Quality metrics
        let status: Option<String> = node.get("status").ok();
        let maturity: Option<String> = node.get("maturity").ok();
        let quality_score: Option<f64> = node.get("quality_score").ok();
        let authority_score: Option<f64> = node.get("authority_score").ok();
        let public_access: Option<bool> = node.get("public_access").ok();
        let content_status: Option<String> = node.get("content_status").ok();

        // OWL2 properties
        let owl_physicality: Option<String> = node.get("owl_physicality").ok();
        let owl_role: Option<String> = node.get("owl_role").ok();

        // Domain relationships
        let belongs_to_domain: Option<String> = node.get("belongs_to_domain").ok();
        let bridges_to_domain: Option<String> = node.get("bridges_to_domain").ok();

        // Source tracking
        let source_file: Option<String> = node.get("source_file").ok();
        let file_sha1: Option<String> = node.get("file_sha1").ok();
        let markdown_content: Option<String> = node.get("markdown_content").ok();
        let last_synced: Option<chrono::DateTime<chrono::Utc>> = node.get("last_synced").ok();

        // Additional metadata
        let additional_metadata: Option<String> = node.get("additional_metadata").ok();

        Ok(OwlClass {
            iri,
            term_id,
            preferred_term,
            label,
            description,
            parent_classes: Vec::new(), // Fetched separately via relationships
            source_domain,
            version,
            class_type,
            status,
            maturity,
            quality_score: quality_score.map(|s| s as f32),
            authority_score: authority_score.map(|s| s as f32),
            public_access,
            content_status,
            owl_physicality,
            owl_role,
            belongs_to_domain,
            bridges_to_domain,
            source_file,
            file_sha1,
            markdown_content,
            last_synced,
            properties: std::collections::HashMap::new(),
            additional_metadata,
        })
    }
}

#[async_trait]
impl OntologyRepository for Neo4jOntologyRepository {
    // ============================================================
    // OWL Class Methods
    // ============================================================

    #[instrument(skip(self))]
    async fn add_owl_class(&self, class: &OwlClass) -> RepoResult<String> {
        debug!("Storing OWL class with rich metadata: {}", class.iri);

        let query_str = "
            MERGE (c:OwlClass {iri: $iri})
            ON CREATE SET
                c.created_at = datetime(),
                c.term_id = $term_id,
                c.preferred_term = $preferred_term,
                c.label = $label,
                c.description = $description,
                c.source_domain = $source_domain,
                c.version = $version,
                c.class_type = $class_type,
                c.status = $status,
                c.maturity = $maturity,
                c.quality_score = $quality_score,
                c.authority_score = $authority_score,
                c.public_access = $public_access,
                c.content_status = $content_status,
                c.owl_physicality = $owl_physicality,
                c.owl_role = $owl_role,
                c.belongs_to_domain = $belongs_to_domain,
                c.bridges_to_domain = $bridges_to_domain,
                c.source_file = $source_file,
                c.file_sha1 = $file_sha1,
                c.markdown_content = $markdown_content,
                c.last_synced = $last_synced,
                c.additional_metadata = $additional_metadata
            ON MATCH SET
                c.updated_at = datetime(),
                c.term_id = $term_id,
                c.preferred_term = $preferred_term,
                c.label = $label,
                c.description = $description,
                c.source_domain = $source_domain,
                c.version = $version,
                c.class_type = $class_type,
                c.status = $status,
                c.maturity = $maturity,
                c.quality_score = $quality_score,
                c.authority_score = $authority_score,
                c.public_access = $public_access,
                c.content_status = $content_status,
                c.owl_physicality = $owl_physicality,
                c.owl_role = $owl_role,
                c.belongs_to_domain = $belongs_to_domain,
                c.bridges_to_domain = $bridges_to_domain,
                c.source_file = $source_file,
                c.file_sha1 = $file_sha1,
                c.markdown_content = $markdown_content,
                c.last_synced = $last_synced,
                c.additional_metadata = $additional_metadata
        ";

        self.graph
            .run(query(query_str)
                .param("iri", class.iri.clone())
                .param("term_id", class.term_id.clone().unwrap_or_default())
                .param("preferred_term", class.preferred_term.clone().unwrap_or_default())
                .param("label", class.label.clone().unwrap_or_default())
                .param("description", class.description.clone().unwrap_or_default())
                .param("source_domain", class.source_domain.clone().unwrap_or_default())
                .param("version", class.version.clone().unwrap_or_default())
                .param("class_type", class.class_type.clone().unwrap_or_default())
                .param("status", class.status.clone().unwrap_or_default())
                .param("maturity", class.maturity.clone().unwrap_or_default())
                .param("quality_score", class.quality_score.map(|s| s as f64).unwrap_or(0.0))
                .param("authority_score", class.authority_score.map(|s| s as f64).unwrap_or(0.0))
                .param("public_access", class.public_access.unwrap_or(false))
                .param("content_status", class.content_status.clone().unwrap_or_default())
                .param("owl_physicality", class.owl_physicality.clone().unwrap_or_default())
                .param("owl_role", class.owl_role.clone().unwrap_or_default())
                .param("belongs_to_domain", class.belongs_to_domain.clone().unwrap_or_default())
                .param("bridges_to_domain", class.bridges_to_domain.clone().unwrap_or_default())
                .param("source_file", class.source_file.clone().unwrap_or_default())
                .param("file_sha1", class.file_sha1.clone().unwrap_or_default())
                .param("markdown_content", class.markdown_content.clone().unwrap_or_default())
                .param("last_synced", class.last_synced.map(|dt| dt.to_rfc3339()).unwrap_or_default())
                .param("additional_metadata", class.additional_metadata.clone().unwrap_or_default()))
            .await
            .map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!(
                    "Failed to store OWL class: {}",
                    e
                ))
            })?;

        // Store parent relationships
        for parent_iri in &class.parent_classes {
            let rel_query = "
                MATCH (c:OwlClass {iri: $child_iri})
                MERGE (p:OwlClass {iri: $parent_iri})
                MERGE (c)-[:SUBCLASS_OF]->(p)
            ";

            self.graph
                .run(query(rel_query)
                    .param("child_iri", class.iri.clone())
                    .param("parent_iri", parent_iri.clone()))
                .await
                .map_err(|e| {
                    OntologyRepositoryError::DatabaseError(format!(
                        "Failed to store parent relationship: {}",
                        e
                    ))
                })?;
        }

        Ok(class.iri.clone())
    }

    #[instrument(skip(self))]
    async fn get_owl_class(&self, iri: &str) -> RepoResult<Option<OwlClass>> {
        debug!("Fetching OWL class: {}", iri);

        let query_str = "
            MATCH (c:OwlClass {iri: $iri})
            OPTIONAL MATCH (c)-[:SUBCLASS_OF]->(p:OwlClass)
            RETURN c, collect(p.iri) as parent_iris
        ";

        let mut result = self.graph
            .execute(query(query_str).param("iri", iri.to_string()))
            .await
            .map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!(
                    "Failed to get OWL class: {}",
                    e
                ))
            })?;

        if let Some(row) = result.next().await.map_err(|e| {
            OntologyRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
        })? {
            let node: Neo4jNode = row.get("c")
                .map_err(|_| OntologyRepositoryError::DeserializationError(
                    "Missing node in result".to_string()
                ))?;

            let mut owl_class = self.node_to_owl_class(node)?;

            // Get parent IRIs
            let parent_iris: Vec<String> = row.get("parent_iris")
                .unwrap_or_else(|_| Vec::new());
            owl_class.parent_classes = parent_iris;

            Ok(Some(owl_class))
        } else {
            Ok(None)
        }
    }

    #[instrument(skip(self))]
    async fn list_owl_classes(&self) -> RepoResult<Vec<OwlClass>> {
        debug!("Listing OWL classes");

        let query_str = "
            MATCH (c:OwlClass)
            OPTIONAL MATCH (c)-[:SUBCLASS_OF]->(p:OwlClass)
            RETURN c, collect(p.iri) as parent_iris
            ";

        let query_obj = query(query_str);

        let mut result = self.graph
            .execute(query_obj)
            .await
            .map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!(
                    "Failed to list OWL classes: {}",
                    e
                ))
            })?;

        let mut classes = Vec::new();
        while let Some(row) = result.next().await.map_err(|e| {
            OntologyRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
        })? {
            let node: Neo4jNode = row.get("c").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get node: {}", e))
            })?;
            let mut owl_class = self.node_to_owl_class(node)?;

            let parent_iris: Vec<String> = row.get("parent_iris")
                .unwrap_or_else(|_| Vec::new());
            owl_class.parent_classes = parent_iris;

            classes.push(owl_class);
        }

        debug!("Found {} OWL classes", classes.len());
        Ok(classes)
    }

    // ============================================================
    // OWL Property Methods
    // ============================================================

    #[instrument(skip(self))]
    async fn add_owl_property(&self, property: &OwlProperty) -> RepoResult<String> {
        debug!("Storing OWL property with quality metrics: {}", property.iri);

        let query_str = "
            MERGE (p:OwlProperty {iri: $iri})
            ON CREATE SET
                p.created_at = datetime(),
                p.label = $label,
                p.property_type = $property_type,
                p.domain = $domain,
                p.range = $range,
                p.quality_score = $quality_score,
                p.authority_score = $authority_score,
                p.source_file = $source_file
            ON MATCH SET
                p.updated_at = datetime(),
                p.label = $label,
                p.property_type = $property_type,
                p.domain = $domain,
                p.range = $range,
                p.quality_score = $quality_score,
                p.authority_score = $authority_score,
                p.source_file = $source_file
        ";

        let domain_json = to_json(&property.domain)
            .map_err(|e| OntologyRepositoryError::SerializationError(e.to_string()))?;
        let range_json = to_json(&property.range)
            .map_err(|e| OntologyRepositoryError::SerializationError(e.to_string()))?;

        self.graph
            .run(query(query_str)
                .param("iri", property.iri.clone())
                .param("label", property.label.clone().unwrap_or_default())
                .param("property_type", format!("{:?}", property.property_type))
                .param("domain", domain_json)
                .param("range", range_json)
                .param("quality_score", property.quality_score.map(|s| s as f64).unwrap_or(0.0))
                .param("authority_score", property.authority_score.map(|s| s as f64).unwrap_or(0.0))
                .param("source_file", property.source_file.clone().unwrap_or_default()))
            .await
            .map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!(
                    "Failed to store OWL property: {}",
                    e
                ))
            })?;

        Ok(property.iri.clone())
    }

    #[instrument(skip(self))]
    async fn get_owl_property(&self, iri: &str) -> RepoResult<Option<OwlProperty>> {
        debug!("Fetching OWL property: {}", iri);

        let query_str = "
            MATCH (p:OwlProperty {iri: $iri})
            RETURN p
        ";

        let mut result = self.graph
            .execute(query(query_str).param("iri", iri.to_string()))
            .await
            .map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!(
                    "Failed to get OWL property: {}",
                    e
                ))
            })?;

        if let Some(row) = result.next().await.map_err(|e| {
            OntologyRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
        })? {
            let node: Neo4jNode = row.get("p").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get node: {}", e))
            })?;

            let iri: String = node.get("iri").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get iri: {}", e))
            })?;
            let label: Option<String> = node.get("label").ok();
            let property_type_str: String = node.get("property_type").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get property_type: {}", e))
            })?;
            let domain_json: String = node.get("domain").unwrap_or_else(|_| "[]".to_string());
            let range_json: String = node.get("range").unwrap_or_else(|_| "[]".to_string());

            // Schema V2: Quality metrics
            let quality_score: Option<f64> = node.get("quality_score").ok();
            let authority_score: Option<f64> = node.get("authority_score").ok();
            let source_file: Option<String> = node.get("source_file").ok();

            let property_type = match property_type_str.as_str() {
                "ObjectProperty" => PropertyType::ObjectProperty,
                "DataProperty" => PropertyType::DataProperty,
                "AnnotationProperty" => PropertyType::AnnotationProperty,
                _ => PropertyType::ObjectProperty,
            };

            let domain: Vec<String> = from_json(&domain_json)
                .map_err(|e| OntologyRepositoryError::DeserializationError(e.to_string()))?;
            let range: Vec<String> = from_json(&range_json)
                .map_err(|e| OntologyRepositoryError::DeserializationError(e.to_string()))?;

            Ok(Some(OwlProperty {
                iri,
                label,
                property_type,
                domain,
                range,
                quality_score: quality_score.map(|s| s as f32),
                authority_score: authority_score.map(|s| s as f32),
                source_file,
            }))
        } else {
            Ok(None)
        }
    }

    #[instrument(skip(self))]
    async fn list_owl_properties(&self) -> RepoResult<Vec<OwlProperty>> {
        debug!("Listing all OWL properties");

        let query_str = "MATCH (p:OwlProperty) RETURN p";

        let mut result = self.graph
            .execute(query(query_str))
            .await
            .map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!(
                    "Failed to list OWL properties: {}",
                    e
                ))
            })?;

        let mut properties = Vec::new();
        while let Some(row) = result.next().await.map_err(|e| {
            OntologyRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
        })? {
            let node: Neo4jNode = row.get("p").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get node: {}", e))
            })?;

            let iri: String = node.get("iri").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get iri: {}", e))
            })?;
            let label: Option<String> = node.get("label").ok();
            let property_type_str: String = node.get("property_type").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get property_type: {}", e))
            })?;
            let domain_json: String = node.get("domain").unwrap_or_else(|_| "[]".to_string());
            let range_json: String = node.get("range").unwrap_or_else(|_| "[]".to_string());

            // Schema V2: Quality metrics
            let quality_score: Option<f64> = node.get("quality_score").ok();
            let authority_score: Option<f64> = node.get("authority_score").ok();
            let source_file: Option<String> = node.get("source_file").ok();

            let property_type = match property_type_str.as_str() {
                "ObjectProperty" => PropertyType::ObjectProperty,
                "DataProperty" => PropertyType::DataProperty,
                "AnnotationProperty" => PropertyType::AnnotationProperty,
                _ => PropertyType::ObjectProperty,
            };

            let domain: Vec<String> = from_json(&domain_json)
                .map_err(|e| OntologyRepositoryError::DeserializationError(e.to_string()))?;
            let range: Vec<String> = from_json(&range_json)
                .map_err(|e| OntologyRepositoryError::DeserializationError(e.to_string()))?;

            properties.push(OwlProperty {
                iri,
                label,
                property_type,
                domain,
                range,
                quality_score: quality_score.map(|s| s as f32),
                authority_score: authority_score.map(|s| s as f32),
                source_file,
            });
        }

        debug!("Found {} OWL properties", properties.len());
        Ok(properties)
    }

    // ============================================================
    // OWL Axiom Methods
    // ============================================================

    #[instrument(skip(self))]
    async fn add_axiom(&self, axiom: &OwlAxiom) -> RepoResult<u64> {
        debug!("Storing OWL axiom: {:?}", axiom.id);

        let annotations_json = to_json(&axiom.annotations)
            .map_err(|e| OntologyRepositoryError::SerializationError(e.to_string()))?;

        let axiom_id = axiom.id.unwrap_or_else(|| {
            std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .map(|d| d.as_millis() as u64)
                .unwrap_or(0)
        });

        let query_str = "
            MERGE (a:OwlAxiom {id: $id})
            ON CREATE SET
                a.created_at = datetime(),
                a.axiom_type = $axiom_type,
                a.subject = $subject,
                a.object = $object,
                a.annotations = $annotations
            ON MATCH SET
                a.updated_at = datetime(),
                a.axiom_type = $axiom_type,
                a.subject = $subject,
                a.object = $object,
                a.annotations = $annotations
        ";

        self.graph
            .run(query(query_str)
                .param("id", axiom_id as i64)
                .param("axiom_type", format!("{:?}", axiom.axiom_type))
                .param("subject", axiom.subject.clone())
                .param("object", axiom.object.clone())
                .param("annotations", annotations_json))
            .await
            .map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!(
                    "Failed to store OWL axiom: {}",
                    e
                ))
            })?;

        Ok(axiom_id)
    }

    #[instrument(skip(self))]
    async fn get_axioms(&self) -> RepoResult<Vec<OwlAxiom>> {
        debug!("Fetching all OWL axioms");

        let query_str = "MATCH (a:OwlAxiom) RETURN a";
        let query_obj = query(query_str);

        let mut result = self.graph
            .execute(query_obj)
            .await
            .map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!(
                    "Failed to get OWL axioms: {}",
                    e
                ))
            })?;

        let mut axioms = Vec::new();
        while let Some(row) = result.next().await.map_err(|e| {
            OntologyRepositoryError::DatabaseError(format!("Failed to fetch row: {}", e))
        })? {
            let node: Neo4jNode = row.get("a").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get node: {}", e))
            })?;

            let id: i64 = node.get("id").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get id: {}", e))
            })?;
            let axiom_type_str: String = node.get("axiom_type").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get axiom_type: {}", e))
            })?;
            let subject: String = node.get("subject").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get subject: {}", e))
            })?;
            let object: String = node.get("object").map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!("Failed to get object: {}", e))
            })?;
            let annotations_json: String = node.get("annotations").unwrap_or_else(|_| "{}".to_string());

            let axiom_type = match axiom_type_str.as_str() {
                "SubClassOf" => AxiomType::SubClassOf,
                "EquivalentClass" => AxiomType::EquivalentClass,
                "DisjointWith" => AxiomType::DisjointWith,
                "ObjectPropertyAssertion" => AxiomType::ObjectPropertyAssertion,
                "DataPropertyAssertion" => AxiomType::DataPropertyAssertion,
                _ => AxiomType::SubClassOf,
            };

            let annotations: HashMap<String, String> = from_json(&annotations_json)
                .map_err(|e| OntologyRepositoryError::DeserializationError(e.to_string()))?;

            axioms.push(OwlAxiom {
                id: Some(id as u64),
                axiom_type,
                subject,
                object,
                annotations,
            });
        }

        debug!("Found {} OWL axioms", axioms.len());
        Ok(axioms)
    }

    // ============================================================
    // Inference Methods
    // ============================================================

    #[instrument(skip(self, results))]
    async fn store_inference_results(&self, results: &InferenceResults) -> RepoResult<()> {
        info!("Storing {} inferred axioms", results.inferred_axioms.len());

        for axiom in &results.inferred_axioms {
            self.add_axiom(axiom).await?;
        }

        Ok(())
    }

    // ============================================================
    // Metrics and Validation
    // ============================================================

    #[instrument(skip(self))]
    async fn get_metrics(&self) -> RepoResult<OntologyMetrics> {
        debug!("Computing ontology metrics");

        // Count classes
        let class_count_query = query("MATCH (c:OwlClass) RETURN count(c) as count");

        let mut result = self.graph.execute(class_count_query).await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let class_count: i64 = if let Some(row) = result.next().await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))? {
            row.get("count").unwrap_or(0)
        } else {
            0
        };

        // Count properties
        let property_count_query = query("MATCH (p:OwlProperty) RETURN count(p) as count");
        let mut result = self.graph.execute(property_count_query).await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let property_count: i64 = if let Some(row) = result.next().await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))? {
            row.get("count").unwrap_or(0)
        } else {
            0
        };

        // Count axioms
        let axiom_count_query = query("MATCH (a:OwlAxiom) RETURN count(a) as count");
        let mut result = self.graph.execute(axiom_count_query).await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let axiom_count: i64 = if let Some(row) = result.next().await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))? {
            row.get("count").unwrap_or(0)
        } else {
            0
        };

        // Calculate max depth by finding longest path in class hierarchy
        let depth_query = query("
            MATCH path = (root:OwlClass)-[:SUBCLASS_OF*]->(leaf:OwlClass)
            WHERE NOT (root)-[:SUBCLASS_OF]->()
            RETURN length(path) as depth
            ORDER BY depth DESC
            LIMIT 1
        ");
        let mut result = self.graph.execute(depth_query).await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let max_depth: usize = if let Some(row) = result.next().await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))? {
            row.get::<i64>("depth").unwrap_or(0) as usize
        } else {
            0
        };

        // Calculate average branching factor: avg number of direct subclasses
        let branching_query = query("
            MATCH (parent:OwlClass)<-[:SUBCLASS_OF]-(child:OwlClass)
            WITH parent, count(child) as children
            RETURN avg(children) as avg_branching
        ");
        let mut result = self.graph.execute(branching_query).await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let average_branching_factor: f32 = if let Some(row) = result.next().await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))? {
            row.get::<f64>("avg_branching").unwrap_or(0.0) as f32
        } else {
            0.0
        };

        Ok(OntologyMetrics {
            class_count: class_count as usize,
            property_count: property_count as usize,
            axiom_count: axiom_count as usize,
            max_depth,
            average_branching_factor,
        })
    }

    #[instrument(skip(self))]
    async fn validate_ontology(&self) -> RepoResult<ValidationReport> {
        debug!("Validating ontology");

        let mut errors = Vec::new();
        let mut warnings = Vec::new();

        // Check for orphaned classes (no relationships)
        let orphan_query = query("
            MATCH (c:OwlClass)
            WHERE NOT (c)-[:SUBCLASS_OF]->() AND NOT ()-[:SUBCLASS_OF]->(c)
            RETURN count(c) as count
        ");

        let mut result = self.graph.execute(orphan_query).await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        if let Some(row) = result.next().await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))? {
            let orphan_count: i64 = row.get("count").unwrap_or(0);
            if orphan_count > 0 {
                warnings.push(format!("{} orphaned classes found (no hierarchy relationships)", orphan_count));
            }
        }

        let is_valid = errors.is_empty();

        Ok(ValidationReport {
            is_valid,
            errors,
            warnings,
            timestamp: chrono::Utc::now(),
        })
    }

    #[instrument(skip(self))]
    async fn cache_sssp_result(&self, _entry: &PathfindingCacheEntry) -> RepoResult<()> {
        // Pathfinding cache not yet implemented
        // When implementing, consider:
        // - Storage: In-memory (DashMap) vs Neo4j nodes with :PathCache label
        // - TTL: Time-to-live for cache entries (e.g., 1 hour)
        // - Eviction: LRU or size-based eviction policy
        // - Invalidation: Automatic on graph topology changes
        // Current: No-op, pathfinding recomputed on each query
        Ok(())
    }

    #[instrument(skip(self))]
    async fn get_cached_sssp(&self, _source_node_id: u32) -> RepoResult<Option<PathfindingCacheEntry>> {
        // Pathfinding cache not yet implemented
        // Returns None, forcing recomputation
        Ok(None)
    }

    #[instrument(skip(self))]
    async fn cache_apsp_result(&self, _distance_matrix: &Vec<Vec<f32>>) -> RepoResult<()> {
        // APSP (All-Pairs Shortest Path) cache not yet implemented
        // Note: APSP results can be very large (O(n) space)
        // Consider sparse matrix representation or only cache frequently accessed pairs
        Ok(())
    }

    #[instrument(skip(self))]
    async fn get_cached_apsp(&self) -> RepoResult<Option<Vec<Vec<f32>>>> {
        // APSP cache not yet implemented
        // Returns None, forcing recomputation
        Ok(None)
    }

    #[instrument(skip(self))]
    async fn invalidate_pathfinding_caches(&self) -> RepoResult<()> {
        info!("Clearing pathfinding cache (no-op, cache not implemented)");
        // When cache is implemented, this should:
        // 1. Clear all in-memory cache entries
        // 2. Delete all Neo4j :PathCache nodes
        // 3. Reset any cache statistics
        Ok(())
    }

    #[instrument(skip(self))]
    async fn load_ontology_graph(&self) -> RepoResult<Arc<GraphData>> {
        debug!("Loading ontology graph from Neo4j");

        // Query all nodes
        let nodes_query = query("MATCH (n) RETURN n, id(n) as neo4j_id");
        let mut result = self.graph.execute(nodes_query).await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let mut nodes = Vec::new();
        while let Ok(Some(row)) = result.next().await {
            if let Ok(neo4j_node) = row.get::<Neo4jNode>("n") {
                if let Ok(neo4j_id) = row.get::<i64>("neo4j_id") {
                    // Convert Neo4j node to our Node type
                    let label = neo4j_node.get::<String>("label").unwrap_or_default();
                    let node = Node::new_with_id(label, Some(neo4j_id as u32));
                    nodes.push(node);
                }
            }
        }

        // Query all edges
        let edges_query = query("MATCH (n)-[r]->(m) RETURN id(n) as source, id(m) as target, type(r) as rel_type");
        let mut result = self.graph.execute(edges_query).await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let mut edges = Vec::new();
        while let Ok(Some(row)) = result.next().await {
            if let (Ok(source), Ok(target), Ok(rel_type)) = (
                row.get::<i64>("source"),
                row.get::<i64>("target"),
                row.get::<String>("rel_type"),
            ) {
                let edge = Edge::new(source as u32, target as u32, 1.0)
                    .with_edge_type(rel_type);
                edges.push(edge);
            }
        }

        Ok(Arc::new(GraphData {
            nodes,
            edges,
            metadata: Default::default(),
            id_to_metadata: HashMap::new(),
        }))
    }

    #[instrument(skip(self, graph))]
    async fn save_ontology_graph(&self, graph: &GraphData) -> RepoResult<()> {
        debug!("Saving ontology graph to Neo4j");

        // Clear existing graph
        let clear_query = query("MATCH (n) DETACH DELETE n");
        self.graph.execute(clear_query).await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        // Insert nodes
        for node in &graph.nodes {
            let node_query = query("CREATE (n {id: $id, label: $label})")
                .param("id", node.id as i64)
                .param("label", node.label.clone());
            self.graph.execute(node_query).await
                .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;
        }

        // Insert edges
        for edge in &graph.edges {
            let rel_type = edge.edge_type.clone().unwrap_or_else(|| "RELATES".to_string());
            let edge_query = query(
                "MATCH (n {id: $source}), (m {id: $target}) \
                 CREATE (n)-[r:RELATES {relationship: $rel_type}]->(m)"
            )
            .param("source", edge.source as i64)
            .param("target", edge.target as i64)
            .param("rel_type", rel_type);

            self.graph.execute(edge_query).await
                .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;
        }

        Ok(())
    }

    #[instrument(skip(self, classes, properties, axioms))]
    async fn save_ontology(
        &self,
        classes: &[OwlClass],
        properties: &[OwlProperty],
        axioms: &[OwlAxiom],
    ) -> RepoResult<()> {
        debug!("Saving ontology: {} classes, {} properties, {} axioms",
               classes.len(), properties.len(), axioms.len());

        // Save classes
        for class in classes {
            self.add_owl_class(class).await?;
        }

        // Save properties
        for property in properties {
            self.add_owl_property(property).await?;
        }

        // Save axioms
        for axiom in axioms {
            self.add_axiom(axiom).await?;
        }

        Ok(())
    }

    #[instrument(skip(self))]
    async fn get_classes(&self) -> RepoResult<Vec<OwlClass>> {
        self.list_owl_classes().await
    }

    #[instrument(skip(self))]
    async fn get_class_axioms(&self, class_iri: &str) -> RepoResult<Vec<OwlAxiom>> {
        debug!("Getting axioms for class: {}", class_iri);

        let query_str = query(
            "MATCH (c:OwlClass {iri: $iri})-[:HAS_AXIOM]->(a:Axiom) \
             RETURN a.axiom_type as axiom_type, \
                    a.subject as subject, \
                    a.predicate as predicate, \
                    a.object as object, \
                    a.axiom_json as axiom_json"
        ).param("iri", class_iri);

        let mut result = self.graph.execute(query_str).await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let mut axioms = Vec::new();
        while let Ok(Some(row)) = result.next().await {
            if let (Ok(axiom_type_str), Ok(subject), Ok(predicate), Ok(object)) = (
                row.get::<String>("axiom_type"),
                row.get::<String>("subject"),
                row.get::<String>("predicate"),
                row.get::<String>("object"),
            ) {
                let axiom_type = match axiom_type_str.as_str() {
                    "SubClassOf" => AxiomType::SubClassOf,
                    "EquivalentClass" | "EquivalentClasses" => AxiomType::EquivalentClass,
                    "DisjointWith" | "DisjointClasses" => AxiomType::DisjointWith,
                    "ObjectPropertyAssertion" | "SubObjectProperty" => AxiomType::ObjectPropertyAssertion,
                    "DataPropertyAssertion" | "Domain" | "Range" => AxiomType::DataPropertyAssertion,
                    _ => AxiomType::SubClassOf,
                };

                let axiom = OwlAxiom {
                    id: None,
                    axiom_type,
                    subject,
                    object,
                    annotations: HashMap::new(),
                };
                axioms.push(axiom);
            }
        }

        Ok(axioms)
    }
}

// ============================================================
// Extended Query Methods for Rich Metadata (Schema V2)
// ============================================================

impl Neo4jOntologyRepository {
    /// Query classes by quality score threshold
    ///
    /// Returns classes with quality_score >= min_score, ordered by combined score
    pub async fn query_by_quality(&self, min_score: f32) -> RepoResult<Vec<OwlClass>> {
        debug!("Querying classes with quality_score >= {}", min_score);

        let query_str = "
            MATCH (c:OwlClass)
            WHERE c.quality_score >= $min_score
            WITH c, (COALESCE(c.quality_score, 0.0) * COALESCE(c.authority_score, 0.0)) as combined_score
            RETURN c
            ORDER BY combined_score DESC
        ";

        let mut result = self.graph
            .execute(query(query_str).param("min_score", min_score as f64))
            .await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let mut classes = Vec::new();
        while let Ok(Some(row)) = result.next().await {
            if let Ok(node) = row.get::<Neo4jNode>("c") {
                classes.push(self.node_to_owl_class(node)?);
            }
        }

        debug!("Found {} classes with quality >= {}", classes.len(), min_score);
        Ok(classes)
    }

    /// Query cross-domain bridges
    ///
    /// Returns classes that bridge between different domains
    pub async fn query_cross_domain_bridges(&self) -> RepoResult<Vec<OwlClass>> {
        debug!("Querying cross-domain bridge classes");

        let query_str = "
            MATCH (c:OwlClass)
            WHERE c.bridges_to_domain IS NOT NULL AND c.bridges_to_domain <> ''
            RETURN c
            ORDER BY c.belongs_to_domain, c.bridges_to_domain
        ";

        let mut result = self.graph
            .execute(query(query_str))
            .await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let mut classes = Vec::new();
        while let Ok(Some(row)) = result.next().await {
            if let Ok(node) = row.get::<Neo4jNode>("c") {
                classes.push(self.node_to_owl_class(node)?);
            }
        }

        debug!("Found {} cross-domain bridge classes", classes.len());
        Ok(classes)
    }

    /// Query classes by domain
    ///
    /// Returns all classes belonging to a specific domain
    pub async fn query_by_domain(&self, domain: &str) -> RepoResult<Vec<OwlClass>> {
        debug!("Querying classes in domain: {}", domain);

        let query_str = "
            MATCH (c:OwlClass)
            WHERE c.source_domain = $domain OR c.belongs_to_domain = $domain
            RETURN c
            ORDER BY c.quality_score DESC
        ";

        let mut result = self.graph
            .execute(query(query_str).param("domain", domain.to_string()))
            .await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let mut classes = Vec::new();
        while let Ok(Some(row)) = result.next().await {
            if let Ok(node) = row.get::<Neo4jNode>("c") {
                classes.push(self.node_to_owl_class(node)?);
            }
        }

        debug!("Found {} classes in domain {}", classes.len(), domain);
        Ok(classes)
    }

    /// Query classes by maturity level
    ///
    /// Returns classes filtered by maturity (experimental, beta, stable)
    pub async fn query_by_maturity(&self, maturity: &str) -> RepoResult<Vec<OwlClass>> {
        debug!("Querying classes with maturity: {}", maturity);

        let query_str = "
            MATCH (c:OwlClass)
            WHERE c.maturity = $maturity
            RETURN c
            ORDER BY c.quality_score DESC
        ";

        let mut result = self.graph
            .execute(query(query_str).param("maturity", maturity.to_string()))
            .await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let mut classes = Vec::new();
        while let Ok(Some(row)) = result.next().await {
            if let Ok(node) = row.get::<Neo4jNode>("c") {
                classes.push(self.node_to_owl_class(node)?);
            }
        }

        debug!("Found {} classes with maturity {}", classes.len(), maturity);
        Ok(classes)
    }

    /// Query classes by physicality
    ///
    /// Returns classes filtered by OWL physicality (physical, virtual, abstract)
    pub async fn query_by_physicality(&self, physicality: &str) -> RepoResult<Vec<OwlClass>> {
        debug!("Querying classes with physicality: {}", physicality);

        let query_str = "
            MATCH (c:OwlClass)
            WHERE c.owl_physicality = $physicality
            RETURN c
            ORDER BY c.label
        ";

        let mut result = self.graph
            .execute(query(query_str).param("physicality", physicality.to_string()))
            .await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let mut classes = Vec::new();
        while let Ok(Some(row)) = result.next().await {
            if let Ok(node) = row.get::<Neo4jNode>("c") {
                classes.push(self.node_to_owl_class(node)?);
            }
        }

        debug!("Found {} classes with physicality {}", classes.len(), physicality);
        Ok(classes)
    }

    /// Query classes by role
    ///
    /// Returns classes filtered by OWL role (agent, patient, instrument)
    pub async fn query_by_role(&self, role: &str) -> RepoResult<Vec<OwlClass>> {
        debug!("Querying classes with role: {}", role);

        let query_str = "
            MATCH (c:OwlClass)
            WHERE c.owl_role = $role
            RETURN c
            ORDER BY c.label
        ";

        let mut result = self.graph
            .execute(query(query_str).param("role", role.to_string()))
            .await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let mut classes = Vec::new();
        while let Ok(Some(row)) = result.next().await {
            if let Ok(node) = row.get::<Neo4jNode>("c") {
                classes.push(self.node_to_owl_class(node)?);
            }
        }

        debug!("Found {} classes with role {}", classes.len(), role);
        Ok(classes)
    }

    /// Add semantic relationship between classes
    ///
    /// Creates a RELATES relationship with metadata
    pub async fn add_relationship(
        &self,
        source_iri: &str,
        relationship_type: &str,
        target_iri: &str,
        confidence: f32,
        is_inferred: bool,
    ) -> RepoResult<()> {
        debug!("Adding relationship: {} -[{}]-> {}", source_iri, relationship_type, target_iri);

        let query_str = "
            MATCH (s:OwlClass {iri: $source_iri})
            MATCH (t:OwlClass {iri: $target_iri})
            MERGE (s)-[r:RELATES {relationship_type: $relationship_type}]->(t)
            SET r.confidence = $confidence,
                r.is_inferred = $is_inferred,
                r.created_at = datetime()
        ";

        self.graph
            .run(query(query_str)
                .param("source_iri", source_iri.to_string())
                .param("target_iri", target_iri.to_string())
                .param("relationship_type", relationship_type.to_string())
                .param("confidence", confidence as f64)
                .param("is_inferred", is_inferred))
            .await
            .map_err(|e| {
                OntologyRepositoryError::DatabaseError(format!(
                    "Failed to add relationship: {}",
                    e
                ))
            })?;

        Ok(())
    }

    /// Query relationships by type
    ///
    /// Returns all relationships of a specific type
    pub async fn query_relationships_by_type(&self, relationship_type: &str) -> RepoResult<Vec<(String, String, f32, bool)>> {
        debug!("Querying relationships of type: {}", relationship_type);

        let query_str = "
            MATCH (s:OwlClass)-[r:RELATES {relationship_type: $relationship_type}]->(t:OwlClass)
            RETURN s.iri as source, t.iri as target, r.confidence as confidence, r.is_inferred as is_inferred
            ORDER BY r.confidence DESC
        ";

        let mut result = self.graph
            .execute(query(query_str).param("relationship_type", relationship_type.to_string()))
            .await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let mut relationships = Vec::new();
        while let Ok(Some(row)) = result.next().await {
            if let (Ok(source), Ok(target), Ok(confidence), Ok(is_inferred)) = (
                row.get::<String>("source"),
                row.get::<String>("target"),
                row.get::<f64>("confidence"),
                row.get::<bool>("is_inferred"),
            ) {
                relationships.push((source, target, confidence as f32, is_inferred));
            }
        }

        debug!("Found {} relationships of type {}", relationships.len(), relationship_type);
        Ok(relationships)
    }

    /// Batch add classes (efficient bulk insert)
    ///
    /// Uses UNWIND for optimal batch insertion performance
    pub async fn batch_add_classes(&self, classes: &[OwlClass]) -> RepoResult<Vec<String>> {
        info!("Batch adding {} classes", classes.len());

        // Process in batches of 100 for optimal performance
        const BATCH_SIZE: usize = 100;
        let mut added_iris = Vec::new();

        for chunk in classes.chunks(BATCH_SIZE) {
            for class in chunk {
                let iri = self.add_owl_class(class).await?;
                added_iris.push(iri);
            }
            debug!("Added batch of {} classes", chunk.len());
        }

        info!("Successfully batch added {} classes", added_iris.len());
        Ok(added_iris)
    }

    /// Batch add relationships (efficient bulk insert)
    ///
    /// Optimized for large-scale relationship insertion
    pub async fn batch_add_relationships(
        &self,
        relationships: &[(String, String, String, f32, bool)],
    ) -> RepoResult<()> {
        info!("Batch adding {} relationships", relationships.len());

        const BATCH_SIZE: usize = 100;

        for chunk in relationships.chunks(BATCH_SIZE) {
            for (source, relationship_type, target, confidence, is_inferred) in chunk {
                self.add_relationship(source, relationship_type, target, *confidence, *is_inferred)
                    .await?;
            }
            debug!("Added batch of {} relationships", chunk.len());
        }

        info!("Successfully batch added {} relationships", relationships.len());
        Ok(())
    }

    /// Get clustering by physicality and role
    ///
    /// Returns a grouped view of classes organized by physicality and role
    pub async fn get_physicality_role_clustering(&self) -> RepoResult<HashMap<String, HashMap<String, Vec<OwlClass>>>> {
        debug!("Computing physicality-role clustering");

        let query_str = "
            MATCH (c:OwlClass)
            WHERE c.owl_physicality IS NOT NULL AND c.owl_role IS NOT NULL
            RETURN c.owl_physicality as physicality, c.owl_role as role, collect(c) as classes
            ORDER BY physicality, role
        ";

        let mut result = self.graph
            .execute(query(query_str))
            .await
            .map_err(|e| OntologyRepositoryError::DatabaseError(e.to_string()))?;

        let mut clustering: HashMap<String, HashMap<String, Vec<OwlClass>>> = HashMap::new();

        while let Ok(Some(row)) = result.next().await {
            if let (Ok(physicality), Ok(role), Ok(nodes)) = (
                row.get::<String>("physicality"),
                row.get::<String>("role"),
                row.get::<Vec<Neo4jNode>>("classes"),
            ) {
                let classes: Result<Vec<OwlClass>, _> = nodes
                    .into_iter()
                    .map(|n| self.node_to_owl_class(n))
                    .collect();

                if let Ok(classes) = classes {
                    clustering
                        .entry(physicality)
                        .or_insert_with(HashMap::new)
                        .insert(role, classes);
                }
            }
        }

        debug!("Computed clustering with {} physicality groups", clustering.len());
        Ok(clustering)
    }
}

--------------------------------------------------------------------------------
FILE: src/adapters/whelk_inference_engine.rs
PURPOSE: Whelk OWL reasoner adapter for inference
--------------------------------------------------------------------------------
// src/adapters/whelk_inference_engine.rs
//! Whelk Inference Engine Adapter
//!
//! Implements the InferenceEngine port using horned-owl for OWL ontology loading
//! and whelk-rs for EL reasoning. This adapter provides complete EL reasoning capabilities.

use async_trait::async_trait;
use tracing::{debug, info, instrument, warn};

use crate::ports::inference_engine::{
    InferenceEngine, InferenceEngineError, InferenceStatistics, Result as EngineResult,
};
use crate::ports::ontology_repository::{AxiomType, InferenceResults, OwlAxiom, OwlClass};

use horned_owl::model::{
    AnnotatedComponent, ArcStr, Build, Class, ClassExpression, Component, DeclareClass,
    MutableOntology, SubClassOf,
};
use horned_owl::ontology::set::SetOntology;
use std::collections::hash_map::DefaultHasher;
use std::hash::{Hash, Hasher};

///
///
///
///
pub struct WhelkInferenceEngine {
    ontology: Option<SetOntology<ArcStr>>,

    cached_subsumptions: Option<Vec<OwlAxiom>>,

    last_checksum: Option<u64>,

    _phantom: std::marker::PhantomData<()>,

    loaded_classes: usize,
    loaded_axioms: usize,
    inferred_axioms: usize,
    last_inference_time_ms: u64,
    total_inferences: usize,
}

///
use whelk;
use crate::utils::time;

impl WhelkInferenceEngine {
    
    pub fn new() -> Self {
        info!("Initializing WhelkInferenceEngine");
        Self {
            ontology: None,

            cached_subsumptions: None,

            last_checksum: None,

            _phantom: std::marker::PhantomData,

            loaded_classes: 0,
            loaded_axioms: 0,
            inferred_axioms: 0,
            last_inference_time_ms: 0,
            total_inferences: 0,
        }
    }

    
    fn convert_class_to_horned(class: &OwlClass) -> Option<AnnotatedComponent<ArcStr>> {
        let iri = Build::new().iri(class.iri.clone());
        let class_decl = Class(iri);
        Some(AnnotatedComponent {
            component: Component::DeclareClass(DeclareClass(class_decl)),
            ann: Default::default(),
        })
    }

    
    fn convert_axiom_to_horned(axiom: &OwlAxiom) -> Option<AnnotatedComponent<ArcStr>> {
        let component = match axiom.axiom_type {
            AxiomType::SubClassOf => {
                
                let sub_iri = Build::new().iri(axiom.subject.clone());
                let sup_iri = Build::new().iri(axiom.object.clone());

                let sub_class = ClassExpression::Class(Class(sub_iri));
                let sup_class = ClassExpression::Class(Class(sup_iri));

                Component::SubClassOf(SubClassOf {
                    sub: sub_class,
                    sup: sup_class,
                })
            }
            AxiomType::EquivalentClass => {
                
                warn!("EquivalentClass axioms require special handling - converting to SubClassOf");
                let sub_iri = Build::new().iri(axiom.subject.clone());
                let sup_iri = Build::new().iri(axiom.object.clone());

                Component::SubClassOf(SubClassOf {
                    sub: ClassExpression::Class(Class(sub_iri)),
                    sup: ClassExpression::Class(Class(sup_iri)),
                })
            }
            AxiomType::ObjectPropertyAssertion => {
                
                
                warn!("ObjectPropertyAssertion not directly translated to EL Tbox");
                return None;
            }
            _ => {
                warn!("Unsupported axiom type: {:?}", axiom.axiom_type);
                return None;
            }
        };

        Some(AnnotatedComponent {
            component,
            ann: Default::default(),
        })
    }

    
    fn compute_ontology_checksum(ontology: &SetOntology<ArcStr>) -> u64 {
        let mut hasher = DefaultHasher::new();

        
        let mut axioms: Vec<String> = ontology
            .iter()
            .map(|ann| format!("{:?}", ann.component))
            .collect();
        axioms.sort();

        for axiom in axioms {
            axiom.hash(&mut hasher);
        }

        hasher.finish()
    }

    
    
    
    fn convert_subsumptions_to_axioms<V>(subsumptions: &V) -> Vec<OwlAxiom>
    where
        V: IntoIterator<
                Item = (
                    std::rc::Rc<whelk::whelk::model::AtomicConcept>,
                    std::rc::Rc<whelk::whelk::model::AtomicConcept>,
                ),
            > + Clone,
    {
        subsumptions
            .clone()
            .into_iter()
            .map(|(sub, sup)| OwlAxiom {
                id: None,
                axiom_type: AxiomType::SubClassOf,
                subject: sub.id.clone(),
                object: sup.id.clone(),
                annotations: std::collections::HashMap::new(),
            })
            .collect()
    }
}

impl Default for WhelkInferenceEngine {
    fn default() -> Self {
        Self::new()
    }
}

#[async_trait]
impl InferenceEngine for WhelkInferenceEngine {
    #[instrument(skip(self, classes, axioms), fields(classes = classes.len(), axioms = axioms.len()), level = "debug")]
    async fn load_ontology(
        &mut self,
        classes: Vec<OwlClass>,
        axioms: Vec<OwlAxiom>,
    ) -> EngineResult<()> {
        {
            let mut ontology = SetOntology::new();

            
            for class in &classes {
                if let Some(horned_class) = Self::convert_class_to_horned(class) {
                    ontology.insert(horned_class);
                }
            }

            
            for axiom in &axioms {
                if let Some(horned_axiom) = Self::convert_axiom_to_horned(axiom) {
                    ontology.insert(horned_axiom);
                }
            }

            
            let checksum = Self::compute_ontology_checksum(&ontology);

            
            let needs_reasoning = match self.last_checksum {
                Some(last) => last != checksum,
                None => true,
            };

            if needs_reasoning {
                info!("Ontology changed, will perform fresh reasoning");
                self.last_checksum = Some(checksum);
                self.cached_subsumptions = None; 
            } else {
                info!("Ontology unchanged, reusing cached reasoning results");
            }

            self.ontology = Some(ontology);
            self.loaded_classes = classes.len();
            self.loaded_axioms = axioms.len();

            info!(
                "Loaded ontology with {} classes and {} axioms",
                classes.len(),
                axioms.len()
            );
            Ok(())
        }
    }

    #[instrument(skip(self), level = "debug")]
    async fn infer(&mut self) -> EngineResult<InferenceResults> {
        let start = std::time::Instant::now();

        {
            let ontology = self
                .ontology
                .as_ref()
                .ok_or(InferenceEngineError::OntologyNotLoaded)?;

            
            if let Some(ref cached) = self.cached_subsumptions {
                info!("Using cached reasoning results");

                let inference_time_ms = start.elapsed().as_millis() as u64;
                self.last_inference_time_ms = inference_time_ms;

                return Ok(InferenceResults {
                    timestamp: time::now(),
                    inferred_axioms: cached.clone(),
                    inference_time_ms,
                    reasoner_version: format!("whelk-rs-{}", env!("CARGO_PKG_VERSION")),
                });
            }

            
            info!("Performing EL reasoning with whelk-rs");

            
            let whelk_axioms = whelk::whelk::owl::translate_ontology(ontology);
            debug!("Translated {} axioms to whelk format", whelk_axioms.len());

            
            let reasoner_state = whelk::whelk::reasoner::assert(&whelk_axioms);

            
            let subsumptions = reasoner_state.named_subsumptions();
            info!("Inferred {} subsumption relationships", subsumptions.len());

            
            let inferred_axioms = Self::convert_subsumptions_to_axioms(&subsumptions);
            self.inferred_axioms = inferred_axioms.len();

            
            self.cached_subsumptions = Some(inferred_axioms.clone());
            self.total_inferences += 1;

            let inference_time_ms = start.elapsed().as_millis() as u64;
            self.last_inference_time_ms = inference_time_ms;

            info!(
                "EL reasoning completed in {}ms with {} inferred axioms",
                inference_time_ms,
                inferred_axioms.len()
            );

            Ok(InferenceResults {
                timestamp: time::now(),
                inferred_axioms,
                inference_time_ms,
                reasoner_version: format!("whelk-rs-{}", env!("CARGO_PKG_VERSION")),
            })
        }
    }

    async fn is_entailed(&self, axiom: &OwlAxiom) -> EngineResult<bool> {
        {
            let cached = self
                .cached_subsumptions
                .as_ref()
                .ok_or(InferenceEngineError::OntologyNotLoaded)?;

            
            if axiom.axiom_type == AxiomType::SubClassOf {
                let is_entailed = cached.iter().any(|inferred| {
                    inferred.axiom_type == AxiomType::SubClassOf
                        && inferred.subject == axiom.subject
                        && inferred.object == axiom.object
                });

                return Ok(is_entailed);
            }

            Ok(false)
        }
    }

    async fn get_subclass_hierarchy(&self) -> EngineResult<Vec<(String, String)>> {
        {
            let cached = self
                .cached_subsumptions
                .as_ref()
                .ok_or(InferenceEngineError::OntologyNotLoaded)?;

            
            let hierarchy: Vec<(String, String)> = cached
                .iter()
                .filter(|ax| ax.axiom_type == AxiomType::SubClassOf)
                .map(|ax| (ax.subject.clone(), ax.object.clone()))
                .collect();

            debug!("Extracted {} subsumption relationships", hierarchy.len());
            Ok(hierarchy)
        }
    }

    async fn classify_instance(&self, instance_iri: &str) -> EngineResult<Vec<String>> {
        {
            let cached = self
                .cached_subsumptions
                .as_ref()
                .ok_or(InferenceEngineError::OntologyNotLoaded)?;

            
            let class_iris: Vec<String> = cached
                .iter()
                .filter(|ax| ax.axiom_type == AxiomType::SubClassOf && ax.subject == instance_iri)
                .map(|ax| ax.object.clone())
                .collect();

            debug!(
                "Instance {} belongs to {} classes",
                instance_iri,
                class_iris.len()
            );
            Ok(class_iris)
        }
    }

    async fn check_consistency(&self) -> EngineResult<bool> {
        {
            let cached = self
                .cached_subsumptions
                .as_ref()
                .ok_or(InferenceEngineError::OntologyNotLoaded)?;

            
            
            let bottom_iri = "http://www.w3.org/2002/07/owl#Nothing";

            let inconsistent_classes: Vec<&OwlAxiom> = cached
                .iter()
                .filter(|ax| {
                    ax.axiom_type == AxiomType::SubClassOf
                        && ax.object == bottom_iri
                        && ax.subject != bottom_iri
                })
                .collect();

            if !inconsistent_classes.is_empty() {
                warn!(
                    "Ontology is inconsistent: {} classes are equivalent to owl:Nothing",
                    inconsistent_classes.len()
                );
                return Ok(false);
            }

            info!("Ontology is consistent");
            Ok(true)
        }
    }

    async fn explain_entailment(&self, axiom: &OwlAxiom) -> EngineResult<Vec<OwlAxiom>> {
        {
            
            
            if axiom.axiom_type != AxiomType::SubClassOf {
                return Ok(Vec::new());
            }

            let cached = self
                .cached_subsumptions
                .as_ref()
                .ok_or(InferenceEngineError::OntologyNotLoaded)?;

            
            let mut explanation = Vec::new();

            
            for inferred in cached.iter() {
                if inferred.subject == axiom.subject && inferred.axiom_type == AxiomType::SubClassOf
                {
                    explanation.push(inferred.clone());
                }
            }

            debug!("Found {} axioms in explanation", explanation.len());
            Ok(explanation)
        }
    }

    async fn clear(&mut self) -> EngineResult<()> {
        {
            self.ontology = None;
            self.cached_subsumptions = None;
            self.last_checksum = None;
        }

        self.loaded_classes = 0;
        self.loaded_axioms = 0;
        self.inferred_axioms = 0;

        info!("Cleared ontology from inference engine");
        Ok(())
    }

    async fn get_statistics(&self) -> EngineResult<InferenceStatistics> {
        Ok(InferenceStatistics {
            loaded_classes: self.loaded_classes,
            loaded_axioms: self.loaded_axioms,
            inferred_axioms: self.inferred_axioms,
            last_inference_time_ms: self.last_inference_time_ms,
            total_inferences: self.total_inferences as u64,
        })
    }
}

================================================================================
                    SECTION 4: CORE SERVICES (Business Logic)
================================================================================

--------------------------------------------------------------------------------
FILE: src/services/mod.rs
PURPOSE: Module exports for all business logic services
--------------------------------------------------------------------------------
pub mod agent_visualization_processor;
pub mod agent_visualization_protocol;
pub mod bots_client;
pub mod edge_generation;
pub mod file_service;
pub mod github;
pub mod github_sync_service;
pub mod local_file_sync_service;
pub mod local_markdown_sync;
pub mod management_api_client;
pub mod multi_mcp_agent_discovery;
pub mod natural_language_query_service;
pub mod parsers;
pub mod real_mcp_integration_bridge;
pub mod topology_visualization_engine;
// graph_service module removed - functionality moved to GraphServiceActor
pub mod graph_serialization;
pub mod mcp_relay_manager;
pub mod nostr_service;
pub mod owl_validator;

// horned-functional API stabilized in current implementation
// #[cfg(feature = "ontology")]
// pub mod owl_extractor_service; // Deprecated - functionality merged into owl_validator
pub mod perplexity_service;
pub mod ragflow_service;
pub mod schema_service;
pub mod semantic_analyzer;
pub mod semantic_pathfinding_service;
pub mod settings_watcher;
pub mod speech_service;
pub mod speech_voice_integration;
pub mod voice_context_manager;
pub mod voice_tag_manager;
pub mod streaming_sync_service;
pub mod ontology_converter;
pub mod edge_classifier;
pub mod ontology_reasoner;
pub mod ontology_enrichment_service;
pub mod ontology_reasoning_service;
pub mod ontology_pipeline_service;
pub mod pipeline_events;
pub mod ontology_content_analyzer;
pub mod ontology_file_cache;
pub mod jss_sync_service;
pub mod jss_websocket_bridge;
pub mod semantic_type_registry;

// Re-export semantic type registry types for convenience
pub use semantic_type_registry::{
    DynamicForceConfigGPU, RelationshipForceConfig, SemanticTypeRegistry,
    SEMANTIC_TYPE_REGISTRY,
};

--------------------------------------------------------------------------------
FILE: src/services/nostr_service.rs
PURPOSE: Nostr protocol authentication and user management
--------------------------------------------------------------------------------
use crate::config::feature_access::FeatureAccess;
use crate::models::protected_settings::{ApiKeys, NostrUser};
use crate::utils::nip98::{
    parse_auth_header, validate_nip98_token, Nip98ValidationError, Nip98ValidationResult,
};
use chrono::Utc;
use log::{debug, error, info, warn};
use nostr_sdk::{event::Error as EventError, prelude::*};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use thiserror::Error;
use tokio::sync::RwLock;
use uuid::Uuid;
use crate::utils::time;
use crate::utils::json::{from_json, to_json};

#[derive(Debug, Error)]
pub enum NostrError {
    #[error("Invalid event: {0}")]
    InvalidEvent(String),
    #[error("Invalid signature")]
    InvalidSignature,
    #[error("User not found")]
    UserNotFound,
    #[error("Invalid token")]
    InvalidToken,
    #[error("Session expired")]
    SessionExpired,
    #[error("Power user operation not allowed")]
    PowerUserOperation,
    #[error("Nostr event error: {0}")]
    NostrError(#[from] EventError),
    #[error("JSON error: {0}")]
    JsonError(#[from] serde_json::Error),
    #[error("NIP-98 validation error: {0}")]
    Nip98Error(String),
}

impl Serialize for NostrError {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        use serde::ser::SerializeStruct;
        let mut state = serializer.serialize_struct("NostrError", 2)?;
        match self {
            NostrError::InvalidEvent(msg) => {
                state.serialize_field("type", "InvalidEvent")?;
                state.serialize_field("message", msg)?;
            }
            NostrError::InvalidSignature => {
                state.serialize_field("type", "InvalidSignature")?;
                state.serialize_field("message", "Invalid signature")?;
            }
            NostrError::UserNotFound => {
                state.serialize_field("type", "UserNotFound")?;
                state.serialize_field("message", "User not found")?;
            }
            NostrError::InvalidToken => {
                state.serialize_field("type", "InvalidToken")?;
                state.serialize_field("message", "Invalid token")?;
            }
            NostrError::SessionExpired => {
                state.serialize_field("type", "SessionExpired")?;
                state.serialize_field("message", "Session expired")?;
            }
            NostrError::PowerUserOperation => {
                state.serialize_field("type", "PowerUserOperation")?;
                state.serialize_field("message", "Power user operation not allowed")?;
            }
            NostrError::NostrError(e) => {
                state.serialize_field("type", "NostrError")?;
                state.serialize_field("message", &e.to_string())?;
            }
            NostrError::JsonError(e) => {
                state.serialize_field("type", "JsonError")?;
                state.serialize_field("message", &e.to_string())?;
            }
            NostrError::Nip98Error(msg) => {
                state.serialize_field("type", "Nip98Error")?;
                state.serialize_field("message", msg)?;
            }
        }
        state.end()
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AuthEvent {
    pub id: String,
    pub pubkey: String,
    pub content: String,
    pub sig: String,
    pub created_at: i64,
    pub kind: i32,
    pub tags: Vec<Vec<String>>,
}

#[derive(Clone)]
pub struct NostrService {
    users: Arc<RwLock<HashMap<String, NostrUser>>>,
    power_user_pubkeys: Vec<String>,
    token_expiry: i64,
    feature_access: Arc<RwLock<FeatureAccess>>,
}

impl NostrService {
    pub fn new() -> Self {
        let power_users = std::env::var("POWER_USER_PUBKEYS")
            .unwrap_or_default()
            .split(',')
            .map(|s| s.trim().to_string())
            .collect();

        let token_expiry = std::env::var("AUTH_TOKEN_EXPIRY")
            .unwrap_or_else(|_| "3600".to_string())
            .parse()
            .unwrap_or(3600);

        let feature_access = Arc::new(RwLock::new(FeatureAccess::from_env()));
        Self {
            users: Arc::new(RwLock::new(HashMap::new())),
            power_user_pubkeys: power_users,
            feature_access,
            token_expiry,
        }
    }

    pub async fn verify_auth_event(&self, event: AuthEvent) -> Result<NostrUser, NostrError> {
        
        
        debug!(
            "Verifying auth event with id: {} and pubkey: {}",
            event.id, event.pubkey
        );

        let json_str = match to_json(&event) {
            Ok(s) => s,
            Err(e) => {
                error!("Failed to serialize auth event with id {}: {}", event.id, e);
                return Err(NostrError::JsonError(serde_json::Error::io(std::io::Error::new(std::io::ErrorKind::Other, e.to_string()))));
            }
        };

        debug!(
            "Event JSON for verification (truncated): {}...",
            if json_str.len() > 100 {
                &json_str[0..100]
            } else {
                &json_str
            }
        );

        let nostr_event = match Event::from_json(&json_str) {
            Ok(e) => e,
            Err(e) => {
                error!(
                    "Failed to parse Nostr event for pubkey {}: {}",
                    event.pubkey, e
                );
                return Err(NostrError::InvalidEvent(format!(
                    "Parse error for event {}: {}",
                    event.id, e
                )));
            }
        };

        if let Err(e) = nostr_event.verify() {
            error!(
                "Signature verification failed for pubkey {}: {}",
                event.pubkey, e
            );
            return Err(NostrError::InvalidSignature);
        }

        
        let mut feature_access = self.feature_access.write().await;
        if feature_access.register_new_user(&event.pubkey) {
            info!("Registered new user with basic access: {}", event.pubkey);
        }

        let now = time::now();
        let is_power_user = self.power_user_pubkeys.contains(&event.pubkey);

        
        let session_token = Uuid::new_v4().to_string();

        let user = NostrUser {
            pubkey: event.pubkey.clone(),
            npub: nostr_event
                .pubkey
                .to_bech32()
                .map_err(|_| NostrError::NostrError(EventError::InvalidId))?,
            is_power_user,
            api_keys: ApiKeys::default(),
            last_seen: now.timestamp(),
            session_token: Some(session_token),
        };

        
        info!(
            "Created/updated user: pubkey={}, is_power_user={}",
            user.pubkey, user.is_power_user
        );

        
        let mut users = self.users.write().await;
        users.insert(user.pubkey.clone(), user.clone());

        Ok(user)
    }

    pub async fn get_user(&self, pubkey: &str) -> Option<NostrUser> {
        let users = self.users.read().await;
        users.get(pubkey).cloned()
    }

    pub async fn update_user_api_keys(
        &self,
        pubkey: &str,
        api_keys: ApiKeys,
    ) -> Result<NostrUser, NostrError> {
        let mut users = self.users.write().await;

        if let Some(user) = users.get_mut(pubkey) {
            if user.is_power_user {
                return Err(NostrError::PowerUserOperation);
            }
            user.api_keys = api_keys;
            user.last_seen = time::timestamp_seconds();
            Ok(user.clone())
        } else {
            Err(NostrError::UserNotFound)
        }
    }

    pub async fn validate_session(&self, pubkey: &str, token: &str) -> bool {
        if let Some(user) = self.get_user(pubkey).await {
            if let Some(session_token) = user.session_token {
                let now = time::timestamp_seconds();
                if now - user.last_seen <= self.token_expiry {
                    return session_token == token;
                }
            }
        }
        false
    }

    pub async fn refresh_session(&self, pubkey: &str) -> Result<String, NostrError> {
        let mut users = self.users.write().await;

        if let Some(user) = users.get_mut(pubkey) {
            let now = time::timestamp_seconds();
            let new_token = Uuid::new_v4().to_string();
            user.session_token = Some(new_token.clone());
            user.last_seen = now;
            Ok(new_token)
        } else {
            Err(NostrError::UserNotFound)
        }
    }

    pub async fn logout(&self, pubkey: &str) -> Result<(), NostrError> {
        let mut users = self.users.write().await;

        if let Some(user) = users.get_mut(pubkey) {
            user.session_token = None;
            user.last_seen = time::timestamp_seconds();
            Ok(())
        } else {
            Err(NostrError::UserNotFound)
        }
    }

    pub async fn cleanup_sessions(&self, max_age_hours: i64) {
        let now = time::now();
        let mut users = self.users.write().await;

        users.retain(|_, user| {
            let age = now.timestamp() - user.last_seen;
            age < (max_age_hours * 3600)
        });
    }

    pub async fn is_power_user(&self, pubkey: &str) -> bool {
        if let Some(user) = self.get_user(pubkey).await {
            user.is_power_user
        } else {
            false
        }
    }

    /// Get session by token (looks up user by token)
    pub async fn get_session(&self, token: &str) -> Option<NostrUser> {
        let users = self.users.read().await;
        let token_string = token.to_string();
        users.values()
            .find(|user| {
                user.session_token.as_ref() == Some(&token_string)
            })
            .cloned()
    }

    /// Validate NIP-98 HTTP authentication from Authorization header
    ///
    /// This validates tokens for Solid server requests per NIP-98 spec.
    /// Tokens must be signed, unexpired (60s max), and match the request URL/method.
    ///
    /// # Arguments
    /// * `auth_header` - Full Authorization header (e.g., "Nostr <base64>")
    /// * `request_url` - The URL the request was made to
    /// * `request_method` - The HTTP method (GET, POST, PUT, etc.)
    /// * `request_body` - Optional request body for payload verification
    ///
    /// # Returns
    /// The authenticated NostrUser or an error
    pub async fn verify_nip98_auth(
        &self,
        auth_header: &str,
        request_url: &str,
        request_method: &str,
        request_body: Option<&str>,
    ) -> Result<NostrUser, NostrError> {
        // Parse the Authorization header
        let token = parse_auth_header(auth_header).ok_or_else(|| {
            NostrError::Nip98Error("Invalid Authorization header format".to_string())
        })?;

        // Validate the NIP-98 token
        let validation = validate_nip98_token(token, request_url, request_method, request_body)
            .map_err(|e| NostrError::Nip98Error(e.to_string()))?;

        debug!(
            "NIP-98 token validated for pubkey: {}..., url: {}, method: {}",
            &validation.pubkey[..16.min(validation.pubkey.len())],
            validation.url,
            validation.method
        );

        // Get or create the user
        let user = self.get_or_create_user_from_pubkey(&validation.pubkey).await?;

        info!(
            "NIP-98 auth successful for pubkey: {}, is_power_user: {}",
            user.pubkey, user.is_power_user
        );

        Ok(user)
    }

    /// Get existing user or create a new one from pubkey
    async fn get_or_create_user_from_pubkey(&self, pubkey: &str) -> Result<NostrUser, NostrError> {
        // Check if user exists
        if let Some(user) = self.get_user(pubkey).await {
            // Update last_seen
            let mut users = self.users.write().await;
            if let Some(user) = users.get_mut(pubkey) {
                user.last_seen = time::timestamp_seconds();
            }
            return Ok(users.get(pubkey).cloned().unwrap());
        }

        // Register new user with feature access
        let mut feature_access = self.feature_access.write().await;
        if feature_access.register_new_user(pubkey) {
            info!("Registered new user via NIP-98 with basic access: {}", pubkey);
        }

        let is_power_user = self.power_user_pubkeys.contains(&pubkey.to_string());
        let session_token = Uuid::new_v4().to_string();

        // Convert hex pubkey to npub (bech32)
        let npub = match PublicKey::from_hex(pubkey) {
            Ok(pk) => pk.to_bech32().unwrap_or_else(|_| pubkey.to_string()),
            Err(_) => {
                warn!("Could not convert pubkey to npub: {}", pubkey);
                pubkey.to_string()
            }
        };

        let user = NostrUser {
            pubkey: pubkey.to_string(),
            npub,
            is_power_user,
            api_keys: ApiKeys::default(),
            last_seen: time::timestamp_seconds(),
            session_token: Some(session_token),
        };

        // Store the new user
        let mut users = self.users.write().await;
        users.insert(pubkey.to_string(), user.clone());

        info!(
            "Created new user via NIP-98: pubkey={}, is_power_user={}",
            user.pubkey, user.is_power_user
        );

        Ok(user)
    }

    /// Validate NIP-98 token and return just the validation result (no user creation)
    ///
    /// Use this for stateless validation when you only need to verify the token.
    pub fn validate_nip98_token_only(
        &self,
        auth_header: &str,
        request_url: &str,
        request_method: &str,
        request_body: Option<&str>,
    ) -> Result<Nip98ValidationResult, NostrError> {
        let token = parse_auth_header(auth_header).ok_or_else(|| {
            NostrError::Nip98Error("Invalid Authorization header format".to_string())
        })?;

        validate_nip98_token(token, request_url, request_method, request_body)
            .map_err(|e| NostrError::Nip98Error(e.to_string()))
    }
}

impl Default for NostrService {
    fn default() -> Self {
        Self::new()
    }
}

--------------------------------------------------------------------------------
FILE: src/services/github_sync_service.rs
PURPOSE: GitHub content synchronization and markdown processing
--------------------------------------------------------------------------------
// src/services/github_sync_service.rs
//! GitHub Sync Service
//!
//! Synchronizes markdown files from GitHub repository to Neo4j.
//! - Parses public:: true pages as knowledge graph nodes (KnowledgeGraphRepository - Neo4jAdapter)
//! - Extracts OntologyBlock sections as OWL data (Neo4jOntologyRepository)
//! - Enriches graph nodes with owl_class_iri metadata via OntologyEnrichmentService
//! - Triggers OntologyPipelineService for automatic reasoning and constraint generation
//! - Uses SHA1 filtering to process only changed files (unless FORCE_FULL_SYNC=1)
//! - Batch processing (50 files) to avoid memory issues with large repositories

use crate::adapters::neo4j_ontology_repository::Neo4jOntologyRepository;
use crate::ports::knowledge_graph_repository::KnowledgeGraphRepository;
use crate::ports::ontology_repository::OntologyRepository;
use crate::services::github::content_enhanced::EnhancedContentAPI;
use crate::services::github::types::GitHubFileBasicMetadata;
use crate::services::parsers::{KnowledgeGraphParser, OntologyParser};
use crate::services::ontology_enrichment_service::OntologyEnrichmentService;
use crate::services::ontology_reasoner::OntologyReasoner;
use crate::services::edge_classifier::EdgeClassifier;
use crate::services::ontology_pipeline_service::OntologyPipelineService;
use crate::adapters::whelk_inference_engine::WhelkInferenceEngine;
use futures::stream::{FuturesUnordered, StreamExt};
use log::{debug, error, info, warn};
use std::sync::Arc;
use std::time::{Duration, Instant};
use crate::utils::time;

const BATCH_SIZE: usize = 50; // Save to database every 50 files

#[derive(Debug, Clone, PartialEq)]
pub enum FileType {
    KnowledgeGraph,
    Ontology,
    Skip,
}

#[derive(Debug, Clone)]
pub struct SyncStatistics {
    pub total_files: usize,
    pub kg_files_processed: usize,
    pub ontology_files_processed: usize,
    pub skipped_files: usize,
    pub errors: Vec<String>,
    pub duration: Duration,
    pub total_nodes: usize,
    pub total_edges: usize,
}

pub struct GitHubSyncService {
    content_api: Arc<EnhancedContentAPI>,
    kg_parser: Arc<KnowledgeGraphParser>,
    onto_parser: Arc<OntologyParser>,
    kg_repo: Arc<dyn KnowledgeGraphRepository>,
    onto_repo: Arc<Neo4jOntologyRepository>,
    enrichment_service: Arc<OntologyEnrichmentService>,
    pipeline_service: Option<Arc<OntologyPipelineService>>,
}

impl GitHubSyncService {
    pub fn new(
        content_api: Arc<EnhancedContentAPI>,
        kg_repo: Arc<dyn KnowledgeGraphRepository>,
        onto_repo: Arc<Neo4jOntologyRepository>,
    ) -> Self {
        // Initialize ontology enrichment service
        let inference_engine = Arc::new(WhelkInferenceEngine::new());
        let reasoner = Arc::new(OntologyReasoner::new(
            inference_engine,
            onto_repo.clone() as Arc<dyn OntologyRepository>,
        ));
        let classifier = Arc::new(EdgeClassifier::new());
        let enrichment_service = Arc::new(OntologyEnrichmentService::new(
            reasoner,
            classifier,
        ));

        Self {
            content_api,
            kg_parser: Arc::new(KnowledgeGraphParser::new()),
            onto_parser: Arc::new(OntologyParser::new()),
            kg_repo,
            onto_repo,
            enrichment_service,
            pipeline_service: None,
        }
    }

    /// Set the ontology pipeline service for automatic reasoning
    pub fn set_pipeline_service(&mut self, pipeline: Arc<OntologyPipelineService>) {
        info!("GitHubSyncService: Ontology pipeline service registered");
        self.pipeline_service = Some(pipeline);
    }

    /// Synchronize graphs from GitHub - processes in batches with progress logging
    pub async fn sync_graphs(&self) -> Result<SyncStatistics, String> {
        info!(" Starting GitHub sync (batch size: {})", BATCH_SIZE);
        let start_time = Instant::now();

        let mut stats = SyncStatistics {
            total_files: 0,
            kg_files_processed: 0,
            ontology_files_processed: 0,
            skipped_files: 0,
            errors: Vec::new(),
            duration: Duration::from_secs(0),
            total_nodes: 0,
            total_edges: 0,
        };

        // Fetch files
        let files = match self.fetch_all_markdown_files().await {
            Ok(files) => {
                info!(" Found {} markdown files", files.len());
                files
            }
            Err(e) => {
                let error_msg = format!("Failed to fetch files: {}", e);
                error!("{}", error_msg);
                stats.errors.push(error_msg);
                stats.duration = start_time.elapsed();
                return Ok(stats);
            }
        };

        stats.total_files = files.len();

        // SHA1 filtering - only process changed files (unless FORCE_FULL_SYNC is set)
        let force_full_sync = std::env::var("FORCE_FULL_SYNC")
            .map(|v| v == "1" || v.to_lowercase() == "true")
            .unwrap_or(false);

        let files_to_process = if force_full_sync {
            info!(" FORCE_FULL_SYNC enabled - processing ALL {} files (bypassing SHA1 filter)", files.len());
            files.clone()
        } else {
            match self.filter_changed_files(&files).await {
                Ok(filtered) => {
                    info!(" Processing {} changed files ({} unchanged)",
                        filtered.len(), files.len() - filtered.len());
                    stats.skipped_files = files.len() - filtered.len();
                    filtered
                }
                Err(e) => {
                    error!("SHA1 filter failed: {}", e);
                    files.clone() // Process all if filter fails
                }
            }
        };

        // Clone files_to_process for metadata update later
        let all_files_to_process = files_to_process.clone();

        // Process in batches
        for (batch_idx, batch) in files_to_process.chunks(BATCH_SIZE).enumerate() {
            let batch_start = Instant::now();
            info!(" Processing batch {}/{} ({} files)",
                batch_idx + 1,
                (files_to_process.len() + BATCH_SIZE - 1) / BATCH_SIZE,
                batch.len()
            );

            match self.process_batch(batch, &mut stats).await {
                Ok(_) => {
                    info!(" Batch {} completed in {:?}", batch_idx + 1, batch_start.elapsed());
                }
                Err(e) => {
                    error!(" Batch {} failed: {}", batch_idx + 1, e);
                    stats.errors.push(format!("Batch {}: {}", batch_idx + 1, e));
                }
            }
        }

        // Update metadata
        if let Err(e) = self.update_file_metadata(&all_files_to_process).await {
            warn!("Failed to update file_metadata: {}", e);
        }

        stats.duration = start_time.elapsed();
        info!(" Sync complete: {} nodes, {} edges in {:?}",
            stats.total_nodes, stats.total_edges, stats.duration);

        Ok(stats)
    }

    /// Process a batch of files with parallel content fetching
    ///
    /// Uses FuturesUnordered to fetch file contents in parallel (the main I/O bottleneck)
    /// while processing/parsing sequentially to maintain state consistency.
    async fn process_batch(
        &self,
        files: &[GitHubFileBasicMetadata],
        stats: &mut SyncStatistics,
    ) -> Result<(), String> {
        let mut batch_nodes = std::collections::HashMap::new();
        let mut batch_edges = std::collections::HashMap::new();
        let mut public_pages = std::collections::HashSet::new();

        info!(" [DEBUG] Starting batch with {} files (parallel fetch)", files.len());

        // Phase 1: Fetch all file contents in parallel
        const PARALLEL_FETCHES: usize = 8;

        // Helper to create fetch future with consistent type
        fn create_fetch_future(
            content_api: Arc<EnhancedContentAPI>,
            file: GitHubFileBasicMetadata,
        ) -> std::pin::Pin<Box<dyn std::future::Future<Output = (GitHubFileBasicMetadata, Result<String, String>)> + Send>> {
            let download_url = file.download_url.clone();
            Box::pin(async move {
                let result = content_api.fetch_file_content(&download_url).await
                    .map_err(|e| format!("Failed to fetch content: {}", e));
                (file, result)
            })
        }

        let mut fetch_futures: FuturesUnordered<_> = FuturesUnordered::new();
        let mut fetched_contents: Vec<(GitHubFileBasicMetadata, Result<String, String>)> = Vec::with_capacity(files.len());
        let mut file_iter = files.iter().cloned().peekable();

        // Seed initial batch of parallel fetches
        while fetch_futures.len() < PARALLEL_FETCHES {
            if let Some(file) = file_iter.next() {
                fetch_futures.push(create_fetch_future(Arc::clone(&self.content_api), file));
            } else {
                break;
            }
        }

        // Collect all fetched contents
        while let Some((file, content_result)) = fetch_futures.next().await {
            fetched_contents.push((file, content_result));

            // Add next file to maintain parallelism
            if let Some(file) = file_iter.next() {
                fetch_futures.push(create_fetch_future(Arc::clone(&self.content_api), file));
            }
        }

        info!(" [DEBUG] Fetched {} files, now processing", fetched_contents.len());

        // Phase 2: Process fetched contents sequentially (modifies shared state)
        for (idx, (file, content_result)) in fetched_contents.into_iter().enumerate() {
            if idx % 10 == 0 && idx > 0 {
                info!("  Progress: {}/{} files in batch (nodes so far: {}, edges: {})",
                    idx, files.len(), batch_nodes.len(), batch_edges.len());
            }

            match content_result {
                Ok(content) => {
                    match self.process_fetched_file(&file, &content, &mut batch_nodes, &mut batch_edges, &mut public_pages).await {
                        Ok(()) => {
                            stats.kg_files_processed += 1;
                            debug!(" Processed {}: {} nodes total, {} edges total",
                                file.name, batch_nodes.len(), batch_edges.len());
                        }
                        Err(e) => {
                            warn!("Error processing {}: {}", file.name, e);
                            stats.errors.push(format!("{}: {}", file.name, e));
                        }
                    }
                }
                Err(e) => {
                    warn!("Error fetching {}: {}", file.name, e);
                    stats.errors.push(format!("{}: {}", file.name, e));
                }
            }
        }

        info!(" [DEBUG] After processing: {} nodes, {} edges, {} public_pages",
            batch_nodes.len(), batch_edges.len(), public_pages.len());

        // Don't filter nodes/edges - save everything to maintain graph connectivity
        // Edge cross-references between batches should be preserved
        // let nodes_before_filter = batch_nodes.len();
        // self.filter_linked_pages(&mut batch_nodes, &public_pages);
        // info!(" [DEBUG] After filter_linked_pages: {} nodes (removed {})",
        //     batch_nodes.len(), nodes_before_filter - batch_nodes.len());

        // let edges_before_filter = batch_edges.len();
        // self.filter_orphan_edges(&mut batch_edges, &batch_nodes);
        // info!(" [DEBUG] After filter_orphan_edges: {} edges (removed {})",
        //     batch_edges.len(), edges_before_filter - batch_edges.len());

        // Save batch to database
        if !batch_nodes.is_empty() {
            let node_vec: Vec<_> = batch_nodes.into_values().collect();
            let edge_vec: Vec<_> = batch_edges.into_values().collect();

            stats.total_nodes += node_vec.len();
            stats.total_edges += edge_vec.len();

            info!(" Saving batch: {} nodes, {} edges", node_vec.len(), edge_vec.len());

            let mut graph = crate::models::graph::GraphData::new();
            graph.nodes = node_vec;
            graph.edges = edge_vec;

            info!(" [DEBUG] Calling save_graph() with {} nodes, {} edges",
                graph.nodes.len(), graph.edges.len());

            self.kg_repo.save_graph(&graph).await.map_err(|e| {
                error!(" save_graph() failed: {}", e);
                format!("Failed to save batch: {}", e)
            })?;

            info!(" [DEBUG] save_graph() completed successfully");
        } else {
            warn!(" [DEBUG] Batch is EMPTY after filtering - nothing to save!");
        }

        Ok(())
    }

    /// Process a single file (fetches content internally)
    #[allow(dead_code)]
    async fn process_single_file(
        &self,
        file: &GitHubFileBasicMetadata,
        nodes: &mut std::collections::HashMap<u32, crate::models::node::Node>,
        edges: &mut std::collections::HashMap<String, crate::models::edge::Edge>,
        public_pages: &mut std::collections::HashSet<String>,
    ) -> Result<(), String> {
        // Fetch content
        let content = self.content_api
            .fetch_file_content(&file.download_url)
            .await
            .map_err(|e| format!("Failed to fetch content: {}", e))?;

        self.process_fetched_file(file, &content, nodes, edges, public_pages).await
    }

    /// Process a file with pre-fetched content (used by parallel batch processing)
    async fn process_fetched_file(
        &self,
        file: &GitHubFileBasicMetadata,
        content: &str,
        nodes: &mut std::collections::HashMap<u32, crate::models::node::Node>,
        edges: &mut std::collections::HashMap<String, crate::models::edge::Edge>,
        public_pages: &mut std::collections::HashSet<String>,
    ) -> Result<(), String> {
        debug!(" Processing file: {}", file.name);
        debug!(" Content size: {} bytes for {}", content.len(), file.name);

        // Detect file type
        let file_type = self.detect_file_type(&content);
        debug!(" Detected file type: {:?} for {}", file_type, file.name);

        let page_name = file.name.trim_end_matches(".md");

        match file_type {
            FileType::KnowledgeGraph => {
                // Process public:: true files as knowledge graph nodes
                debug!(" Parsing knowledge graph from {}", file.name);
                let mut parsed = self.kg_parser.parse(&content, &file.name)
                    .map_err(|e| format!("Parse error: {}", e))?;

                info!(" Parsed {}: {} nodes, {} edges",
                    file.name, parsed.nodes.len(), parsed.edges.len());

                //  ENRICH WITH ONTOLOGY DATA
                debug!(" Enriching graph with ontology data for {}", file.name);
                match self.enrichment_service.enrich_graph(&mut parsed, &file.path, &content).await {
                    Ok((nodes_enriched, edges_enriched)) => {
                        info!(" Enriched {}: {} nodes with owl_class_iri, {} edges with owl_property_iri",
                            file.name, nodes_enriched, edges_enriched);
                    }
                    Err(e) => {
                        warn!("  Failed to enrich {}: {} (continuing with unenriched data)", file.name, e);
                    }
                }

                // Add to public pages
                public_pages.insert(page_name.to_string());
                debug!(" Added '{}' to public_pages (total: {})", page_name, public_pages.len());

                // Add nodes from KG parser
                let nodes_before = nodes.len();
                for node in parsed.nodes {
                    debug!("   Node {}: {} (type: {:?})",
                        node.id, node.label,
                        node.metadata.get("type"));
                    nodes.insert(node.id, node);
                }
                let kg_nodes_added = nodes.len() - nodes_before;
                info!(" Added {} KG nodes from {} (total now: {})",
                    kg_nodes_added, file.name, nodes.len());

                // Add edges from KG parser
                let edges_before = edges.len();
                for edge in parsed.edges {
                    edges.insert(edge.id.clone(), edge);
                }
                if edges.len() > edges_before {
                    debug!(" Added {} edges from {}", edges.len() - edges_before, file.name);
                }

                // Also check for and parse ontology blocks in this file
                if content.contains("### OntologyBlock") {
                    debug!(" Detected OntologyBlock in {}, extracting ontology data", file.name);
                    match self.onto_parser.parse(&content, &file.name) {
                        Ok(onto_data) => {
                            info!(" Extracted from {}: {} classes, {} properties, {} axioms",
                                file.name,
                                onto_data.classes.len(),
                                onto_data.properties.len(),
                                onto_data.axioms.len());

                            // Save ontology data immediately
                            if let Err(e) = self.save_ontology_data(onto_data).await {
                                error!("Failed to save ontology data from {}: {}", file.name, e);
                            } else {
                                debug!(" Saved ontology data from {}", file.name);
                            }
                        }
                        Err(e) => {
                            debug!("Failed to parse ontology block in {}: {}", file.name, e);
                        }
                    }
                }

                Ok(())
            }
            FileType::Ontology => {
                // Process files with ontology blocks
                debug!(" Processing ontology file {}", file.name);
                match self.onto_parser.parse(&content, &file.name) {
                    Ok(onto_data) => {
                        info!(" Extracted from {}: {} classes, {} properties, {} axioms",
                            file.name,
                            onto_data.classes.len(),
                            onto_data.properties.len(),
                            onto_data.axioms.len());

                        // Save ontology data immediately
                        if let Err(e) = self.save_ontology_data(onto_data).await {
                            error!("Failed to save ontology data from {}: {}", file.name, e);
                        } else {
                            debug!(" Saved ontology data from {}", file.name);
                        }
                    }
                    Err(e) => {
                        debug!("Failed to parse ontology file {}: {}", file.name, e);
                    }
                }
                Ok(())
            }
            FileType::Skip => {
                // Skip regular notes without public:: true or ontology blocks
                debug!("  Skipped regular note: {} (no public:: true or ontology block)", file.name);
                Ok(())
            }
        }
    }

    /// Filter linked pages
    fn filter_linked_pages(
        &self,
        nodes: &mut std::collections::HashMap<u32, crate::models::node::Node>,
        public_pages: &std::collections::HashSet<String>,
    ) {
        let before = nodes.len();
        nodes.retain(|_, node| {
            match node.metadata.get("type").map(|s| s.as_str()) {
                Some("page") => true,
                Some("linked_page") => public_pages.contains(&node.metadata_id),
                _ => true,
            }
        });
        let filtered = before - nodes.len();
        if filtered > 0 {
            info!(" Filtered {} linked_page nodes", filtered);
        }
    }

    /// Filter orphan edges
    fn filter_orphan_edges(
        &self,
        edges: &mut std::collections::HashMap<String, crate::models::edge::Edge>,
        nodes: &std::collections::HashMap<u32, crate::models::node::Node>,
    ) {
        let before = edges.len();
        edges.retain(|_, edge| {
            nodes.contains_key(&edge.source) && nodes.contains_key(&edge.target)
        });
        let filtered = before - edges.len();
        if filtered > 0 {
            info!(" Filtered {} orphan edges", filtered);
        }
    }

    /// SHA1-based filtering
    async fn filter_changed_files(
        &self,
        files: &[GitHubFileBasicMetadata],
    ) -> Result<Vec<GitHubFileBasicMetadata>, String> {
        let existing = self.get_existing_file_metadata().await?;

        Ok(files
            .iter()
            .filter(|file| {
                match existing.get(&file.name) {
                    Some(existing_sha) if existing_sha == &file.sha => false,
                    _ => true,
                }
            })
            .cloned()
            .collect())
    }

    // ... (rest of helper methods unchanged)
    async fn fetch_all_markdown_files(&self) -> Result<Vec<GitHubFileBasicMetadata>, String> {
        self.content_api
            .list_markdown_files("")
            .await
            .map_err(|e| format!("GitHub API error: {}", e))
    }

    async fn get_existing_file_metadata(
        &self,
    ) -> Result<std::collections::HashMap<String, String>, String> {
        // TODO: File metadata tracking removed after Neo4j migration
        // Return empty map to process all files
        info!("[GitHubSync][SHA1] File metadata tracking disabled (Neo4j migration)");
        Ok(std::collections::HashMap::new())
    }

    async fn update_file_metadata(
        &self,
        files: &[GitHubFileBasicMetadata],
    ) -> Result<(), String> {
        // TODO: File metadata tracking removed after Neo4j migration
        // This function is now a no-op
        info!("[GitHubSync] File metadata update skipped (Neo4j migration) - {} files", files.len());
        Ok(())
    }

    fn detect_file_type(&self, content: &str) -> FileType {
        let content = content.trim_start_matches('\u{feff}');
        let lines: Vec<&str> = content.lines().take(20).collect();

        // Check for ontology blocks first (highest priority)
        if content.contains("### OntologyBlock") {
            return FileType::Ontology;
        }

        // Check for explicit public:: true (knowledge graph files)
        for line in lines.iter() {
            if line.trim() == "public:: true" {
                return FileType::KnowledgeGraph;
            }
        }

        // Default: skip regular notes without public:: true or ontology blocks
        FileType::Skip
    }

    /// Save ontology data to Neo4j and trigger reasoning pipeline
    ///
    /// This method:
    /// 1. Saves OWL classes, properties, and axioms to Neo4jOntologyRepository
    /// 2. Triggers OntologyPipelineService for automatic reasoning
    /// 3. Pipeline generates semantic constraints and uploads to GPU
    ///
    /// The reasoning pipeline runs asynchronously to avoid blocking sync.
    async fn save_ontology_data(&self, onto_data: crate::services::parsers::ontology_parser::OntologyData) -> Result<(), String> {
        use crate::ports::ontology_repository::OntologyRepository;

        // Save all ontology data to Neo4j graph database
        self.onto_repo.save_ontology(&onto_data.classes, &onto_data.properties, &onto_data.axioms).await
            .map_err(|e| format!("Failed to save ontology data: {}", e))?;

        // Log class hierarchy
        for (subclass_iri, superclass_iri) in onto_data.class_hierarchy {
            debug!("Class hierarchy: {} -> {}", subclass_iri, superclass_iri);
        }

        //  TRIGGER REASONING PIPELINE if configured
        // This spawns an async task to run CustomReasoner inference, generate
        // semantic constraints, and upload to GPU without blocking GitHub sync
        if let Some(pipeline) = &self.pipeline_service {
            info!(" Triggering ontology reasoning pipeline after ontology save");

            // Convert parsed ontology data to Ontology struct for reasoning
            let mut ontology = crate::reasoning::custom_reasoner::Ontology::default();

            // Add classes
            for class in &onto_data.classes {
                use crate::reasoning::custom_reasoner::OWLClass;
                ontology.classes.insert(
                    class.iri.clone(),
                    OWLClass {
                        iri: class.iri.clone(),
                        label: class.label.clone(),
                        parent_class_iri: None, // Will be populated from axioms
                    },
                );
            }

            // Add subclass relationships
            use crate::ports::ontology_repository::AxiomType;
            for axiom in &onto_data.axioms {
                if matches!(axiom.axiom_type, AxiomType::SubClassOf) {
                    ontology.subclass_of
                        .entry(axiom.subject.clone())
                        .or_insert_with(std::collections::HashSet::new)
                        .insert(axiom.object.clone());
                }
            }

            // Trigger the pipeline asynchronously
            let ontology_id = 1; // Using default ontology ID - multi-ontology support deferred
            let pipeline_clone = Arc::clone(pipeline);

            tokio::spawn(async move {
                match pipeline_clone.on_ontology_modified(ontology_id, ontology).await {
                    Ok(stats) => {
                        info!(
                            " Ontology pipeline complete: {} axioms inferred, {} constraints generated, GPU upload: {}",
                            stats.inferred_axioms_count,
                            stats.constraints_generated,
                            stats.gpu_upload_success
                        );
                    }
                    Err(e) => {
                        error!(" Ontology pipeline failed: {}", e);
                    }
                }
            });
        }

        Ok(())
    }
}

--------------------------------------------------------------------------------
FILE: src/services/ontology_reasoning_service.rs
PURPOSE: OWL reasoning with transitive closure and axiom inference
--------------------------------------------------------------------------------
// src/services/ontology_reasoning_service.rs
//! Ontology Reasoning Service
//!
//! Provides complete OWL reasoning using CustomReasoner with caching and persistence.
//! Infers missing axioms, computes class hierarchies, and identifies disjoint classes.
//! All data is stored in Neo4j using Neo4jOntologyRepository.

use async_trait::async_trait;
use log::{debug, info, warn};
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use std::time::Instant;
use tracing::instrument;

use crate::adapters::whelk_inference_engine::WhelkInferenceEngine; // Currently used for initialization only
use crate::ports::inference_engine::InferenceEngine;
use crate::ports::ontology_repository::{
    AxiomType, OntologyRepository, OntologyRepositoryError, OwlAxiom, OwlClass,
};
use crate::utils::time;

/// Inferred axiom with metadata about the inference process
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferredAxiom {
    pub id: String,
    pub ontology_id: String,
    pub axiom_type: String,  // "SubClassOf", "DisjointWith", "InverseOf"
    pub subject_iri: String,
    pub object_iri: Option<String>,
    pub property_iri: Option<String>,
    pub confidence: f32,
    pub inference_path: Vec<String>,
    pub user_defined: bool,
}

/// Class hierarchy representation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClassHierarchy {
    pub root_classes: Vec<String>,
    pub hierarchy: HashMap<String, ClassNode>,
}

/// Node in the class hierarchy tree
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClassNode {
    pub iri: String,
    pub label: String,
    pub parent_iri: Option<String>,
    pub children_iris: Vec<String>,
    pub node_count: usize,
    pub depth: usize,
}

/// Pair of disjoint classes
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DisjointPair {
    pub class_a: String,
    pub class_b: String,
    pub reason: String,
}

/// Cached inference result
#[derive(Debug, Clone, Serialize, Deserialize)]
struct InferenceCacheEntry {
    pub ontology_id: String,
    pub ontology_checksum: String,
    pub inferred_axioms: Vec<InferredAxiom>,
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub inference_time_ms: u64,
}

/// Ontology Reasoning Service with CustomReasoner integration
///
/// Uses CustomReasoner for actual inference operations. The WhelkInferenceEngine
/// is currently maintained for API compatibility but will be phased out.
/// All ontology data is persisted in Neo4j via Neo4jOntologyRepository.
pub struct OntologyReasoningService {
    inference_engine: Arc<WhelkInferenceEngine>, // Legacy - to be removed
    ontology_repo: Arc<dyn OntologyRepository>,
    cache: tokio::sync::RwLock<HashMap<String, InferenceCacheEntry>>,
}

impl OntologyReasoningService {
    /// Create a new OntologyReasoningService
    pub fn new(
        inference_engine: Arc<WhelkInferenceEngine>,
        ontology_repo: Arc<dyn OntologyRepository>,
    ) -> Self {
        info!("Initializing OntologyReasoningService");
        Self {
            inference_engine,
            ontology_repo,
            cache: tokio::sync::RwLock::new(HashMap::new()),
        }
    }

    /// Infer axioms from the ontology using CustomReasoner
    ///
    /// This method:
    /// 1. Loads ontology data from Neo4j
    /// 2. Runs CustomReasoner for EL++ inference
    /// 3. Caches results with checksum validation
    /// 4. Stores inferred axioms back to Neo4j
    ///
    /// # Arguments
    /// * `ontology_id` - Ontology identifier
    ///
    /// # Returns
    /// Vector of inferred axioms with confidence scores and inference paths
    #[instrument(skip(self), level = "info")]
    pub async fn infer_axioms(
        &self,
        ontology_id: &str,
    ) -> Result<Vec<InferredAxiom>, OntologyRepositoryError> {
        let start = Instant::now();
        info!("Starting axiom inference for ontology: {}", ontology_id);

        // Check cache first
        let checksum = self.calculate_ontology_checksum(ontology_id).await?;
        if let Some(cached) = self.get_cached_inference(ontology_id, &checksum).await {
            info!("Using cached inference results for {}", ontology_id);
            return Ok(cached.inferred_axioms);
        }

        // Load ontology data
        let classes = self.ontology_repo.get_classes().await?;
        let axioms = self.ontology_repo.get_axioms().await?;

        debug!(
            "Loaded {} classes and {} axioms for inference",
            classes.len(),
            axioms.len()
        );

        // Build ontology for reasoning
        use crate::reasoning::custom_reasoner::{Ontology, OWLClass};
        use std::collections::{HashMap, HashSet};

        let mut ontology = Ontology::default();
        for class in &classes {
            ontology.classes.insert(
                class.iri.clone(),
                OWLClass {
                    iri: class.iri.clone(),
                    label: class.label.clone(),
                    parent_class_iri: None,
                },
            );
        }

        // Build subclass relationships from axioms
        for axiom in &axioms {
            if matches!(axiom.axiom_type, AxiomType::SubClassOf) {
                ontology.subclass_of
                    .entry(axiom.subject.clone())
                    .or_insert_with(HashSet::new)
                    .insert(axiom.object.clone());
            }
        }

        // Run inference using CustomReasoner
        use crate::reasoning::custom_reasoner::{CustomReasoner, OntologyReasoner as _};
        let reasoner = CustomReasoner::new();
        let inference_results = reasoner.infer_axioms(&ontology)
            .map_err(|e| OntologyRepositoryError::InvalidData(format!("Inference error: {}", e)))?;

        // Convert inferred axioms to our format
        let mut inferred_axioms = Vec::new();
        for axiom in &inference_results {
            use crate::reasoning::custom_reasoner::AxiomType as CustomAxiomType;
            let axiom_type_str = match axiom.axiom_type {
                CustomAxiomType::SubClassOf => "SubClassOf",
                CustomAxiomType::DisjointWith => "DisjointWith",
                CustomAxiomType::EquivalentTo => "EquivalentTo",
                CustomAxiomType::FunctionalProperty => "FunctionalProperty",
            };

            let inferred = InferredAxiom {
                id: uuid::Uuid::new_v4().to_string(),
                ontology_id: ontology_id.to_string(),
                axiom_type: axiom_type_str.to_string(),
                subject_iri: axiom.subject.clone(),
                object_iri: axiom.object.clone(),
                property_iri: None,
                confidence: axiom.confidence,
                inference_path: vec![], // Inference path tracking deferred to future enhancement
                user_defined: false,
            };
            inferred_axioms.push(inferred);
        }

        // Store inferred axioms in database
        self.store_inferred_axioms(&inferred_axioms).await?;

        // Cache the results
        let cache_entry = InferenceCacheEntry {
            ontology_id: ontology_id.to_string(),
            ontology_checksum: checksum,
            inferred_axioms: inferred_axioms.clone(),
            timestamp: time::now(),
            inference_time_ms: start.elapsed().as_millis() as u64,
        };
        self.cache_inference_results(cache_entry).await;

        info!(
            "Inference complete: {} axioms inferred in {:?}ms",
            inferred_axioms.len(),
            start.elapsed().as_millis()
        );

        Ok(inferred_axioms)
    }

    /// Get the class hierarchy for an ontology
    ///
    /// # Arguments
    /// * `ontology_id` - Ontology identifier
    ///
    /// # Returns
    /// Complete class hierarchy with depth and node counts
    #[instrument(skip(self), level = "info")]
    pub async fn get_class_hierarchy(
        &self,
        ontology_id: &str,
    ) -> Result<ClassHierarchy, OntologyRepositoryError> {
        info!("Computing class hierarchy for ontology: {}", ontology_id);

        let classes = self.ontology_repo.get_classes().await?;
        let axioms = self.ontology_repo.get_axioms().await?;

        // Build parent-child relationships
        let mut parent_map: HashMap<String, Vec<String>> = HashMap::new();
        let mut child_map: HashMap<String, String> = HashMap::new();

        for axiom in &axioms {
            if axiom.axiom_type == AxiomType::SubClassOf {
                parent_map
                    .entry(axiom.object.clone())
                    .or_insert_with(Vec::new)
                    .push(axiom.subject.clone());
                child_map.insert(axiom.subject.clone(), axiom.object.clone());
            }
        }

        // Find root classes (classes with no parents)
        let all_iris: HashSet<String> = classes.iter().map(|c| c.iri.clone()).collect();
        let root_classes: Vec<String> = all_iris
            .iter()
            .filter(|iri| !child_map.contains_key(*iri))
            .cloned()
            .collect();

        // Build hierarchy nodes
        let mut hierarchy = HashMap::new();
        for class in &classes {
            let children = parent_map.get(&class.iri).cloned().unwrap_or_default();
            let parent = child_map.get(&class.iri).cloned();

            let node = ClassNode {
                iri: class.iri.clone(),
                label: class.label.clone().unwrap_or_else(|| class.iri.clone()),
                parent_iri: parent,
                children_iris: children.clone(),
                node_count: self.count_descendants(&children, &parent_map),
                depth: self.calculate_depth(&class.iri, &child_map),
            };
            hierarchy.insert(class.iri.clone(), node);
        }

        let class_hierarchy = ClassHierarchy {
            root_classes,
            hierarchy,
        };

        debug!(
            "Computed hierarchy with {} root classes and {} total nodes",
            class_hierarchy.root_classes.len(),
            class_hierarchy.hierarchy.len()
        );

        Ok(class_hierarchy)
    }

    /// Get disjoint class pairs
    ///
    /// # Arguments
    /// * `ontology_id` - Ontology identifier
    ///
    /// # Returns
    /// Vector of disjoint class pairs with explanations
    #[instrument(skip(self), level = "info")]
    pub async fn get_disjoint_classes(
        &self,
        ontology_id: &str,
    ) -> Result<Vec<DisjointPair>, OntologyRepositoryError> {
        info!("Finding disjoint classes for ontology: {}", ontology_id);

        let axioms = self.ontology_repo.get_axioms().await?;

        let mut disjoint_pairs = Vec::new();

        for axiom in &axioms {
            if axiom.axiom_type == AxiomType::DisjointWith {
                let pair = DisjointPair {
                    class_a: axiom.subject.clone(),
                    class_b: axiom.object.clone(),
                    reason: "Explicit DisjointWith axiom".to_string(),
                };
                disjoint_pairs.push(pair);
            }
        }

        debug!("Found {} disjoint class pairs", disjoint_pairs.len());

        Ok(disjoint_pairs)
    }

    /// Clear inference cache
    pub async fn clear_cache(&self) {
        let mut cache = self.cache.write().await;
        cache.clear();
        info!("Cleared inference cache");
    }

    /// Calculate ontology checksum for cache invalidation
    async fn calculate_ontology_checksum(
        &self,
        ontology_id: &str,
    ) -> Result<String, OntologyRepositoryError> {
        let classes = self.ontology_repo.get_classes().await?;
        let axioms = self.ontology_repo.get_axioms().await?;

        use blake3::Hasher;
        let mut hasher = Hasher::new();

        hasher.update(ontology_id.as_bytes());
        hasher.update(&classes.len().to_le_bytes());
        hasher.update(&axioms.len().to_le_bytes());

        for class in &classes {
            hasher.update(class.iri.as_bytes());
        }

        for axiom in &axioms {
            hasher.update(axiom.subject.as_bytes());
            hasher.update(axiom.object.as_bytes());
        }

        Ok(hasher.finalize().to_hex().to_string())
    }

    /// Get cached inference results if valid
    async fn get_cached_inference(
        &self,
        ontology_id: &str,
        checksum: &str,
    ) -> Option<InferenceCacheEntry> {
        let cache = self.cache.read().await;
        cache.get(ontology_id).and_then(|entry| {
            if entry.ontology_checksum == checksum {
                Some(entry.clone())
            } else {
                None
            }
        })
    }

    /// Cache inference results
    async fn cache_inference_results(&self, entry: InferenceCacheEntry) {
        let mut cache = self.cache.write().await;
        cache.insert(entry.ontology_id.clone(), entry);
    }

    /// Store inferred axioms in database
    async fn store_inferred_axioms(
        &self,
        axioms: &[InferredAxiom],
    ) -> Result<(), OntologyRepositoryError> {
        for axiom in axioms {
            let owl_axiom = OwlAxiom {
                id: None,
                axiom_type: self.string_to_axiom_type(&axiom.axiom_type),
                subject: axiom.subject_iri.clone(),
                object: axiom.object_iri.clone().unwrap_or_default(),
                annotations: HashMap::from([
                    ("inferred".to_string(), "true".to_string()),
                    ("confidence".to_string(), axiom.confidence.to_string()),
                ]),
            };

            // Store in owl_axioms table with user_defined=false
            // Note: The table doesn't have user_defined column yet,
            // we'll use annotations to track this
            self.ontology_repo.add_axiom(&owl_axiom).await?;
        }

        Ok(())
    }

    /// Convert axiom type enum to string
    fn axiom_type_to_string(&self, axiom_type: &AxiomType) -> String {
        match axiom_type {
            AxiomType::SubClassOf => "SubClassOf".to_string(),
            AxiomType::EquivalentClass => "EquivalentClass".to_string(),
            AxiomType::DisjointWith => "DisjointWith".to_string(),
            AxiomType::ObjectPropertyAssertion => "ObjectPropertyAssertion".to_string(),
            AxiomType::DataPropertyAssertion => "DataPropertyAssertion".to_string(),
        }
    }

    /// Convert string to axiom type enum
    fn string_to_axiom_type(&self, s: &str) -> AxiomType {
        match s {
            "SubClassOf" => AxiomType::SubClassOf,
            "EquivalentClass" => AxiomType::EquivalentClass,
            "DisjointWith" => AxiomType::DisjointWith,
            "ObjectPropertyAssertion" => AxiomType::ObjectPropertyAssertion,
            "DataPropertyAssertion" => AxiomType::DataPropertyAssertion,
            _ => AxiomType::SubClassOf, // default
        }
    }

    /// Count total descendants in hierarchy
    fn count_descendants(
        &self,
        children: &[String],
        parent_map: &HashMap<String, Vec<String>>,
    ) -> usize {
        let mut count = children.len();
        for child in children {
            if let Some(grandchildren) = parent_map.get(child) {
                count += self.count_descendants(grandchildren, parent_map);
            }
        }
        count
    }

    /// Calculate depth in hierarchy
    fn calculate_depth(&self, iri: &str, child_map: &HashMap<String, String>) -> usize {
        let mut depth = 0;
        let mut current = iri;

        while let Some(parent) = child_map.get(current) {
            depth += 1;
            current = parent;

            // Prevent infinite loops
            if depth > 100 {
                warn!("Possible cycle detected in hierarchy for {}", iri);
                break;
            }
        }

        depth
    }
}

// TODO: Update all tests to use Neo4j test containers
#[cfg(test)]
mod tests {
    use super::*;
    use std::collections::HashMap;

    // TODO: Update tests to use Neo4j test containers
    // #[tokio::test]
    // async fn test_create_service() {
    //     let engine = Arc::new(WhelkInferenceEngine::new());
    //     let repo = Arc::new(/* TODO: Use Neo4j test container */);
    //
    //     let service = OntologyReasoningService::new(engine, repo);
    //
    //     // Service should initialize without errors
    //     service.clear_cache().await;
    // }

    // #[tokio::test]
    // async fn test_hierarchy_depth_calculation() {
    //     let engine = Arc::new(WhelkInferenceEngine::new());
    //     let repo = Arc::new(/* TODO: Use Neo4j test container */);
    //
    //     let service = OntologyReasoningService::new(engine, repo);
    //
    //     let mut child_map = HashMap::new();
    //     child_map.insert("child".to_string(), "parent".to_string());
    //     child_map.insert("parent".to_string(), "grandparent".to_string());
    //
    //     let depth = service.calculate_depth("child", &child_map);
    //     assert_eq!(depth, 2);
    // }

    // #[tokio::test]
    // async fn test_descendant_counting() {
    //     // Test disabled until Neo4j test containers are available
    //     let engine = Arc::new(WhelkInferenceEngine::new());
    //     let repo = Arc::new(/* TODO: Use Neo4j test container */);
    //
    //     let service = OntologyReasoningService::new(engine, repo);
    //
    //     let mut parent_map = HashMap::new();
    //     parent_map.insert(
    //         "parent".to_string(),
    //         vec!["child1".to_string(), "child2".to_string()],
    //     );
    //     parent_map.insert("child1".to_string(), vec!["grandchild".to_string()]);
    //
    //     let count = service.count_descendants(
    //         &vec!["child1".to_string(), "child2".to_string()],
    //         &parent_map,
    //     );
    //
    //     // 2 children + 1 grandchild = 3 total descendants
    //     assert_eq!(count, 3);
    // }
}

--------------------------------------------------------------------------------
FILE: src/services/ontology_enrichment_service.rs
PURPOSE: Semantic enrichment of graph data with ontology
--------------------------------------------------------------------------------
// src/services/ontology_enrichment_service.rs
//! Ontology Enrichment Service
//!
//! Enriches parsed graph data with ontology information (owl_class_iri, owl_property_iri)
//! AFTER parsing but BEFORE saving to database.

use std::sync::Arc;
use log::{info, debug, warn};

use crate::models::graph::GraphData;
use crate::services::ontology_reasoner::{OntologyReasoner, FileContext};
use crate::services::edge_classifier::{EdgeClassifier, EdgeContext};

/// Service that enriches graph data with ontology classifications
pub struct OntologyEnrichmentService {
    reasoner: Arc<OntologyReasoner>,
    classifier: Arc<EdgeClassifier>,
}

impl OntologyEnrichmentService {
    /// Create a new enrichment service
    pub fn new(
        reasoner: Arc<OntologyReasoner>,
        classifier: Arc<EdgeClassifier>,
    ) -> Self {
        info!("Initializing OntologyEnrichmentService");
        Self {
            reasoner,
            classifier,
        }
    }

    /// Enrich a graph with ontology information
    ///
    /// This modifies the graph in-place, adding:
    /// - `owl_class_iri` to all nodes based on file path/content analysis
    /// - `owl_property_iri` to all edges based on context analysis
    ///
    /// # Arguments
    /// * `graph` - Mutable reference to graph data
    /// * `file_path` - Path to the source markdown file
    /// * `content` - Full markdown content
    ///
    /// # Returns
    /// Number of nodes and edges enriched
    pub async fn enrich_graph(
        &self,
        graph: &mut GraphData,
        file_path: &str,
        content: &str,
    ) -> Result<(usize, usize), String> {
        info!("Enriching graph from file: {}", file_path);

        let nodes_enriched = self.enrich_nodes(graph, file_path, content).await?;
        let edges_enriched = self.enrich_edges(graph, content).await?;

        info!(
            "Enriched {} nodes and {} edges with ontology data",
            nodes_enriched, edges_enriched
        );

        Ok((nodes_enriched, edges_enriched))
    }

    /// Enrich all nodes in the graph with owl_class_iri
    async fn enrich_nodes(
        &self,
        graph: &mut GraphData,
        file_path: &str,
        content: &str,
    ) -> Result<usize, String> {
        let mut enriched_count = 0;

        // Parse frontmatter/metadata if present
        let metadata = self.extract_frontmatter(content);

        for node in &mut graph.nodes {
            // Skip nodes that already have owl_class_iri
            if node.owl_class_iri.is_some() {
                continue;
            }

            // Infer class for this node
            let class_iri = self
                .reasoner
                .infer_class(file_path, content, metadata.as_ref())
                .await
                .map_err(|e| format!("Failed to infer class: {}", e))?;

            if let Some(iri) = class_iri {
                // Ensure the class exists in ontology
                self.reasoner
                    .ensure_class_exists(&iri)
                    .await
                    .map_err(|e| format!("Failed to ensure class exists: {}", e))?;

                node.owl_class_iri = Some(iri.clone());
                enriched_count += 1;

                debug!(
                    "Enriched node '{}' with class: {}",
                    node.label, iri
                );

                // Also update visual properties based on class
                self.update_node_visuals_by_class(node, &iri);
            }
        }

        Ok(enriched_count)
    }

    /// Enrich all edges in the graph with owl_property_iri
    async fn enrich_edges(
        &self,
        graph: &mut GraphData,
        content: &str,
    ) -> Result<usize, String> {
        let mut enriched_count = 0;

        // Build node ID to node map for lookups
        let node_map: std::collections::HashMap<u32, &crate::models::node::Node> =
            graph.nodes.iter().map(|n| (n.id, n)).collect();

        for edge in &mut graph.edges {
            // Skip edges that already have owl_property_iri
            if edge.owl_property_iri.is_some() {
                continue;
            }

            // Get source and target nodes
            let source_node = node_map.get(&edge.source);
            let target_node = node_map.get(&edge.target);

            if let (Some(src), Some(tgt)) = (source_node, target_node) {
                // Extract context around the link
                let context = self.extract_link_context(content, &tgt.label);

                // Classify the edge
                let property_iri = self.classifier.classify_edge(
                    &src.label,
                    &tgt.label,
                    src.owl_class_iri.as_deref(),
                    tgt.owl_class_iri.as_deref(),
                    &context,
                );

                if let Some(iri) = property_iri {
                    edge.owl_property_iri = Some(iri.clone());
                    enriched_count += 1;

                    debug!(
                        "Enriched edge {} -> {} with property: {}",
                        src.label, tgt.label, iri
                    );
                }
            }
        }

        Ok(enriched_count)
    }

    /// Extract frontmatter metadata from markdown
    fn extract_frontmatter(
        &self,
        content: &str,
    ) -> Option<std::collections::HashMap<String, String>> {
        // Simple frontmatter parser (YAML-style)
        // Looks for:
        // ---
        // key: value
        // ---

        let mut metadata = std::collections::HashMap::new();

        if !content.starts_with("---") {
            return None;
        }

        let lines: Vec<&str> = content.lines().collect();
        let mut in_frontmatter = false;
        let mut frontmatter_found = false;

        for line in lines.iter().skip(1) {
            if line.trim() == "---" {
                if !in_frontmatter && !frontmatter_found {
                    in_frontmatter = true;
                    frontmatter_found = true;
                } else {
                    break; // End of frontmatter
                }
            } else if in_frontmatter {
                if let Some((key, value)) = line.split_once(':') {
                    metadata.insert(
                        key.trim().to_string(),
                        value.trim().to_string(),
                    );
                }
            }
        }

        if metadata.is_empty() {
            None
        } else {
            Some(metadata)
        }
    }

    /// Extract context around a link in markdown content
    fn extract_link_context(&self, content: &str, link_target: &str) -> String {
        // Find the line containing the link
        for line in content.lines() {
            if line.contains(&format!("[[{}]]", link_target)) {
                return line.to_string();
            }
        }

        // If not found as [[link]], try with aliases
        for line in content.lines() {
            if line.contains(link_target) {
                return line.to_string();
            }
        }

        String::new()
    }

    /// Update node visual properties based on its OWL class
    fn update_node_visuals_by_class(&self, node: &mut crate::models::node::Node, class_iri: &str) {
        // Match the visual properties from OntologyConverter
        let (color, size) = if class_iri.contains("Person") || class_iri.contains("Individual") {
            ("#90EE90", 8.0) // Light green, small
        } else if class_iri.contains("Company") || class_iri.contains("Organization") {
            ("#4169E1", 12.0) // Royal blue, large
        } else if class_iri.contains("Project") || class_iri.contains("Work") {
            ("#FFA500", 10.0) // Orange, medium
        } else if class_iri.contains("Concept") || class_iri.contains("Idea") {
            ("#9370DB", 9.0) // Medium purple, small-medium
        } else if class_iri.contains("Technology") || class_iri.contains("Tool") {
            ("#00CED1", 11.0) // Dark turquoise, medium-large
        } else {
            ("#CCCCCC", 10.0) // Gray, default medium
        };

        node.color = Some(color.to_string());
        node.size = Some(size as f32);

        // Update node type to reflect ontology class
        node.node_type = Some("ontology_node".to_string());
    }

    /// Batch enrich multiple graphs
    pub async fn enrich_graphs_batch(
        &self,
        graphs: Vec<(GraphData, String, String)>, // (graph, path, content)
    ) -> Vec<Result<(usize, usize), String>> {
        let mut results = Vec::with_capacity(graphs.len());

        for (mut graph, path, content) in graphs {
            let result = self.enrich_graph(&mut graph, &path, &content).await;
            results.push(result);
        }

        results
    }
}

// TODO: Update tests to use Neo4j test containers
// Tests temporarily disabled - need to be updated to use Neo4j instead of SQLite
// #[cfg(test)]
// mod tests {
//     use super::*;
//
//     #[test]
//     fn test_extract_frontmatter() {
//         let content = r#"---
// type: person
// category: engineer
// ---
//
// # Content here"#;
//
//         let service = OntologyEnrichmentService::new(
//             Arc::new(OntologyReasoner::new(
//                 Arc::new(crate::adapters::whelk_inference_engine::WhelkInferenceEngine::new()),
//                 Arc::new(crate::repositories::unified_ontology_repository::UnifiedOntologyRepository::new(":memory:").unwrap())
//             )),
//             Arc::new(EdgeClassifier::new()),
//         );
//
//         let metadata = service.extract_frontmatter(content);
//         assert!(metadata.is_some());
//         let meta = metadata.unwrap();
//         assert_eq!(meta.get("type"), Some(&"person".to_string()));
//         assert_eq!(meta.get("category"), Some(&"engineer".to_string()));
//     }
//
//     #[test]
//     fn test_extract_link_context() {
//         let content = "Tim Cook is the CEO of [[Apple Inc]].";
//
//         let service = OntologyEnrichmentService::new(
//             Arc::new(OntologyReasoner::new(
//                 Arc::new(crate::adapters::whelk_inference_engine::WhelkInferenceEngine::new()),
//                 Arc::new(crate::repositories::unified_ontology_repository::UnifiedOntologyRepository::new(":memory:").unwrap())
//             )),
//             Arc::new(EdgeClassifier::new()),
//         );
//
//         let context = service.extract_link_context(content, "Apple Inc");
//         assert_eq!(context, "Tim Cook is the CEO of [[Apple Inc]].");
//     }
// }

--------------------------------------------------------------------------------
FILE: src/services/jss_sync_service.rs
PURPOSE: JavaScript Solid Server synchronization
--------------------------------------------------------------------------------
//! JSS Sync Service
//!
//! Synchronizes ontology data from Neo4j (authoritative source) to JavaScript Solid Server (JSS) pods.
//! Provides unidirectional sync: Neo4j -> JSS for federation/distribution.
//!
//! Architecture:
//! - Neo4j is the authoritative source of truth for ontology data
//! - JSS serves as the distribution/federation layer for Solid protocol access
//! - Sync is unidirectional: changes flow from Neo4j to JSS only
//!
//! Sync Strategies:
//! - Full sync on startup (ensures JSS mirrors Neo4j state)
//! - Incremental sync on Neo4j change events
//! - Scheduled periodic sync (configurable interval, default 5 minutes)
//!
//! Features:
//! - Sync ontology classes, properties, and axioms to /public/ontology/
//! - Sync user contributions to personal pods at /pods/{npub}/contributions/
//! - Conflict resolution: Neo4j always wins (unidirectional)
//! - Metrics and logging for monitoring sync operations
//! - Turtle/JSON-LD serialization for Solid LDP containers

use chrono::{DateTime, Utc};
use log::{debug, error, info, warn};
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};
use thiserror::Error;
use tokio::sync::{mpsc, RwLock};
use tokio::time::interval;

use crate::handlers::solid_proxy_handler::JssConfig;
use crate::ports::ontology_repository::{OntologyRepository, OwlClass, OwlProperty, OwlAxiom};

// ============================================================================
// Error Types
// ============================================================================

/// JSS Sync Service errors
#[derive(Debug, Error)]
pub enum JssSyncError {
    #[error("HTTP request failed: {0}")]
    HttpError(#[from] reqwest::Error),

    #[error("Serialization error: {0}")]
    SerializationError(String),

    #[error("Neo4j query failed: {0}")]
    Neo4jError(String),

    #[error("JSS server error: {status} - {message}")]
    JssServerError { status: u16, message: String },

    #[error("Resource not found: {0}")]
    NotFound(String),

    #[error("Authentication required")]
    AuthenticationRequired,

    #[error("Sync conflict: {0}")]
    SyncConflict(String),

    #[error("Repository error: {0}")]
    RepositoryError(String),

    #[error("Service not started")]
    NotStarted,
}

pub type Result<T> = std::result::Result<T, JssSyncError>;

// ============================================================================
// Data Types
// ============================================================================

/// Ontology resource for syncing to JSS
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OntologyResource {
    pub iri: String,
    pub label: Option<String>,
    pub description: Option<String>,
    pub resource_type: OntologyResourceType,
    pub parent_iris: Vec<String>,
    pub properties: HashMap<String, String>,
    pub source_domain: Option<String>,
    pub quality_score: Option<f32>,
    pub last_modified: Option<DateTime<Utc>>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum OntologyResourceType {
    Class,
    Property,
    Individual,
    Axiom,
}

/// User contribution for syncing to personal pod
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UserContribution {
    pub user_npub: String,
    pub contribution_id: String,
    pub contribution_type: ContributionType,
    pub target_iri: String,
    pub proposed_changes: serde_json::Value,
    pub status: ContributionStatus,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum ContributionType {
    NewClass,
    UpdateClass,
    NewProperty,
    UpdateProperty,
    NewRelationship,
    Annotation,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum ContributionStatus {
    Draft,
    Proposed,
    UnderReview,
    Accepted,
    Rejected,
}

/// Neo4j change event for triggering sync
#[derive(Debug, Clone)]
pub struct Neo4jChangeEvent {
    pub change_type: Neo4jChangeType,
    pub affected_iris: Vec<String>,
    pub timestamp: DateTime<Utc>,
    /// Source of the change for audit trail
    pub source: ChangeSource,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum Neo4jChangeType {
    ClassCreated,
    ClassUpdated,
    ClassDeleted,
    PropertyCreated,
    PropertyUpdated,
    PropertyDeleted,
    RelationshipCreated,
    RelationshipDeleted,
    AxiomAdded,
    AxiomRemoved,
    BulkImport,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum ChangeSource {
    GitHubSync,
    LocalMarkdownSync,
    UserContribution,
    Inference,
    Manual,
}

// ============================================================================
// Sync Status & Metrics
// ============================================================================

/// Sync status for tracking progress
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SyncStatus {
    pub last_full_sync: Option<DateTime<Utc>>,
    pub last_incremental_sync: Option<DateTime<Utc>>,
    pub resources_synced: u64,
    pub sync_in_progress: bool,
    pub last_error: Option<String>,
    pub pending_changes: u64,
    pub sync_type: Option<String>,
}

/// Detailed sync metrics for monitoring
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SyncMetrics {
    // Counters (total since startup)
    pub total_full_syncs: u64,
    pub total_incremental_syncs: u64,
    pub total_resources_synced: u64,
    pub total_errors: u64,
    pub total_conflicts_resolved: u64,

    // Current state
    pub classes_in_neo4j: u64,
    pub classes_in_jss: u64,
    pub properties_in_neo4j: u64,
    pub properties_in_jss: u64,

    // Timing
    pub avg_sync_duration_ms: f64,
    pub last_sync_duration_ms: u64,
    pub uptime_secs: u64,

    // Health
    pub neo4j_connected: bool,
    pub jss_connected: bool,
    pub last_neo4j_check: Option<DateTime<Utc>>,
    pub last_jss_check: Option<DateTime<Utc>>,
}

/// Internal metrics counters (atomic for thread safety)
struct MetricsCounters {
    total_full_syncs: AtomicU64,
    total_incremental_syncs: AtomicU64,
    total_resources_synced: AtomicU64,
    total_errors: AtomicU64,
    total_conflicts_resolved: AtomicU64,
    total_sync_duration_ms: AtomicU64,
    sync_count_for_avg: AtomicU64,
}

impl MetricsCounters {
    fn new() -> Self {
        Self {
            total_full_syncs: AtomicU64::new(0),
            total_incremental_syncs: AtomicU64::new(0),
            total_resources_synced: AtomicU64::new(0),
            total_errors: AtomicU64::new(0),
            total_conflicts_resolved: AtomicU64::new(0),
            total_sync_duration_ms: AtomicU64::new(0),
            sync_count_for_avg: AtomicU64::new(0),
        }
    }
}

// ============================================================================
// Configuration
// ============================================================================

/// Configuration for JSS sync service
#[derive(Debug, Clone)]
pub struct JssSyncConfig {
    pub jss_config: JssConfig,
    /// Interval for periodic sync (seconds)
    pub sync_interval_secs: u64,
    /// Batch size for resource syncing
    pub batch_size: usize,
    /// Path for public ontology resources
    pub public_ontology_path: String,
    /// Path for user contributions
    pub contributions_path: String,
    /// Enable automatic periodic sync
    pub enable_auto_sync: bool,
    /// Enable full sync on startup
    pub enable_startup_sync: bool,
    /// Timeout for HTTP requests (seconds)
    pub http_timeout_secs: u64,
    /// Maximum retries for failed sync operations
    pub max_retries: u32,
    /// Delay between retries (milliseconds)
    pub retry_delay_ms: u64,
}

impl Default for JssSyncConfig {
    fn default() -> Self {
        Self {
            jss_config: JssConfig::from_env(),
            sync_interval_secs: 300, // 5 minutes
            batch_size: 100,
            public_ontology_path: "/public/ontology".to_string(),
            contributions_path: "/contributions".to_string(),
            enable_auto_sync: true,
            enable_startup_sync: true,
            http_timeout_secs: 30,
            max_retries: 3,
            retry_delay_ms: 1000,
        }
    }
}

// ============================================================================
// JSS Sync Service
// ============================================================================

/// JSS Sync Service
///
/// Manages unidirectional synchronization from Neo4j (authoritative) to JSS (distribution).
///
/// Sync Flow:
/// 1. Full sync on startup (if enabled)
/// 2. Listen for Neo4j change events via channel
/// 3. Periodic sync at configured interval
/// 4. Incremental sync triggered by change events
pub struct JssSyncService {
    config: JssSyncConfig,
    http_client: Client,
    ontology_repo: Option<Arc<dyn OntologyRepository>>,
    sync_status: Arc<RwLock<SyncStatus>>,
    metrics: Arc<MetricsCounters>,
    change_tx: mpsc::Sender<Neo4jChangeEvent>,
    change_rx: Arc<RwLock<mpsc::Receiver<Neo4jChangeEvent>>>,
    shutdown_tx: Arc<RwLock<Option<mpsc::Sender<()>>>>,
    started_at: Arc<RwLock<Option<Instant>>>,

    // Track last known state for conflict detection
    last_sync_checksums: Arc<RwLock<HashMap<String, String>>>,
}

impl JssSyncService {
    /// Create a new JSS sync service
    pub fn new(config: JssSyncConfig) -> Self {
        let (change_tx, change_rx) = mpsc::channel(1000);

        let http_client = Client::builder()
            .timeout(Duration::from_secs(config.http_timeout_secs))
            .build()
            .expect("Failed to create HTTP client");

        info!(
            "JSS Sync Service initialized - JSS URL: {}, auto-sync: {}, interval: {}s",
            config.jss_config.base_url,
            config.enable_auto_sync,
            config.sync_interval_secs
        );

        Self {
            config,
            http_client,
            ontology_repo: None,
            sync_status: Arc::new(RwLock::new(SyncStatus {
                last_full_sync: None,
                last_incremental_sync: None,
                resources_synced: 0,
                sync_in_progress: false,
                last_error: None,
                pending_changes: 0,
                sync_type: None,
            })),
            metrics: Arc::new(MetricsCounters::new()),
            change_tx,
            change_rx: Arc::new(RwLock::new(change_rx)),
            shutdown_tx: Arc::new(RwLock::new(None)),
            started_at: Arc::new(RwLock::new(None)),
            last_sync_checksums: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    /// Create with default configuration from environment
    pub fn from_env() -> Self {
        Self::new(JssSyncConfig::default())
    }

    /// Set the ontology repository for Neo4j access
    pub fn with_ontology_repository(mut self, repo: Arc<dyn OntologyRepository>) -> Self {
        self.ontology_repo = Some(repo);
        self
    }

    /// Get sender for Neo4j change events
    pub fn get_change_sender(&self) -> mpsc::Sender<Neo4jChangeEvent> {
        self.change_tx.clone()
    }

    /// Get current sync status
    pub async fn get_status(&self) -> SyncStatus {
        self.sync_status.read().await.clone()
    }

    /// Get detailed sync metrics
    pub async fn get_metrics(&self) -> SyncMetrics {
        let started_at = *self.started_at.read().await;
        let uptime = started_at.map(|s| s.elapsed().as_secs()).unwrap_or(0);

        let total_sync_duration = self.metrics.total_sync_duration_ms.load(Ordering::Relaxed);
        let sync_count = self.metrics.sync_count_for_avg.load(Ordering::Relaxed);
        let avg_duration = if sync_count > 0 {
            total_sync_duration as f64 / sync_count as f64
        } else {
            0.0
        };

        SyncMetrics {
            total_full_syncs: self.metrics.total_full_syncs.load(Ordering::Relaxed),
            total_incremental_syncs: self.metrics.total_incremental_syncs.load(Ordering::Relaxed),
            total_resources_synced: self.metrics.total_resources_synced.load(Ordering::Relaxed),
            total_errors: self.metrics.total_errors.load(Ordering::Relaxed),
            total_conflicts_resolved: self.metrics.total_conflicts_resolved.load(Ordering::Relaxed),
            classes_in_neo4j: 0, // Updated during sync
            classes_in_jss: 0,   // Updated during sync
            properties_in_neo4j: 0,
            properties_in_jss: 0,
            avg_sync_duration_ms: avg_duration,
            last_sync_duration_ms: 0, // Updated during sync
            uptime_secs: uptime,
            neo4j_connected: self.ontology_repo.is_some(),
            jss_connected: true, // Updated during health check
            last_neo4j_check: None,
            last_jss_check: None,
        }
    }

    /// Start the sync service with background workers
    pub async fn start(&self) -> Result<()> {
        info!("Starting JSS Sync Service...");

        let (shutdown_tx, mut shutdown_rx) = mpsc::channel::<()>(1);
        *self.shutdown_tx.write().await = Some(shutdown_tx);
        *self.started_at.write().await = Some(Instant::now());

        // Perform full sync on startup if enabled
        if self.config.enable_startup_sync {
            info!("Performing full sync on startup...");
            if let Err(e) = self.full_sync().await {
                error!("Startup full sync failed: {}", e);
                self.metrics.total_errors.fetch_add(1, Ordering::Relaxed);
            }
        }

        // Start periodic sync worker if enabled
        if self.config.enable_auto_sync {
            let config = self.config.clone();
            let http_client = self.http_client.clone();
            let sync_status = self.sync_status.clone();
            let metrics = self.metrics.clone();
            let ontology_repo = self.ontology_repo.clone();
            let checksums = self.last_sync_checksums.clone();

            let mut shutdown_rx_clone = {
                let (tx, rx) = mpsc::channel::<()>(1);
                // We'll use a separate channel for the periodic worker
                rx
            };

            tokio::spawn(async move {
                let mut sync_interval = interval(Duration::from_secs(config.sync_interval_secs));

                loop {
                    tokio::select! {
                        _ = sync_interval.tick() => {
                            debug!("Running periodic ontology sync...");
                            if let Err(e) = Self::run_periodic_sync(
                                &config,
                                &http_client,
                                &sync_status,
                                &metrics,
                                ontology_repo.as_ref(),
                                &checksums,
                            ).await {
                                error!("Periodic sync failed: {}", e);
                                metrics.total_errors.fetch_add(1, Ordering::Relaxed);
                            }
                        }
                        _ = shutdown_rx_clone.recv() => {
                            info!("Periodic sync worker received shutdown signal");
                            break;
                        }
                    }
                }
            });
        }

        // Start change event worker
        let change_rx = self.change_rx.clone();
        let config = self.config.clone();
        let http_client = self.http_client.clone();
        let sync_status = self.sync_status.clone();
        let metrics = self.metrics.clone();
        let ontology_repo = self.ontology_repo.clone();
        let checksums = self.last_sync_checksums.clone();

        tokio::spawn(async move {
            let mut rx = change_rx.write().await;

            while let Some(event) = rx.recv().await {
                info!(
                    "Processing Neo4j change event: {:?} affecting {} resources",
                    event.change_type,
                    event.affected_iris.len()
                );

                // Update pending changes count
                {
                    let mut status = sync_status.write().await;
                    status.pending_changes += event.affected_iris.len() as u64;
                }

                // Perform incremental sync for affected resources
                if let Err(e) = Self::incremental_sync(
                    &config,
                    &http_client,
                    &sync_status,
                    &metrics,
                    ontology_repo.as_ref(),
                    &event,
                    &checksums,
                ).await {
                    error!("Incremental sync failed for event {:?}: {}", event.change_type, e);
                    metrics.total_errors.fetch_add(1, Ordering::Relaxed);

                    let mut status = sync_status.write().await;
                    status.last_error = Some(format!("{}", e));
                }
            }
        });

        info!("JSS Sync Service started successfully");
        Ok(())
    }

    /// Stop the sync service
    pub async fn stop(&self) {
        info!("Stopping JSS Sync Service...");

        if let Some(tx) = self.shutdown_tx.write().await.take() {
            let _ = tx.send(()).await;
        }

        info!("JSS Sync Service stopped");
    }

    /// Perform a full sync of all ontology data from Neo4j to JSS
    pub async fn full_sync(&self) -> Result<u64> {
        let start_time = Instant::now();
        info!("Starting full sync from Neo4j to JSS...");

        // Update status
        {
            let mut status = self.sync_status.write().await;
            status.sync_in_progress = true;
            status.sync_type = Some("full".to_string());
        }

        let repo = self.ontology_repo.as_ref()
            .ok_or(JssSyncError::RepositoryError("Ontology repository not configured".to_string()))?;

        // Load all classes from Neo4j
        let classes = repo.list_owl_classes().await
            .map_err(|e| JssSyncError::Neo4jError(format!("Failed to load classes: {}", e)))?;

        info!("Loaded {} classes from Neo4j", classes.len());

        // Load all properties from Neo4j
        let properties = repo.list_owl_properties().await
            .map_err(|e| JssSyncError::Neo4jError(format!("Failed to load properties: {}", e)))?;

        info!("Loaded {} properties from Neo4j", properties.len());

        // Convert to OntologyResource format
        let mut resources: Vec<OntologyResource> = Vec::with_capacity(classes.len() + properties.len());

        for class in &classes {
            resources.push(Self::owl_class_to_resource(class));
        }

        for prop in &properties {
            resources.push(Self::owl_property_to_resource(prop));
        }

        // Ensure public ontology container exists
        self.ensure_container_exists(&self.config.public_ontology_path).await?;

        // Sync all resources to JSS
        let synced_count = self.sync_resources_to_jss(&resources).await?;

        // Update checksums for conflict detection
        {
            let mut checksums = self.last_sync_checksums.write().await;
            for resource in &resources {
                let checksum = Self::compute_resource_checksum(resource);
                checksums.insert(resource.iri.clone(), checksum);
            }
        }

        let duration = start_time.elapsed();

        // Update metrics
        self.metrics.total_full_syncs.fetch_add(1, Ordering::Relaxed);
        self.metrics.total_resources_synced.fetch_add(synced_count, Ordering::Relaxed);
        self.metrics.total_sync_duration_ms.fetch_add(duration.as_millis() as u64, Ordering::Relaxed);
        self.metrics.sync_count_for_avg.fetch_add(1, Ordering::Relaxed);

        // Update status
        {
            let mut status = self.sync_status.write().await;
            status.sync_in_progress = false;
            status.last_full_sync = Some(Utc::now());
            status.resources_synced += synced_count;
            status.last_error = None;
            status.sync_type = None;
        }

        info!(
            "Full sync completed: {} resources synced in {}ms",
            synced_count,
            duration.as_millis()
        );

        Ok(synced_count)
    }

    /// Sync ontology classes and properties to public JSS pod
    pub async fn sync_ontology_to_public(&self, resources: &[OntologyResource]) -> Result<u64> {
        info!("Syncing {} ontology resources to public pod", resources.len());

        // Update sync status
        {
            let mut status = self.sync_status.write().await;
            status.sync_in_progress = true;
        }

        // Ensure public ontology container exists
        self.ensure_container_exists(&self.config.public_ontology_path).await?;

        let synced_count = self.sync_resources_to_jss(resources).await?;

        // Update sync status
        {
            let mut status = self.sync_status.write().await;
            status.sync_in_progress = false;
            status.last_incremental_sync = Some(Utc::now());
            status.resources_synced += synced_count;
            status.last_error = None;
        }

        info!("Synced {} ontology resources to public pod", synced_count);
        Ok(synced_count)
    }

    /// Sync user contributions to their personal pod
    pub async fn sync_user_contributions(
        &self,
        user_npub: &str,
        contributions: &[UserContribution],
    ) -> Result<u64> {
        info!(
            "Syncing {} contributions for user {}",
            contributions.len(),
            user_npub
        );

        let mut synced_count = 0u64;

        // Build user-specific path
        let user_path = format!("/pods/{}{}", user_npub, self.config.contributions_path);

        // Ensure contributions container exists
        self.ensure_container_exists(&user_path).await?;

        for contribution in contributions {
            match self.sync_contribution_to_jss(&user_path, contribution).await {
                Ok(_) => {
                    synced_count += 1;
                    debug!("Synced contribution: {}", contribution.contribution_id);
                }
                Err(e) => {
                    warn!(
                        "Failed to sync contribution {}: {}",
                        contribution.contribution_id, e
                    );
                }
            }
        }

        info!("Synced {} contributions for user {}", synced_count, user_npub);
        Ok(synced_count)
    }

    /// Notify of Neo4j changes to trigger sync
    pub async fn notify_neo4j_change(&self, event: Neo4jChangeEvent) -> Result<()> {
        self.change_tx
            .send(event)
            .await
            .map_err(|e| JssSyncError::SerializationError(format!("Failed to send change event: {}", e)))
    }

    /// Check if JSS is reachable
    pub async fn check_jss_health(&self) -> bool {
        let health_url = format!("{}/health", self.config.jss_config.base_url);
        match self.http_client.get(&health_url).send().await {
            Ok(response) => response.status().is_success(),
            Err(_) => false,
        }
    }

    // ========================================================================
    // Private Implementation
    // ========================================================================

    /// Run periodic sync (called by background worker)
    async fn run_periodic_sync(
        config: &JssSyncConfig,
        http_client: &Client,
        sync_status: &Arc<RwLock<SyncStatus>>,
        metrics: &Arc<MetricsCounters>,
        ontology_repo: Option<&Arc<dyn OntologyRepository>>,
        checksums: &Arc<RwLock<HashMap<String, String>>>,
    ) -> Result<()> {
        let start_time = Instant::now();

        let repo = ontology_repo
            .ok_or(JssSyncError::RepositoryError("Repository not configured".to_string()))?;

        // Load current state from Neo4j
        let classes = repo.list_owl_classes().await
            .map_err(|e| JssSyncError::Neo4jError(format!("{}", e)))?;

        let mut resources_to_sync = Vec::new();

        {
            let current_checksums = checksums.read().await;

            for class in &classes {
                let resource = Self::owl_class_to_resource(class);
                let new_checksum = Self::compute_resource_checksum(&resource);

                // Only sync if changed
                if current_checksums.get(&resource.iri) != Some(&new_checksum) {
                    resources_to_sync.push(resource);
                }
            }
        }

        if resources_to_sync.is_empty() {
            debug!("No changes detected, skipping periodic sync");
            return Ok(());
        }

        info!("Periodic sync: {} resources changed", resources_to_sync.len());

        // Sync changed resources
        let mut synced = 0u64;
        for resource in &resources_to_sync {
            if let Err(e) = Self::sync_single_resource(config, http_client, resource).await {
                warn!("Failed to sync resource {}: {}", resource.iri, e);
            } else {
                synced += 1;
            }
        }

        // Update checksums
        {
            let mut current_checksums = checksums.write().await;
            for resource in &resources_to_sync {
                let checksum = Self::compute_resource_checksum(resource);
                current_checksums.insert(resource.iri.clone(), checksum);
            }
        }

        let duration = start_time.elapsed();

        // Update metrics
        metrics.total_incremental_syncs.fetch_add(1, Ordering::Relaxed);
        metrics.total_resources_synced.fetch_add(synced, Ordering::Relaxed);
        metrics.total_sync_duration_ms.fetch_add(duration.as_millis() as u64, Ordering::Relaxed);
        metrics.sync_count_for_avg.fetch_add(1, Ordering::Relaxed);

        // Update status
        {
            let mut status = sync_status.write().await;
            status.last_incremental_sync = Some(Utc::now());
            status.resources_synced += synced;
        }

        info!(
            "Periodic sync completed: {} resources in {}ms",
            synced,
            duration.as_millis()
        );

        Ok(())
    }

    /// Perform incremental sync for specific changed resources
    async fn incremental_sync(
        config: &JssSyncConfig,
        http_client: &Client,
        sync_status: &Arc<RwLock<SyncStatus>>,
        metrics: &Arc<MetricsCounters>,
        ontology_repo: Option<&Arc<dyn OntologyRepository>>,
        event: &Neo4jChangeEvent,
        checksums: &Arc<RwLock<HashMap<String, String>>>,
    ) -> Result<()> {
        let start_time = Instant::now();

        info!(
            "Incremental sync for {:?} event, {} affected IRIs",
            event.change_type,
            event.affected_iris.len()
        );

        let repo = ontology_repo
            .ok_or(JssSyncError::RepositoryError("Repository not configured".to_string()))?;

        let mut synced = 0u64;
        let mut deleted = 0u64;

        match event.change_type {
            Neo4jChangeType::ClassDeleted | Neo4jChangeType::PropertyDeleted => {
                // Handle deletions - remove from JSS
                for iri in &event.affected_iris {
                    if let Err(e) = Self::delete_resource_from_jss(config, http_client, iri).await {
                        warn!("Failed to delete resource {} from JSS: {}", iri, e);
                    } else {
                        deleted += 1;
                        // Remove from checksums
                        checksums.write().await.remove(iri);
                    }
                }
            }
            _ => {
                // Handle creates/updates - sync to JSS
                for iri in &event.affected_iris {
                    // Fetch the current state from Neo4j
                    if let Ok(Some(class)) = repo.get_owl_class(iri).await {
                        let resource = Self::owl_class_to_resource(&class);

                        if let Err(e) = Self::sync_single_resource(config, http_client, &resource).await {
                            warn!("Failed to sync resource {}: {}", iri, e);
                        } else {
                            synced += 1;
                            // Update checksum
                            let checksum = Self::compute_resource_checksum(&resource);
                            checksums.write().await.insert(iri.clone(), checksum);
                        }
                    } else if let Ok(Some(prop)) = repo.get_owl_property(iri).await {
                        let resource = Self::owl_property_to_resource(&prop);

                        if let Err(e) = Self::sync_single_resource(config, http_client, &resource).await {
                            warn!("Failed to sync resource {}: {}", iri, e);
                        } else {
                            synced += 1;
                            let checksum = Self::compute_resource_checksum(&resource);
                            checksums.write().await.insert(iri.clone(), checksum);
                        }
                    } else {
                        debug!("Resource {} not found in Neo4j, skipping", iri);
                    }
                }
            }
        }

        let duration = start_time.elapsed();

        // Update metrics
        metrics.total_incremental_syncs.fetch_add(1, Ordering::Relaxed);
        metrics.total_resources_synced.fetch_add(synced, Ordering::Relaxed);
        metrics.total_sync_duration_ms.fetch_add(duration.as_millis() as u64, Ordering::Relaxed);
        metrics.sync_count_for_avg.fetch_add(1, Ordering::Relaxed);

        // Decrement pending changes
        {
            let mut status = sync_status.write().await;
            status.pending_changes = status.pending_changes.saturating_sub(event.affected_iris.len() as u64);
            status.last_incremental_sync = Some(Utc::now());
            status.resources_synced += synced;
        }

        info!(
            "Incremental sync completed: {} synced, {} deleted in {}ms",
            synced,
            deleted,
            duration.as_millis()
        );

        Ok(())
    }

    /// Sync a batch of resources to JSS
    async fn sync_resources_to_jss(&self, resources: &[OntologyResource]) -> Result<u64> {
        let mut synced_count = 0u64;

        // Sync in batches
        for chunk in resources.chunks(self.config.batch_size) {
            for resource in chunk {
                match self.sync_resource_to_jss(resource).await {
                    Ok(_) => {
                        synced_count += 1;
                        debug!("Synced resource: {}", resource.iri);
                    }
                    Err(e) => {
                        warn!("Failed to sync resource {}: {}", resource.iri, e);
                    }
                }
            }
        }

        Ok(synced_count)
    }

    /// Sync a single resource (static method for use in workers)
    async fn sync_single_resource(
        config: &JssSyncConfig,
        http_client: &Client,
        resource: &OntologyResource,
    ) -> Result<()> {
        let slug = Self::iri_to_slug(&resource.iri);
        let resource_path = format!("{}/{}.jsonld", config.public_ontology_path, slug);
        let url = format!("{}{}", config.jss_config.base_url, resource_path);

        // Serialize resource to JSON-LD
        let jsonld = Self::resource_to_jsonld_static(resource)?;

        // PUT to JSS with retries
        let mut last_error = None;
        for attempt in 0..config.max_retries {
            let response = http_client
                .put(&url)
                .header("Content-Type", "application/ld+json")
                .body(serde_json::to_string(&jsonld).map_err(|e| JssSyncError::SerializationError(e.to_string()))?)
                .send()
                .await;

            match response {
                Ok(resp) if resp.status().is_success() => {
                    return Ok(());
                }
                Ok(resp) => {
                    last_error = Some(JssSyncError::JssServerError {
                        status: resp.status().as_u16(),
                        message: format!("Failed to sync resource: {}", resource.iri),
                    });
                }
                Err(e) => {
                    last_error = Some(JssSyncError::HttpError(e));
                }
            }

            if attempt < config.max_retries - 1 {
                tokio::time::sleep(Duration::from_millis(config.retry_delay_ms * (attempt as u64 + 1))).await;
            }
        }

        Err(last_error.unwrap_or(JssSyncError::SerializationError("Unknown error after retries".to_string())))
    }

    /// Delete a resource from JSS
    async fn delete_resource_from_jss(
        config: &JssSyncConfig,
        http_client: &Client,
        iri: &str,
    ) -> Result<()> {
        let slug = Self::iri_to_slug(iri);
        let resource_path = format!("{}/{}.jsonld", config.public_ontology_path, slug);
        let url = format!("{}{}", config.jss_config.base_url, resource_path);

        let response = http_client.delete(&url).send().await?;

        if response.status().is_success() || response.status().as_u16() == 404 {
            Ok(())
        } else {
            Err(JssSyncError::JssServerError {
                status: response.status().as_u16(),
                message: format!("Failed to delete resource: {}", iri),
            })
        }
    }

    async fn ensure_container_exists(&self, path: &str) -> Result<()> {
        let url = format!("{}{}", self.config.jss_config.base_url, path);

        // Check if container exists
        let response = self.http_client.head(&url).send().await?;

        if response.status().as_u16() == 404 {
            // Create container
            debug!("Creating container: {}", path);

            let create_response = self.http_client
                .put(&url)
                .header("Content-Type", "text/turtle")
                .header("Link", "<http://www.w3.org/ns/ldp#BasicContainer>; rel=\"type\"")
                .body("")
                .send()
                .await?;

            if !create_response.status().is_success() {
                return Err(JssSyncError::JssServerError {
                    status: create_response.status().as_u16(),
                    message: format!("Failed to create container: {}", path),
                });
            }

            info!("Created container: {}", path);
        }

        Ok(())
    }

    async fn sync_resource_to_jss(&self, resource: &OntologyResource) -> Result<()> {
        Self::sync_single_resource(&self.config, &self.http_client, resource).await
    }

    async fn sync_contribution_to_jss(
        &self,
        user_path: &str,
        contribution: &UserContribution,
    ) -> Result<()> {
        let resource_path = format!("{}/{}.jsonld", user_path, contribution.contribution_id);
        let url = format!("{}{}", self.config.jss_config.base_url, resource_path);

        // Serialize contribution to JSON-LD
        let jsonld = self.contribution_to_jsonld(contribution)?;

        // PUT to JSS
        let response = self.http_client
            .put(&url)
            .header("Content-Type", "application/ld+json")
            .body(jsonld)
            .send()
            .await?;

        if !response.status().is_success() {
            return Err(JssSyncError::JssServerError {
                status: response.status().as_u16(),
                message: format!("Failed to sync contribution: {}", contribution.contribution_id),
            });
        }

        Ok(())
    }

    // ========================================================================
    // Conversion Helpers
    // ========================================================================

    fn owl_class_to_resource(class: &OwlClass) -> OntologyResource {
        OntologyResource {
            iri: class.iri.clone(),
            label: class.label.clone(),
            description: class.description.clone(),
            resource_type: OntologyResourceType::Class,
            parent_iris: class.parent_classes.clone(),
            properties: class.properties.clone(),
            source_domain: class.source_domain.clone(),
            quality_score: class.quality_score,
            last_modified: class.last_synced,
        }
    }

    fn owl_property_to_resource(prop: &OwlProperty) -> OntologyResource {
        OntologyResource {
            iri: prop.iri.clone(),
            label: prop.label.clone(),
            description: None,
            resource_type: OntologyResourceType::Property,
            parent_iris: Vec::new(),
            properties: HashMap::new(),
            source_domain: None,
            quality_score: prop.quality_score,
            last_modified: None,
        }
    }

    fn compute_resource_checksum(resource: &OntologyResource) -> String {
        use std::hash::{Hash, Hasher};
        use std::collections::hash_map::DefaultHasher;

        let mut hasher = DefaultHasher::new();
        resource.iri.hash(&mut hasher);
        resource.label.hash(&mut hasher);
        resource.description.hash(&mut hasher);
        for parent in &resource.parent_iris {
            parent.hash(&mut hasher);
        }
        format!("{:x}", hasher.finish())
    }

    fn iri_to_slug(iri: &str) -> String {
        // Extract local name from IRI
        if let Some(hash_pos) = iri.rfind('#') {
            return iri[hash_pos + 1..].to_string();
        }
        if let Some(slash_pos) = iri.rfind('/') {
            return iri[slash_pos + 1..].to_string();
        }
        // Fallback: URL-encode the whole IRI
        urlencoding::encode(iri).to_string()
    }

    /// Convert ontology resource to JSON-LD format (native for JSS)
    fn resource_to_jsonld(&self, resource: &OntologyResource) -> Result<serde_json::Value> {
        Self::resource_to_jsonld_static(resource)
    }

    fn resource_to_jsonld_static(resource: &OntologyResource) -> Result<serde_json::Value> {
        Ok(serde_json::json!({
            "@context": {
                "@vocab": "http://visionflow.io/ontology#",
                "owl": "http://www.w3.org/2002/07/owl#",
                "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
                "xsd": "http://www.w3.org/2001/XMLSchema#",
                "vf": "http://visionflow.io/ontology#"
            },
            "@id": &resource.iri,
            "@type": match &resource.resource_type {
                OntologyResourceType::Class => "owl:Class",
                OntologyResourceType::Property => "owl:ObjectProperty",
                OntologyResourceType::Individual => "owl:NamedIndividual",
                OntologyResourceType::Axiom => "owl:Axiom",
            },
            "rdfs:label": &resource.label,
            "rdfs:comment": &resource.description,
            "rdfs:subClassOf": resource.parent_iris.iter()
                .map(|p| serde_json::json!({"@id": p}))
                .collect::<Vec<_>>(),
            "vf:qualityScore": resource.quality_score,
            "vf:sourceDomain": &resource.source_domain,
            "vf:lastModified": resource.last_modified.map(|dt| dt.to_rfc3339()),
            "vf:syncedAt": Utc::now().to_rfc3339(),
        }))
    }

    fn resource_to_turtle(&self, resource: &OntologyResource) -> Result<String> {
        let mut turtle = String::new();

        // Prefixes
        turtle.push_str("@prefix owl: <http://www.w3.org/2002/07/owl#> .\n");
        turtle.push_str("@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n");
        turtle.push_str("@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n");
        turtle.push_str("@prefix vf: <http://visionflow.io/ontology#> .\n\n");

        // Resource declaration
        turtle.push_str(&format!("<{}>\n", resource.iri));

        // Type based on resource type
        match resource.resource_type {
            OntologyResourceType::Class => {
                turtle.push_str("    a owl:Class");
            }
            OntologyResourceType::Property => {
                turtle.push_str("    a owl:ObjectProperty");
            }
            OntologyResourceType::Individual => {
                turtle.push_str("    a owl:NamedIndividual");
            }
            OntologyResourceType::Axiom => {
                turtle.push_str("    a owl:Axiom");
            }
        }

        // Label
        if let Some(label) = &resource.label {
            turtle.push_str(&format!(" ;\n    rdfs:label \"{}\"", Self::escape_turtle_string(label)));
        }

        // Description
        if let Some(desc) = &resource.description {
            turtle.push_str(&format!(" ;\n    rdfs:comment \"{}\"", Self::escape_turtle_string(desc)));
        }

        // Parent classes
        for parent in &resource.parent_iris {
            turtle.push_str(&format!(" ;\n    rdfs:subClassOf <{}>", parent));
        }

        // Quality score
        if let Some(score) = resource.quality_score {
            turtle.push_str(&format!(" ;\n    vf:qualityScore \"{}\"^^xsd:float", score));
        }

        // Source domain
        if let Some(domain) = &resource.source_domain {
            turtle.push_str(&format!(" ;\n    vf:sourceDomain \"{}\"", Self::escape_turtle_string(domain)));
        }

        // Additional properties
        for (key, value) in &resource.properties {
            turtle.push_str(&format!(" ;\n    vf:{} \"{}\"", key, Self::escape_turtle_string(value)));
        }

        turtle.push_str(" .\n");

        Ok(turtle)
    }

    fn contribution_to_jsonld(&self, contribution: &UserContribution) -> Result<String> {
        let jsonld = serde_json::json!({
            "@context": {
                "@vocab": "http://visionflow.io/contributions#",
                "xsd": "http://www.w3.org/2001/XMLSchema#",
                "created": {"@type": "xsd:dateTime"},
                "updated": {"@type": "xsd:dateTime"}
            },
            "@id": format!("urn:contribution:{}", contribution.contribution_id),
            "@type": format!("{:?}", contribution.contribution_type),
            "contributor": contribution.user_npub,
            "target": contribution.target_iri,
            "status": format!("{:?}", contribution.status),
            "proposedChanges": contribution.proposed_changes,
            "created": contribution.created_at.to_rfc3339(),
            "updated": contribution.updated_at.to_rfc3339()
        });

        serde_json::to_string_pretty(&jsonld)
            .map_err(|e| JssSyncError::SerializationError(e.to_string()))
    }

    fn escape_turtle_string(s: &str) -> String {
        s.replace('\\', "\\\\")
            .replace('"', "\\\"")
            .replace('\n', "\\n")
            .replace('\r', "\\r")
            .replace('\t', "\\t")
    }
}

impl Default for JssSyncService {
    fn default() -> Self {
        Self::from_env()
    }
}

// ============================================================================
// Tests
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_iri_to_slug() {
        assert_eq!(
            JssSyncService::iri_to_slug("http://example.org/ontology#Person"),
            "Person"
        );
        assert_eq!(
            JssSyncService::iri_to_slug("http://example.org/ontology/Agent"),
            "Agent"
        );
    }

    #[test]
    fn test_escape_turtle_string() {
        assert_eq!(
            JssSyncService::escape_turtle_string("Hello \"World\""),
            "Hello \\\"World\\\""
        );
        assert_eq!(
            JssSyncService::escape_turtle_string("Line1\nLine2"),
            "Line1\\nLine2"
        );
    }

    #[tokio::test]
    async fn test_sync_service_creation() {
        let service = JssSyncService::from_env();
        let status = service.get_status().await;

        assert!(!status.sync_in_progress);
        assert_eq!(status.resources_synced, 0);
        assert!(status.last_full_sync.is_none());
        assert!(status.last_incremental_sync.is_none());
    }

    #[tokio::test]
    async fn test_metrics_initialization() {
        let service = JssSyncService::from_env();
        let metrics = service.get_metrics().await;

        assert_eq!(metrics.total_full_syncs, 0);
        assert_eq!(metrics.total_incremental_syncs, 0);
        assert_eq!(metrics.total_resources_synced, 0);
        assert_eq!(metrics.total_errors, 0);
    }

    #[test]
    fn test_resource_to_turtle() {
        let service = JssSyncService::from_env();

        let resource = OntologyResource {
            iri: "http://example.org/ontology#Person".to_string(),
            label: Some("Person".to_string()),
            description: Some("A human being".to_string()),
            resource_type: OntologyResourceType::Class,
            parent_iris: vec!["http://example.org/ontology#Agent".to_string()],
            properties: HashMap::new(),
            source_domain: Some("core".to_string()),
            quality_score: Some(0.95),
            last_modified: None,
        };

        let turtle = service.resource_to_turtle(&resource).unwrap();

        assert!(turtle.contains("@prefix owl:"));
        assert!(turtle.contains("<http://example.org/ontology#Person>"));
        assert!(turtle.contains("a owl:Class"));
        assert!(turtle.contains("rdfs:label \"Person\""));
        assert!(turtle.contains("rdfs:subClassOf <http://example.org/ontology#Agent>"));
    }

    #[test]
    fn test_resource_to_jsonld() {
        let resource = OntologyResource {
            iri: "http://example.org/ontology#Person".to_string(),
            label: Some("Person".to_string()),
            description: Some("A human being".to_string()),
            resource_type: OntologyResourceType::Class,
            parent_iris: vec!["http://example.org/ontology#Agent".to_string()],
            properties: HashMap::new(),
            source_domain: Some("core".to_string()),
            quality_score: Some(0.95),
            last_modified: None,
        };

        let jsonld = JssSyncService::resource_to_jsonld_static(&resource).unwrap();

        assert_eq!(jsonld["@id"], "http://example.org/ontology#Person");
        assert_eq!(jsonld["@type"], "owl:Class");
        assert_eq!(jsonld["rdfs:label"], "Person");
        assert_eq!(jsonld["rdfs:comment"], "A human being");
        assert_eq!(jsonld["vf:qualityScore"], 0.95);
        assert_eq!(jsonld["vf:sourceDomain"], "core");

        let subclass_of = jsonld["rdfs:subClassOf"].as_array().unwrap();
        assert_eq!(subclass_of.len(), 1);
        assert_eq!(subclass_of[0]["@id"], "http://example.org/ontology#Agent");
    }

    #[test]
    fn test_change_event_types() {
        let event = Neo4jChangeEvent {
            change_type: Neo4jChangeType::ClassCreated,
            affected_iris: vec!["http://example.org/Test".to_string()],
            timestamp: Utc::now(),
            source: ChangeSource::GitHubSync,
        };

        assert_eq!(event.change_type, Neo4jChangeType::ClassCreated);
        assert_eq!(event.source, ChangeSource::GitHubSync);
        assert_eq!(event.affected_iris.len(), 1);
    }

    #[test]
    fn test_compute_resource_checksum() {
        let resource1 = OntologyResource {
            iri: "http://example.org/ontology#Person".to_string(),
            label: Some("Person".to_string()),
            description: None,
            resource_type: OntologyResourceType::Class,
            parent_iris: vec![],
            properties: HashMap::new(),
            source_domain: None,
            quality_score: None,
            last_modified: None,
        };

        let resource2 = OntologyResource {
            iri: "http://example.org/ontology#Person".to_string(),
            label: Some("Person Updated".to_string()), // Different label
            description: None,
            resource_type: OntologyResourceType::Class,
            parent_iris: vec![],
            properties: HashMap::new(),
            source_domain: None,
            quality_score: None,
            last_modified: None,
        };

        let checksum1 = JssSyncService::compute_resource_checksum(&resource1);
        let checksum2 = JssSyncService::compute_resource_checksum(&resource2);

        // Same resource should produce same checksum
        assert_eq!(checksum1, JssSyncService::compute_resource_checksum(&resource1));

        // Different content should produce different checksum
        assert_ne!(checksum1, checksum2);
    }

    #[test]
    fn test_config_defaults() {
        let config = JssSyncConfig::default();

        assert_eq!(config.sync_interval_secs, 300);
        assert_eq!(config.batch_size, 100);
        assert!(config.enable_auto_sync);
        assert!(config.enable_startup_sync);
        assert_eq!(config.max_retries, 3);
    }
}

--------------------------------------------------------------------------------
FILE: src/services/jss_websocket_bridge.rs
PURPOSE: WebSocket bridge for JSS notifications
--------------------------------------------------------------------------------
//! JSS WebSocket Bridge
//!
//! Bridges JSS WebSocket notifications (solid-0.1 protocol) to VisionFlow clients.
//! Connects to JSS at ws://jss:3030/.notifications and forwards resource update
//! notifications to connected VisionFlow clients via both JSON and binary protocols.
//!
//! Protocol:
//! - JSS sends: "pub <url>" when a resource is published/updated
//! - JSS sends: "ack <url>" when a subscription is acknowledged
//! - VisionFlow clients receive:
//!   - JSON messages via RealtimeWebSocketHandler (for general updates)
//!   - Binary messages via ClientCoordinatorActor (for ontology/agent updates)
//!
//! Event Filtering:
//! - Ontology changes (/ontology/, /public/ontology/) -> Binary + JSON
//! - Agent updates (/agents/, /contributions/) -> Binary + JSON
//! - Profile changes (/profile/) -> JSON only
//! - Other resources -> JSON only

use actix::Addr;
use futures_util::{SinkExt, StreamExt};
use log::{debug, error, info, warn};
use serde::{Deserialize, Serialize};
use serde_json::json;
use std::collections::HashSet;
use std::sync::Arc;
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};
use thiserror::Error;
use tokio::sync::{mpsc, RwLock};
use tokio::time::{interval, timeout};
use tokio_tungstenite::{connect_async, tungstenite::Message as WsMessage};

use crate::actors::client_coordinator_actor::ClientCoordinatorActor;
use crate::actors::messages::BroadcastNodePositions;
use crate::handlers::solid_proxy_handler::JssConfig;
use crate::handlers::realtime_websocket_handler::{
    RealtimeWebSocketMessage, CONNECTION_MANAGER,
};

/// JSS WebSocket Bridge errors
#[derive(Debug, Error)]
pub enum JssBridgeError {
    #[error("WebSocket connection failed: {0}")]
    ConnectionError(String),

    #[error("WebSocket send failed: {0}")]
    SendError(String),

    #[error("Protocol error: {0}")]
    ProtocolError(String),

    #[error("Reconnection limit exceeded")]
    ReconnectionLimitExceeded,

    #[error("Bridge already running")]
    AlreadyRunning,

    #[error("Bridge not running")]
    NotRunning,
}

pub type Result<T> = std::result::Result<T, JssBridgeError>;

/// JSS notification message types
#[derive(Debug, Clone, PartialEq)]
pub enum JssNotificationType {
    /// Resource published/updated: "pub <url>"
    Publish(String),
    /// Subscription acknowledged: "ack <url>"
    Acknowledge(String),
    /// Ping message for keepalive
    Ping,
    /// Pong response
    Pong,
    /// Unknown message
    Unknown(String),
}

impl JssNotificationType {
    /// Parse a JSS notification message
    pub fn parse(message: &str) -> Self {
        let trimmed = message.trim();

        if trimmed.starts_with("pub ") {
            JssNotificationType::Publish(trimmed[4..].to_string())
        } else if trimmed.starts_with("ack ") {
            JssNotificationType::Acknowledge(trimmed[4..].to_string())
        } else if trimmed == "ping" {
            JssNotificationType::Ping
        } else if trimmed == "pong" {
            JssNotificationType::Pong
        } else {
            JssNotificationType::Unknown(trimmed.to_string())
        }
    }
}

/// VisionFlow notification message for clients
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct JssResourceNotification {
    /// URL of the affected resource
    pub resource_url: String,
    /// Type of notification (publish, acknowledge)
    pub notification_type: String,
    /// Timestamp when the notification was received
    pub timestamp: u64,
    /// Extracted resource path
    pub resource_path: Option<String>,
    /// Resource type if identifiable (ontology, contribution, etc.)
    pub resource_type: Option<String>,
}

/// Event relevance categories for binary protocol routing
#[derive(Debug, Clone, PartialEq)]
pub enum EventRelevance {
    /// Ontology changes - high priority, triggers graph reload
    OntologyChange,
    /// Agent/contribution updates - high priority, triggers position updates
    AgentUpdate,
    /// Profile changes - medium priority, JSON only
    ProfileChange,
    /// Pod resource changes - medium priority, JSON only
    PodResource,
    /// Other/unknown - low priority, JSON only
    Other,
}

impl EventRelevance {
    /// Determine relevance from resource URL
    pub fn from_url(url: &str) -> Self {
        let url_lower = url.to_lowercase();

        if url_lower.contains("/ontology/") || url_lower.contains("/public/ontology/") {
            EventRelevance::OntologyChange
        } else if url_lower.contains("/agents/") || url_lower.contains("/contributions/") {
            EventRelevance::AgentUpdate
        } else if url_lower.contains("/profile/") {
            EventRelevance::ProfileChange
        } else if url_lower.contains("/pods/") {
            EventRelevance::PodResource
        } else {
            EventRelevance::Other
        }
    }

    /// Check if this event should trigger binary protocol broadcast
    pub fn requires_binary_broadcast(&self) -> bool {
        matches!(self, EventRelevance::OntologyChange | EventRelevance::AgentUpdate)
    }

    /// Get priority level (higher = more urgent)
    pub fn priority(&self) -> u8 {
        match self {
            EventRelevance::OntologyChange => 10,
            EventRelevance::AgentUpdate => 8,
            EventRelevance::ProfileChange => 5,
            EventRelevance::PodResource => 3,
            EventRelevance::Other => 1,
        }
    }
}

/// Bridge connection state
#[derive(Debug, Clone, PartialEq)]
pub enum BridgeState {
    Disconnected,
    Connecting,
    Connected,
    Reconnecting,
    Stopped,
}

/// Bridge status for monitoring
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BridgeStatus {
    pub state: String,
    pub connected: bool,
    pub last_message_at: Option<u64>,
    pub messages_received: u64,
    pub messages_forwarded: u64,
    pub reconnect_count: u64,
    pub subscribed_resources: Vec<String>,
    pub uptime_secs: u64,
}

/// Configuration for JSS WebSocket bridge
#[derive(Debug, Clone)]
pub struct JssBridgeConfig {
    pub jss_config: JssConfig,
    pub reconnect_initial_delay_ms: u64,
    pub reconnect_max_delay_ms: u64,
    pub reconnect_max_attempts: u32,
    pub ping_interval_secs: u64,
    pub connection_timeout_secs: u64,
    pub auto_subscribe_paths: Vec<String>,
    /// Enable binary protocol broadcasts for relevant events
    pub enable_binary_broadcast: bool,
    /// Event types to broadcast via binary protocol
    pub binary_event_types: Vec<String>,
}

impl Default for JssBridgeConfig {
    fn default() -> Self {
        Self {
            jss_config: JssConfig::from_env(),
            reconnect_initial_delay_ms: 1000,
            reconnect_max_delay_ms: 60000,
            reconnect_max_attempts: 0, // 0 = unlimited
            ping_interval_secs: 30,
            connection_timeout_secs: 30,
            auto_subscribe_paths: vec![
                "/public/ontology/*".to_string(),
                "/pods/*/contributions/*".to_string(),
                "/pods/*/agents/*".to_string(),
            ],
            enable_binary_broadcast: true,
            binary_event_types: vec![
                "ontology".to_string(),
                "contribution".to_string(),
                "agent".to_string(),
            ],
        }
    }
}

/// JSS WebSocket Bridge
///
/// Maintains a persistent WebSocket connection to JSS and bridges
/// notifications to VisionFlow clients via both JSON and binary protocols.
pub struct JssWebSocketBridge {
    config: JssBridgeConfig,
    state: Arc<RwLock<BridgeState>>,
    status: Arc<RwLock<BridgeStatus>>,
    subscriptions: Arc<RwLock<HashSet<String>>>,
    shutdown_tx: Arc<RwLock<Option<mpsc::Sender<()>>>>,
    started_at: Arc<RwLock<Option<Instant>>>,
    /// ClientCoordinatorActor address for binary protocol broadcasts
    client_coordinator_addr: Arc<RwLock<Option<Addr<ClientCoordinatorActor>>>>,
    /// Binary broadcast statistics
    binary_broadcasts_sent: Arc<RwLock<u64>>,
}

impl JssWebSocketBridge {
    /// Create a new JSS WebSocket bridge
    pub fn new(config: JssBridgeConfig) -> Self {
        info!(
            "JSS WebSocket Bridge initialized - WS URL: {}, binary_broadcast: {}",
            config.jss_config.ws_url,
            config.enable_binary_broadcast
        );

        Self {
            config,
            state: Arc::new(RwLock::new(BridgeState::Disconnected)),
            status: Arc::new(RwLock::new(BridgeStatus {
                state: "disconnected".to_string(),
                connected: false,
                last_message_at: None,
                messages_received: 0,
                messages_forwarded: 0,
                reconnect_count: 0,
                subscribed_resources: Vec::new(),
                uptime_secs: 0,
            })),
            subscriptions: Arc::new(RwLock::new(HashSet::new())),
            shutdown_tx: Arc::new(RwLock::new(None)),
            started_at: Arc::new(RwLock::new(None)),
            client_coordinator_addr: Arc::new(RwLock::new(None)),
            binary_broadcasts_sent: Arc::new(RwLock::new(0)),
        }
    }

    /// Create with default configuration from environment
    pub fn from_env() -> Self {
        Self::new(JssBridgeConfig::default())
    }

    /// Set the ClientCoordinatorActor address for binary protocol broadcasts
    pub async fn set_client_coordinator(&self, addr: Addr<ClientCoordinatorActor>) {
        info!("JSS Bridge: ClientCoordinatorActor address set for binary broadcasts");
        *self.client_coordinator_addr.write().await = Some(addr);
    }

    /// Get binary broadcast count
    pub async fn get_binary_broadcast_count(&self) -> u64 {
        *self.binary_broadcasts_sent.read().await
    }

    /// Get current bridge state
    pub async fn get_state(&self) -> BridgeState {
        self.state.read().await.clone()
    }

    /// Get bridge status for monitoring
    pub async fn get_status(&self) -> BridgeStatus {
        let mut status = self.status.read().await.clone();

        // Update uptime
        if let Some(started) = *self.started_at.read().await {
            status.uptime_secs = started.elapsed().as_secs();
        }

        // Update subscriptions list
        status.subscribed_resources = self.subscriptions.read().await.iter().cloned().collect();

        status
    }

    /// Start the WebSocket bridge
    pub async fn start(&self) -> Result<()> {
        // Check if already running
        {
            let state = self.state.read().await;
            if *state != BridgeState::Disconnected && *state != BridgeState::Stopped {
                return Err(JssBridgeError::AlreadyRunning);
            }
        }

        info!("Starting JSS WebSocket Bridge...");

        let (shutdown_tx, mut shutdown_rx) = mpsc::channel::<()>(1);
        *self.shutdown_tx.write().await = Some(shutdown_tx);
        *self.started_at.write().await = Some(Instant::now());

        // Clone state for async task
        let config = self.config.clone();
        let state = self.state.clone();
        let status = self.status.clone();
        let subscriptions = self.subscriptions.clone();
        let client_coordinator_addr = self.client_coordinator_addr.clone();
        let binary_broadcasts_sent = self.binary_broadcasts_sent.clone();

        // Spawn the main connection loop
        tokio::spawn(async move {
            let mut reconnect_attempts = 0u32;
            let mut current_delay = config.reconnect_initial_delay_ms;

            loop {
                // Update state to connecting
                {
                    let mut s = state.write().await;
                    *s = if reconnect_attempts > 0 {
                        BridgeState::Reconnecting
                    } else {
                        BridgeState::Connecting
                    };
                }

                Self::update_status_state(&status, "connecting").await;

                // Attempt connection
                match Self::connect_and_run(
                    &config,
                    &state,
                    &status,
                    &subscriptions,
                    &client_coordinator_addr,
                    &binary_broadcasts_sent,
                    &mut shutdown_rx,
                ).await {
                    Ok(_) => {
                        // Clean shutdown
                        info!("JSS WebSocket Bridge stopped cleanly");
                        break;
                    }
                    Err(e) => {
                        error!("JSS WebSocket connection error: {}", e);

                        // Check if we should retry
                        reconnect_attempts += 1;

                        if config.reconnect_max_attempts > 0
                            && reconnect_attempts >= config.reconnect_max_attempts
                        {
                            error!("Max reconnection attempts exceeded");
                            break;
                        }

                        // Update status
                        {
                            let mut st = status.write().await;
                            st.reconnect_count += 1;
                        }

                        // Exponential backoff
                        info!(
                            "Reconnecting in {}ms (attempt {})",
                            current_delay, reconnect_attempts
                        );

                        tokio::select! {
                            _ = tokio::time::sleep(Duration::from_millis(current_delay)) => {}
                            _ = shutdown_rx.recv() => {
                                info!("Shutdown received during reconnect wait");
                                break;
                            }
                        }

                        // Increase delay with exponential backoff
                        current_delay = (current_delay * 2).min(config.reconnect_max_delay_ms);
                    }
                }
            }

            // Final state update
            *state.write().await = BridgeState::Stopped;
            Self::update_status_state(&status, "stopped").await;
        });

        Ok(())
    }

    /// Stop the WebSocket bridge
    pub async fn stop(&self) -> Result<()> {
        info!("Stopping JSS WebSocket Bridge...");

        let shutdown_tx = self.shutdown_tx.write().await.take();

        if let Some(tx) = shutdown_tx {
            let _ = tx.send(()).await;
        }

        Ok(())
    }

    /// Subscribe to resource notifications
    pub async fn subscribe(&self, resource_path: &str) -> Result<()> {
        self.subscriptions.write().await.insert(resource_path.to_string());
        debug!("Added subscription for: {}", resource_path);
        Ok(())
    }

    /// Unsubscribe from resource notifications
    pub async fn unsubscribe(&self, resource_path: &str) -> Result<()> {
        self.subscriptions.write().await.remove(resource_path);
        debug!("Removed subscription for: {}", resource_path);
        Ok(())
    }

    // Private methods

    async fn connect_and_run(
        config: &JssBridgeConfig,
        state: &Arc<RwLock<BridgeState>>,
        status: &Arc<RwLock<BridgeStatus>>,
        subscriptions: &Arc<RwLock<HashSet<String>>>,
        client_coordinator_addr: &Arc<RwLock<Option<Addr<ClientCoordinatorActor>>>>,
        binary_broadcasts_sent: &Arc<RwLock<u64>>,
        shutdown_rx: &mut mpsc::Receiver<()>,
    ) -> Result<()> {
        let ws_url = &config.jss_config.ws_url;

        info!("Connecting to JSS WebSocket: {}", ws_url);

        // Connect with timeout
        let connect_result = timeout(
            Duration::from_secs(config.connection_timeout_secs),
            connect_async(ws_url),
        ).await;

        let (ws_stream, response) = match connect_result {
            Ok(Ok((stream, resp))) => (stream, resp),
            Ok(Err(e)) => {
                return Err(JssBridgeError::ConnectionError(e.to_string()));
            }
            Err(_) => {
                return Err(JssBridgeError::ConnectionError(
                    "Connection timeout".to_string(),
                ));
            }
        };

        info!(
            "Connected to JSS WebSocket (HTTP status: {})",
            response.status()
        );

        // Update state to connected
        *state.write().await = BridgeState::Connected;
        Self::update_status_state(status, "connected").await;
        {
            let mut st = status.write().await;
            st.connected = true;
        }

        let (mut ws_tx, mut ws_rx) = ws_stream.split();

        // Subscribe to auto-subscribe paths
        for path in &config.auto_subscribe_paths {
            let sub_msg = format!("sub {}", path);
            if let Err(e) = ws_tx.send(WsMessage::Text(sub_msg.clone())).await {
                warn!("Failed to send subscription: {}", e);
            } else {
                debug!("Sent subscription: {}", sub_msg);
                subscriptions.write().await.insert(path.clone());
            }
        }

        // Set up ping interval
        let mut ping_interval = interval(Duration::from_secs(config.ping_interval_secs));

        loop {
            tokio::select! {
                // Handle incoming WebSocket messages
                msg = ws_rx.next() => {
                    match msg {
                        Some(Ok(WsMessage::Text(text))) => {
                            Self::handle_message(
                                &text,
                                config,
                                status,
                                client_coordinator_addr,
                                binary_broadcasts_sent,
                            ).await;
                        }
                        Some(Ok(WsMessage::Ping(data))) => {
                            debug!("Received WebSocket ping");
                            if let Err(e) = ws_tx.send(WsMessage::Pong(data)).await {
                                warn!("Failed to send pong: {}", e);
                            }
                        }
                        Some(Ok(WsMessage::Pong(_))) => {
                            debug!("Received WebSocket pong");
                        }
                        Some(Ok(WsMessage::Close(frame))) => {
                            info!("JSS WebSocket closed: {:?}", frame);
                            return Err(JssBridgeError::ConnectionError(
                                "Connection closed by server".to_string(),
                            ));
                        }
                        Some(Err(e)) => {
                            error!("WebSocket error: {}", e);
                            return Err(JssBridgeError::ConnectionError(e.to_string()));
                        }
                        None => {
                            info!("WebSocket stream ended");
                            return Err(JssBridgeError::ConnectionError(
                                "Stream ended".to_string(),
                            ));
                        }
                        _ => {}
                    }
                }

                // Send periodic pings
                _ = ping_interval.tick() => {
                    debug!("Sending WebSocket ping");
                    if let Err(e) = ws_tx.send(WsMessage::Ping(vec![])).await {
                        warn!("Failed to send ping: {}", e);
                    }
                }

                // Handle shutdown
                _ = shutdown_rx.recv() => {
                    info!("Shutdown signal received");

                    // Send close frame
                    let _ = ws_tx.send(WsMessage::Close(None)).await;

                    *state.write().await = BridgeState::Stopped;
                    return Ok(());
                }
            }
        }
    }

    async fn handle_message(
        message: &str,
        config: &JssBridgeConfig,
        status: &Arc<RwLock<BridgeStatus>>,
        client_coordinator_addr: &Arc<RwLock<Option<Addr<ClientCoordinatorActor>>>>,
        binary_broadcasts_sent: &Arc<RwLock<u64>>,
    ) {
        debug!("Received JSS message: {}", message);

        // Update message count
        {
            let mut st = status.write().await;
            st.messages_received += 1;
            st.last_message_at = Some(Self::current_timestamp());
        }

        let notification_type = JssNotificationType::parse(message);

        match notification_type {
            JssNotificationType::Publish(url) => {
                info!("JSS resource published: {}", url);
                Self::forward_to_visionflow(
                    "publish",
                    &url,
                    config,
                    status,
                    client_coordinator_addr,
                    binary_broadcasts_sent,
                ).await;
            }
            JssNotificationType::Acknowledge(url) => {
                debug!("JSS subscription acknowledged: {}", url);
                Self::forward_to_visionflow(
                    "acknowledge",
                    &url,
                    config,
                    status,
                    client_coordinator_addr,
                    binary_broadcasts_sent,
                ).await;
            }
            JssNotificationType::Ping => {
                debug!("Received JSS ping");
            }
            JssNotificationType::Pong => {
                debug!("Received JSS pong");
            }
            JssNotificationType::Unknown(msg) => {
                warn!("Unknown JSS message: {}", msg);
            }
        }
    }

    async fn forward_to_visionflow(
        notification_type: &str,
        resource_url: &str,
        config: &JssBridgeConfig,
        status: &Arc<RwLock<BridgeStatus>>,
        client_coordinator_addr: &Arc<RwLock<Option<Addr<ClientCoordinatorActor>>>>,
        binary_broadcasts_sent: &Arc<RwLock<u64>>,
    ) {
        // Determine event relevance for routing
        let relevance = EventRelevance::from_url(resource_url);
        let resource_type = Self::determine_resource_type(resource_url);

        // Create VisionFlow notification
        let notification = JssResourceNotification {
            resource_url: resource_url.to_string(),
            notification_type: notification_type.to_string(),
            timestamp: Self::current_timestamp(),
            resource_path: Self::extract_path(resource_url),
            resource_type: resource_type.clone(),
        };

        // Create realtime message for JSON broadcast
        let message = RealtimeWebSocketMessage {
            msg_type: "jss_notification".to_string(),
            data: serde_json::to_value(&notification).unwrap_or(json!({})),
            timestamp: Self::current_timestamp(),
            client_id: None,
            session_id: None,
        };

        // Broadcast to all subscribed VisionFlow clients via JSON (always)
        let msg_clone = message.clone();
        tokio::spawn(async move {
            let manager = CONNECTION_MANAGER.lock().await;
            manager.broadcast("jss_notification", msg_clone).await;
        });

        // Binary protocol broadcast for high-priority events (ontology/agent changes)
        if config.enable_binary_broadcast && relevance.requires_binary_broadcast() {
            if let Some(ref addr) = *client_coordinator_addr.read().await {
                // Create binary notification message
                let binary_msg = Self::create_binary_notification(
                    notification_type,
                    resource_url,
                    &relevance,
                    &resource_type,
                );

                if !binary_msg.is_empty() {
                    info!(
                        "JSS Bridge: Sending binary broadcast for {:?} event: {} ({} bytes)",
                        relevance,
                        resource_url,
                        binary_msg.len()
                    );

                    // Send via ClientCoordinatorActor
                    addr.do_send(BroadcastNodePositions {
                        positions: binary_msg,
                    });

                    // Update binary broadcast count
                    {
                        let mut count = binary_broadcasts_sent.write().await;
                        *count += 1;
                    }
                }
            } else {
                debug!(
                    "JSS Bridge: Binary broadcast skipped - no ClientCoordinatorActor address (event: {:?})",
                    relevance
                );
            }
        }

        // Update forwarded count
        {
            let mut st = status.write().await;
            st.messages_forwarded += 1;
        }

        debug!(
            "Forwarded JSS notification to VisionFlow clients (relevance: {:?}, binary: {})",
            relevance,
            relevance.requires_binary_broadcast()
        );
    }

    /// Create a binary notification message for the SocketFlowHandler binary protocol
    fn create_binary_notification(
        notification_type: &str,
        resource_url: &str,
        relevance: &EventRelevance,
        resource_type: &Option<String>,
    ) -> Vec<u8> {
        // Binary message format:
        // [message_type: u8][relevance_priority: u8][timestamp: u64][url_len: u16][url: bytes][type_len: u8][type: bytes]
        let mut buffer = Vec::with_capacity(256);

        // Message type: 0x20 = JSS notification (custom type for JSS events)
        let msg_type: u8 = match relevance {
            EventRelevance::OntologyChange => 0x21, // Ontology update
            EventRelevance::AgentUpdate => 0x22,    // Agent/contribution update
            _ => 0x20,                              // Generic JSS notification
        };
        buffer.push(msg_type);

        // Relevance priority (1-10)
        buffer.push(relevance.priority());

        // Notification type (0 = publish, 1 = acknowledge)
        buffer.push(if notification_type == "publish" { 0 } else { 1 });

        // Timestamp (8 bytes, big endian)
        let timestamp = Self::current_timestamp();
        buffer.extend_from_slice(&timestamp.to_be_bytes());

        // Resource URL length and data
        let url_bytes = resource_url.as_bytes();
        let url_len = url_bytes.len().min(u16::MAX as usize) as u16;
        buffer.extend_from_slice(&url_len.to_be_bytes());
        buffer.extend_from_slice(&url_bytes[..url_len as usize]);

        // Resource type length and data
        if let Some(ref res_type) = resource_type {
            let type_bytes = res_type.as_bytes();
            let type_len = type_bytes.len().min(u8::MAX as usize) as u8;
            buffer.push(type_len);
            buffer.extend_from_slice(&type_bytes[..type_len as usize]);
        } else {
            buffer.push(0);
        }

        buffer
    }

    fn extract_path(url: &str) -> Option<String> {
        // Extract path from full URL
        url::Url::parse(url)
            .ok()
            .map(|u| u.path().to_string())
    }

    fn determine_resource_type(url: &str) -> Option<String> {
        if url.contains("/ontology/") {
            Some("ontology".to_string())
        } else if url.contains("/contributions/") {
            Some("contribution".to_string())
        } else if url.contains("/profile/") {
            Some("profile".to_string())
        } else if url.contains("/pods/") {
            Some("pod_resource".to_string())
        } else {
            None
        }
    }

    async fn update_status_state(status: &Arc<RwLock<BridgeStatus>>, state: &str) {
        let mut st = status.write().await;
        st.state = state.to_string();
        st.connected = state == "connected";
    }

    fn current_timestamp() -> u64 {
        SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_millis() as u64
    }
}

impl Default for JssWebSocketBridge {
    fn default() -> Self {
        Self::from_env()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_notification_pub() {
        let msg = "pub http://jss:3030/pods/alice/ontology/Person.ttl";
        let notification = JssNotificationType::parse(msg);

        assert_eq!(
            notification,
            JssNotificationType::Publish("http://jss:3030/pods/alice/ontology/Person.ttl".to_string())
        );
    }

    #[test]
    fn test_parse_notification_ack() {
        let msg = "ack /public/ontology/*";
        let notification = JssNotificationType::parse(msg);

        assert_eq!(
            notification,
            JssNotificationType::Acknowledge("/public/ontology/*".to_string())
        );
    }

    #[test]
    fn test_parse_notification_ping() {
        let msg = "ping";
        let notification = JssNotificationType::parse(msg);

        assert_eq!(notification, JssNotificationType::Ping);
    }

    #[test]
    fn test_parse_notification_unknown() {
        let msg = "unknown message";
        let notification = JssNotificationType::parse(msg);

        assert_eq!(
            notification,
            JssNotificationType::Unknown("unknown message".to_string())
        );
    }

    #[test]
    fn test_extract_path() {
        let url = "http://jss:3030/pods/alice/ontology/Person.ttl";
        let path = JssWebSocketBridge::extract_path(url);

        assert_eq!(path, Some("/pods/alice/ontology/Person.ttl".to_string()));
    }

    #[test]
    fn test_determine_resource_type() {
        assert_eq!(
            JssWebSocketBridge::determine_resource_type("http://jss:3030/public/ontology/Person.ttl"),
            Some("ontology".to_string())
        );

        assert_eq!(
            JssWebSocketBridge::determine_resource_type("http://jss:3030/pods/alice/contributions/prop1.jsonld"),
            Some("contribution".to_string())
        );

        assert_eq!(
            JssWebSocketBridge::determine_resource_type("http://jss:3030/pods/alice/profile/card"),
            Some("profile".to_string())
        );
    }

    #[tokio::test]
    async fn test_bridge_creation() {
        let bridge = JssWebSocketBridge::from_env();
        let state = bridge.get_state().await;

        assert_eq!(state, BridgeState::Disconnected);
    }

    #[tokio::test]
    async fn test_subscription_management() {
        let bridge = JssWebSocketBridge::from_env();

        bridge.subscribe("/test/path/*").await.unwrap();

        let status = bridge.get_status().await;
        assert!(status.subscribed_resources.contains(&"/test/path/*".to_string()));

        bridge.unsubscribe("/test/path/*").await.unwrap();

        let status = bridge.get_status().await;
        assert!(!status.subscribed_resources.contains(&"/test/path/*".to_string()));
    }

    #[test]
    fn test_event_relevance_ontology() {
        let url = "http://jss:3030/public/ontology/Person.ttl";
        let relevance = EventRelevance::from_url(url);

        assert_eq!(relevance, EventRelevance::OntologyChange);
        assert!(relevance.requires_binary_broadcast());
        assert_eq!(relevance.priority(), 10);
    }

    #[test]
    fn test_event_relevance_agent() {
        let url = "http://jss:3030/pods/alice/contributions/prop1.jsonld";
        let relevance = EventRelevance::from_url(url);

        assert_eq!(relevance, EventRelevance::AgentUpdate);
        assert!(relevance.requires_binary_broadcast());
        assert_eq!(relevance.priority(), 8);
    }

    #[test]
    fn test_event_relevance_profile() {
        let url = "http://jss:3030/pods/alice/profile/card";
        let relevance = EventRelevance::from_url(url);

        assert_eq!(relevance, EventRelevance::ProfileChange);
        assert!(!relevance.requires_binary_broadcast());
        assert_eq!(relevance.priority(), 5);
    }

    #[test]
    fn test_event_relevance_pod_resource() {
        let url = "http://jss:3030/pods/alice/documents/readme.txt";
        let relevance = EventRelevance::from_url(url);

        assert_eq!(relevance, EventRelevance::PodResource);
        assert!(!relevance.requires_binary_broadcast());
        assert_eq!(relevance.priority(), 3);
    }

    #[test]
    fn test_event_relevance_other() {
        let url = "http://example.com/some/random/path";
        let relevance = EventRelevance::from_url(url);

        assert_eq!(relevance, EventRelevance::Other);
        assert!(!relevance.requires_binary_broadcast());
        assert_eq!(relevance.priority(), 1);
    }

    #[test]
    fn test_create_binary_notification() {
        let binary_msg = JssWebSocketBridge::create_binary_notification(
            "publish",
            "http://jss:3030/public/ontology/Person.ttl",
            &EventRelevance::OntologyChange,
            &Some("ontology".to_string()),
        );

        // Verify message structure
        assert!(!binary_msg.is_empty());
        assert_eq!(binary_msg[0], 0x21); // OntologyChange message type
        assert_eq!(binary_msg[1], 10);   // Priority
        assert_eq!(binary_msg[2], 0);    // Publish = 0

        // Timestamp is 8 bytes
        // URL length is 2 bytes, then URL
        // Resource type length is 1 byte, then type
    }

    #[test]
    fn test_create_binary_notification_agent() {
        let binary_msg = JssWebSocketBridge::create_binary_notification(
            "acknowledge",
            "http://jss:3030/pods/alice/contributions/test.jsonld",
            &EventRelevance::AgentUpdate,
            &Some("contribution".to_string()),
        );

        assert!(!binary_msg.is_empty());
        assert_eq!(binary_msg[0], 0x22); // AgentUpdate message type
        assert_eq!(binary_msg[1], 8);    // Priority
        assert_eq!(binary_msg[2], 1);    // Acknowledge = 1
    }

    #[tokio::test]
    async fn test_bridge_binary_broadcast_count() {
        let bridge = JssWebSocketBridge::from_env();

        // Initially should be 0
        assert_eq!(bridge.get_binary_broadcast_count().await, 0);
    }
}

--------------------------------------------------------------------------------
FILE: src/services/speech_service.rs
PURPOSE: Text-to-speech service (Kokoro integration)
--------------------------------------------------------------------------------
use crate::config::AppFullSettings;
use crate::time;
use serde_json::json;
use std::sync::Arc;
use tokio::sync::broadcast;
use tokio::sync::{mpsc, Mutex, RwLock};
use tokio::task;
use tokio_tungstenite::{connect_async, tungstenite, MaybeTlsStream, WebSocketStream};
use tungstenite::http::Request;
// use crate::config::Settings;
use crate::actors::voice_commands::VoiceCommand;
use crate::errors::{SpeechError as VisionSpeechError, VisionFlowError, VisionFlowResult};
use crate::types::speech::{
    STTProvider, SpeechCommand, SpeechOptions, TTSProvider, TranscriptionOptions,
};
use crate::utils::mcp_connection::{
    call_agent_list, call_agent_spawn, call_swarm_init, call_task_orchestrate,
};
use base64::engine::general_purpose::STANDARD as BASE64;
use base64::Engine as _;
use futures::{SinkExt, StreamExt};
use log::{debug, error, info};
use tokio::net::TcpStream;
use url::Url;
// DEPRECATED: call_task_orchestrate_docker removed - use TaskOrchestratorActor
use crate::services::voice_context_manager::VoiceContextManager;
use crate::services::voice_tag_manager::{TaggedVoiceResponse, VoiceTagManager};
use chrono;
use reqwest::Client;
use uuid::Uuid;

///
///
///
///
///
///
///
///
///
///
pub struct SpeechService {
    
    sender: Arc<Mutex<mpsc::Sender<SpeechCommand>>>,
    
    settings: Arc<RwLock<AppFullSettings>>,
    
    tts_provider: Arc<RwLock<TTSProvider>>,
    
    stt_provider: Arc<RwLock<STTProvider>>,
    
    
    audio_tx: broadcast::Sender<Vec<u8>>,
    
    
    transcription_tx: broadcast::Sender<String>,
    
    
    http_client: Arc<Client>,
    
    context_manager: Arc<VoiceContextManager>,
    
    tag_manager: Arc<VoiceTagManager>,
    
    tts_response_rx: Option<Arc<Mutex<mpsc::Receiver<TaggedVoiceResponse>>>>,
}

impl SpeechService {
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    pub fn new(settings: Arc<RwLock<AppFullSettings>>) -> Self {
        
        let (tx, rx) = mpsc::channel(100);
        let sender = Arc::new(Mutex::new(tx));

        
        
        let (audio_tx, _) = broadcast::channel(100);

        
        
        let http_client = Arc::new(Client::new());

        
        
        let (transcription_tx, _) = broadcast::channel(100);

        
        let (tts_response_tx, tts_response_rx) = mpsc::channel(100);

        
        let mut tag_manager = VoiceTagManager::new();
        tag_manager.set_tts_sender(tts_response_tx);
        let tag_manager = Arc::new(tag_manager);

        let service = SpeechService {
            sender,
            settings,
            tts_provider: Arc::new(RwLock::new(TTSProvider::Kokoro)), 
            stt_provider: Arc::new(RwLock::new(STTProvider::Whisper)), 
            audio_tx,
            transcription_tx,
            http_client,
            context_manager: Arc::new(VoiceContextManager::new()),
            tag_manager,
            tts_response_rx: Some(Arc::new(Mutex::new(tts_response_rx))),
        };

        
        service.start(rx);

        
        service.start_tagged_tts_handler();

        service
    }

    fn start(&self, mut receiver: mpsc::Receiver<SpeechCommand>) {
        let settings: Arc<RwLock<AppFullSettings>> = Arc::clone(&self.settings);
        let http_client = Arc::clone(&self.http_client);
        let tts_provider = Arc::clone(&self.tts_provider);
        let stt_provider = Arc::clone(&self.stt_provider);
        let audio_tx = self.audio_tx.clone();
        let transcription_tx = self.transcription_tx.clone();

        task::spawn(async move {
            let mut ws_stream: Option<WebSocketStream<MaybeTlsStream<TcpStream>>> = None;

            while let Some(command) = receiver.recv().await {
                match command {
                    SpeechCommand::Initialize => {
                        let settings_read = settings.read().await;

                        
                        let openai_api_key = match settings_read
                            .openai
                            .as_ref()
                            .and_then(|o| o.api_key.as_ref())
                        {
                            Some(key) if !key.is_empty() => key.clone(),
                            _ => {
                                error!("OpenAI API key not configured or empty. Cannot initialize OpenAI Realtime API.");
                                continue; 
                            }
                        };

                        let url_str = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01";
                        let url = match Url::parse(url_str) {
                            Ok(url) => url,
                            Err(e) => {
                                error!("Failed to parse OpenAI URL '{}': {}", url_str, e);
                                continue;
                            }
                        };

                        let request = match Request::builder()
                            .uri(url.as_str())
                            .header("Authorization", format!("Bearer {}", openai_api_key))
                            .header("OpenAI-Beta", "realtime=v1")
                            .header("Content-Type", "application/json")
                            .header("User-Agent", "WebXR Graph")
                            .header("Sec-WebSocket-Version", "13")
                            .header(
                                "Sec-WebSocket-Key",
                                tungstenite::handshake::client::generate_key(),
                            )
                            .header("Connection", "Upgrade")
                            .header("Upgrade", "websocket")
                            .body(())
                        {
                            Ok(req) => req,
                            Err(e) => {
                                error!("Failed to build request: {}", e);
                                continue;
                            }
                        };

                        match connect_async(request).await {
                            Ok((mut stream, _)) => {
                                info!("Connected to OpenAI Realtime API");

                                let init_event = json!({
                                    "type": "response.create",
                                    "response": {
                                        "modalities": ["text", "audio"],
                                        "instructions": "You are a helpful AI assistant. Respond naturally and conversationally."
                                    }
                                });

                                if let Err(e) = stream
                                    .send(tungstenite::Message::Text(init_event.to_string()))
                                    .await
                                {
                                    error!("Failed to send initial response.create event: {}", e);
                                    continue;
                                }

                                ws_stream = Some(stream);
                            }
                            Err(e) => error!("Failed to connect to OpenAI Realtime API: {}", e),
                        }
                    }
                    SpeechCommand::SendMessage(msg) => {
                        if let Some(stream) = &mut ws_stream {
                            let msg_event = json!({
                                "type": "conversation.item.create",
                                "item": {
                                    "type": "message",
                                    "role": "user",
                                    "content": [{
                                        "type": "input_text",
                                        "text": msg
                                    }]
                                }
                            });

                            if let Err(e) = stream
                                .send(tungstenite::Message::Text(msg_event.to_string()))
                                .await
                            {
                                error!("Failed to send message to OpenAI: {}", e);
                                continue;
                            }

                            let response_event = json!({
                                "type": "response.create"
                            });

                            if let Err(e) = stream
                                .send(tungstenite::Message::Text(response_event.to_string()))
                                .await
                            {
                                error!("Failed to request response from OpenAI: {}", e);
                                continue;
                            }

                            while let Some(message) = stream.next().await {
                                match message {
                                    Ok(tungstenite::Message::Text(text)) => {
                                        let event = match serde_json::from_str::<serde_json::Value>(
                                            &text,
                                        ) {
                                            Ok(event) => event,
                                            Err(e) => {
                                                error!("Failed to parse server event: {}", e);
                                                continue;
                                            }
                                        };

                                        match event["type"].as_str() {
                                            Some("conversation.item.created") => {
                                                if let Some(content) =
                                                    event["item"]["content"].as_array()
                                                {
                                                    for item in content {
                                                        if item["type"] == "audio" {
                                                            if let Some(audio_data) =
                                                                item["audio"].as_str()
                                                            {
                                                                match BASE64.decode(audio_data) {
                                                                    Ok(audio_bytes) => {
                                                                        debug!("Received audio data of size: {}", audio_bytes.len());
                                                                    },
                                                                    Err(e) => error!("Failed to decode audio data: {}", e),
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                            Some("error") => {
                                                error!("OpenAI Realtime API error: {:?}", event);
                                                break;
                                            }
                                            Some("response.completed") => break,
                                            _ => {}
                                        }
                                    }
                                    Ok(tungstenite::Message::Close(_)) => break,
                                    Err(e) => {
                                        error!("Error receiving from OpenAI: {}", e);
                                        break;
                                    }
                                    _ => {}
                                }
                            }
                        } else {
                            error!("OpenAI WebSocket not initialized");
                        }
                    }
                    SpeechCommand::Close => {
                        if let Some(mut stream) = ws_stream.take() {
                            if let Err(e) = stream.send(tungstenite::Message::Close(None)).await {
                                error!("Failed to send close frame: {}", e);
                            }
                        }
                        break;
                    }
                    SpeechCommand::SetTTSProvider(provider) => {
                        let mut current_provider = tts_provider.write().await;
                        *current_provider = provider.clone();
                        info!("TTS provider updated to: {:?}", provider);
                    }
                    SpeechCommand::TextToSpeech(text, options) => {
                        let provider = tts_provider.read().await.clone();

                        match provider {
                            TTSProvider::OpenAI => {
                                info!("Processing TextToSpeech command with OpenAI provider");
                                let openai_config = {
                                    let s = settings.read().await;
                                    s.openai.clone()
                                };

                                if let Some(config) = openai_config {
                                    if let Some(api_key) = config.api_key.as_ref() {
                                        let api_url = "https://api.openai.com/v1/audio/speech";
                                        info!("Sending TTS request to OpenAI API: {}", api_url);

                                        let request_body = json!({
                                            "model": "tts-1",
                                            "input": text,
                                            "voice": options.voice.clone(),
                                            "response_format": "mp3",
                                            "speed": options.speed
                                        });

                                        let response = match http_client
                                            .post(api_url)
                                            .header("Authorization", format!("Bearer {}", api_key))
                                            .header("Content-Type", "application/json")
                                            .body(request_body.to_string())
                                            .send()
                                            .await
                                        {
                                            Ok(response) => {
                                                if !response.status().is_success() {
                                                    let status = response.status();
                                                    let error_text =
                                                        response.text().await.unwrap_or_default();
                                                    error!(
                                                        "OpenAI TTS API error {}: {}",
                                                        status, error_text
                                                    );
                                                    continue;
                                                }
                                                response
                                            }
                                            Err(e) => {
                                                error!(
                                                    "Failed to connect to OpenAI TTS API: {}",
                                                    e
                                                );
                                                continue;
                                            }
                                        };

                                        match response.bytes().await {
                                            Ok(bytes) => {
                                                if let Err(e) = audio_tx.send(bytes.to_vec()) {
                                                    error!(
                                                        "Failed to send OpenAI audio data: {}",
                                                        e
                                                    );
                                                } else {
                                                    debug!(
                                                        "Sent {} bytes of OpenAI audio data",
                                                        bytes.len()
                                                    );
                                                }
                                            }
                                            Err(e) => {
                                                error!("Failed to get OpenAI audio bytes: {}", e);
                                            }
                                        }
                                    } else {
                                        error!("OpenAI API key not configured");
                                    }
                                } else {
                                    error!("OpenAI configuration not found");
                                }
                            }
                            TTSProvider::Kokoro => {
                                info!("Processing TextToSpeech command with Kokoro provider");
                                let kokoro_config = {
                                    let s = settings.read().await;
                                    s.kokoro.clone()
                                };

                                if let Some(config) = kokoro_config {
                                    let api_url_base = match config.api_url.as_deref() {
                                        Some(url) if !url.is_empty() => url,
                                        _ => {
                                            
                                            info!("Using default Kokoro API URL on Docker network");
                                            "http://kokoro-tts-container:8880"
                                        }
                                    };
                                    let api_url = format!(
                                        "{}/v1/audio/speech",
                                        api_url_base.trim_end_matches('/')
                                    );
                                    info!("Sending TTS request to Kokoro API: {}", api_url);

                                    let response_format =
                                        config.default_format.as_deref().unwrap_or("mp3");

                                    let request_body = json!({
                                        "model": "kokoro",
                                        "input": text,
                                        "voice": options.voice.clone(),
                                        "response_format": response_format,
                                        "speed": options.speed,
                                        "stream": options.stream
                                    });

                                    let response = match http_client
                                        .post(&api_url)
                                        .header("Content-Type", "application/json")
                                        .body(request_body.to_string())
                                        .send()
                                        .await
                                    {
                                        Ok(response) => {
                                            if !response.status().is_success() {
                                                let status = response.status();
                                                let error_text =
                                                    response.text().await.unwrap_or_default();
                                                error!(
                                                    "Kokoro API error {}: {}",
                                                    status, error_text
                                                );
                                                continue;
                                            }
                                            response
                                        }
                                        Err(e) => {
                                            error!("Failed to connect to Kokoro API: {}", e);
                                            continue;
                                        }
                                    };

                                    if options.stream {
                                        let stream = response.bytes_stream();
                                        let audio_broadcaster = audio_tx.clone();

                                        tokio::spawn(async move {
                                            let mut stream = Box::pin(stream);

                                            while let Some(item) = stream.next().await {
                                                match item {
                                                    Ok(bytes) => {
                                                        if let Err(e) =
                                                            audio_broadcaster.send(bytes.to_vec())
                                                        {
                                                            error!("Failed to broadcast audio chunk: {}", e);
                                                        }
                                                    }
                                                    Err(e) => {
                                                        error!(
                                                            "Error receiving audio stream: {}",
                                                            e
                                                        );
                                                        break;
                                                    }
                                                }
                                            }
                                            debug!("Finished streaming audio from Kokoro");
                                        });
                                    } else {
                                        match response.bytes().await {
                                            Ok(bytes) => {
                                                if let Err(e) = audio_tx.send(bytes.to_vec()) {
                                                    error!("Failed to send audio data: {}", e);
                                                } else {
                                                    debug!(
                                                        "Sent {} bytes of audio data",
                                                        bytes.len()
                                                    );
                                                }
                                            }
                                            Err(e) => {
                                                error!("Failed to get audio bytes: {}", e);
                                            }
                                        }
                                    }
                                } else {
                                    error!("Kokoro configuration not found");
                                }
                            }
                        }
                    }
                    SpeechCommand::SetSTTProvider(provider) => {
                        let mut current_provider = stt_provider.write().await;
                        *current_provider = provider.clone();
                        info!("STT provider updated to: {:?}", provider);
                    }
                    SpeechCommand::StartTranscription(options) => {
                        let provider = stt_provider.read().await.clone();

                        match provider {
                            STTProvider::Whisper => {
                                info!("Starting Whisper transcription with options: {:?}", options);

                                let whisper_config = {
                                    let s = settings.read().await;
                                    s.whisper.clone()
                                };

                                if let Some(config) = whisper_config {
                                    let api_url = config
                                        .api_url
                                        .as_deref()
                                        .unwrap_or("http://whisper-webui-backend:8000");
                                    info!("Whisper STT initialized with API URL: {}", api_url);

                                    let _ = transcription_tx.send("Whisper STT ready".to_string());
                                } else {
                                    error!("Whisper configuration not found");
                                    let _ = transcription_tx
                                        .send("Whisper STT configuration missing".to_string());
                                }
                            }
                            STTProvider::OpenAI => {
                                info!("Starting OpenAI transcription with options: {:?}", options);
                                let openai_config = {
                                    let s = settings.read().await;
                                    s.openai.clone()
                                };

                                if let Some(config) = openai_config {
                                    if config.api_key.is_some() {
                                        info!("OpenAI STT initialized with API key configured");
                                        let _ =
                                            transcription_tx.send("OpenAI STT ready".to_string());
                                    } else {
                                        error!("OpenAI API key not configured for STT");
                                        let _ = transcription_tx
                                            .send("OpenAI STT API key missing".to_string());
                                    }
                                } else {
                                    error!("OpenAI configuration not found for STT");
                                    let _ = transcription_tx
                                        .send("OpenAI STT configuration missing".to_string());
                                }
                            }
                        }
                    }
                    SpeechCommand::StopTranscription => {
                        info!("Stopping transcription");

                        
                        let _ = transcription_tx.send("Transcription stopped".to_string());

                        
                        match stt_provider.read().await.clone() {
                            STTProvider::Whisper => {
                                debug!("Whisper transcription stopped");
                            }
                            STTProvider::OpenAI => {
                                debug!("OpenAI transcription stopped");
                            }
                        }
                    }
                    SpeechCommand::ProcessAudioChunk(audio_data) => {
                        debug!("Processing audio chunk of size: {} bytes", audio_data.len());

                        let provider = stt_provider.read().await.clone();

                        match provider {
                            STTProvider::Whisper => {
                                let whisper_config = {
                                    let s = settings.read().await;
                                    s.whisper.clone()
                                };

                                if let Some(config) = whisper_config {
                                    let api_url_base = config
                                        .api_url
                                        .as_deref()
                                        .unwrap_or("http://whisper-webui-backend:8000");
                                    let api_url = format!(
                                        "{}/transcription/",
                                        api_url_base.trim_end_matches('/')
                                    );

                                    
                                    
                                    
                                    let (mime_type, file_ext) = if audio_data.len() >= 4 {
                                        let header = &audio_data[0..4];
                                        if header == [0x1A, 0x45, 0xDF, 0xA3] {
                                            
                                            ("audio/webm", "audio.webm")
                                        } else if header == [0x52, 0x49, 0x46, 0x46] {
                                            
                                            ("audio/wav", "audio.wav")
                                        } else {
                                            
                                            info!("Unknown audio format, header: {:?}, defaulting to webm", header);
                                            ("audio/webm", "audio.webm")
                                        }
                                    } else {
                                        ("audio/webm", "audio.webm")
                                    };

                                    info!(
                                        "Detected audio format: {} for upload to Whisper",
                                        mime_type
                                    );

                                    
                                    let mut form = reqwest::multipart::Form::new().part(
                                        "file",
                                        reqwest::multipart::Part::bytes(audio_data)
                                            .file_name(file_ext)
                                            .mime_str(mime_type)
                                            .unwrap_or_else(|_| {
                                                reqwest::multipart::Part::bytes(vec![])
                                                    .mime_str("audio/webm")
                                                    .unwrap()
                                            }),
                                    );

                                    
                                    if let Some(model) = config.default_model.clone() {
                                        form = form.text("model_size", model);
                                    }
                                    if let Some(language) = config.default_language.clone() {
                                        form = form.text("lang", language);
                                    }
                                    if let Some(temperature) = config.temperature {
                                        form = form.text("temperature", temperature.to_string());
                                    }
                                    if let Some(vad_filter) = config.vad_filter {
                                        form = form.text("vad_filter", vad_filter.to_string());
                                    }
                                    if let Some(word_timestamps) = config.word_timestamps {
                                        form = form
                                            .text("word_timestamps", word_timestamps.to_string());
                                    }
                                    if let Some(initial_prompt) = config.initial_prompt.clone() {
                                        form = form.text("initial_prompt", initial_prompt);
                                    }

                                    
                                    let http_client_clone = Arc::clone(&http_client);
                                    let transcription_broadcaster = transcription_tx.clone();
                                    let api_url_clone = api_url.clone();

                                    
                                    {
                                        
                                        match http_client_clone
                                            .post(&api_url_clone)
                                            .multipart(form)
                                            .send()
                                            .await
                                        {
                                            Ok(response) => {
                                                if response.status().is_success() {
                                                    match response.json::<serde_json::Value>().await
                                                    {
                                                        Ok(json) => {
                                                            
                                                            if let Some(identifier) = json
                                                                .get("identifier")
                                                                .and_then(|t| t.as_str())
                                                            {
                                                                info!("Whisper task queued with ID: {}", identifier);

                                                                
                                                                let task_url = format!(
                                                                    "{}/task/{}",
                                                                    api_url_clone.trim_end_matches(
                                                                        "/transcription/"
                                                                    ),
                                                                    identifier
                                                                );
                                                                let mut attempts = 0;
                                                                const MAX_ATTEMPTS: u32 = 30;
                                                                const POLL_DELAY_MS: u64 = 200;

                                                                loop {
                                                                    attempts += 1;
                                                                    if attempts > MAX_ATTEMPTS {
                                                                        error!("Timeout waiting for Whisper task {}", identifier);
                                                                        break;
                                                                    }

                                                                    tokio::time::sleep(tokio::time::Duration::from_millis(POLL_DELAY_MS)).await;

                                                                    match http_client_clone
                                                                        .get(&task_url)
                                                                        .send()
                                                                        .await
                                                                    {
                                                                        Ok(task_response) => {
                                                                            if task_response
                                                                                .status()
                                                                                .is_success()
                                                                            {
                                                                                if let Ok(task_json) = task_response.json::<serde_json::Value>().await {
                                                                                    if let Some(status) = task_json.get("status").and_then(|s| s.as_str()) {
                                                                                        match status {
                                                                                            "completed" => {
                                                                                                
                                                                                                if let Some(result) = task_json.get("result").and_then(|r| r.as_array()) {
                                                                                                    let mut full_text = String::new();
                                                                                                    for segment in result {
                                                                                                        if let Some(text) = segment.get("text").and_then(|t| t.as_str()) {
                                                                                                            full_text.push_str(text);
                                                                                                            full_text.push(' ');
                                                                                                        }
                                                                                                    }

                                                                                                    let transcription_text = full_text.trim().to_string();
                                                                                                    if !transcription_text.is_empty() {
                                                                                                        info!("Whisper transcription: {}", transcription_text);
                                                                                                        let _ = transcription_broadcaster.send(transcription_text.clone());

                                                                                                        
                                                                                                        if Self::is_voice_command(&transcription_text) {
                                                                                                            let session_id = Uuid::new_v4().to_string();
                                                                                                            debug!("Processing as voice command: {}", transcription_text);

                                                                                                            
                                                                                                            if let Ok(voice_cmd) = VoiceCommand::parse(&transcription_text, session_id) {
                                                                                                                debug!("Executing voice command: {:?}", voice_cmd.parsed_intent);

                                                                                                                
                                                                                                                let context_manager = Arc::new(VoiceContextManager::new());
                                                                                                                let response_text = Self::execute_voice_command_with_context(voice_cmd, context_manager).await;

                                                                                                                
                                                                                                                let _ = transcription_broadcaster.send(format!("Response: {}", response_text));
                                                                                                            }
                                                                                                        }
                                                                                                    }
                                                                                                }
                                                                                                break;
                                                                                            },
                                                                                            "failed" => {
                                                                                                error!("Whisper task {} failed: {:?}", identifier, task_json.get("error"));
                                                                                                break;
                                                                                            },
                                                                                            "queued" | "in_progress" => {
                                                                                                
                                                                                                debug!("Whisper task {} status: {}", identifier, status);
                                                                                            },
                                                                                            _ => {
                                                                                                debug!("Unknown Whisper task status: {}", status);
                                                                                            }
                                                                                        }
                                                                                    }
                                                                                }
                                                                            }
                                                                        }
                                                                        Err(e) => {
                                                                            error!("Failed to poll Whisper task {}: {}", identifier, e);
                                                                            break;
                                                                        }
                                                                    }
                                                                }
                                                            } else {
                                                                error!("No identifier field in Whisper response: {:?}", json);
                                                            }
                                                        }
                                                        Err(e) => {
                                                            error!("Failed to parse Whisper response JSON: {}", e);
                                                        }
                                                    }
                                                } else {
                                                    let status = response.status();
                                                    let error_text =
                                                        response.text().await.unwrap_or_default();
                                                    error!(
                                                        "Whisper API error {}: {}",
                                                        status, error_text
                                                    );
                                                }
                                            }
                                            Err(e) => {
                                                error!("Failed to connect to Whisper API: {}", e);
                                            }
                                        }
                                    }
                                } else {
                                    error!("Whisper configuration not found for audio processing");
                                }
                            }
                            STTProvider::OpenAI => {
                                debug!("Processing audio chunk with OpenAI STT");
                                let openai_config = {
                                    let s = settings.read().await;
                                    s.openai.clone()
                                };

                                if let Some(config) = openai_config {
                                    if let Some(api_key) = config.api_key.as_ref() {
                                        let api_url =
                                            "https://api.openai.com/v1/audio/transcriptions";

                                        let form = reqwest::multipart::Form::new()
                                            .part(
                                                "file",
                                                reqwest::multipart::Part::bytes(audio_data)
                                                    .file_name("audio.wav")
                                                    .mime_str("audio/wav")
                                                    .unwrap_or_else(|_| {
                                                        reqwest::multipart::Part::bytes(vec![])
                                                            .mime_str("audio/wav")
                                                            .unwrap()
                                                    }),
                                            )
                                            .text("model", "whisper-1")
                                            .text("response_format", "json");

                                        let http_client_clone = Arc::clone(&http_client);
                                        let transcription_broadcaster = transcription_tx.clone();
                                        let api_key_clone = api_key.clone();

                                        tokio::spawn(async move {
                                            match http_client_clone
                                                .post(api_url)
                                                .header(
                                                    "Authorization",
                                                    format!("Bearer {}", api_key_clone),
                                                )
                                                .multipart(form)
                                                .send()
                                                .await
                                            {
                                                Ok(response) => {
                                                    if response.status().is_success() {
                                                        match response
                                                            .json::<serde_json::Value>()
                                                            .await
                                                        {
                                                            Ok(json) => {
                                                                if let Some(text) = json
                                                                    .get("text")
                                                                    .and_then(|t| t.as_str())
                                                                {
                                                                    if !text.trim().is_empty() {
                                                                        debug!("OpenAI transcription: {}", text);
                                                                        let _ = transcription_broadcaster.send(text.to_string());
                                                                    }
                                                                } else {
                                                                    error!("No text field in OpenAI response: {:?}", json);
                                                                }
                                                            }
                                                            Err(e) => {
                                                                error!("Failed to parse OpenAI response JSON: {}", e);
                                                            }
                                                        }
                                                    } else {
                                                        let status = response.status();
                                                        let error_text = response
                                                            .text()
                                                            .await
                                                            .unwrap_or_default();
                                                        error!(
                                                            "OpenAI STT API error {}: {}",
                                                            status, error_text
                                                        );
                                                    }
                                                }
                                                Err(e) => {
                                                    error!(
                                                        "Failed to connect to OpenAI STT API: {}",
                                                        e
                                                    );
                                                }
                                            }
                                        });
                                    } else {
                                        error!(
                                            "OpenAI API key not configured for audio processing"
                                        );
                                    }
                                } else {
                                    error!("OpenAI configuration not found for audio processing");
                                }
                            }
                        }
                    }
                }
            }
        });
    }

    
    fn start_tagged_tts_handler(&self) {
        if let Some(rx) = &self.tts_response_rx {
            let rx = Arc::clone(rx);
            let sender = Arc::clone(&self.sender);
            let tag_manager = Arc::clone(&self.tag_manager);

            task::spawn(async move {
                let mut receiver = rx.lock().await;

                while let Some(tagged_response) = receiver.recv().await {
                    info!(
                        "Processing tagged TTS response: {} (tag: {})",
                        tagged_response.response.text,
                        tagged_response.tag.short_id()
                    );

                    
                    let tts_command = SpeechCommand::TextToSpeech(
                        tagged_response.response.text.clone(),
                        SpeechOptions::default(),
                    );

                    
                    if let Err(e) = sender.lock().await.send(tts_command).await {
                        error!("Failed to send tagged response to TTS: {}", e);
                    } else {
                        debug!(
                            "Successfully routed tagged response {} to TTS",
                            tagged_response.tag.short_id()
                        );
                    }

                    
                    tag_manager.cleanup_expired_commands().await;
                }

                info!("Tagged TTS response handler terminated");
            });
        }
    }

    pub async fn initialize(&self) -> VisionFlowResult<()> {
        let command = SpeechCommand::Initialize;
        self.sender.lock().await.send(command).await.map_err(|e| {
            VisionFlowError::Speech(VisionSpeechError::InitializationFailed(e.to_string()))
        })?;
        Ok(())
    }

    pub async fn send_message(&self, message: String) -> VisionFlowResult<()> {
        let command = SpeechCommand::SendMessage(message);
        self.sender.lock().await.send(command).await.map_err(|e| {
            VisionFlowError::Speech(VisionSpeechError::TTSFailed {
                text: "message".to_string(),
                reason: e.to_string(),
            })
        })?;
        Ok(())
    }

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    pub async fn text_to_speech(
        &self,
        text: String,
        options: SpeechOptions,
    ) -> VisionFlowResult<()> {
        let command = SpeechCommand::TextToSpeech(text.clone(), options);
        self.sender.lock().await.send(command).await.map_err(|e| {
            VisionFlowError::Speech(VisionSpeechError::TTSFailed {
                text,
                reason: e.to_string(),
            })
        })?;
        Ok(())
    }

    pub async fn close(&self) -> VisionFlowResult<()> {
        let command = SpeechCommand::Close;
        self.sender.lock().await.send(command).await.map_err(|e| {
            VisionFlowError::Speech(VisionSpeechError::InitializationFailed(format!(
                "Failed to close speech service: {}",
                e
            )))
        })?;
        Ok(())
    }

    pub async fn set_tts_provider(&self, provider: TTSProvider) -> VisionFlowResult<()> {
        let command = SpeechCommand::SetTTSProvider(provider.clone());
        self.sender.lock().await.send(command).await.map_err(|e| {
            VisionFlowError::Speech(VisionSpeechError::ProviderConfigError {
                provider: format!("{:?}", provider),
                reason: e.to_string(),
            })
        })?;
        Ok(())
    }

    
    
    
    
    
    
    
    
    
    pub fn subscribe_to_audio(&self) -> broadcast::Receiver<Vec<u8>> {
        self.audio_tx.subscribe()
    }

    
    pub async fn get_tts_provider(&self) -> TTSProvider {
        self.tts_provider.read().await.clone()
    }

    pub async fn set_stt_provider(&self, provider: STTProvider) -> VisionFlowResult<()> {
        let command = SpeechCommand::SetSTTProvider(provider.clone());
        self.sender.lock().await.send(command).await.map_err(|e| {
            VisionFlowError::Speech(VisionSpeechError::ProviderConfigError {
                provider: format!("{:?}", provider),
                reason: e.to_string(),
            })
        })?;
        Ok(())
    }

    pub async fn start_transcription(&self, options: TranscriptionOptions) -> VisionFlowResult<()> {
        let command = SpeechCommand::StartTranscription(options);
        self.sender.lock().await.send(command).await.map_err(|e| {
            VisionFlowError::Speech(VisionSpeechError::STTFailed {
                reason: format!("Failed to start transcription: {}", e),
            })
        })?;
        Ok(())
    }

    pub async fn stop_transcription(&self) -> VisionFlowResult<()> {
        let command = SpeechCommand::StopTranscription;
        self.sender.lock().await.send(command).await.map_err(|e| {
            VisionFlowError::Speech(VisionSpeechError::STTFailed {
                reason: format!("Failed to stop transcription: {}", e),
            })
        })?;
        Ok(())
    }

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    pub async fn process_audio_chunk(&self, audio_data: Vec<u8>) -> VisionFlowResult<()> {
        let command = SpeechCommand::ProcessAudioChunk(audio_data);
        self.sender.lock().await.send(command).await.map_err(|e| {
            VisionFlowError::Speech(VisionSpeechError::AudioProcessingFailed {
                reason: format!("Failed to process audio chunk: {}", e),
            })
        })?;
        Ok(())
    }

    
    
    
    
    
    
    
    
    
    pub fn subscribe_to_transcriptions(&self) -> broadcast::Receiver<String> {
        self.transcription_tx.subscribe()
    }

    
    pub async fn process_voice_command(&self, text: String) -> VisionFlowResult<String> {
        let session_id = Uuid::new_v4().to_string();

        if Self::is_voice_command(&text) {
            if let Ok(voice_cmd) = VoiceCommand::parse(&text, session_id) {
                let response = Self::execute_voice_command_with_context(
                    voice_cmd.clone(),
                    Arc::clone(&self.context_manager),
                )
                .await;

                
                let _ = self
                    .context_manager
                    .add_conversation_turn(
                        &voice_cmd.session_id,
                        text,
                        response.clone(),
                        Some(voice_cmd.parsed_intent),
                    )
                    .await;

                
                let contextual_response = self
                    .context_manager
                    .generate_contextual_response(&voice_cmd.session_id, &response)
                    .await;

                Ok(contextual_response)
            } else {
                Ok("Sorry, I couldn't understand that command.".to_string())
            }
        } else {
            Ok("That doesn't appear to be a voice command.".to_string())
        }
    }

    
    pub async fn get_conversation_context(
        &self,
        session_id: &str,
    ) -> Option<crate::actors::voice_commands::ConversationContext> {
        self.context_manager.get_context(session_id).await
    }

    
    pub async fn session_needs_follow_up(&self, session_id: &str) -> bool {
        self.context_manager.needs_follow_up(session_id).await
    }

    
    pub fn get_tag_manager(&self) -> Arc<VoiceTagManager> {
        Arc::clone(&self.tag_manager)
    }

    
    pub fn get_transcription_sender(&self) -> broadcast::Sender<String> {
        self.transcription_tx.clone()
    }

    
    pub async fn process_voice_command_with_tags(
        &self,
        text: String,
        session_id: String,
    ) -> VisionFlowResult<String> {
        use crate::services::speech_voice_integration::VoiceSwarmIntegration;
use crate::utils::json::{from_json, to_json};

        match VoiceSwarmIntegration::process_voice_command_with_tags(
            self,
            text,
            session_id,
            Arc::clone(&self.tag_manager),
        )
        .await
        {
            Ok(tag) => Ok(format!(
                "Voice command processed with tag: {}",
                tag.short_id()
            )),
            Err(e) => {
                error!("Failed to process tagged voice command: {}", e);
                Err(VisionFlowError::Speech(
                    VisionSpeechError::AudioProcessingFailed {
                        reason: format!("Tagged voice command failed: {}", e),
                    },
                ))
            }
        }
    }

    
    fn is_voice_command(text: &str) -> bool {
        let command_keywords = [
            "spawn",
            "agent",
            "status",
            "list",
            "stop",
            "add",
            "remove",
            "help",
            "show",
            "create",
            "delete",
            "query",
            "execute",
            "run",
            "node",
            "graph",
            "connect",
            "researcher",
            "coder",
            "analyst",
        ];

        let lower = text.to_lowercase();
        command_keywords
            .iter()
            .any(|keyword| lower.contains(keyword))
    }

    
    async fn execute_voice_command_with_context(
        voice_cmd: VoiceCommand,
        context_manager: Arc<VoiceContextManager>,
    ) -> String {
        let mcp_host =
            std::env::var("MCP_HOST").unwrap_or_else(|_| "multi-agent-container".to_string());
        let mcp_port = std::env::var("MCP_TCP_PORT").unwrap_or_else(|_| "9500".to_string());

        
        let session_id = context_manager
            .get_or_create_session(Some(voice_cmd.session_id.clone()), None)
            .await;

        match voice_cmd.parsed_intent {
            crate::actors::voice_commands::SwarmIntent::SpawnAgent { agent_type, .. } => {
                info!("Executing spawn agent command for type: {}", agent_type);

                
                match call_swarm_init(&mcp_host, &mcp_port, "mesh", 10, "balanced").await {
                    Ok(swarm_result) => {
                        let swarm_id = swarm_result.get("swarmId")
                            .and_then(|s| s.as_str())
                            .unwrap_or("default-swarm");

                        
                        match call_agent_spawn(&mcp_host, &mcp_port, &agent_type, swarm_id).await {
                            Ok(_) => {
                                
                                let mut params = std::collections::HashMap::new();
                                params.insert("agent_type".to_string(), agent_type.clone());
                                params.insert("swarm_id".to_string(), swarm_id.to_string());

                                let _ = context_manager.add_pending_operation(
                                    &session_id,
                                    "spawn_agent".to_string(),
                                    params,
                                    None,
                                ).await;

                                format!("Successfully spawned {} agent in swarm {}.", agent_type, swarm_id)
                            }
                            Err(e) => {
                                error!("Failed to spawn agent: {}", e);
                                format!("Failed to spawn {} agent. Error: {}", agent_type, e)
                            }
                        }
                    }
                    Err(e) => {
                        error!("Failed to initialize swarm: {}", e);
                        format!("Failed to initialize swarm for agent spawning. Error: {}", e)
                    }
                }
            },

            crate::actors::voice_commands::SwarmIntent::QueryStatus { target } => {
                info!("Executing status query for target: {:?}", target);

                match call_agent_list(&mcp_host, &mcp_port, "all").await {
                    Ok(agent_result) => {
                        
                        let agent_count = agent_result.get("content")
                            .and_then(|c| c.as_array())
                            .map(|arr| arr.len())
                            .unwrap_or(0);

                        if agent_count > 0 {
                            format!("System status: {} agents active and operational.", agent_count)
                        } else {
                            "System status: No active agents found.".to_string()
                        }
                    }
                    Err(e) => {
                        error!("Failed to query agent status: {}", e);
                        format!("Failed to query system status. Error: {}", e)
                    }
                }
            },

            crate::actors::voice_commands::SwarmIntent::ListAgents => {
                info!("Executing list agents command");

                match call_agent_list(&mcp_host, &mcp_port, "all").await {
                    Ok(agent_result) => {
                        
                        if let Some(content) = agent_result.get("content").and_then(|c| c.as_array()) {
                            let mut agent_names: Vec<String> = Vec::new();
                            for agent in content.iter() {
                                if let Some(text) = agent.get("text").and_then(|t| t.as_str()) {
                                    if let Ok(parsed) = serde_json::from_str::<serde_json::Value>(text) {
                                        if let Some(agents) = parsed.get("agents").and_then(|a| a.as_array()) {
                                            for a in agents {
                                                if let Some(name) = a.get("name").and_then(|n| n.as_str()) {
                                                    agent_names.push(name.to_string());
                                                }
                                            }
                                        }
                                    }
                                }
                            }

                            if agent_names.is_empty() {
                                "No agents are currently active.".to_string()
                            } else {
                                format!("Active agents: {}.", agent_names.join(", "))
                            }
                        } else {
                            "No agents found in the system.".to_string()
                        }
                    }
                    Err(e) => {
                        error!("Failed to list agents: {}", e);
                        format!("Failed to list agents. Error: {}", e)
                    }
                }
            },

            crate::actors::voice_commands::SwarmIntent::ExecuteTask { description, priority } => {
                info!("Executing task: {} with priority: {:?}", description, priority);

                let priority_str = match priority {
                    crate::actors::voice_commands::TaskPriority::Critical => "critical",
                    crate::actors::voice_commands::TaskPriority::High => "high",
                    crate::actors::voice_commands::TaskPriority::Medium => "medium",
                    crate::actors::voice_commands::TaskPriority::Low => "low",
                };

                match call_task_orchestrate(&mcp_host, &mcp_port, &description, Some(priority_str), Some("balanced")).await {
                    Ok(task_result) => {
                        let task_id = task_result.get("taskId")
                            .and_then(|id| id.as_str())
                            .unwrap_or("unknown");

                        
                        let mut params = std::collections::HashMap::new();
                        params.insert("task_id".to_string(), task_id.to_string());
                        params.insert("description".to_string(), description.clone());
                        params.insert("priority".to_string(), priority_str.to_string());

                        let _ = context_manager.add_pending_operation(
                            &session_id,
                            "execute_task".to_string(),
                            params,
                            Some(time::now() + chrono::Duration::minutes(30)), 
                        ).await;

                        format!("Task '{}' has been assigned to the swarm with ID: {}.", description, task_id)
                    }
                    Err(e) => {
                        error!("Failed to orchestrate task: {}", e);
                        format!("Failed to execute task '{}'. Error: {}", description, e)
                    }
                }
            },

            crate::actors::voice_commands::SwarmIntent::Help => {
                "You can ask me to spawn agents, check status, list agents, or execute tasks. Just speak naturally!".to_string()
            },

            _ => {
                "Command received but not yet implemented.".to_string()
            }
        }
    }
}

--------------------------------------------------------------------------------
FILE: src/services/semantic_analyzer.rs
PURPOSE: Document semantic analysis service
--------------------------------------------------------------------------------
//! Advanced semantic analysis service for knowledge graph enhancement

use crate::models::metadata::Metadata;
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};
use std::path::Path;

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SemanticFeatures {
    
    pub id: String,
    
    pub topics: HashMap<String, f32>,
    
    pub domains: Vec<KnowledgeDomain>,
    
    pub temporal: TemporalFeatures,
    
    pub structural: StructuralFeatures,
    
    pub content: ContentFeatures,
    
    pub agent_patterns: Option<AgentCommunicationPatterns>,
    
    pub importance_score: f32,
}

///
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum KnowledgeDomain {
    Mathematics,
    Physics,
    ComputerScience,
    Biology,
    Chemistry,
    Engineering,
    DataScience,
    MachineLearning,
    WebDevelopment,
    SystemsProgramming,
    DevOps,
    Security,
    Documentation,
    Configuration,
    Testing,
    UserInterface,
    Database,
    Networking,
    CloudComputing,
    Other(String),
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TemporalFeatures {
    
    pub created_at: Option<DateTime<Utc>>,
    
    pub modified_at: Option<DateTime<Utc>>,
    
    pub modification_frequency: f32,
    
    pub co_evolution_score: f32,
    
    pub temporal_cluster: Option<u32>,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StructuralFeatures {
    
    pub file_type: String,
    
    pub directory_depth: u32,
    
    pub dependency_count: u32,
    
    pub complexity_score: f32,
    
    pub loc: Option<u32>,
    
    pub module_path: Vec<String>,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ContentFeatures {
    
    pub language: String,
    
    pub key_terms: Vec<String>,
    
    pub embeddings: Option<Vec<f32>>,
    
    pub content_hash: String,
    
    pub documentation_score: f32,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentCommunicationPatterns {
    
    pub send_frequency: f32,
    
    pub receive_frequency: f32,
    
    pub communication_partners: HashMap<String, f32>,
    
    pub message_types: HashSet<String>,
    
    pub clustering_coefficient: f32,
    
    pub network_role: NetworkRole,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum NetworkRole {
    Hub,        
    Bridge,     
    Peripheral, 
    Isolated,   
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SemanticAnalyzerConfig {
    
    pub enable_topics: bool,
    
    pub num_topics: usize,
    
    pub enable_temporal: bool,
    
    pub enable_agent_patterns: bool,
    
    pub min_term_frequency: f32,
    
    pub max_features: usize,
    
    pub enable_caching: bool,
}

impl Default for SemanticAnalyzerConfig {
    fn default() -> Self {
        Self {
            enable_topics: true,
            num_topics: 10,
            enable_temporal: true,
            enable_agent_patterns: false,
            min_term_frequency: 0.01,
            max_features: 100,
            enable_caching: true,
        }
    }
}

///
pub struct SemanticAnalyzer {
    config: SemanticAnalyzerConfig,
    feature_cache: HashMap<String, SemanticFeatures>,
    domain_patterns: HashMap<KnowledgeDomain, Vec<String>>,
}

impl Clone for SemanticAnalyzer {
    fn clone(&self) -> Self {
        Self {
            config: self.config.clone(),
            feature_cache: self.feature_cache.clone(),
            domain_patterns: self.domain_patterns.clone(),
        }
    }
}

impl SemanticAnalyzer {
    
    pub fn new(config: SemanticAnalyzerConfig) -> Self {
        let mut analyzer = Self {
            config,
            feature_cache: HashMap::new(),
            domain_patterns: HashMap::new(),
        };
        analyzer.initialize_domain_patterns();
        analyzer
    }

    
    fn initialize_domain_patterns(&mut self) {
        self.domain_patterns.insert(
            KnowledgeDomain::Mathematics,
            vec![
                "theorem", "proof", "equation", "matrix", "vector", "calculus", "algebra",
            ]
            .into_iter()
            .map(String::from)
            .collect(),
        );

        self.domain_patterns.insert(
            KnowledgeDomain::MachineLearning,
            vec![
                "model",
                "training",
                "neural",
                "network",
                "tensor",
                "gradient",
                "optimizer",
            ]
            .into_iter()
            .map(String::from)
            .collect(),
        );

        self.domain_patterns.insert(
            KnowledgeDomain::WebDevelopment,
            vec![
                "react",
                "vue",
                "angular",
                "html",
                "css",
                "javascript",
                "frontend",
                "backend",
            ]
            .into_iter()
            .map(String::from)
            .collect(),
        );

        self.domain_patterns.insert(
            KnowledgeDomain::SystemsProgramming,
            vec![
                "kernel", "memory", "pointer", "thread", "mutex", "syscall", "buffer",
            ]
            .into_iter()
            .map(String::from)
            .collect(),
        );

        self.domain_patterns.insert(
            KnowledgeDomain::Database,
            vec![
                "sql",
                "query",
                "table",
                "index",
                "transaction",
                "schema",
                "relation",
            ]
            .into_iter()
            .map(String::from)
            .collect(),
        );

        self.domain_patterns.insert(
            KnowledgeDomain::Security,
            vec![
                "encryption",
                "authentication",
                "vulnerability",
                "exploit",
                "firewall",
                "ssl",
                "tls",
            ]
            .into_iter()
            .map(String::from)
            .collect(),
        );
    }

    
    pub fn analyze_metadata(&mut self, metadata: &Metadata) -> SemanticFeatures {
        
        let id = metadata.file_name.trim_end_matches(".md").to_string();

        
        if self.config.enable_caching {
            if let Some(cached) = self.feature_cache.get(&id) {
                return cached.clone();
            }
        }

        
        let topics = self.extract_topics(metadata);
        let domains = self.classify_domains(&topics, &metadata.file_name);
        let temporal = self.extract_temporal_features(metadata);
        let structural = self.extract_structural_features(metadata);
        let content = self.extract_content_features(metadata);
        let importance_score = self.calculate_importance_score(&topics, &temporal, &structural);

        let features = SemanticFeatures {
            id: id.clone(),
            topics,
            domains,
            temporal,
            structural,
            content,
            agent_patterns: None,
            importance_score,
        };

        
        if self.config.enable_caching {
            self.feature_cache.insert(id, features.clone());
        }

        features
    }

    
    fn extract_topics(&self, metadata: &Metadata) -> HashMap<String, f32> {
        let mut topics = HashMap::new();

        if !self.config.enable_topics {
            return topics;
        }

        
        for (topic, &count) in &metadata.topic_counts {
            let weight = (count as f32).ln() + 1.0;
            topics.insert(topic.clone(), weight);
        }

        
        let total: f32 = topics.values().sum();
        if total > 0.0 {
            for weight in topics.values_mut() {
                *weight /= total;
            }
        }

        topics
    }

    
    fn classify_domains(&self, topics: &HashMap<String, f32>, path: &str) -> Vec<KnowledgeDomain> {
        let mut domains = Vec::new();
        let mut domain_scores: HashMap<KnowledgeDomain, f32> = HashMap::new();

        
        let extension = Path::new(path)
            .extension()
            .and_then(|e| e.to_str())
            .unwrap_or("");

        match extension {
            "py" => domain_scores.insert(KnowledgeDomain::DataScience, 0.3),
            "rs" => domain_scores.insert(KnowledgeDomain::SystemsProgramming, 0.4),
            "js" | "jsx" | "ts" | "tsx" => {
                domain_scores.insert(KnowledgeDomain::WebDevelopment, 0.4)
            }
            "sql" => domain_scores.insert(KnowledgeDomain::Database, 0.5),
            "cu" | "cuda" => domain_scores.insert(KnowledgeDomain::Engineering, 0.4),
            _ => None,
        };

        
        for (domain, patterns) in &self.domain_patterns {
            let mut score = 0.0;
            for pattern in patterns {
                if let Some(&weight) = topics.get(pattern) {
                    score += weight;
                }
            }
            if score > 0.0 {
                *domain_scores.entry(domain.clone()).or_insert(0.0) += score;
            }
        }

        
        let mut scored_domains: Vec<_> = domain_scores.into_iter().collect();
        scored_domains.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

        for (domain, score) in scored_domains.iter().take(3) {
            if *score > 0.1 {
                domains.push(domain.clone());
            }
        }

        if domains.is_empty() {
            domains.push(KnowledgeDomain::Other(extension.to_string()));
        }

        domains
    }

    
    fn extract_temporal_features(&self, _metadata: &Metadata) -> TemporalFeatures {
        TemporalFeatures {
            created_at: None,            
            modified_at: None,           
            modification_frequency: 1.0, 
            co_evolution_score: 0.0,     
            temporal_cluster: None,
        }
    }

    
    fn extract_structural_features(&self, metadata: &Metadata) -> StructuralFeatures {
        let path = Path::new(&metadata.file_name);
        let directory_depth = path.components().count() as u32;
        let file_type = path
            .extension()
            .and_then(|e| e.to_str())
            .unwrap_or("unknown")
            .to_string();

        StructuralFeatures {
            file_type,
            directory_depth,
            dependency_count: 0, 
            complexity_score: (metadata.topic_counts.len() as f32).ln() + 1.0,
            loc: Some(metadata.file_size as u32),
            module_path: path
                .parent()
                .map(|p| p.to_string_lossy().split('/').map(String::from).collect())
                .unwrap_or_default(),
        }
    }

    
    fn extract_content_features(&self, metadata: &Metadata) -> ContentFeatures {
        let mut key_terms: Vec<_> = metadata.topic_counts.keys().cloned().collect();
        key_terms.sort_by_key(|k| std::cmp::Reverse(metadata.topic_counts[k]));
        key_terms.truncate(20);

        ContentFeatures {
            language: self.detect_language(&metadata.file_name),
            key_terms,
            embeddings: None, 
            content_hash: metadata.sha1.clone(), 
            documentation_score: self.calculate_documentation_score(metadata),
        }
    }

    
    fn detect_language(&self, path: &str) -> String {
        let extension = Path::new(path)
            .extension()
            .and_then(|e| e.to_str())
            .unwrap_or("");

        match extension {
            "py" => "Python",
            "rs" => "Rust",
            "js" | "jsx" => "JavaScript",
            "ts" | "tsx" => "TypeScript",
            "java" => "Java",
            "cpp" | "cc" | "cxx" => "C++",
            "c" | "h" => "C",
            "go" => "Go",
            "rb" => "Ruby",
            "php" => "PHP",
            "swift" => "Swift",
            "kt" => "Kotlin",
            "scala" => "Scala",
            "r" => "R",
            "m" => "MATLAB",
            "cu" | "cuda" => "CUDA",
            "md" => "Markdown",
            "txt" => "Text",
            "json" => "JSON",
            "yaml" | "yml" => "YAML",
            "toml" => "TOML",
            "xml" => "XML",
            "html" => "HTML",
            "css" => "CSS",
            "sql" => "SQL",
            _ => "Unknown",
        }
        .to_string()
    }

    
    fn calculate_documentation_score(&self, metadata: &Metadata) -> f32 {
        let mut score: f32 = 0.0;

        
        let doc_terms = [
            "readme",
            "doc",
            "comment",
            "description",
            "example",
            "usage",
            "api",
        ];
        for term in doc_terms {
            if metadata.topic_counts.contains_key(term) {
                score += 0.2;
            }
        }

        
        if metadata.file_name.ends_with(".md") {
            score += 0.3;
        }

        score.min(1.0)
    }

    
    fn calculate_importance_score(
        &self,
        topics: &HashMap<String, f32>,
        temporal: &TemporalFeatures,
        structural: &StructuralFeatures,
    ) -> f32 {
        let mut score = 0.0;

        
        let topic_entropy = -topics
            .values()
            .filter(|&&v| v > 0.0)
            .map(|&v| v * v.ln())
            .sum::<f32>();
        score += topic_entropy.min(1.0) * 0.3;

        
        score += temporal.modification_frequency.min(1.0) * 0.2;

        
        score += (structural.dependency_count as f32 / 10.0).min(1.0) * 0.3;

        
        score += (structural.complexity_score / 5.0).min(1.0) * 0.2;

        score.min(1.0)
    }

    
    pub fn analyze_agent_patterns(
        &mut self,
        agent_id: &str,
        messages: &[(String, String, DateTime<Utc>)], 
    ) -> AgentCommunicationPatterns {
        let mut send_count = 0;
        let mut receive_count = 0;
        let mut partners: HashMap<String, f32> = HashMap::new();
        let mut message_types = HashSet::new();

        for (from, to, _timestamp) in messages {
            if from == agent_id {
                send_count += 1;
                *partners.entry(to.clone()).or_insert(0.0) += 1.0;
            }
            if to == agent_id {
                receive_count += 1;
                *partners.entry(from.clone()).or_insert(0.0) += 1.0;
            }
            
            message_types.insert("default".to_string());
        }

        let total_messages = (send_count + receive_count) as f32;
        let send_frequency = send_count as f32 / total_messages.max(1.0);
        let receive_frequency = receive_count as f32 / total_messages.max(1.0);

        
        let degree = partners.len();
        let network_role = if degree == 0 {
            NetworkRole::Isolated
        } else if degree > 10 {
            NetworkRole::Hub
        } else if degree > 5 {
            NetworkRole::Bridge
        } else {
            NetworkRole::Peripheral
        };

        AgentCommunicationPatterns {
            send_frequency,
            receive_frequency,
            communication_partners: partners,
            message_types,
            clustering_coefficient: 0.0, 
            network_role,
        }
    }

    
    pub fn compute_similarity(
        &self,
        features1: &SemanticFeatures,
        features2: &SemanticFeatures,
    ) -> f32 {
        let mut similarity = 0.0;

        
        let topic_sim = self.cosine_similarity(&features1.topics, &features2.topics);
        similarity += topic_sim * 0.4;

        
        let domain_overlap = features1
            .domains
            .iter()
            .filter(|d| features2.domains.contains(d))
            .count() as f32;
        let domain_sim =
            domain_overlap / (features1.domains.len().max(features2.domains.len()) as f32).max(1.0);
        similarity += domain_sim * 0.2;

        
        if features1.structural.file_type == features2.structural.file_type {
            similarity += 0.1;
        }

        let depth_diff = (features1.structural.directory_depth as f32
            - features2.structural.directory_depth as f32)
            .abs();
        similarity += (1.0 / (1.0 + depth_diff)) * 0.1;

        
        let temporal_sim = 1.0
            / (1.0
                + (features1.temporal.modification_frequency
                    - features2.temporal.modification_frequency)
                    .abs());
        similarity += temporal_sim * 0.1;

        
        let importance_diff = (features1.importance_score - features2.importance_score).abs();
        similarity += (1.0 - importance_diff) * 0.1;

        similarity.min(1.0)
    }

    
    fn cosine_similarity(
        &self,
        topics1: &HashMap<String, f32>,
        topics2: &HashMap<String, f32>,
    ) -> f32 {
        let mut dot_product = 0.0;
        let mut norm1 = 0.0;
        let mut norm2 = 0.0;

        let all_topics: HashSet<_> = topics1.keys().chain(topics2.keys()).collect();

        for topic in all_topics {
            let v1 = topics1.get(topic.as_str()).unwrap_or(&0.0);
            let v2 = topics2.get(topic.as_str()).unwrap_or(&0.0);

            dot_product += v1 * v2;
            norm1 += v1 * v1;
            norm2 += v2 * v2;
        }

        if norm1 > 0.0 && norm2 > 0.0 {
            dot_product / (norm1.sqrt() * norm2.sqrt())
        } else {
            0.0
        }
    }

    
    pub fn get_cached_features(&self) -> &HashMap<String, SemanticFeatures> {
        &self.feature_cache
    }

    
    pub fn clear_cache(&mut self) {
        self.feature_cache.clear();
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_semantic_analyzer_creation() {
        let config = SemanticAnalyzerConfig::default();
        let analyzer = SemanticAnalyzer::new(config);
        assert!(analyzer.domain_patterns.len() > 0);
    }

    #[test]
    fn test_domain_classification() {
        let analyzer = SemanticAnalyzer::new(SemanticAnalyzerConfig::default());

        let mut topics = HashMap::new();
        topics.insert("neural".to_string(), 0.3);
        topics.insert("network".to_string(), 0.2);
        topics.insert("training".to_string(), 0.4);

        let domains = analyzer.classify_domains(&topics, "model.py");
        assert!(
            domains.contains(&KnowledgeDomain::MachineLearning)
                || domains.contains(&KnowledgeDomain::DataScience)
        );
    }

    #[test]
    fn test_language_detection() {
        let analyzer = SemanticAnalyzer::new(SemanticAnalyzerConfig::default());

        assert_eq!(analyzer.detect_language("test.py"), "Python");
        assert_eq!(analyzer.detect_language("main.rs"), "Rust");
        assert_eq!(analyzer.detect_language("app.js"), "JavaScript");
        assert_eq!(analyzer.detect_language("kernel.cu"), "CUDA");
    }

    #[test]
    fn test_similarity_computation() {
        let analyzer = SemanticAnalyzer::new(SemanticAnalyzerConfig::default());

        let mut topics1 = HashMap::new();
        topics1.insert("test".to_string(), 0.5);
        topics1.insert("unit".to_string(), 0.5);

        let mut topics2 = HashMap::new();
        topics2.insert("test".to_string(), 0.4);
        topics2.insert("integration".to_string(), 0.6);

        let similarity = analyzer.cosine_similarity(&topics1, &topics2);
        assert!(similarity > 0.0 && similarity < 1.0);
    }
}

--------------------------------------------------------------------------------
FILE: src/services/semantic_type_registry.rs
PURPOSE: Type system for semantic relationships and GPU force configs
--------------------------------------------------------------------------------
//! Semantic Type Registry
//!
//! Dynamic registry for ontology relationship types that decouples ontology from code.
//! Eliminates hard-coded edge_type_to_int mappings and enables runtime type registration.
//!
//! ## Schema-Code Decoupling
//!
//! This registry enables adding new relationship types (e.g., ngm:requires, ngm:enables)
//! without requiring CUDA recompilation. The workflow is:
//!
//! 1. Register new relationship type with `registry.register("ngm:new-type", config)`
//! 2. Build GPU buffer with `registry.build_dynamic_gpu_buffer()`
//! 3. Upload to GPU with `set_dynamic_relationship_buffer(buffer.as_ptr(), count, true)`
//! 4. GPU kernel uses lookup table instead of switch statement
//!
//! Hot-reload is supported: call `update_dynamic_relationship_config` to update
//! individual types without full buffer re-upload.

use std::collections::HashMap;
use std::sync::atomic::{AtomicU32, Ordering};
use std::sync::RwLock;

/// Force configuration for a relationship type
#[derive(Clone, Copy, Debug)]
#[repr(C)]
pub struct RelationshipForceConfig {
    /// Spring strength (0.0 - 1.0, can be negative for repulsion)
    pub strength: f32,
    /// Rest length for spring calculations
    pub rest_length: f32,
    /// Whether the force is directional (source  target only)
    pub is_directional: bool,
    /// Force type identifier for GPU kernel dispatch:
    /// - 0: Standard spring force
    /// - 1: Orbit clustering (has-part)
    /// - 2: Cross-domain long-range spring
    /// - 3: Repulsion force
    pub force_type: u32,
}

/// GPU-compatible dynamic force configuration
/// Matches the DynamicForceConfig struct in semantic_forces.cu
#[derive(Clone, Copy, Debug)]
#[repr(C)]
pub struct DynamicForceConfigGPU {
    /// Spring strength (can be negative for repulsion)
    pub strength: f32,
    /// Rest length for spring calculations
    pub rest_length: f32,
    /// 1 = directional (source  target), 0 = bidirectional
    pub is_directional: i32,
    /// Force behavior type (0=spring, 1=orbit, 2=cross-domain, 3=repulsion)
    pub force_type: u32,
}

impl Default for DynamicForceConfigGPU {
    fn default() -> Self {
        Self {
            strength: 0.5,
            rest_length: 100.0,
            is_directional: 0,
            force_type: 0,
        }
    }
}

impl From<&RelationshipForceConfig> for DynamicForceConfigGPU {
    fn from(config: &RelationshipForceConfig) -> Self {
        Self {
            strength: config.strength,
            rest_length: config.rest_length,
            is_directional: if config.is_directional { 1 } else { 0 },
            force_type: config.force_type,
        }
    }
}

impl Default for RelationshipForceConfig {
    fn default() -> Self {
        Self {
            strength: 0.5,
            rest_length: 100.0,
            is_directional: false,
            force_type: 0,
        }
    }
}

/// Thread-safe registry for semantic relationship types
pub struct SemanticTypeRegistry {
    uri_to_id: RwLock<HashMap<String, u32>>,
    id_to_config: RwLock<Vec<RelationshipForceConfig>>,
    id_to_uri: RwLock<Vec<String>>,
    next_id: AtomicU32,
}

impl SemanticTypeRegistry {
    /// Create a new registry with default relationship types
    pub fn new() -> Self {
        let registry = Self {
            uri_to_id: RwLock::new(HashMap::new()),
            id_to_config: RwLock::new(Vec::new()),
            id_to_uri: RwLock::new(Vec::new()),
            next_id: AtomicU32::new(0),
        };

        // Register default relationship types
        // Generic/unknown type
        registry.register_internal("generic", RelationshipForceConfig {
            strength: 0.3,
            rest_length: 100.0,
            is_directional: false,
            force_type: 0,
        });

        // Basic relationship types
        registry.register_internal("dependency", RelationshipForceConfig {
            strength: 0.6,
            rest_length: 80.0,
            is_directional: true,
            force_type: 0,
        });

        registry.register_internal("hierarchy", RelationshipForceConfig {
            strength: 0.8,
            rest_length: 60.0,
            is_directional: true,
            force_type: 0,
        });

        registry.register_internal("association", RelationshipForceConfig {
            strength: 0.4,
            rest_length: 120.0,
            is_directional: false,
            force_type: 0,
        });

        registry.register_internal("sequence", RelationshipForceConfig {
            strength: 0.5,
            rest_length: 90.0,
            is_directional: true,
            force_type: 0,
        });

        // OWL relationship types
        registry.register_internal("subClassOf", RelationshipForceConfig {
            strength: 0.8,
            rest_length: 60.0,
            is_directional: true,
            force_type: 0,
        });

        registry.register_internal("rdfs:subClassOf", RelationshipForceConfig {
            strength: 0.8,
            rest_length: 60.0,
            is_directional: true,
            force_type: 0,
        });

        registry.register_internal("instanceOf", RelationshipForceConfig {
            strength: 0.7,
            rest_length: 70.0,
            is_directional: true,
            force_type: 0,
        });

        registry.register_internal("rdf:type", RelationshipForceConfig {
            strength: 0.7,
            rest_length: 70.0,
            is_directional: true,
            force_type: 0,
        });

        // NGM ontology relationship types
        registry.register_internal("ngm:requires", RelationshipForceConfig {
            strength: 0.7,
            rest_length: 80.0,
            is_directional: true,
            force_type: 0,
        });

        registry.register_internal("requires", RelationshipForceConfig {
            strength: 0.7,
            rest_length: 80.0,
            is_directional: true,
            force_type: 0,
        });

        registry.register_internal("ngm:enables", RelationshipForceConfig {
            strength: 0.4,
            rest_length: 120.0,
            is_directional: false,
            force_type: 0,
        });

        registry.register_internal("enables", RelationshipForceConfig {
            strength: 0.4,
            rest_length: 120.0,
            is_directional: false,
            force_type: 0,
        });

        registry.register_internal("ngm:has-part", RelationshipForceConfig {
            strength: 0.9,
            rest_length: 40.0,
            is_directional: true,
            force_type: 1, // Orbit clustering
        });

        registry.register_internal("has-part", RelationshipForceConfig {
            strength: 0.9,
            rest_length: 40.0,
            is_directional: true,
            force_type: 1,
        });

        registry.register_internal("ngm:bridges-to", RelationshipForceConfig {
            strength: 0.3,
            rest_length: 200.0,
            is_directional: false,
            force_type: 2, // Cross-domain long-range
        });

        registry.register_internal("bridges-to", RelationshipForceConfig {
            strength: 0.3,
            rest_length: 200.0,
            is_directional: false,
            force_type: 2,
        });

        // Additional common relationship types
        registry.register_internal("owl:equivalentClass", RelationshipForceConfig {
            strength: 0.9,
            rest_length: 30.0,
            is_directional: false,
            force_type: 0,
        });

        registry.register_internal("owl:disjointWith", RelationshipForceConfig {
            strength: -0.3, // Repulsive
            rest_length: 150.0,
            is_directional: false,
            force_type: 3, // Repulsion
        });

        registry.register_internal("skos:broader", RelationshipForceConfig {
            strength: 0.6,
            rest_length: 70.0,
            is_directional: true,
            force_type: 0,
        });

        registry.register_internal("skos:narrower", RelationshipForceConfig {
            strength: 0.6,
            rest_length: 70.0,
            is_directional: true,
            force_type: 0,
        });

        registry.register_internal("skos:related", RelationshipForceConfig {
            strength: 0.4,
            rest_length: 100.0,
            is_directional: false,
            force_type: 0,
        });

        registry
    }

    /// Internal registration (bypasses lock acquisition for initialization)
    fn register_internal(&self, uri: &str, config: RelationshipForceConfig) -> u32 {
        let id = self.next_id.fetch_add(1, Ordering::SeqCst);

        let mut uri_map = self.uri_to_id.write().unwrap();
        let mut configs = self.id_to_config.write().unwrap();
        let mut uris = self.id_to_uri.write().unwrap();

        uri_map.insert(uri.to_string(), id);
        configs.push(config);
        uris.push(uri.to_string());

        id
    }

    /// Register a new relationship type with force configuration
    /// Returns the assigned ID for the type
    pub fn register(&self, uri: &str, config: RelationshipForceConfig) -> u32 {
        // Check if already registered
        {
            let uri_map = self.uri_to_id.read().unwrap();
            if let Some(&existing_id) = uri_map.get(uri) {
                // Update existing config
                let mut configs = self.id_to_config.write().unwrap();
                if (existing_id as usize) < configs.len() {
                    configs[existing_id as usize] = config;
                }
                return existing_id;
            }
        }

        self.register_internal(uri, config)
    }

    /// Get the ID for a relationship type URI
    pub fn get_id(&self, uri: &str) -> Option<u32> {
        let uri_map = self.uri_to_id.read().unwrap();
        uri_map.get(uri).copied()
    }

    /// Get the ID for a relationship type, registering with defaults if not found
    pub fn get_or_register_id(&self, uri: &str) -> u32 {
        if let Some(id) = self.get_id(uri) {
            return id;
        }

        // Register with default config
        self.register(uri, RelationshipForceConfig::default())
    }

    /// Get the force configuration for a relationship type ID
    pub fn get_config(&self, id: u32) -> Option<RelationshipForceConfig> {
        let configs = self.id_to_config.read().unwrap();
        configs.get(id as usize).copied()
    }

    /// Get the URI for a relationship type ID
    pub fn get_uri(&self, id: u32) -> Option<String> {
        let uris = self.id_to_uri.read().unwrap();
        uris.get(id as usize).cloned()
    }

    /// Update the configuration for an existing relationship type
    pub fn update_config(&self, uri: &str, config: RelationshipForceConfig) -> bool {
        let uri_map = self.uri_to_id.read().unwrap();
        if let Some(&id) = uri_map.get(uri) {
            let mut configs = self.id_to_config.write().unwrap();
            if (id as usize) < configs.len() {
                configs[id as usize] = config;
                return true;
            }
        }
        false
    }

    /// Build a GPU-compatible buffer of all force configurations
    /// Buffer is indexed by relationship type ID
    pub fn build_gpu_buffer(&self) -> Vec<RelationshipForceConfig> {
        let configs = self.id_to_config.read().unwrap();
        configs.clone()
    }

    /// Build a GPU buffer with the proper C-compatible struct layout
    /// for the dynamic relationship system in semantic_forces.cu
    pub fn build_dynamic_gpu_buffer(&self) -> Vec<DynamicForceConfigGPU> {
        let configs = self.id_to_config.read().unwrap();
        configs.iter().map(|c| DynamicForceConfigGPU::from(c)).collect()
    }

    /// Get the buffer version (incremented on each registration/update)
    /// Useful for hot-reload detection
    pub fn version(&self) -> u32 {
        self.next_id.load(Ordering::SeqCst)
    }

    /// Get the number of registered relationship types
    pub fn len(&self) -> usize {
        let configs = self.id_to_config.read().unwrap();
        configs.len()
    }

    /// Check if the registry is empty
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// Get all registered URIs
    pub fn registered_uris(&self) -> Vec<String> {
        let uris = self.id_to_uri.read().unwrap();
        uris.clone()
    }

    /// Convert edge type string to integer ID (legacy compatibility)
    /// Returns the ID if the type is registered, or 0 (generic) if not found
    pub fn edge_type_to_int(&self, edge_type: &Option<String>) -> i32 {
        edge_type
            .as_deref()
            .and_then(|uri| self.get_id(uri))
            .map(|id| id as i32)
            .unwrap_or(0)
    }
}

impl Default for SemanticTypeRegistry {
    fn default() -> Self {
        Self::new()
    }
}

/// Global singleton registry instance
lazy_static::lazy_static! {
    pub static ref SEMANTIC_TYPE_REGISTRY: SemanticTypeRegistry = SemanticTypeRegistry::new();
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_registry_creation() {
        let registry = SemanticTypeRegistry::new();
        // Should have default types registered
        assert!(registry.len() > 0);
    }

    #[test]
    fn test_default_types_registered() {
        let registry = SemanticTypeRegistry::new();

        // Check that default types are registered
        assert!(registry.get_id("generic").is_some());
        assert!(registry.get_id("ngm:requires").is_some());
        assert!(registry.get_id("ngm:enables").is_some());
        assert!(registry.get_id("ngm:has-part").is_some());
        assert!(registry.get_id("ngm:bridges-to").is_some());
        assert!(registry.get_id("rdfs:subClassOf").is_some());
    }

    #[test]
    fn test_register_new_type() {
        let registry = SemanticTypeRegistry::new();
        let initial_len = registry.len();

        let id = registry.register("custom:test-type", RelationshipForceConfig {
            strength: 0.5,
            rest_length: 100.0,
            is_directional: true,
            force_type: 0,
        });

        assert_eq!(registry.len(), initial_len + 1);
        assert_eq!(registry.get_id("custom:test-type"), Some(id));
    }

    #[test]
    fn test_get_config() {
        let registry = SemanticTypeRegistry::new();

        let id = registry.get_id("ngm:requires").unwrap();
        let config = registry.get_config(id).unwrap();

        assert_eq!(config.strength, 0.7);
        assert!(config.is_directional);
    }

    #[test]
    fn test_update_config() {
        let registry = SemanticTypeRegistry::new();

        let updated = registry.update_config("ngm:requires", RelationshipForceConfig {
            strength: 0.9,
            rest_length: 50.0,
            is_directional: true,
            force_type: 0,
        });

        assert!(updated);

        let id = registry.get_id("ngm:requires").unwrap();
        let config = registry.get_config(id).unwrap();
        assert_eq!(config.strength, 0.9);
        assert_eq!(config.rest_length, 50.0);
    }

    #[test]
    fn test_gpu_buffer() {
        let registry = SemanticTypeRegistry::new();
        let buffer = registry.build_gpu_buffer();

        assert_eq!(buffer.len(), registry.len());
    }

    #[test]
    fn test_edge_type_to_int() {
        let registry = SemanticTypeRegistry::new();

        // Registered type
        let id = registry.edge_type_to_int(&Some("ngm:requires".to_string()));
        assert!(id > 0);

        // Unregistered type returns 0 (generic)
        let unknown_id = registry.edge_type_to_int(&Some("unknown:type".to_string()));
        assert_eq!(unknown_id, 0);

        // None returns 0
        let none_id = registry.edge_type_to_int(&None);
        assert_eq!(none_id, 0);
    }

    #[test]
    fn test_get_or_register_id() {
        let registry = SemanticTypeRegistry::new();

        // Existing type
        let id1 = registry.get_or_register_id("ngm:requires");
        let id2 = registry.get_or_register_id("ngm:requires");
        assert_eq!(id1, id2);

        // New type gets registered
        let new_id = registry.get_or_register_id("new:auto-registered");
        assert!(registry.get_id("new:auto-registered").is_some());
        assert_eq!(registry.get_id("new:auto-registered"), Some(new_id));
    }
}

================================================================================
                    SECTION 5: GITHUB & PARSING SERVICES
================================================================================

--------------------------------------------------------------------------------
FILE: src/services/github/mod.rs
PURPOSE: GitHub service module with API client exports
--------------------------------------------------------------------------------
//! GitHub service module providing API interactions for content and pull requests
//!
//! This module is split into:
//! - Content API: Handles fetching and checking markdown files
//! - Pull Request API: Manages creation and updates of pull requests
//! - Common types and error handling
//! - Configuration: Environment-based configuration

pub mod api;
pub mod config;
pub mod content_enhanced;
pub mod pr;
pub mod types;

pub use api::GitHubClient;
pub use config::GitHubConfig;
pub use content_enhanced::EnhancedContentAPI as ContentAPI;
pub use pr::PullRequestAPI;
pub use types::{GitHubError, GitHubFile, GitHubFileMetadata};

// Re-export commonly used types for convenience
pub use types::{ContentResponse, PullRequestResponse};

--------------------------------------------------------------------------------
FILE: src/services/github/api.rs
PURPOSE: GitHub HTTP client implementation
--------------------------------------------------------------------------------
use super::config::GitHubConfig;
use crate::config::AppFullSettings; 
use crate::errors::VisionFlowResult;
use log::{debug, info};
use reqwest::Client;
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::RwLock;

// const GITHUB_API_DELAY: Duration = Duration::from_millis(500); 
// const MAX_RETRIES: u32 = 3; 
// const RETRY_DELAY: Duration = Duration::from_secs(2); 

///
pub struct GitHubClient {
    client: Client,
    token: String,
    owner: String,
    repo: String,
    base_path: String,
    branch: String,
    settings: Arc<RwLock<AppFullSettings>>,
}

impl GitHubClient {
    
    pub async fn new(
        config: GitHubConfig,
        settings: Arc<RwLock<AppFullSettings>>, 
    ) -> VisionFlowResult<Self> {
        let debug_enabled = crate::utils::logging::is_debug_enabled();

        if debug_enabled {
            debug!(
                "Initializing GitHub client - Owner: '{}', Repo: '{}', Base path: '{}'",
                config.owner, config.repo, config.base_path
            );
        }

        
        if debug_enabled {
            debug!("Configuring HTTP client - Timeout: 30s, User-Agent: github-api-client");
        }

        let client = Client::builder()
            .user_agent("github-api-client")
            .timeout(Duration::from_secs(30))
            .build()?;

        if debug_enabled {
            debug!("HTTP client configured successfully");
        }

        
        let decoded_path = urlencoding::decode(&config.base_path)
            .unwrap_or(std::borrow::Cow::Owned(config.base_path.clone()))
            .into_owned();

        if debug_enabled {
            debug!("Decoded base path: '{}'", decoded_path);
        }


        let base_path = decoded_path
            .trim_matches('/')
            .replace("//", "/")
            .replace('\\', "/");

        if debug_enabled {
            debug!(
                "Cleaned base path: '{}' (original: '{}')",
                base_path, base_path
            );
            debug!("GitHub client initialization complete");
        }

        Ok(Self {
            client,
            token: config.token,
            owner: config.owner,
            repo: config.repo,
            base_path,
            branch: config.branch,
            settings: Arc::clone(&settings),
        })
    }

    

    
    pub async fn get_full_path(&self, path: &str) -> String {
        let settings = self.settings.read().await;
        let debug_enabled = crate::utils::logging::is_debug_enabled();
        drop(settings);

        if debug_enabled {
            debug!(
                "Getting full path - Base: '{}', Input path: '{}'",
                self.base_path, path
            );
        }

        let base = self.base_path.trim_matches('/');
        let path = path.trim_matches('/');

        if debug_enabled {
            log::debug!("Trimmed paths - Base: '{}', Path: '{}'", base, path);
        }

        
        let decoded_path = urlencoding::decode(path)
            .unwrap_or(std::borrow::Cow::Owned(path.to_string()))
            .into_owned();
        let decoded_base = urlencoding::decode(base)
            .unwrap_or(std::borrow::Cow::Owned(base.to_string()))
            .into_owned();

        if debug_enabled {
            log::debug!(
                "Decoded paths - Base: '{}', Path: '{}'",
                decoded_base,
                decoded_path
            );
        }

        let full_path = if decoded_base.is_empty() {
            if debug_enabled {
                log::debug!(
                    "Base path is empty, using decoded path only: '{}'",
                    decoded_path
                );
            }
            decoded_path
        } else {
            if decoded_path.is_empty() {
                if debug_enabled {
                    log::debug!("Path is empty, using base path only: '{}'", decoded_base);
                }
                decoded_base
            } else if decoded_path.starts_with(&decoded_base) {
                
                if debug_enabled {
                    log::debug!(
                        "Path already contains base path, using as-is: '{}'",
                        decoded_path
                    );
                }
                decoded_path
            } else {
                let combined = format!("{}/{}", decoded_base, decoded_path);
                if debug_enabled {
                    log::debug!("Combined path: '{}'", combined);
                }
                combined
            }
        };

        // FIX: Do not URL-encode the entire path as it converts '/' to '%2F'
        // GitHub API expects literal slashes in the path segment
        // Only encode individual path components if they contain special characters
        if debug_enabled {
            log::debug!("Final full path (no encoding): '{}'", full_path);
        }

        full_path
    }


    pub async fn get_contents_url(&self, path: &str) -> String {
        let settings = self.settings.read().await;
        let _debug_enabled = crate::utils::logging::is_debug_enabled();
        drop(settings);

        info!("get_contents_url: Building GitHub API URL - Owner: '{}', Repo: '{}', Base path: '{}', Input path: '{}', Branch: '{}'",
            self.owner, self.repo, self.base_path, path, self.branch);

        let full_path = self.get_full_path(path).await;

        info!(
            "get_contents_url: Full path after encoding: '{}'",
            full_path
        );

        let url = format!(
            "https://api.github.com/repos/{}/{}/contents/{}?ref={}",
            self.owner, self.repo, full_path, self.branch
        );

        info!("get_contents_url: Final GitHub API URL: '{}'", url);

        url
    }

    
    pub fn client(&self) -> &Client {
        &self.client
    }

    
    pub(crate) fn token(&self) -> &str {
        &self.token
    }

    
    pub(crate) fn owner(&self) -> &str {
        &self.owner
    }

    
    pub(crate) fn repo(&self) -> &str {
        &self.repo
    }


    pub(crate) fn base_path(&self) -> &str {
        &self.base_path
    }

    pub(crate) fn branch(&self) -> &str {
        &self.branch
    }

    #[allow(dead_code)]
    pub(crate) fn settings(&self) -> &Arc<RwLock<AppFullSettings>> {

        &self.settings
    }

}

--------------------------------------------------------------------------------
FILE: src/services/github/types.rs
PURPOSE: GitHub API response types and error definitions
--------------------------------------------------------------------------------
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::error::Error;
use std::fmt;

///
#[derive(Debug, Clone)]
pub struct RateLimitInfo {
    pub remaining: u32,
    pub limit: u32,
    pub reset_time: DateTime<Utc>,
}

///
#[derive(Debug)]
pub enum GitHubError {
    
    ApiError(String),
    
    NetworkError(reqwest::Error),
    
    SerializationError(serde_json::Error),
    
    ValidationError(String),
    
    Base64Error(base64::DecodeError),
    
    RateLimitExceeded(RateLimitInfo),
    
    NotFound(String),
}

impl fmt::Display for GitHubError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            GitHubError::ApiError(msg) => write!(f, "GitHub API error: {}", msg),
            GitHubError::NetworkError(e) => write!(f, "Network error: {}", e),
            GitHubError::SerializationError(e) => write!(f, "Serialization error: {}", e),
            GitHubError::ValidationError(msg) => write!(f, "Validation error: {}", msg),
            GitHubError::Base64Error(e) => write!(f, "Base64 encoding error: {}", e),
            GitHubError::RateLimitExceeded(info) => {
                write!(
                    f,
                    "Rate limit exceeded. Remaining: {}/{}, Reset time: {}",
                    info.remaining, info.limit, info.reset_time
                )
            }
            GitHubError::NotFound(path) => {
                write!(f, "Resource not found: {}", path)
            }
        }
    }
}

impl Error for GitHubError {}

impl From<reqwest::Error> for GitHubError {
    fn from(err: reqwest::Error) -> Self {
        GitHubError::NetworkError(err)
    }
}

impl From<serde_json::Error> for GitHubError {
    fn from(err: serde_json::Error) -> Self {
        GitHubError::SerializationError(err)
    }
}

impl From<base64::DecodeError> for GitHubError {
    fn from(err: base64::DecodeError) -> Self {
        GitHubError::Base64Error(err)
    }
}

///
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct GitHubFile {
    
    pub name: String,
    
    pub path: String,
    
    pub sha: String,
    
    pub size: usize,
    
    pub url: String,
    
    pub download_url: String,
}

///
#[derive(Debug, Serialize, Deserialize, Clone, Eq, PartialEq, Hash)]
pub struct GitHubFileMetadata {
    
    pub name: String,
    
    pub sha: String,
    
    pub download_url: String,
    
    pub etag: Option<String>,
    
    #[serde(with = "chrono::serde::ts_seconds_option")]
    pub last_checked: Option<DateTime<Utc>>,
    
    #[serde(with = "chrono::serde::ts_seconds_option")]
    pub last_modified: Option<DateTime<Utc>>,
    
    #[serde(with = "chrono::serde::ts_seconds_option")]
    pub last_content_change: Option<DateTime<Utc>>,
    
    pub file_blob_sha: Option<String>,
}

///
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct GitHubFileBasicMetadata {
    pub name: String,
    pub path: String,
    pub sha: String,
    pub size: u64,
    pub download_url: String,
}

///
#[derive(Debug, Deserialize)]
pub struct ContentResponse {
    pub sha: String,
}

///
#[derive(Debug, Deserialize)]
pub struct PullRequestResponse {
    pub html_url: String,
    pub number: u32,
    pub state: String,
}

///
#[derive(Debug, Serialize)]
pub struct CreateBranchRequest {
    pub ref_name: String,
    pub sha: String,
}

///
#[derive(Debug, Serialize)]
pub struct CreatePullRequest {
    pub title: String,
    pub head: String,
    pub base: String,
    pub body: String,
}

///
#[derive(Debug, Serialize)]
pub struct UpdateFileRequest {
    pub message: String,
    pub content: String,
    pub sha: String,
    pub branch: String,
}

/// Ontology-specific file metadata
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OntologyFileMetadata {
    /// Basic file metadata
    pub name: String,
    pub path: String,
    pub sha: String,
    pub size: u64,
    pub download_url: String,

    /// Git commit information
    pub git_commit_date: Option<DateTime<Utc>>,

    /// Ontology-specific flags
    pub has_public_flag: bool,
    pub has_ontology_block: bool,
    pub priority: OntologyPriority,

    /// Extracted metadata
    pub source_domain: Option<String>,
    pub topics: Vec<String>,
    pub relationship_count: usize,
    pub class_count: usize,
    pub property_count: usize,
}

/// Priority levels for ontology file processing
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
pub enum OntologyPriority {
    /// Files with both public:: true AND OntologyBlock
    Priority1 = 1,
    /// Files with OntologyBlock only
    Priority2 = 2,
    /// Files with public:: true only (knowledge graph)
    Priority3 = 3,
    /// No special flags
    None = 99,
}

impl OntologyFileMetadata {
    pub fn new(basic: GitHubFileBasicMetadata) -> Self {
        Self {
            name: basic.name,
            path: basic.path,
            sha: basic.sha,
            size: basic.size,
            download_url: basic.download_url,
            git_commit_date: None,
            has_public_flag: false,
            has_ontology_block: false,
            priority: OntologyPriority::None,
            source_domain: None,
            topics: Vec::new(),
            relationship_count: 0,
            class_count: 0,
            property_count: 0,
        }
    }

    pub fn calculate_priority(&mut self) {
        self.priority = match (self.has_public_flag, self.has_ontology_block) {
            (true, true) => OntologyPriority::Priority1,
            (false, true) => OntologyPriority::Priority2,
            (true, false) => OntologyPriority::Priority3,
            (false, false) => OntologyPriority::None,
        };
    }
}

--------------------------------------------------------------------------------
FILE: src/services/github/config.rs
PURPOSE: GitHub configuration from environment variables
--------------------------------------------------------------------------------
use std::env;
use std::error::Error;
use std::fmt;

#[derive(Debug)]
pub enum GitHubConfigError {
    MissingEnvVar(String),
    ValidationError(String),
}

impl fmt::Display for GitHubConfigError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Self::MissingEnvVar(var) => write!(f, "Missing environment variable: {}", var),
            Self::ValidationError(msg) => write!(f, "Configuration validation error: {}", msg),
        }
    }
}

impl Error for GitHubConfigError {}

#[derive(Debug, Clone)]
pub struct GitHubConfig {
    pub token: String,
    pub owner: String,
    pub repo: String,
    pub base_path: String,
    pub branch: String,
    pub rate_limit: bool,
    pub version: String,
}

impl GitHubConfig {
    pub fn from_env() -> Result<Self, GitHubConfigError> {
        let token = env::var("GITHUB_TOKEN")
            .map_err(|_| GitHubConfigError::MissingEnvVar("GITHUB_TOKEN".to_string()))?;

        let owner = env::var("GITHUB_OWNER")
            .map_err(|_| GitHubConfigError::MissingEnvVar("GITHUB_OWNER".to_string()))?;

        let repo = env::var("GITHUB_REPO")
            .map_err(|_| GitHubConfigError::MissingEnvVar("GITHUB_REPO".to_string()))?;

        let base_path = env::var("GITHUB_BASE_PATH")
            .map_err(|_| GitHubConfigError::MissingEnvVar("GITHUB_BASE_PATH".to_string()))?;

        let branch = env::var("GITHUB_BRANCH").unwrap_or_else(|_| "main".to_string());

        let rate_limit = env::var("GITHUB_RATE_LIMIT")
            .map(|v| v.parse::<bool>().unwrap_or(true))
            .unwrap_or(true);

        let version = env::var("GITHUB_API_VERSION").unwrap_or_else(|_| "v3".to_string());

        let config = Self {
            token,
            owner,
            repo,
            base_path,
            branch,
            rate_limit,
            version,
        };

        config.validate()?;

        Ok(config)
    }

    fn validate(&self) -> Result<(), GitHubConfigError> {
        if self.token.is_empty() {
            return Err(GitHubConfigError::ValidationError(
                "GitHub token cannot be empty".to_string(),
            ));
        }

        if self.owner.is_empty() {
            return Err(GitHubConfigError::ValidationError(
                "GitHub owner cannot be empty".to_string(),
            ));
        }

        if self.repo.is_empty() {
            return Err(GitHubConfigError::ValidationError(
                "GitHub repository cannot be empty".to_string(),
            ));
        }

        if self.base_path.is_empty() {
            return Err(GitHubConfigError::ValidationError(
                "GitHub base path cannot be empty".to_string(),
            ));
        }

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::env;

    #[test]
    fn test_missing_required_vars() {
        env::remove_var("GITHUB_TOKEN");
        env::remove_var("GITHUB_OWNER");
        env::remove_var("GITHUB_REPO");
        env::remove_var("GITHUB_BASE_PATH");

        match GitHubConfig::from_env() {
            Err(GitHubConfigError::MissingEnvVar(var)) => {
                assert_eq!(var, "GITHUB_TOKEN");
            }
            other => {
                panic!("Expected MissingEnvVar error, got: {:?}", other);
            }
        }
    }

    #[test]
    fn test_empty_values() {
        env::set_var("GITHUB_TOKEN", "");
        env::set_var("GITHUB_OWNER", "owner");
        env::set_var("GITHUB_REPO", "repo");
        env::set_var("GITHUB_BASE_PATH", "path");

        match GitHubConfig::from_env() {
            Err(GitHubConfigError::ValidationError(msg)) => {
                assert!(msg.contains("token cannot be empty"));
            }
            other => {
                panic!("Expected ValidationError, got: {:?}", other);
            }
        }
    }

    #[test]
    fn test_valid_config() {
        env::set_var("GITHUB_TOKEN", "token");
        env::set_var("GITHUB_OWNER", "owner");
        env::set_var("GITHUB_REPO", "repo");
        env::set_var("GITHUB_BASE_PATH", "path");

        let config = GitHubConfig::from_env().unwrap();
        assert_eq!(config.token, "token");
        assert_eq!(config.owner, "owner");
        assert_eq!(config.repo, "repo");
        assert_eq!(config.base_path, "path");
        assert_eq!(config.branch, "main");
        assert!(config.rate_limit);
        assert_eq!(config.version, "v3");
    }

    #[test]
    fn test_optional_settings() {
        env::set_var("GITHUB_TOKEN", "token");
        env::set_var("GITHUB_OWNER", "owner");
        env::set_var("GITHUB_REPO", "repo");
        env::set_var("GITHUB_BASE_PATH", "path");
        env::set_var("GITHUB_RATE_LIMIT", "false");
        env::set_var("GITHUB_API_VERSION", "v4");
        env::set_var("GITHUB_BRANCH", "multi-ontology");

        let config = GitHubConfig::from_env().unwrap();
        assert!(!config.rate_limit);
        assert_eq!(config.version, "v4");
        assert_eq!(config.branch, "multi-ontology");
    }
}

--------------------------------------------------------------------------------
FILE: src/services/github/content_enhanced.rs
PURPOSE: Enhanced content API with recursive listing and pagination
--------------------------------------------------------------------------------
use super::api::GitHubClient;
use super::types::GitHubFileBasicMetadata;
use crate::errors::VisionFlowResult;
use chrono::{DateTime, Utc};
use log::{debug, error, info, warn};
use serde_json::Value;
use std::sync::Arc;
use crate::utils::time;

///
#[derive(Clone)] 
pub struct EnhancedContentAPI {
    client: Arc<GitHubClient>,
}

impl EnhancedContentAPI {
    pub fn new(client: Arc<GitHubClient>) -> Self {
        Self { client }
    }


    pub fn list_markdown_files<'a>(
        &'a self,
        path: &'a str,
    ) -> std::pin::Pin<Box<dyn std::future::Future<Output = VisionFlowResult<Vec<GitHubFileBasicMetadata>>> + Send + 'a>> {
        Box::pin(async move {
            self.list_markdown_files_impl(path).await
        })
    }

    async fn list_markdown_files_impl(
        &self,
        path: &str,
    ) -> VisionFlowResult<Vec<GitHubFileBasicMetadata>> {
        let mut all_markdown_files = Vec::new();
        let mut page = 1;
        const PER_PAGE: usize = 100;

        info!("list_markdown_files: Starting paginated fetch from GitHub API");

        loop {
            let contents_url = format!(
                "{}?per_page={}&page={}",
                GitHubClient::get_contents_url(&self.client, path).await,
                PER_PAGE,
                page
            );

            debug!("list_markdown_files: Fetching page {} from: {}", page, contents_url);

            let response = self
                .client
                .client()
                .get(&contents_url)
                .header("Authorization", format!("Bearer {}", self.client.token()))
                .header("Accept", "application/vnd.github+json")
                .send()
                .await?;

            let status = response.status();
            debug!("list_markdown_files: Page {} response status: {}", page, status);

            if !status.is_success() {
                let error_text = response.text().await?;
                error!(
                    "list_markdown_files: GitHub API error on page {} ({}): {}",
                    page, status, error_text
                );
                return Err(format!(
                    "GitHub API error listing files page {} ({}): {}",
                    page, status, error_text
                )
                .into());
            }

            let files: Vec<Value> = response.json().await?;
            let files_count = files.len();
            info!(
                "list_markdown_files: Page {} received {} items from GitHub",
                page, files_count
            );

            // Break if no more files
            if files_count == 0 {
                info!("list_markdown_files: No more files, stopping pagination at page {}", page);
                break;
            }

            // Process files on this page
            for file in files {
                let file_type = file["type"].as_str().unwrap_or("unknown");
                let file_name = file["name"].as_str().unwrap_or("unnamed");

                if file_type == "file" && file_name.ends_with(".md") {
                    debug!("list_markdown_files: Found markdown file: {}", file_name);
                    all_markdown_files.push(GitHubFileBasicMetadata {
                        name: file_name.to_string(),
                        path: file["path"].as_str().unwrap_or("").to_string(),
                        sha: file["sha"].as_str().unwrap_or("").to_string(),
                        size: file["size"].as_u64().unwrap_or(0),
                        download_url: file["download_url"].as_str().unwrap_or("").to_string(),
                    });
                } else if file_type == "dir" {
                    let dir_path = file["path"].as_str().unwrap_or("");
                    debug!("list_markdown_files_impl: Recursively processing directory: {}", dir_path);

                    // Recursively fetch markdown files from subdirectory
                    match self.list_markdown_files(dir_path).await {
                        Ok(mut subdir_files) => {
                            let count = subdir_files.len();
                            debug!("list_markdown_files_impl: Found {} files in subdirectory {}", count, dir_path);
                            all_markdown_files.append(&mut subdir_files);
                        }
                        Err(e) => {
                            warn!("list_markdown_files_impl: Failed to process subdirectory {}: {}", dir_path, e);
                        }
                    }
                }
            }

            // GitHub API returns < PER_PAGE items on last page
            if files_count < PER_PAGE {
                info!("list_markdown_files: Last page detected (received {} < {} items)", files_count, PER_PAGE);
                break;
            }

            page += 1;

            // Safety limit to prevent infinite loops
            if page > 100 {
                warn!("list_markdown_files: Reached safety limit of 100 pages (10,000 files)");
                break;
            }
        }

        info!(
            "list_markdown_files: Pagination complete. Found {} markdown files total across {} pages",
            all_markdown_files.len(),
            page
        );
        Ok(all_markdown_files)
    }

    
    pub async fn fetch_file_content(&self, download_url: &str) -> VisionFlowResult<String> {
        debug!("Fetching file content from: {}", download_url);
        let response = self
            .client
            .client()
            .get(download_url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            return Err(format!("Failed to fetch file content: {}", error_text).into());
        }

        Ok(response.text().await?)
    }

    
    pub async fn get_file_content_last_modified(
        &self,
        file_path: &str,
        check_actual_changes: bool,
    ) -> VisionFlowResult<DateTime<Utc>> {
        let encoded_path = GitHubClient::get_full_path(&self.client, file_path).await;

        
        let commits_url = format!(
            "https://api.github.com/repos/{}/{}/commits",
            self.client.owner(),
            self.client.repo()
        );

        debug!("Fetching commits for path: {}", encoded_path);

        let response = self
            .client
            .client()
            .get(&commits_url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .query(&[
                ("path", encoded_path.as_str()),
                ("ref", self.client.branch()),
                ("per_page", if check_actual_changes { "10" } else { "1" }),
            ])
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            return Err(format!("GitHub API error: {}", error_text).into());
        }

        let commits: Vec<Value> = response.json().await?;

        if commits.is_empty() {
            return Err(format!("No commit history found for {}", file_path).into());
        }

        
        if !check_actual_changes {
            return self.extract_commit_date(&commits[0]);
        }

        
        for commit in &commits {
            let sha = commit["sha"].as_str().ok_or("Missing commit SHA")?;

            if self.was_file_modified_in_commit(sha, &encoded_path).await? {
                debug!("File was actually modified in commit: {}", sha);
                return self.extract_commit_date(commit);
            } else {
                debug!(
                    "File was not modified in commit: {} (likely a merge commit)",
                    sha
                );
            }
        }

        
        warn!("No actual content changes found in recent commits, using oldest available");
        self.extract_commit_date(&commits[commits.len() - 1])
    }

    
    async fn was_file_modified_in_commit(
        &self,
        commit_sha: &str,
        file_path: &str,
    ) -> VisionFlowResult<bool> {
        let commit_url = format!(
            "https://api.github.com/repos/{}/{}/commits/{}",
            self.client.owner(),
            self.client.repo(),
            commit_sha
        );

        debug!("Checking commit {} for file changes", commit_sha);

        let response = self
            .client
            .client()
            .get(&commit_url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            warn!("Failed to get commit details: {}", error_text);
            
            return Ok(true);
        }

        let commit_data: Value = response.json().await?;

        
        if let Some(files) = commit_data["files"].as_array() {
            for file in files {
                if let Some(filename) = file["filename"].as_str() {
                    
                    if filename == file_path
                        || filename.ends_with(&format!("/{}", file_path))
                        || filename == file_path.replace("%2F", "/")
                        || filename.ends_with(&format!("/{}", file_path.replace("%2F", "/")))
                    {
                        
                        let additions = file["additions"].as_u64().unwrap_or(0);
                        let deletions = file["deletions"].as_u64().unwrap_or(0);
                        let changes = file["changes"].as_u64().unwrap_or(0);

                        debug!(
                            "File {} in commit {}: +{} -{} (total: {} changes)",
                            filename, commit_sha, additions, deletions, changes
                        );

                        
                        return Ok(changes > 0);
                    }
                }
            }
        }

        
        Ok(false)
    }

    
    fn extract_commit_date(&self, commit: &Value) -> VisionFlowResult<DateTime<Utc>> {
        
        let date_str = commit["commit"]["committer"]["date"]
            .as_str()
            .or_else(|| commit["commit"]["author"]["date"].as_str())
            .ok_or("No commit date found")?;

        DateTime::parse_from_rfc3339(date_str)
            .map(|dt| dt.with_timezone(&Utc))
            .map_err(|e| format!("Failed to parse date {}: {}", date_str, e).into())
    }

    
    pub async fn get_file_metadata_extended(
        &self,
        file_path: &str,
    ) -> VisionFlowResult<ExtendedFileMetadata> {
        let encoded_path = GitHubClient::get_full_path(&self.client, file_path).await;

        
        let contents_url = format!(
            "https://api.github.com/repos/{}/{}/contents/{}?ref={}",
            self.client.owner(),
            self.client.repo(),
            encoded_path,
            self.client.branch()
        );

        let response = self
            .client
            .client()
            .get(&contents_url)
            .header("Authorization", format!("Bearer {}", self.client.token()))
            .header("Accept", "application/vnd.github+json")
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            return Err(format!("Failed to get file metadata: {}", error_text).into());
        }

        let content_data: Value = response.json().await?;

        
        let last_content_modified = match self.get_file_content_last_modified(file_path, true).await
        {
            Ok(date) => date,
            Err(e) => {
                
                debug!(
                    "Could not get commit history for {}: {}. Using current time.",
                    file_path, e
                );
                time::now()
            }
        };

        Ok(ExtendedFileMetadata {
            name: content_data["name"].as_str().unwrap_or("").to_string(),
            path: content_data["path"].as_str().unwrap_or("").to_string(),
            sha: content_data["sha"].as_str().unwrap_or("").to_string(),
            size: content_data["size"].as_u64().unwrap_or(0),
            download_url: content_data["download_url"]
                .as_str()
                .unwrap_or("")
                .to_string(),
            last_content_modified,
            file_type: content_data["type"].as_str().unwrap_or("file").to_string(),
        })
    }
}

#[derive(Debug, Clone)]
pub struct ExtendedFileMetadata {
    pub name: String,
    pub path: String,
    pub sha: String,
    pub size: u64,
    pub download_url: String,
    pub last_content_modified: DateTime<Utc>,
    pub file_type: String,
}

--------------------------------------------------------------------------------
FILE: src/services/parsers/mod.rs
PURPOSE: Parser module aggregator
--------------------------------------------------------------------------------
pub mod knowledge_graph_parser;
pub mod ontology_parser;

pub use knowledge_graph_parser::KnowledgeGraphParser;
pub use ontology_parser::OntologyParser;

///
///
///
///
///
#[derive(Debug, Clone)]
pub struct OntologyData {
    
    pub classes: Vec<crate::ports::ontology_repository::OwlClass>,

    
    pub properties: Vec<crate::ports::ontology_repository::OwlProperty>,

    
    pub axioms: Vec<crate::ports::ontology_repository::OwlAxiom>,
}

impl OntologyData {
    
    pub fn new() -> Self {
        Self {
            classes: Vec::new(),
            properties: Vec::new(),
            axioms: Vec::new(),
        }
    }

    
    pub fn with_capacity(classes: usize, properties: usize, axioms: usize) -> Self {
        Self {
            classes: Vec::with_capacity(classes),
            properties: Vec::with_capacity(properties),
            axioms: Vec::with_capacity(axioms),
        }
    }

    
    pub fn is_empty(&self) -> bool {
        self.classes.is_empty() && self.properties.is_empty() && self.axioms.is_empty()
    }

    
    pub fn total_elements(&self) -> usize {
        self.classes.len() + self.properties.len() + self.axioms.len()
    }
}

impl Default for OntologyData {
    fn default() -> Self {
        Self::new()
    }
}

--------------------------------------------------------------------------------
FILE: src/services/parsers/knowledge_graph_parser.rs
PURPOSE: Parses markdown files to extract nodes and edges
--------------------------------------------------------------------------------
// src/services/parsers/knowledge_graph_parser.rs
//! Knowledge Graph Parser
//!
//! Parses markdown files marked with `public:: true` to extract:
//! - Nodes (pages, concepts)
//! - Edges (links, relationships)
//! - Metadata (properties, tags)

use crate::models::edge::Edge;
use crate::models::graph::GraphData;
use crate::models::metadata::MetadataStore;
use crate::models::node::Node;
use crate::utils::socket_flow_messages::BinaryNodeData;
use log::{debug, info};
use std::collections::HashMap;

/// Knowledge graph parser with position preservation support
pub struct KnowledgeGraphParser {
    /// Existing positions from database (node_id -> (x, y, z))
    existing_positions: Option<HashMap<u32, (f32, f32, f32)>>,
}

impl KnowledgeGraphParser {
    pub fn new() -> Self {
        Self {
            existing_positions: None,
        }
    }

    /// Create parser with existing positions from database
    /// These positions will be used instead of generating random ones
    pub fn with_positions(existing_positions: HashMap<u32, (f32, f32, f32)>) -> Self {
        Self {
            existing_positions: Some(existing_positions),
        }
    }

    /// Set existing positions for position preservation
    pub fn set_positions(&mut self, positions: HashMap<u32, (f32, f32, f32)>) {
        self.existing_positions = Some(positions);
    }

    /// Get position for a node ID, using existing position or generating random
    fn get_position(&self, node_id: u32) -> (f32, f32, f32) {
        if let Some(ref positions) = self.existing_positions {
            if let Some(&(x, y, z)) = positions.get(&node_id) {
                return (x, y, z);
            }
        }
        // Generate random position only if no existing position found
        use rand::Rng;
        let mut rng = rand::thread_rng();
        (
            rng.gen_range(-100.0..100.0),
            rng.gen_range(-100.0..100.0),
            rng.gen_range(-100.0..100.0),
        )
    }

    
    pub fn parse(&self, content: &str, filename: &str) -> Result<GraphData, String> {
        info!("Parsing knowledge graph file: {}", filename);

        
        let page_name = filename.strip_suffix(".md").unwrap_or(filename).to_string();

        
        let mut nodes = vec![self.create_page_node(&page_name, content)];
        let mut id_to_metadata = HashMap::new();
        id_to_metadata.insert(nodes[0].id.to_string(), page_name.clone());

        
        
        
        let (linked_nodes, file_edges) = self.extract_links(content, &nodes[0].id);
        for node in &linked_nodes {
            id_to_metadata.insert(node.id.to_string(), node.metadata_id.clone());
        }
        nodes.extend(linked_nodes);

        
        let metadata = self.extract_metadata_store(content);

        debug!(
            "Parsed {}: {} nodes, {} edges (linked nodes will be filtered)",
            filename,
            nodes.len(),
            file_edges.len()
        );

        Ok(GraphData {
            nodes,
            edges: file_edges,
            metadata,
            id_to_metadata,
        })
    }

    /// Create a page node, preserving existing position if available
    fn create_page_node(&self, page_name: &str, content: &str) -> Node {
        let mut metadata = HashMap::new();
        metadata.insert("type".to_string(), "page".to_string());
        metadata.insert("source_file".to_string(), format!("{}.md", page_name));
        metadata.insert("public".to_string(), "true".to_string());

        let tags = self.extract_tags(content);
        if !tags.is_empty() {
            metadata.insert("tags".to_string(), tags.join(", "));
        }

        let id = self.page_name_to_id(page_name);

        // Use existing position or generate random (position preservation)
        let (x, y, z) = self.get_position(id);
        let data = BinaryNodeData {
            node_id: id,
            x,
            y,
            z,
            vx: 0.0,
            vy: 0.0,
            vz: 0.0,
        };

        Node {
            id,
            metadata_id: page_name.to_string(),
            label: page_name.to_string(),
            data,
            metadata,
            file_size: 0,
            node_type: Some("page".to_string()),
            color: Some("#4A90E2".to_string()),
            size: Some(1.0),
            weight: Some(1.0),
            group: None,
            user_data: None,
            mass: Some(1.0),
            x: Some(data.x),
            y: Some(data.y),
            z: Some(data.z),
            vx: Some(0.0),
            vy: Some(0.0),
            vz: Some(0.0),
            owl_class_iri: None,
        }
    }

    /// Extract links from content, preserving existing positions
    fn extract_links(&self, content: &str, source_id: &u32) -> (Vec<Node>, Vec<Edge>) {
        let mut nodes = Vec::new();
        let mut edges = Vec::new();

        let link_pattern = regex::Regex::new(r"\[\[([^\]|]+)(?:\|[^\]]+)?\]\]").expect("Invalid regex pattern");

        for cap in link_pattern.captures_iter(content) {
            if let Some(link_match) = cap.get(1) {
                let target_page = link_match.as_str().trim().to_string();
                let target_id = self.page_name_to_id(&target_page);

                let mut metadata = HashMap::new();
                metadata.insert("type".to_string(), "linked_page".to_string());

                // Use existing position or generate random (position preservation)
                let (x, y, z) = self.get_position(target_id);
                let data = BinaryNodeData {
                    node_id: target_id,
                    x,
                    y,
                    z,
                    vx: 0.0,
                    vy: 0.0,
                    vz: 0.0,
                };

                nodes.push(Node {
                    id: target_id,
                    metadata_id: target_page.clone(),
                    label: target_page.clone(),
                    data,
                    metadata,
                    file_size: 0,
                    node_type: Some("linked_page".to_string()),
                    color: Some("#7C3AED".to_string()),
                    size: Some(0.8),
                    weight: Some(0.8),
                    group: None,
                    user_data: None,
                    mass: Some(1.0),
                    x: Some(data.x),
                    y: Some(data.y),
                    z: Some(data.z),
                    vx: Some(0.0),
                    vy: Some(0.0),
                    vz: Some(0.0),
                    owl_class_iri: None,
                });

                edges.push(Edge {
                    id: format!("{}_{}", source_id, target_id),
                    source: *source_id,
                    target: target_id,
                    weight: 1.0,
                    edge_type: Some("link".to_string()),
                    metadata: Some(HashMap::new()),
                    owl_property_iri: None,
                });
            }
        }

        (nodes, edges)
    }

    
    fn extract_metadata_store(&self, content: &str) -> MetadataStore {
        let store = MetadataStore::new();

        
        let prop_pattern = regex::Regex::new(r"([a-zA-Z_]+)::\s*(.+)").expect("Invalid regex pattern");

        
        let mut properties = HashMap::new();
        for cap in prop_pattern.captures_iter(content) {
            if let (Some(key), Some(value)) = (cap.get(1), cap.get(2)) {
                let key_str = key.as_str().to_string();
                let value_str = value.as_str().trim().to_string();

                
                properties.insert(key_str, value_str);
            }
        }

        
        
        store
    }

    
    fn extract_tags(&self, content: &str) -> Vec<String> {
        let mut tags = Vec::new();

        
        let tag_pattern =
            regex::Regex::new(r"#([a-zA-Z0-9_-]+)|tag::\s*#?([a-zA-Z0-9_-]+)").expect("Invalid regex pattern");

        for cap in tag_pattern.captures_iter(content) {
            if let Some(tag) = cap.get(1).or_else(|| cap.get(2)) {
                tags.push(tag.as_str().to_string());
            }
        }

        tags.dedup();
        tags
    }

    
    fn page_name_to_id(&self, page_name: &str) -> u32 {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        page_name.hash(&mut hasher);
        let hash_val = hasher.finish();
        
        ((hash_val % 999999) as u32) + 1
    }
}

impl Default for KnowledgeGraphParser {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_position_preservation() {
        let mut positions = HashMap::new();
        positions.insert(12345u32, (10.0f32, 20.0f32, 30.0f32));

        let parser = KnowledgeGraphParser::with_positions(positions);
        let pos = parser.get_position(12345);

        assert_eq!(pos, (10.0, 20.0, 30.0));
    }

    #[test]
    fn test_fallback_to_random() {
        let parser = KnowledgeGraphParser::new();
        let pos = parser.get_position(99999);

        // Should be within random range
        assert!(pos.0 >= -100.0 && pos.0 <= 100.0);
        assert!(pos.1 >= -100.0 && pos.1 <= 100.0);
        assert!(pos.2 >= -100.0 && pos.2 <= 100.0);
    }
}

--------------------------------------------------------------------------------
FILE: src/services/parsers/ontology_parser.rs
PURPOSE: Parses OntologyBlock sections from markdown for OWL classes
--------------------------------------------------------------------------------
// src/services/parsers/ontology_parser.rs
//! Enhanced Ontology Parser
//!
//! Parses markdown files containing `- ### OntologyBlock` headers to extract:
//! - Complete Tier 1 (Required) properties
//! - Complete Tier 2 (Recommended) properties
//! - Complete Tier 3 (Optional) properties
//! - All relationship types (is-subclass-of, has-part, requires, enables, bridges-to, etc.)
//! - OWL axioms in Clojure format
//! - Domain-specific extension properties
//!
//! Based on canonical-ontology-block.md specification v1.0.0

use crate::ports::ontology_repository::{AxiomType, OwlAxiom, OwlClass, OwlProperty, PropertyType};
use log::{debug, info, warn};
use once_cell::sync::Lazy;
use regex::Regex;
use std::collections::HashMap;

// ============================================================================
// Regex Patterns - Compiled once at startup for performance
// ============================================================================

// Property extraction patterns
static PROPERTY_PATTERN: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"^\s*-\s*([a-zA-Z0-9_:-]+)::\s*(.+)$").expect("Invalid PROPERTY_PATTERN regex")
});

static WIKI_LINK_PATTERN: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"\[\[([^\]]+)\]\]").expect("Invalid WIKI_LINK_PATTERN regex")
});

static SECTION_HEADER_PATTERN: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"^\s*-\s*(#{1,4})\s*(.+)$").expect("Invalid SECTION_HEADER_PATTERN regex")
});

static OWL_AXIOM_PATTERN: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"```(?:clojure|owl)\s*\n(.*?)\n```").expect("Invalid OWL_AXIOM_PATTERN regex")
});

static BRIDGE_PATTERN: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"^\s*-\s*(bridges-(?:to|from))::\s*\[\[([^\]]+)\]\]\s*via\s+(\w+)")
        .expect("Invalid BRIDGE_PATTERN regex")
});

// Domain configuration
static DOMAIN_PREFIXES: Lazy<HashMap<&'static str, &'static str>> = Lazy::new(|| {
    let mut m = HashMap::new();
    m.insert("AI-", "ai");
    m.insert("BC-", "bc");
    m.insert("RB-", "rb");
    m.insert("MV-", "mv");
    m.insert("TC-", "tc");
    m.insert("DT-", "dt");
    m
});

// ============================================================================
// Data Structures
// ============================================================================

/// Complete ontology block with all tiers of metadata
#[derive(Debug, Clone)]
pub struct OntologyBlock {
    // === File Location ===
    pub file_path: String,
    pub raw_block: String,

    // === Tier 1: Required Properties ===
    // Identification
    pub ontology: bool,
    pub term_id: Option<String>,
    pub preferred_term: Option<String>,
    pub source_domain: Option<String>,
    pub status: Option<String>,
    pub public_access: Option<bool>,
    pub last_updated: Option<String>,

    // Definition
    pub definition: Option<String>,

    // Semantic Classification
    pub owl_class: Option<String>,
    pub owl_physicality: Option<String>,
    pub owl_role: Option<String>,

    // Relationships (Tier 1)
    pub is_subclass_of: Vec<String>,

    // === Tier 2: Recommended Properties ===
    // Identification (Tier 2)
    pub alt_terms: Vec<String>,
    pub version: Option<String>,
    pub quality_score: Option<f64>,
    pub cross_domain_links: Option<i32>,

    // Definition (Tier 2)
    pub maturity: Option<String>,
    pub source: Vec<String>,
    pub authority_score: Option<f64>,
    pub scope_note: Option<String>,

    // Semantic Classification (Tier 2)
    pub owl_inferred_class: Option<String>,
    pub belongs_to_domain: Vec<String>,

    // Relationships (Tier 2)
    pub has_part: Vec<String>,
    pub is_part_of: Vec<String>,
    pub requires: Vec<String>,
    pub depends_on: Vec<String>,
    pub enables: Vec<String>,
    pub relates_to: Vec<String>,

    // === Tier 3: Optional Properties ===
    pub implemented_in_layer: Vec<String>,

    // Cross-domain bridges
    pub bridges_to: Vec<String>,
    pub bridges_from: Vec<String>,

    // OWL axioms from code blocks
    pub owl_axioms: Vec<String>,

    // Domain-specific extension properties
    pub domain_extensions: HashMap<String, String>,

    // All other relationships not explicitly modeled
    pub other_relationships: HashMap<String, Vec<String>>,
}

impl OntologyBlock {
    pub fn new(file_path: String) -> Self {
        Self {
            file_path,
            raw_block: String::new(),
            ontology: false,
            term_id: None,
            preferred_term: None,
            source_domain: None,
            status: None,
            public_access: None,
            last_updated: None,
            definition: None,
            owl_class: None,
            owl_physicality: None,
            owl_role: None,
            is_subclass_of: Vec::new(),
            alt_terms: Vec::new(),
            version: None,
            quality_score: None,
            cross_domain_links: None,
            maturity: None,
            source: Vec::new(),
            authority_score: None,
            scope_note: None,
            owl_inferred_class: None,
            belongs_to_domain: Vec::new(),
            has_part: Vec::new(),
            is_part_of: Vec::new(),
            requires: Vec::new(),
            depends_on: Vec::new(),
            enables: Vec::new(),
            relates_to: Vec::new(),
            implemented_in_layer: Vec::new(),
            bridges_to: Vec::new(),
            bridges_from: Vec::new(),
            owl_axioms: Vec::new(),
            domain_extensions: HashMap::new(),
            other_relationships: HashMap::new(),
        }
    }

    /// Get domain from term-id, source-domain, or namespace
    pub fn get_domain(&self) -> Option<String> {
        // Try source-domain first
        if let Some(ref domain) = self.source_domain {
            return Some(domain.to_lowercase());
        }

        // Try term-id prefix
        if let Some(ref term_id) = self.term_id {
            for (prefix, domain) in DOMAIN_PREFIXES.iter() {
                if term_id.starts_with(prefix) {
                    return Some(domain.to_string());
                }
            }
        }

        // Try namespace in owl_class
        if let Some(ref owl_class) = self.owl_class {
            if let Some(colon_idx) = owl_class.find(':') {
                let prefix = &owl_class[..colon_idx];
                if DOMAIN_PREFIXES.values().any(|&d| d == prefix) {
                    return Some(prefix.to_string());
                }
            }
        }

        None
    }

    /// Get full IRI from owl:class property
    pub fn get_full_iri(&self) -> Option<String> {
        let owl_class = self.owl_class.as_ref()?;

        // If already a full URI, return it
        if owl_class.starts_with("http://") || owl_class.starts_with("https://") {
            return Some(owl_class.clone());
        }

        // Parse namespace:localname format
        if let Some(colon_idx) = owl_class.find(':') {
            let prefix = &owl_class[..colon_idx];
            let localname = &owl_class[colon_idx + 1..];

            // Map domain prefixes to namespaces
            let namespace = match prefix {
                "ai" => "http://narrativegoldmine.com/ai#",
                "bc" => "http://narrativegoldmine.com/blockchain#",
                "rb" => "http://narrativegoldmine.com/robotics#",
                "mv" => "http://narrativegoldmine.com/metaverse#",
                "tc" => "http://narrativegoldmine.com/telecollaboration#",
                "dt" => "http://narrativegoldmine.com/disruptive-tech#",
                "owl" => "http://www.w3.org/2002/07/owl#",
                "rdfs" => "http://www.w3.org/2000/01/rdf-schema#",
                "rdf" => "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
                "xsd" => "http://www.w3.org/2001/XMLSchema#",
                "dcterms" => "http://purl.org/dc/terms/",
                "skos" => "http://www.w3.org/2004/02/skos/core#",
                _ => return None,
            };

            return Some(format!("{}{}", namespace, localname));
        }

        None
    }

    /// Validate that all Tier 1 (required) properties are present
    pub fn validate(&self) -> Vec<String> {
        let mut errors = Vec::new();

        // Tier 1 required properties
        if self.term_id.is_none() {
            errors.push("Missing required property: term-id".to_string());
        }

        if self.preferred_term.is_none() {
            errors.push("Missing required property: preferred-term".to_string());
        }

        if self.source_domain.is_none() {
            errors.push("Missing required property: source-domain".to_string());
        }

        if self.status.is_none() {
            errors.push("Missing required property: status".to_string());
        }

        if self.public_access.is_none() {
            errors.push("Missing required property: public-access".to_string());
        }

        if self.last_updated.is_none() {
            errors.push("Missing required property: last-updated".to_string());
        }

        if self.definition.is_none() {
            errors.push("Missing required property: definition".to_string());
        }

        if self.owl_class.is_none() {
            errors.push("Missing required property: owl:class".to_string());
        }

        if self.owl_physicality.is_none() {
            errors.push("Missing required property: owl:physicality".to_string());
        }

        if self.owl_role.is_none() {
            errors.push("Missing required property: owl:role".to_string());
        }

        if self.is_subclass_of.is_empty() {
            errors.push("Missing required property: is-subclass-of (at least one parent class)".to_string());
        }

        // Validate term-id format
        if let Some(ref term_id) = self.term_id {
            if let Some(domain) = self.get_domain() {
                if let Some((&expected_prefix, _)) = DOMAIN_PREFIXES
                    .iter()
                    .find(|(_, &d)| d == domain.as_str())
                {
                    if !term_id.starts_with(expected_prefix) {
                        errors.push(format!(
                            "term-id '{}' doesn't match domain '{}' (expected {})",
                            term_id, domain, expected_prefix
                        ));
                    }
                }
            }
        }

        // Validate namespace consistency
        if let Some(ref owl_class) = self.owl_class {
            if let Some(colon_idx) = owl_class.find(':') {
                let prefix = &owl_class[..colon_idx];
                if let Some(ref domain) = self.source_domain {
                    let domain_lower = domain.to_lowercase();
                    if prefix != domain_lower && DOMAIN_PREFIXES.values().any(|&d| d == prefix) {
                        errors.push(format!(
                            "owl:class namespace '{}' doesn't match source-domain '{}'",
                            prefix, domain
                        ));
                    }
                }
            }
        }

        errors
    }
}

/// Legacy output structure for backward compatibility
#[derive(Debug)]
pub struct OntologyData {
    pub classes: Vec<OwlClass>,
    pub properties: Vec<OwlProperty>,
    pub axioms: Vec<OwlAxiom>,
    pub class_hierarchy: Vec<(String, String)>,
}

// ============================================================================
// Parser Implementation
// ============================================================================

pub struct OntologyParser;

impl OntologyParser {
    pub fn new() -> Self {
        Self
    }

    /// Parse a markdown file and extract the complete ontology block
    pub fn parse_enhanced(&self, content: &str, filename: &str) -> Result<OntologyBlock, String> {
        info!("Parsing ontology file (enhanced): {}", filename);

        // Extract ontology section
        let ontology_section = self.extract_ontology_section(content)?;

        // Create block object
        let mut block = OntologyBlock::new(filename.to_string());
        block.raw_block = ontology_section.clone();

        // === Extract Tier 1 Properties ===
        self.extract_tier1_properties(&ontology_section, &mut block);

        // === Extract Tier 2 Properties ===
        self.extract_tier2_properties(&ontology_section, &mut block);

        // === Extract Tier 3 Properties ===
        self.extract_tier3_properties(&ontology_section, &mut block);

        // === Extract Relationships ===
        self.extract_relationships(&ontology_section, &mut block);

        // === Extract Cross-Domain Bridges ===
        self.extract_bridges(&ontology_section, &mut block);

        // === Extract OWL Axioms ===
        self.extract_owl_axioms(content, &mut block);

        // === Extract Domain Extensions ===
        self.extract_domain_extensions(&ontology_section, &mut block);

        debug!(
            "Parsed enhanced {}: term_id={:?}, domain={:?}, relationships={}",
            filename,
            block.term_id,
            block.get_domain(),
            block.is_subclass_of.len()
                + block.has_part.len()
                + block.requires.len()
                + block.enables.len()
        );

        Ok(block)
    }

    /// Legacy parse method for backward compatibility
    pub fn parse(&self, content: &str, filename: &str) -> Result<OntologyData, String> {
        let block = self.parse_enhanced(content, filename)?;

        // Convert to legacy format
        let classes = self.block_to_classes(&block);
        let properties = Vec::new(); // Could extract from OWL axioms if needed
        let axioms = self.block_to_axioms(&block);
        let class_hierarchy = block.is_subclass_of
            .iter()
            .filter_map(|parent| {
                block.owl_class.as_ref().map(|cls| (cls.clone(), parent.clone()))
            })
            .collect();

        Ok(OntologyData {
            classes,
            properties,
            axioms,
            class_hierarchy,
        })
    }

    // ========================================================================
    // Section Extraction
    // ========================================================================

    fn extract_ontology_section(&self, content: &str) -> Result<String, String> {
        let lines: Vec<&str> = content.lines().collect();
        let mut section_start = None;

        for (i, line) in lines.iter().enumerate() {
            if line.contains("### OntologyBlock") {
                section_start = Some(i);
                break;
            }
        }

        let start = section_start.ok_or_else(|| "No OntologyBlock found in file".to_string())?;
        let section: Vec<&str> = lines[start..].iter().copied().collect();

        Ok(section.join("\n"))
    }

    // ========================================================================
    // Tier 1 Property Extraction
    // ========================================================================

    fn extract_tier1_properties(&self, section: &str, block: &mut OntologyBlock) {
        // Identification
        if let Some(val) = self.extract_property(section, "ontology") {
            block.ontology = val.to_lowercase() == "true";
        }
        block.term_id = self.extract_property(section, "term-id");
        block.preferred_term = self.extract_property(section, "preferred-term");
        block.source_domain = self.extract_property(section, "source-domain");
        block.status = self.extract_property(section, "status");

        if let Some(val) = self.extract_property(section, "public-access") {
            block.public_access = Some(val.to_lowercase() == "true");
        }

        block.last_updated = self.extract_property(section, "last-updated");

        // Definition
        block.definition = self.extract_property(section, "definition");

        // Semantic Classification
        block.owl_class = self.extract_property(section, "owl:class");
        block.owl_physicality = self.extract_property(section, "owl:physicality");
        block.owl_role = self.extract_property(section, "owl:role");
    }

    // ========================================================================
    // Tier 2 Property Extraction
    // ========================================================================

    fn extract_tier2_properties(&self, section: &str, block: &mut OntologyBlock) {
        // Identification (Tier 2)
        block.alt_terms = self.extract_property_list(section, "alt-terms");
        block.version = self.extract_property(section, "version");

        if let Some(val) = self.extract_property(section, "quality-score") {
            block.quality_score = val.parse::<f64>().ok();
        }

        if let Some(val) = self.extract_property(section, "cross-domain-links") {
            block.cross_domain_links = val.parse::<i32>().ok();
        }

        // Definition (Tier 2)
        block.maturity = self.extract_property(section, "maturity");
        block.source = self.extract_property_list(section, "source");

        if let Some(val) = self.extract_property(section, "authority-score") {
            block.authority_score = val.parse::<f64>().ok();
        }

        block.scope_note = self.extract_property(section, "scope-note");

        // Semantic Classification (Tier 2)
        block.owl_inferred_class = self.extract_property(section, "owl:inferred-class");
        block.belongs_to_domain = self.extract_property_list(section, "belongsToDomain");
    }

    // ========================================================================
    // Tier 3 Property Extraction
    // ========================================================================

    fn extract_tier3_properties(&self, section: &str, block: &mut OntologyBlock) {
        block.implemented_in_layer = self.extract_property_list(section, "implementedInLayer");
    }

    // ========================================================================
    // Relationship Extraction
    // ========================================================================

    fn extract_relationships(&self, section: &str, block: &mut OntologyBlock) {
        // Known relationships
        block.is_subclass_of = self.extract_property_list(section, "is-subclass-of");
        block.has_part = self.extract_property_list(section, "has-part");
        block.is_part_of = self.extract_property_list(section, "is-part-of");
        block.requires = self.extract_property_list(section, "requires");
        block.depends_on = self.extract_property_list(section, "depends-on");
        block.enables = self.extract_property_list(section, "enables");
        block.relates_to = self.extract_property_list(section, "relates-to");

        // Extract other relationships from Relationships section
        let relationships_section = self.extract_relationships_section(section);

        let known_rels = vec![
            "is-subclass-of", "has-part", "is-part-of", "requires",
            "depends-on", "enables", "relates-to", "bridges-to", "bridges-from"
        ];

        for (rel_name, targets) in relationships_section {
            if !known_rels.contains(&rel_name.as_str()) {
                block.other_relationships.insert(rel_name, targets);
            }
        }
    }

    fn extract_relationships_section(&self, section: &str) -> HashMap<String, Vec<String>> {
        let mut relationships = HashMap::new();
        let mut in_relationships = false;

        for line in section.lines() {
            // Check for Relationships section header
            if line.contains("#### Relationships") {
                in_relationships = true;
                continue;
            }

            // Stop at next section
            if in_relationships && line.contains("####") && !line.contains("Relationships") {
                break;
            }

            if in_relationships {
                if let Some(caps) = PROPERTY_PATTERN.captures(line) {
                    let prop_name = caps.get(1).unwrap().as_str().to_string();
                    let value_text = caps.get(2).unwrap().as_str();

                    // Extract wiki-links
                    let wiki_links = self.extract_wiki_links(value_text);
                    if !wiki_links.is_empty() {
                        relationships.entry(prop_name).or_insert_with(Vec::new).extend(wiki_links);
                    }
                }
            }
        }

        relationships
    }

    // ========================================================================
    // Cross-Domain Bridges Extraction
    // ========================================================================

    fn extract_bridges(&self, section: &str, block: &mut OntologyBlock) {
        for line in section.lines() {
            if let Some(caps) = BRIDGE_PATTERN.captures(line) {
                let direction = caps.get(1).unwrap().as_str();
                let target = caps.get(2).unwrap().as_str();
                let via = caps.get(3).unwrap().as_str();

                let bridge_str = format!("{} via {}", target, via);

                if direction == "bridges-to" {
                    block.bridges_to.push(bridge_str);
                } else {
                    block.bridges_from.push(bridge_str);
                }
            }
        }
    }

    // ========================================================================
    // OWL Axioms Extraction
    // ========================================================================

    fn extract_owl_axioms(&self, content: &str, block: &mut OntologyBlock) {
        for caps in OWL_AXIOM_PATTERN.captures_iter(content) {
            if let Some(axiom_match) = caps.get(1) {
                block.owl_axioms.push(axiom_match.as_str().trim().to_string());
            }
        }
    }

    // ========================================================================
    // Domain Extension Properties
    // ========================================================================

    fn extract_domain_extensions(&self, section: &str, block: &mut OntologyBlock) {
        let domain = match block.get_domain() {
            Some(d) => d,
            None => return,
        };

        // Domain-specific properties based on canonical schema
        let extension_props = match domain.as_str() {
            "ai" => vec!["algorithm-type", "computational-complexity"],
            "bc" => vec!["consensus-mechanism", "decentralization-level"],
            "rb" => vec!["physicality", "autonomy-level"],
            "mv" => vec!["immersion-level", "interaction-mode"],
            "tc" => vec!["collaboration-type", "communication-mode"],
            "dt" => vec!["disruption-level", "maturity-stage"],
            _ => vec![],
        };

        for prop in extension_props {
            if let Some(val) = self.extract_property(section, prop) {
                block.domain_extensions.insert(prop.to_string(), val);
            }
        }
    }

    // ========================================================================
    // Property Extraction Utilities
    // ========================================================================

    fn extract_property(&self, section: &str, property_name: &str) -> Option<String> {
        for line in section.lines() {
            if let Some(caps) = PROPERTY_PATTERN.captures(line) {
                let prop = caps.get(1).unwrap().as_str();
                if prop == property_name {
                    let value = caps.get(2).unwrap().as_str().trim();
                    // Remove wiki-link brackets if present
                    let cleaned = if value.starts_with("[[") && value.ends_with("]]") {
                        &value[2..value.len() - 2]
                    } else {
                        value
                    };
                    return Some(cleaned.to_string());
                }
            }
        }
        None
    }

    fn extract_property_list(&self, section: &str, property_name: &str) -> Vec<String> {
        let mut result = Vec::new();

        for line in section.lines() {
            if let Some(caps) = PROPERTY_PATTERN.captures(line) {
                let prop = caps.get(1).unwrap().as_str();
                if prop == property_name {
                    let value_text = caps.get(2).unwrap().as_str();
                    let wiki_links = self.extract_wiki_links(value_text);
                    result.extend(wiki_links);
                }
            }
        }

        result
    }

    fn extract_wiki_links(&self, text: &str) -> Vec<String> {
        WIKI_LINK_PATTERN
            .captures_iter(text)
            .filter_map(|caps| caps.get(1).map(|m| m.as_str().trim().to_string()))
            .collect()
    }

    // ========================================================================
    // Legacy Conversion Methods
    // ========================================================================

    fn block_to_classes(&self, block: &OntologyBlock) -> Vec<OwlClass> {
        if block.owl_class.is_none() {
            return Vec::new();
        }

        let mut properties = HashMap::new();
        properties.insert("source_file".to_string(), block.file_path.clone());

        if let Some(ref term_id) = block.term_id {
            properties.insert("term_id".to_string(), term_id.clone());
        }
        if let Some(ref status) = block.status {
            properties.insert("status".to_string(), status.clone());
        }

        vec![OwlClass {
            iri: block.owl_class.clone().unwrap_or_default(),
            term_id: block.term_id.clone(),
            preferred_term: block.preferred_term.clone(),
            label: block.preferred_term.clone(),
            description: block.definition.clone(),
            parent_classes: block.is_subclass_of.clone(),
            source_domain: block.source_domain.clone(),
            version: block.version.clone(),
            class_type: block.owl_class.clone(),
            status: block.status.clone(),
            maturity: block.maturity.clone(),
            quality_score: block.quality_score.map(|v| v as f32),
            authority_score: block.authority_score.map(|v| v as f32),
            public_access: block.public_access,
            content_status: None,
            owl_physicality: block.owl_physicality.clone(),
            owl_role: block.owl_role.clone(),
            belongs_to_domain: block.belongs_to_domain.first().cloned(),
            bridges_to_domain: None,
            source_file: Some(block.file_path.clone()),
            file_sha1: None,
            markdown_content: Some(block.raw_block.clone()),
            last_synced: None,
            properties,
            additional_metadata: None,
        }]
    }

    fn block_to_axioms(&self, block: &OntologyBlock) -> Vec<OwlAxiom> {
        let mut axioms = Vec::new();

        // SubClassOf axioms
        if let Some(ref subject) = block.owl_class {
            for parent in &block.is_subclass_of {
                axioms.push(OwlAxiom {
                    id: None,
                    axiom_type: AxiomType::SubClassOf,
                    subject: subject.clone(),
                    object: parent.clone(),
                    annotations: HashMap::new(),
                });
            }
        }

        axioms
    }
}

impl Default for OntologyParser {
    fn default() -> Self {
        Self::new()
    }
}

// ============================================================================
// Tests
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_enhanced_complete_block() {
        let parser = OntologyParser::new();
        let content = r#"
# Large Language Models

- ### OntologyBlock
  id:: llm-ontology
  collapsed:: true

  - **Identification**
    - ontology:: true
    - term-id:: AI-0850
    - preferred-term:: Large Language Models
    - alt-terms:: [[LLM]], [[Foundation Models]]
    - source-domain:: ai
    - status:: complete
    - public-access:: true
    - version:: 1.0.0
    - last-updated:: 2025-11-21
    - quality-score:: 0.85

  - **Definition**
    - definition:: A Large Language Model (LLM) is an artificial intelligence system based on deep neural networks (typically [[Transformer]] architectures) trained on vast text corpora to understand and generate human-like text.
    - maturity:: mature
    - source:: [[OpenAI Research]], [[Stanford AI Index]]
    - authority-score:: 0.95

  - **Semantic Classification**
    - owl:class:: ai:LargeLanguageModel
    - owl:physicality:: VirtualEntity
    - owl:role:: Process
    - belongsToDomain:: [[AI-GroundedDomain]]

  - #### Relationships
    id:: llm-relationships
    - is-subclass-of:: [[Artificial Intelligence]], [[Neural Network Architecture]]
    - requires:: [[Training Data]], [[Computational Resources]]
    - enables:: [[Few-Shot Learning]], [[Text Generation]]
"#;

        let result = parser.parse_enhanced(content, "test.md");
        assert!(result.is_ok());

        let block = result.unwrap();

        // Tier 1 properties
        assert_eq!(block.term_id, Some("AI-0850".to_string()));
        assert_eq!(block.preferred_term, Some("Large Language Models".to_string()));
        assert_eq!(block.source_domain, Some("ai".to_string()));
        assert_eq!(block.status, Some("complete".to_string()));
        assert_eq!(block.public_access, Some(true));
        assert_eq!(block.owl_class, Some("ai:LargeLanguageModel".to_string()));
        assert_eq!(block.owl_physicality, Some("VirtualEntity".to_string()));
        assert_eq!(block.owl_role, Some("Process".to_string()));

        // Tier 2 properties
        assert_eq!(block.alt_terms, vec!["LLM", "Foundation Models"]);
        assert_eq!(block.version, Some("1.0.0".to_string()));
        assert_eq!(block.quality_score, Some(0.85));
        assert_eq!(block.maturity, Some("mature".to_string()));
        assert_eq!(block.authority_score, Some(0.95));

        // Relationships
        assert_eq!(block.is_subclass_of.len(), 2);
        assert!(block.is_subclass_of.contains(&"Artificial Intelligence".to_string()));
        assert_eq!(block.requires, vec!["Training Data", "Computational Resources"]);
        assert_eq!(block.enables, vec!["Few-Shot Learning", "Text Generation"]);

        // Validation
        let errors = block.validate();
        assert!(errors.is_empty(), "Validation errors: {:?}", errors);
    }

    #[test]
    fn test_parse_enhanced_with_bridges() {
        let parser = OntologyParser::new();
        let content = r#"
- ### OntologyBlock
  - ontology:: true
  - term-id:: AI-0001
  - preferred-term:: Test Concept
  - source-domain:: ai
  - status:: complete
  - public-access:: true
  - last-updated:: 2025-11-21
  - definition:: A test concept
  - owl:class:: ai:TestConcept
  - owl:physicality:: VirtualEntity
  - owl:role:: Concept

  - #### Relationships
    - is-subclass-of:: [[owl:Thing]]

  - #### CrossDomainBridges
    - bridges-to:: [[Blockchain Verification]] via enables
    - bridges-from:: [[Robot Control]] via requires
"#;

        let result = parser.parse_enhanced(content, "test.md");
        assert!(result.is_ok());

        let block = result.unwrap();
        assert_eq!(block.bridges_to, vec!["Blockchain Verification via enables"]);
        assert_eq!(block.bridges_from, vec!["Robot Control via requires"]);
    }

    #[test]
    fn test_parse_enhanced_with_owl_axioms() {
        let parser = OntologyParser::new();
        let content = r#"
- ### OntologyBlock
  - term-id:: AI-0002
  - preferred-term:: Test
  - source-domain:: ai
  - status:: draft
  - public-access:: true
  - last-updated:: 2025-11-21
  - definition:: Test
  - owl:class:: ai:Test
  - owl:physicality:: VirtualEntity
  - owl:role:: Concept

  - #### Relationships
    - is-subclass-of:: [[owl:Thing]]

  - #### OWL Axioms
    - ```clojure
      (Declaration (Class :TestConcept))
      (SubClassOf :TestConcept :ParentClass)
      ```
"#;

        let result = parser.parse_enhanced(content, "test.md");
        assert!(result.is_ok());

        let block = result.unwrap();
        assert_eq!(block.owl_axioms.len(), 1);
        assert!(block.owl_axioms[0].contains("Declaration"));
    }

    #[test]
    fn test_validation_missing_required() {
        let mut block = OntologyBlock::new("test.md".to_string());
        block.term_id = Some("AI-0001".to_string());
        // Missing other required fields

        let errors = block.validate();
        assert!(!errors.is_empty());
        assert!(errors.iter().any(|e| e.contains("preferred-term")));
        assert!(errors.iter().any(|e| e.contains("definition")));
    }

    #[test]
    fn test_get_domain() {
        let mut block = OntologyBlock::new("test.md".to_string());

        // From source-domain
        block.source_domain = Some("ai".to_string());
        assert_eq!(block.get_domain(), Some("ai".to_string()));

        // From term-id
        block.source_domain = None;
        block.term_id = Some("BC-0001".to_string());
        assert_eq!(block.get_domain(), Some("bc".to_string()));
    }

    #[test]
    fn test_get_full_iri() {
        let mut block = OntologyBlock::new("test.md".to_string());
        block.owl_class = Some("ai:LargeLanguageModel".to_string());

        let iri = block.get_full_iri();
        assert_eq!(iri, Some("http://narrativegoldmine.com/ai#LargeLanguageModel".to_string()));
    }

    #[test]
    fn test_legacy_parse_backward_compatibility() {
        let parser = OntologyParser::new();
        let content = r#"
- ### OntologyBlock
  - owl:class:: ai:Test
  - preferred-term:: Test Concept
  - definition:: A test
  - owl:physicality:: VirtualEntity
  - owl:role:: Concept
  - term-id:: AI-0001
  - source-domain:: ai
  - status:: complete
  - public-access:: true
  - last-updated:: 2025-11-21

  - #### Relationships
    - is-subclass-of:: [[Parent]]
"#;

        let result = parser.parse(content, "test.md");
        assert!(result.is_ok());

        let data = result.unwrap();
        assert_eq!(data.classes.len(), 1);
        assert_eq!(data.classes[0].iri, "ai:Test");
        assert_eq!(data.axioms.len(), 1);
        assert_eq!(data.class_hierarchy.len(), 1);
    }
}

================================================================================
                    SECTION 6: HTTP/WEBSOCKET HANDLERS
================================================================================

--------------------------------------------------------------------------------
FILE: src/handlers/mod.rs
PURPOSE: Module exports for all HTTP and WebSocket handlers
--------------------------------------------------------------------------------
pub mod admin_sync_handler;
// DEPRECATED: admin_bridge_handler removed (legacy ontology bridge)
pub mod api_handler;
pub mod bots_handler;
pub mod bots_visualization_handler;
pub mod client_log_handler;
pub mod client_messages_handler;
pub mod clustering_handler;
pub mod consolidated_health_handler;
pub mod constraints_handler;
pub mod cypher_query_handler;
pub mod graph_export_handler;
pub mod graph_state_handler; 
                             
pub mod mcp_relay_handler;
pub mod multi_mcp_websocket_handler;
pub mod natural_language_query_handler;
pub mod nostr_handler;
pub mod ontology_handler; 
pub mod pages_handler;
pub mod perplexity_handler;
pub mod pipeline_admin_handler;
pub mod ragflow_handler;
pub mod realtime_websocket_handler;
pub mod settings_handler; 
                          
pub mod settings_validation_fix;
pub mod socket_flow_handler;
pub mod speech_socket_handler;
pub mod utils;
pub mod validation_handler;
pub mod websocket_settings_handler;
pub mod websocket_utils; // WebSocket common utilities
pub mod workspace_handler;

// Phase 5: Hexagonal architecture handlers
pub mod physics_handler;
pub mod schema_handler;
pub mod semantic_handler;

pub use natural_language_query_handler::configure_nl_query_routes;
pub use physics_handler::configure_routes as configure_physics_routes;
pub use schema_handler::configure_schema_routes;
pub use semantic_handler::configure_routes as configure_semantic_routes;

// Phase 7: Inference handler
pub mod inference_handler;

pub use inference_handler::configure_routes as configure_inference_routes;

#[cfg(test)]
pub mod tests;
pub mod semantic_pathfinding_handler;
pub use semantic_pathfinding_handler::configure_pathfinding_routes;

// High-Performance Networking (QUIC/WebTransport + fastwebsockets)
pub mod quic_transport_handler;
pub mod fastwebsockets_handler;

// Solid Server (JSS) integration
pub mod solid_proxy_handler;
pub use solid_proxy_handler::configure_routes as configure_solid_routes;

pub use quic_transport_handler::{
    QuicTransportServer, QuicServerConfig,
    PostcardNodeUpdate, PostcardBatchUpdate, PostcardDeltaUpdate,
    ControlMessage, TopologyNode, TopologyEdge,
    encode_postcard_batch, decode_postcard_batch, calculate_deltas,
};

pub use fastwebsockets_handler::{
    FastWebSocketServer, FastWebSocketConfig,
    StandaloneFastWsHandler,
    TransportProtocol, SerializationFormat, NegotiatedProtocol,
    negotiate_protocol,
};

--------------------------------------------------------------------------------
FILE: src/handlers/graph_state_handler.rs
PURPOSE: Graph state CRUD operations handler
--------------------------------------------------------------------------------
// CQRS-Based Graph State Handler
// Uses Knowledge Graph application layer for all graph operations

use crate::handlers::utils::execute_in_thread;
use crate::{ok_json, error_json, bad_request, not_found, created_json, service_unavailable};
use crate::AppState;
use actix_web::{web, HttpResponse, Responder};
use log::{debug, error, info};
use serde::{Deserialize, Serialize};

// Import CQRS handlers
use crate::application::knowledge_graph::{
    AddEdge,
    AddEdgeHandler,
    
    AddNode,
    AddNodeHandler,
    BatchUpdatePositions,
    BatchUpdatePositionsHandler,
    GetGraphStatistics,
    GetGraphStatisticsHandler,
    GetNode,
    GetNodeHandler,
    
    LoadGraph,
    LoadGraphHandler,
    RemoveNode,
    RemoveNodeHandler,
    UpdateEdge,
    UpdateEdgeHandler,
    UpdateNode,
    UpdateNodeHandler,
};
use crate::models::edge::Edge;
use crate::models::node::Node;
use hexser::{DirectiveHandler, QueryHandler};

#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct GraphStateResponse {
    pub nodes_count: usize,
    pub edges_count: usize,
    pub metadata_count: usize,
    pub positions: Vec<NodePosition>,
    pub settings_version: String,
    pub timestamp: u64,
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct NodePosition {
    pub id: u32,
    pub x: f32,
    pub y: f32,
    pub z: f32,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct AddNodeRequest {
    pub node: Node,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct UpdateNodeRequest {
    pub node: Node,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct AddEdgeRequest {
    pub edge: Edge,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct BatchPositionsRequest {
    pub positions: Vec<(u32, f32, f32, f32)>,
}

///
pub async fn get_graph_state(state: web::Data<AppState>) -> impl Responder {
    info!("Received request for complete graph state via CQRS");

    
    let load_handler = LoadGraphHandler::new(state.neo4j_adapter.clone());

    
    let result = execute_in_thread(move || load_handler.handle(LoadGraph)).await;

    match result {
        Ok(Ok(query_result)) => {
            
            let graph_data = match query_result {
                crate::application::knowledge_graph::QueryResult::Graph(graph_arc) => graph_arc,
                _ => {
                    error!("Unexpected query result type");
                    return error_json!("Unexpected query result type");
                }
            };

            
            let graph_ref = graph_data.as_ref();
            let positions: Vec<NodePosition> = graph_ref
                .nodes
                .iter()
                .map(|node| NodePosition {
                    id: node.id,
                    x: node.data.x,
                    y: node.data.y,
                    z: node.data.z,
                })
                .collect();

            let response = GraphStateResponse {
                nodes_count: graph_ref.nodes.len(),
                edges_count: graph_ref.edges.len(),
                metadata_count: graph_ref.metadata.len(),
                positions,
                settings_version: "1.0.0".to_string(), 
                timestamp: std::time::SystemTime::now()
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap_or_default()
                    .as_secs(),
            };

            debug!(
                "Returning graph state via CQRS: {} nodes, {} edges, {} metadata entries",
                response.nodes_count, response.edges_count, response.metadata_count
            );

            ok_json!(response)
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to get graph data: {}", e);
            error_json!("Failed to retrieve graph state", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn get_graph_statistics(state: web::Data<AppState>) -> impl Responder {
    info!("Received request for graph statistics via CQRS");

    
    let handler = GetGraphStatisticsHandler::new(state.neo4j_adapter.clone());

    
    let result = execute_in_thread(move || handler.handle(GetGraphStatistics)).await;

    match result {
        Ok(Ok(query_result)) => {
            
            let statistics = match query_result {
                crate::application::knowledge_graph::QueryResult::Statistics(stats) => stats,
                _ => {
                    error!("Unexpected query result type");
                    return error_json!("Unexpected query result type");
                }
            };

            info!("Graph statistics retrieved successfully via CQRS");
            ok_json!(statistics)
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to get statistics: {}", e);
            error_json!("Failed to retrieve statistics", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn add_node(
    state: web::Data<AppState>,
    request: web::Json<AddNodeRequest>,
) -> impl Responder {
    let node = request.into_inner().node;
    let node_id = node.id;
    info!(
        "Adding node via CQRS directive: metadata_id={}",
        node.metadata_id
    );

    
    let handler = AddNodeHandler::new(state.neo4j_adapter.clone());

    
    let result = execute_in_thread(move || handler.handle(AddNode { node })).await;

    match result {
        Ok(Ok(())) => {
            info!("Node added successfully via CQRS: id={}", node_id);
            ok_json!(serde_json::json!({
                "success": true,
                "node_id": node_id
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to add node: {}", e);
            error_json!("Failed to add node", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn update_node(
    state: web::Data<AppState>,
    request: web::Json<UpdateNodeRequest>,
) -> impl Responder {
    let node = request.into_inner().node;
    info!("Updating node via CQRS directive: id={}", node.id);

    
    let handler = UpdateNodeHandler::new(state.neo4j_adapter.clone());

    
    let result = execute_in_thread(move || handler.handle(UpdateNode { node })).await;

    match result {
        Ok(Ok(())) => {
            info!("Node updated successfully via CQRS");
            ok_json!(serde_json::json!({
                "success": true
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to update node: {}", e);
            error_json!("Failed to update node", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn remove_node(state: web::Data<AppState>, node_id: web::Path<u32>) -> impl Responder {
    let id = node_id.into_inner();
    info!("Removing node via CQRS directive: id={}", id);

    
    let handler = RemoveNodeHandler::new(state.neo4j_adapter.clone());

    
    let result = execute_in_thread(move || handler.handle(RemoveNode { node_id: id })).await;

    match result {
        Ok(Ok(())) => {
            info!("Node removed successfully via CQRS");
            ok_json!(serde_json::json!({
                "success": true
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to remove node: {}", e);
            error_json!("Failed to remove node", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn get_node(state: web::Data<AppState>, node_id: web::Path<u32>) -> impl Responder {
    let id = node_id.into_inner();
    info!("Getting node via CQRS query: id={}", id);

    
    let handler = GetNodeHandler::new(state.neo4j_adapter.clone());

    
    let result = execute_in_thread(move || handler.handle(GetNode { node_id: id })).await;

    match result {
        Ok(Ok(query_result)) => {
            
            let node_opt = match query_result {
                crate::application::knowledge_graph::QueryResult::Node(node) => node,
                _ => {
                    error!("Unexpected query result type");
                    return error_json!("Unexpected query result type");
                }
            };

            match node_opt {
                Some(node) => {
                    info!("Node found via CQRS: id={}", id);
                    ok_json!(node)
                }
                None => {
                    info!("Node not found: id={}", id);
                    not_found!("Node not found")
                }
            }
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to get node: {}", e);
            error_json!("Failed to get node", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn add_edge(
    state: web::Data<AppState>,
    request: web::Json<AddEdgeRequest>,
) -> impl Responder {
    let edge = request.into_inner().edge;
    let edge_id = edge.id.clone();
    let edge_source = edge.source;
    let edge_target = edge.target;
    info!(
        "Adding edge via CQRS directive: source={}, target={}",
        edge_source, edge_target
    );

    
    let handler = AddEdgeHandler::new(state.neo4j_adapter.clone());

    
    let result = execute_in_thread(move || handler.handle(AddEdge { edge })).await;

    match result {
        Ok(Ok(())) => {
            info!("Edge added successfully via CQRS: id={}", edge_id);
            ok_json!(serde_json::json!({
                "success": true,
                "edge_id": edge_id
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to add edge: {}", e);
            error_json!("Failed to add edge", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn update_edge(state: web::Data<AppState>, request: web::Json<Edge>) -> impl Responder {
    let edge = request.into_inner();
    info!("Updating edge via CQRS directive: id={}", edge.id);

    
    let handler = UpdateEdgeHandler::new(state.neo4j_adapter.clone());

    
    let result = execute_in_thread(move || handler.handle(UpdateEdge { edge })).await;

    match result {
        Ok(Ok(())) => {
            info!("Edge updated successfully via CQRS");
            ok_json!(serde_json::json!({
                "success": true
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to update edge: {}", e);
            error_json!("Failed to update edge", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn batch_update_positions(
    state: web::Data<AppState>,
    request: web::Json<BatchPositionsRequest>,
) -> impl Responder {
    let positions = request.into_inner().positions;
    info!(
        "Batch updating {} positions via CQRS directive",
        positions.len()
    );

    
    let handler = BatchUpdatePositionsHandler::new(state.neo4j_adapter.clone());

    
    let result =
        execute_in_thread(move || handler.handle(BatchUpdatePositions { positions })).await;

    match result {
        Ok(Ok(())) => {
            info!("Positions updated successfully via CQRS");
            ok_json!(serde_json::json!({
                "success": true
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to batch update positions: {}", e);
            error_json!("Failed to update positions", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/graph")
            .route("/state", web::get().to(get_graph_state))
            .route("/statistics", web::get().to(get_graph_statistics))
            .route("/nodes", web::post().to(add_node))
            .route("/nodes/{id}", web::get().to(get_node))
            .route("/nodes/{id}", web::put().to(update_node))
            .route("/nodes/{id}", web::delete().to(remove_node))
            .route("/edges", web::post().to(add_edge))
            .route("/edges/{id}", web::put().to(update_edge))
            .route("/positions/batch", web::post().to(batch_update_positions)),
    );
}

--------------------------------------------------------------------------------
FILE: src/handlers/settings_handler.rs
PURPOSE: Settings management handler
--------------------------------------------------------------------------------
// Unified Settings Handler - Single source of truth: AppFullSettings
use crate::actors::messages::{GetSettings, UpdateSettings, UpdateSimulationParams};
use crate::app_state::AppState;
use crate::config::path_access::JsonPathAccessible;
use crate::config::AppFullSettings;
use crate::handlers::validation_handler::ValidationService;
use crate::utils::validation::rate_limit::{
    extract_client_id, EndpointRateLimits, RateLimitConfig, RateLimiter,
};
use crate::utils::validation::MAX_REQUEST_SIZE;
use actix_web::{web, Error, HttpRequest, HttpResponse};
use log::{debug, error, info, warn};
use tracing::info as trace_info;
use uuid::Uuid;
use crate::{ok_json, error_json, bad_request, not_found, created_json, service_unavailable, too_many_requests, payload_too_large};

// Import comprehensive validation for GPU parameters
use crate::handlers::settings_validation_fix::{
    convert_to_snake_case_recursive,
    validate_physics_settings_complete,
};

///
fn value_type_name(value: &Value) -> &'static str {
    match value {
        Value::Null => "null",
        Value::Bool(_) => "boolean",
        Value::Number(_) => "number",
        Value::String(_) => "string",
        Value::Array(_) => "array",
        Value::Object(_) => "object",
    }
}
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use std::borrow::Cow;
use std::sync::Arc;

///
#[derive(Debug, Serialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct SettingsResponseDTO {
    pub visualisation: VisualisationSettingsDTO,
    pub system: SystemSettingsDTO,
    pub xr: XRSettingsDTO,
    pub auth: AuthSettingsDTO,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub ragflow: Option<RagFlowSettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub perplexity: Option<PerplexitySettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub openai: Option<OpenAISettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub kokoro: Option<KokoroSettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub whisper: Option<WhisperSettingsDTO>,
}

///
#[derive(Debug, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct SettingsUpdateDTO {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub visualisation: Option<VisualisationSettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub system: Option<SystemSettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub xr: Option<XRSettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub auth: Option<AuthSettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub ragflow: Option<RagFlowSettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub perplexity: Option<PerplexitySettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub openai: Option<OpenAISettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub kokoro: Option<KokoroSettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub whisper: Option<WhisperSettingsDTO>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct VisualisationSettingsDTO {
    pub rendering: RenderingSettingsDTO,
    pub animations: AnimationSettingsDTO,
    
    pub glow: GlowSettingsDTO,
    pub hologram: HologramSettingsDTO,
    pub graphs: GraphsSettingsDTO,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub camera: Option<CameraSettingsDTO>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub space_pilot: Option<SpacePilotSettingsDTO>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct RenderingSettingsDTO {
    pub ambient_light_intensity: f32,
    pub background_color: String,
    pub directional_light_intensity: f32,
    pub enable_ambient_occlusion: bool,
    pub enable_antialiasing: bool,
    pub enable_shadows: bool,
    pub environment_intensity: f32,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub shadow_map_size: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub shadow_bias: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub context: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub agent_colors: Option<AgentColorsDTO>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct AgentColorsDTO {
    pub coordinator: String,
    pub coder: String,
    pub architect: String,
    pub analyst: String,
    pub tester: String,
    pub researcher: String,
    pub reviewer: String,
    pub optimizer: String,
    pub documenter: String,
    pub queen: String,
    pub default: String,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct AnimationSettingsDTO {
    pub enable_motion_blur: bool,
    pub enable_node_animations: bool,
    pub motion_blur_strength: f32,
    pub selection_wave_enabled: bool,
    pub pulse_enabled: bool,
    pub pulse_speed: f32,
    pub pulse_strength: f32,
    pub wave_speed: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct GlowSettingsDTO {
    pub enabled: bool,
    pub intensity: f32,
    pub radius: f32,
    pub threshold: f32,
    pub diffuse_strength: f32,
    pub atmospheric_density: f32,
    pub volumetric_intensity: f32,
    pub base_color: String,
    pub emission_color: String,
    pub opacity: f32,
    pub pulse_speed: f32,
    pub flow_speed: f32,
    pub node_glow_strength: f32,
    pub edge_glow_strength: f32,
    pub environment_glow_strength: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct HologramSettingsDTO {
    pub ring_count: u32,
    pub ring_color: String,
    pub ring_opacity: f32,
    pub sphere_sizes: Vec<f32>,
    pub ring_rotation_speed: f32,
    pub enable_buckminster: bool,
    pub buckminster_size: f32,
    pub buckminster_opacity: f32,
    pub enable_geodesic: bool,
    pub geodesic_size: f32,
    pub geodesic_opacity: f32,
    pub enable_triangle_sphere: bool,
    pub triangle_sphere_size: f32,
    pub triangle_sphere_opacity: f32,
    pub global_rotation_speed: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct GraphsSettingsDTO {
    pub logseq: GraphSettingsDTO,
    pub visionflow: GraphSettingsDTO,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct GraphSettingsDTO {
    pub nodes: NodeSettingsDTO,
    pub edges: EdgeSettingsDTO,
    pub labels: LabelSettingsDTO,
    pub physics: PhysicsSettingsDTO,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct NodeSettingsDTO {
    pub base_color: String,
    pub metalness: f32,
    pub opacity: f32,
    pub roughness: f32,
    pub node_size: f32,
    pub quality: String,
    pub enable_instancing: bool,
    pub enable_hologram: bool,
    pub enable_metadata_shape: bool,
    pub enable_metadata_visualisation: bool,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct EdgeSettingsDTO {
    pub arrow_size: f32,
    pub base_width: f32,
    pub color: String,
    pub enable_arrows: bool,
    pub opacity: f32,
    pub width_range: Vec<f32>,
    pub quality: String,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct LabelSettingsDTO {
    pub desktop_font_size: f32,
    pub enable_labels: bool,
    pub text_color: String,
    pub text_outline_color: String,
    pub text_outline_width: f32,
    pub text_resolution: u32,
    pub text_padding: f32,
    pub billboard_mode: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub show_metadata: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_label_width: Option<f32>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct PhysicsSettingsDTO {
    pub auto_balance: bool,
    pub auto_balance_interval_ms: u32,
    pub auto_balance_config: AutoBalanceConfigDTO,
    pub spring_k: f32,
    pub bounds_size: f32,
    pub separation_radius: f32,
    pub damping: f32,
    pub enable_bounds: bool,
    pub enabled: bool,
    pub iterations: u32,
    pub max_velocity: f32,
    pub max_force: f32,
    pub repel_k: f32,
    pub mass_scale: f32,
    pub boundary_damping: f32,
    pub update_threshold: f32,
    pub dt: f32,
    pub temperature: f32,
    pub gravity: f32,
    pub stress_weight: f32,
    pub stress_alpha: f32,
    pub boundary_limit: f32,
    pub alignment_strength: f32,
    pub cluster_strength: f32,
    pub compute_mode: i32,
    pub rest_length: f32,
    pub repulsion_cutoff: f32,
    pub repulsion_softening_epsilon: f32,
    pub center_gravity_k: f32,
    pub grid_cell_size: f32,
    pub warmup_iterations: u32,
    pub cooling_rate: f32,
    pub boundary_extreme_multiplier: f32,
    pub boundary_extreme_force_multiplier: f32,
    pub boundary_velocity_damping: f32,
    pub min_distance: f32,
    pub max_repulsion_dist: f32,
    pub boundary_margin: f32,
    pub boundary_force_strength: f32,
    pub warmup_curve: String,
    pub zero_velocity_iterations: u32,
    pub clustering_algorithm: String,
    pub cluster_count: u32,
    pub clustering_resolution: f32,
    pub clustering_iterations: u32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct AutoBalanceConfigDTO {
    pub stability_variance_threshold: f32,
    pub stability_frame_count: u32,
    pub clustering_distance_threshold: f32,
    pub bouncing_node_percentage: f32,
    pub boundary_min_distance: f32,
    pub boundary_max_distance: f32,
    pub extreme_distance_threshold: f32,
    pub explosion_distance_threshold: f32,
    pub spreading_distance_threshold: f32,
    pub oscillation_detection_frames: usize,
    pub oscillation_change_threshold: f32,
    pub min_oscillation_changes: usize,
    pub grid_cell_size_min: f32,
    pub grid_cell_size_max: f32,
    pub repulsion_cutoff_min: f32,
    pub repulsion_cutoff_max: f32,
    pub repulsion_softening_min: f32,
    pub repulsion_softening_max: f32,
    pub center_gravity_min: f32,
    pub center_gravity_max: f32,
    pub spatial_hash_efficiency_threshold: f32,
    pub cluster_density_threshold: f32,
    pub numerical_instability_threshold: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct CameraSettingsDTO {
    pub fov: f32,
    pub near: f32,
    pub far: f32,
    pub position: PositionDTO,
    pub look_at: PositionDTO,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct PositionDTO {
    pub x: f32,
    pub y: f32,
    pub z: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct SpacePilotSettingsDTO {
    pub enabled: bool,
    pub mode: String,
    pub sensitivity: SensitivityDTO,
    pub smoothing: f32,
    pub deadzone: f32,
    pub button_functions: std::collections::HashMap<String, String>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct SensitivityDTO {
    pub translation: f32,
    pub rotation: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct SystemSettingsDTO {
    pub network: NetworkSettingsDTO,
    pub websocket: WebSocketSettingsDTO,
    pub security: SecuritySettingsDTO,
    pub debug: DebugSettingsDTO,
    pub persist_settings: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub custom_backend_url: Option<String>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct NetworkSettingsDTO {
    pub bind_address: String,
    pub domain: String,
    pub enable_http2: bool,
    pub enable_rate_limiting: bool,
    pub enable_tls: bool,
    pub max_request_size: usize,
    pub min_tls_version: String,
    pub port: u16,
    pub rate_limit_requests: u32,
    pub rate_limit_window: u32,
    pub tunnel_id: String,
    pub api_client_timeout: u64,
    pub enable_metrics: bool,
    pub max_concurrent_requests: u32,
    pub max_retries: u32,
    pub metrics_port: u16,
    pub retry_delay: u32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct WebSocketSettingsDTO {
    pub binary_chunk_size: usize,
    pub binary_update_rate: u32,
    pub min_update_rate: u32,
    pub max_update_rate: u32,
    pub motion_threshold: f32,
    pub motion_damping: f32,
    pub binary_message_version: u32,
    pub compression_enabled: bool,
    pub compression_threshold: usize,
    pub heartbeat_interval: u64,
    pub heartbeat_timeout: u64,
    pub max_connections: usize,
    pub max_message_size: usize,
    pub reconnect_attempts: u32,
    pub reconnect_delay: u64,
    pub update_rate: u32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct SecuritySettingsDTO {
    pub allowed_origins: Vec<String>,
    pub audit_log_path: String,
    pub cookie_httponly: bool,
    pub cookie_samesite: String,
    pub cookie_secure: bool,
    pub csrf_token_timeout: u32,
    pub enable_audit_logging: bool,
    pub enable_request_validation: bool,
    pub session_timeout: u32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct DebugSettingsDTO {
    pub enabled: bool,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct XRSettingsDTO {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub client_side_enable_xr: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub mode: Option<String>,
    pub room_scale: f32,
    pub space_type: String,
    pub quality: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub render_scale: Option<f32>,
    pub interaction_distance: f32,
    pub locomotion_method: String,
    pub teleport_ray_color: String,
    pub controller_ray_color: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub controller_model: Option<String>,
    pub enable_hand_tracking: bool,
    pub hand_mesh_enabled: bool,
    pub hand_mesh_color: String,
    pub hand_mesh_opacity: f32,
    pub hand_point_size: f32,
    pub hand_ray_enabled: bool,
    pub hand_ray_color: String,
    pub hand_ray_width: f32,
    pub gesture_smoothing: f32,
    pub enable_haptics: bool,
    pub haptic_intensity: f32,
    pub drag_threshold: f32,
    pub pinch_threshold: f32,
    pub rotation_threshold: f32,
    pub interaction_radius: f32,
    pub movement_speed: f32,
    pub dead_zone: f32,
    pub movement_axes: MovementAxesDTO,
    pub enable_light_estimation: bool,
    pub enable_plane_detection: bool,
    pub enable_scene_understanding: bool,
    pub plane_color: String,
    pub plane_opacity: f32,
    pub plane_detection_distance: f32,
    pub show_plane_overlay: bool,
    pub snap_to_floor: bool,
    pub enable_passthrough_portal: bool,
    pub passthrough_opacity: f32,
    pub passthrough_brightness: f32,
    pub passthrough_contrast: f32,
    pub portal_size: f32,
    pub portal_edge_color: String,
    pub portal_edge_width: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct MovementAxesDTO {
    pub horizontal: i32,
    pub vertical: i32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct AuthSettingsDTO {
    pub enabled: bool,
    pub provider: String,
    pub required: bool,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct RagFlowSettingsDTO {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub api_key: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub agent_id: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub api_base_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub timeout: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_retries: Option<u32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub chat_id: Option<String>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct PerplexitySettingsDTO {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub api_key: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub model: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub api_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_tokens: Option<u32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub temperature: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub top_p: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub presence_penalty: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub frequency_penalty: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub timeout: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub rate_limit: Option<u32>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct OpenAISettingsDTO {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub api_key: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub base_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub timeout: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub rate_limit: Option<u32>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct KokoroSettingsDTO {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub api_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub default_voice: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub default_format: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub default_speed: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub timeout: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub stream: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub return_timestamps: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub sample_rate: Option<u32>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct WhisperSettingsDTO {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub api_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub default_model: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub default_language: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub timeout: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub temperature: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub return_timestamps: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub vad_filter: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub word_timestamps: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub initial_prompt: Option<String>,
}

// Conversion functions between AppFullSettings and DTOs
impl From<&AppFullSettings> for SettingsResponseDTO {
    fn from(settings: &AppFullSettings) -> Self {
        Self {
            visualisation: (&settings.visualisation).into(),
            system: (&settings.system).into(),
            xr: (&settings.xr).into(),
            auth: (&settings.auth).into(),
            ragflow: settings.ragflow.as_ref().map(|r| r.into()),
            perplexity: settings.perplexity.as_ref().map(|p| p.into()),
            openai: settings.openai.as_ref().map(|o| o.into()),
            kokoro: settings.kokoro.as_ref().map(|k| k.into()),
            whisper: settings.whisper.as_ref().map(|w| w.into()),
        }
    }
}

// Implement all the necessary From conversions for nested structures
impl From<&crate::config::VisualisationSettings> for VisualisationSettingsDTO {
    fn from(settings: &crate::config::VisualisationSettings) -> Self {
        Self {
            rendering: (&settings.rendering).into(),
            animations: (&settings.animations).into(),
            glow: (&settings.glow).into(),
            hologram: (&settings.hologram).into(),
            graphs: (&settings.graphs).into(),
            camera: settings.camera.as_ref().map(|c| c.into()),
            space_pilot: settings.space_pilot.as_ref().map(|sp| sp.into()),
        }
    }
}

impl From<&crate::config::RenderingSettings> for RenderingSettingsDTO {
    fn from(settings: &crate::config::RenderingSettings) -> Self {
        
        let dev_config = crate::config::dev_config::rendering();
        let agent_colors = Some(AgentColorsDTO {
            coordinator: dev_config.agent_colors.coordinator.clone(),
            coder: dev_config.agent_colors.coder.clone(),
            architect: dev_config.agent_colors.architect.clone(),
            analyst: dev_config.agent_colors.analyst.clone(),
            tester: dev_config.agent_colors.tester.clone(),
            researcher: dev_config.agent_colors.researcher.clone(),
            reviewer: dev_config.agent_colors.reviewer.clone(),
            optimizer: dev_config.agent_colors.optimizer.clone(),
            documenter: dev_config.agent_colors.documenter.clone(),
            queen: "#FFD700".to_string(), 
            default: dev_config.agent_colors.default.clone(),
        });

        Self {
            ambient_light_intensity: settings.ambient_light_intensity,
            background_color: settings.background_color.clone(),
            directional_light_intensity: settings.directional_light_intensity,
            enable_ambient_occlusion: settings.enable_ambient_occlusion,
            enable_antialiasing: settings.enable_antialiasing,
            enable_shadows: settings.enable_shadows,
            environment_intensity: settings.environment_intensity,
            shadow_map_size: settings.shadow_map_size.clone(),
            shadow_bias: settings.shadow_bias,
            context: settings.context.clone(),
            agent_colors,
        }
    }
}

impl From<&crate::config::AnimationSettings> for AnimationSettingsDTO {
    fn from(settings: &crate::config::AnimationSettings) -> Self {
        Self {
            enable_motion_blur: settings.enable_motion_blur,
            enable_node_animations: settings.enable_node_animations,
            motion_blur_strength: settings.motion_blur_strength,
            selection_wave_enabled: settings.selection_wave_enabled,
            pulse_enabled: settings.pulse_enabled,
            pulse_speed: settings.pulse_speed,
            pulse_strength: settings.pulse_strength,
            wave_speed: settings.wave_speed,
        }
    }
}

impl From<&crate::config::GlowSettings> for GlowSettingsDTO {
    fn from(settings: &crate::config::GlowSettings) -> Self {
        Self {
            enabled: settings.enabled,
            intensity: settings.intensity,
            radius: settings.radius,
            threshold: settings.threshold,
            diffuse_strength: settings.diffuse_strength,
            atmospheric_density: settings.atmospheric_density,
            volumetric_intensity: settings.volumetric_intensity,
            base_color: settings.base_color.clone(),
            emission_color: settings.emission_color.clone(),
            opacity: settings.opacity,
            pulse_speed: settings.pulse_speed,
            flow_speed: settings.flow_speed,
            node_glow_strength: settings.node_glow_strength,
            edge_glow_strength: settings.edge_glow_strength,
            environment_glow_strength: settings.environment_glow_strength,
        }
    }
}

impl From<&crate::config::HologramSettings> for HologramSettingsDTO {
    fn from(settings: &crate::config::HologramSettings) -> Self {
        Self {
            ring_count: settings.ring_count,
            ring_color: settings.ring_color.clone(),
            ring_opacity: settings.ring_opacity,
            sphere_sizes: settings.sphere_sizes.clone(),
            ring_rotation_speed: settings.ring_rotation_speed,
            enable_buckminster: settings.enable_buckminster,
            buckminster_size: settings.buckminster_size,
            buckminster_opacity: settings.buckminster_opacity,
            enable_geodesic: settings.enable_geodesic,
            geodesic_size: settings.geodesic_size,
            geodesic_opacity: settings.geodesic_opacity,
            enable_triangle_sphere: settings.enable_triangle_sphere,
            triangle_sphere_size: settings.triangle_sphere_size,
            triangle_sphere_opacity: settings.triangle_sphere_opacity,
            global_rotation_speed: settings.global_rotation_speed,
        }
    }
}

impl From<&crate::config::GraphsSettings> for GraphsSettingsDTO {
    fn from(settings: &crate::config::GraphsSettings) -> Self {
        Self {
            logseq: (&settings.logseq).into(),
            visionflow: (&settings.visionflow).into(),
        }
    }
}

impl From<&crate::config::GraphSettings> for GraphSettingsDTO {
    fn from(settings: &crate::config::GraphSettings) -> Self {
        Self {
            nodes: (&settings.nodes).into(),
            edges: (&settings.edges).into(),
            labels: (&settings.labels).into(),
            physics: (&settings.physics).into(),
        }
    }
}

impl From<&crate::config::NodeSettings> for NodeSettingsDTO {
    fn from(settings: &crate::config::NodeSettings) -> Self {
        Self {
            base_color: settings.base_color.clone(),
            metalness: settings.metalness,
            opacity: settings.opacity,
            roughness: settings.roughness,
            node_size: settings.node_size,
            quality: settings.quality.clone(),
            enable_instancing: settings.enable_instancing,
            enable_hologram: settings.enable_hologram,
            enable_metadata_shape: settings.enable_metadata_shape,
            enable_metadata_visualisation: settings.enable_metadata_visualisation,
        }
    }
}

impl From<&crate::config::EdgeSettings> for EdgeSettingsDTO {
    fn from(settings: &crate::config::EdgeSettings) -> Self {
        Self {
            arrow_size: settings.arrow_size,
            base_width: settings.base_width,
            color: settings.color.clone(),
            enable_arrows: settings.enable_arrows,
            opacity: settings.opacity,
            width_range: settings.width_range.clone(),
            quality: settings.quality.clone(),
        }
    }
}

impl From<&crate::config::LabelSettings> for LabelSettingsDTO {
    fn from(settings: &crate::config::LabelSettings) -> Self {
        Self {
            desktop_font_size: settings.desktop_font_size,
            enable_labels: settings.enable_labels,
            text_color: settings.text_color.clone(),
            text_outline_color: settings.text_outline_color.clone(),
            text_outline_width: settings.text_outline_width,
            text_resolution: settings.text_resolution,
            text_padding: settings.text_padding,
            billboard_mode: settings.billboard_mode.clone(),
            show_metadata: settings.show_metadata,
            max_label_width: settings.max_label_width,
        }
    }
}

impl From<&crate::config::PhysicsSettings> for PhysicsSettingsDTO {
    fn from(settings: &crate::config::PhysicsSettings) -> Self {
        Self {
            auto_balance: settings.auto_balance,
            auto_balance_interval_ms: settings.auto_balance_interval_ms,
            auto_balance_config: (&settings.auto_balance_config).into(),
            spring_k: settings.spring_k,
            bounds_size: settings.bounds_size,
            separation_radius: settings.separation_radius,
            damping: settings.damping,
            enable_bounds: settings.enable_bounds,
            enabled: settings.enabled,
            iterations: settings.iterations,
            max_velocity: settings.max_velocity,
            max_force: settings.max_force,
            repel_k: settings.repel_k,
            mass_scale: settings.mass_scale,
            boundary_damping: settings.boundary_damping,
            update_threshold: settings.update_threshold,
            dt: settings.dt,
            temperature: settings.temperature,
            gravity: settings.gravity,
            stress_weight: settings.stress_weight,
            stress_alpha: settings.stress_alpha,
            boundary_limit: settings.boundary_limit,
            alignment_strength: settings.alignment_strength,
            cluster_strength: settings.cluster_strength,
            compute_mode: settings.compute_mode,
            rest_length: settings.rest_length,
            repulsion_cutoff: settings.repulsion_cutoff,
            repulsion_softening_epsilon: settings.repulsion_softening_epsilon,
            center_gravity_k: settings.center_gravity_k,
            grid_cell_size: settings.grid_cell_size,
            warmup_iterations: settings.warmup_iterations,
            cooling_rate: settings.cooling_rate,
            boundary_extreme_multiplier: settings.boundary_extreme_multiplier,
            boundary_extreme_force_multiplier: settings.boundary_extreme_force_multiplier,
            boundary_velocity_damping: settings.boundary_velocity_damping,
            min_distance: settings.min_distance,
            max_repulsion_dist: settings.max_repulsion_dist,
            boundary_margin: settings.boundary_margin,
            boundary_force_strength: settings.boundary_force_strength,
            warmup_curve: settings.warmup_curve.clone(),
            zero_velocity_iterations: settings.zero_velocity_iterations,
            clustering_algorithm: settings.clustering_algorithm.clone(),
            cluster_count: settings.cluster_count,
            clustering_resolution: settings.clustering_resolution,
            clustering_iterations: settings.clustering_iterations,
        }
    }
}

impl From<&crate::config::AutoBalanceConfig> for AutoBalanceConfigDTO {
    fn from(settings: &crate::config::AutoBalanceConfig) -> Self {
        Self {
            stability_variance_threshold: settings.stability_variance_threshold,
            stability_frame_count: settings.stability_frame_count,
            clustering_distance_threshold: settings.clustering_distance_threshold,
            bouncing_node_percentage: settings.bouncing_node_percentage,
            boundary_min_distance: settings.boundary_min_distance,
            boundary_max_distance: settings.boundary_max_distance,
            extreme_distance_threshold: settings.extreme_distance_threshold,
            explosion_distance_threshold: settings.explosion_distance_threshold,
            spreading_distance_threshold: settings.spreading_distance_threshold,
            oscillation_detection_frames: settings.oscillation_detection_frames,
            oscillation_change_threshold: settings.oscillation_change_threshold,
            min_oscillation_changes: settings.min_oscillation_changes,
            grid_cell_size_min: settings.grid_cell_size_min,
            grid_cell_size_max: settings.grid_cell_size_max,
            repulsion_cutoff_min: settings.repulsion_cutoff_min,
            repulsion_cutoff_max: settings.repulsion_cutoff_max,
            repulsion_softening_min: settings.repulsion_softening_min,
            repulsion_softening_max: settings.repulsion_softening_max,
            center_gravity_min: settings.center_gravity_min,
            center_gravity_max: settings.center_gravity_max,
            spatial_hash_efficiency_threshold: settings.spatial_hash_efficiency_threshold,
            cluster_density_threshold: settings.cluster_density_threshold,
            numerical_instability_threshold: settings.numerical_instability_threshold,
        }
    }
}

impl From<&crate::config::CameraSettings> for CameraSettingsDTO {
    fn from(settings: &crate::config::CameraSettings) -> Self {
        Self {
            fov: settings.fov,
            near: settings.near,
            far: settings.far,
            position: (&settings.position).into(),
            look_at: (&settings.look_at).into(),
        }
    }
}

impl From<&crate::config::Position> for PositionDTO {
    fn from(pos: &crate::config::Position) -> Self {
        Self {
            x: pos.x,
            y: pos.y,
            z: pos.z,
        }
    }
}

impl From<&crate::config::SpacePilotSettings> for SpacePilotSettingsDTO {
    fn from(settings: &crate::config::SpacePilotSettings) -> Self {
        Self {
            enabled: settings.enabled,
            mode: settings.mode.clone(),
            sensitivity: (&settings.sensitivity).into(),
            smoothing: settings.smoothing,
            deadzone: settings.deadzone,
            button_functions: settings.button_functions.clone(),
        }
    }
}

impl From<&crate::config::Sensitivity> for SensitivityDTO {
    fn from(sens: &crate::config::Sensitivity) -> Self {
        Self {
            translation: sens.translation,
            rotation: sens.rotation,
        }
    }
}

impl From<&crate::config::SystemSettings> for SystemSettingsDTO {
    fn from(settings: &crate::config::SystemSettings) -> Self {
        Self {
            network: (&settings.network).into(),
            websocket: (&settings.websocket).into(),
            security: (&settings.security).into(),
            debug: (&settings.debug).into(),
            persist_settings: settings.persist_settings,
            custom_backend_url: settings.custom_backend_url.clone(),
        }
    }
}

impl From<&crate::config::NetworkSettings> for NetworkSettingsDTO {
    fn from(settings: &crate::config::NetworkSettings) -> Self {
        Self {
            bind_address: settings.bind_address.clone(),
            domain: settings.domain.clone(),
            enable_http2: settings.enable_http2,
            enable_rate_limiting: settings.enable_rate_limiting,
            enable_tls: settings.enable_tls,
            max_request_size: settings.max_request_size,
            min_tls_version: settings.min_tls_version.clone(),
            port: settings.port,
            rate_limit_requests: settings.rate_limit_requests,
            rate_limit_window: settings.rate_limit_window,
            tunnel_id: settings.tunnel_id.clone(),
            api_client_timeout: settings.api_client_timeout,
            enable_metrics: settings.enable_metrics,
            max_concurrent_requests: settings.max_concurrent_requests,
            max_retries: settings.max_retries,
            metrics_port: settings.metrics_port,
            retry_delay: settings.retry_delay,
        }
    }
}

impl From<&crate::config::WebSocketSettings> for WebSocketSettingsDTO {
    fn from(settings: &crate::config::WebSocketSettings) -> Self {
        Self {
            binary_chunk_size: settings.binary_chunk_size,
            binary_update_rate: settings.binary_update_rate,
            min_update_rate: settings.min_update_rate,
            max_update_rate: settings.max_update_rate,
            motion_threshold: settings.motion_threshold,
            motion_damping: settings.motion_damping,
            binary_message_version: settings.binary_message_version,
            compression_enabled: settings.compression_enabled,
            compression_threshold: settings.compression_threshold,
            heartbeat_interval: settings.heartbeat_interval,
            heartbeat_timeout: settings.heartbeat_timeout,
            max_connections: settings.max_connections,
            max_message_size: settings.max_message_size,
            reconnect_attempts: settings.reconnect_attempts,
            reconnect_delay: settings.reconnect_delay,
            update_rate: settings.update_rate,
        }
    }
}

impl From<&crate::config::SecuritySettings> for SecuritySettingsDTO {
    fn from(settings: &crate::config::SecuritySettings) -> Self {
        Self {
            allowed_origins: settings.allowed_origins.clone(),
            audit_log_path: settings.audit_log_path.clone(),
            cookie_httponly: settings.cookie_httponly,
            cookie_samesite: settings.cookie_samesite.clone(),
            cookie_secure: settings.cookie_secure,
            csrf_token_timeout: settings.csrf_token_timeout,
            enable_audit_logging: settings.enable_audit_logging,
            enable_request_validation: settings.enable_request_validation,
            session_timeout: settings.session_timeout,
        }
    }
}

impl From<&crate::config::DebugSettings> for DebugSettingsDTO {
    fn from(settings: &crate::config::DebugSettings) -> Self {
        Self {
            enabled: settings.enabled,
        }
    }
}

impl From<&crate::config::XRSettings> for XRSettingsDTO {
    fn from(settings: &crate::config::XRSettings) -> Self {
        Self {
            enabled: settings.enabled,
            client_side_enable_xr: settings.client_side_enable_xr,
            mode: settings.mode.clone(),
            room_scale: settings.room_scale,
            space_type: settings.space_type.clone(),
            quality: settings.quality.clone(),
            render_scale: settings.render_scale,
            interaction_distance: settings.interaction_distance,
            locomotion_method: settings.locomotion_method.clone(),
            teleport_ray_color: settings.teleport_ray_color.clone(),
            controller_ray_color: settings.controller_ray_color.clone(),
            controller_model: settings.controller_model.clone(),
            enable_hand_tracking: settings.enable_hand_tracking,
            hand_mesh_enabled: settings.hand_mesh_enabled,
            hand_mesh_color: settings.hand_mesh_color.clone(),
            hand_mesh_opacity: settings.hand_mesh_opacity,
            hand_point_size: settings.hand_point_size,
            hand_ray_enabled: settings.hand_ray_enabled,
            hand_ray_color: settings.hand_ray_color.clone(),
            hand_ray_width: settings.hand_ray_width,
            gesture_smoothing: settings.gesture_smoothing,
            enable_haptics: settings.enable_haptics,
            haptic_intensity: settings.haptic_intensity,
            drag_threshold: settings.drag_threshold,
            pinch_threshold: settings.pinch_threshold,
            rotation_threshold: settings.rotation_threshold,
            interaction_radius: settings.interaction_radius,
            movement_speed: settings.movement_speed,
            dead_zone: settings.dead_zone,
            movement_axes: (&settings.movement_axes).into(),
            enable_light_estimation: settings.enable_light_estimation,
            enable_plane_detection: settings.enable_plane_detection,
            enable_scene_understanding: settings.enable_scene_understanding,
            plane_color: settings.plane_color.clone(),
            plane_opacity: settings.plane_opacity,
            plane_detection_distance: settings.plane_detection_distance,
            show_plane_overlay: settings.show_plane_overlay,
            snap_to_floor: settings.snap_to_floor,
            enable_passthrough_portal: settings.enable_passthrough_portal,
            passthrough_opacity: settings.passthrough_opacity,
            passthrough_brightness: settings.passthrough_brightness,
            passthrough_contrast: settings.passthrough_contrast,
            portal_size: settings.portal_size,
            portal_edge_color: settings.portal_edge_color.clone(),
            portal_edge_width: settings.portal_edge_width,
        }
    }
}

impl From<&crate::config::MovementAxes> for MovementAxesDTO {
    fn from(axes: &crate::config::MovementAxes) -> Self {
        Self {
            horizontal: axes.horizontal,
            vertical: axes.vertical,
        }
    }
}

impl From<&crate::config::AuthSettings> for AuthSettingsDTO {
    fn from(settings: &crate::config::AuthSettings) -> Self {
        Self {
            enabled: settings.enabled,
            provider: settings.provider.clone(),
            required: settings.required,
        }
    }
}

impl From<&crate::config::RagFlowSettings> for RagFlowSettingsDTO {
    fn from(settings: &crate::config::RagFlowSettings) -> Self {
        Self {
            api_key: settings.api_key.clone(),
            agent_id: settings.agent_id.clone(),
            api_base_url: settings.api_base_url.clone(),
            timeout: settings.timeout,
            max_retries: settings.max_retries,
            chat_id: settings.chat_id.clone(),
        }
    }
}

impl From<&crate::config::PerplexitySettings> for PerplexitySettingsDTO {
    fn from(settings: &crate::config::PerplexitySettings) -> Self {
        Self {
            api_key: settings.api_key.clone(),
            model: settings.model.clone(),
            api_url: settings.api_url.clone(),
            max_tokens: settings.max_tokens,
            temperature: settings.temperature,
            top_p: settings.top_p,
            presence_penalty: settings.presence_penalty,
            frequency_penalty: settings.frequency_penalty,
            timeout: settings.timeout,
            rate_limit: settings.rate_limit,
        }
    }
}

impl From<&crate::config::OpenAISettings> for OpenAISettingsDTO {
    fn from(settings: &crate::config::OpenAISettings) -> Self {
        Self {
            api_key: settings.api_key.clone(),
            base_url: settings.base_url.clone(),
            timeout: settings.timeout,
            rate_limit: settings.rate_limit,
        }
    }
}

impl From<&crate::config::KokoroSettings> for KokoroSettingsDTO {
    fn from(settings: &crate::config::KokoroSettings) -> Self {
        Self {
            api_url: settings.api_url.clone(),
            default_voice: settings.default_voice.clone(),
            default_format: settings.default_format.clone(),
            default_speed: settings.default_speed,
            timeout: settings.timeout,
            stream: settings.stream,
            return_timestamps: settings.return_timestamps,
            sample_rate: settings.sample_rate,
        }
    }
}

impl From<&crate::config::WhisperSettings> for WhisperSettingsDTO {
    fn from(settings: &crate::config::WhisperSettings) -> Self {
        Self {
            api_url: settings.api_url.clone(),
            default_model: settings.default_model.clone(),
            default_language: settings.default_language.clone(),
            timeout: settings.timeout,
            temperature: settings.temperature,
            return_timestamps: settings.return_timestamps,
            vad_filter: settings.vad_filter,
            word_timestamps: settings.word_timestamps,
            initial_prompt: settings.initial_prompt.clone(),
        }
    }
}

///
pub struct EnhancedSettingsHandler {
    validation_service: ValidationService,
    rate_limiter: Arc<RateLimiter>,
}

impl EnhancedSettingsHandler {
    pub fn new() -> Self {
        let config = EndpointRateLimits::settings_update();
        let rate_limiter = Arc::new(RateLimiter::new(config));

        Self {
            validation_service: ValidationService::new(),
            rate_limiter,
        }
    }

    
    pub async fn update_settings_enhanced(
        &self,
        req: HttpRequest,
        state: web::Data<AppState>,
        payload: web::Json<Value>,
    ) -> Result<HttpResponse, Error> {
        
        let request_id = req
            .headers()
            .get("X-Request-ID")
            .and_then(|v| v.to_str().ok())
            .unwrap_or(&Uuid::new_v4().to_string())
            .to_string();

        
        let pubkey = req
            .headers()
            .get("X-Nostr-Pubkey")
            .and_then(|v| v.to_str().ok());
        let has_token = req.headers().get("X-Nostr-Token").is_some();

        trace_info!(
            request_id = %request_id,
            user_pubkey = ?pubkey,
            authenticated = pubkey.is_some() && has_token,
            "Settings update request received"
        );

        let client_id = extract_client_id(&req);

        
        if !self.rate_limiter.is_allowed(&client_id) {
            warn!(
                "Rate limit exceeded for settings update from client: {}",
                client_id
            );
            return too_many_requests!("Too many settings update requests. Please wait before retrying.");
        }

        
        let payload_size = serde_json::to_vec(&*payload).unwrap_or_default().len();
        if payload_size > MAX_REQUEST_SIZE {
            error!("Settings update payload too large: {} bytes", payload_size);
            return payload_too_large!(format!("Payload size {} bytes exceeds limit of {} bytes", payload_size, MAX_REQUEST_SIZE));
        }

        

        
        let validated_payload = match self.validation_service.validate_settings_update(&payload) {
            Ok(sanitized) => sanitized,
            Err(validation_error) => {
                warn!(
                    "Settings validation failed for client {}: {}",
                    client_id, validation_error
                );
                return Ok(validation_error.to_http_response());
            }
        };

        

        
        let update = validated_payload;

        

        
        let mut app_settings = match state.settings_addr.send(GetSettings).await {
            Ok(Ok(s)) => s,
            Ok(Err(e)) => {
                error!("Failed to get current settings: {}", e);
                return error_json!("Failed to get current settings");
            }
            Err(e) => {
                error!("Settings actor error: {}", e);
                return service_unavailable!("Settings service unavailable");
            }
        };

        
        let mut modified_update = update.clone();
        let auto_balance_update = update
            .get("visualisation")
            .and_then(|v| v.get("graphs"))
            .and_then(|g| {
                if let Some(logseq) = g.get("logseq") {
                    if let Some(physics) = logseq.get("physics") {
                        if let Some(auto_balance) = physics.get("autoBalance") {
                            return Some(auto_balance.clone());
                        }
                    }
                }
                if let Some(visionflow) = g.get("visionflow") {
                    if let Some(physics) = visionflow.get("physics") {
                        if let Some(auto_balance) = physics.get("autoBalance") {
                            return Some(auto_balance.clone());
                        }
                    }
                }
                None
            });

        
        if let Some(ref auto_balance_value) = auto_balance_update {
            

            let vis_obj = modified_update
                .as_object_mut()
                .and_then(|o| {
                    o.entry("visualisation")
                        .or_insert_with(|| json!({}))
                        .as_object_mut()
                })
                .and_then(|v| {
                    v.entry("graphs")
                        .or_insert_with(|| json!({}))
                        .as_object_mut()
                });

            if let Some(graphs) = vis_obj {
                let logseq_physics = graphs
                    .entry("logseq")
                    .or_insert_with(|| json!({}))
                    .as_object_mut()
                    .and_then(|l| {
                        l.entry("physics")
                            .or_insert_with(|| json!({}))
                            .as_object_mut()
                    });
                if let Some(physics) = logseq_physics {
                    physics.insert("autoBalance".to_string(), auto_balance_value.clone());
                }

                let visionflow_physics = graphs
                    .entry("visionflow")
                    .or_insert_with(|| json!({}))
                    .as_object_mut()
                    .and_then(|v| {
                        v.entry("physics")
                            .or_insert_with(|| json!({}))
                            .as_object_mut()
                    });
                if let Some(physics) = visionflow_physics {
                    physics.insert("autoBalance".to_string(), auto_balance_value.clone());
                }
            }
        }

        
        if let Err(e) = app_settings.merge_update(modified_update.clone()) {
            error!("Failed to merge settings: {}", e);
            if crate::utils::logging::is_debug_enabled() {
                error!(
                    "Update payload that caused error: {}",
                    serde_json::to_string_pretty(&modified_update)
                        .unwrap_or_else(|_| "Could not serialize".to_string())
                );
            }
            return error_json!("Failed to merge settings: {}", e);
        }

        
        let _updated_graphs = if auto_balance_update.is_some() {
            vec!["logseq", "visionflow"]
        } else {
            
            let _physics_updates = extract_physics_updates(&modified_update);
            modified_update
                .get("visualisation")
                .and_then(|v| v.get("graphs"))
                .and_then(|g| g.as_object())
                .map(|graphs| {
                    let mut updated = Vec::new();
                    if graphs.contains_key("logseq") {
                        updated.push("logseq");
                    }
                    if graphs.contains_key("visionflow") {
                        updated.push("visionflow");
                    }
                    updated
                })
                .unwrap_or_default()
        };

        let auto_balance_active = app_settings
            .visualisation
            .graphs
            .logseq
            .physics
            .auto_balance
            || app_settings
                .visualisation
                .graphs
                .visionflow
                .physics
                .auto_balance;

        
        match state
            .settings_addr
            .send(UpdateSettings {
                settings: app_settings.clone(),
            })
            .await
        {
            Ok(Ok(())) => {
                

                let is_auto_balance_change = auto_balance_update.is_some();

                if is_auto_balance_change || !auto_balance_active {
                    
                    
                    propagate_physics_to_gpu(&state, &app_settings, "logseq").await;
                    if is_auto_balance_change {
                        
                    }
                } else {
                    
                }

                let response_dto: SettingsResponseDTO = (&app_settings).into();

                ok_json!(json!({
                    "status": "success",
                    "message": "Settings updated successfully",
                    "settings": response_dto,
                    "client_id": client_id,
                    "timestamp": chrono::Utc::now().to_rfc3339()
                }))
            }
            Ok(Err(e)) => {
                error!("Failed to save settings: {}", e);
                error_json!("Failed to save settings: {}", e)
            }
            Err(e) => {
                error!("Settings actor error: {}", e);
                service_unavailable!("Settings service unavailable")
            }
        }
    }

    
    pub async fn get_settings_enhanced(
        &self,
        req: HttpRequest,
        state: web::Data<AppState>,
    ) -> Result<HttpResponse, Error> {
        
        let request_id = req
            .headers()
            .get("X-Request-ID")
            .and_then(|v| v.to_str().ok())
            .unwrap_or(&Uuid::new_v4().to_string())
            .to_string();

        
        let pubkey = req
            .headers()
            .get("X-Nostr-Pubkey")
            .and_then(|v| v.to_str().ok());
        let has_token = req.headers().get("X-Nostr-Token").is_some();

        trace_info!(
            request_id = %request_id,
            user_pubkey = ?pubkey,
            authenticated = pubkey.is_some() && has_token,
            "Settings GET request received"
        );

        let client_id = extract_client_id(&req);

        
        let get_rate_limiter = Arc::new(RateLimiter::new(RateLimitConfig {
            requests_per_minute: 120,
            burst_size: 20,
            ..Default::default()
        }));

        if !get_rate_limiter.is_allowed(&client_id) {
            return too_many_requests!("Too many get settings requests");
        }

        

        let app_settings = match state.settings_addr.send(GetSettings).await {
            Ok(Ok(settings)) => settings,
            Ok(Err(e)) => {
                error!("Failed to get settings: {}", e);
                return error_json!("Failed to retrieve settings");
            }
            Err(e) => {
                error!("Settings actor error: {}", e);
                return service_unavailable!("Settings service unavailable");
            }
        };

        let response_dto: SettingsResponseDTO = (&app_settings).into();

        ok_json!(json!({
            "status": "success",
            "settings": response_dto,
            "validation_info": {
                "input_sanitization": "enabled",
                "rate_limiting": "active",
                "schema_validation": "enforced"
            },
            "client_id": client_id,
            "timestamp": chrono::Utc::now().to_rfc3339()
        }))
    }

    
    pub async fn reset_settings_enhanced(
        &self,
        req: HttpRequest,
        state: web::Data<AppState>,
    ) -> Result<HttpResponse, Error> {
        let client_id = extract_client_id(&req);

        
        let reset_rate_limiter = Arc::new(RateLimiter::new(RateLimitConfig {
            requests_per_minute: 10,
            burst_size: 2,
            ..Default::default()
        }));

        if !reset_rate_limiter.is_allowed(&client_id) {
            warn!(
                "Rate limit exceeded for settings reset from client: {}",
                client_id
            );
            return too_many_requests!("Too many reset requests. This is a destructive operation with strict limits.");
        }

        

        
        let default_settings = match AppFullSettings::new() {
            Ok(settings) => settings,
            Err(e) => {
                error!("Failed to load default settings: {}", e);
                return error_json!("Failed to load default settings");
            }
        };

        
        match state
            .settings_addr
            .send(UpdateSettings {
                settings: default_settings.clone(),
            })
            .await
        {
            Ok(Ok(())) => {
                info!("Settings reset to defaults for client: {}", client_id);

                let response_dto: SettingsResponseDTO = (&default_settings).into();

                ok_json!(json!({
                    "status": "success",
                    "message": "Settings reset to defaults successfully",
                    "settings": response_dto,
                    "client_id": client_id,
                    "timestamp": chrono::Utc::now().to_rfc3339()
                }))
            }
            Ok(Err(e)) => {
                error!("Failed to reset settings: {}", e);
                error_json!("Failed to reset settings: {}", e)
            }
            Err(e) => {
                error!("Settings actor error during reset: {}", e);
                service_unavailable!("Settings service unavailable during reset")
            }
        }
    }

    
    pub async fn settings_health(
        &self,
        req: HttpRequest,
        state: web::Data<AppState>,
    ) -> Result<HttpResponse, Error> {
        let request_id = req
            .headers()
            .get("X-Request-ID")
            .and_then(|v| v.to_str().ok())
            .unwrap_or(&Uuid::new_v4().to_string())
            .to_string();

        trace_info!(
            request_id = %request_id,
            "Settings health check requested"
        );

        
        let (cache_entries, cache_ages) =
            crate::models::user_settings::UserSettings::get_cache_stats();

        
        let cache_hit_rate = if cache_entries > 0 {
            
            0.85 
        } else {
            0.0
        };

        let oldest_cache_entry = cache_ages
            .iter()
            .map(|(_, age)| age.as_secs())
            .max()
            .unwrap_or(0);

        let avg_cache_age = if !cache_ages.is_empty() {
            cache_ages.iter().map(|(_, age)| age.as_secs()).sum::<u64>() / cache_ages.len() as u64
        } else {
            0
        };

        
        let settings_healthy = match state.settings_addr.send(GetSettings).await {
            Ok(Ok(_)) => true,
            _ => false,
        };

        ok_json!(json!({
            "status": if settings_healthy { "healthy" } else { "degraded" },
            "request_id": request_id,
            "cache": {
                "entries": cache_entries,
                "hit_rate": cache_hit_rate,
                "oldest_entry_secs": oldest_cache_entry,
                "avg_age_secs": avg_cache_age,
                "ttl_secs": 600, 
            },
            "settings_actor": {
                "responsive": settings_healthy,
            },
            "rate_limiting": {
                "stats": self.rate_limiter.get_stats(),
            },
            "timestamp": chrono::Utc::now().to_rfc3339()
        }))
    }

    
    pub async fn get_validation_stats(&self, req: HttpRequest) -> Result<HttpResponse, Error> {
        let client_id = extract_client_id(&req);
        debug!("Validation stats request from client: {}", client_id);

        let stats = self.rate_limiter.get_stats();

        ok_json!(json!({
            "validation_service": "active",
            "rate_limiting": {
                "total_clients": stats.total_clients,
                "banned_clients": stats.banned_clients,
                "active_clients": stats.active_clients,
                "config": stats.config
            },
            "security_features": [
                "comprehensive_input_validation",
                "xss_prevention",
                "sql_injection_prevention",
                "path_traversal_prevention",
                "malicious_content_detection",
                "rate_limiting",
                "request_size_validation"
            ],
            "endpoints_protected": [
                "/settings",
                "/settings/reset",
                "/physics/update",
                "/physics/compute-mode",
                "/clustering/algorithm",
                "/constraints/update",
                "/stress/optimization"
            ],
            "timestamp": chrono::Utc::now().to_rfc3339()
        }))
    }

    
    async fn propagate_physics_updates(
        &self,
        state: &web::Data<AppState>,
        settings: &AppFullSettings,
        update: &Value,
    ) {
        
        let has_physics_update = update
            .get("visualisation")
            .and_then(|v| v.get("graphs"))
            .map(|g| {
                g.as_object()
                    .map(|obj| obj.values().any(|graph| graph.get("physics").is_some()))
                    .unwrap_or(false)
            })
            .unwrap_or(false);

        if has_physics_update {
            info!("Propagating physics updates to GPU actors");

            
            
            let graph_name = "logseq";
            let physics = settings.get_physics(graph_name);
            let sim_params = crate::models::simulation_params::SimulationParams::from(physics);

            if let Some(gpu_addr) = &state.gpu_compute_addr {
                if let Err(e) = gpu_addr
                    .send(UpdateSimulationParams { params: sim_params })
                    .await
                {
                    error!(
                        "Failed to update GPU simulation params for {}: {}",
                        graph_name, e
                    );
                } else {
                    info!(
                        "GPU simulation params updated for {} (knowledge graph)",
                        graph_name
                    );
                }
            }
        }
    }
}

impl Default for EnhancedSettingsHandler {
    fn default() -> Self {
        Self::new()
    }
}

///
pub fn config(cfg: &mut web::ServiceConfig) {
    let handler = web::Data::new(EnhancedSettingsHandler::new());

    cfg.app_data(handler.clone())
        .service(
            web::scope("/settings")
                
                .route("/path", web::get().to(get_setting_by_path))
                .route("/path", web::put().to(update_setting_by_path))
                
                
                
                .route("/schema", web::get().to(get_settings_schema))
                .route("/current", web::get().to(get_current_settings))
                
                .route("", web::get().to(get_settings))
                .route("", web::post().to(update_settings))
                .route("/reset", web::post().to(reset_settings))
                .route("/save", web::post().to(save_settings))
                .route(
                    "/validation/stats",
                    web::get().to(
                        |req, handler: web::Data<EnhancedSettingsHandler>| async move {
                            handler.get_validation_stats(req).await
                        },
                    ),
                ),
        )
        .service(
            web::scope("/api/physics").route("/compute-mode", web::post().to(update_compute_mode)),
        )
        .service(
            web::scope("/api/clustering")
                .route("/algorithm", web::post().to(update_clustering_algorithm)),
        )
        .service(
            web::scope("/api/constraints").route("/update", web::post().to(update_constraints)),
        )
        .service(
            web::scope("/api/analytics").route("/clusters", web::get().to(get_cluster_analytics)),
        )
        .service(
            web::scope("/api/stress")
                .route("/optimization", web::post().to(update_stress_optimization)),
        );
}

///
async fn get_setting_by_path(
    req: HttpRequest,
    state: web::Data<AppState>,
) -> Result<HttpResponse, Error> {
    let path = req
        .query_string()
        .split('&')
        .find(|param| param.starts_with("path="))
        .and_then(|p| p.strip_prefix("path="))
        .map(|p| {
            urlencoding::decode(p)
                .unwrap_or(Cow::Borrowed(p))
                .to_string()
        })
        .ok_or_else(|| actix_web::error::ErrorBadRequest("Missing 'path' query parameter"))?;

    let app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(settings)) => settings,
        Ok(Err(e)) => {
            error!("Failed to get settings: {}", e);
            return error_json!("Failed to retrieve settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    match app_settings.get_json_by_path(&path) {
        Ok(value_json) => ok_json!(json!({
            "success": true,
            "path": path,
            "value": value_json
        })),
        Err(e) => {
            warn!("Path not found '{}': {}", path, e);
            not_found!("Path not found", e)
        }
    }
}

///
async fn update_setting_by_path(
    _req: HttpRequest,
    state: web::Data<AppState>,
    payload: web::Json<Value>,
) -> Result<HttpResponse, Error> {
    let update = payload.into_inner();
    let path = update
        .get("path")
        .and_then(|p| p.as_str())
        .ok_or_else(|| actix_web::error::ErrorBadRequest("Missing 'path' in request body"))?
        .to_string();
    let value = update
        .get("value")
        .ok_or_else(|| actix_web::error::ErrorBadRequest("Missing 'value' in request body"))?
        .clone();

    let mut app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(settings)) => settings,
        Ok(Err(e)) => {
            error!("Failed to get settings: {}", e);
            return error_json!("Failed to retrieve settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    let previous_value = app_settings.get_json_by_path(&path).ok();

    match app_settings.set_json_by_path(&path, value.clone()) {
        Ok(()) => {
            match state
                .settings_addr
                .send(UpdateSettings {
                    settings: app_settings.clone(),
                })
                .await
            {
                Ok(Ok(())) => {
                    info!("Updated setting at path: {}", path);

                    
                    if path.contains(".physics.")
                        || path.contains(".graphs.logseq.")
                        || path.contains(".graphs.visionflow.")
                    {
                        info!("Physics setting changed, propagating to GPU actors");

                        
                        let graph_name = if path.contains(".graphs.logseq.") {
                            "logseq"
                        } else if path.contains(".graphs.visionflow.") {
                            "visionflow"
                        } else {
                            
                            "logseq"
                        };

                        
                        propagate_physics_to_gpu(&state, &app_settings, graph_name).await;
                    }

                    ok_json!(json!({
                        "success": true,
                        "path": path,
                        "value": update.get("value").expect("Missing required key: value"),
                        "previousValue": previous_value
                    }))
                }
                Ok(Err(e)) => {
                    error!("Failed to save settings: {}", e);
                    Ok(HttpResponse::InternalServerError().json(json!({
                        "error": format!("Failed to save settings: {}", e),
                        "path": path
                    })))
                }
                Err(e) => {
                    error!("Settings actor error: {}", e);
                    service_unavailable!("Settings service unavailable")
                }
            }
        }
        Err(e) => {
            warn!("Failed to update path '{}': {}", path, e);
            bad_request!("Invalid path or value", e)
        }
    }
}

///
async fn batch_get_settings(
    state: web::Data<AppState>,
    payload: web::Json<Value>,
) -> Result<HttpResponse, Error> {
    let paths = payload
        .get("paths")
        .and_then(|p| p.as_array())
        .ok_or_else(|| actix_web::error::ErrorBadRequest("Missing 'paths' array"))?
        .iter()
        .map(|p| p.as_str().unwrap_or("").to_string())
        .collect::<Vec<String>>();

    if paths.is_empty() {
        return bad_request!("Paths array cannot be empty");
    }

    let app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(settings)) => settings,
        Ok(Err(e)) => {
            error!("Failed to get settings: {}", e);
            return error_json!("Failed to retrieve settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    let results: Vec<Value> = paths
        .iter()
        .map(|path| match app_settings.get_json_by_path(path) {
            Ok(value_json) => {
                json!({
                    "path": path,
                    "value": value_json,
                    "success": true
                })
            }
            Err(e) => {
                warn!("Path not found '{}': {}", path, e);
                json!({
                    "path": path,
                    "success": false,
                    "error": "Path not found",
                    "message": e
                })
            }
        })
        .collect();

    ok_json!(json!({
        "success": true,
        "message": format!("Successfully processed {} paths", results.len()),
        "values": results
    }))
}

///
async fn batch_update_settings(
    state: web::Data<AppState>,
    payload: web::Json<Value>,
) -> Result<HttpResponse, Error> {
    
    info!("Batch update request received: {:?}", payload);

    let updates = payload
        .get("updates")
        .and_then(|u| u.as_array())
        .ok_or_else(|| {
            error!(
                "Batch update failed: Missing 'updates' array in payload: {:?}",
                payload
            );
            actix_web::error::ErrorBadRequest("Missing 'updates' array")
        })?;

    if updates.is_empty() {
        error!("Batch update failed: Empty updates array");
        return bad_request!("Updates array cannot be empty");
    }

    info!("Processing {} batch updates", updates.len());

    let mut app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(settings)) => settings,
        Ok(Err(e)) => {
            error!("Failed to get settings: {}", e);
            return error_json!("Failed to retrieve settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    let mut results = Vec::new();
    let mut success_count = 0;

    for update in updates {
        let path = update.get("path").and_then(|p| p.as_str()).unwrap_or("");
        let value = update.get("value").unwrap_or(&Value::Null).clone();

        info!(
            "Processing batch update: path='{}', value={:?}",
            path, value
        );

        let previous_value = app_settings.get_json_by_path(path).ok();

        match app_settings.set_json_by_path(path, value.clone()) {
            Ok(()) => {
                success_count += 1;
                info!(
                    "Successfully updated path '{}' with value {:?}",
                    path, value
                );
                results.push(json!({
                    "path": path,
                    "success": true,
                    "value": update.get("value").expect("Missing required key: value"),
                    "previousValue": previous_value
                }));
            }
            Err(e) => {
                
                error!(
                    "Failed to update path '{}' with value {:?}: {}",
                    path, value, e
                );

                
                let error_detail = if e.contains("does not exist") {
                    format!("Path '{}' does not exist in settings structure", path)
                } else if e.contains("Type mismatch") {
                    format!("Type mismatch: {}", e)
                } else if e.contains("not found") {
                    format!("Field not found: {}", e)
                } else {
                    e.clone()
                };

                results.push(json!({
                    "path": path,
                    "success": false,
                    "error": error_detail,
                    "message": e,
                    "providedValue": value,
                    "expectedType": previous_value.as_ref().map(|v| value_type_name(v))
                }));
            }
        }
    }

    
    if success_count > 0 {
        match state
            .settings_addr
            .send(UpdateSettings {
                settings: app_settings.clone(),
            })
            .await
        {
            Ok(Ok(())) => {
                info!("Batch updated {} settings successfully", success_count);

                
                let mut physics_updated = false;
                for update in updates {
                    let path = update.get("path").and_then(|p| p.as_str()).unwrap_or("");
                    if path.contains(".physics.")
                        || path.contains(".graphs.logseq.")
                        || path.contains(".graphs.visionflow.")
                    {
                        physics_updated = true;
                        break;
                    }
                }

                if physics_updated {
                    info!("Physics settings changed in batch update, propagating to GPU actors");
                    
                    propagate_physics_to_gpu(&state, &app_settings, "logseq").await;
                    
                    
                }
            }
            Ok(Err(e)) => {
                error!("Failed to save batch settings: {}", e);
                return Ok(HttpResponse::InternalServerError().json(json!({
                    "success": false,
                    "error": format!("Failed to save settings: {}", e),
                    "results": results
                })));
            }
            Err(e) => {
                error!("Settings actor error: {}", e);
                return service_unavailable!("Settings service unavailable");
            }
        }
    }

    ok_json!(json!({
        "success": true,
        "message": format!("Successfully updated {} out of {} settings", success_count, updates.len()),
        "results": results
    }))
}

///
async fn get_settings_schema(
    req: HttpRequest,
    _state: web::Data<AppState>,
) -> Result<HttpResponse, Error> {
    let path = req
        .query_string()
        .split('&')
        .find(|param| param.starts_with("path="))
        .and_then(|p| p.strip_prefix("path="))
        .map(|p| {
            urlencoding::decode(p)
                .unwrap_or(Cow::Borrowed(p))
                .to_string()
        })
        .unwrap_or_default();

    
    
    let schema = json!({
        "type": "object",
        "properties": {
            "damping": { "type": "number", "description": "Physics damping factor (0.0-1.0)" },
            "gravity": { "type": "number", "description": "Physics gravity strength" },
            
        },
        "path": path
    });

    ok_json!(json!({
        "success": true,
        "path": path,
        "schema": schema
    }))
}

///
async fn get_settings(
    _req: HttpRequest,
    state: web::Data<AppState>,
) -> Result<HttpResponse, Error> {
    let app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(settings)) => settings,
        Ok(Err(e)) => {
            error!("Failed to get settings: {}", e);
            return error_json!("Failed to retrieve settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    
    let response_dto: SettingsResponseDTO = (&app_settings).into();

    ok_json!(response_dto)
}

///
async fn get_current_settings(
    _req: HttpRequest,
    state: web::Data<AppState>,
) -> Result<HttpResponse, Error> {
    let app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(settings)) => settings,
        Ok(Err(e)) => {
            error!("Failed to get settings: {}", e);
            return error_json!("Failed to retrieve settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    
    let response_dto: SettingsResponseDTO = (&app_settings).into();

    
    ok_json!(json!({
        "settings": response_dto,
        "version": app_settings.version,
        "timestamp": std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs()
    }))
}

///
async fn update_settings(
    _req: HttpRequest,
    state: web::Data<AppState>,
    payload: web::Json<Value>,
) -> Result<HttpResponse, Error> {
    let mut update = payload.into_inner();

    
    convert_to_snake_case_recursive(&mut update);

    debug!("Settings update received: {:?}", update);

    
    if let Err(e) = validate_settings_update(&update) {
        error!("Settings validation failed: {}", e);
        error!(
            "Failed update payload: {}",
            serde_json::to_string_pretty(&update).unwrap_or_default()
        );
        return bad_request!("Invalid settings: {}", e);
    }

    
    let mut app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(s)) => s,
        Ok(Err(e)) => {
            error!("Failed to get current settings: {}", e);
            return error_json!("Failed to get current settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    
    if crate::utils::logging::is_debug_enabled() {
        debug!(
            "Settings update payload (before merge): {}",
            serde_json::to_string_pretty(&update)
                .unwrap_or_else(|_| "Could not serialize".to_string())
        );
    }

    
    
    let mut modified_update = update.clone();
    let auto_balance_update = update
        .get("visualisation")
        .and_then(|v| v.get("graphs"))
        .and_then(|g| {
            
            if let Some(logseq) = g.get("logseq") {
                if let Some(physics) = logseq.get("physics") {
                    if let Some(auto_balance) = physics.get("autoBalance") {
                        return Some(auto_balance.clone());
                    }
                }
            }
            
            if let Some(visionflow) = g.get("visionflow") {
                if let Some(physics) = visionflow.get("physics") {
                    if let Some(auto_balance) = physics.get("autoBalance") {
                        return Some(auto_balance.clone());
                    }
                }
            }
            None
        });

    
    if let Some(ref auto_balance_value) = auto_balance_update {
        info!(
            "Synchronizing auto_balance setting across both graphs: {}",
            auto_balance_value
        );

        
        let vis_obj = modified_update
            .as_object_mut()
            .and_then(|o| {
                o.entry("visualisation")
                    .or_insert_with(|| json!({}))
                    .as_object_mut()
            })
            .and_then(|v| {
                v.entry("graphs")
                    .or_insert_with(|| json!({}))
                    .as_object_mut()
            });

        if let Some(graphs) = vis_obj {
            
            let logseq_physics = graphs
                .entry("logseq")
                .or_insert_with(|| json!({}))
                .as_object_mut()
                .and_then(|l| {
                    l.entry("physics")
                        .or_insert_with(|| json!({}))
                        .as_object_mut()
                });
            if let Some(physics) = logseq_physics {
                physics.insert("autoBalance".to_string(), auto_balance_value.clone());
            }

            
            let visionflow_physics = graphs
                .entry("visionflow")
                .or_insert_with(|| json!({}))
                .as_object_mut()
                .and_then(|v| {
                    v.entry("physics")
                        .or_insert_with(|| json!({}))
                        .as_object_mut()
                });
            if let Some(physics) = visionflow_physics {
                physics.insert("autoBalance".to_string(), auto_balance_value.clone());
            }
        }
    }

    
    if let Err(e) = app_settings.merge_update(modified_update.clone()) {
        error!("Failed to merge settings: {}", e);
        if crate::utils::logging::is_debug_enabled() {
            error!(
                "Update payload that caused error: {}",
                serde_json::to_string_pretty(&modified_update)
                    .unwrap_or_else(|_| "Could not serialize".to_string())
            );
        }
        return error_json!("Failed to merge settings: {}", e);
    }

    
    
    let _updated_graphs = if auto_balance_update.is_some() {
        
        let _physics_updates = extract_physics_updates(&update);
        vec!["logseq", "visionflow"]
    } else {
        modified_update
            .get("visualisation")
            .and_then(|v| v.get("graphs"))
            .and_then(|g| g.as_object())
            .map(|graphs| {
                let mut updated = Vec::new();
                if graphs.contains_key("logseq") {
                    updated.push("logseq");
                }
                if graphs.contains_key("visionflow") {
                    updated.push("visionflow");
                }
                updated
            })
            .unwrap_or_default()
    };

    
    
    let auto_balance_active = app_settings
        .visualisation
        .graphs
        .logseq
        .physics
        .auto_balance
        || app_settings
            .visualisation
            .graphs
            .visionflow
            .physics
            .auto_balance;

    
    match state
        .settings_addr
        .send(UpdateSettings {
            settings: app_settings.clone(),
        })
        .await
    {
        Ok(Ok(())) => {
            info!("Settings updated successfully");

            
            
            let is_auto_balance_change = auto_balance_update.is_some();

            
            
            
            
            if is_auto_balance_change || !auto_balance_active {
                
                
                propagate_physics_to_gpu(&state, &app_settings, "logseq").await;
                if is_auto_balance_change {
                    info!("[AUTO-BALANCE] Propagating auto_balance setting change to GPU (logseq only)");
                }
            } else {
                info!("[AUTO-BALANCE] Skipping physics propagation to GPU - auto-balance is active and not changing");
            }

            
            let response_dto: SettingsResponseDTO = (&app_settings).into();

            ok_json!(response_dto)
        }
        Ok(Err(e)) => {
            error!("Failed to save settings: {}", e);
            error_json!("Failed to save settings: {}", e)
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            service_unavailable!("Settings service unavailable")
        }
    }
}

///
async fn reset_settings(
    _req: HttpRequest,
    state: web::Data<AppState>,
) -> Result<HttpResponse, Error> {
    
    let default_settings = match AppFullSettings::new() {
        Ok(settings) => settings,
        Err(e) => {
            error!("Failed to load default settings: {}", e);
            return error_json!("Failed to load default settings");
        }
    };

    
    match state
        .settings_addr
        .send(UpdateSettings {
            settings: default_settings.clone(),
        })
        .await
    {
        Ok(Ok(())) => {
            info!("Settings reset to defaults");

            
            let response_dto: SettingsResponseDTO = (&default_settings).into();

            ok_json!(response_dto)
        }
        Ok(Err(e)) => {
            error!("Failed to reset settings: {}", e);
            error_json!("Failed to reset settings: {}", e)
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            service_unavailable!("Settings service unavailable")
        }
    }
}

///
async fn save_settings(
    _req: HttpRequest,
    state: web::Data<AppState>,
    payload: Option<web::Json<Value>>,
) -> Result<HttpResponse, Error> {
    
    let mut app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(s)) => s,
        Ok(Err(e)) => {
            error!("Failed to get current settings: {}", e);
            return error_json!("Failed to get current settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    
    if let Some(update) = payload {
        let update_value = update.into_inner();

        
        if let Err(e) = validate_settings_update(&update_value) {
            error!("Settings validation failed: {}", e);
            return bad_request!("Invalid settings: {}", e);
        }

        
        if let Err(e) = app_settings.merge_update(update_value) {
            error!("Failed to merge settings update: {}", e);
            return bad_request!("Failed to merge settings: {}", e);
        }
    }

    
    if !app_settings.system.persist_settings {
        return bad_request!("Settings persistence is disabled. Enable 'system.persist_settings' to save settings.");
    }

    
    match app_settings.save() {
        Ok(()) => {
            info!("Settings successfully saved to file");

            
            match state
                .settings_addr
                .send(UpdateSettings {
                    settings: app_settings.clone(),
                })
                .await
            {
                Ok(Ok(())) => {
                    let response_dto: SettingsResponseDTO = (&app_settings).into();
                    ok_json!(json!({
                        "message": "Settings saved successfully",
                        "settings": response_dto
                    }))
                }
                Ok(Err(e)) => {
                    error!("Failed to update settings in actor after save: {}", e);
                    error_json!("Settings saved to file but failed to update in memory")
                }
                Err(e) => {
                    error!("Settings actor communication error: {}", e);
                    service_unavailable!("Settings saved to file but service is unavailable")
                }
            }
        }
        Err(e) => {
            error!("Failed to save settings to file: {}", e);
            error_json!("Failed to save settings to file")
        }
    }
}

///
fn validate_settings_update(update: &Value) -> Result<(), String> {
    
    if let Some(vis) = update.get("visualisation") {
        if let Some(graphs) = vis.get("graphs") {
            
            for (graph_name, graph_settings) in
                graphs.as_object().ok_or("graphs must be an object")?.iter()
            {
                if graph_name != "logseq" && graph_name != "visionflow" {
                    return Err(format!("Invalid graph name: {}", graph_name));
                }

                
                if let Some(physics) = graph_settings.get("physics") {
                    validate_physics_settings(physics)?;
                }

                
                if let Some(nodes) = graph_settings.get("nodes") {
                    validate_node_settings(nodes)?;
                }
            }
        }

        
        if let Some(rendering) = vis.get("rendering") {
            validate_rendering_settings(rendering)?;
        }

        
        if let Some(hologram) = vis.get("hologram") {
            validate_hologram_settings(hologram)?;
        }
    }

    
    if let Some(xr) = update.get("xr") {
        validate_xr_settings(xr)?;
    }

    
    if let Some(system) = update.get("system") {
        validate_system_settings(system)?;
    }

    Ok(())
}

fn validate_physics_settings(physics: &Value) -> Result<(), String> {
    
    validate_physics_settings_complete(physics)?;

    
    if let Some(obj) = physics.as_object() {
        debug!(
            "Physics settings fields received: {:?}",
            obj.keys().collect::<Vec<_>>()
        );
    }

    
    if let Some(iterations) = physics.get("iterations") {
        let val = iterations
            .as_f64()
            .map(|f| f.round() as u64)
            .or_else(|| iterations.as_u64())
            .ok_or("iterations must be a positive number")?;
        if val == 0 || val > 1000 {
            return Err("iterations must be between 1 and 1000".to_string());
        }
    }

    
    if let Some(auto_balance_interval) = physics.get("autoBalanceIntervalMs") {
        let val = auto_balance_interval
            .as_u64()
            .or_else(|| auto_balance_interval.as_f64().map(|f| f.round() as u64))
            .ok_or("autoBalanceIntervalMs must be a positive integer")?;
        if val < 10 || val > 60000 {
            return Err("autoBalanceIntervalMs must be between 10 and 60000 ms".to_string());
        }
    }

    
    if let Some(boundary_limit) = physics.get("boundaryLimit") {
        let val = boundary_limit
            .as_f64()
            .ok_or("boundaryLimit must be a number")?;
        if val < 0.1 || val > 100000.0 {
            return Err("boundaryLimit must be between 0.1 and 100000.0".to_string());
        }

        
        if let Some(bounds_size) = physics.get("boundsSize").and_then(|b| b.as_f64()) {
            let max_boundary = bounds_size * 0.99;
            if val > max_boundary {
                return Err(format!(
                    "boundaryLimit ({:.1}) must be less than 99% of boundsSize ({:.1})",
                    val, bounds_size
                ));
            }
        }
    }

    Ok(())
}

fn validate_node_settings(nodes: &Value) -> Result<(), String> {
    
    if let Some(color) = nodes.get("baseColor") {
        let color_str = color.as_str().ok_or("baseColor must be a string")?;
        if !color_str.starts_with('#') || (color_str.len() != 7 && color_str.len() != 4) {
            return Err("baseColor must be a valid hex color (e.g., #ffffff or #fff)".to_string());
        }
    }

    if let Some(opacity) = nodes.get("opacity") {
        let val = opacity.as_f64().ok_or("opacity must be a number")?;
        if !(0.0..=1.0).contains(&val) {
            return Err("opacity must be between 0.0 and 1.0".to_string());
        }
    }

    if let Some(metalness) = nodes.get("metalness") {
        let val = metalness.as_f64().ok_or("metalness must be a number")?;
        if !(0.0..=1.0).contains(&val) {
            return Err("metalness must be between 0.0 and 1.0".to_string());
        }
    }

    if let Some(roughness) = nodes.get("roughness") {
        let val = roughness.as_f64().ok_or("roughness must be a number")?;
        if !(0.0..=1.0).contains(&val) {
            return Err("roughness must be between 0.0 and 1.0".to_string());
        }
    }

    
    if let Some(node_size) = nodes.get("nodeSize") {
        let val = node_size.as_f64().ok_or("nodeSize must be a number")?;
        if val <= 0.0 || val > 1000.0 {
            return Err("nodeSize must be between 0.0 and 1000.0".to_string());
        }
    }

    if let Some(quality) = nodes.get("quality") {
        let q = quality.as_str().ok_or("quality must be a string")?;
        if !["low", "medium", "high"].contains(&q) {
            return Err("quality must be 'low', 'medium', or 'high'".to_string());
        }
    }

    Ok(())
}

fn validate_rendering_settings(rendering: &Value) -> Result<(), String> {
    
    if let Some(ambient) = rendering.get("ambientLightIntensity") {
        let val = ambient
            .as_f64()
            .ok_or("ambientLightIntensity must be a number")?;
        if val < 0.0 || val > 100.0 {
            return Err("ambientLightIntensity must be between 0.0 and 100.0".to_string());
        }
    }

    
    if let Some(glow) = rendering.get("glow") {
        validate_glow_settings(glow)?;
    }

    Ok(())
}

///
fn validate_glow_settings(glow: &Value) -> Result<(), String> {
    
    if let Some(enabled) = glow.get("enabled") {
        if !enabled.is_boolean() {
            return Err("glow enabled must be a boolean".to_string());
        }
    }

    
    for field_name in ["intensity", "strength"] {
        if let Some(intensity) = glow.get(field_name) {
            let val = intensity
                .as_f64()
                .ok_or(format!("glow {} must be a number", field_name))?;
            if val < 0.0 || val > 10.0 {
                return Err(format!("glow {} must be between 0.0 and 10.0", field_name));
            }
        }
    }

    
    if let Some(radius) = glow.get("radius") {
        let val = radius.as_f64().ok_or("glow radius must be a number")?;
        if val < 0.0 || val > 5.0 {
            return Err("glow radius must be between 0.0 and 5.0".to_string());
        }
    }

    
    if let Some(threshold) = glow.get("threshold") {
        let val = threshold
            .as_f64()
            .ok_or("glow threshold must be a number")?;
        if val < 0.0 || val > 2.0 {
            return Err("glow threshold must be between 0.0 and 2.0".to_string());
        }
    }

    
    for field_name in [
        "edgeGlowStrength",
        "environmentGlowStrength",
        "nodeGlowStrength",
    ] {
        if let Some(strength) = glow.get(field_name) {
            let val = strength
                .as_f64()
                .ok_or(format!("glow {} must be a number", field_name))?;
            if val < 0.0 || val > 1.0 {
                return Err(format!("glow {} must be between 0.0 and 1.0", field_name));
            }
        }
    }

    Ok(())
}

fn validate_hologram_settings(hologram: &Value) -> Result<(), String> {
    
    if let Some(ring_count) = hologram.get("ringCount") {
        
        let val = ring_count
            .as_f64()
            .map(|f| f.round() as u64) 
            .or_else(|| ring_count.as_u64()) 
            .ok_or("ringCount must be a positive integer")?;

        if val > 20 {
            return Err("ringCount must be between 0 and 20".to_string());
        }
    }

    
    if let Some(color) = hologram.get("ringColor") {
        let color_str = color.as_str().ok_or("ringColor must be a string")?;
        if !color_str.starts_with('#') || (color_str.len() != 7 && color_str.len() != 4) {
            return Err("ringColor must be a valid hex color (e.g., #ffffff or #fff)".to_string());
        }
    }

    
    if let Some(opacity) = hologram.get("ringOpacity") {
        let val = opacity.as_f64().ok_or("ringOpacity must be a number")?;
        if !(0.0..=1.0).contains(&val) {
            return Err("ringOpacity must be between 0.0 and 1.0".to_string());
        }
    }

    
    if let Some(speed) = hologram.get("ringRotationSpeed") {
        let val = speed.as_f64().ok_or("ringRotationSpeed must be a number")?;
        if val < 0.0 || val > 1000.0 {
            return Err("ringRotationSpeed must be between 0.0 and 1000.0".to_string());
        }
    }

    Ok(())
}

fn validate_system_settings(system: &Value) -> Result<(), String> {
    
    if let Some(debug) = system.get("debug") {
        if let Some(debug_obj) = debug.as_object() {
            
            let boolean_fields = [
                "enabled", 
                "showFPS",
                "showMemory",
                "enablePerformanceDebug",
                "enableTelemetry",
                "enableDataDebug",
                "enableWebSocketDebug",
                "enablePhysicsDebug",
                "enableNodeDebug",
                "enableShaderDebug",
                "enableMatrixDebug",
            ];

            for field in &boolean_fields {
                if let Some(val) = debug_obj.get(*field) {
                    if !val.is_boolean() {
                        return Err(format!("debug.{} must be a boolean", field));
                    }
                }
            }

            
            if let Some(log_level) = debug_obj.get("logLevel") {
                if let Some(val) = log_level.as_f64() {
                    if val < 0.0 || val > 3.0 {
                        return Err("debug.logLevel must be between 0 and 3".to_string());
                    }
                } else if let Some(val) = log_level.as_u64() {
                    if val > 3 {
                        return Err("debug.logLevel must be between 0 and 3".to_string());
                    }
                } else if let Some(val) = log_level.as_str() {
                    
                    match val {
                        "error" | "warn" | "info" | "debug" => {
                            
                        }
                        _ => {
                            return Err(
                                "debug.logLevel must be 'error', 'warn', 'info', or 'debug'"
                                    .to_string(),
                            );
                        }
                    }
                } else {
                    return Err("debug.logLevel must be a number or string".to_string());
                }
            }
        }
    }

    
    if let Some(persist) = system.get("persistSettingsOnServer") {
        if !persist.is_boolean() {
            return Err("system.persistSettingsOnServer must be a boolean".to_string());
        }
    }

    
    if let Some(url) = system.get("customBackendUrl") {
        if !url.is_string() && !url.is_null() {
            return Err("system.customBackendUrl must be a string or null".to_string());
        }
    }

    Ok(())
}

fn validate_xr_settings(xr: &Value) -> Result<(), String> {
    
    if let Some(enabled) = xr.get("enabled") {
        if !enabled.is_boolean() {
            return Err("XR enabled must be a boolean".to_string());
        }
    }

    
    if let Some(quality) = xr.get("quality") {
        if let Some(q) = quality.as_str() {
            if !["Low", "Medium", "High", "low", "medium", "high"].contains(&q) {
                return Err("XR quality must be Low, Medium, or High".to_string());
            }
        } else {
            return Err("XR quality must be a string".to_string());
        }
    }

    
    if let Some(render_scale) = xr.get("renderScale") {
        let val = render_scale
            .as_f64()
            .ok_or("renderScale must be a number")?;
        if val < 0.1 || val > 10.0 {
            return Err("renderScale must be between 0.1 and 10.0".to_string());
        }
    }

    
    if let Some(room_scale) = xr.get("roomScale") {
        let val = room_scale.as_f64().ok_or("roomScale must be a number")?;
        if val <= 0.0 || val > 100.0 {
            return Err("roomScale must be between 0.0 and 100.0".to_string());
        }
    }

    
    if let Some(hand_tracking) = xr.get("handTracking") {
        if let Some(ht_obj) = hand_tracking.as_object() {
            if let Some(enabled) = ht_obj.get("enabled") {
                if !enabled.is_boolean() {
                    return Err("handTracking.enabled must be a boolean".to_string());
                }
            }
        }
    }

    
    if let Some(interactions) = xr.get("interactions") {
        if let Some(int_obj) = interactions.as_object() {
            if let Some(haptics) = int_obj.get("enableHaptics") {
                if !haptics.is_boolean() {
                    return Err("interactions.enableHaptics must be a boolean".to_string());
                }
            }
        }
    }

    Ok(())
}

///
async fn propagate_physics_to_gpu(
    state: &web::Data<AppState>,
    settings: &AppFullSettings,
    graph: &str,
) {
    let physics = settings.get_physics(graph);

    
    info!("[PHYSICS UPDATE] Propagating {} physics to actors:", graph);
    info!(
        "  - repulsion_k: {:.3} (affects node spreading)",
        physics.repel_k
    );
    info!(
        "  - spring_k: {:.3} (affects edge tension)",
        physics.spring_k
    );
    info!("  - spring_k: {:.3} (affects clustering)", physics.spring_k);
    info!(
        "  - damping: {:.3} (affects settling, 1.0 = no movement)",
        physics.damping
    );
    info!("  - time_step: {:.3} (simulation speed)", physics.dt);
    info!(
        "  - max_velocity: {:.3} (prevents explosions)",
        physics.max_velocity
    );
    info!(
        "  - temperature: {:.3} (random motion)",
        physics.temperature
    );
    info!("  - gravity: {:.3} (directional force)", physics.gravity);

    if crate::utils::logging::is_debug_enabled() {
        debug!("  - bounds_size: {:.1}", physics.bounds_size);
        debug!("  - separation_radius: {:.3}", physics.separation_radius); 
        debug!("  - mass_scale: {:.3}", physics.mass_scale);
        debug!("  - boundary_damping: {:.3}", physics.boundary_damping);
        debug!("  - update_threshold: {:.3}", physics.update_threshold);
        debug!("  - iterations: {}", physics.iterations);
        debug!("  - enabled: {}", physics.enabled);

        
        debug!("  - min_distance: {:.3}", physics.min_distance);
        debug!("  - max_repulsion_dist: {:.1}", physics.max_repulsion_dist);
        debug!("  - boundary_margin: {:.3}", physics.boundary_margin);
        debug!(
            "  - boundary_force_strength: {:.1}",
            physics.boundary_force_strength
        );
        debug!("  - warmup_iterations: {}", physics.warmup_iterations);
        debug!("  - warmup_curve: {}", physics.warmup_curve);
        debug!(
            "  - zero_velocity_iterations: {}",
            physics.zero_velocity_iterations
        );
        debug!("  - cooling_rate: {:.6}", physics.cooling_rate);
        debug!("  - clustering_algorithm: {}", physics.clustering_algorithm);
        debug!("  - cluster_count: {}", physics.cluster_count);
        debug!(
            "  - clustering_resolution: {:.3}",
            physics.clustering_resolution
        );
        debug!(
            "  - clustering_iterations: {}",
            physics.clustering_iterations
        );
        debug!("[GPU Parameters] All new parameters available for GPU processing");
    }

    let sim_params: crate::models::simulation_params::SimulationParams = physics.into();

    info!(
        "[PHYSICS UPDATE] Converted to SimulationParams - repulsion: {}, damping: {:.3}, time_step: {:.3}",
        sim_params.repel_k, sim_params.damping, sim_params.dt
    );

    let update_msg = UpdateSimulationParams {
        params: sim_params.clone(),
    };

    
    if let Some(gpu_addr) = &state.gpu_compute_addr {
        info!("[PHYSICS UPDATE] Sending to GPUComputeActor...");
        if let Err(e) = gpu_addr.send(update_msg.clone()).await {
            error!("[PHYSICS UPDATE] FAILED to update GPUComputeActor: {}", e);
        } else {
            info!("[PHYSICS UPDATE] GPUComputeActor updated successfully");
        }
    } else {
        warn!("[PHYSICS UPDATE] No GPUComputeActor available");
    }

    
    info!("[PHYSICS UPDATE] Sending to GraphServiceActor...");
    if let Err(e) = state.graph_service_addr.send(update_msg).await {
        error!("[PHYSICS UPDATE] FAILED to update GraphServiceActor: {}", e);
    } else {
        info!("[PHYSICS UPDATE] GraphServiceActor updated successfully");
    }
}

///
fn get_field_variant<'a>(obj: &'a Value, variants: &[&str]) -> Option<&'a Value> {
    for variant in variants {
        if let Some(val) = obj.get(*variant) {
            return Some(val);
        }
    }
    None
}

///
fn count_fields(value: &Value) -> usize {
    match value {
        Value::Object(map) => map.len() + map.values().map(count_fields).sum::<usize>(),
        Value::Array(arr) => arr.iter().map(count_fields).sum(),
        _ => 0,
    }
}

///
fn extract_physics_updates(update: &Value) -> Vec<&str> {
    update
        .get("visualisation")
        .and_then(|v| v.get("graphs"))
        .and_then(|g| g.as_object())
        .map(|graphs| {
            let mut updated = Vec::new();
            if graphs.contains_key("logseq")
                && graphs
                    .get("logseq")
                    .and_then(|g| g.get("physics"))
                    .is_some()
            {
                updated.push("logseq");
            }
            if graphs.contains_key("visionflow")
                && graphs
                    .get("visionflow")
                    .and_then(|g| g.get("physics"))
                    .is_some()
            {
                updated.push("visionflow");
            }
            updated
        })
        .unwrap_or_default()
}

///
fn extract_failed_field(physics: &Value) -> String {
    if let Some(obj) = physics.as_object() {
        obj.keys().next().unwrap_or(&"unknown".to_string()).clone()
    } else {
        "unknown".to_string()
    }
}

///
///
fn create_physics_settings_update(physics_update: Value) -> Value {
    let mut normalized_physics = physics_update.clone();

    
    if let Some(obj) = normalized_physics.as_object_mut() {
        
        if let Some(spring_strength) = obj.remove("springStrength") {
            if !obj.contains_key("springK") {
                obj.insert("springK".to_string(), spring_strength);
            }
        }

        
        if let Some(repulsion_strength) = obj.remove("repulsionStrength") {
            if !obj.contains_key("repelK") {
                obj.insert("repelK".to_string(), repulsion_strength);
            }
        }

        
        if let Some(attraction_strength) = obj.remove("attractionStrength") {
            if !obj.contains_key("attractionK") {
                obj.insert("attractionK".to_string(), attraction_strength);
            }
        }

        
        if let Some(collision_radius) = obj.remove("collisionRadius") {
            if !obj.contains_key("separationRadius") {
                obj.insert("separationRadius".to_string(), collision_radius);
            }
        }
    }

    json!({
        "visualisation": {
            "graphs": {
                "logseq": {
                    "physics": normalized_physics
                },
                "visionflow": {
                    "physics": normalized_physics.clone()
                }
            }
        }
    })
}

///
async fn update_compute_mode(
    _req: HttpRequest,
    state: web::Data<AppState>,
    payload: web::Json<Value>,
) -> Result<HttpResponse, Error> {
    let update = payload.into_inner();

    info!("Compute mode update request received");
    debug!(
        "Compute mode payload: {}",
        serde_json::to_string_pretty(&update).unwrap_or_default()
    );

    
    let compute_mode = update
        .get("computeMode")
        .and_then(|v| v.as_u64())
        .ok_or_else(|| {
            actix_web::error::ErrorBadRequest("computeMode must be an integer between 0 and 3")
        })?;

    if compute_mode > 3 {
        return bad_request!("computeMode must be between 0 and 3");
    }

    
    let physics_update = json!({
        "computeMode": compute_mode
    });

    let settings_update = create_physics_settings_update(physics_update);

    
    let mut app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(s)) => s,
        Ok(Err(e)) => {
            error!("Failed to get current settings: {}", e);
            return error_json!("Failed to get current settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    if let Err(e) = app_settings.merge_update(settings_update) {
        error!("Failed to merge compute mode settings: {}", e);
        return error_json!("Failed to update compute mode: {}", e);
    }

    
    match state
        .settings_addr
        .send(UpdateSettings {
            settings: app_settings.clone(),
        })
        .await
    {
        Ok(Ok(())) => {
            info!("Compute mode updated successfully to: {}", compute_mode);

            
            propagate_physics_to_gpu(&state, &app_settings, "logseq").await;
            propagate_physics_to_gpu(&state, &app_settings, "visionflow").await;

            ok_json!(json!({
                "status": "Compute mode updated successfully",
                "computeMode": compute_mode
            }))
        }
        Ok(Err(e)) => {
            error!("Failed to save compute mode settings: {}", e);
            error_json!("Failed to save compute mode settings: {}", e)
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            service_unavailable!("Settings service unavailable")
        }
    }
}

///
async fn update_clustering_algorithm(
    _req: HttpRequest,
    state: web::Data<AppState>,
    payload: web::Json<Value>,
) -> Result<HttpResponse, Error> {
    let update = payload.into_inner();

    info!("Clustering algorithm update request received");
    debug!(
        "Clustering payload: {}",
        serde_json::to_string_pretty(&update).unwrap_or_default()
    );

    
    let algorithm = update
        .get("algorithm")
        .and_then(|v| v.as_str())
        .ok_or_else(|| actix_web::error::ErrorBadRequest("algorithm must be a string"))?;

    if !["none", "kmeans", "spectral", "louvain"].contains(&algorithm) {
        return bad_request!("algorithm must be 'none', 'kmeans', 'spectral', or 'louvain'");
    }

    
    let cluster_count = update
        .get("clusterCount")
        .and_then(|v| v.as_u64())
        .unwrap_or(5);
    let resolution = update
        .get("resolution")
        .and_then(|v| v.as_f64())
        .unwrap_or(1.0) as f32;
    let iterations = update
        .get("iterations")
        .and_then(|v| v.as_u64())
        .unwrap_or(30);

    
    let physics_update = json!({
        "clusteringAlgorithm": algorithm,
        "clusterCount": cluster_count,
        "clusteringResolution": resolution,
        "clusteringIterations": iterations
    });

    let settings_update = create_physics_settings_update(physics_update);

    
    let mut app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(s)) => s,
        Ok(Err(e)) => {
            error!("Failed to get current settings: {}", e);
            return error_json!("Failed to get current settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    if let Err(e) = app_settings.merge_update(settings_update) {
        error!("Failed to merge clustering settings: {}", e);
        return error_json!("Failed to update clustering algorithm: {}", e);
    }

    
    match state
        .settings_addr
        .send(UpdateSettings {
            settings: app_settings.clone(),
        })
        .await
    {
        Ok(Ok(())) => {
            info!(
                "Clustering algorithm updated successfully to: {}",
                algorithm
            );

            
            propagate_physics_to_gpu(&state, &app_settings, "logseq").await;
            propagate_physics_to_gpu(&state, &app_settings, "visionflow").await;

            ok_json!(json!({
                "status": "Clustering algorithm updated successfully",
                "algorithm": algorithm,
                "clusterCount": cluster_count,
                "resolution": resolution,
                "iterations": iterations
            }))
        }
        Ok(Err(e)) => {
            error!("Failed to save clustering settings: {}", e);
            error_json!("Failed to save clustering settings: {}", e)
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            service_unavailable!("Settings service unavailable")
        }
    }
}

///
async fn update_constraints(
    _req: HttpRequest,
    state: web::Data<AppState>,
    payload: web::Json<Value>,
) -> Result<HttpResponse, Error> {
    let update = payload.into_inner();

    info!("Constraints update request received");
    debug!(
        "Constraints payload: {}",
        serde_json::to_string_pretty(&update).unwrap_or_default()
    );

    
    if let Err(e) = validate_constraints(&update) {
        return bad_request!("Invalid constraints: {}", e);
    }

    
    
    let settings_update = json!({
        "visualisation": {
            "graphs": {
                "logseq": {
                    "physics": {
                        "computeMode": 2  
                    }
                },
                "visionflow": {
                    "physics": {
                        "computeMode": 2
                    }
                }
            }
        }
    });

    
    let mut app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(s)) => s,
        Ok(Err(e)) => {
            error!("Failed to get current settings: {}", e);
            return error_json!("Failed to get current settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    if let Err(e) = app_settings.merge_update(settings_update) {
        error!("Failed to merge constraints settings: {}", e);
        return error_json!("Failed to update constraints: {}", e);
    }

    
    match state
        .settings_addr
        .send(UpdateSettings {
            settings: app_settings.clone(),
        })
        .await
    {
        Ok(Ok(())) => {
            info!("Constraints updated successfully");

            
            propagate_physics_to_gpu(&state, &app_settings, "logseq").await;
            propagate_physics_to_gpu(&state, &app_settings, "visionflow").await;

            ok_json!(json!({
                "status": "Constraints updated successfully"
            }))
        }
        Ok(Err(e)) => {
            error!("Failed to save constraints settings: {}", e);
            error_json!("Failed to save constraints settings: {}", e)
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            service_unavailable!("Settings service unavailable")
        }
    }
}

///
async fn get_cluster_analytics(
    _req: HttpRequest,
    state: web::Data<AppState>,
) -> Result<HttpResponse, Error> {
    info!("Cluster analytics request received");

    
    if let Some(gpu_addr) = &state.gpu_compute_addr {
        
        use crate::actors::messages::GetGraphData;

        
        let graph_data = match state.graph_service_addr.send(GetGraphData).await {
            Ok(Ok(data)) => data,
            Ok(Err(e)) => {
                error!("Failed to get graph data for clustering analytics: {}", e);
                return error_json!("Failed to get graph data for analytics");
            }
            Err(e) => {
                error!("Graph service communication error: {}", e);
                return service_unavailable!("Graph service unavailable");
            }
        };

        
        info!("GPU compute actor available but clustering not handled by force compute actor");
        get_cpu_fallback_analytics(&graph_data).await
    } else {
        
        use crate::actors::messages::GetGraphData;
        match state.graph_service_addr.send(GetGraphData).await {
            Ok(Ok(graph_data)) => get_cpu_fallback_analytics(&graph_data).await,
            Ok(Err(e)) => {
                error!("Failed to get graph data: {}", e);
                error_json!("Failed to get graph data for analytics")
            }
            Err(e) => {
                error!("Graph service unavailable: {}", e);
                service_unavailable!("Graph service unavailable")
            }
        }
    }
}

///
async fn get_cpu_fallback_analytics(
    graph_data: &crate::models::graph::GraphData,
) -> Result<HttpResponse, Error> {
    use std::collections::HashMap;
use crate::{
    ok_json, created_json, error_json, bad_request, not_found,
    unauthorized, forbidden, conflict, no_content, accepted,
    too_many_requests, service_unavailable, payload_too_large
};



    
    let node_count = graph_data.nodes.len();
    let edge_count = graph_data.edges.len();

    
    let mut type_clusters: HashMap<String, Vec<&crate::models::node::Node>> = HashMap::new();

    for node in &graph_data.nodes {
        let node_type = node
            .node_type
            .as_ref()
            .unwrap_or(&"unknown".to_string())
            .clone();
        type_clusters
            .entry(node_type)
            .or_insert_with(Vec::new)
            .push(node);
    }

    
    let clusters: Vec<_> = type_clusters
        .into_iter()
        .enumerate()
        .map(|(i, (type_name, nodes))| {
            
            let centroid = if !nodes.is_empty() {
                let sum_x: f32 = nodes.iter().map(|n| n.data.x).sum();
                let sum_y: f32 = nodes.iter().map(|n| n.data.y).sum();
                let sum_z: f32 = nodes.iter().map(|n| n.data.z).sum();
                let count = nodes.len() as f32;
                [sum_x / count, sum_y / count, sum_z / count]
            } else {
                [0.0, 0.0, 0.0]
            };

            json!({
                "id": format!("cpu_cluster_{}", i),
                "nodeCount": nodes.len(),
                "coherence": 0.6, 
                "centroid": centroid,
                "keywords": [type_name.clone(), "cpu_cluster"],
                "type": type_name
            })
        })
        .collect();

    let fallback_analytics = json!({
        "clusters": clusters,
        "totalNodes": node_count,
        "algorithmUsed": "cpu_heuristic",
        "modularity": 0.4, 
        "lastUpdated": chrono::Utc::now().to_rfc3339(),
        "gpu_accelerated": false,
        "note": "CPU fallback clustering based on node types",
        "computation_time_ms": 0
    });

    ok_json!(fallback_analytics)
}

///
async fn update_stress_optimization(
    _req: HttpRequest,
    state: web::Data<AppState>,
    payload: web::Json<Value>,
) -> Result<HttpResponse, Error> {
    let update = payload.into_inner();

    info!("Stress optimization update request received");
    debug!(
        "Stress optimization payload: {}",
        serde_json::to_string_pretty(&update).unwrap_or_default()
    );

    
    let stress_weight = update
        .get("stressWeight")
        .and_then(|v| v.as_f64())
        .unwrap_or(0.1) as f32;

    let stress_alpha = update
        .get("stressAlpha")
        .and_then(|v| v.as_f64())
        .unwrap_or(0.1) as f32;

    if !(0.0..=1.0).contains(&stress_weight) || !(0.0..=1.0).contains(&stress_alpha) {
        return bad_request!("stressWeight and stressAlpha must be between 0.0 and 1.0");
    }

    
    let physics_update = json!({
        "stressWeight": stress_weight,
        "stressAlpha": stress_alpha
    });

    let settings_update = create_physics_settings_update(physics_update);

    
    let mut app_settings = match state.settings_addr.send(GetSettings).await {
        Ok(Ok(s)) => s,
        Ok(Err(e)) => {
            error!("Failed to get current settings: {}", e);
            return error_json!("Failed to get current settings");
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            return service_unavailable!("Settings service unavailable");
        }
    };

    if let Err(e) = app_settings.merge_update(settings_update) {
        error!("Failed to merge stress optimization settings: {}", e);
        return error_json!("Failed to update stress optimization: {}", e);
    }

    
    match state
        .settings_addr
        .send(UpdateSettings {
            settings: app_settings.clone(),
        })
        .await
    {
        Ok(Ok(())) => {
            info!("Stress optimization updated successfully");

            
            propagate_physics_to_gpu(&state, &app_settings, "logseq").await;
            propagate_physics_to_gpu(&state, &app_settings, "visionflow").await;

            ok_json!(json!({
                "status": "Stress optimization updated successfully",
                "stressWeight": stress_weight,
                "stressAlpha": stress_alpha
            }))
        }
        Ok(Err(e)) => {
            error!("Failed to save stress optimization settings: {}", e);
            error_json!("Failed to save stress optimization settings: {}", e)
        }
        Err(e) => {
            error!("Settings actor error: {}", e);
            service_unavailable!("Settings service unavailable")
        }
    }
}

///
fn validate_constraints(constraints: &Value) -> Result<(), String> {
    
    if let Some(obj) = constraints.as_object() {
        for (constraint_type, constraint_data) in obj {
            if !["separation", "boundary", "alignment", "cluster"]
                .contains(&constraint_type.as_str())
            {
                return Err(format!("Unknown constraint type: {}", constraint_type));
            }

            if let Some(data) = constraint_data.as_object() {
                if let Some(strength) = data.get("strength") {
                    let val = strength.as_f64().ok_or("strength must be a number")?;
                    if val < 0.0 || val > 100.0 {
                        return Err("strength must be between 0.0 and 100.0".to_string());
                    }
                }

                if let Some(enabled) = data.get("enabled") {
                    if !enabled.is_boolean() {
                        return Err("enabled must be a boolean".to_string());
                    }
                }
            }
        }
    }

    Ok(())
}

--------------------------------------------------------------------------------
FILE: src/handlers/nostr_handler.rs
PURPOSE: Nostr protocol authentication handler
--------------------------------------------------------------------------------
use crate::app_state::AppState;
use crate::config::feature_access::FeatureAccess;
use crate::models::protected_settings::ApiKeys;
use crate::services::nostr_service::{AuthEvent, NostrError, NostrService};
use actix_web::{web, Error, HttpRequest, HttpResponse};
use serde::{Deserialize, Serialize};
use serde_json::json;
use crate::{
    ok_json, created_json, error_json, bad_request, not_found,
    unauthorized, forbidden, conflict, no_content, accepted,
    too_many_requests, service_unavailable, payload_too_large
};



#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct AuthResponse {
    pub user: UserResponseDTO,
    pub token: String,
    pub expires_at: i64,
    pub features: Vec<String>,
}

// Data transfer object for user response that matches client expectations
#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct UserResponseDTO {
    pub pubkey: String,
    pub npub: Option<String>,
    pub is_power_user: bool,
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct VerifyResponse {
    pub valid: bool,
    pub user: Option<UserResponseDTO>,
    pub features: Vec<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ApiKeysRequest {
    pub perplexity: Option<String>,
    pub openai: Option<String>,
    pub ragflow: Option<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ValidateRequest {
    pub pubkey: String,
    pub token: String,
}

pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/auth/nostr") 
            .route("", web::post().to(login))
            .route("", web::delete().to(logout))
            .route("/verify", web::post().to(verify))
            .route("/refresh", web::post().to(refresh))
            .route("/api-keys", web::post().to(update_api_keys))
            .route("/api-keys", web::get().to(get_api_keys))
            .route("/power-user-status", web::get().to(check_power_user_status))
            .route("/features", web::get().to(get_available_features))
            .route("/features/{feature}", web::get().to(check_feature_access)),
    );
}

async fn check_power_user_status(
    req: HttpRequest,
    feature_access: web::Data<FeatureAccess>,
) -> Result<HttpResponse, actix_web::Error> {
    let pubkey = req
        .headers()
        .get("X-Nostr-Pubkey")
        .and_then(|h| h.to_str().ok())
        .unwrap_or("");

    if pubkey.is_empty() {
        return bad_request!("Missing Nostr pubkey");
    }

    ok_json!(json!({
        "is_power_user": feature_access.is_power_user(pubkey)
    }))
}

async fn get_available_features(
    req: HttpRequest,
    feature_access: web::Data<FeatureAccess>,
) -> Result<HttpResponse, actix_web::Error> {
    let pubkey = req
        .headers()
        .get("X-Nostr-Pubkey")
        .and_then(|h| h.to_str().ok())
        .unwrap_or("");

    if pubkey.is_empty() {
        return bad_request!("Missing Nostr pubkey");
    }

    let features = feature_access.get_available_features(pubkey);
    ok_json!(json!({
        "features": features
    }))
}

async fn check_feature_access(
    req: HttpRequest,
    feature_access: web::Data<FeatureAccess>,
    feature: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    let pubkey = req
        .headers()
        .get("X-Nostr-Pubkey")
        .and_then(|h| h.to_str().ok())
        .unwrap_or("");

    if pubkey.is_empty() {
        return bad_request!("Missing Nostr pubkey");
    }

    ok_json!(json!({
        "has_access": feature_access.has_feature_access(pubkey, &feature)
    }))
}

async fn login(
    event: web::Json<AuthEvent>,
    nostr_service: web::Data<NostrService>,
    feature_access: web::Data<FeatureAccess>,
) -> Result<HttpResponse, actix_web::Error> {
    match nostr_service.verify_auth_event(event.into_inner()).await {
        Ok(user) => {
            let token = user.session_token.clone().unwrap_or_default();
            let expires_at = user.last_seen
                + std::env::var("AUTH_TOKEN_EXPIRY")
                    .unwrap_or_else(|_| "3600".to_string())
                    .parse::<i64>()
                    .unwrap_or(3600);

            
            let features = feature_access.get_available_features(&user.pubkey);

            
            let user_dto = UserResponseDTO {
                pubkey: user.pubkey.clone(),
                npub: Some(user.npub.clone()),
                is_power_user: user.is_power_user,
            };

            ok_json!(AuthResponse {
                user: user_dto,
                token,
                expires_at,
                features,
            })
        }
        Err(NostrError::InvalidSignature) => Ok(HttpResponse::Unauthorized().json(json!({
            "error": "Invalid signature"
        }))),
        Err(e) => error_json!("Authentication error: {}", e),
    }
}

async fn logout(
    req: web::Json<ValidateRequest>,
    nostr_service: web::Data<NostrService>,
) -> Result<HttpResponse, actix_web::Error> {
    
    if !nostr_service
        .validate_session(&req.pubkey, &req.token)
        .await
    {
        return Ok(HttpResponse::Unauthorized().json(json!({
            "error": "Invalid session"
        })));
    }

    match nostr_service.logout(&req.pubkey).await {
        Ok(_) => ok_json!(json!({
            "message": "Logged out successfully"
        })),
        Err(e) => error_json!("Logout error: {}", e),
    }
}

async fn verify(
    req: web::Json<ValidateRequest>,
    nostr_service: web::Data<NostrService>,
    feature_access: web::Data<FeatureAccess>,
) -> Result<HttpResponse, actix_web::Error> {
    let is_valid = nostr_service
        .validate_session(&req.pubkey, &req.token)
        .await;
    let user = if is_valid {
        nostr_service
            .get_user(&req.pubkey)
            .await
            .map(|u| UserResponseDTO {
                pubkey: u.pubkey,
                npub: Some(u.npub),
                is_power_user: u.is_power_user,
            })
    } else {
        None
    };

    
    let features = if is_valid {
        feature_access.get_available_features(&req.pubkey)
    } else {
        Vec::new()
    };

    ok_json!(VerifyResponse {
        valid: is_valid,
        user,
        features,
    })
}

async fn refresh(
    req: web::Json<ValidateRequest>,
    nostr_service: web::Data<NostrService>,
    feature_access: web::Data<FeatureAccess>,
) -> Result<HttpResponse, actix_web::Error> {
    
    if !nostr_service
        .validate_session(&req.pubkey, &req.token)
        .await
    {
        return Ok(HttpResponse::Unauthorized().json(json!({
            "error": "Invalid session"
        })));
    }

    match nostr_service.refresh_session(&req.pubkey).await {
        Ok(new_token) => {
            if let Some(user) = nostr_service.get_user(&req.pubkey).await {
                let expires_at = user.last_seen
                    + std::env::var("AUTH_TOKEN_EXPIRY")
                        .unwrap_or_else(|_| "3600".to_string())
                        .parse::<i64>()
                        .unwrap_or(3600);
                
                let features = feature_access.get_available_features(&req.pubkey);

                ok_json!(AuthResponse {
                    user: UserResponseDTO {
                        pubkey: user.pubkey.clone(),
                        npub: Some(user.npub.clone()),
                        is_power_user: user.is_power_user,
                    },
                    token: new_token,
                    expires_at,
                    features,
                })
            } else {
                error_json!("User not found after refresh")
            }
        }
        Err(e) => error_json!("Session refresh error: {}", e),
    }
}

async fn update_api_keys(
    req: web::Json<ApiKeysRequest>,
    nostr_service: web::Data<NostrService>,
    pubkey: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    let api_keys = ApiKeys {
        perplexity: req.perplexity.clone(),
        openai: req.openai.clone(),
        ragflow: req.ragflow.clone(),
    };

    match nostr_service.update_user_api_keys(&pubkey, api_keys).await {
        Ok(user) => {
            let user_dto = UserResponseDTO {
                pubkey: user.pubkey.clone(),
                npub: Some(user.npub.clone()),
                is_power_user: user.is_power_user,
            };
            ok_json!(user_dto)
        }
        Err(NostrError::UserNotFound) => not_found!("User not found"),
        Err(NostrError::PowerUserOperation) => Ok(HttpResponse::Forbidden().json(json!({
            "error": "Cannot update API keys for power users"
        }))),
        Err(e) => error_json!("Failed to update API keys: {}", e),
    }
}

async fn get_api_keys(
    state: web::Data<AppState>,
    pubkey: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    let api_keys = state.get_api_keys(&pubkey).await;

    ok_json!(api_keys)
}

// Add the handler to app_state initialization
pub fn init_nostr_service(app_state: &mut AppState) {
    let nostr_service = NostrService::new();

    
    let service_clone = nostr_service.clone();
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(tokio::time::Duration::from_secs(3600)); 
        loop {
            interval.tick().await;
            service_clone.cleanup_sessions(24).await; 
        }
    });

    app_state.nostr_service = Some(web::Data::new(nostr_service));
}

--------------------------------------------------------------------------------
FILE: src/handlers/socket_flow_handler.rs
PURPOSE: Binary socket protocol handler for position updates
--------------------------------------------------------------------------------
use actix::{prelude::*, Actor, Handler, Message};
use actix_web::{web, Error, HttpRequest, HttpResponse};
use actix_web_actors::ws;
use log::{debug, error, info, trace, warn};
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Instant;

use crate::app_state::AppState;
use crate::types::vec3::Vec3Data;
use crate::utils::binary_protocol;
use crate::utils::socket_flow_messages::{
    BinaryNodeData, BinaryNodeDataClient, PingMessage, PongMessage,
};
use crate::utils::validation::rate_limit::{
    create_rate_limit_response, extract_client_id, EndpointRateLimits, RateLimiter,
};

// Constants for throttling debug logs
const DEBUG_LOG_SAMPLE_RATE: usize = 10; 

// Default values for deadbands if not provided in settings
const DEFAULT_POSITION_DEADBAND: f32 = 0.01; 
const DEFAULT_VELOCITY_DEADBAND: f32 = 0.005; 
                                              
const BATCH_UPDATE_WINDOW_MS: u64 = 200; 

// Create a global rate limiter for WebSocket position updates
lazy_static::lazy_static! {
    static ref WEBSOCKET_RATE_LIMITER: Arc<RateLimiter> = {
        Arc::new(RateLimiter::new(EndpointRateLimits::socket_flow_updates()))
    };
}

// Note: Now using u32 node IDs throughout the system

///
#[derive(Clone, Debug)]
pub struct PreReadSocketSettings {
    pub min_update_rate: u32,
    pub max_update_rate: u32,
    pub motion_threshold: f32,
    pub motion_damping: f32,
    pub heartbeat_interval_ms: u64, 
    pub heartbeat_timeout_ms: u64,  
}

// Old ClientManager struct removed - now using ClientManagerActor

// Message to set client ID after registration
#[derive(Message)]
#[rtype(result = "()")]
struct SetClientId(usize);

// Implement handler for SetClientId message
impl Handler<SetClientId> for SocketFlowServer {
    type Result = ();

    fn handle(&mut self, msg: SetClientId, _ctx: &mut Self::Context) -> Self::Result {
        self.client_id = Some(msg.0);
        info!("[WebSocket] Client assigned ID: {}", msg.0);
    }
}

// Implement handler for BroadcastPositionUpdate message
impl Handler<BroadcastPositionUpdate> for SocketFlowServer {
    type Result = ();

    fn handle(&mut self, msg: BroadcastPositionUpdate, ctx: &mut Self::Context) -> Self::Result {
        if !msg.0.is_empty() {
            
            let binary_data = binary_protocol::encode_node_data(&msg.0);

            
            ctx.binary(binary_data);

            
            if self.should_log_update() {
                trace!("[WebSocket] Position update sent: {} nodes", msg.0.len());
            }
        }
    }
}
///
#[derive(Message, Clone)]
#[rtype(result = "()")]
pub struct BroadcastPositionUpdate(pub Vec<(u32, BinaryNodeData)>);

// Import the new messages
use crate::actors::messages::{SendToClientBinary, SendToClientText};

impl Handler<SendToClientBinary> for SocketFlowServer {
    type Result = ();

    fn handle(&mut self, msg: SendToClientBinary, ctx: &mut Self::Context) {
        ctx.binary(msg.0);
    }
}

impl Handler<SendToClientText> for SocketFlowServer {
    type Result = ();

    fn handle(&mut self, msg: SendToClientText, ctx: &mut Self::Context) {
        ctx.text(msg.0);
    }
}

// Handler for initial graph load - sends all nodes and edges as JSON
use crate::actors::messages::{SendInitialGraphLoad, SendPositionUpdate};

impl Handler<SendInitialGraphLoad> for SocketFlowServer {
    type Result = ();

    fn handle(&mut self, msg: SendInitialGraphLoad, ctx: &mut Self::Context) -> Self::Result {
        use crate::utils::socket_flow_messages::Message;

        let initial_load = Message::InitialGraphLoad {
            nodes: msg.nodes,
            edges: msg.edges,
            timestamp: chrono::Utc::now().timestamp_millis() as u64,
        };

        if let Ok(json) = serde_json::to_string(&initial_load) {
            ctx.text(json);
            if let Message::InitialGraphLoad { nodes, edges, .. } = &initial_load {
                info!("[WebSocket] Sent initial graph load: {} nodes, {} edges",
                       nodes.len(), edges.len());
            }
        } else {
            error!("[WebSocket] Failed to serialize initial graph load message");
        }
    }
}

// Handler for streamed position updates - sends individual node updates efficiently
impl Handler<SendPositionUpdate> for SocketFlowServer {
    type Result = ();

    fn handle(&mut self, msg: SendPositionUpdate, ctx: &mut Self::Context) -> Self::Result {
        use crate::utils::socket_flow_messages::Message;

        let position_update = Message::PositionUpdate {
            node_id: msg.node_id,
            x: msg.x,
            y: msg.y,
            z: msg.z,
            vx: msg.vx,
            vy: msg.vy,
            vz: msg.vz,
            timestamp: chrono::Utc::now().timestamp_millis() as u64,
        };

        if let Ok(json) = serde_json::to_string(&position_update) {
            ctx.text(json);
            if self.should_log_update() {
                trace!("[WebSocket] Sent position update for node {}", msg.node_id);
            }
        } else {
            error!("[WebSocket] Failed to serialize position update for node {}", msg.node_id);
        }
    }
}

pub struct SocketFlowServer {
    app_state: Arc<AppState>,
    client_id: Option<usize>,
    client_manager_addr:
        actix::Addr<crate::actors::client_coordinator_actor::ClientCoordinatorActor>,
    last_ping: Option<u64>,
    update_counter: usize,
    last_activity: std::time::Instant,
    heartbeat_timer_set: bool,

    _node_position_cache: HashMap<String, BinaryNodeData>,
    last_sent_positions: HashMap<String, Vec3Data>,
    last_sent_velocities: HashMap<String, Vec3Data>,
    position_deadband: f32,
    velocity_deadband: f32,

    last_transfer_size: usize,
    last_transfer_time: Instant,
    total_bytes_sent: usize,
    update_count: usize,
    nodes_sent_count: usize,


    last_batch_time: Instant,
    current_update_rate: u32,

    min_update_rate: u32,
    max_update_rate: u32,
    motion_threshold: f32,
    motion_damping: f32,


    nodes_in_motion: usize,
    total_node_count: usize,
    last_motion_check: Instant,


    client_ip: String,
    is_reconnection: bool,
    state_synced: bool,

    // Authentication state
    pubkey: Option<String>,
    is_power_user: bool,
}

impl SocketFlowServer {
    pub fn new(
        app_state: Arc<AppState>,
        pre_read_settings: PreReadSocketSettings,
        client_manager_addr: actix::Addr<
            crate::actors::client_coordinator_actor::ClientCoordinatorActor,
        >,
        client_ip: String,
    ) -> Self {
        let min_update_rate = pre_read_settings.min_update_rate;
        let max_update_rate = pre_read_settings.max_update_rate;
        let motion_threshold = pre_read_settings.motion_threshold;
        let motion_damping = pre_read_settings.motion_damping;
        
        

        
        let position_deadband = DEFAULT_POSITION_DEADBAND;
        let velocity_deadband = DEFAULT_VELOCITY_DEADBAND;

        
        let current_update_rate = max_update_rate;

        Self {
            app_state,
            client_id: None,
            client_manager_addr,
            last_ping: None,
            update_counter: 0,
            last_activity: std::time::Instant::now(),
            heartbeat_timer_set: false,
            _node_position_cache: HashMap::new(),
            last_sent_positions: HashMap::new(),
            last_sent_velocities: HashMap::new(),
            position_deadband,
            velocity_deadband,
            last_transfer_size: 0,
            last_transfer_time: Instant::now(),
            total_bytes_sent: 0,
            last_batch_time: Instant::now(),
            update_count: 0,
            nodes_sent_count: 0,
            current_update_rate,
            min_update_rate,
            max_update_rate,
            motion_threshold,
            motion_damping,


            nodes_in_motion: 0,
            total_node_count: 0,
            last_motion_check: Instant::now(),
            client_ip,
            is_reconnection: false,
            state_synced: false,
            pubkey: None,
            is_power_user: false,
        }
    }

    
    fn send_full_state_sync(&self, ctx: &mut <Self as Actor>::Context) {
        let app_state = self.app_state.clone();
        let addr = ctx.address();

        
        actix::spawn(async move {
            
            if let Ok(Ok(graph_data)) = app_state
                .graph_service_addr
                .send(crate::actors::messages::GetGraphData)
                .await
            {
                
                if let Ok(Ok(settings)) = app_state
                    .settings_addr
                    .send(crate::actors::messages::GetSettings)
                    .await
                {
                    
                    let state_sync = serde_json::json!({
                        "type": "state_sync",
                        "data": {
                            "graph": {
                                "nodes_count": graph_data.nodes.len(),
                                "edges_count": graph_data.edges.len(),
                                "metadata_count": graph_data.metadata.len(),
                            },
                            "settings": {
                                "version": settings.version,
                            },
                            "timestamp": std::time::SystemTime::now()
                                .duration_since(std::time::UNIX_EPOCH)
                                .unwrap_or_default()
                                .as_secs(),
                        }
                    });

                    
                    if let Ok(msg_str) = serde_json::to_string(&state_sync) {
                        addr.do_send(SendToClientText(msg_str));
                        info!(
                            "Sent state sync: {} nodes, {} edges, version: {}",
                            graph_data.nodes.len(),
                            graph_data.edges.len(),
                            settings.version
                        );
                    }


                    // DEFAULT INITIAL LOAD SIZE - fresh clients receive sparse, metadata-rich dataset
                    // Client can request more nodes later using filter settings
                    const DEFAULT_INITIAL_NODE_LIMIT: usize = 200;

                    // Send new InitialGraphLoad message with LIMITED node set for fast initial render
                    if !graph_data.nodes.is_empty() || !graph_data.edges.is_empty() {
                        use crate::utils::socket_flow_messages::{InitialNodeData, InitialEdgeData};
                        use std::collections::HashSet;

                        // Take first N nodes (sorted by quality if available, otherwise by ID)
                        // This provides a sparse initial load that client can expand via filter controls
                        let mut sorted_nodes: Vec<&crate::models::node::Node> = graph_data
                            .nodes
                            .iter()
                            .collect();

                        // Sort by quality_score descending (nodes with quality first, then others)
                        sorted_nodes.sort_by(|a, b| {
                            let quality_a = graph_data.metadata.get(&a.metadata_id)
                                .and_then(|m| m.quality_score)
                                .unwrap_or(0.0);
                            let quality_b = graph_data.metadata.get(&b.metadata_id)
                                .and_then(|m| m.quality_score)
                                .unwrap_or(0.0);
                            quality_b.partial_cmp(&quality_a).unwrap_or(std::cmp::Ordering::Equal)
                        });

                        // Take limited set for initial sparse load
                        let filtered_nodes: Vec<&crate::models::node::Node> = sorted_nodes
                            .into_iter()
                            .take(DEFAULT_INITIAL_NODE_LIMIT)
                            .collect();

                        // Collect filtered node IDs for edge filtering
                        let filtered_node_ids: HashSet<u32> = filtered_nodes.iter().map(|n| n.id).collect();

                        let nodes: Vec<InitialNodeData> = filtered_nodes
                            .iter()
                            .map(|node| InitialNodeData {
                                id: node.id,
                                metadata_id: node.metadata_id.clone(),
                                label: node.label.clone(),
                                x: node.data.x,
                                y: node.data.y,
                                z: node.data.z,
                                vx: node.data.vx,
                                vy: node.data.vy,
                                vz: node.data.vz,
                                owl_class_iri: node.owl_class_iri.clone(),
                                node_type: node.node_type.clone(),
                            })
                            .collect();

                        // Only include edges where BOTH source and target are in filtered nodes
                        let edges: Vec<InitialEdgeData> = graph_data
                            .edges
                            .iter()
                            .filter(|edge| {
                                filtered_node_ids.contains(&edge.source) && filtered_node_ids.contains(&edge.target)
                            })
                            .map(|edge| InitialEdgeData {
                                id: edge.id.clone(),
                                source_id: edge.source,
                                target_id: edge.target,
                                weight: Some(edge.weight),
                                edge_type: edge.edge_type.clone(),
                            })
                            .collect();

                        addr.do_send(SendInitialGraphLoad { nodes: nodes.clone(), edges: edges.clone() });
                        info!(" Sent InitialGraphLoad: {} nodes (sparse from {} total), {} edges [limit: {}]",
                              nodes.len(), graph_data.nodes.len(),
                              edges.len(), DEFAULT_INITIAL_NODE_LIMIT);

                        // Also send binary position data for SAME limited nodes only
                        // Use filtered_node_ids to maintain consistency with InitialGraphLoad
                        let node_data: Vec<(u32, BinaryNodeData)> = graph_data
                            .nodes
                            .iter()
                            .filter(|node| filtered_node_ids.contains(&node.id))
                            .map(|node| {
                                (
                                    node.id,
                                    BinaryNodeData {
                                        node_id: node.id,
                                        x: node.data.x,
                                        y: node.data.y,
                                        z: node.data.z,
                                        vx: node.data.vx,
                                        vy: node.data.vy,
                                        vz: node.data.vz,
                                    },
                                )
                            })
                            .collect();

                        addr.do_send(BroadcastPositionUpdate(node_data.clone()));
                        debug!("Sent initial node positions for {} limited nodes (binary)", node_data.len());
                    }
                }
            }
        });
    }

    fn handle_ping(&mut self, msg: PingMessage) -> PongMessage {
        self.last_ping = Some(msg.timestamp);
        PongMessage {
            type_: "pong".to_string(),
            timestamp: msg.timestamp,
        }
    }

    
    fn should_log_update(&mut self) -> bool {
        self.update_counter = (self.update_counter + 1) % DEBUG_LOG_SAMPLE_RATE;
        self.update_counter == 0
    }

    
    fn has_node_changed_significantly(
        &mut self,
        node_id: &str,
        new_position: Vec3Data,
        new_velocity: Vec3Data,
    ) -> bool {
        let position_changed = if let Some(last_position) = self.last_sent_positions.get(node_id) {
            
            let dx = new_position.x - last_position.x;
            let dy = new_position.y - last_position.y;
            let dz = new_position.z - last_position.z;
            let distance_squared = dx * dx + dy * dy + dz * dz;

            
            distance_squared > self.position_deadband * self.position_deadband
        } else {
            
            true
        };

        let velocity_changed = if let Some(last_velocity) = self.last_sent_velocities.get(node_id) {
            
            let dvx = new_velocity.x - last_velocity.x;
            let dvy = new_velocity.y - last_velocity.y;
            let dvz = new_velocity.z - last_velocity.z;
            let velocity_change_squared = dvx * dvx + dvy * dvy + dvz * dvz;

            
            velocity_change_squared > self.velocity_deadband * self.velocity_deadband
        } else {
            
            true
        };

        
        if position_changed || velocity_changed {
            self.last_sent_positions
                .insert(node_id.to_string(), new_position);
            self.last_sent_velocities
                .insert(node_id.to_string(), new_velocity);
            return true;
        }

        false
    }

    
    fn get_current_update_interval(&self) -> std::time::Duration {
        let millis = (1000.0 / self.current_update_rate as f64) as u64;
        std::time::Duration::from_millis(millis)
    }

    
    fn calculate_motion_percentage(&self) -> f32 {
        if self.total_node_count == 0 {
            return 0.0;
        }

        (self.nodes_in_motion as f32) / (self.total_node_count as f32)
    }

    
    fn update_dynamic_rate(&mut self) {
        
        let now = Instant::now();
        let batch_window = std::time::Duration::from_millis(BATCH_UPDATE_WINDOW_MS);
        let elapsed = now.duration_since(self.last_batch_time);

        
        if elapsed >= batch_window {
            
            let motion_pct = self.calculate_motion_percentage();

            
            if motion_pct > self.motion_threshold {
                
                self.current_update_rate = ((self.current_update_rate as f32) * self.motion_damping
                    + (self.max_update_rate as f32) * (1.0 - self.motion_damping))
                    as u32;
            } else {
                
                self.current_update_rate = ((self.current_update_rate as f32) * self.motion_damping
                    + (self.min_update_rate as f32) * (1.0 - self.motion_damping))
                    as u32;
            }

            
            self.current_update_rate = self
                .current_update_rate
                .clamp(self.min_update_rate, self.max_update_rate);

            
            self.last_motion_check = now;
        }
    }

    
    

    
    
    

    
    
    
    
    

    
    
}

impl Actor for SocketFlowServer {
    type Context = ws::WebsocketContext<Self>;

    fn started(&mut self, ctx: &mut Self::Context) {
        let client_ip = self.client_ip.clone();
        let cm_addr = self.client_manager_addr.clone();
        let addr = ctx.address();
        let is_reconnection = self.is_reconnection;
        let addr_clone = addr.clone();

        actix::spawn(async move {
            use crate::actors::messages::RegisterClient;
            match cm_addr.send(RegisterClient { addr: addr_clone }).await {
                Ok(Ok(id)) => {
                    addr.do_send(SetClientId(id));
                }
                Ok(Err(e)) => {
                    error!("ClientManagerActor failed to register client: {}", e);
                }
                Err(e) => {
                    error!(
                        "Failed to send RegisterClient message to ClientManagerActor: {}",
                        e
                    );
                }
            }
        });

        info!(
            "[WebSocket] {} client connected from {}",
            if is_reconnection {
                "Reconnecting"
            } else {
                "New"
            },
            client_ip
        );
        self.last_activity = std::time::Instant::now();

        // Note: client_id is assigned asynchronously via SetClientId message after RegisterClient completes
        // We don't reset it here to avoid race conditions - it will be set by the async handler

        if !self.heartbeat_timer_set {
            ctx.run_interval(std::time::Duration::from_secs(5), |act, ctx| {
                
                trace!("[WebSocket] Sending server heartbeat ping");
                ctx.ping(b"");

                
                act.last_activity = std::time::Instant::now();
            });
            self.heartbeat_timer_set = true;
        }

        
        self.send_full_state_sync(ctx);
        self.state_synced = true;


        let response = serde_json::json!({
            "type": "connection_established",
            "timestamp": chrono::Utc::now().timestamp_millis(),
            "is_reconnection": is_reconnection,
            "state_sync_sent": true,
            "protocol": {
                "supported": [2, 3],
                "preferred": 3
            }
        });

        if let Ok(msg_str) = serde_json::to_string(&response) {
            ctx.text(msg_str);
            self.last_activity = std::time::Instant::now();
        }

        
        let loading_msg = serde_json::json!({
            "type": "loading",
            "message": if is_reconnection { "Restoring state..." } else { "Calculating initial layout..." }
        });
        ctx.text(serde_json::to_string(&loading_msg).unwrap_or_default());
        self.last_activity = std::time::Instant::now();
    }

    fn stopped(&mut self, _ctx: &mut Self::Context) {
        
        if let Some(client_id) = self.client_id {
            let cm_addr = self.client_manager_addr.clone();
            actix::spawn(async move {
                use crate::actors::messages::UnregisterClient;
                if let Err(e) = cm_addr.send(UnregisterClient { client_id }).await {
                    error!("Failed to unregister client from ClientManagerActor: {}", e);
                }
            });
            info!("[WebSocket] Client {} disconnected", client_id);
        }
    }
}

// Helper function to fetch nodes without borrowing from the actor
// Update signature to work with actor system
async fn fetch_nodes(
    app_state: Arc<AppState>,
    _settings_addr: actix::Addr<crate::actors::optimized_settings_actor::OptimizedSettingsActor>,
) -> Option<(Vec<(u32, BinaryNodeData)>, bool)> {
    
    use crate::actors::messages::GetGraphData;
    let graph_data = match app_state.graph_service_addr.send(GetGraphData).await {
        Ok(Ok(data)) => data,
        Ok(Err(e)) => {
            error!("[WebSocket] Failed to get graph data: {}", e);
            return None;
        }
        Err(e) => {
            error!(
                "[WebSocket] Failed to send message to GraphServiceActor: {}",
                e
            );
            return None;
        }
    };

    if graph_data.nodes.is_empty() {
        debug!("[WebSocket] No nodes to send! Empty graph data.");
        return None;
    }

    
    let debug_enabled = crate::utils::logging::is_debug_enabled();
    let debug_websocket = debug_enabled; 
    let detailed_debug = debug_enabled && debug_websocket;

    if detailed_debug {
        debug!(
            "Raw nodes count: {}, showing first 5 nodes IDs:",
            graph_data.nodes.len()
        );
        for (i, node) in graph_data.nodes.iter().take(5).enumerate() {
            debug!(
                "  Node {}: id={} (numeric), metadata_id={} (filename)",
                i, node.id, node.metadata_id
            );
        }
    }

    let mut nodes = Vec::with_capacity(graph_data.nodes.len());
    for node in &graph_data.nodes {
        
        
        let node_id = node.id;
        let node_data =
            BinaryNodeDataClient::new(node_id, node.data.position(), node.data.velocity());
        nodes.push((node_id, node_data));
    }

    if nodes.is_empty() {
        return None;
    }

    
    Some((nodes, detailed_debug))
}

impl StreamHandler<Result<ws::Message, ws::ProtocolError>> for SocketFlowServer {
    fn handle(&mut self, msg: Result<ws::Message, ws::ProtocolError>, ctx: &mut Self::Context) {
        match msg {
            Ok(ws::Message::Ping(msg)) => {
                debug!("[WebSocket] Received standard ping");
                self.last_activity = std::time::Instant::now();
                ctx.pong(&msg);
            }
            Ok(ws::Message::Pong(_)) => {
                
                
                self.last_activity = std::time::Instant::now();
            }
            Ok(ws::Message::Text(text)) => {
                info!("Received text message: {}", text);
                self.last_activity = std::time::Instant::now();
                match serde_json::from_str::<serde_json::Value>(&text) {
                    Ok(msg) => {
                        match msg.get("type").and_then(|t| t.as_str()) {
                            Some("ping") => {
                                if let Ok(ping_msg) =
                                    serde_json::from_value::<PingMessage>(msg.clone())
                                {
                                    let pong = self.handle_ping(ping_msg);
                                    self.last_activity = std::time::Instant::now();
                                    if let Ok(response) = serde_json::to_string(&pong) {
                                        ctx.text(response);
                                    }
                                } else if let Some(text_ping) = msg.as_str() {
                                    if text_ping == "ping" {
                                        self.last_activity = std::time::Instant::now();
                                        ctx.text("pong");
                                    }
                                }
                            }
                            Some("update_physics_params") => {
                                warn!("Client attempted deprecated WebSocket physics update - ignoring");
                                ctx.text(r#"{"type":"error","message":"Physics updates must use REST API: POST /api/analytics/params"}"#);
                            }
                            Some("request_full_snapshot") => {
                                info!("Client requested full position snapshot");

                                
                                let include_knowledge = msg
                                    .get("graphs")
                                    .and_then(|g| g.as_array())
                                    .map_or(true, |arr| {
                                        arr.iter().any(|v| v.as_str() == Some("knowledge"))
                                    });
                                let include_agent = msg
                                    .get("graphs")
                                    .and_then(|g| g.as_array())
                                    .map_or(true, |arr| {
                                        arr.iter().any(|v| v.as_str() == Some("agent"))
                                    });


                                let fut = async move {
                                    use crate::actors::messages::RequestPositionSnapshot;
                                    // Log position snapshot request (GraphServiceSupervisor doesn't implement Handler<RequestPositionSnapshot>)
                                    debug!("RequestPositionSnapshot: include_knowledge={}, include_agent={}",
                                           include_knowledge, include_agent);
                                    // Return empty snapshot as GraphServiceSupervisor handler not implemented
                                    crate::actors::messages::PositionSnapshot {
                                        knowledge_nodes: Vec::new(),
                                        agent_nodes: Vec::new(),
                                        timestamp: std::time::Instant::now(),
                                    }
                                };

                                let fut = actix::fut::wrap_future::<_, Self>(fut);
                                ctx.spawn(fut.map(move |snapshot, _act, ctx| {
                                    let mut all_nodes = Vec::new();

                                    // Add knowledge nodes
                                    for (id, data) in snapshot.knowledge_nodes {
                                        all_nodes.push((
                                            binary_protocol::set_knowledge_flag(id),
                                            data,
                                        ));
                                    }

                                    // Add agent nodes
                                    for (id, data) in snapshot.agent_nodes {
                                        all_nodes.push((
                                            binary_protocol::set_agent_flag(id),
                                            data,
                                        ));
                                    }

                                    if !all_nodes.is_empty() {
                                        let binary_data =
                                            binary_protocol::encode_node_data(&all_nodes);
                                        ctx.binary(binary_data);
                                        info!(
                                            "Sent position snapshot with {} nodes",
                                            all_nodes.len()
                                        );
                                    }
                                }));
                            }
                            Some("requestInitialData") => {
                                info!("Client requested initial data - unified init flow expects REST call first");

                                
                                
                                
                                let response = serde_json::json!({
                                    "type": "initialDataInfo",
                                    "message": "Please call REST endpoint /api/graph/data first, which will trigger WebSocket sync",
                                    "flow": "unified_init",
                                    "timestamp": chrono::Utc::now().timestamp_millis()
                                });

                                if let Ok(msg_str) = serde_json::to_string(&response) {
                                    self.last_activity = std::time::Instant::now();
                                    ctx.text(msg_str);
                                }
                            }
                            Some("enableRandomization") => {
                                if let Ok(enable_msg) =
                                    serde_json::from_value::<serde_json::Value>(msg.clone())
                                {
                                    let enabled = enable_msg
                                        .get("enabled")
                                        .and_then(|e| e.as_bool())
                                        .unwrap_or(false);
                                    info!("Client requested to {} node position randomization (server-side randomization removed)",
                                         if enabled { "enable" } else { "disable" });

                                    
                                    
                                    actix::spawn(async move {
                                        
                                        info!("Node position randomization request acknowledged, but server-side randomization is no longer supported");
                                        info!("Client-side randomization is now used instead");
                                    });
                                }
                            }
                            Some("requestBotsGraph") => {
                                info!("Client requested bots graph - returning optimized position data only");

                                
                                let graph_addr = self.app_state.graph_service_addr.clone();

                                ctx.spawn(actix::fut::wrap_future::<_, Self>(async move {
                                    
                                    use crate::actors::messages::GetBotsGraphData;
                                    match graph_addr.send(GetBotsGraphData).await {
                                        Ok(Ok(graph_data)) => Some(graph_data),
                                        _ => None
                                    }
                                }).map(|graph_data_opt, _act, ctx| {
                                    if let Some(graph_data) = graph_data_opt {
                                        
                                        let minimal_nodes: Vec<serde_json::Value> = graph_data.nodes.iter().map(|node| {
                                            serde_json::json!({
                                                "id": node.id,
                                                "metadata_id": node.metadata_id,
                                                "x": node.data.x,
                                                "y": node.data.y,
                                                "z": node.data.z,
                                                "vx": node.data.vx,
                                                "vy": node.data.vy,
                                                "vz": node.data.vz
                                            })
                                        }).collect();

                                        let minimal_edges: Vec<serde_json::Value> = graph_data.edges.iter().map(|edge| {
                                            serde_json::json!({
                                                "id": edge.id,
                                                "source": edge.source,
                                                "target": edge.target,
                                                "weight": edge.weight
                                            })
                                        }).collect();

                                        let response = serde_json::json!({
                                            "type": "botsGraphUpdate",
                                            "data": {
                                                "nodes": minimal_nodes,
                                                "edges": minimal_edges,
                                            },
                                            "meta": {
                                                "optimized": true,
                                                "message": "This response contains only position data. For full agent details:",
                                                "api_endpoints": {
                                                    "full_agent_data": "/api/bots/data",
                                                    "agent_status": "/api/bots/status",
                                                    "individual_agent": "/api/agents/{id}"
                                                }
                                            },
                                            "timestamp": chrono::Utc::now().timestamp_millis()
                                        });

                                        if let Ok(msg_str) = serde_json::to_string(&response) {
                                            let original_size = graph_data.nodes.len() * 500; 
                                            let optimized_size = msg_str.len();
                                            info!("Sending optimized bots graph: {} nodes, {} edges ({} bytes, est. {}% reduction)",
                                                minimal_nodes.len(), minimal_edges.len(), optimized_size,
                                                if original_size > 0 { 100 - (optimized_size * 100 / original_size) } else { 0 });
                                            ctx.text(msg_str);
                                        }
                                    } else {
                                        warn!("No bots graph data available");
                                        let response = serde_json::json!({
                                            "type": "botsGraphUpdate",
                                            "error": "No data available",
                                            "meta": {
                                                "api_endpoints": {
                                                    "full_agent_data": "/api/bots/data",
                                                    "agent_status": "/api/bots/status"
                                                }
                                            },
                                            "timestamp": chrono::Utc::now().timestamp_millis()
                                        });
                                        if let Ok(msg_str) = serde_json::to_string(&response) {
                                            ctx.text(msg_str);
                                        }
                                    }
                                }));
                            }
                            Some("requestBotsPositions") => {
                                info!("Client requested bots position updates");

                                
                                let app_state = self.app_state.clone();

                                ctx.spawn(
                                    actix::fut::wrap_future::<_, Self>(async move {
                                        
                                        let bots_nodes =
                                            crate::handlers::bots_handler::get_bots_positions(
                                                &app_state.bots_client,
                                            )
                                            .await;

                                        if bots_nodes.is_empty() {
                                            return vec![];
                                        }

                                        
                                        let mut nodes_data = Vec::new();
                                        for node in bots_nodes {
                                            let node_data = BinaryNodeData {
                                                node_id: node.id,
                                                x: node.data.x,
                                                y: node.data.y,
                                                z: node.data.z,
                                                vx: node.data.vx,
                                                vy: node.data.vy,
                                                vz: node.data.vz,
                                            };
                                            nodes_data.push((node.id, node_data));
                                        }

                                        nodes_data
                                    })
                                    .map(
                                        |nodes_data, _act, ctx| {
                                            if !nodes_data.is_empty() {
                                                
                                                let binary_data =
                                                    binary_protocol::encode_node_data(&nodes_data);

                                                info!(
                                                    "Sending bots positions: {} nodes, {} bytes",
                                                    nodes_data.len(),
                                                    binary_data.len()
                                                );

                                                ctx.binary(binary_data);
                                            }
                                        },
                                    ),
                                );

                                
                                let response = serde_json::json!({
                                    "type": "botsUpdatesStarted",
                                    "timestamp": chrono::Utc::now().timestamp_millis()
                                });
                                if let Ok(msg_str) = serde_json::to_string(&response) {
                                    ctx.text(msg_str);
                                }
                            }
                            Some("subscribe_position_updates") => {
                                info!("Client requested position update subscription");

                                
                                let interval = msg
                                    .get("data")
                                    .and_then(|data| data.get("interval"))
                                    .and_then(|interval| interval.as_u64())
                                    .unwrap_or(60); 

                                let binary = msg
                                    .get("data")
                                    .and_then(|data| data.get("binary"))
                                    .and_then(|binary| binary.as_bool())
                                    .unwrap_or(true); 

                                
                                let min_allowed_interval = 1000
                                    / (EndpointRateLimits::socket_flow_updates()
                                        .requests_per_minute
                                        / 60);
                                let actual_interval = interval.max(min_allowed_interval as u64);

                                if actual_interval != interval {
                                    info!("Adjusted position update interval from {}ms to {}ms to comply with rate limits",
                                        interval, actual_interval);
                                }

                                info!(
                                    "Starting position updates with interval: {}ms, binary: {}",
                                    actual_interval, binary
                                );

                                
                                let update_interval =
                                    std::time::Duration::from_millis(actual_interval);
                                let app_state = self.app_state.clone();
                                let settings_addr = self.app_state.settings_addr.clone();

                                
                                let response = serde_json::json!({
                                    "type": "subscription_confirmed",
                                    "subscription": "position_updates",
                                    "interval": actual_interval,
                                    "binary": binary,
                                    "timestamp": chrono::Utc::now().timestamp_millis(),
                                    "rate_limit": {
                                        "requests_per_minute": EndpointRateLimits::socket_flow_updates().requests_per_minute,
                                        "min_interval_ms": min_allowed_interval
                                    }
                                });
                                if let Ok(msg_str) = serde_json::to_string(&response) {
                                    ctx.text(msg_str);
                                }

                                
                                ctx.run_later(update_interval, move |_act, ctx| {
                                    
                                    let fut = fetch_nodes(app_state.clone(), settings_addr.clone());
                                    let fut = actix::fut::wrap_future::<_, Self>(fut);

                                    ctx.spawn(fut.map(move |result, act, ctx| {
                                        if let Some((nodes, detailed_debug)) = result {
                                            
                                            let mut filtered_nodes = Vec::new();
                                            for (node_id, node_data) in &nodes {
                                                let node_id_str = node_id.to_string();
                                                let position = node_data.position();
                                                let velocity = node_data.velocity();

                                                
                                                if act.has_node_changed_significantly(
                                                    &node_id_str,
                                                    position.clone(),
                                                    velocity.clone()
                                                ) {
                                                    filtered_nodes.push((*node_id, node_data.clone()));
                                                }
                                            }

                                            
                                            if !filtered_nodes.is_empty() {
                                                
                                                let binary_data = binary_protocol::encode_node_data(&filtered_nodes);

                                                
                                                act.total_node_count = filtered_nodes.len();
                                                let moving_nodes = filtered_nodes.iter()
                                                    .filter(|(_, node_data)| {
                                                        let vel = node_data.velocity();
                                                        vel.x.abs() > 0.001 || vel.y.abs() > 0.001 || vel.z.abs() > 0.001
                                                    })
                                                    .count();
                                                act.nodes_in_motion = moving_nodes;

                                                
                                                act.last_transfer_size = binary_data.len();
                                                act.total_bytes_sent += binary_data.len();
                                                act.update_count += 1;
                                                act.nodes_sent_count += filtered_nodes.len();

                                                if detailed_debug {
                                                    debug!("[Position Updates] Sending {} nodes, {} bytes",
                                                           filtered_nodes.len(), binary_data.len());
                                                }

                                                ctx.binary(binary_data);
                                            }

                                            
                                            let next_interval = std::time::Duration::from_millis(actual_interval);
                                            ctx.run_later(next_interval, move |act, ctx| {
                                                
                                                let subscription_msg = format!(
                                                    "{{\"type\":\"subscribe_position_updates\",\"data\":{{\"interval\":{},\"binary\":{}}}}}",
                                                    actual_interval, binary
                                                );
                                                <SocketFlowServer as StreamHandler<Result<ws::Message, ws::ProtocolError>>>::handle(
                                                    act,
                                                    Ok(ws::Message::Text(subscription_msg.into())),
                                                    ctx
                                                );
                                            });
                                        }
                                    }));
                                });
                            }
                            Some("requestPositionUpdates") => {
                                info!("Client requested position updates (legacy format)");
                                
                                let subscription_msg = r#"{"type":"subscribe_position_updates","data":{"interval":60,"binary":true}}"#;
                                <SocketFlowServer as StreamHandler<
                                    Result<ws::Message, ws::ProtocolError>,
                                >>::handle(
                                    self,
                                    Ok(ws::Message::Text(subscription_msg.to_string().into())),
                                    ctx,
                                );
                            }
                            Some("authenticate") => {
                                info!("Client sent authenticate message");

                                let token = msg.get("token").and_then(|t| t.as_str()).map(String::from);
                                let pubkey = msg.get("pubkey").and_then(|p| p.as_str()).map(String::from);

                                if let (Some(token), Some(pubkey)) = (token, pubkey) {
                                    let nostr_service = self.app_state.nostr_service.clone();
                                    let client_id = self.client_id;
                                    let cm_addr = self.client_manager_addr.clone();

                                    // Validate and load user
                                    ctx.spawn(actix::fut::wrap_future::<_, Self>(async move {
                                        if let Some(ref ns) = nostr_service {
                                            if let Some(user) = ns.get_session(&token).await {
                                                if user.pubkey == pubkey {
                                                    return (Some(user), client_id, cm_addr);
                                                }
                                            }
                                        }
                                        (None, client_id, cm_addr)
                                    }).map(|(user_opt, client_id, cm_addr), act, ctx| {
                                        if let Some(user) = user_opt {
                                            // Update local state
                                            act.pubkey = Some(user.pubkey.clone());
                                            act.is_power_user = user.is_power_user;

                                            // Update ClientCoordinator state
                                            if let Some(cid) = client_id {
                                                use crate::actors::messages::AuthenticateClient;
                                                cm_addr.do_send(AuthenticateClient {
                                                    client_id: cid,
                                                    pubkey: user.pubkey.clone(),
                                                    is_power_user: user.is_power_user,
                                                });
                                            }

                                            // Send confirmation
                                            let response = serde_json::json!({
                                                "type": "authenticate_success",
                                                "pubkey": user.pubkey,
                                                "is_power_user": user.is_power_user,
                                                "timestamp": chrono::Utc::now().timestamp_millis()
                                            });
                                            if let Ok(msg_str) = serde_json::to_string(&response) {
                                                ctx.text(msg_str);
                                            }

                                            info!("Client authenticated: pubkey={}, power_user={}", user.pubkey, user.is_power_user);
                                        } else {
                                            let error_msg = serde_json::json!({
                                                "type": "error",
                                                "message": "Authentication failed: invalid token or pubkey mismatch"
                                            });
                                            if let Ok(msg_str) = serde_json::to_string(&error_msg) {
                                                ctx.text(msg_str);
                                            }
                                            warn!("Authentication failed for client");
                                        }
                                    }));
                                } else {
                                    let error_msg = serde_json::json!({
                                        "type": "error",
                                        "message": "Authentication requires both 'token' and 'pubkey'"
                                    });
                                    if let Ok(msg_str) = serde_json::to_string(&error_msg) {
                                        ctx.text(msg_str);
                                    }
                                }
                            }
                            Some("filter_update") => {
                                info!("Client sent filter_update message");

                                if let Some(client_id) = self.client_id {
                                    // Check both nested "filter" key and "data" key (client sends in data)
                                    let filter_data = msg.get("filter")
                                        .or_else(|| msg.get("data"))
                                        .unwrap_or(&msg);

                                    use crate::actors::messages::UpdateClientFilter;
                                    let update = UpdateClientFilter {
                                        client_id,
                                        enabled: filter_data.get("enabled").and_then(|v| v.as_bool()).unwrap_or(false),
                                        quality_threshold: filter_data.get("quality_threshold").and_then(|v| v.as_f64()).unwrap_or(0.7),
                                        authority_threshold: filter_data.get("authority_threshold").and_then(|v| v.as_f64()).unwrap_or(0.5),
                                        filter_by_quality: filter_data.get("filter_by_quality").and_then(|v| v.as_bool()).unwrap_or(true),
                                        filter_by_authority: filter_data.get("filter_by_authority").and_then(|v| v.as_bool()).unwrap_or(false),
                                        filter_mode: filter_data.get("filter_mode").and_then(|v| v.as_str()).unwrap_or("or").to_string(),
                                        max_nodes: filter_data.get("max_nodes").and_then(|v| v.as_i64()).map(|n| n as i32),
                                    };

                                    info!("Processing filter update: enabled={}, quality_threshold={}, filter_by_quality={}",
                                          update.enabled, update.quality_threshold, update.filter_by_quality);

                                    let cm_addr = self.client_manager_addr.clone();
                                    let pubkey = self.pubkey.clone();

                                    // Send to ClientCoordinator
                                    ctx.spawn(actix::fut::wrap_future::<_, Self>(async move {
                                        match cm_addr.send(update.clone()).await {
                                            Ok(Ok(())) => {
                                                (true, pubkey, update)
                                            }
                                            Ok(Err(e)) => {
                                                error!("Failed to update client filter: {}", e);
                                                (false, pubkey, update)
                                            }
                                            Err(e) => {
                                                error!("Failed to send filter update: {}", e);
                                                (false, pubkey, update)
                                            }
                                        }
                                    }).map(|(success, pubkey_opt, update), act, ctx| {
                                        if success {
                                            // Also persist to Neo4j if authenticated
                                            if let Some(pubkey) = pubkey_opt {
                                                info!("Filter updated for pubkey {}: enabled={}, max_nodes={:?}",
                                                      pubkey, update.enabled, update.max_nodes);

                                                // Save to Neo4j asynchronously
                                                let neo4j_repo = act.app_state.neo4j_settings_repository.clone();
                                                let pubkey_clone = pubkey.clone();
                                                use crate::adapters::neo4j_settings_repository::UserFilter;
                                                let filter = UserFilter {
                                                    pubkey: pubkey_clone.clone(),
                                                    enabled: update.enabled,
                                                    quality_threshold: update.quality_threshold,
                                                    authority_threshold: update.authority_threshold,
                                                    filter_by_quality: update.filter_by_quality,
                                                    filter_by_authority: update.filter_by_authority,
                                                    filter_mode: update.filter_mode.clone(),
                                                    max_nodes: update.max_nodes,
                                                    updated_at: chrono::Utc::now(),
                                                };

                                                ctx.spawn(actix::fut::wrap_future::<_, Self>(async move {
                                                    match neo4j_repo.save_user_filter(&pubkey_clone, &filter).await {
                                                        Ok(()) => {
                                                            info!(" Filter persisted to Neo4j for pubkey: {}", pubkey_clone);
                                                        }
                                                        Err(e) => {
                                                            error!(" Failed to persist filter to Neo4j: {}", e);
                                                        }
                                                    }
                                                }).map(|_result, _act, _ctx| ()));
                                            }

                                            let response = serde_json::json!({
                                                "type": "filter_update_success",
                                                "enabled": update.enabled,
                                                "timestamp": chrono::Utc::now().timestamp_millis()
                                            });
                                            if let Ok(msg_str) = serde_json::to_string(&response) {
                                                ctx.text(msg_str);
                                            }
                                        } else {
                                            let error_msg = serde_json::json!({
                                                "type": "error",
                                                "message": "Failed to update filter"
                                            });
                                            if let Ok(msg_str) = serde_json::to_string(&error_msg) {
                                                ctx.text(msg_str);
                                            }
                                        }
                                    }));
                                } else {
                                    // Client ID not yet assigned - registration still in progress
                                    warn!("filter_update received but client_id not yet assigned - registration may still be in progress");
                                    let error_msg = serde_json::json!({
                                        "type": "error",
                                        "message": "Client registration in progress, please retry filter update in a moment"
                                    });
                                    if let Ok(msg_str) = serde_json::to_string(&error_msg) {
                                        ctx.text(msg_str);
                                    }
                                }
                            }
                            Some("requestSwarmTelemetry") => {
                                info!("Client requested enhanced swarm telemetry");

                                let app_state = self.app_state.clone();

                                ctx.spawn(actix::fut::wrap_future::<_, Self>(async move {
                                    
                                    match crate::handlers::bots_handler::fetch_hive_mind_agents(&app_state, None).await {
                                        Ok(agents) => {
                                            let mut nodes_data = Vec::new();
                                            let mut swarm_metrics = serde_json::json!({
                                                "total_agents": agents.len(),
                                                "active_agents": 0,
                                                "avg_health": 0.0,
                                                "avg_cpu": 0.0,
                                                "avg_workload": 0.0,
                                                "total_tokens": 0,
                                                "swarm_ids": std::collections::HashSet::<String>::new(),
                                            });

                                            let mut active_count = 0;
                                            let mut total_health = 0.0;
                                            let mut total_cpu = 0.0;
                                            let mut total_workload = 0.0;
                                            let total_tokens = 0;
                                            let swarm_ids: std::collections::HashSet<String> = std::collections::HashSet::new();

                                            for (idx, agent) in agents.iter().enumerate() {
                                                if agent.status == "active" {
                                                    active_count += 1;
                                                }
                                                total_health += agent.health;
                                                total_cpu += agent.cpu_usage;
                                                total_workload += agent.workload;
                                                
                                                
                                                
                                                
                                                

                                                
                                                let position = Vec3Data::new(
                                                    (idx as f32 * 100.0).sin() * 500.0,
                                                    (idx as f32 * 100.0).cos() * 500.0,
                                                    0.0
                                                );

                                                let node_data = BinaryNodeData {
                                                    node_id: (1000 + idx) as u32,
                                                    x: position.x,
                                                    y: position.y,
                                                    z: position.z,
                                                    vx: 0.0,
                                                    vy: 0.0,
                                                    vz: 0.0,
                                                };
                                                nodes_data.push(((1000 + idx) as u32, node_data));
                                            }

                                            
                                            if !agents.is_empty() {
                                                swarm_metrics["active_agents"] = serde_json::json!(active_count);
                                                swarm_metrics["avg_health"] = serde_json::json!(total_health / agents.len() as f32);
                                                swarm_metrics["avg_cpu"] = serde_json::json!(total_cpu / agents.len() as f32);
                                                swarm_metrics["avg_workload"] = serde_json::json!(total_workload / agents.len() as f32);
                                                swarm_metrics["total_tokens"] = serde_json::json!(total_tokens);
                                                swarm_metrics["swarm_count"] = serde_json::json!(swarm_ids.len());
                                            }

                                            (nodes_data, swarm_metrics)
                                        }
                                        Err(_) => (vec![], serde_json::json!({}))
                                    }
                                }).map(|(nodes_data, swarm_metrics), _act, ctx| {
                                    
                                    if !nodes_data.is_empty() {
                                        let binary_data = binary_protocol::encode_node_data(&nodes_data);
                                        ctx.binary(binary_data);
                                    }

                                    
                                    let telemetry_response = serde_json::json!({
                                        "type": "swarmTelemetry",
                                        "timestamp": chrono::Utc::now().timestamp_millis(),
                                        "data_source": "live",
                                        "metrics": swarm_metrics,
                                        "node_count": nodes_data.len()
                                    });

                                    if let Ok(msg_str) = serde_json::to_string(&telemetry_response) {
                                        ctx.text(msg_str);
                                    }
                                }));
                            }
                            _ => {
                                warn!("[WebSocket] Unknown message type: {:?}", msg);
                            }
                        }
                    }
                    Err(e) => {
                        warn!("[WebSocket] Failed to parse text message: {}", e);
                        let error_msg = serde_json::json!({
                            "type": "error",
                            "message": format!("Failed to parse text message: {}", e)
                        });
                        if let Ok(msg_str) = serde_json::to_string(&error_msg) {
                            ctx.text(msg_str);
                        }
                    }
                }
            }
            Ok(ws::Message::Binary(data)) => {
                
                if !WEBSOCKET_RATE_LIMITER.is_allowed(&self.client_ip) {
                    warn!(
                        "Position update rate limit exceeded for client: {}",
                        self.client_ip
                    );
                    let error_msg = serde_json::json!({
                        "type": "rate_limit_warning",
                        "message": "Update rate too high, some updates may be dropped",
                        "retry_after": WEBSOCKET_RATE_LIMITER.reset_time(&self.client_ip).as_secs()
                    });
                    if let Ok(msg_str) = serde_json::to_string(&error_msg) {
                        ctx.text(msg_str);
                    }
                    
                    return;
                }

                
                info!("Received binary message, length: {}", data.len());
                self.last_activity = std::time::Instant::now();

                
                use crate::utils::binary_protocol::{BinaryProtocol, Message as ProtocolMessage};

                match BinaryProtocol::decode_message(&data) {
                    Ok(ProtocolMessage::GraphUpdate { graph_type, nodes }) => {
                        info!(
                            "Received graph update: type={:?}, nodes={}",
                            graph_type,
                            nodes.len()
                        );

                        
                        let app_state = self.app_state.clone();
                        let graph_type_clone = graph_type;

                        let fut = async move {
                            
                            for (node_id_str, data) in nodes {
                                if let Ok(node_id) = node_id_str.parse::<u32>() {
                                    debug!("Updating node {} from graph {:?}: pos=[{:.3}, {:.3}, {:.3}]",
                                           node_id, graph_type_clone, data[0], data[1], data[2]);


                                    use crate::types::vec3::Vec3Data;
                                    use glam::Vec3;

                                    let position: Vec3 = Vec3Data::new(data[0], data[1], data[2]).into();
                                    let velocity: Vec3 = Vec3Data::new(data[3], data[4], data[5]).into();

                                    // Log node position update (GraphServiceSupervisor doesn't implement Handler<UpdateNodePosition>)
                                    debug!("UpdateNodePosition: node_id={}, position=[{:.3}, {:.3}, {:.3}], velocity=[{:.3}, {:.3}, {:.3}]",
                                           node_id, data[0], data[1], data[2], data[3], data[4], data[5]);
                                }
                            }

                            info!("Processed graph update from client");
                        };

                        let fut = fut.into_actor(self);
                        ctx.spawn(fut.map(|_, _, _| ()));
                        return;
                    }
                    Ok(ProtocolMessage::VoiceData { audio }) => {
                        info!("Received voice data: {} bytes", audio.len());


                        let response = serde_json::json!({
                            "type": "voice_ack",
                            "bytes": audio.len(),
                            "message": "Voice data received but not yet processed"
                        });
                        if let Ok(msg_str) = serde_json::to_string(&response) {
                            ctx.text(msg_str);
                        }
                        return;
                    }
                    Ok(ProtocolMessage::BroadcastAck { sequence_id, nodes_received, timestamp }) => {
                        // True end-to-end backpressure: client confirms receipt of position broadcast
                        // Forward to ClientCoordinatorActor which routes to GPU for token restoration
                        use crate::actors::messages::ClientBroadcastAck;

                        trace!(
                            "Received BroadcastAck: seq={}, nodes={}, timestamp={}",
                            sequence_id, nodes_received, timestamp
                        );

                        // Send ACK to client coordinator for forwarding to GPU actor
                        self.client_manager_addr.do_send(ClientBroadcastAck {
                            sequence_id,
                            nodes_received,
                            timestamp,
                            client_id: self.client_id,
                        });
                        return;
                    }
                    Err(e) => {

                        debug!("New protocol decode failed ({}), trying legacy protocol", e);
                    }
                }

                
                
                
                

                match binary_protocol::decode_node_data(&data) {
                    Ok(nodes) => {
                        info!("Decoded {} nodes from binary message", nodes.len());
                        let _nodes_vec: Vec<_> = nodes.clone().into_iter().collect();

                        
                        
                        {
                            let app_state = self.app_state.clone();
                            let nodes_vec: Vec<_> = nodes.clone().into_iter().collect();

                            let fut = async move {
                                for (node_id, node_data) in &nodes_vec {
                                    
                                    if *node_id < 5 {
                                        debug!(
                                            "Processing binary update for node ID: {} with position [{:.3}, {:.3}, {:.3}]",
                                            node_id, node_data.x, node_data.y, node_data.z
                                        );
                                    }
                                }

                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                

                                
                                info!("Received {} node positions from client (feedback loop disabled)", nodes_vec.len());

                                info!("Updated node positions from binary data (preserving server-side properties)");

                                
                                info!("Preparing to recalculate layout after client-side node position update");

                                
                                use crate::actors::messages::GetSettingByPath;
                                let settings_addr = app_state.settings_addr.clone();

                                
                                if let Ok(Ok(_iterations_val)) = settings_addr
                                    .send(GetSettingByPath {
                                        path: "visualisation.graphs.logseq.physics.iterations"
                                            .to_string(),
                                    })
                                    .await
                                {
                                    if let Ok(Ok(_spring_val)) = settings_addr
                                        .send(GetSettingByPath {
                                            path: "visualisation.graphs.logseq.physics.spring_k"
                                                .to_string(),
                                        })
                                        .await
                                    {
                                        if let Ok(Ok(_repulsion_val)) = settings_addr
                                            .send(GetSettingByPath {
                                                path: "visualisation.graphs.logseq.physics.repel_k"
                                                    .to_string(),
                                            })
                                            .await
                                        {
                                            
                                            use crate::actors::messages::SimulationStep;
                                            if let Err(e) = app_state
                                                .graph_service_addr
                                                .send(SimulationStep)
                                                .await
                                            {
                                                error!("Failed to trigger simulation step: {}", e);
                                            } else {
                                                info!(
                                                    "Successfully triggered layout recalculation"
                                                );
                                            }
                                        }
                                    }
                                }
                            };

                            let fut = fut.into_actor(self);
                            ctx.spawn(fut.map(|_, _, _| ()));
                        }
                    }
                    Err(e) => {
                        error!("Failed to decode binary message: {}", e);
                        let error_msg = serde_json::json!({
                            "type": "error",
                            "message": format!("Failed to decode binary message: {}", e),
                            "recoverable": true,
                            "details": {
                                "data_length": data.len(),
                                "expected_item_size": 26,
                                "remainder": data.len() % 26
                            }
                        });
                        if let Ok(msg_str) = serde_json::to_string(&error_msg) {
                            ctx.text(msg_str);
                        }
                        
                    }
                }
            }
            Ok(ws::Message::Close(reason)) => {
                info!("[WebSocket] Client initiated close: {:?}", reason);
                ctx.close(reason); 
                ctx.stop();
            }
            Ok(ws::Message::Continuation(_)) => {
                warn!("[WebSocket] Received unexpected continuation frame");
            }
            Ok(ws::Message::Nop) => {
                debug!("[WebSocket] Received Nop");
            }
            Err(e) => {
                error!("[WebSocket] Error in WebSocket connection: {}", e);
                
                let error_msg = serde_json::json!({
                    "type": "error",
                    "message": format!("WebSocket error: {}", e),
                    "recoverable": true
                });
                if let Ok(msg_str) = serde_json::to_string(&error_msg) {
                    ctx.text(msg_str);
                }
                
            }
        }
    }
}

pub async fn socket_flow_handler(
    req: HttpRequest,
    stream: web::Payload,
    app_state_data: web::Data<AppState>, 
    pre_read_ws_settings: web::Data<PreReadSocketSettings>, 
) -> Result<HttpResponse, actix_web::Error> {
    
    let client_ip = extract_client_id(&req);


    if !WEBSOCKET_RATE_LIMITER.is_allowed(&client_ip) {
        warn!("WebSocket rate limit exceeded for client: {}", client_ip);
        return create_rate_limit_response(&client_ip, &WEBSOCKET_RATE_LIMITER);
    }

    // SECURITY: Validate Origin header to prevent cross-site WebSocket hijacking
    if let Some(origin_header) = req.headers().get("Origin") {
        let origin = origin_header.to_str().unwrap_or("");
        let allowed_origins = std::env::var("CORS_ALLOWED_ORIGINS")
            .unwrap_or_else(|_| {
                if std::env::var("ALLOW_INSECURE_DEFAULTS").is_ok() {
                    "http://localhost:3000,http://localhost:3001,http://127.0.0.1:3000,http://localhost:5173".to_string()
                } else {
                    "http://localhost:3000".to_string()
                }
            });

        let is_allowed = allowed_origins.split(',')
            .map(|s| s.trim())
            .any(|allowed| allowed == origin);

        if !is_allowed {
            warn!("WebSocket connection rejected - invalid origin: {} (allowed: {})", origin, allowed_origins);
            return Ok(HttpResponse::Forbidden()
                .body(format!("Origin '{}' not allowed for WebSocket connections", origin)));
        }
    } else if std::env::var("ALLOW_INSECURE_DEFAULTS").is_err() {
        // In production, require Origin header for WebSocket connections
        warn!("WebSocket connection rejected - missing Origin header from {}", client_ip);
        return Ok(HttpResponse::BadRequest()
            .body("Origin header required for WebSocket connections"));
    }

    let app_state_arc = app_state_data.into_inner(); 

    
    let client_manager_addr = app_state_arc.client_manager_addr.clone();

    
    use crate::actors::messages::GetSettingByPath;
    let settings_addr = app_state_arc.settings_addr.clone();

    let debug_enabled = match settings_addr
        .send(GetSettingByPath {
            path: "system.debug.enabled".to_string(),
        })
        .await
    {
        Ok(Ok(value)) => value.as_bool().unwrap_or(false),
        _ => false,
    };
    let debug_websocket = match settings_addr
        .send(GetSettingByPath {
            path: "system.debug.enable_websocket_debug".to_string(),
        })
        .await
    {
        Ok(Ok(value)) => value.as_bool().unwrap_or(false),
        _ => false,
    };
    let should_debug = debug_enabled && debug_websocket;

    if should_debug {
        debug!("WebSocket connection attempt from {:?}", req.peer_addr());
    }

    
    if !req.headers().contains_key("Upgrade") {
        return Ok(HttpResponse::BadRequest().body("WebSocket upgrade required"));
    }

    let is_reconnection = req
        .headers()
        .get("X-Client-Session")
        .and_then(|h| h.to_str().ok())
        .is_some();

    // Extract token from query string for authentication
    let token_from_qs = req.query_string()
        .split('&')
        .find_map(|param| {
            let parts: Vec<&str> = param.split('=').collect();
            if parts.len() == 2 && parts[0] == "token" {
                Some(parts[1].to_string())
            } else {
                None
            }
        });

    let mut ws = SocketFlowServer::new(
        app_state_arc.clone(),
        pre_read_ws_settings.get_ref().clone(),
        client_manager_addr,
        client_ip.clone(),
    );

    ws.is_reconnection = is_reconnection;

    // Try to authenticate from query string token
    if let Some(token) = token_from_qs {
        if let Some(ref nostr_service) = app_state_arc.nostr_service {
            if let Some(user) = nostr_service.get_session(&token).await {
                ws.pubkey = Some(user.pubkey.clone());
                ws.is_power_user = user.is_power_user;
                info!("Pre-authenticated WebSocket client via query string: pubkey={}", user.pubkey);
            }
        }
    }

    
    
    match ws::WsResponseBuilder::new(ws, &req, stream)
        .protocols(&["permessage-deflate"])
        .start()
    {
        Ok(response) => {
            info!(
                "[WebSocket] Client {} connected successfully with compression support",
                client_ip
            );
            Ok(response)
        }
        Err(e) => {
            error!(
                "[WebSocket] Failed to start WebSocket for client {}: {}",
                client_ip, e
            );
            Err(e)
        }
    }
}

--------------------------------------------------------------------------------
FILE: src/handlers/realtime_websocket_handler.rs
PURPOSE: Real-time WebSocket updates handler
--------------------------------------------------------------------------------
// Real-Time WebSocket Handler for All Feature Updates
// Handles workspace events, analysis progress, optimization status, and export notifications

use crate::app_state::AppState;
use actix::prelude::*;
use actix_web_actors::ws;
use log::{debug, error, info, warn};
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use std::collections::{HashMap, HashSet};
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};
use uuid::Uuid;

// Enhanced WebSocket message types
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RealtimeWebSocketMessage {
    #[serde(rename = "type")]
    pub msg_type: String,
    pub data: Value,
    pub timestamp: u64,
    pub client_id: Option<String>,
    pub session_id: Option<String>,
}

// Workspace event messages
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkspaceUpdateEvent {
    pub workspace_id: String,
    pub changes: Value,
    pub operation: String, 
    pub user_id: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkspaceDeletedEvent {
    pub workspace_id: String,
    pub user_id: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkspaceCollaborationEvent {
    pub workspace_id: String,
    pub action: String, 
    pub user_id: String,
    pub user_name: Option<String>,
    pub permissions: Option<Vec<String>>,
}

// Analysis event messages
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AnalysisProgressEvent {
    pub analysis_id: String,
    pub graph_id: Option<String>,
    pub progress: f64, 
    pub stage: String,
    pub estimated_time_remaining: Option<u64>,
    pub current_operation: String,
    pub metrics: Option<Value>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AnalysisCompleteEvent {
    pub analysis_id: String,
    pub graph_id: Option<String>,
    pub results: Value,
    pub success: bool,
    pub error: Option<String>,
    pub processing_time: f64,
}

// Optimization event messages
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OptimizationUpdateEvent {
    pub optimization_id: String,
    pub graph_id: Option<String>,
    pub progress: f64, 
    pub algorithm: String,
    pub current_iteration: u64,
    pub total_iterations: u64,
    pub metrics: Value,
    pub recommendations: Option<Vec<Value>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OptimizationResultEvent {
    pub optimization_id: String,
    pub graph_id: Option<String>,
    pub algorithm: String,
    pub confidence: f64,
    pub performance_gain: f64,
    pub clusters: u64,
    pub recommendations: Vec<Value>,
    pub layout_changes: Option<Value>,
    pub success: bool,
    pub error: Option<String>,
}

// Export event messages
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExportProgressEvent {
    pub export_id: String,
    pub graph_id: Option<String>,
    pub format: String,
    pub progress: f64, 
    pub stage: String, 
    pub size: Option<u64>,
    pub estimated_time_remaining: Option<u64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExportReadyEvent {
    pub export_id: String,
    pub graph_id: Option<String>,
    pub format: String,
    pub download_url: String,
    pub size: u64,
    pub expires_at: String,
    pub metadata: Value,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ShareCreatedEvent {
    pub share_id: String,
    pub graph_id: Option<String>,
    pub share_url: String,
    pub expires_at: Option<String>,
    pub password_protected: bool,
    pub permissions: Vec<String>,
    pub description: Option<String>,
}

// System notification messages
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SystemNotificationEvent {
    pub level: String, 
    pub title: String,
    pub message: String,
    pub actions: Option<Vec<Value>>,
    pub persistent: Option<bool>,
}

// Connection and subscription management
#[derive(Debug, Clone)]
pub struct ClientSubscription {
    pub client_id: String,
    pub subscriptions: HashSet<String>,   
    pub filters: HashMap<String, String>, 
    pub last_activity: Instant,
}

pub struct RealtimeWebSocketHandler {
    client_id: String,
    session_id: String,
    app_state: actix_web::web::Data<AppState>,
    subscriptions: HashSet<String>,
    filters: HashMap<String, String>,
    heartbeat: Instant,
    last_ping: Instant,
    message_count: u64,
    bytes_sent: u64,
    bytes_received: u64,
}

// Global connection manager for broadcasting
pub struct ConnectionManager {
    connections: HashMap<String, Addr<RealtimeWebSocketHandler>>,
    subscriptions: HashMap<String, HashSet<String>>, 
}

impl ConnectionManager {
    pub fn new() -> Self {
        Self {
            connections: HashMap::new(),
            subscriptions: HashMap::new(),
        }
    }

    pub fn add_connection(&mut self, client_id: String, addr: Addr<RealtimeWebSocketHandler>) {
        self.connections.insert(client_id.clone(), addr);
        info!("Added WebSocket connection for client: {}", client_id);
    }

    pub fn remove_connection(&mut self, client_id: &str) {
        self.connections.remove(client_id);
        
        for (_, client_ids) in self.subscriptions.iter_mut() {
            client_ids.remove(client_id);
        }
        info!("Removed WebSocket connection for client: {}", client_id);
    }

    pub fn subscribe(&mut self, client_id: String, event_type: String) {
        self.subscriptions
            .entry(event_type.clone())
            .or_insert_with(HashSet::new)
            .insert(client_id.clone());
        debug!("Client {} subscribed to {}", client_id, event_type);
    }

    pub fn unsubscribe(&mut self, client_id: &str, event_type: &str) {
        if let Some(client_ids) = self.subscriptions.get_mut(event_type) {
            client_ids.remove(client_id);
            debug!("Client {} unsubscribed from {}", client_id, event_type);
        }
    }

    pub async fn broadcast(&self, event_type: &str, message: RealtimeWebSocketMessage) {
        if let Some(client_ids) = self.subscriptions.get(event_type) {
            for client_id in client_ids {
                if let Some(addr) = self.connections.get(client_id) {
                    addr.do_send(BroadcastMessage {
                        message: message.clone(),
                    });
                }
            }
        }
    }
}

// Static connection manager instance
use lazy_static::lazy_static;
use tokio::sync::Mutex;

lazy_static! {
    /// Global connection manager for WebSocket broadcasting
    pub static ref CONNECTION_MANAGER: Mutex<ConnectionManager> = Mutex::new(ConnectionManager::new());
}

impl RealtimeWebSocketHandler {
    pub fn new(app_state: actix_web::web::Data<AppState>) -> Self {
        let client_id = Uuid::new_v4().to_string();
        let session_id = Uuid::new_v4().to_string();

        Self {
            client_id,
            session_id,
            app_state,
            subscriptions: HashSet::new(),
            filters: HashMap::new(),
            heartbeat: Instant::now(),
            last_ping: Instant::now(),
            message_count: 0,
            bytes_sent: 0,
            bytes_received: 0,
        }
    }

    fn current_timestamp() -> u64 {
        SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_millis() as u64
    }

    fn send_message(
        &mut self,
        ctx: &mut ws::WebsocketContext<Self>,
        message: RealtimeWebSocketMessage,
    ) {
        match serde_json::to_string(&message) {
            Ok(json_str) => {
                ctx.text(json_str.clone());
                self.message_count += 1;
                self.bytes_sent += json_str.len() as u64;

                if log::log_enabled!(log::Level::Debug) {
                    debug!("Sent message to {}: {}", self.client_id, message.msg_type);
                }
            }
            Err(e) => {
                error!("Failed to serialize message: {}", e);
            }
        }
    }

    fn handle_subscription(
        &mut self,
        ctx: &mut ws::WebsocketContext<Self>,
        event_type: String,
        filters: Option<HashMap<String, String>>,
    ) {
        self.subscriptions.insert(event_type.clone());

        if let Some(filter_map) = filters {
            for (key, value) in filter_map {
                self.filters
                    .insert(format!("{}:{}", event_type, key), value);
            }
        }

        
        let client_id = self.client_id.clone();
        let event_type_clone = event_type.clone();
        tokio::spawn(async move {
            let mut manager = CONNECTION_MANAGER.lock().await;
            manager.subscribe(client_id, event_type_clone);
        });

        
        let confirmation = RealtimeWebSocketMessage {
            msg_type: "subscription_confirmed".to_string(),
            data: json!({
                "event_type": event_type,
                "client_id": self.client_id,
                "filters_applied": !self.filters.is_empty()
            }),
            timestamp: Self::current_timestamp(),
            client_id: Some(self.client_id.clone()),
            session_id: Some(self.session_id.clone()),
        };

        self.send_message(ctx, confirmation);
        info!("Client {} subscribed to {}", self.client_id, event_type);
    }

    fn handle_unsubscription(&mut self, _ctx: &mut ws::WebsocketContext<Self>, event_type: String) {
        self.subscriptions.remove(&event_type);

        
        self.filters
            .retain(|key, _| !key.starts_with(&format!("{}:", event_type)));

        
        let client_id = self.client_id.clone();
        let event_type_clone = event_type.clone();
        tokio::spawn(async move {
            let mut manager = CONNECTION_MANAGER.lock().await;
            manager.unsubscribe(&client_id, &event_type_clone);
        });

        info!("Client {} unsubscribed from {}", self.client_id, event_type);
    }

    fn send_heartbeat(&mut self, ctx: &mut ws::WebsocketContext<Self>) {
        let heartbeat_msg = RealtimeWebSocketMessage {
            msg_type: "heartbeat".to_string(),
            data: json!({
                "server_time": Self::current_timestamp(),
                "client_id": self.client_id,
                "message_count": self.message_count,
                "bytes_sent": self.bytes_sent,
                "bytes_received": self.bytes_received,
                "active_subscriptions": self.subscriptions.len(),
                "uptime": self.heartbeat.elapsed().as_secs()
            }),
            timestamp: Self::current_timestamp(),
            client_id: Some(self.client_id.clone()),
            session_id: Some(self.session_id.clone()),
        };

        self.send_message(ctx, heartbeat_msg);
        self.last_ping = Instant::now();
    }
}

impl Actor for RealtimeWebSocketHandler {
    type Context = ws::WebsocketContext<Self>;

    fn started(&mut self, ctx: &mut Self::Context) {
        info!(
            "Real-time WebSocket handler started for client: {}",
            self.client_id
        );

        
        let client_id = self.client_id.clone();
        let ctx_address = ctx.address();
        tokio::spawn(async move {
            let mut manager = CONNECTION_MANAGER.lock().await;
            manager.add_connection(client_id, ctx_address);
        });

        
        ctx.run_interval(Duration::from_secs(30), |act, ctx| {
            act.send_heartbeat(ctx);
        });

        
        ctx.run_interval(Duration::from_secs(10), |act, ctx| {
            if Instant::now().duration_since(act.heartbeat) > Duration::from_secs(120) {
                warn!(
                    "Client {} heartbeat timeout, closing connection",
                    act.client_id
                );
                ctx.stop();
                return;
            }
        });

        
        let welcome_message = RealtimeWebSocketMessage {
            msg_type: "connection_established".to_string(),
            data: json!({
                "client_id": self.client_id,
                "session_id": self.session_id,
                "server_time": Self::current_timestamp(),
                "features": [
                    "workspace_events",
                    "analysis_progress",
                    "optimization_updates",
                    "export_notifications",
                    "system_notifications",
                    "real_time_collaboration"
                ]
            }),
            timestamp: Self::current_timestamp(),
            client_id: Some(self.client_id.clone()),
            session_id: Some(self.session_id.clone()),
        };

        self.send_message(ctx, welcome_message);
    }

    fn stopped(&mut self, _ctx: &mut Self::Context) {
        info!(
            "Real-time WebSocket handler stopped for client: {}",
            self.client_id
        );

        
        let client_id = self.client_id.clone();
        tokio::spawn(async move {
            let mut manager = CONNECTION_MANAGER.lock().await;
            manager.remove_connection(&client_id);
        });

        
        info!(
            "Final statistics for client {}: {} messages sent, {} bytes sent, {} bytes received",
            self.client_id, self.message_count, self.bytes_sent, self.bytes_received
        );
    }
}

impl StreamHandler<Result<ws::Message, ws::ProtocolError>> for RealtimeWebSocketHandler {
    fn handle(&mut self, msg: Result<ws::Message, ws::ProtocolError>, ctx: &mut Self::Context) {
        match msg {
            Ok(ws::Message::Text(text)) => {
                self.heartbeat = Instant::now();
                self.bytes_received += text.len() as u64;

                match serde_json::from_str::<RealtimeWebSocketMessage>(&text) {
                    Ok(ws_message) => match ws_message.msg_type.as_str() {
                        "subscribe" => {
                            if let (Ok(event_type), filters) = (
                                serde_json::from_value::<String>(
                                    ws_message
                                        .data
                                        .get("event_type")
                                        .unwrap_or(&Value::Null)
                                        .clone(),
                                ),
                                ws_message.data.get("filters").and_then(|f| {
                                    serde_json::from_value::<HashMap<String, String>>(f.clone())
                                        .ok()
                                }),
                            ) {
                                self.handle_subscription(ctx, event_type, filters);
                            }
                        }
                        "unsubscribe" => {
                            if let Ok(event_type) = serde_json::from_value::<String>(
                                ws_message
                                    .data
                                    .get("event_type")
                                    .unwrap_or(&Value::Null)
                                    .clone(),
                            ) {
                                self.handle_unsubscription(ctx, event_type);
                            }
                        }
                        "ping" => {
                            let pong = RealtimeWebSocketMessage {
                                msg_type: "pong".to_string(),
                                data: json!({
                                    "server_time": Self::current_timestamp(),
                                    "client_time": ws_message.timestamp
                                }),
                                timestamp: Self::current_timestamp(),
                                client_id: Some(self.client_id.clone()),
                                session_id: Some(self.session_id.clone()),
                            };
                            self.send_message(ctx, pong);
                        }
                        "get_subscriptions" => {
                            let subscriptions_msg = RealtimeWebSocketMessage {
                                msg_type: "subscriptions".to_string(),
                                data: json!({
                                    "subscriptions": self.subscriptions.iter().collect::<Vec<_>>(),
                                    "filters": self.filters
                                }),
                                timestamp: Self::current_timestamp(),
                                client_id: Some(self.client_id.clone()),
                                session_id: Some(self.session_id.clone()),
                            };
                            self.send_message(ctx, subscriptions_msg);
                        }
                        _ => {
                            debug!("Unhandled message type: {}", ws_message.msg_type);
                        }
                    },
                    Err(e) => {
                        error!("Failed to parse WebSocket message: {}", e);
                    }
                }
            }

            Ok(ws::Message::Ping(msg)) => {
                self.heartbeat = Instant::now();
                ctx.pong(&msg);
            }

            Ok(ws::Message::Pong(_)) => {
                self.heartbeat = Instant::now();
            }

            Ok(ws::Message::Close(reason)) => {
                info!(
                    "WebSocket closing for client {}: {:?}",
                    self.client_id, reason
                );
                ctx.stop();
            }

            Err(e) => {
                error!(
                    "WebSocket protocol error for client {}: {}",
                    self.client_id, e
                );
                ctx.stop();
            }

            _ => {
                debug!(
                    "Unhandled WebSocket message type for client {}",
                    self.client_id
                );
            }
        }
    }
}

// Message for broadcasting to specific client
#[derive(Message)]
#[rtype(result = "()")]
pub struct BroadcastMessage {
    pub message: RealtimeWebSocketMessage,
}

impl Handler<BroadcastMessage> for RealtimeWebSocketHandler {
    type Result = ();

    fn handle(&mut self, msg: BroadcastMessage, ctx: &mut Self::Context) {
        
        let should_send = if self.filters.is_empty() {
            true
        } else {
            
            let event_type = &msg.message.msg_type;
            let data = &msg.message.data;

            
            self.filters.iter().any(|(key, filter_value)| {
                if let Some((filter_event_type, filter_key)) = key.split_once(':') {
                    if filter_event_type == event_type {
                        if let Some(data_value) = data.get(filter_key) {
                            return data_value.as_str() == Some(filter_value);
                        }
                    }
                }
                false
            }) || !self.subscriptions.contains(event_type)
        };

        if should_send || self.filters.is_empty() {
            self.send_message(ctx, msg.message);
        }
    }
}

// Public API functions for broadcasting events
pub async fn broadcast_workspace_update(
    workspace_id: String,
    changes: Value,
    operation: String,
    user_id: Option<String>,
) {
    let event = WorkspaceUpdateEvent {
        workspace_id,
        changes,
        operation,
        user_id,
    };

    let message = RealtimeWebSocketMessage {
        msg_type: "workspace_update".to_string(),
        data: serde_json::to_value(&event).unwrap_or_default(),
        timestamp: RealtimeWebSocketHandler::current_timestamp(),
        client_id: None,
        session_id: None,
    };

    
    let msg_to_send = message.clone();
    tokio::spawn(async move {
        let manager = CONNECTION_MANAGER.lock().await;
        manager.broadcast("workspace_update", msg_to_send).await;
    });
}

pub async fn broadcast_analysis_progress(
    analysis_id: String,
    graph_id: Option<String>,
    progress: f64,
    stage: String,
    current_operation: String,
    metrics: Option<Value>,
) {
    let event = AnalysisProgressEvent {
        analysis_id,
        graph_id,
        progress,
        stage,
        estimated_time_remaining: None,
        current_operation,
        metrics,
    };

    let message = RealtimeWebSocketMessage {
        msg_type: "analysis_progress".to_string(),
        data: serde_json::to_value(&event).unwrap_or_default(),
        timestamp: RealtimeWebSocketHandler::current_timestamp(),
        client_id: None,
        session_id: None,
    };

    
    let msg = message.clone();
    tokio::spawn(async move {
        let manager = CONNECTION_MANAGER.lock().await;
        manager.broadcast("analysis_progress", msg).await;
    });
}

pub async fn broadcast_optimization_update(
    optimization_id: String,
    graph_id: Option<String>,
    progress: f64,
    algorithm: String,
    current_iteration: u64,
    total_iterations: u64,
    metrics: Value,
) {
    let event = OptimizationUpdateEvent {
        optimization_id,
        graph_id,
        progress,
        algorithm,
        current_iteration,
        total_iterations,
        metrics,
        recommendations: None,
    };

    let message = RealtimeWebSocketMessage {
        msg_type: "optimization_update".to_string(),
        data: serde_json::to_value(&event).unwrap_or_default(),
        timestamp: RealtimeWebSocketHandler::current_timestamp(),
        client_id: None,
        session_id: None,
    };

    
    let msg = message.clone();
    tokio::spawn(async move {
        let manager = CONNECTION_MANAGER.lock().await;
        manager.broadcast("optimization_update", msg).await;
    });
}

pub async fn broadcast_export_progress(
    export_id: String,
    graph_id: Option<String>,
    format: String,
    progress: f64,
    stage: String,
) {
    let event = ExportProgressEvent {
        export_id,
        graph_id,
        format,
        progress,
        stage,
        size: None,
        estimated_time_remaining: None,
    };

    let message = RealtimeWebSocketMessage {
        msg_type: "export_progress".to_string(),
        data: serde_json::to_value(&event).unwrap_or_default(),
        timestamp: RealtimeWebSocketHandler::current_timestamp(),
        client_id: None,
        session_id: None,
    };

    
    let msg = message.clone();
    tokio::spawn(async move {
        let manager = CONNECTION_MANAGER.lock().await;
        manager.broadcast("export_progress", msg).await;
    });
}

pub async fn broadcast_export_ready(
    export_id: String,
    graph_id: Option<String>,
    format: String,
    download_url: String,
    size: u64,
) {
    let event = ExportReadyEvent {
        export_id,
        graph_id,
        format,
        download_url,
        size,
        expires_at: chrono::Utc::now()
            .checked_add_signed(chrono::Duration::hours(24))
            .unwrap_or_else(chrono::Utc::now)
            .to_rfc3339(),
        metadata: json!({}),
    };

    let message = RealtimeWebSocketMessage {
        msg_type: "export_ready".to_string(),
        data: serde_json::to_value(&event).unwrap_or_default(),
        timestamp: RealtimeWebSocketHandler::current_timestamp(),
        client_id: None,
        session_id: None,
    };

    
    let msg = message.clone();
    tokio::spawn(async move {
        let manager = CONNECTION_MANAGER.lock().await;
        manager.broadcast("export_ready", msg).await;
    });
}

// WebSocket route handler
pub async fn realtime_websocket(
    req: actix_web::HttpRequest,
    stream: actix_web::web::Payload,
    app_state: actix_web::web::Data<AppState>,
) -> Result<actix_web::HttpResponse, actix_web::Error> {
    let resp = ws::start(RealtimeWebSocketHandler::new(app_state), &req, stream);

    info!("New real-time WebSocket connection established");
    resp
}

--------------------------------------------------------------------------------
FILE: src/handlers/solid_proxy_handler.rs
PURPOSE: Solid/JSS server proxy with NIP-98 authentication
--------------------------------------------------------------------------------
//! Solid Proxy Handler
//!
//! Proxies requests to JavaScript Solid Server (JSS) with NIP-98 authentication.
//! Routes: /solid/* -> JSS
//!
//! Features:
//! - NIP-98 authentication header generation and forwarding
//! - User identity preservation for Solid ACL enforcement
//! - Content negotiation passthrough (JSON-LD, Turtle)
//! - LDP CRUD operations (GET, PUT, POST, DELETE, PATCH, HEAD)
//! - Pod management endpoints
//! - WebSocket upgrade for solid-0.1 notifications
//!
//! Security Architecture:
//! - User's NIP-98 token is verified locally, then forwarded to JSS
//! - Server signing only used when user auth is unavailable (anonymous requests)
//! - This preserves Solid's ACL model where the user's identity is the access subject

use actix_web::{web, HttpRequest, HttpResponse, http::Method};
use log::{debug, error, info, warn};
use reqwest::Client;
use serde::{Deserialize, Serialize};

use crate::models::protected_settings::NostrUser;
use crate::services::nostr_service::NostrService;
use crate::utils::nip98::{generate_nip98_token, build_auth_header, extract_pubkey_from_token, Nip98Config};
use nostr_sdk::{Keys, PublicKey, ToBech32};

/// JSS configuration from environment
#[derive(Debug, Clone)]
pub struct JssConfig {
    pub base_url: String,
    pub ws_url: String,
}

impl JssConfig {
    pub fn from_env() -> Self {
        Self {
            base_url: std::env::var("JSS_URL").unwrap_or_else(|_| "http://jss:3030".to_string()),
            ws_url: std::env::var("JSS_WS_URL")
                .unwrap_or_else(|_| "ws://jss:3030/.notifications".to_string()),
        }
    }
}

/// Response from pod creation
#[derive(Debug, Serialize, Deserialize)]
pub struct PodCreationResponse {
    pub pod_url: String,
    pub webid: String,
    pub created: bool,
    pub structure: PodStructure,
}

/// Pod directory structure
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PodStructure {
    /// User's WebID profile card
    pub profile: String,
    /// Ontology contributions directory
    pub ontology_contributions: String,
    /// Ontology proposals directory
    pub ontology_proposals: String,
    /// Ontology annotations directory
    pub ontology_annotations: String,
    /// User preferences
    pub preferences: String,
    /// Notifications inbox
    pub inbox: String,
}

/// Error response structure
#[derive(Debug, Serialize)]
pub struct SolidProxyError {
    pub error: String,
    pub details: Option<String>,
}

/// Result of extracting user identity from request
#[derive(Debug, Clone)]
pub struct UserIdentity {
    /// User's Nostr public key (hex)
    pub pubkey: String,
    /// Original NIP-98 token to forward
    pub nip98_token: String,
    /// Full Authorization header value
    pub auth_header: String,
}

/// Shared state for the proxy
pub struct SolidProxyState {
    pub config: JssConfig,
    pub http_client: Client,
    /// Server-side signing key for fallback (anonymous requests only)
    /// Used when user has no NIP-98 auth - JSS will see server identity
    pub server_keys: Option<Keys>,
    /// Whether to allow anonymous requests (server-signed)
    pub allow_anonymous: bool,
}

impl SolidProxyState {
    pub fn new() -> Self {
        let server_keys = std::env::var("SOLID_PROXY_SECRET_KEY")
            .ok()
            .and_then(|hex| {
                nostr_sdk::SecretKey::from_hex(&hex)
                    .ok()
                    .map(Keys::new)
            });

        let allow_anonymous = std::env::var("SOLID_ALLOW_ANONYMOUS")
            .map(|v| v == "true" || v == "1")
            .unwrap_or(true);

        if server_keys.is_some() {
            info!("Solid proxy initialized with server-side signing key (for anonymous fallback)");
        } else {
            info!("Solid proxy initialized without server-side signing");
        }

        if allow_anonymous {
            info!("Anonymous Solid requests enabled (will use server identity)");
        } else {
            info!("Anonymous Solid requests disabled (user auth required)");
        }

        Self {
            config: JssConfig::from_env(),
            http_client: Client::builder()
                .timeout(std::time::Duration::from_secs(30))
                .build()
                .expect("Failed to create HTTP client"),
            server_keys,
            allow_anonymous,
        }
    }

    /// Extract user identity from NIP-98 Authorization header
    /// Returns the user's pubkey and original token for forwarding
    pub fn extract_user_identity(&self, req: &HttpRequest) -> Option<UserIdentity> {
        let auth_header = req.headers().get("Authorization")?;
        let auth_str = auth_header.to_str().ok()?;

        // Must be "Nostr <base64-token>" format
        if !auth_str.starts_with("Nostr ") {
            debug!("Authorization header is not NIP-98 format");
            return None;
        }

        let token = &auth_str[6..]; // Skip "Nostr "

        // Extract and validate the pubkey from the token
        let pubkey = extract_pubkey_from_token(token)?;

        debug!("Extracted user identity from NIP-98: pubkey={}...", &pubkey[..16.min(pubkey.len())]);

        Some(UserIdentity {
            pubkey,
            nip98_token: token.to_string(),
            auth_header: auth_str.to_string(),
        })
    }
}

impl Default for SolidProxyState {
    fn default() -> Self {
        Self::new()
    }
}

/// Main proxy handler for all /solid/* routes
///
/// Security: This handler prioritizes forwarding the USER's NIP-98 identity to JSS.
/// This ensures Solid ACLs are enforced against the actual user, not the proxy server.
///
/// Authentication flow:
/// 1. If user has NIP-98 Authorization header -> Forward it directly to JSS
/// 2. If no user auth AND anonymous allowed -> Generate server-signed NIP-98
/// 3. If no user auth AND anonymous NOT allowed -> Return 401
pub async fn handle_solid_proxy(
    req: HttpRequest,
    body: web::Bytes,
    path: web::Path<String>,
    state: web::Data<SolidProxyState>,
    _nostr_service: web::Data<NostrService>,
) -> HttpResponse {
    let target_path = path.into_inner();
    let method = req.method().clone();

    debug!(
        "Solid proxy: {} /solid/{} -> JSS",
        method, target_path
    );

    // Build target URL
    let target_url = format!("{}/{}", state.config.base_url, target_path);

    // Extract user identity from NIP-98 header (if present)
    let user_identity = state.extract_user_identity(&req);

    // Build the proxied request
    let mut proxy_req = match method.as_str() {
        "GET" => state.http_client.get(&target_url),
        "HEAD" => state.http_client.head(&target_url),
        "PUT" => state.http_client.put(&target_url),
        "POST" => state.http_client.post(&target_url),
        "DELETE" => state.http_client.delete(&target_url),
        "PATCH" => state.http_client.patch(&target_url),
        _ => {
            return HttpResponse::MethodNotAllowed().json(SolidProxyError {
                error: "Method not allowed".to_string(),
                details: Some(format!("Unsupported method: {}", method)),
            });
        }
    };

    // Forward relevant headers (excluding Authorization - handled separately)
    for (name, value) in req.headers() {
        let name_str = name.as_str().to_lowercase();
        // Forward these headers to JSS
        if matches!(
            name_str.as_str(),
            "accept" | "content-type" | "if-match" | "if-none-match" | "slug" | "link"
        ) {
            if let Ok(val) = value.to_str() {
                proxy_req = proxy_req.header(name.as_str(), val);
            }
        }
    }

    // Authentication handling: Prioritize USER identity over server identity
    if let Some(identity) = &user_identity {
        // PREFERRED: Forward user's NIP-98 directly - JSS sees the USER's identity
        // This ensures Solid ACLs are enforced against the actual user
        proxy_req = proxy_req.header("Authorization", &identity.auth_header);
        debug!(
            "Forwarding user NIP-98 to JSS (pubkey: {}...)",
            &identity.pubkey[..16.min(identity.pubkey.len())]
        );

        // Also add X-Forwarded-User for audit/logging (JSS can use this for context)
        proxy_req = proxy_req.header("X-Forwarded-User", format!("did:nostr:{}", identity.pubkey));
    } else if state.allow_anonymous {
        // FALLBACK: Anonymous request - use server identity if available
        if let Some(keys) = &state.server_keys {
            let config = Nip98Config {
                url: target_url.clone(),
                method: method.to_string(),
                body: if body.is_empty() {
                    None
                } else {
                    String::from_utf8(body.to_vec()).ok()
                },
            };

            match generate_nip98_token(keys, &config) {
                Ok(token) => {
                    proxy_req = proxy_req.header("Authorization", build_auth_header(&token));
                    debug!("Using server identity for anonymous request");
                }
                Err(e) => {
                    warn!("Failed to generate server NIP-98 token: {}", e);
                    // Continue without auth - JSS may allow public resources
                }
            }
        }
        // If no server keys, request goes through without Authorization
        // JSS will apply public access rules
    } else {
        // Anonymous not allowed and no user auth
        return HttpResponse::Unauthorized().json(SolidProxyError {
            error: "Authentication required".to_string(),
            details: Some("NIP-98 Authorization header required for Solid access".to_string()),
        });
    }

    // Add body for methods that support it
    if !body.is_empty() && matches!(method.as_str(), "PUT" | "POST" | "PATCH") {
        proxy_req = proxy_req.body(body.to_vec());
    }

    // Execute the request
    match proxy_req.send().await {
        Ok(response) => {
            let status = response.status();
            let mut builder = HttpResponse::build(
                actix_web::http::StatusCode::from_u16(status.as_u16())
                    .unwrap_or(actix_web::http::StatusCode::INTERNAL_SERVER_ERROR),
            );

            // Forward response headers
            for (name, value) in response.headers() {
                let name_str = name.as_str().to_lowercase();
                // Forward these headers from JSS
                if matches!(
                    name_str.as_str(),
                    "content-type"
                        | "etag"
                        | "last-modified"
                        | "link"
                        | "location"
                        | "updates-via"
                        | "wac-allow"
                        | "accept-patch"
                        | "accept-post"
                        | "allow"
                        | "ms-author-via"
                ) {
                    if let Ok(val) = value.to_str() {
                        builder.insert_header((name.as_str(), val));
                    }
                }
            }

            // Get response body
            match response.bytes().await {
                Ok(bytes) => builder.body(bytes.to_vec()),
                Err(e) => {
                    error!("Failed to read JSS response body: {}", e);
                    HttpResponse::BadGateway().json(SolidProxyError {
                        error: "Failed to read response".to_string(),
                        details: Some(e.to_string()),
                    })
                }
            }
        }
        Err(e) => {
            error!("Solid proxy request failed: {}", e);
            HttpResponse::BadGateway().json(SolidProxyError {
                error: "Proxy request failed".to_string(),
                details: Some(e.to_string()),
            })
        }
    }
}

/// Check if a pod exists for the given npub
async fn pod_exists(state: &SolidProxyState, npub: &str) -> bool {
    let pod_url = format!("{}/pods/{}/", state.config.base_url, npub);
    match state.http_client.head(&pod_url).send().await {
        Ok(resp) => resp.status().is_success(),
        Err(_) => false,
    }
}

/// Create the standard pod directory structure
async fn create_pod_structure(
    state: &SolidProxyState,
    npub: &str,
    pubkey: &str,
    auth_header: Option<&str>,
) -> Result<PodStructure, String> {
    let pod_base = format!("{}/pods/{}", state.config.base_url, npub);

    // Directories to create (relative to pod root)
    let directories = [
        "profile",
        "ontology",
        "ontology/contributions",
        "ontology/proposals",
        "ontology/annotations",
        "preferences",
        "inbox",
    ];

    // Create each directory with a .meta file to ensure it exists as a container
    for dir in &directories {
        let dir_url = format!("{}/{}/", pod_base, dir);
        let mut req = state.http_client.put(&dir_url);

        if let Some(auth) = auth_header {
            req = req.header("Authorization", auth);
        }

        // Use Link header to indicate this is a Container (directory)
        req = req
            .header("Content-Type", "text/turtle")
            .header("Link", "<http://www.w3.org/ns/ldp#Container>; rel=\"type\"")
            .body("");

        match req.send().await {
            Ok(resp) if resp.status().is_success() || resp.status().as_u16() == 409 => {
                debug!("Created/confirmed directory: {}", dir);
            }
            Ok(resp) => {
                let status = resp.status();
                debug!("Directory {} creation returned {}: may already exist", dir, status);
            }
            Err(e) => {
                warn!("Failed to create directory {}: {}", dir, e);
            }
        }
    }

    // Create WebID profile card with Nostr identity
    let profile_url = format!("{}/profile/card", pod_base);
    let webid = format!("{}#me", profile_url);
    let profile_content = format!(
        r#"@prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix solid: <http://www.w3.org/ns/solid/terms#> .
@prefix vcard: <http://www.w3.org/2006/vcard/ns#> .
@prefix nostr: <https://github.com/nostr-protocol/nostr#> .

<#me>
    a foaf:Person ;
    solid:oidcIssuer <https://visionflow.info> ;
    nostr:pubkey "{pubkey}" ;
    nostr:npub "{npub}" ;
    vcard:hasUID <did:nostr:{pubkey}> .
"#,
        pubkey = pubkey,
        npub = npub
    );

    let mut profile_req = state.http_client.put(&profile_url);
    if let Some(auth) = auth_header {
        profile_req = profile_req.header("Authorization", auth);
    }
    profile_req = profile_req
        .header("Content-Type", "text/turtle")
        .body(profile_content);

    match profile_req.send().await {
        Ok(resp) if resp.status().is_success() || resp.status().as_u16() == 409 => {
            info!("Created WebID profile for {}", npub);
        }
        Ok(resp) => {
            let status = resp.status();
            debug!("Profile creation returned {}: may already exist", status);
        }
        Err(e) => {
            warn!("Failed to create profile: {}", e);
        }
    }

    Ok(PodStructure {
        profile: format!("{}/profile/card#me", pod_base),
        ontology_contributions: format!("{}/ontology/contributions/", pod_base),
        ontology_proposals: format!("{}/ontology/proposals/", pod_base),
        ontology_annotations: format!("{}/ontology/annotations/", pod_base),
        preferences: format!("{}/preferences/", pod_base),
        inbox: format!("{}/inbox/", pod_base),
    })
}

/// Initialize pod with auto-provisioning
/// Called when user first accesses their pod area
pub async fn ensure_pod_exists(
    state: &SolidProxyState,
    npub: &str,
    pubkey: &str,
    auth_header: Option<&str>,
) -> Result<(bool, PodStructure), String> {
    // Check if pod already exists
    if pod_exists(state, npub).await {
        let pod_base = format!("{}/pods/{}", state.config.base_url, npub);
        return Ok((false, PodStructure {
            profile: format!("{}/profile/card#me", pod_base),
            ontology_contributions: format!("{}/ontology/contributions/", pod_base),
            ontology_proposals: format!("{}/ontology/proposals/", pod_base),
            ontology_annotations: format!("{}/ontology/annotations/", pod_base),
            preferences: format!("{}/preferences/", pod_base),
            inbox: format!("{}/inbox/", pod_base),
        }));
    }

    info!("Auto-provisioning pod for user: {}", npub);

    // Create pod via JSS API
    let pod_create_url = format!("{}/.pods", state.config.base_url);
    let pod_request = serde_json::json!({
        "name": npub,
        "webId": format!("did:nostr:{}", pubkey)
    });

    let mut req = state.http_client.post(&pod_create_url);
    if let Some(auth) = auth_header {
        req = req.header("Authorization", auth);
    }

    let response = req.json(&pod_request).send().await;

    match response {
        Ok(resp) if resp.status().is_success() || resp.status().as_u16() == 409 => {
            // Pod created (or already exists), now create structure
            let structure = create_pod_structure(state, npub, pubkey, auth_header).await?;
            Ok((true, structure))
        }
        Ok(resp) => {
            let status = resp.status();
            let body = resp.text().await.unwrap_or_default();
            Err(format!("Pod creation failed ({}): {}", status, body))
        }
        Err(e) => Err(format!("Failed to connect to Solid server: {}", e)),
    }
}

/// Create a new pod for a user based on their Nostr identity
pub async fn create_pod(
    req: HttpRequest,
    _body: web::Json<CreatePodRequest>,
    state: web::Data<SolidProxyState>,
    nostr_service: web::Data<NostrService>,
) -> HttpResponse {
    // Get user from session/token
    let user = match get_user_from_request(&req, &nostr_service).await {
        Some(u) => u,
        None => {
            return HttpResponse::Unauthorized().json(SolidProxyError {
                error: "Authentication required".to_string(),
                details: Some("Valid Nostr session required to create pod".to_string()),
            });
        }
    };

    let npub = &user.npub;
    let pubkey = &user.pubkey;
    info!("Creating pod for user: {}", npub);

    // Get auth header for forwarding
    let auth_header = req.headers()
        .get("Authorization")
        .and_then(|h| h.to_str().ok());

    // Use ensure_pod_exists for creation with full structure
    match ensure_pod_exists(&state, npub, pubkey, auth_header).await {
        Ok((created, structure)) => {
            let pod_url = format!("{}/pods/{}/", state.config.base_url, npub);
            let status = if created {
                actix_web::http::StatusCode::CREATED
            } else {
                actix_web::http::StatusCode::OK
            };
            HttpResponse::build(status).json(PodCreationResponse {
                pod_url,
                webid: structure.profile.clone(),
                created,
                structure,
            })
        }
        Err(e) => {
            error!("Pod creation failed: {}", e);
            HttpResponse::BadGateway().json(SolidProxyError {
                error: "Pod creation failed".to_string(),
                details: Some(e),
            })
        }
    }
}

#[derive(Debug, Deserialize)]
pub struct CreatePodRequest {
    /// Optional custom pod name (defaults to npub)
    pub name: Option<String>,
}

/// Check if a pod exists for the current user
pub async fn check_pod_exists(
    req: HttpRequest,
    state: web::Data<SolidProxyState>,
    nostr_service: web::Data<NostrService>,
) -> HttpResponse {
    let user = match get_user_from_request(&req, &nostr_service).await {
        Some(u) => u,
        None => {
            return HttpResponse::Unauthorized().json(SolidProxyError {
                error: "Authentication required".to_string(),
                details: None,
            });
        }
    };

    let pod_base = format!("{}/pods/{}", state.config.base_url, user.npub);
    let pod_url = format!("{}/", pod_base);

    match state.http_client.head(&pod_url).send().await {
        Ok(resp) if resp.status().is_success() => {
            HttpResponse::Ok().json(serde_json::json!({
                "exists": true,
                "pod_url": pod_url,
                "webid": format!("{}/profile/card#me", pod_base),
                "structure": PodStructure {
                    profile: format!("{}/profile/card#me", pod_base),
                    ontology_contributions: format!("{}/ontology/contributions/", pod_base),
                    ontology_proposals: format!("{}/ontology/proposals/", pod_base),
                    ontology_annotations: format!("{}/ontology/annotations/", pod_base),
                    preferences: format!("{}/preferences/", pod_base),
                    inbox: format!("{}/inbox/", pod_base),
                }
            }))
        }
        Ok(resp) if resp.status().as_u16() == 404 => {
            HttpResponse::Ok().json(serde_json::json!({
                "exists": false,
                "suggested_url": pod_url
            }))
        }
        Ok(resp) => {
            HttpResponse::build(
                actix_web::http::StatusCode::from_u16(resp.status().as_u16())
                    .unwrap_or(actix_web::http::StatusCode::INTERNAL_SERVER_ERROR),
            )
            .json(SolidProxyError {
                error: "Failed to check pod".to_string(),
                details: None,
            })
        }
        Err(e) => {
            HttpResponse::BadGateway().json(SolidProxyError {
                error: "Failed to connect to Solid server".to_string(),
                details: Some(e.to_string()),
            })
        }
    }
}

/// Initialize pod for current user (auto-provision if needed)
/// This should be called on user login to ensure their pod exists
pub async fn init_pod(
    req: HttpRequest,
    state: web::Data<SolidProxyState>,
    nostr_service: web::Data<NostrService>,
) -> HttpResponse {
    // Get user from session/token
    let user = match get_user_from_request(&req, &nostr_service).await {
        Some(u) => u,
        None => {
            return HttpResponse::Unauthorized().json(SolidProxyError {
                error: "Authentication required".to_string(),
                details: Some("Valid Nostr session required to initialize pod".to_string()),
            });
        }
    };

    let npub = &user.npub;
    let pubkey = &user.pubkey;

    // Get auth header for forwarding
    let auth_header = req.headers()
        .get("Authorization")
        .and_then(|h| h.to_str().ok());

    debug!("Initializing pod for user: {}", npub);

    // Use ensure_pod_exists for auto-provisioning
    match ensure_pod_exists(&state, npub, pubkey, auth_header).await {
        Ok((created, structure)) => {
            let pod_url = format!("{}/pods/{}/", state.config.base_url, npub);
            HttpResponse::Ok().json(serde_json::json!({
                "pod_url": pod_url,
                "webid": structure.profile,
                "created": created,
                "structure": structure
            }))
        }
        Err(e) => {
            error!("Pod initialization failed: {}", e);
            HttpResponse::BadGateway().json(SolidProxyError {
                error: "Pod initialization failed".to_string(),
                details: Some(e),
            })
        }
    }
}

/// Initialize pod from NIP-98 auth (for Solid-first requests)
/// Can be called with NIP-98 Authorization header instead of Bearer token
pub async fn init_pod_nip98(
    req: HttpRequest,
    state: web::Data<SolidProxyState>,
) -> HttpResponse {
    // Get user identity from NIP-98 header
    let identity = match state.extract_user_identity(&req) {
        Some(id) => id,
        None => {
            return HttpResponse::Unauthorized().json(SolidProxyError {
                error: "NIP-98 authentication required".to_string(),
                details: Some("Valid NIP-98 Authorization header required".to_string()),
            });
        }
    };

    // Convert hex pubkey to npub (bech32)
    let npub = match PublicKey::from_hex(&identity.pubkey) {
        Ok(pk) => match pk.to_bech32() {
            Ok(n) => n,
            Err(e) => {
                error!("Failed to convert pubkey to npub: {}", e);
                return HttpResponse::InternalServerError().json(SolidProxyError {
                    error: "Failed to process public key".to_string(),
                    details: Some(e.to_string()),
                });
            }
        },
        Err(e) => {
            error!("Invalid pubkey in NIP-98 token: {}", e);
            return HttpResponse::BadRequest().json(SolidProxyError {
                error: "Invalid public key".to_string(),
                details: Some(e.to_string()),
            });
        }
    };

    debug!("Initializing pod for NIP-98 user: {}", npub);

    // Use ensure_pod_exists for auto-provisioning
    match ensure_pod_exists(&state, &npub, &identity.pubkey, Some(&identity.auth_header)).await {
        Ok((created, structure)) => {
            let pod_url = format!("{}/pods/{}/", state.config.base_url, npub);
            HttpResponse::Ok().json(serde_json::json!({
                "pod_url": pod_url,
                "webid": structure.profile,
                "created": created,
                "structure": structure,
                "npub": npub
            }))
        }
        Err(e) => {
            error!("Pod initialization failed: {}", e);
            HttpResponse::BadGateway().json(SolidProxyError {
                error: "Pod initialization failed".to_string(),
                details: Some(e),
            })
        }
    }
}

/// Get user from request using session token
async fn get_user_from_request(
    req: &HttpRequest,
    nostr_service: &web::Data<NostrService>,
) -> Option<NostrUser> {
    // Try to get token from Authorization header
    let auth_header = req.headers().get("Authorization")?;
    let auth_str = auth_header.to_str().ok()?;

    // Extract Bearer token
    if auth_str.starts_with("Bearer ") {
        let token = &auth_str[7..];
        nostr_service.get_session(token).await
    } else {
        None
    }
}

/// Get user identity from NIP-98 Authorization header
async fn get_user_identity_from_request(
    req: &HttpRequest,
    state: &web::Data<SolidProxyState>,
) -> Option<UserIdentity> {
    state.extract_user_identity(req)
}

// ============================================================================
// WebSocket Handler for Solid-0.1 Notifications
// ============================================================================

use actix::{Actor, StreamHandler, ActorContext};
use actix_web_actors::ws;

/// WebSocket actor for proxying solid-0.1 notifications
pub struct SolidNotificationWs {
    /// User identity for the connection
    user_identity: Option<UserIdentity>,
    /// JSS WebSocket URL
    jss_ws_url: String,
    /// Subscribed resources
    subscriptions: Vec<String>,
}

impl SolidNotificationWs {
    pub fn new(user_identity: Option<UserIdentity>, jss_config: &JssConfig) -> Self {
        Self {
            user_identity,
            jss_ws_url: jss_config.ws_url.clone(),
            subscriptions: Vec::new(),
        }
    }
}

impl Actor for SolidNotificationWs {
    type Context = ws::WebsocketContext<Self>;

    fn started(&mut self, _ctx: &mut Self::Context) {
        info!("Solid notification WebSocket started for user: {:?}",
            self.user_identity.as_ref().map(|u| &u.pubkey[..16.min(u.pubkey.len())]));
    }

    fn stopped(&mut self, _ctx: &mut Self::Context) {
        info!("Solid notification WebSocket stopped");
    }
}

/// Message format for solid-0.1 protocol
#[derive(Debug, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum SolidNotificationMessage {
    /// Subscribe to resource changes
    #[serde(rename = "sub")]
    Subscribe { resource: String },
    /// Unsubscribe from resource
    #[serde(rename = "unsub")]
    Unsubscribe { resource: String },
    /// Acknowledgment from server
    #[serde(rename = "ack")]
    Ack { resource: String },
    /// Publication notification (resource changed)
    #[serde(rename = "pub")]
    Publish { resource: String },
    /// Ping for keepalive
    #[serde(rename = "ping")]
    Ping,
    /// Pong response
    #[serde(rename = "pong")]
    Pong,
}

impl StreamHandler<Result<ws::Message, ws::ProtocolError>> for SolidNotificationWs {
    fn handle(&mut self, msg: Result<ws::Message, ws::ProtocolError>, ctx: &mut Self::Context) {
        match msg {
            Ok(ws::Message::Text(text)) => {
                debug!("Received solid notification message: {}", text);

                // Parse the solid-0.1 protocol message
                match serde_json::from_str::<SolidNotificationMessage>(&text) {
                    Ok(SolidNotificationMessage::Subscribe { resource }) => {
                        info!("Client subscribing to: {}", resource);
                        self.subscriptions.push(resource.clone());
                        // Send ack back to client
                        let ack = SolidNotificationMessage::Ack { resource };
                        if let Ok(json) = serde_json::to_string(&ack) {
                            ctx.text(json);
                        }
                    }
                    Ok(SolidNotificationMessage::Unsubscribe { resource }) => {
                        info!("Client unsubscribing from: {}", resource);
                        self.subscriptions.retain(|r| r != &resource);
                    }
                    Ok(SolidNotificationMessage::Ping) => {
                        let pong = SolidNotificationMessage::Pong;
                        if let Ok(json) = serde_json::to_string(&pong) {
                            ctx.text(json);
                        }
                    }
                    Ok(msg) => {
                        debug!("Received other solid message: {:?}", msg);
                    }
                    Err(e) => {
                        warn!("Failed to parse solid notification message: {}", e);
                    }
                }
            }
            Ok(ws::Message::Ping(msg)) => {
                ctx.pong(&msg);
            }
            Ok(ws::Message::Pong(_)) => {}
            Ok(ws::Message::Binary(_)) => {
                warn!("Binary messages not supported for solid notifications");
            }
            Ok(ws::Message::Close(reason)) => {
                info!("WebSocket close requested: {:?}", reason);
                ctx.stop();
            }
            Ok(ws::Message::Continuation(_)) => {
                warn!("Continuation frames not supported");
            }
            Ok(ws::Message::Nop) => {}
            Err(e) => {
                error!("WebSocket protocol error: {}", e);
                ctx.stop();
            }
        }
    }
}

/// WebSocket handler for solid-0.1 notifications
///
/// Endpoint: /solid/.notifications (WebSocket upgrade)
///
/// Protocol: solid-0.1
/// - Client sends: { "type": "sub", "resource": "<url>" }
/// - Server sends: { "type": "ack", "resource": "<url>" }
/// - Server sends: { "type": "pub", "resource": "<url>" } on changes
pub async fn handle_solid_notifications_ws(
    req: HttpRequest,
    stream: web::Payload,
    state: web::Data<SolidProxyState>,
) -> Result<HttpResponse, actix_web::Error> {
    // Extract user identity if present
    let user_identity = state.extract_user_identity(&req);

    if let Some(ref identity) = user_identity {
        debug!(
            "Solid notifications WebSocket connecting for user: {}...",
            &identity.pubkey[..16.min(identity.pubkey.len())]
        );
    } else {
        debug!("Solid notifications WebSocket connecting (anonymous)");
    }

    // Create WebSocket actor
    let ws_actor = SolidNotificationWs::new(user_identity, &state.config);

    // Start WebSocket handshake
    ws::start(ws_actor, &req, stream)
}

/// Configuration for connecting to JSS notifications via WebSocket proxy
///
/// This creates a bidirectional proxy between the client and JSS's WebSocket endpoint
pub async fn handle_solid_notifications_proxy(
    req: HttpRequest,
    stream: web::Payload,
    state: web::Data<SolidProxyState>,
) -> Result<HttpResponse, actix_web::Error> {
    // For full proxy mode, we would need to establish a connection to JSS
    // and relay messages bidirectionally. For now, use the simpler actor model.
    handle_solid_notifications_ws(req, stream, state).await
}

/// Health check for JSS connectivity
///
/// Returns the health status of the connection to the JavaScript Solid Server.
/// - 200 OK with "healthy" status if JSS is reachable
/// - 503 Service Unavailable with "degraded" if JSS responds with non-success
/// - 503 Service Unavailable with "unhealthy" if JSS is unreachable
pub async fn jss_health_check(state: web::Data<SolidProxyState>) -> HttpResponse {
    let health_url = format!("{}/", state.config.base_url);

    match state
        .http_client
        .head(&health_url)
        .timeout(std::time::Duration::from_secs(5))
        .send()
        .await
    {
        Ok(response) if response.status().is_success() => {
            HttpResponse::Ok().json(serde_json::json!({
                "status": "healthy",
                "jss_url": state.config.base_url
            }))
        }
        Ok(response) => {
            HttpResponse::ServiceUnavailable().json(serde_json::json!({
                "status": "degraded",
                "code": response.status().as_u16()
            }))
        }
        Err(e) => {
            HttpResponse::ServiceUnavailable().json(serde_json::json!({
                "status": "unhealthy",
                "error": e.to_string()
            }))
        }
    }
}

/// Configure Solid proxy routes
pub fn configure_routes(cfg: &mut web::ServiceConfig) {
    cfg.app_data(web::Data::new(SolidProxyState::new()))
        .service(
            web::scope("/solid")
                // Health check endpoint
                .route("/health", web::get().to(jss_health_check))
                // WebSocket endpoint for notifications (solid-0.1 protocol)
                .route("/.notifications", web::get().to(handle_solid_notifications_ws))
                // Pod management endpoints
                .route("/pods", web::post().to(create_pod))
                .route("/pods/check", web::get().to(check_pod_exists))
                .route("/pods/init", web::post().to(init_pod))
                .route("/pods/init-nip98", web::post().to(init_pod_nip98))
                // LDP proxy for all other paths
                .route("/{tail:.*}", web::get().to(handle_solid_proxy))
                .route("/{tail:.*}", web::put().to(handle_solid_proxy))
                .route("/{tail:.*}", web::post().to(handle_solid_proxy))
                .route("/{tail:.*}", web::delete().to(handle_solid_proxy))
                .route("/{tail:.*}", web::head().to(handle_solid_proxy))
                .route(
                    "/{tail:.*}",
                    web::method(Method::PATCH).to(handle_solid_proxy),
                ),
        );
}

--------------------------------------------------------------------------------
FILE: src/handlers/ontology_handler.rs
PURPOSE: OWL ontology operations handler
--------------------------------------------------------------------------------
// CQRS-Based Ontology Handler
// Uses Ontology application layer for all OWL operations

use crate::handlers::utils::execute_in_thread;
use crate::{ok_json, error_json, bad_request, not_found, created_json, service_unavailable};
use crate::AppState;
use actix_web::{web, HttpResponse, Responder};
use log::{error, info};
use serde::Deserialize;

// Import CQRS handlers
use crate::application::ontology::{
    AddAxiom,
    AddAxiomHandler,
    
    AddOwlClass,
    AddOwlClassHandler,
    AddOwlProperty,
    AddOwlPropertyHandler,
    GetClassAxioms,
    GetClassAxiomsHandler,
    GetInferenceResults,
    GetInferenceResultsHandler,
    GetOntologyMetrics,
    GetOntologyMetricsHandler,
    GetOwlClass,
    GetOwlClassHandler,
    GetOwlProperty,
    GetOwlPropertyHandler,
    ListOwlClasses,
    ListOwlClassesHandler,
    ListOwlProperties,
    ListOwlPropertiesHandler,
    
    LoadOntologyGraph,
    LoadOntologyGraphHandler,
    QueryOntology,
    QueryOntologyHandler,
    RemoveAxiom,
    RemoveAxiomHandler,
    RemoveOwlClass,
    RemoveOwlClassHandler,
    SaveOntologyGraph,
    SaveOntologyGraphHandler,
    StoreInferenceResults,
    StoreInferenceResultsHandler,
    UpdateOwlClass,
    UpdateOwlClassHandler,
    UpdateOwlProperty,
    UpdateOwlPropertyHandler,
    ValidateOntology,
    ValidateOntologyHandler,
};
use crate::models::graph::GraphData;
use crate::ports::ontology_repository::{InferenceResults, OwlAxiom, OwlClass, OwlProperty};
use hexser::{DirectiveHandler, QueryHandler};

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct AddClassRequest {
    pub class: OwlClass,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct UpdateClassRequest {
    pub class: OwlClass,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct AddPropertyRequest {
    pub property: OwlProperty,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct UpdatePropertyRequest {
    pub property: OwlProperty,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct AddAxiomRequest {
    pub axiom: OwlAxiom,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct StoreInferenceRequest {
    pub results: InferenceResults,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct QueryRequest {
    pub query: String,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct SaveGraphRequest {
    pub graph: GraphData,
}

///
pub async fn get_ontology_graph(state: web::Data<AppState>) -> Result<HttpResponse, actix_web::Error> {
    info!("Getting ontology graph via CQRS query");

    
    let handler = LoadOntologyGraphHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(LoadOntologyGraph)).await;

    
    match result {
        Ok(Ok(graph)) => {
            info!("Ontology graph loaded successfully via CQRS");
            ok_json!(&*graph)
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to load ontology graph: {}", e);
            error_json!("Failed to load ontology graph", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error in get_ontology_graph: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn save_ontology_graph(
    state: web::Data<AppState>,
    request: web::Json<SaveGraphRequest>,
) -> Result<HttpResponse, actix_web::Error> {
    let graph = request.into_inner().graph;
    info!("Saving ontology graph via CQRS directive");

    
    let handler = SaveOntologyGraphHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(SaveOntologyGraph { graph })).await;

    match result {
        Ok(Ok(())) => {
            info!("Ontology graph saved successfully via CQRS");
            ok_json!(serde_json::json!({
                "success": true
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to save ontology graph: {}", e);
            error_json!("Failed to save ontology graph", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn get_owl_class(state: web::Data<AppState>, iri: web::Path<String>) -> Result<HttpResponse, actix_web::Error> {
    let class_iri = iri.into_inner();
    info!("Getting OWL class via CQRS query: iri={}", class_iri);

    
    let handler = GetOwlClassHandler::new(state.ontology_repository.clone());

    
    let iri_clone = class_iri.clone();
    let result = execute_in_thread(move || handler.handle(GetOwlClass { iri: iri_clone })).await;

    match result {
        Ok(Ok(Some(class))) => {
            info!("OWL class found via CQRS: iri={}", class_iri);
            ok_json!(class)
        }
        Ok(Ok(None)) => {
            info!("OWL class not found: iri={}", class_iri);
            not_found!("OWL class not found")
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to get OWL class: {}", e);
            error_json!("Failed to get OWL class", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn list_owl_classes(state: web::Data<AppState>) -> Result<HttpResponse, actix_web::Error> {
    info!("Listing all OWL classes via CQRS query");

    
    let handler = ListOwlClassesHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(ListOwlClasses)).await;

    match result {
        Ok(Ok(classes)) => {
            info!(
                "OWL classes listed successfully via CQRS: {} classes",
                classes.len()
            );
            ok_json!(classes)
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to list OWL classes: {}", e);
            error_json!("Failed to list OWL classes", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn add_owl_class(
    state: web::Data<AppState>,
    request: web::Json<AddClassRequest>,
) -> Result<HttpResponse, actix_web::Error> {
    let class = request.into_inner().class;
    info!("Adding OWL class via CQRS directive: iri={}", class.iri);

    
    let handler = AddOwlClassHandler::new(state.ontology_repository.clone());

    
    let class_iri = class.iri.clone();
    let result = execute_in_thread(move || handler.handle(AddOwlClass { class })).await;

    match result {
        Ok(Ok(())) => {
            info!("OWL class added successfully via CQRS: iri={}", class_iri);
            ok_json!(serde_json::json!({
                "success": true,
                "iri": class_iri
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to add OWL class: {}", e);
            error_json!("Failed to add OWL class", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn update_owl_class(
    state: web::Data<AppState>,
    request: web::Json<UpdateClassRequest>,
) -> Result<HttpResponse, actix_web::Error> {
    let class = request.into_inner().class;
    info!("Updating OWL class via CQRS directive: iri={}", class.iri);

    
    let handler = UpdateOwlClassHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(UpdateOwlClass { class })).await;

    match result {
        Ok(Ok(())) => {
            info!("OWL class updated successfully via CQRS");
            ok_json!(serde_json::json!({
                "success": true
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to update OWL class: {}", e);
            error_json!("Failed to update OWL class", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn remove_owl_class(
    state: web::Data<AppState>,
    iri: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    let class_iri = iri.into_inner();
    info!("Removing OWL class via CQRS directive: iri={}", class_iri);

    
    let handler = RemoveOwlClassHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(RemoveOwlClass { iri: class_iri })).await;

    match result {
        Ok(Ok(())) => {
            info!("OWL class removed successfully via CQRS");
            ok_json!(serde_json::json!({
                "success": true
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to remove OWL class: {}", e);
            error_json!("Failed to remove OWL class", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn get_owl_property(
    state: web::Data<AppState>,
    iri: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    let property_iri = iri.into_inner();
    info!("Getting OWL property via CQRS query: iri={}", property_iri);

    
    let handler = GetOwlPropertyHandler::new(state.ontology_repository.clone());

    
    match handler.handle(GetOwlProperty {
        iri: property_iri.clone(),
    }) {
        Ok(Some(property)) => {
            info!("OWL property found via CQRS: iri={}", property_iri);
            ok_json!(property)
        }
        Ok(None) => {
            info!("OWL property not found: iri={}", property_iri);
            not_found!("OWL property not found")
        }
        Err(e) => {
            error!("CQRS query failed to get OWL property: {}", e);
            error_json!("Failed to get OWL property", e.to_string())
        }
    }
}

///
pub async fn list_owl_properties(state: web::Data<AppState>) -> Result<HttpResponse, actix_web::Error> {
    info!("Listing all OWL properties via CQRS query");

    
    let handler = ListOwlPropertiesHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(ListOwlProperties)).await;

    match result {
        Ok(Ok(properties)) => {
            info!(
                "OWL properties listed successfully via CQRS: {} properties",
                properties.len()
            );
            ok_json!(properties)
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to list OWL properties: {}", e);
            error_json!("Failed to list OWL properties", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn add_owl_property(
    state: web::Data<AppState>,
    request: web::Json<AddPropertyRequest>,
) -> Result<HttpResponse, actix_web::Error> {
    let property = request.into_inner().property;
    info!(
        "Adding OWL property via CQRS directive: iri={}",
        property.iri
    );

    
    let handler = AddOwlPropertyHandler::new(state.ontology_repository.clone());

    
    let property_iri = property.iri.clone();
    match handler.handle(AddOwlProperty { property }) {
        Ok(()) => {
            info!(
                "OWL property added successfully via CQRS: iri={}",
                property_iri
            );
            ok_json!(serde_json::json!({
                "success": true,
                "iri": property_iri
            }))
        }
        Err(e) => {
            error!("CQRS directive failed to add OWL property: {}", e);
            error_json!("Failed to add OWL property", e.to_string())
        }
    }
}

///
pub async fn update_owl_property(
    state: web::Data<AppState>,
    request: web::Json<UpdatePropertyRequest>,
) -> Result<HttpResponse, actix_web::Error> {
    let property = request.into_inner().property;
    info!(
        "Updating OWL property via CQRS directive: iri={}",
        property.iri
    );

    
    let handler = UpdateOwlPropertyHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(UpdateOwlProperty { property })).await;

    match result {
        Ok(Ok(())) => {
            info!("OWL property updated successfully via CQRS");
            ok_json!(serde_json::json!({
                "success": true
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to update OWL property: {}", e);
            error_json!("Failed to update OWL property", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn get_class_axioms(
    state: web::Data<AppState>,
    iri: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    let class_iri = iri.into_inner();
    info!("Getting class axioms via CQRS query: iri={}", class_iri);

    
    let handler = GetClassAxiomsHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(GetClassAxioms { class_iri })).await;

    match result {
        Ok(Ok(axioms)) => {
            info!(
                "Class axioms retrieved successfully via CQRS: {} axioms",
                axioms.len()
            );
            ok_json!(axioms)
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to get class axioms: {}", e);
            error_json!("Failed to get class axioms", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn add_axiom(
    state: web::Data<AppState>,
    request: web::Json<AddAxiomRequest>,
) -> Result<HttpResponse, actix_web::Error> {
    let axiom = request.into_inner().axiom;
    info!(
        "Adding axiom via CQRS directive: type={:?}",
        axiom.axiom_type
    );

    
    let handler = AddAxiomHandler::new(state.ontology_repository.clone());

    
    let axiom_type = format!("{:?}", axiom.axiom_type);
    match handler.handle(AddAxiom { axiom }) {
        Ok(()) => {
            info!("Axiom added successfully via CQRS: type={}", axiom_type);
            ok_json!(serde_json::json!({
                "success": true,
                "message": format!("Axiom of type {} added", axiom_type)
            }))
        }
        Err(e) => {
            error!("CQRS directive failed to add axiom: {}", e);
            error_json!("Failed to add axiom", e.to_string())
        }
    }
}

///
pub async fn remove_axiom(state: web::Data<AppState>, axiom_id: web::Path<u64>) -> Result<HttpResponse, actix_web::Error> {
    let id = axiom_id.into_inner();
    info!("Removing axiom via CQRS directive: id={}", id);

    
    let handler = RemoveAxiomHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(RemoveAxiom { axiom_id: id })).await;

    match result {
        Ok(Ok(())) => {
            info!("Axiom removed successfully via CQRS");
            ok_json!(serde_json::json!({
                "success": true
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to remove axiom: {}", e);
            error_json!("Failed to remove axiom", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn get_inference_results(state: web::Data<AppState>) -> Result<HttpResponse, actix_web::Error> {
    info!("Getting inference results via CQRS query");

    
    let handler = GetInferenceResultsHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(GetInferenceResults)).await;

    match result {
        Ok(Ok(Some(results))) => {
            info!("Inference results retrieved successfully via CQRS");
            ok_json!(results)
        }
        Ok(Ok(None)) => {
            info!("No inference results found");
            not_found!("No inference results available")
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to get inference results: {}", e);
            error_json!("Failed to get inference results", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn store_inference_results(
    state: web::Data<AppState>,
    request: web::Json<StoreInferenceRequest>,
) -> Result<HttpResponse, actix_web::Error> {
    let results = request.into_inner().results;
    info!(
        "Storing inference results via CQRS directive: {} axioms",
        results.inferred_axioms.len()
    );

    
    let handler = StoreInferenceResultsHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(StoreInferenceResults { results })).await;

    match result {
        Ok(Ok(())) => {
            info!("Inference results stored successfully via CQRS");
            ok_json!(serde_json::json!({
                "success": true
            }))
        }
        Ok(Err(e)) => {
            error!("CQRS directive failed to store inference results: {}", e);
            error_json!("Failed to store inference results", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn validate_ontology(state: web::Data<AppState>) -> Result<HttpResponse, actix_web::Error> {
    info!("Validating ontology via CQRS query");

    
    let handler = ValidateOntologyHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(ValidateOntology)).await;

    match result {
        Ok(Ok(report)) => {
            info!(
                "Ontology validation completed via CQRS: is_valid={}",
                report.is_valid
            );
            ok_json!(report)
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to validate ontology: {}", e);
            error_json!("Failed to validate ontology", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn query_ontology(
    state: web::Data<AppState>,
    request: web::Json<QueryRequest>,
) -> Result<HttpResponse, actix_web::Error> {
    let query = request.into_inner().query;
    info!("Querying ontology via CQRS query");

    
    let handler = QueryOntologyHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(QueryOntology { query })).await;

    match result {
        Ok(Ok(results)) => {
            info!(
                "Ontology query successful via CQRS: {} results",
                results.len()
            );
            ok_json!(results)
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to query ontology: {}", e);
            error_json!("Failed to query ontology", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub async fn get_ontology_metrics(state: web::Data<AppState>) -> Result<HttpResponse, actix_web::Error> {
    info!("Getting ontology metrics via CQRS query");

    
    let handler = GetOntologyMetricsHandler::new(state.ontology_repository.clone());

    
    let result = execute_in_thread(move || handler.handle(GetOntologyMetrics)).await;

    match result {
        Ok(Ok(metrics)) => {
            info!("Ontology metrics retrieved successfully via CQRS");
            ok_json!(metrics)
        }
        Ok(Err(e)) => {
            error!("CQRS query failed to get ontology metrics: {}", e);
            error_json!("Failed to get ontology metrics", e.to_string())
        }
        Err(e) => {
            error!("Thread execution error: {}", e);
            error_json!("Internal server error")
        }
    }
}

///
pub fn config(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/ontology")
            
            .route("/graph", web::get().to(get_ontology_graph))
            .route("/graph", web::post().to(save_ontology_graph))
            
            .route("/classes", web::get().to(list_owl_classes))
            .route("/classes", web::post().to(add_owl_class))
            .route("/classes/{iri}", web::get().to(get_owl_class))
            .route("/classes/{iri}", web::put().to(update_owl_class))
            .route("/classes/{iri}", web::delete().to(remove_owl_class))
            .route("/classes/{iri}/axioms", web::get().to(get_class_axioms))
            
            .route("/properties", web::get().to(list_owl_properties))
            .route("/properties", web::post().to(add_owl_property))
            .route("/properties/{iri}", web::get().to(get_owl_property))
            .route("/properties/{iri}", web::put().to(update_owl_property))
            
            .route("/axioms", web::post().to(add_axiom))
            .route("/axioms/{id}", web::delete().to(remove_axiom))
            
            .route("/inference", web::get().to(get_inference_results))
            .route("/inference", web::post().to(store_inference_results))
            
            .route("/validate", web::get().to(validate_ontology))
            .route("/query", web::post().to(query_ontology))
            .route("/metrics", web::get().to(get_ontology_metrics)),
    );
}

--------------------------------------------------------------------------------
FILE: src/handlers/inference_handler.rs
PURPOSE: OWL reasoning endpoint handler
--------------------------------------------------------------------------------
// src/handlers/inference_handler.rs
//! Inference HTTP Handlers
//!
//! REST API endpoints for ontology inference operations.

use actix_web::{web, HttpResponse, Responder};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use tokio::sync::RwLock;
use tracing::{info, warn};
use crate::{ok_json, error_json, bad_request, not_found, created_json, service_unavailable};

use crate::application::inference_service::InferenceService;

///
#[derive(Debug, Deserialize)]
pub struct RunInferenceRequest {
    
    pub ontology_id: String,

    
    #[serde(default)]
    pub force: bool,
}

///
#[derive(Debug, Serialize)]
pub struct RunInferenceResponse {
    pub success: bool,
    pub ontology_id: String,
    pub inferred_axioms_count: usize,
    pub inference_time_ms: u64,
    pub reasoner_version: String,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub error: Option<String>,
}

///
#[derive(Debug, Deserialize)]
pub struct BatchInferenceRequest {
    
    pub ontology_ids: Vec<String>,

    
    #[serde(default = "default_max_parallel")]
    pub max_parallel: usize,
}

fn default_max_parallel() -> usize {
    4
}

///
#[derive(Debug, Serialize)]
pub struct BatchInferenceResponse {
    pub success: bool,
    pub total_ontologies: usize,
    pub completed: usize,
    pub failed: usize,
    pub total_time_ms: u64,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub results: Option<Vec<RunInferenceResponse>>,
}

///
#[derive(Debug, Deserialize)]
pub struct ValidateOntologyRequest {
    pub ontology_id: String,
}

///
#[derive(Debug, Deserialize)]
pub struct GetExplanationRequest {
    pub axiom_id: String,
}

///
///
pub async fn run_inference(
    service: web::Data<Arc<RwLock<InferenceService>>>,
    req: web::Json<RunInferenceRequest>,
) -> Result<HttpResponse, actix_web::Error> {
    info!("Inference request for ontology: {}", req.ontology_id);

    let service_lock = service.read().await;


    if req.force {
        service_lock.invalidate_cache(&req.ontology_id).await;
    }

    match service_lock.run_inference(&req.ontology_id).await {
        Ok(results) => {
            let response = RunInferenceResponse {
                success: true,
                ontology_id: req.ontology_id.clone(),
                inferred_axioms_count: results.inferred_axioms.len(),
                inference_time_ms: results.inference_time_ms,
                reasoner_version: results.reasoner_version,
                error: None,
            };

            ok_json!(response)
        }
        Err(e) => {
            warn!("Inference failed: {:?}", e);

            let response = RunInferenceResponse {
                success: false,
                ontology_id: req.ontology_id.clone(),
                inferred_axioms_count: 0,
                inference_time_ms: 0,
                reasoner_version: String::new(),
                error: Some(format!("{:?}", e)),
            };

            ok_json!(response)
        }
    }
}

///
///
pub async fn batch_inference(
    service: web::Data<Arc<RwLock<InferenceService>>>,
    req: web::Json<BatchInferenceRequest>,
) -> Result<HttpResponse, actix_web::Error> {
    info!("Batch inference request for {} ontologies", req.ontology_ids.len());
    let start = std::time::Instant::now();

    let service_lock = service.read().await;

    match service_lock.batch_inference(req.ontology_ids.clone()).await {
        Ok(results_map) => {
            let mut responses = Vec::new();
            let mut completed = 0;
            let mut failed = 0;

            for (ont_id, results) in results_map {
                completed += 1;
                responses.push(RunInferenceResponse {
                    success: true,
                    ontology_id: ont_id,
                    inferred_axioms_count: results.inferred_axioms.len(),
                    inference_time_ms: results.inference_time_ms,
                    reasoner_version: results.reasoner_version,
                    error: None,
                });
            }

            failed = req.ontology_ids.len() - completed;
            let total_time_ms = start.elapsed().as_millis() as u64;

            let response = BatchInferenceResponse {
                success: true,
                total_ontologies: req.ontology_ids.len(),
                completed,
                failed,
                total_time_ms,
                results: Some(responses),
            };

            ok_json!(response)
        }
        Err(e) => {
            warn!("Batch inference failed: {:?}", e);

            let response = BatchInferenceResponse {
                success: false,
                total_ontologies: req.ontology_ids.len(),
                completed: 0,
                failed: req.ontology_ids.len(),
                total_time_ms: start.elapsed().as_millis() as u64,
                results: None,
            };

            ok_json!(response)
        }
    }
}

///
///
pub async fn validate_ontology(
    service: web::Data<Arc<RwLock<InferenceService>>>,
    req: web::Json<ValidateOntologyRequest>,
) -> Result<HttpResponse, actix_web::Error> {
    info!("Validation request for ontology: {}", req.ontology_id);

    let service_lock = service.read().await;

    match service_lock.validate_ontology(&req.ontology_id).await {
        Ok(validation_result) => ok_json!(validation_result),
        Err(e) => {
            warn!("Validation failed: {:?}", e);
            ok_json!(serde_json::json!({
                "success": false,
                "error": format!("{:?}", e)
            }))
        }
    }
}

///
///
pub async fn get_inference_results(
    service: web::Data<Arc<RwLock<InferenceService>>>,
    path: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    let ontology_id = path.into_inner();
    info!("Get inference results for: {}", ontology_id);

    let service_lock = service.read().await;


    match service_lock.run_inference(&ontology_id).await {
        Ok(results) => ok_json!(results),
        Err(e) => {
            warn!("Failed to get results: {:?}", e);
            ok_json!(serde_json::json!({
                "success": false,
                "error": format!("{:?}", e)
            }))
        }
    }
}

///
///
pub async fn classify_ontology(
    service: web::Data<Arc<RwLock<InferenceService>>>,
    path: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    let ontology_id = path.into_inner();
    info!("Classification request for: {}", ontology_id);

    let service_lock = service.read().await;

    match service_lock.classify_ontology(&ontology_id).await {
        Ok(classification) => ok_json!(classification),
        Err(e) => {
            warn!("Classification failed: {:?}", e);
            ok_json!(serde_json::json!({
                "success": false,
                "error": format!("{:?}", e)
            }))
        }
    }
}

///
///
pub async fn get_consistency_report(
    service: web::Data<Arc<RwLock<InferenceService>>>,
    path: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    let ontology_id = path.into_inner();
    info!("Consistency report request for: {}", ontology_id);

    let service_lock = service.read().await;

    match service_lock.get_consistency_report(&ontology_id).await {
        Ok(report) => ok_json!(report),
        Err(e) => {
            warn!("Consistency check failed: {:?}", e);
            ok_json!(serde_json::json!({
                "success": false,
                "error": format!("{:?}", e)
            }))
        }
    }
}

///
///
pub async fn invalidate_cache(
    service: web::Data<Arc<RwLock<InferenceService>>>,
    path: web::Path<String>,
) -> Result<HttpResponse, actix_web::Error> {
    let ontology_id = path.into_inner();
    info!("Cache invalidation request for: {}", ontology_id);

    let service_lock = service.read().await;
    service_lock.invalidate_cache(&ontology_id).await;

    ok_json!(serde_json::json!({
        "success": true,
        "message": "Cache invalidated"
    }))
}

///
pub fn configure_routes(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/inference")
            .route("/run", web::post().to(run_inference))
            .route("/batch", web::post().to(batch_inference))
            .route("/validate", web::post().to(validate_ontology))
            .route("/results/{ontology_id}", web::get().to(get_inference_results))
            .route("/classify/{ontology_id}", web::get().to(classify_ontology))
            .route("/consistency/{ontology_id}", web::get().to(get_consistency_report))
            .route("/cache/{ontology_id}", web::delete().to(invalidate_cache)),
    );
}

#[cfg(test)]
mod tests {
    use super::*;
    use actix_web::{test, App};

    
}

================================================================================
                    SECTION 7: GPU ACTORS (Actix Actor System)
================================================================================

--------------------------------------------------------------------------------
FILE: src/actors/mod.rs
PURPOSE: Module exports for all actors
--------------------------------------------------------------------------------
//! Actor system modules for replacing Arc<RwLock<T>> patterns with Actix actors

pub mod agent_monitor_actor;
pub mod client_coordinator_actor;
pub mod client_filter;
pub mod gpu;
pub mod graph_state_actor;
pub mod graph_actor {
    // Re-export graph_state_actor types for backward compatibility
    pub use super::graph_state_actor::GraphStateActor;
    pub use super::graph_messages::AutoBalanceNotification;

    // PhysicsState type alias - represents the state of physics simulation
    // Contains simulation parameters and running status
    #[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
    pub struct PhysicsState {
        pub is_running: bool,
        pub params: crate::models::simulation_params::SimulationParams,
    }

    impl Default for PhysicsState {
        fn default() -> Self {
            Self {
                is_running: false,
                params: crate::models::simulation_params::SimulationParams::default(),
            }
        }
    }
}
pub mod metadata_actor;
pub mod optimized_settings_actor;
pub mod physics_orchestrator_actor;
pub mod protected_settings_actor;
pub mod supervisor;
pub mod voice_commands;
// pub mod supervisor_voice; 
pub mod graph_messages;
pub mod graph_service_supervisor;
pub mod messages;
pub mod messaging;
pub mod multi_mcp_visualization_actor;
pub mod ontology_actor;
pub mod semantic_processor_actor;
pub mod task_orchestrator_actor;
pub mod workspace_actor;

pub use agent_monitor_actor::AgentMonitorActor;
pub use client_coordinator_actor::{
    ClientCoordinatorActor, ClientCoordinatorStats, ClientManager, ClientState,
};
pub use gpu::GPUManagerActor;
pub use graph_state_actor::GraphStateActor;
pub use graph_service_supervisor::{
    ActorHealth, ActorHeartbeat, ActorType, BackoffStrategy, GetSupervisorStatus,
    GraphServiceSupervisor, GraphSupervisionStrategy, RestartActor, RestartAllActors,
    RestartPolicy, SupervisorMessage, SupervisorStatus,
};
pub use messages::*;
pub use messaging::{AckStatus, MessageAck, MessageId, MessageKind, MessageMetrics, MessageTracker};
pub use metadata_actor::MetadataActor;
pub use multi_mcp_visualization_actor::MultiMcpVisualizationActor;
pub use ontology_actor::{
    ActorStatistics as OntologyActorStatistics, JobPriority, JobStatus, OntologyActor,
    OntologyActorConfig, ValidationJob,
};
pub use optimized_settings_actor::OptimizedSettingsActor;
pub use physics_orchestrator_actor::{PhysicsOrchestratorActor, SetClientCoordinator, UserNodeInteraction};
pub use protected_settings_actor::ProtectedSettingsActor;
pub use semantic_processor_actor::{
    AISemanticFeatures, SemanticProcessorActor, SemanticProcessorConfig, SemanticStats,
};
pub use supervisor::{
    SupervisedActorInfo, SupervisedActorTrait, SupervisionStrategy, SupervisorActor,
};
pub use task_orchestrator_actor::{
    CreateTask, GetSystemStatus, GetTaskStatus, ListActiveTasks, StopTask, SystemStatusInfo,
    TaskOrchestratorActor, TaskState,
};
pub use voice_commands::{SwarmIntent, SwarmVoiceResponse, VoiceCommand, VoicePreamble};
pub use workspace_actor::WorkspaceActor;

// Phase 5: Actor lifecycle management and coordination
pub mod event_coordination;
pub mod lifecycle;
pub use event_coordination::{initialize_event_coordinator, EventCoordinator};
pub use lifecycle::{
    initialize_actor_system, shutdown_actor_system, ActorLifecycleManager,
    SupervisionStrategy as Phase5SupervisionStrategy,
};

--------------------------------------------------------------------------------
FILE: src/actors/gpu/mod.rs
PURPOSE: GPU actor subsystem module exports
--------------------------------------------------------------------------------
//! GPU actor module for specialized GPU computation actors
//!
//! ## Architecture (Phase 7: God Actor Decomposition)
//!
//! The GPU subsystem is organized into independent subsystems managed by
//! dedicated supervisors with proper error isolation and timeout handling:
//!
//! ```text
//!                    GPUManagerActor (Coordinator)
//!                           |
//!          +----------------+----------------+----------------+
//!          |                |                |                |
//!   ResourceSupervisor  PhysicsSupervisor  AnalyticsSupervisor  GraphAnalyticsSupervisor
//!          |                |                |                |
//!   GPUResourceActor   +----+----+      +----+----+      +----+----+
//!                      |    |    |      |    |    |      |         |
//!                   Force Stress Constraint Cluster Anomaly PageRank ShortestPath ConnComp
//! ```
//!
//! ### Subsystem Supervisors
//!
//! - **ResourceSupervisor**: Manages GPU initialization with timeout handling
//! - **PhysicsSupervisor**: Force computation, stress majorization, constraints
//! - **AnalyticsSupervisor**: Clustering, anomaly detection, PageRank
//! - **GraphAnalyticsSupervisor**: Shortest path, connected components
//!
//! ### Error Isolation
//!
//! Each subsystem supervisor:
//! - Isolates failures from other subsystems
//! - Implements exponential backoff restart policies
//! - Reports health status independently
//! - Receives SharedGPUContext via GPUContextBus broadcast

// Child actors
pub mod anomaly_detection_actor;
pub mod clustering_actor;
pub mod constraint_actor;
pub mod context_bus;
pub mod cuda_stream_wrapper;
pub mod force_compute_actor;
pub mod gpu_manager_actor;
pub mod gpu_resource_actor;
pub mod ontology_constraint_actor;
pub mod pagerank_actor;
pub mod shortest_path_actor;
pub mod connected_components_actor;
pub mod shared;
pub mod stress_majorization_actor;
pub mod semantic_forces_actor;

// Supervisor actors
pub mod supervisor_messages;
pub mod physics_supervisor;
pub mod analytics_supervisor;
pub mod graph_analytics_supervisor;
pub mod resource_supervisor;

// Child actor exports
pub use anomaly_detection_actor::AnomalyDetectionActor;
pub use clustering_actor::ClusteringActor;
pub use constraint_actor::ConstraintActor;
pub use context_bus::{GPUContextBus, GPUContextReady, GPUContextSubscriber, GPUContextSubscription};
pub use force_compute_actor::ForceComputeActor;
pub use gpu_manager_actor::GPUManagerActor;
pub use gpu_resource_actor::GPUResourceActor;
pub use ontology_constraint_actor::OntologyConstraintActor;
pub use pagerank_actor::PageRankActor;
pub use shortest_path_actor::ShortestPathActor;
pub use connected_components_actor::ConnectedComponentsActor;
pub use shared::{GPUContext, SharedGPUContext, UnifiedGPUCompute};
pub use stress_majorization_actor::StressMajorizationActor;
pub use semantic_forces_actor::SemanticForcesActor;

// Supervisor exports
pub use supervisor_messages::{
    ActorFailure, ActorHealthState, ActorRecovered, GetSubsystemHealth,
    InitializationTimeouts, InitializeSubsystem, RestartActor, RestartSubsystem,
    RouteMessage, SubsystemHealth, SubsystemInitialized, SubsystemStatus,
    SubsystemType, SupervisionPolicy,
};
pub use physics_supervisor::PhysicsSupervisor;
pub use analytics_supervisor::AnalyticsSupervisor;
pub use graph_analytics_supervisor::GraphAnalyticsSupervisor;
pub use resource_supervisor::{ResourceSupervisor, GetContextBus, SetSubsystemSupervisors};

--------------------------------------------------------------------------------
FILE: src/actors/gpu/gpu_manager_actor.rs
PURPOSE: Master GPU coordinator actor
--------------------------------------------------------------------------------
//! GPU Manager Actor - Lightweight Coordinator for GPU Subsystem Supervisors
//!
//! ## Architecture
//!
//! GPUManagerActor has been refactored from a "God Actor" pattern to a lightweight
//! coordinator that delegates to specialized subsystem supervisors:
//!
//! - **ResourceSupervisor**: GPU initialization with timeout handling
//! - **PhysicsSupervisor**: Force computation, stress majorization, constraints
//! - **AnalyticsSupervisor**: Clustering, anomaly detection, PageRank
//! - **GraphAnalyticsSupervisor**: Shortest path, connected components
//!
//! ## Error Isolation
//!
//! Each subsystem operates independently. If one subsystem hangs or fails:
//! - Other subsystems continue operating normally
//! - The failed subsystem's supervisor handles restart with backoff
//! - Health status is reported per-subsystem

use actix::prelude::*;
use log::{debug, error, info, warn};
use std::sync::Arc;
use std::time::Duration;

use super::supervisor_messages::*;
use super::shared::{GPUState, SharedGPUContext};
use super::physics_supervisor::PhysicsSupervisor;
use super::analytics_supervisor::AnalyticsSupervisor;
use super::graph_analytics_supervisor::GraphAnalyticsSupervisor;
use super::resource_supervisor::{ResourceSupervisor, SetSubsystemSupervisors};
use super::ForceComputeActor;
use super::force_compute_actor::PhysicsStats;
use super::pagerank_actor::PageRankResult;
use crate::actors::messages::*;
use crate::telemetry::agent_telemetry::{
    get_telemetry_logger, CorrelationId, LogLevel, TelemetryEvent,
};
use crate::utils::socket_flow_messages::BinaryNodeData;

/// Addresses for subsystem supervisors
#[derive(Clone)]
struct SubsystemSupervisors {
    resource: Addr<ResourceSupervisor>,
    physics: Addr<PhysicsSupervisor>,
    analytics: Addr<AnalyticsSupervisor>,
    graph_analytics: Addr<GraphAnalyticsSupervisor>,
}

/// GPU Manager Actor - Lightweight Coordinator
///
/// Coordinates between subsystem supervisors rather than managing
/// individual child actors directly. This provides:
/// - Better error isolation
/// - Independent subsystem lifecycle
/// - Timeout handling for GPU initialization
/// - Health monitoring per subsystem
pub struct GPUManagerActor {
    /// Subsystem supervisor addresses
    supervisors: Option<SubsystemSupervisors>,

    /// GPU state for status reporting
    gpu_state: GPUState,

    /// Shared GPU context (cached for status queries)
    shared_context: Option<Arc<SharedGPUContext>>,

    /// Whether supervisors have been spawned
    supervisors_spawned: bool,
}

impl GPUManagerActor {
    pub fn new() -> Self {
        Self {
            supervisors: None,
            gpu_state: GPUState::default(),
            shared_context: None,
            supervisors_spawned: false,
        }
    }

    /// Spawn all subsystem supervisors
    fn spawn_supervisors(&mut self, _ctx: &mut Context<Self>) -> Result<(), String> {
        if self.supervisors_spawned {
            debug!("Subsystem supervisors already spawned, skipping");
            return Ok(());
        }

        info!("GPUManagerActor: Spawning subsystem supervisors");

        // Spawn supervisors - each manages its own child actors
        let physics_supervisor = PhysicsSupervisor::new().start();
        debug!("PhysicsSupervisor spawned");

        let analytics_supervisor = AnalyticsSupervisor::new().start();
        debug!("AnalyticsSupervisor spawned");

        let graph_analytics_supervisor = GraphAnalyticsSupervisor::new().start();
        debug!("GraphAnalyticsSupervisor spawned");

        // ResourceSupervisor is spawned last and configured with other supervisor addresses
        let resource_supervisor = ResourceSupervisor::new().start();
        debug!("ResourceSupervisor spawned");

        // Register subsystem supervisors with ResourceSupervisor for context distribution
        if let Err(e) = resource_supervisor.try_send(SetSubsystemSupervisors {
            physics: Some(physics_supervisor.clone()),
            analytics: Some(analytics_supervisor.clone()),
            graph_analytics: Some(graph_analytics_supervisor.clone()),
        }) {
            warn!("Failed to register subsystem supervisors: {}", e);
        }

        self.supervisors = Some(SubsystemSupervisors {
            resource: resource_supervisor,
            physics: physics_supervisor,
            analytics: analytics_supervisor,
            graph_analytics: graph_analytics_supervisor,
        });

        self.supervisors_spawned = true;
        info!("GPUManagerActor: All subsystem supervisors spawned successfully");
        Ok(())
    }

    /// Get subsystem supervisors, spawning if needed
    fn get_supervisors(&mut self, ctx: &mut Context<Self>) -> Result<&SubsystemSupervisors, String> {
        if !self.supervisors_spawned {
            self.spawn_supervisors(ctx)?;
        }

        self.supervisors
            .as_ref()
            .ok_or_else(|| "Failed to get subsystem supervisors".to_string())
    }
}

impl Actor for GPUManagerActor {
    type Context = Context<Self>;

    fn started(&mut self, _ctx: &mut Self::Context) {
        info!("GPU Manager Actor started (supervisor coordinator mode)");

        if let Some(logger) = get_telemetry_logger() {
            let correlation_id = CorrelationId::new();
            let event = TelemetryEvent::new(
                correlation_id,
                LogLevel::INFO,
                "gpu_system",
                "manager_startup",
                "GPU Manager Actor started - subsystem supervisors will be spawned on first message",
                "gpu_manager_actor",
            );
            logger.log_event(event);
        }
    }

    fn stopped(&mut self, _ctx: &mut Self::Context) {
        info!("GPU Manager Actor stopped");
    }
}

// ============================================================================
// Health Monitoring
// ============================================================================

/// Get aggregated health status from all subsystems
#[derive(Message)]
#[rtype(result = "GPUSystemHealth")]
pub struct GetGPUSystemHealth;

/// Aggregated health status
#[derive(Debug, Clone)]
pub struct GPUSystemHealth {
    pub overall_status: SubsystemStatus,
    pub subsystems: Vec<SubsystemHealth>,
}

impl Handler<GetGPUSystemHealth> for GPUManagerActor {
    type Result = ResponseActFuture<Self, GPUSystemHealth>;

    fn handle(&mut self, _msg: GetGPUSystemHealth, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(_) => {
                return Box::pin(async {
                    GPUSystemHealth {
                        overall_status: SubsystemStatus::Failed,
                        subsystems: vec![],
                    }
                }.into_actor(self));
            }
        };

        Box::pin(
            async move {
                let mut subsystems = Vec::new();

                // Query each subsystem supervisor for health
                if let Ok(health) = supervisors.resource.send(GetSubsystemHealth).await {
                    subsystems.push(health);
                }
                if let Ok(health) = supervisors.physics.send(GetSubsystemHealth).await {
                    subsystems.push(health);
                }
                if let Ok(health) = supervisors.analytics.send(GetSubsystemHealth).await {
                    subsystems.push(health);
                }
                if let Ok(health) = supervisors.graph_analytics.send(GetSubsystemHealth).await {
                    subsystems.push(health);
                }

                // Determine overall status
                let overall_status = if subsystems.iter().all(|s| s.status == SubsystemStatus::Healthy) {
                    SubsystemStatus::Healthy
                } else if subsystems.iter().any(|s| s.status == SubsystemStatus::Failed) {
                    SubsystemStatus::Degraded
                } else if subsystems.iter().any(|s| s.status == SubsystemStatus::Initializing) {
                    SubsystemStatus::Initializing
                } else {
                    SubsystemStatus::Degraded
                };

                GPUSystemHealth {
                    overall_status,
                    subsystems,
                }
            }
            .into_actor(self)
        )
    }
}

// ============================================================================
// Message Routing to Subsystem Supervisors
// ============================================================================

/// Initialize GPU - routes to ResourceSupervisor with timeout handling
impl Handler<InitializeGPU> for GPUManagerActor {
    type Result = ResponseActFuture<Self, Result<(), String>>;

    fn handle(&mut self, msg: InitializeGPU, ctx: &mut Self::Context) -> Self::Result {
        debug!("GPUManagerActor::handle(InitializeGPU) - delegating to ResourceSupervisor");
        info!(
            "GPU Manager: InitializeGPU received with {} nodes",
            msg.graph.nodes.len()
        );

        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(e) => {
                error!("Failed to get supervisors: {}", e);
                return Box::pin(async move { Err(e) }.into_actor(self));
            }
        };

        // Delegate to ResourceSupervisor which handles timeout
        Box::pin(
            async move {
                match tokio::time::timeout(
                    Duration::from_secs(60),
                    supervisors.resource.send(msg)
                ).await {
                    Ok(Ok(result)) => result,
                    Ok(Err(e)) => Err(format!("ResourceSupervisor communication failed: {}", e)),
                    Err(_) => Err("GPU initialization timed out at coordinator level".to_string()),
                }
            }
            .into_actor(self)
            .map(|result, actor, _ctx| {
                if result.is_ok() {
                    info!("GPUManagerActor: GPU initialization completed successfully");
                }
                result
            })
        )
    }
}

/// Update GPU graph data - routes to ResourceSupervisor and PhysicsSupervisor
impl Handler<UpdateGPUGraphData> for GPUManagerActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: UpdateGPUGraphData, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = self.get_supervisors(ctx)?;

        // Send to ResourceSupervisor (forwards to GPUResourceActor)
        if let Err(e) = supervisors.resource.try_send(msg.clone()) {
            error!("Failed to send UpdateGPUGraphData to ResourceSupervisor: {}", e);
        }

        // Send to PhysicsSupervisor (forwards to ForceComputeActor)
        if let Err(e) = supervisors.physics.try_send(msg) {
            error!("Failed to send UpdateGPUGraphData to PhysicsSupervisor: {}", e);
        }

        Ok(())
    }
}

/// Compute forces - routes to PhysicsSupervisor
impl Handler<ComputeForces> for GPUManagerActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: ComputeForces, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = self.get_supervisors(ctx)?;

        match supervisors.physics.try_send(msg) {
            Ok(_) => Ok(()),
            Err(e) => {
                error!("Failed to send ComputeForces to PhysicsSupervisor: {}", e);
                Err("Failed to delegate force computation".to_string())
            }
        }
    }
}

/// K-means clustering - routes to AnalyticsSupervisor
impl Handler<RunKMeans> for GPUManagerActor {
    type Result = ResponseActFuture<Self, Result<KMeansResult, String>>;

    fn handle(&mut self, msg: RunKMeans, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(e) => return Box::pin(async move { Err(e) }.into_actor(self)),
        };

        Box::pin(
            async move {
                supervisors.analytics.send(msg).await
                    .map_err(|e| format!("AnalyticsSupervisor communication failed: {}", e))?
            }
            .into_actor(self)
        )
    }
}

/// Community detection - routes to AnalyticsSupervisor
impl Handler<RunCommunityDetection> for GPUManagerActor {
    type Result = ResponseActFuture<Self, Result<CommunityDetectionResult, String>>;

    fn handle(&mut self, msg: RunCommunityDetection, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(e) => return Box::pin(async move { Err(e) }.into_actor(self)),
        };

        Box::pin(
            async move {
                supervisors.analytics.send(msg).await
                    .map_err(|e| format!("AnalyticsSupervisor communication failed: {}", e))?
            }
            .into_actor(self)
        )
    }
}

/// Anomaly detection - routes to AnalyticsSupervisor
impl Handler<RunAnomalyDetection> for GPUManagerActor {
    type Result = ResponseActFuture<Self, Result<AnomalyResult, String>>;

    fn handle(&mut self, msg: RunAnomalyDetection, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(e) => return Box::pin(async move { Err(e) }.into_actor(self)),
        };

        Box::pin(
            async move {
                supervisors.analytics.send(msg).await
                    .map_err(|e| format!("AnalyticsSupervisor communication failed: {}", e))?
            }
            .into_actor(self)
        )
    }
}

/// GPU clustering - routes to AnalyticsSupervisor
impl Handler<PerformGPUClustering> for GPUManagerActor {
    type Result = ResponseActFuture<
        Self,
        Result<Vec<crate::handlers::api_handler::analytics::Cluster>, String>,
    >;

    fn handle(&mut self, msg: PerformGPUClustering, ctx: &mut Self::Context) -> Self::Result {
        info!(
            "GPU Manager: PerformGPUClustering received with method: {}",
            msg.method
        );

        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(e) => return Box::pin(async move { Err(e) }.into_actor(self)),
        };

        Box::pin(
            async move {
                supervisors.analytics.send(msg).await
                    .map_err(|e| format!("AnalyticsSupervisor communication failed: {}", e))?
            }
            .into_actor(self)
        )
    }
}

/// Stress majorization - routes to PhysicsSupervisor
impl Handler<TriggerStressMajorization> for GPUManagerActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: TriggerStressMajorization, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = self.get_supervisors(ctx)?;

        match supervisors.physics.try_send(msg) {
            Ok(_) => Ok(()),
            Err(e) => Err(format!("Failed to delegate stress majorization: {}", e)),
        }
    }
}

/// Update constraints - routes to PhysicsSupervisor
impl Handler<UpdateConstraints> for GPUManagerActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: UpdateConstraints, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = self.get_supervisors(ctx)?;

        match supervisors.physics.try_send(msg) {
            Ok(_) => Ok(()),
            Err(e) => Err(format!("Failed to delegate constraint update: {}", e)),
        }
    }
}

/// Get GPU status
impl Handler<GetGPUStatus> for GPUManagerActor {
    type Result = MessageResult<GetGPUStatus>;

    fn handle(&mut self, _msg: GetGPUStatus, _ctx: &mut Self::Context) -> Self::Result {
        MessageResult(GPUStatus {
            is_initialized: self.shared_context.is_some(),
            failure_count: self.gpu_state.gpu_failure_count,
            num_nodes: self.gpu_state.num_nodes,
            iteration_count: self.gpu_state.iteration_count,
        })
    }
}

/// Get ForceComputeActor address - routes to PhysicsSupervisor
impl Handler<GetForceComputeActor> for GPUManagerActor {
    type Result = ResponseActFuture<Self, Result<Addr<ForceComputeActor>, String>>;

    fn handle(&mut self, msg: GetForceComputeActor, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(e) => return Box::pin(async move { Err(e) }.into_actor(self)),
        };

        Box::pin(
            async move {
                supervisors.physics.send(msg).await
                    .map_err(|e| format!("PhysicsSupervisor communication failed: {}", e))?
            }
            .into_actor(self)
        )
    }
}

/// Upload constraints to GPU - routes to PhysicsSupervisor
impl Handler<UploadConstraintsToGPU> for GPUManagerActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: UploadConstraintsToGPU, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = self.get_supervisors(ctx)?;

        match supervisors.physics.try_send(msg) {
            Ok(_) => Ok(()),
            Err(e) => Err(format!("Failed to delegate UploadConstraintsToGPU: {}", e)),
        }
    }
}

/// Get node data - routes to PhysicsSupervisor
impl Handler<GetNodeData> for GPUManagerActor {
    type Result = ResponseActFuture<Self, Result<Vec<BinaryNodeData>, String>>;

    fn handle(&mut self, msg: GetNodeData, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(e) => return Box::pin(async move { Err(e) }.into_actor(self)),
        };

        Box::pin(
            async move {
                supervisors.physics.send(msg).await
                    .map_err(|e| format!("PhysicsSupervisor communication failed: {}", e))?
            }
            .into_actor(self)
        )
    }
}

/// Update simulation params - routes to PhysicsSupervisor
impl Handler<UpdateSimulationParams> for GPUManagerActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: UpdateSimulationParams, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = self.get_supervisors(ctx)?;

        match supervisors.physics.try_send(msg) {
            Ok(_) => Ok(()),
            Err(e) => Err(format!("Failed to delegate UpdateSimulationParams: {}", e)),
        }
    }
}

/// Update advanced params - routes to PhysicsSupervisor
impl Handler<UpdateAdvancedParams> for GPUManagerActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: UpdateAdvancedParams, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = self.get_supervisors(ctx)?;

        match supervisors.physics.try_send(msg) {
            Ok(_) => Ok(()),
            Err(e) => Err(format!("Failed to delegate UpdateAdvancedParams: {}", e)),
        }
    }
}

/// Set shared GPU context - now handled by ResourceSupervisor distributing to all
impl Handler<SetSharedGPUContext> for GPUManagerActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: SetSharedGPUContext, ctx: &mut Self::Context) -> Self::Result {
        info!("GPUManagerActor: Received SharedGPUContext, forwarding to ResourceSupervisor");

        // Cache locally for status queries
        self.shared_context = Some(msg.context.clone());

        let supervisors = self.get_supervisors(ctx)?;

        // ResourceSupervisor handles distribution to all subsystem supervisors
        match supervisors.resource.try_send(msg) {
            Ok(_) => {
                info!("SharedGPUContext forwarded to ResourceSupervisor for distribution");
                Ok(())
            }
            Err(e) => {
                error!("Failed to forward SharedGPUContext to ResourceSupervisor: {}", e);
                Err(format!("Failed to distribute context: {}", e))
            }
        }
    }
}

/// Apply ontology constraints - routes to PhysicsSupervisor
impl Handler<ApplyOntologyConstraints> for GPUManagerActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: ApplyOntologyConstraints, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = self.get_supervisors(ctx)?;

        match supervisors.physics.try_send(msg) {
            Ok(_) => Ok(()),
            Err(e) => Err(format!(
                "Failed to delegate ApplyOntologyConstraints: {}",
                e
            )),
        }
    }
}

/// Get ontology constraint stats - routes to PhysicsSupervisor
impl Handler<GetOntologyConstraintStats> for GPUManagerActor {
    type Result = ResponseActFuture<Self, Result<OntologyConstraintStats, String>>;

    fn handle(&mut self, msg: GetOntologyConstraintStats, ctx: &mut Self::Context) -> Self::Result {
        info!("GPUManagerActor: GetOntologyConstraintStats received - delegating to PhysicsSupervisor");

        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(e) => {
                error!("Failed to get supervisors: {}", e);
                return Box::pin(async move {
                    Err(format!("Failed to get supervisors: {}", e))
                }.into_actor(self));
            }
        };

        Box::pin(
            async move {
                supervisors.physics.send(msg).await
                    .map_err(|e| format!("PhysicsSupervisor communication failed: {}", e))?
            }
            .into_actor(self)
        )
    }
}

/// Shortest path computation - routes to GraphAnalyticsSupervisor
impl Handler<ComputeShortestPaths> for GPUManagerActor {
    type Result = ResponseActFuture<Self, Result<PathfindingResult, String>>;

    fn handle(&mut self, msg: ComputeShortestPaths, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(e) => return Box::pin(async move { Err(e) }.into_actor(self)),
        };

        Box::pin(
            async move {
                supervisors.graph_analytics.send(msg).await
                    .map_err(|e| format!("GraphAnalyticsSupervisor communication failed: {}", e))?
            }
            .into_actor(self)
        )
    }
}

/// PageRank computation - routes to AnalyticsSupervisor
impl Handler<ComputePageRank> for GPUManagerActor {
    type Result = ResponseActFuture<Self, Result<PageRankResult, String>>;

    fn handle(&mut self, msg: ComputePageRank, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(e) => return Box::pin(async move { Err(e) }.into_actor(self)),
        };

        Box::pin(
            async move {
                supervisors.analytics.send(msg).await
                    .map_err(|e| format!("AnalyticsSupervisor communication failed: {}", e))?
            }
            .into_actor(self)
        )
    }
}

/// Get physics stats - routes to PhysicsSupervisor
impl Handler<GetPhysicsStats> for GPUManagerActor {
    type Result = ResponseActFuture<Self, Result<PhysicsStats, String>>;

    fn handle(&mut self, msg: GetPhysicsStats, ctx: &mut Self::Context) -> Self::Result {
        let supervisors = match self.get_supervisors(ctx) {
            Ok(s) => s.clone(),
            Err(e) => return Box::pin(async move { Err(e) }.into_actor(self)),
        };

        Box::pin(
            async move {
                supervisors.physics.send(msg).await
                    .map_err(|e| format!("PhysicsSupervisor communication failed: {}", e))?
            }
            .into_actor(self)
        )
    }
}

--------------------------------------------------------------------------------
FILE: src/actors/gpu/force_compute_actor.rs
PURPOSE: Force field computation actor
--------------------------------------------------------------------------------
//! Force Compute Actor - Handles physics force computation and simulation

use actix::prelude::*;
use log::{debug, error, info, trace, warn};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::time::Instant;

use super::shared::{GPUOperation, GPUState, SharedGPUContext};
use crate::actors::messages::*;
use crate::models::simulation_params::SimulationParams;
use crate::telemetry::agent_telemetry::{
    get_telemetry_logger, CorrelationId, LogLevel, TelemetryEvent,
};
use crate::utils::socket_flow_messages::{glam_to_vec3data, BinaryNodeDataClient};
use crate::utils::unified_gpu_compute::ComputeMode;
use crate::utils::unified_gpu_compute::SimParams;
use crate::gpu::broadcast_optimizer::{BroadcastConfig, BroadcastOptimizer};
use crate::gpu::backpressure::{BackpressureConfig, NetworkBackpressure};
use glam::Vec3;

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PhysicsStats {
    pub iteration_count: u32,
    pub gpu_failure_count: u32,
    pub current_params: SimulationParams,
    pub compute_mode: ComputeMode,
    pub nodes_count: u32,
    pub edges_count: u32,

    
    pub average_velocity: f32,
    pub kinetic_energy: f32,
    pub total_forces: f32,

    
    pub last_step_duration_ms: f32,
    pub fps: f32,

    
    pub num_edges: u32,
    pub total_force_calculations: u32,
}

///
pub struct ForceComputeActor {

    gpu_state: GPUState,


    shared_context: Option<Arc<SharedGPUContext>>,


    simulation_params: SimulationParams,


    unified_params: SimParams,


    compute_mode: ComputeMode,


    last_step_start: Option<Instant>,
    last_step_duration_ms: f32,


    is_computing: bool,


    skipped_frames: u32,



    reheat_factor: f32,


    stability_iterations: u32,


    graph_service_addr: Option<Addr<crate::actors::GraphServiceSupervisor>>,


    ontology_constraint_addr: Option<Addr<super::ontology_constraint_actor::OntologyConstraintActor>>,

    /// Cached constraint buffer from OntologyConstraintActor for GPU upload
    cached_constraint_buffer: Vec<crate::models::constraints::ConstraintData>,

    /// Semantic forces actor for DAG layout, type clustering, and collision
    semantic_forces_addr: Option<Addr<super::semantic_forces_actor::SemanticForcesActor>>,

    /// Broadcast optimizer for delta compression and spatial culling
    broadcast_optimizer: BroadcastOptimizer,

    /// Network backpressure controller with token bucket algorithm
    backpressure: NetworkBackpressure,

    /// Pre-allocated buffer for position/velocity data (reused every frame to avoid 60Hz allocations)
    position_velocity_buffer: Vec<(Vec3, Vec3)>,

    /// Pre-allocated buffer for node IDs (reused every frame to avoid 60Hz allocations)
    node_id_buffer: Vec<u32>,
}

impl ForceComputeActor {
    pub fn new() -> Self {
        // Initialize broadcast optimizer with default config
        let broadcast_config = BroadcastConfig {
            target_fps: 25, // 25fps broadcast, 60fps physics
            delta_threshold: 0.01, // 1cm movement threshold
            enable_spatial_culling: false, // Disabled by default, can be enabled via API
            camera_bounds: None,
        };

        // Initialize network backpressure with token bucket
        let backpressure_config = BackpressureConfig {
            max_tokens: 100,
            initial_tokens: 100,
            refill_rate_per_sec: 30.0, // Match target broadcast rate
            broadcast_cost: 1,
            ack_restore_tokens: 1,
            enable_time_refill: true,
            log_interval_frames: 60,
        };

        Self {
            gpu_state: GPUState::default(),
            shared_context: None,
            simulation_params: SimulationParams::default(),
            unified_params: SimParams::default(),
            compute_mode: ComputeMode::Basic,
            last_step_start: None,
            last_step_duration_ms: 0.0,
            is_computing: false,
            skipped_frames: 0,
            reheat_factor: 0.0,
            stability_iterations: 0,
            graph_service_addr: None,
            ontology_constraint_addr: None,
            cached_constraint_buffer: Vec::new(),
            semantic_forces_addr: None,
            broadcast_optimizer: BroadcastOptimizer::new(broadcast_config),
            backpressure: NetworkBackpressure::new(backpressure_config),
            position_velocity_buffer: Vec::with_capacity(10000),
            node_id_buffer: Vec::with_capacity(10000),
        }
    }

    fn sync_simulation_to_unified_params(&self, unified_params: &mut SimParams) {
        
        unified_params.spring_k = self.simulation_params.spring_k;
        unified_params.repel_k = self.simulation_params.repel_k;
        unified_params.damping = self.simulation_params.damping;
        unified_params.dt = self.simulation_params.dt;
        unified_params.max_velocity = self.simulation_params.max_velocity;
        unified_params.center_gravity_k = self.simulation_params.center_gravity_k;

        
        match self.compute_mode {
            ComputeMode::Basic => {
                
                
            }
            ComputeMode::Advanced => {
                
                
                unified_params.temperature = self.simulation_params.temperature;
                unified_params.alignment_strength = self.simulation_params.alignment_strength;
                unified_params.cluster_strength = self.simulation_params.cluster_strength;
            }
            ComputeMode::DualGraph => {
                
                
                unified_params.temperature = self.simulation_params.temperature;
                unified_params.alignment_strength = self.simulation_params.alignment_strength;
                unified_params.cluster_strength = self.simulation_params.cluster_strength;
            }
            ComputeMode::Constraints => {
                
                unified_params.temperature = self.simulation_params.temperature;
                unified_params.alignment_strength = self.simulation_params.alignment_strength;
                unified_params.cluster_strength = self.simulation_params.cluster_strength;
                unified_params.constraint_ramp_frames =
                    self.simulation_params.constraint_ramp_frames;
                unified_params.constraint_max_force_per_node =
                    self.simulation_params.constraint_max_force_per_node;
            }
        }

        trace!("Unified params updated: spring_k={:.3}, repel_k={:.3}, center_gravity_k={:.3}, damping={:.3}",
               unified_params.spring_k, unified_params.repel_k, unified_params.center_gravity_k, unified_params.damping);
    }

    
    fn iteration_count(&self) -> u32 {
        self.gpu_state.iteration_count
    }

    
    fn update_simulation_parameters(&mut self, params: SimulationParams) {
        info!("ForceComputeActor: Updating simulation parameters");
        info!(
            "  spring_k: {:.3} -> {:.3}",
            self.simulation_params.spring_k, params.spring_k
        );
        info!(
            "  repel_k: {:.3} -> {:.3}",
            self.simulation_params.repel_k, params.repel_k
        );
        info!(
            "  damping: {:.3} -> {:.3}",
            self.simulation_params.damping, params.damping
        );

        self.simulation_params = params;

        
        {
            let unified_params = &mut self.unified_params;
            unified_params.spring_k = self.simulation_params.spring_k;
            unified_params.repel_k = self.simulation_params.repel_k;
            unified_params.damping = self.simulation_params.damping;
            unified_params.dt = self.simulation_params.dt;
        }
    }

    
    fn get_physics_stats(&self) -> PhysicsStats {
        
        let (average_velocity, kinetic_energy, total_forces) = self.calculate_physics_metrics();

        
        let fps = if self.last_step_duration_ms > 0.0 {
            1000.0 / self.last_step_duration_ms
        } else {
            0.0
        };

        PhysicsStats {
            iteration_count: self.gpu_state.iteration_count,
            gpu_failure_count: self.gpu_state.gpu_failure_count,
            current_params: self.simulation_params.clone(),
            compute_mode: self.compute_mode.clone(),
            nodes_count: self.gpu_state.num_nodes,
            edges_count: self.gpu_state.num_edges,

            
            average_velocity,
            kinetic_energy,
            total_forces,

            
            last_step_duration_ms: self.last_step_duration_ms,
            fps,

            
            num_edges: self.gpu_state.num_edges,
            total_force_calculations: self.gpu_state.iteration_count * self.gpu_state.num_nodes,
        }
    }

    
    fn calculate_physics_metrics(&self) -> (f32, f32, f32) {
        
        if let Some(ctx) = &self.shared_context {
            if let Ok(unified_compute) = ctx.unified_compute.lock() {
                return self.extract_gpu_metrics(&*unified_compute);
            }
        }

        
        let estimated_velocity = self.simulation_params.max_velocity * 0.3; 
        let estimated_kinetic_energy =
            0.5 * (self.gpu_state.num_nodes as f32) * estimated_velocity.powi(2);
        let estimated_total_forces =
            self.simulation_params.spring_k * (self.gpu_state.num_edges as f32) * 0.5;

        (
            estimated_velocity,
            estimated_kinetic_energy,
            estimated_total_forces,
        )
    }

    
    fn extract_gpu_metrics(
        &self,
        unified_compute: &crate::utils::unified_gpu_compute::UnifiedGPUCompute,
    ) -> (f32, f32, f32) {
        let num_nodes = unified_compute.num_nodes;

        
        let mut vel_x = vec![0.0f32; num_nodes];
        let mut vel_y = vec![0.0f32; num_nodes];
        let mut vel_z = vec![0.0f32; num_nodes];

        
        if unified_compute
            .download_velocities(&mut vel_x, &mut vel_y, &mut vel_z)
            .is_ok()
        {
            
            let total_velocity: f32 = vel_x
                .iter()
                .zip(&vel_y)
                .zip(&vel_z)
                .map(|((vx, vy), vz)| (vx * vx + vy * vy + vz * vz).sqrt())
                .sum();
            let average_velocity = if num_nodes > 0 {
                total_velocity / num_nodes as f32
            } else {
                0.0
            };

            
            let kinetic_energy: f32 = vel_x
                .iter()
                .zip(&vel_y)
                .zip(&vel_z)
                .map(|((vx, vy), vz)| 0.5 * (vx * vx + vy * vy + vz * vz))
                .sum();

            
            let estimated_total_forces =
                total_velocity * self.simulation_params.damping * num_nodes as f32;

            (average_velocity, kinetic_energy, estimated_total_forces)
        } else {
            
            let estimated_velocity = self.simulation_params.max_velocity * 0.3;
            let estimated_kinetic_energy = 0.5 * (num_nodes as f32) * estimated_velocity.powi(2);
            let estimated_total_forces =
                self.simulation_params.spring_k * (self.gpu_state.num_edges as f32) * 0.5;

            (
                estimated_velocity,
                estimated_kinetic_energy,
                estimated_total_forces,
            )
        }
    }

    

    fn calculate_gpu_utilization(&self, execution_time_ms: f64) -> f32 {

        const TARGET_FRAME_TIME_MS: f64 = 16.67;


        let utilization_percent = (execution_time_ms / TARGET_FRAME_TIME_MS * 100.0) as f32;


        utilization_percent.min(100.0).max(0.0)
    }

    /// Apply ontology-derived constraint forces to the physics simulation
    ///
    /// This method integrates ontology constraints from the OntologyConstraintActor
    /// into the physics pipeline, enabling semantic relationships to influence node positions.
    ///
    /// # Implementation Notes
    ///
    /// This is the final integration point for P0-2 ontology constraints. It:
    /// 1. Retrieves constraint buffer from OntologyConstraintActor (via shared memory/coordination)
    /// 2. Uploads constraints to GPU via UnifiedGPUCompute::upload_constraints()
    /// 3. Constraints are automatically applied during execute_physics_step()
    ///
    /// The constraint buffer contains ConstraintData structs generated from OWL axioms
    /// by OntologyConstraintTranslator, which are processed by ontology_constraints.cu kernels.
    fn apply_ontology_forces(&mut self) -> Result<(), String> {
        trace!("ForceComputeActor: Applying ontology constraint forces");

        // Check if we have a shared context with access to the GPU compute system
        let shared_context = match &self.shared_context {
            Some(ctx) => ctx,
            None => {
                trace!("ForceComputeActor: No shared context available for ontology forces");
                return Ok(()); // Not an error, just not available yet
            }
        };

        // Use the cached constraint buffer (updated via UpdateOntologyConstraintBuffer message)
        let constraint_buffer = &self.cached_constraint_buffer;

        // Skip if no constraints to apply
        if constraint_buffer.is_empty() {
            trace!("ForceComputeActor: No ontology constraints to apply");
            return Ok(());
        }

        // Access unified compute system and upload constraints to GPU
        let mut unified_compute = shared_context
            .unified_compute
            .lock()
            .map_err(|e| format!("Failed to acquire GPU compute lock: {}", e))?;

        // Upload constraints to GPU - this is the critical integration point
        // The upload_constraints method:
        // 1. Converts ConstraintData to GPU-compatible format
        // 2. Allocates/updates constraint buffer on GPU
        // 3. Prepares constraints for processing by ontology_constraints.cu kernels
        unified_compute
            .upload_constraints(constraint_buffer)
            .map_err(|e| format!("Failed to upload ontology constraints to GPU: {}", e))?;

        debug!(
            "ForceComputeActor: Uploaded {} ontology constraints to GPU",
            constraint_buffer.len()
        );

        // Constraints are now on GPU and will be automatically applied
        // during the next execute_physics_step() call
        trace!("ForceComputeActor: Ontology constraint upload complete");
        Ok(())
    }
}

impl Actor for ForceComputeActor {
    type Context = Context<Self>;

    fn started(&mut self, _ctx: &mut Self::Context) {
        info!("Force Compute Actor started");
    }

    fn stopped(&mut self, _ctx: &mut Self::Context) {
        info!("Force Compute Actor stopped");
    }
}

// === Message Handlers ===

impl Handler<ComputeForces> for ForceComputeActor {
    type Result = ResponseActFuture<Self, Result<(), String>>;

    fn handle(&mut self, _msg: ComputeForces, _ctx: &mut Self::Context) -> Self::Result {
        // Early checks that don't need async
        if self.gpu_state.is_gpu_overloaded() {
            self.skipped_frames += 1;
            if self.skipped_frames % 60 == 0 {
                info!("ForceComputeActor: Skipped {} frames due to GPU overload (utilization: {:.1}%, concurrent ops: {})",
                      self.skipped_frames, self.gpu_state.get_average_utilization(), self.gpu_state.concurrent_access_count);
            }
            return Box::pin(futures::future::ready(Ok(())).into_actor(self));
        }

        if self.is_computing {
            self.skipped_frames += 1;
            if self.skipped_frames % 60 == 0 {
                info!(
                    "ForceComputeActor: Skipped {} frames due to ongoing GPU computation",
                    self.skipped_frames
                );
            }
            return Box::pin(futures::future::ready(Ok(())).into_actor(self));
        }

        // Check for shared context
        let shared_context = match &self.shared_context {
            Some(ctx) => ctx.clone(),
            None => {
                let error_msg = "GPU context not initialized".to_string();
                return Box::pin(futures::future::ready(Err(error_msg)).into_actor(self));
            }
        };

        self.is_computing = true;
        self.gpu_state.start_operation(GPUOperation::ForceComputation);

        // Apply ontology forces before async GPU access
        if let Err(e) = self.apply_ontology_forces() {
            warn!("ForceComputeActor: Failed to apply ontology forces: {}", e);
        }

        let step_start = Instant::now();
        let correlation_id = CorrelationId::new();
        let iteration = self.iteration_count();

        if iteration % 60 == 0 {
            info!(
                "ForceComputeActor: Computing forces (iteration {}), nodes: {}",
                iteration, self.gpu_state.num_nodes
            );
        }

        // Log telemetry event
        if let Some(logger) = get_telemetry_logger() {
            let event = TelemetryEvent::new(
                correlation_id.clone(),
                LogLevel::DEBUG,
                "gpu_compute",
                "force_computation_start",
                &format!(
                    "Starting force computation iteration {} for {} nodes",
                    iteration, self.gpu_state.num_nodes
                ),
                "force_compute_actor",
            )
            .with_metadata("iteration", serde_json::json!(iteration))
            .with_metadata("node_count", serde_json::json!(self.gpu_state.num_nodes))
            .with_metadata("edge_count", serde_json::json!(self.gpu_state.num_edges))
            .with_metadata(
                "compute_mode",
                serde_json::json!(format!("{:?}", self.compute_mode)),
            );

            logger.log_event(event);
        }

        // Capture values needed for async block
        let sim_params = self.simulation_params.clone();
        let reheat_factor = self.reheat_factor;

        // Use async pattern instead of blocking
        let fut = async move {
            // Acquire GPU access asynchronously
            let _gpu_guard = match shared_context.acquire_gpu_access().await {
                Ok(guard) => guard,
                Err(e) => {
                    let error_msg = format!("Failed to acquire GPU lock: {}", e);
                    return Err(error_msg);
                }
            };

            // Now perform the actual GPU computation
            let unified_compute_result = shared_context.unified_compute.lock();
            let mut unified_compute = match unified_compute_result {
                Ok(guard) => guard,
                Err(e) => {
                    return Err(format!("Failed to acquire GPU compute lock: {}", e));
                }
            };

            if reheat_factor > 0.0 {
                info!(
                    "Reheating physics with factor {:.2} to break equilibrium after parameter change",
                    reheat_factor
                );
            }

            let gpu_result = unified_compute.execute_physics_step(&sim_params);
            let execution_duration = step_start.elapsed().as_secs_f64() * 1000.0;

            // Get positions and velocities for broadcast
            let positions_result = unified_compute.get_node_positions();
            let velocities_result = unified_compute.get_node_velocities();

            // Return results for processing in actor context
            Ok((gpu_result, execution_duration, positions_result, velocities_result, correlation_id, iteration, step_start))
        };

        Box::pin(fut.into_actor(self).map(move |result, actor, _ctx| {
            match result {
                Ok((gpu_result, execution_duration, positions_result, velocities_result, _correlation_id, _iteration, step_start)) => {
                    // Reset reheat factor
                    if actor.reheat_factor > 0.0 {
                        actor.reheat_factor = 0.0;
                    }
                    actor.stability_iterations += 1;
                    actor.last_step_duration_ms = execution_duration as f32;

                    match gpu_result {
                        Ok(_) => {
                            let gpu_utilization = actor.calculate_gpu_utilization(execution_duration);
                            actor.gpu_state.record_utilization(gpu_utilization);

                            if let Some(ctx) = &actor.shared_context {
                                if let Err(e) = ctx.update_utilization(gpu_utilization) {
                                    log::warn!("Failed to update shared GPU utilization metrics: {}", e);
                                }
                            }

                            // Log telemetry
                            if let Some(logger) = get_telemetry_logger() {
                                let gpu_memory_mb = (actor.gpu_state.num_nodes as f32 * 48.0 +
                                                    actor.gpu_state.num_edges as f32 * 24.0) / (1024.0 * 1024.0);

                                logger.log_gpu_execution(
                                    "force_computation_kernel",
                                    actor.gpu_state.num_nodes,
                                    execution_duration,
                                    gpu_memory_mb
                                );
                            }

                            // Process positions for broadcast
                            if let (Ok((pos_x, pos_y, pos_z)), Ok((vel_x, vel_y, vel_z))) =
                                (positions_result, velocities_result) {

                                // Reuse pre-allocated buffers to avoid 60Hz allocations
                                actor.position_velocity_buffer.clear();
                                actor.node_id_buffer.clear();

                                // Reserve capacity if graph grew beyond initial allocation
                                if pos_x.len() > actor.position_velocity_buffer.capacity() {
                                    actor.position_velocity_buffer.reserve(pos_x.len() - actor.position_velocity_buffer.capacity());
                                    actor.node_id_buffer.reserve(pos_x.len() - actor.node_id_buffer.capacity());
                                }

                                for i in 0..pos_x.len() {
                                    let position = Vec3::new(pos_x[i], pos_y[i], pos_z[i]);
                                    let velocity = Vec3::new(vel_x[i], vel_y[i], vel_z[i]);
                                    actor.position_velocity_buffer.push((position, velocity));
                                    actor.node_id_buffer.push(i as u32);
                                }

                                let (should_broadcast, filtered_indices) =
                                    actor.broadcast_optimizer.process_frame(&actor.position_velocity_buffer, &actor.node_id_buffer);

                                if should_broadcast && !filtered_indices.is_empty() {
                                    if let Some(_sequence_id) = actor.backpressure.try_acquire() {
                                        let mut node_updates = Vec::with_capacity(filtered_indices.len());
                                        for &idx in &filtered_indices {
                                            let node_id = actor.node_id_buffer[idx];
                                            let (position, velocity) = actor.position_velocity_buffer[idx];

                                            node_updates.push((node_id, BinaryNodeDataClient::new(
                                                node_id,
                                                glam_to_vec3data(position),
                                                glam_to_vec3data(velocity),
                                            )));
                                        }

                                        if let Some(ref graph_addr) = actor.graph_service_addr {
                                            graph_addr.do_send(crate::actors::messages::UpdateNodePositions {
                                                positions: node_updates,
                                                correlation_id: Some(crate::actors::messaging::MessageId::new()),
                                            });
                                        }
                                    } else {
                                        actor.backpressure.record_skip();
                                    }
                                }
                            }

                            actor.gpu_state.iteration_count += 1;
                            actor.last_step_duration_ms = step_start.elapsed().as_millis() as f32;

                            if actor.iteration_count() % 300 == 0 {
                                info!("ForceComputeActor: {} iterations completed, {} GPU failures, {} skipped frames, last step: {:.2}ms",
                                      actor.iteration_count(), actor.gpu_state.gpu_failure_count, actor.skipped_frames, actor.last_step_duration_ms);
                            }

                            actor.is_computing = false;
                            actor.gpu_state.complete_operation(&GPUOperation::ForceComputation);
                            Ok(())
                        }
                        Err(e) => {
                            let error_msg = format!("GPU force computation failed: {}", e);
                            error!("{}", error_msg);
                            actor.gpu_state.gpu_failure_count += 1;
                            actor.is_computing = false;
                            actor.gpu_state.complete_operation(&GPUOperation::ForceComputation);
                            Err(error_msg)
                        }
                    }
                }
                Err(e) => {
                    error!("GPU access failed: {}", e);
                    actor.is_computing = false;
                    actor.gpu_state.complete_operation(&GPUOperation::ForceComputation);
                    Err(e)
                }
            }
        }))
    }
}

impl Handler<UpdateSimulationParams> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: UpdateSimulationParams, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: UpdateSimulationParams received");
        info!(
            "  New params - spring_k: {:.3}, repel_k: {:.3}, damping: {:.3}",
            msg.params.spring_k, msg.params.repel_k, msg.params.damping
        );

        
        self.update_simulation_parameters(msg.params);

        
        
        
        let previous_iteration = self.gpu_state.iteration_count;
        self.gpu_state.iteration_count = 0;

        
        self.stability_iterations = 0;

        
        
        self.reheat_factor = 0.3;

        info!(
            "ForceComputeActor: Reset iteration counter from {} to 0 to restart physics",
            previous_iteration
        );
        info!("ForceComputeActor: Stability gate will allow physics to run for at least 600 iterations");

        Ok(())
    }
}

impl Handler<SetComputeMode> for ForceComputeActor {
    type Result = ResponseActFuture<Self, Result<(), String>>;

    fn handle(&mut self, msg: SetComputeMode, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: Setting compute mode to {:?}", msg.mode);

        self.compute_mode = msg.mode;

        
        let mut temp_params = self.unified_params.clone();
        self.sync_simulation_to_unified_params(&mut temp_params);
        self.unified_params = temp_params;

        use futures::future::ready;
        Box::pin(ready(Ok(())).into_actor(self))
    }
}

impl Handler<GetPhysicsStats> for ForceComputeActor {
    type Result = Result<PhysicsStats, String>;

    fn handle(&mut self, _msg: GetPhysicsStats, _ctx: &mut Self::Context) -> Self::Result {
        Ok(self.get_physics_stats())
    }
}

impl Handler<UpdateAdvancedParams> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: UpdateAdvancedParams, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: UpdateAdvancedParams received");
        info!("  Advanced params - semantic_weight: {:.2}, temporal_weight: {:.2}, constraint_weight: {:.2}",
              msg.params.semantic_force_weight, msg.params.temporal_force_weight, msg.params.constraint_force_weight);

        
        
        if msg.params.semantic_force_weight > 0.0 {
            self.unified_params.temperature *= msg.params.semantic_force_weight;
        }

        
        if msg.params.temporal_force_weight > 0.0 {
            self.unified_params.alignment_strength *= msg.params.temporal_force_weight;
        }

        
        if msg.params.constraint_force_weight > 0.0 {
            self.unified_params.cluster_strength *= msg.params.constraint_force_weight;
        }

        info!("Advanced physics parameters applied to unified compute params");

        
        if matches!(self.compute_mode, ComputeMode::Basic) {
            info!("ForceComputeActor: Switching to Advanced compute mode due to advanced params");
            self.compute_mode = ComputeMode::Advanced;
        }

        Ok(())
    }
}

// Position upload support for external updates
impl Handler<UploadPositions> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: UploadPositions, _ctx: &mut Self::Context) -> Self::Result {
        info!(
            "ForceComputeActor: UploadPositions received - {} nodes",
            msg.positions_x.len()
        );

        let mut unified_compute = match &self.shared_context {
            Some(ctx) => ctx
                .unified_compute
                .lock()
                .map_err(|e| format!("Failed to acquire GPU compute lock: {}", e))?,
            None => {
                return Err("GPU context not initialized".to_string());
            }
        };

        
        unified_compute
            .update_positions_only(&msg.positions_x, &msg.positions_y, &msg.positions_z)
            .map_err(|e| format!("Failed to upload positions: {}", e))?;

        info!("ForceComputeActor: Position upload completed successfully");
        Ok(())
    }
}

// === Additional Message Handlers for Compatibility ===

impl Handler<InitializeGPU> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: InitializeGPU, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: InitializeGPU received");


        self.gpu_state.num_nodes = msg.graph.nodes.len() as u32;
        self.gpu_state.num_edges = msg.graph.edges.len() as u32;


        if msg.graph_service_addr.is_some() {
            self.graph_service_addr = msg.graph_service_addr;
            info!("ForceComputeActor: GraphServiceActor address stored for position updates");
        }

        info!(
            "ForceComputeActor: GPU initialized with {} nodes, {} edges",
            self.gpu_state.num_nodes, self.gpu_state.num_edges
        );

        // H4: Send acknowledgment
        if let Some(correlation_id) = msg.correlation_id {
            use crate::actors::messaging::MessageAck;
            if let Some(ref orchestrator_addr) = msg.physics_orchestrator_addr {
                orchestrator_addr.do_send(MessageAck::success(correlation_id)
                    .with_metadata("nodes", self.gpu_state.num_nodes.to_string())
                    .with_metadata("edges", self.gpu_state.num_edges.to_string()));
            }
        }

        Ok(())
    }
}

impl Handler<UpdateGPUGraphData> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: UpdateGPUGraphData, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: UpdateGPUGraphData received");


        self.gpu_state.num_nodes = msg.graph.nodes.len() as u32;
        self.gpu_state.num_edges = msg.graph.edges.len() as u32;

        info!(
            "ForceComputeActor: Graph data updated - {} nodes, {} edges",
            self.gpu_state.num_nodes, self.gpu_state.num_edges
        );

        // H4: Send acknowledgment
        if let Some(correlation_id) = msg.correlation_id {
            use crate::actors::messaging::MessageAck;
            // Note: We don't have a direct physics orchestrator reference here,
            // but acknowledgments can still be sent if the reference is added in the future
            // For now, this demonstrates the pattern
            debug!("UpdateGPUGraphData completed with correlation_id: {}", correlation_id);
        }

        Ok(())
    }
}

impl Handler<GetNodeData> for ForceComputeActor {
    type Result = Result<Vec<crate::utils::socket_flow_messages::BinaryNodeData>, String>;

    fn handle(&mut self, _msg: GetNodeData, _ctx: &mut Self::Context) -> Self::Result {
        
        Ok(Vec::new())
    }
}

impl Handler<GetGPUStatus> for ForceComputeActor {
    type Result = GPUStatus;

    fn handle(&mut self, _msg: GetGPUStatus, _ctx: &mut Self::Context) -> Self::Result {
        GPUStatus {
            is_initialized: self.shared_context.is_some(),
            failure_count: self.gpu_state.gpu_failure_count,
            iteration_count: self.gpu_state.iteration_count,
            num_nodes: self.gpu_state.num_nodes,
        }
    }
}

impl Handler<GetGPUMetrics> for ForceComputeActor {
    type Result = Result<serde_json::Value, String>;

    fn handle(&mut self, _msg: GetGPUMetrics, _ctx: &mut Self::Context) -> Self::Result {
        use serde_json::json;

        Ok(json!({
            "memory_usage_mb": 0.0,
            "gpu_utilization": 0.0,
            "temperature_c": 0.0,
            "power_usage_w": 0.0,
            "compute_units": 0,
            "max_threads": 0,
            "clock_speed_mhz": 0,
        }))
    }
}

impl Handler<RunCommunityDetection> for ForceComputeActor {
    type Result = Result<CommunityDetectionResult, String>;

    fn handle(&mut self, _msg: RunCommunityDetection, _ctx: &mut Self::Context) -> Self::Result {
        
        Err("Community detection should be handled by ClusteringActor".to_string())
    }
}

impl Handler<UpdateVisualAnalyticsParams> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(
        &mut self,
        _msg: UpdateVisualAnalyticsParams,
        _ctx: &mut Self::Context,
    ) -> Self::Result {
        info!("ForceComputeActor: UpdateVisualAnalyticsParams received (no-op, handled by other actors)");
        Ok(())
    }
}

impl Handler<GetConstraints> for ForceComputeActor {
    type Result = Result<crate::models::constraints::ConstraintSet, String>;

    fn handle(&mut self, _msg: GetConstraints, _ctx: &mut Self::Context) -> Self::Result {
        
        Err("Constraints should be handled by ConstraintActor".to_string())
    }
}

impl Handler<UpdateConstraints> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(&mut self, _msg: UpdateConstraints, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: UpdateConstraints received (forwarding to ConstraintActor would be done by GPUManagerActor)");
        Ok(())
    }
}

impl Handler<UploadConstraintsToGPU> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(&mut self, _msg: UploadConstraintsToGPU, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: UploadConstraintsToGPU received (forwarding to ConstraintActor would be done by GPUManagerActor)");
        Ok(())
    }
}

impl Handler<TriggerStressMajorization> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(
        &mut self,
        _msg: TriggerStressMajorization,
        _ctx: &mut Self::Context,
    ) -> Self::Result {
        
        Err("Stress majorization should be handled by StressMajorizationActor".to_string())
    }
}

impl Handler<GetStressMajorizationStats> for ForceComputeActor {
    type Result =
        Result<crate::actors::gpu::stress_majorization_actor::StressMajorizationStats, String>;

    fn handle(
        &mut self,
        _msg: GetStressMajorizationStats,
        _ctx: &mut Self::Context,
    ) -> Self::Result {
        
        Err(
            "Stress majorization stats should be retrieved from StressMajorizationActor"
                .to_string(),
        )
    }
}

impl Handler<ResetStressMajorizationSafety> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(
        &mut self,
        _msg: ResetStressMajorizationSafety,
        _ctx: &mut Self::Context,
    ) -> Self::Result {
        
        Err(
            "Stress majorization safety reset should be handled by StressMajorizationActor"
                .to_string(),
        )
    }
}

impl Handler<UpdateStressMajorizationParams> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(
        &mut self,
        _msg: UpdateStressMajorizationParams,
        _ctx: &mut Self::Context,
    ) -> Self::Result {
        info!("ForceComputeActor: UpdateStressMajorizationParams received (forwarding to StressMajorizationActor would be done by GPUManagerActor)");
        Ok(())
    }
}

impl Handler<PerformGPUClustering> for ForceComputeActor {
    type Result = Result<Vec<crate::handlers::api_handler::analytics::Cluster>, String>;

    fn handle(&mut self, _msg: PerformGPUClustering, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: PerformGPUClustering received - forwarding to ClusteringActor would be done by GPUManagerActor");
        
        
        Err("Clustering should be handled by ClusteringActor, not ForceComputeActor".to_string())
    }
}

impl Handler<GetClusteringResults> for ForceComputeActor {
    type Result = Result<serde_json::Value, String>;

    fn handle(&mut self, _msg: GetClusteringResults, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: GetClusteringResults received - forwarding to ClusteringActor would be done by GPUManagerActor");


        Err(
            "Clustering results should be retrieved from ClusteringActor, not ForceComputeActor"
                .to_string(),
        )
    }
}

/// Handler for UpdateOntologyConstraintBuffer
/// Updates the cached constraint buffer when ontology constraints change
impl Handler<crate::actors::messages::UpdateOntologyConstraintBuffer> for ForceComputeActor {
    type Result = ();

    fn handle(&mut self, msg: crate::actors::messages::UpdateOntologyConstraintBuffer, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: Received updated ontology constraint buffer with {} constraints",
              msg.constraint_buffer.len());

        // Update the cached constraint buffer
        self.cached_constraint_buffer = msg.constraint_buffer;

        debug!("ForceComputeActor: Ontology constraint buffer cached, will be uploaded to GPU on next physics step");
    }
}

///
impl Handler<SetSharedGPUContext> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: SetSharedGPUContext, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: Received SharedGPUContext from ResourceActor");


        self.shared_context = Some(msg.context);


        if let Some(addr) = msg.graph_service_addr {
            self.graph_service_addr = Some(addr);
            info!("ForceComputeActor: GraphServiceActor address stored - position updates will be sent to clients!");
        } else {
            warn!("ForceComputeActor: No GraphServiceActor address provided - positions won't be sent to clients");
        }


        self.gpu_state.is_initialized = true;

        info!("ForceComputeActor: SharedGPUContext stored successfully - GPU physics enabled!");
        info!(
            "ForceComputeActor: Physics can now run with {} nodes and {} edges",
            self.gpu_state.num_nodes, self.gpu_state.num_edges
        );

        // H4: Send acknowledgment
        if let Some(correlation_id) = msg.correlation_id {
            use crate::actors::messaging::MessageAck;
            debug!("SetSharedGPUContext completed with correlation_id: {}", correlation_id);
            // Note: Future enhancement - send ack to physics orchestrator if reference available
        }

        Ok(())
    }
}

/// Handler for ConfigureStressMajorization message
impl Handler<ConfigureStressMajorization> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: ConfigureStressMajorization, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: ConfigureStressMajorization received");

        // Store stress majorization configuration in unified params
        // These parameters affect graph layout optimization
        if let Some(learning_rate) = msg.learning_rate {
            info!("  Setting learning_rate: {:.3}", learning_rate);
            // Apply learning rate to temperature for optimization
            self.unified_params.temperature = learning_rate * 100.0;
        }

        if let Some(momentum) = msg.momentum {
            info!("  Setting momentum: {:.3}", momentum);
            // Momentum affects velocity damping
            self.unified_params.damping = 1.0 - momentum;
        }

        if let Some(max_iterations) = msg.max_iterations {
            info!("  Setting max_iterations: {}", max_iterations);
            // This would be used by stress majorization algorithm
            // For now, we log it as it affects the optimization convergence
        }

        if let Some(auto_run_interval) = msg.auto_run_interval {
            info!("  Setting auto_run_interval: {} frames", auto_run_interval);
            // Auto-run interval affects periodic layout optimization
        }

        info!("ForceComputeActor: Stress majorization configuration applied");
        Ok(())
    }
}

/// Handler for GetStressMajorizationConfig message
impl Handler<GetStressMajorizationConfig> for ForceComputeActor {
    type Result = Result<StressMajorizationConfig, String>;

    fn handle(&mut self, _msg: GetStressMajorizationConfig, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: GetStressMajorizationConfig received");

        // Return current stress majorization configuration based on unified params
        let config = StressMajorizationConfig {
            learning_rate: self.unified_params.temperature / 100.0,
            momentum: 1.0 - self.unified_params.damping,
            max_iterations: 100, // Default value
            auto_run_interval: 60, // Default: every 60 frames
            current_stress: 0.0, // Would be computed from current layout
            converged: self.stability_iterations > 600, // Converged after stability
            iterations_completed: self.gpu_state.iteration_count as usize,
        };

        info!("ForceComputeActor: Returning stress majorization config (learning_rate: {:.3}, momentum: {:.3})",
              config.learning_rate, config.momentum);

        Ok(config)
    }
}

// =============================================================================
// Phase 7: Broadcast Optimization Message Handlers
// =============================================================================

/// Handler for ConfigureBroadcastOptimization
impl Handler<crate::actors::messages::ConfigureBroadcastOptimization> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: crate::actors::messages::ConfigureBroadcastOptimization, _ctx: &mut Self::Context) -> Self::Result {
        info!("ForceComputeActor: ConfigureBroadcastOptimization received");

        // Get current stats before update
        let old_stats = self.broadcast_optimizer.get_performance_stats();

        // Build new config from current + updates
        let mut new_config = BroadcastConfig {
            target_fps: msg.target_fps.unwrap_or(old_stats.target_fps),
            delta_threshold: msg.delta_threshold.unwrap_or(old_stats.delta_threshold),
            enable_spatial_culling: msg.enable_spatial_culling.unwrap_or(false),
            camera_bounds: None, // Updated separately via UpdateCameraFrustum
        };

        // Validate parameters
        if new_config.target_fps == 0 || new_config.target_fps > 60 {
            return Err(format!("Invalid target_fps: {} (must be 1-60)", new_config.target_fps));
        }

        if new_config.delta_threshold < 0.0 {
            return Err(format!("Invalid delta_threshold: {} (must be >= 0.0)", new_config.delta_threshold));
        }

        info!("  Target FPS: {} -> {}", old_stats.target_fps, new_config.target_fps);
        info!("  Delta threshold: {:.4} -> {:.4}", old_stats.delta_threshold, new_config.delta_threshold);
        info!("  Spatial culling: {}", new_config.enable_spatial_culling);

        // Apply new configuration
        self.broadcast_optimizer.update_config(new_config);

        Ok(())
    }
}

/// Handler for UpdateCameraFrustum
impl Handler<crate::actors::messages::UpdateCameraFrustum> for ForceComputeActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: crate::actors::messages::UpdateCameraFrustum, _ctx: &mut Self::Context) -> Self::Result {
        debug!("ForceComputeActor: UpdateCameraFrustum received - min: {:?}, max: {:?}",
               msg.min, msg.max);

        let min = Vec3::new(msg.min.0, msg.min.1, msg.min.2);
        let max = Vec3::new(msg.max.0, msg.max.1, msg.max.2);
        self.broadcast_optimizer.update_camera_bounds(min, max);
        Ok(())
    }
}

/// Handler for GetBroadcastStats
impl Handler<crate::actors::messages::GetBroadcastStats> for ForceComputeActor {
    type Result = Result<crate::actors::messages::BroadcastPerformanceStats, String>;

    fn handle(&mut self, _msg: crate::actors::messages::GetBroadcastStats, _ctx: &mut Self::Context) -> Self::Result {
        let stats = self.broadcast_optimizer.get_performance_stats();

        // Convert from gpu::broadcast_optimizer::BroadcastPerformanceStats
        // to actors::messages::BroadcastPerformanceStats
        Ok(crate::actors::messages::BroadcastPerformanceStats {
            total_frames_processed: stats.total_frames_processed,
            total_nodes_sent: stats.total_nodes_sent,
            total_nodes_processed: stats.total_nodes_processed,
            average_bandwidth_reduction: stats.average_bandwidth_reduction,
            target_fps: stats.target_fps,
            delta_threshold: stats.delta_threshold,
        })
    }
}

// =============================================================================
// Phase 5: GPU Backpressure - Token Bucket Flow Control Handler
// =============================================================================

/// Handler for PositionBroadcastAck - replenishes tokens when network confirms delivery
/// This implements token bucket flow control between GPU producer and network consumer
impl Handler<crate::actors::messages::PositionBroadcastAck> for ForceComputeActor {
    type Result = ();

    fn handle(&mut self, msg: crate::actors::messages::PositionBroadcastAck, _ctx: &mut Self::Context) -> Self::Result {
        // Acknowledge to backpressure controller - this restores tokens
        self.backpressure.acknowledge(msg.clients_delivered as usize);

        // Log token restoration at debug level (every 300 acks to avoid spam)
        if msg.correlation_id % 300 == 0 {
            let metrics = self.backpressure.metrics();
            debug!("ForceComputeActor: Broadcast ack received (correlation_id: {}, clients: {}), tokens: {}/{}, congestion: {:.1}ms",
                   msg.correlation_id, msg.clients_delivered,
                   metrics.available_tokens, metrics.max_tokens,
                   metrics.total_congestion_duration.as_secs_f32() * 1000.0);
        }
    }
}

--------------------------------------------------------------------------------
FILE: src/actors/gpu/semantic_forces_actor.rs
PURPOSE: Semantic relationship forces actor
--------------------------------------------------------------------------------
//! Semantic Forces Actor - Handles DAG layout, type clustering, and collision detection
//! Integrates with GPU kernels in semantic_forces.cu for advanced graph layout

use actix::prelude::*;
use log::{debug, info, warn};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::time::Instant;

use super::shared::{GPUState, SharedGPUContext};
use crate::actors::messages::*;
use crate::telemetry::agent_telemetry::{
    get_telemetry_logger, CorrelationId, LogLevel, TelemetryEvent,
};

// Re-export message types for handlers
pub use crate::actors::messages::{
    ConfigureCollision, ConfigureDAG, ConfigureTypeClustering,
    GetHierarchyLevels, GetSemanticConfig, RecalculateHierarchy,
};

// =============================================================================
// GPU Kernel FFI Declarations
// =============================================================================
#[repr(C)]
struct DAGConfigGPU {
    vertical_spacing: f32,
    horizontal_spacing: f32,
    level_attraction: f32,
    sibling_repulsion: f32,
    enabled: bool,
}
#[repr(C)]
struct TypeClusterConfigGPU {
    cluster_attraction: f32,
    cluster_radius: f32,
    inter_cluster_repulsion: f32,
    enabled: bool,
}
#[repr(C)]
struct CollisionConfigGPU {
    min_distance: f32,
    collision_strength: f32,
    node_radius: f32,
    enabled: bool,
}
#[repr(C)]
struct AttributeSpringConfigGPU {
    base_spring_k: f32,
    weight_multiplier: f32,
    rest_length_min: f32,
    rest_length_max: f32,
    enabled: bool,
}
#[repr(C)]
struct SemanticConfigGPU {
    dag: DAGConfigGPU,
    type_cluster: TypeClusterConfigGPU,
    collision: CollisionConfigGPU,
    attribute_spring: AttributeSpringConfigGPU,
}

// =============================================================================
// Dynamic Force Configuration (Schema-Code Decoupling)
// =============================================================================

/// GPU-compatible dynamic force configuration for a relationship type
/// Matches the DynamicForceConfig struct in semantic_forces.cu
#[repr(C)]
#[derive(Clone, Copy, Debug)]
pub struct DynamicForceConfigGPU {
    pub strength: f32,        // Spring strength (can be negative for repulsion)
    pub rest_length: f32,     // Rest length for spring calculations
    pub is_directional: i32,  // 1 = directional, 0 = bidirectional
    pub force_type: u32,      // Force behavior type (0=spring, 1=orbit, 2=cross-domain, 3=repulsion)
}

impl Default for DynamicForceConfigGPU {
    fn default() -> Self {
        Self {
            strength: 0.5,
            rest_length: 100.0,
            is_directional: 0,
            force_type: 0,
        }
    }
}

#[repr(C)]
#[derive(Clone, Copy)]
struct Float3 {
    x: f32,
    y: f32,
    z: f32,
}
extern "C" {
    /// Upload semantic configuration to GPU constant memory
    fn set_semantic_config(config: *const SemanticConfigGPU);

    /// Apply DAG layout forces based on hierarchy levels
    fn apply_dag_force(
        node_hierarchy_levels: *const i32,
        node_types: *const i32,
        positions: *mut Float3,
        forces: *mut Float3,
        num_nodes: i32,
    );

    /// Apply type clustering forces
    fn apply_type_cluster_force(
        node_types: *const i32,
        type_centroids: *const Float3,
        positions: *mut Float3,
        forces: *mut Float3,
        num_nodes: i32,
        num_types: i32,
    );

    /// Apply collision detection and response forces
    fn apply_collision_force(
        node_radii: *const f32,
        positions: *mut Float3,
        forces: *mut Float3,
        num_nodes: i32,
    );

    /// Apply attribute-weighted spring forces
    fn apply_attribute_spring_force(
        edge_sources: *const i32,
        edge_targets: *const i32,
        edge_weights: *const f32,
        edge_types: *const i32,
        positions: *mut Float3,
        forces: *mut Float3,
        num_edges: i32,
    );

    /// Calculate hierarchy levels for DAG layout
    fn calculate_hierarchy_levels(
        edge_sources: *const i32,
        edge_targets: *const i32,
        edge_types: *const i32,
        node_levels: *mut i32,
        changed: *mut bool,
        num_edges: i32,
        num_nodes: i32,
    );

    /// Calculate centroid positions for each node type
    fn calculate_type_centroids(
        node_types: *const i32,
        positions: *const Float3,
        type_centroids: *mut Float3,
        type_counts: *mut i32,
        num_nodes: i32,
        num_types: i32,
    );

    /// Finalize centroids by dividing by count
    fn finalize_type_centroids(
        type_centroids: *mut Float3,
        type_counts: *const i32,
        num_types: i32,
    );

    // ==========================================================================
    // Dynamic Relationship Buffer Management (Hot-Reload)
    // ==========================================================================

    /// Upload dynamic relationship configurations to GPU
    /// Enables ontology changes without CUDA recompilation
    fn set_dynamic_relationship_buffer(
        configs: *const DynamicForceConfigGPU,
        num_types: i32,
        enabled: bool,
    ) -> i32;

    /// Update a single relationship type configuration (hot-reload)
    fn update_dynamic_relationship_config(
        type_id: i32,
        config: *const DynamicForceConfigGPU,
    ) -> i32;

    /// Enable or disable dynamic relationship forces
    fn set_dynamic_relationships_enabled(enabled: bool) -> i32;

    /// Get current buffer version for hot-reload detection
    fn get_dynamic_relationship_buffer_version() -> i32;

    /// Get maximum supported relationship types
    fn get_max_relationship_types() -> i32;

    /// Apply dynamic relationship forces (schema-code decoupled)
    fn apply_dynamic_relationship_force(
        edge_sources: *const i32,
        edge_targets: *const i32,
        edge_types: *const i32,
        node_cross_domain_count: *const i32,
        positions: *mut Float3,
        forces: *mut Float3,
        num_edges: i32,
    );
}

/// DAG layout configuration matching GPU kernel structure
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DAGConfig {
    pub vertical_spacing: f32,      // Vertical separation between hierarchy levels
    pub horizontal_spacing: f32,    // Minimum horizontal separation within a level
    pub level_attraction: f32,      // Strength of attraction to target level
    pub sibling_repulsion: f32,     // Repulsion between nodes at same level
    pub enabled: bool,
    pub layout_mode: DAGLayoutMode,
}

/// DAG layout modes for different visual hierarchies
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum DAGLayoutMode {
    TopDown,      // Traditional top-down hierarchy
    Radial,       // Radial/circular hierarchy
    LeftRight,    // Left-to-right hierarchy
}

impl Default for DAGConfig {
    fn default() -> Self {
        Self {
            vertical_spacing: 100.0,
            horizontal_spacing: 50.0,
            level_attraction: 0.5,
            sibling_repulsion: 0.3,
            enabled: false,
            layout_mode: DAGLayoutMode::TopDown,
        }
    }
}

/// Type clustering configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TypeClusterConfig {
    pub cluster_attraction: f32,    // Attraction between nodes of same type
    pub cluster_radius: f32,        // Target radius for type clusters
    pub inter_cluster_repulsion: f32, // Repulsion between different type clusters
    pub enabled: bool,
}

impl Default for TypeClusterConfig {
    fn default() -> Self {
        Self {
            cluster_attraction: 0.4,
            cluster_radius: 80.0,
            inter_cluster_repulsion: 0.2,
            enabled: false,
        }
    }
}

/// Collision detection configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CollisionConfig {
    pub min_distance: f32,          // Minimum allowed distance between nodes
    pub collision_strength: f32,    // Force strength when colliding
    pub node_radius: f32,           // Default node radius
    pub enabled: bool,
}

impl Default for CollisionConfig {
    fn default() -> Self {
        Self {
            min_distance: 10.0,
            collision_strength: 0.8,
            node_radius: 15.0,
            enabled: true,
        }
    }
}

/// Attribute-weighted spring configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AttributeSpringConfig {
    pub base_spring_k: f32,         // Base spring constant
    pub weight_multiplier: f32,     // Multiplier for edge weight influence
    pub rest_length_min: f32,       // Minimum rest length
    pub rest_length_max: f32,       // Maximum rest length
    pub enabled: bool,
}

impl Default for AttributeSpringConfig {
    fn default() -> Self {
        Self {
            base_spring_k: 0.1,
            weight_multiplier: 1.5,
            rest_length_min: 50.0,
            rest_length_max: 200.0,
            enabled: false,
        }
    }
}

/// Combined semantic configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SemanticConfig {
    pub dag: DAGConfig,
    pub type_cluster: TypeClusterConfig,
    pub collision: CollisionConfig,
    pub attribute_spring: AttributeSpringConfig,
}

impl Default for SemanticConfig {
    fn default() -> Self {
        Self {
            dag: DAGConfig::default(),
            type_cluster: TypeClusterConfig::default(),
            collision: CollisionConfig::default(),
            attribute_spring: AttributeSpringConfig::default(),
        }
    }
}

/// Node hierarchy level assignment
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HierarchyLevels {
    pub node_levels: Vec<i32>,      // Hierarchy level for each node (-1 = not in DAG)
    pub max_level: i32,             // Maximum hierarchy level
    pub level_counts: Vec<usize>,   // Number of nodes at each level
}

/// Type centroid positions
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TypeCentroids {
    pub centroids: Vec<(f32, f32, f32)>,  // Centroid position for each type
    pub type_counts: Vec<usize>,          // Number of nodes of each type
}

/// Semantic Forces Actor - manages semantic layout forces
pub struct SemanticForcesActor {
    /// Shared GPU context for accessing GPU resources
    shared_context: Option<Arc<SharedGPUContext>>,

    /// Current semantic configuration
    config: SemanticConfig,

    /// GPU state tracking
    gpu_state: GPUState,

    /// Cached hierarchy levels (computed on demand)
    hierarchy_levels: Option<HierarchyLevels>,

    /// Cached type centroids (recomputed each frame)
    type_centroids: Option<TypeCentroids>,

    /// Number of node types in the graph
    num_types: usize,

    /// Cached node types array for GPU access
    node_types: Vec<i32>,

    /// Cached edge data for attribute springs
    edge_sources: Vec<i32>,
    edge_targets: Vec<i32>,
    edge_weights: Vec<f32>,
    edge_types: Vec<i32>,
}

impl SemanticForcesActor {
    pub fn new() -> Self {
        Self {
            shared_context: None,
            config: SemanticConfig::default(),
            gpu_state: GPUState::default(),
            hierarchy_levels: None,
            type_centroids: None,
            num_types: 0,
            node_types: Vec::new(),
            edge_sources: Vec::new(),
            edge_targets: Vec::new(),
            edge_weights: Vec::new(),
            edge_types: Vec::new(),
        }
    }

    /// Convert Rust config to GPU C-compatible struct
    fn config_to_gpu(&self) -> SemanticConfigGPU {
        SemanticConfigGPU {
            dag: DAGConfigGPU {
                vertical_spacing: self.config.dag.vertical_spacing,
                horizontal_spacing: self.config.dag.horizontal_spacing,
                level_attraction: self.config.dag.level_attraction,
                sibling_repulsion: self.config.dag.sibling_repulsion,
                enabled: self.config.dag.enabled,
            },
            type_cluster: TypeClusterConfigGPU {
                cluster_attraction: self.config.type_cluster.cluster_attraction,
                cluster_radius: self.config.type_cluster.cluster_radius,
                inter_cluster_repulsion: self.config.type_cluster.inter_cluster_repulsion,
                enabled: self.config.type_cluster.enabled,
            },
            collision: CollisionConfigGPU {
                min_distance: self.config.collision.min_distance,
                collision_strength: self.config.collision.collision_strength,
                node_radius: self.config.collision.node_radius,
                enabled: self.config.collision.enabled,
            },
            attribute_spring: AttributeSpringConfigGPU {
                base_spring_k: self.config.attribute_spring.base_spring_k,
                weight_multiplier: self.config.attribute_spring.weight_multiplier,
                rest_length_min: self.config.attribute_spring.rest_length_min,
                rest_length_max: self.config.attribute_spring.rest_length_max,
                enabled: self.config.attribute_spring.enabled,
            },
        }
    }

    /// Calculate hierarchy levels using topological sort (BFS-style on GPU)
    fn calculate_hierarchy_levels(
        &mut self,
        num_nodes: usize,
        num_edges: usize,
    ) -> Result<HierarchyLevels, String> {
        info!("SemanticForcesActor: Calculating hierarchy levels for {} nodes, {} edges",
              num_nodes, num_edges);

        let _shared_context = self.shared_context.as_ref()
            .ok_or("GPU context not initialized")?;

        // Initialize node levels to -1 (not in hierarchy)
        let mut node_levels = vec![-1i32; num_nodes];

        // Find root nodes (nodes with no incoming hierarchy edges)
        let mut has_incoming_hierarchy = vec![false; num_nodes];
        for i in 0..self.edge_sources.len() {
            if self.edge_types[i] == 2 { // Hierarchy edge type = 2
                let target = self.edge_targets[i] as usize;
                if target < num_nodes {
                    has_incoming_hierarchy[target] = true;
                }
            }
        }

        // Set root nodes to level 0
        for (i, &has_incoming) in has_incoming_hierarchy.iter().enumerate() {
            if !has_incoming {
                node_levels[i] = 0;
            }
        }
        {
            // GPU-accelerated hierarchy computation using parallel BFS
            if num_edges > 0 && !self.edge_sources.is_empty() {
                let mut changed = true;
                let mut iteration = 0;
                const MAX_ITERATIONS: usize = 100;

                while changed && iteration < MAX_ITERATIONS {
                    changed = false;
                    unsafe {
                        calculate_hierarchy_levels(
                            self.edge_sources.as_ptr(),
                            self.edge_targets.as_ptr(),
                            self.edge_types.as_ptr(),
                            node_levels.as_mut_ptr(),
                            &mut changed as *mut bool,
                            num_edges as i32,
                            num_nodes as i32,
                        );
                    }
                    iteration += 1;
                }

                if iteration >= MAX_ITERATIONS {
                    warn!("SemanticForcesActor: Hierarchy calculation reached max iterations");
                }
            }
        }

        // Calculate max_level and level_counts before moving node_levels
        let max_level = node_levels.iter().copied().max().unwrap_or(0);
        let mut level_counts = vec![0; (max_level + 1) as usize];
        for &level in &node_levels {
            if level >= 0 {
                level_counts[level as usize] += 1;
            }
        }

        // Return computed hierarchy levels
        Ok(HierarchyLevels {
            node_levels,
            max_level,
            level_counts,
        })
    }

    /// Calculate centroids for each node type
    fn calculate_type_centroids(
        &mut self,
        positions: &[(f32, f32, f32)],
        num_nodes: usize,
    ) -> Result<TypeCentroids, String> {
        if self.num_types == 0 {
            return Ok(TypeCentroids {
                centroids: Vec::new(),
                type_counts: Vec::new(),
            });
        }

        let mut centroids = vec![(0.0f32, 0.0f32, 0.0f32); self.num_types];
        let mut type_counts = vec![0usize; self.num_types];

        // Calculate type centroids using GPU
        if self.shared_context.is_some() && num_nodes > 0 && !self.node_types.is_empty() {
            let mut centroid_f3 = vec![Float3 { x: 0.0, y: 0.0, z: 0.0 }; self.num_types];
            let mut counts_i32 = vec![0i32; self.num_types];

            let positions_f3: Vec<Float3> = positions.iter()
                .map(|(x, y, z)| Float3 { x: *x, y: *y, z: *z })
                .collect();

            unsafe {
                calculate_type_centroids(
                    self.node_types.as_ptr(),
                    positions_f3.as_ptr(),
                    centroid_f3.as_mut_ptr(),
                    counts_i32.as_mut_ptr(),
                    num_nodes as i32,
                    self.num_types as i32,
                );

                finalize_type_centroids(
                    centroid_f3.as_mut_ptr(),
                    counts_i32.as_ptr(),
                    self.num_types as i32,
                );
            }

            centroids = centroid_f3.iter()
                .map(|f3| (f3.x, f3.y, f3.z))
                .collect();
            type_counts = counts_i32.iter()
                .map(|&c| c as usize)
                .collect();
        }

        Ok(TypeCentroids {
            centroids,
            type_counts,
        })
    }
}

// Actor implementation
impl Actor for SemanticForcesActor {
    type Context = Context<Self>;

    fn started(&mut self, _ctx: &mut Self::Context) {
        info!("SemanticForcesActor started");
    }

    fn stopped(&mut self, _ctx: &mut Self::Context) {
        info!("SemanticForcesActor stopped");
    }
}
--------------------------------------------------------------------------------
FILE: src/actors/gpu/clustering_actor.rs
PURPOSE: Graph clustering actor
--------------------------------------------------------------------------------
//! Clustering Actor - Handles K-means clustering and community detection algorithms

use actix::prelude::*;
use log::{error, info};
use rand::Rng;
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::time::Instant;
use uuid::Uuid;

use super::shared::{GPUState, SharedGPUContext};
use crate::actors::messages::*;

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClusteringStats {
    pub total_clusters: usize,
    pub average_cluster_size: f32,
    pub largest_cluster_size: usize,
    pub smallest_cluster_size: usize,
    pub silhouette_score: f32,
    pub computation_time_ms: u64,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CommunityDetectionStats {
    pub total_communities: usize,
    pub modularity: f32,
    pub average_community_size: f32,
    pub largest_community: usize,
    pub smallest_community: usize,
    pub computation_time_ms: u64,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Community {
    pub id: String,
    pub nodes: Vec<u32>,
    pub internal_edges: usize,
    pub external_edges: usize,
    pub density: f32,
}

///
pub struct ClusteringActor {
    
    gpu_state: GPUState,

    
    shared_context: Option<Arc<SharedGPUContext>>,
}

impl ClusteringActor {
    pub fn new() -> Self {
        Self {
            gpu_state: GPUState::default(),
            shared_context: None,
        }
    }

    
    fn generate_cluster_keywords(nodes: &[u32]) -> Vec<String> {
        if nodes.is_empty() {
            return vec!["empty".to_string()];
        }

        
        let mut keywords = Vec::new();
        match nodes.len() {
            1 => keywords.push("singleton".to_string()),
            2..=5 => keywords.push("small".to_string()),
            6..=20 => keywords.push("medium".to_string()),
            _ => keywords.push("large".to_string()),
        }

        
        keywords.push(format!("cluster-{}", nodes[0] % 10));
        keywords
    }

    
    async fn perform_kmeans_clustering(
        &mut self,
        params: KMeansParams,
    ) -> Result<KMeansResult, String> {
        info!(
            "ClusteringActor: Starting K-means clustering with {} clusters",
            params.num_clusters
        );

        let mut unified_compute = match &self.shared_context {
            Some(ctx) => ctx
                .unified_compute
                .lock()
                .map_err(|e| format!("Failed to acquire GPU compute lock: {}", e))?,
            None => {
                return Err("GPU context not initialized".to_string());
            }
        };

        let start_time = Instant::now();

        
        let gpu_result = unified_compute
            .run_kmeans_clustering_with_metrics(
                params.num_clusters,
                params.max_iterations.unwrap_or(100),
                params.tolerance.unwrap_or(0.001),
                params.seed.unwrap_or(42),
            )
            .map_err(|e| {
                error!("GPU K-means clustering failed: {}", e);
                format!("K-means clustering failed: {}", e)
            })?;

        let computation_time = start_time.elapsed();
        info!(
            "ClusteringActor: K-means clustering completed in {:?}",
            computation_time
        );

        
        let (assignments, centroids, inertia, actual_iterations, converged) = gpu_result;
        let clusters = self.convert_gpu_kmeans_result_to_clusters(
            assignments.iter().map(|&x| x as u32).collect(),
            params.num_clusters as u32,
        )?;

        
        let cluster_sizes: Vec<usize> = clusters.iter().map(|c| c.nodes.len()).collect();
        let avg_cluster_size = if !cluster_sizes.is_empty() {
            cluster_sizes.iter().sum::<usize>() as f32 / cluster_sizes.len() as f32
        } else {
            0.0
        };

        
        let silhouette_score = if clusters.len() > 1 && !assignments.is_empty() {
            self.calculate_silhouette_score(&assignments, &centroids, &clusters)?
        } else {
            0.0
        };

        let cluster_stats = ClusteringStats {
            total_clusters: clusters.len(),
            average_cluster_size: avg_cluster_size,
            largest_cluster_size: cluster_sizes.iter().max().copied().unwrap_or(0),
            smallest_cluster_size: cluster_sizes.iter().min().copied().unwrap_or(0),
            silhouette_score,
            computation_time_ms: computation_time.as_millis() as u64,
        };

        Ok(KMeansResult {
            cluster_assignments: assignments,
            centroids,
            inertia,
            iterations: actual_iterations,
            clusters,
            stats: cluster_stats,
            converged,
            final_iteration: actual_iterations,
        })
    }

    
    async fn perform_community_detection(
        &mut self,
        params: CommunityDetectionParams,
    ) -> Result<CommunityDetectionResult, String> {
        info!(
            "ClusteringActor: Starting {:?} community detection",
            params.algorithm
        );

        let mut unified_compute = match &self.shared_context {
            Some(ctx) => ctx
                .unified_compute
                .lock()
                .map_err(|e| format!("Failed to acquire GPU compute lock: {}", e))?,
            None => {
                return Err("GPU context not initialized".to_string());
            }
        };

        let start_time = Instant::now();

        
        let gpu_result = match params.algorithm {
            CommunityDetectionAlgorithm::LabelPropagation => unified_compute
                .run_community_detection_label_propagation(
                    params.max_iterations.unwrap_or(100),
                    params.seed.unwrap_or(42),
                )
                .map_err(|e| {
                    error!("GPU label propagation failed: {}", e);
                    format!("Label propagation failed: {}", e)
                })?,
            CommunityDetectionAlgorithm::Louvain => {
                unified_compute
                    .run_louvain_community_detection(
                        params.max_iterations.unwrap_or(100),
                        1.0, 
                        params.seed.unwrap_or(42),
                    )
                    .map_err(|e| {
                        error!("GPU Louvain community detection failed: {}", e);
                        format!("Louvain community detection failed: {}", e)
                    })?
            } 
              
              
              
        };

        let computation_time = start_time.elapsed();
        info!(
            "ClusteringActor: Community detection completed in {:?}",
            computation_time
        );

        
        let (node_labels, num_communities, modularity, iterations, community_sizes, converged) =
            gpu_result;
        let communities = self.convert_gpu_community_result_to_communities(
            node_labels.iter().map(|&x| x as u32).collect(),
        )?;

        
        let actual_community_sizes: Vec<usize> =
            communities.iter().map(|c| c.nodes.len()).collect();
        let actual_modularity = self.calculate_modularity(&communities);

        let stats = CommunityDetectionStats {
            total_communities: communities.len(),
            modularity: actual_modularity,
            average_community_size: if !actual_community_sizes.is_empty() {
                actual_community_sizes.iter().sum::<usize>() as f32
                    / actual_community_sizes.len() as f32
            } else {
                0.0
            },
            largest_community: actual_community_sizes.iter().max().copied().unwrap_or(0) as usize,
            smallest_community: actual_community_sizes.iter().min().copied().unwrap_or(0) as usize,
            computation_time_ms: computation_time.as_millis() as u64,
        };

        Ok(CommunityDetectionResult {
            node_labels: node_labels,
            num_communities,
            modularity,
            iterations,
            community_sizes,
            converged,
            communities,
            stats,
            algorithm: params.algorithm,
        })
    }

    
    fn convert_gpu_kmeans_result_to_clusters(
        &self,
        gpu_result: Vec<u32>,
        num_clusters: u32,
    ) -> Result<Vec<crate::handlers::api_handler::analytics::Cluster>, String> {
        if gpu_result.len() != self.gpu_state.num_nodes as usize {
            return Err(format!(
                "GPU result size mismatch: expected {}, got {}",
                self.gpu_state.num_nodes,
                gpu_result.len()
            ));
        }

        
        let mut cluster_nodes: Vec<Vec<u32>> = vec![Vec::new(); num_clusters as usize];

        for (node_idx, &cluster_id) in gpu_result.iter().enumerate() {
            if (cluster_id as usize) < cluster_nodes.len() {
                cluster_nodes[cluster_id as usize].push(node_idx as u32);
            }
        }

        
        let mut clusters = Vec::new();
        for (cluster_id, nodes) in cluster_nodes.into_iter().enumerate() {
            if !nodes.is_empty() {
                clusters.push(crate::handlers::api_handler::analytics::Cluster {
                    id: Uuid::new_v4().to_string(),
                    label: format!("Cluster {}", cluster_id),
                    node_count: nodes.len() as u32,
                    coherence: {
                        
                        let assignments_i32: Vec<i32> =
                            gpu_result.iter().map(|&x| x as i32).collect();
                        self.calculate_cluster_coherence(&nodes, &assignments_i32)
                    },
                    color: format!(
                        "#{:02X}{:02X}{:02X}",
                        (cluster_id * 50 % 255) as u8,
                        (cluster_id * 100 % 255) as u8,
                        (cluster_id * 150 % 255) as u8
                    ),
                    keywords: Self::generate_cluster_keywords(&nodes),
                    centroid: Some(self.calculate_cluster_centroid(&nodes)),
                    nodes,
                });
            }
        }

        info!(
            "ClusteringActor: Generated {} non-empty clusters",
            clusters.len()
        );
        Ok(clusters)
    }

    
    fn convert_gpu_community_result_to_communities(
        &self,
        gpu_result: Vec<u32>,
    ) -> Result<Vec<Community>, String> {
        if gpu_result.len() != self.gpu_state.num_nodes as usize {
            return Err(format!(
                "GPU result size mismatch: expected {}, got {}",
                self.gpu_state.num_nodes,
                gpu_result.len()
            ));
        }

        
        let mut community_nodes: std::collections::HashMap<u32, Vec<u32>> =
            std::collections::HashMap::new();

        for (node_idx, &community_id) in gpu_result.iter().enumerate() {
            community_nodes
                .entry(community_id)
                .or_insert_with(Vec::new)
                .push(node_idx as u32);
        }

        
        let mut communities = Vec::new();
        for (community_id, nodes) in community_nodes {
            let internal_edges = self.calculate_internal_edges(&nodes);
            let external_edges = self.calculate_external_edges(&nodes);
            let density = self.calculate_community_density(&nodes);

            communities.push(Community {
                id: community_id.to_string(),
                nodes,
                internal_edges,
                external_edges,
                density,
            });
        }

        info!(
            "ClusteringActor: Generated {} communities",
            communities.len()
        );
        Ok(communities)
    }

    
    fn generate_cluster_color(cluster_id: usize) -> [f32; 3] {
        let mut rng = rand::thread_rng();

        
        let hue = (cluster_id as f32 * 137.5) % 360.0; 
        let saturation = 0.7 + (rng.gen::<f32>() * 0.3); 
        let value = 0.8 + (rng.gen::<f32>() * 0.2); 

        
        let c = value * saturation;
        let x = c * (1.0 - ((hue / 60.0) % 2.0 - 1.0).abs());
        let m = value - c;

        let (r, g, b) = match hue as i32 / 60 {
            0 => (c, x, 0.0),
            1 => (x, c, 0.0),
            2 => (0.0, c, x),
            3 => (0.0, x, c),
            4 => (x, 0.0, c),
            _ => (c, 0.0, x),
        };

        [r + m, g + m, b + m]
    }

    
    
    fn calculate_silhouette_score(
        &self,
        assignments: &[i32],
        centroids: &[(f32, f32, f32)],
        clusters: &[crate::handlers::api_handler::analytics::Cluster],
    ) -> Result<f32, String> {
        if clusters.len() < 2 || assignments.is_empty() {
            return Ok(0.0);
        }

        
        let mut total_silhouette = 0.0;
        let mut valid_samples = 0;

        for (node_idx, &cluster_id) in assignments.iter().enumerate() {
            if cluster_id < 0 || cluster_id as usize >= centroids.len() {
                continue;
            }

            
            let own_cluster_nodes: Vec<usize> = assignments
                .iter()
                .enumerate()
                .filter(|(_, &cid)| cid == cluster_id)
                .map(|(idx, _)| idx)
                .collect();

            let intra_cluster_distance = if own_cluster_nodes.len() > 1 {
                let mut total_distance = 0.0;
                let mut count = 0;
                for &other_node in &own_cluster_nodes {
                    if other_node != node_idx {
                        total_distance +=
                            self.calculate_node_distance(node_idx, other_node, centroids);
                        count += 1;
                    }
                }
                if count > 0 {
                    total_distance / count as f32
                } else {
                    0.0
                }
            } else {
                0.0
            };

            
            let mut min_inter_cluster_distance = f32::INFINITY;
            for other_cluster_id in 0..centroids.len() {
                if other_cluster_id != cluster_id as usize {
                    let other_cluster_nodes: Vec<usize> = assignments
                        .iter()
                        .enumerate()
                        .filter(|(_, &cid)| cid == other_cluster_id as i32)
                        .map(|(idx, _)| idx)
                        .collect();

                    if !other_cluster_nodes.is_empty() {
                        let mut total_distance = 0.0;
                        for &other_node in &other_cluster_nodes {
                            total_distance +=
                                self.calculate_node_distance(node_idx, other_node, centroids);
                        }
                        let avg_distance = total_distance / other_cluster_nodes.len() as f32;
                        min_inter_cluster_distance = min_inter_cluster_distance.min(avg_distance);
                    }
                }
            }

            
            if min_inter_cluster_distance.is_finite() && intra_cluster_distance.is_finite() {
                let max_distance = intra_cluster_distance.max(min_inter_cluster_distance);
                if max_distance > 0.0 {
                    let silhouette =
                        (min_inter_cluster_distance - intra_cluster_distance) / max_distance;
                    total_silhouette += silhouette;
                    valid_samples += 1;
                }
            }
        }

        Ok(if valid_samples > 0 {
            total_silhouette / valid_samples as f32
        } else {
            0.0
        })
    }

    
    fn calculate_node_distance(
        &self,
        node1: usize,
        node2: usize,
        centroids: &[(f32, f32, f32)],
    ) -> f32 {
        
        
        let diff = (node1 as f32 - node2 as f32).abs();

        
        if !centroids.is_empty() {
            let centroid_idx = (node1 + node2) % centroids.len();
            let (cx, cy, cz) = centroids[centroid_idx];
            let centroid_magnitude = (cx * cx + cy * cy + cz * cz).sqrt();
            diff + centroid_magnitude * 0.1
        } else {
            diff
        }
    }

    
    fn calculate_modularity(&self, communities: &[Community]) -> f32 {
        let _num_nodes = self.gpu_state.num_nodes as f32;
        let total_edges = communities
            .iter()
            .map(|c| c.internal_edges + c.external_edges)
            .sum::<usize>() as f32;

        if total_edges == 0.0 || communities.is_empty() {
            return 0.0;
        }

        let mut modularity = 0.0;

        for community in communities {
            let m = total_edges / 2.0; 
            let e_in = community.internal_edges as f32 / (2.0 * m); 
            let degree_sum = (community.internal_edges + community.external_edges) as f32;
            let a_sq = (degree_sum / (2.0 * m)).powi(2); 

            modularity += e_in - a_sq;
        }

        modularity.max(0.0).min(1.0)
    }

    
    fn calculate_cluster_coherence(&self, nodes: &[u32], _assignments: &[i32]) -> f32 {
        if nodes.len() < 2 {
            return 1.0;
        }

        
        let mut total_distance = 0.0;
        let mut pair_count = 0;

        for i in 0..nodes.len() {
            for j in (i + 1)..nodes.len() {
                let dist = ((nodes[i] as f32 - nodes[j] as f32).abs() + 1.0).ln();
                total_distance += dist;
                pair_count += 1;
            }
        }

        if pair_count > 0 {
            let avg_distance = total_distance / pair_count as f32;
            (1.0 / (1.0 + avg_distance)).max(0.1).min(1.0)
        } else {
            1.0
        }
    }

    
    fn calculate_cluster_centroid(&self, nodes: &[u32]) -> [f32; 3] {
        if nodes.is_empty() {
            return [0.0, 0.0, 0.0];
        }

        
        let sum_x: f32 = nodes.iter().map(|&n| (n % 100) as f32).sum();
        let sum_y: f32 = nodes.iter().map(|&n| ((n / 100) % 100) as f32).sum();
        let sum_z: f32 = nodes.iter().map(|&n| (n / 10000) as f32).sum();

        let count = nodes.len() as f32;
        [sum_x / count, sum_y / count, sum_z / count]
    }

    
    fn calculate_internal_edges(&self, nodes: &[u32]) -> usize {
        
        
        let n = nodes.len();
        if n < 2 {
            0
        } else {
            
            ((n * (n - 1)) as f32 * 0.3 / 2.0) as usize
        }
    }

    
    fn calculate_external_edges(&self, nodes: &[u32]) -> usize {
        
        let n = nodes.len();
        let total_nodes = self.gpu_state.num_nodes as usize;
        let external_nodes = total_nodes - n;

        if external_nodes > 0 {
            
            (n * external_nodes / 20).max(1)
        } else {
            0
        }
    }

    
    fn calculate_community_density(&self, nodes: &[u32]) -> f32 {
        let n = nodes.len();
        if n < 2 {
            return 1.0;
        }

        let max_possible_edges = n * (n - 1) / 2;
        let actual_edges = self.calculate_internal_edges(nodes);

        (actual_edges as f32 / max_possible_edges as f32).min(1.0)
    }
}

impl Actor for ClusteringActor {
    type Context = Context<Self>;

    fn started(&mut self, _ctx: &mut Self::Context) {
        info!("Clustering Actor started");
    }

    fn stopped(&mut self, _ctx: &mut Self::Context) {
        info!("Clustering Actor stopped");
    }
}

// === Message Handlers ===

///
impl Handler<SetSharedGPUContext> for ClusteringActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: SetSharedGPUContext, _ctx: &mut Self::Context) -> Self::Result {
        info!("ClusteringActor: Received SharedGPUContext from ResourceActor");
        self.shared_context = Some(msg.context);
        
        info!("ClusteringActor: SharedGPUContext stored successfully");
        Ok(())
    }
}

///
impl Handler<RunKMeans> for ClusteringActor {
    type Result = actix::ResponseFuture<Result<KMeansResult, String>>;

    fn handle(&mut self, msg: RunKMeans, _ctx: &mut Self::Context) -> Self::Result {
        info!(
            "ClusteringActor: Received RunKMeans request with {} clusters",
            msg.params.num_clusters
        );

        
        let mut actor_clone = Self {
            gpu_state: self.gpu_state.clone(),
            shared_context: self.shared_context.clone(),
        };

        Box::pin(async move { actor_clone.perform_kmeans_clustering(msg.params).await })
    }
}

///
impl Handler<RunCommunityDetection> for ClusteringActor {
    type Result = actix::ResponseFuture<Result<CommunityDetectionResult, String>>;

    fn handle(&mut self, msg: RunCommunityDetection, _ctx: &mut Self::Context) -> Self::Result {
        info!("ClusteringActor: Received RunCommunityDetection request");

        
        let mut actor_clone = Self {
            gpu_state: self.gpu_state.clone(),
            shared_context: self.shared_context.clone(),
        };

        Box::pin(async move { actor_clone.perform_community_detection(msg.params).await })
    }
}

///
impl Handler<PerformGPUClustering> for ClusteringActor {
    type Result = actix::ResponseFuture<
        Result<Vec<crate::handlers::api_handler::analytics::Cluster>, String>,
    >;

    fn handle(&mut self, msg: PerformGPUClustering, _ctx: &mut Self::Context) -> Self::Result {
        info!(
            "ClusteringActor: Received PerformGPUClustering request with method: {}",
            msg.method
        );

        
        let mut actor_clone = Self {
            gpu_state: self.gpu_state.clone(),
            shared_context: self.shared_context.clone(),
        };

        Box::pin(async move {
            
            let params = KMeansParams {
                num_clusters: msg.params.num_clusters.unwrap_or(5) as usize,
                max_iterations: msg.params.max_iterations,
                tolerance: msg.params.convergence_threshold,
                seed: None,
            };

            
            let result = actor_clone.perform_kmeans_clustering(params).await?;

            
            Ok(result.clusters)
        })
    }
}

--------------------------------------------------------------------------------
FILE: src/actors/gpu/shortest_path_actor.rs
PURPOSE: SSSP pathfinding actor
--------------------------------------------------------------------------------
//! Shortest Path Actor - Handles SSSP and APSP computations on GPU
//!
//! This actor wraps the existing GPU kernels for:
//! - Single-Source Shortest Path (SSSP) using Bellman-Ford-based frontier compaction
//! - All-Pairs Shortest Path (APSP) using landmark-based approximation
//!
//! Use cases:
//! - Path highlighting in graph visualization
//! - Route visualization for navigation
//! - Connectivity analysis
//! - Distance-based graph analytics

use actix::prelude::*;
use log::{error, info, warn};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::time::Instant;

use super::shared::{GPUState, SharedGPUContext};
use crate::actors::messages::*;

/// SSSP computation parameters
#[derive(Debug, Clone, Serialize, Deserialize, Message)]
#[rtype(result = "Result<SSSPResult, String>")]
pub struct ComputeSSP {
    /// Source node index for SSSP computation
    pub source_idx: usize,
    /// Optional maximum distance cutoff
    pub max_distance: Option<f32>,
}

/// APSP computation parameters
#[derive(Debug, Clone, Serialize, Deserialize, Message)]
#[rtype(result = "Result<APSPResult, String>")]
pub struct ComputeAPSP {
    /// Number of landmark nodes for approximation
    pub num_landmarks: usize,
    /// Optional seed for landmark selection
    pub seed: Option<u64>,
}

/// Query shortest path between two nodes
#[derive(Debug, Clone, Serialize, Deserialize, Message)]
#[rtype(result = "Result<PathResult, String>")]
pub struct QueryPath {
    /// Source node ID
    pub source_id: String,
    /// Target node ID
    pub target_id: String,
}

/// SSSP computation result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SSSPResult {
    /// Distance from source to each node (indexed by node index)
    pub distances: Vec<f32>,
    /// Source node index
    pub source_idx: usize,
    /// Number of nodes reached
    pub nodes_reached: usize,
    /// Maximum distance found
    pub max_distance: f32,
    /// Computation time in milliseconds
    pub computation_time_ms: u64,
}

/// APSP computation result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct APSPResult {
    /// Approximate all-pairs distances [num_nodes x num_nodes]
    /// Stored in row-major order: distance[i][j] = distances[i * num_nodes + j]
    pub distances: Vec<f32>,
    /// Number of nodes
    pub num_nodes: usize,
    /// Number of landmarks used
    pub num_landmarks: usize,
    /// Landmark node indices
    pub landmarks: Vec<usize>,
    /// Average approximation error estimate
    pub avg_error_estimate: f32,
    /// Computation time in milliseconds
    pub computation_time_ms: u64,
}

/// Path query result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PathResult {
    /// Path as sequence of node IDs
    pub path: Vec<String>,
    /// Total path distance
    pub distance: f32,
    /// Whether path exists
    pub exists: bool,
}

/// Shortest path computation statistics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ShortestPathStats {
    pub total_sssp_computations: u64,
    pub total_apsp_computations: u64,
    pub avg_sssp_time_ms: f32,
    pub avg_apsp_time_ms: f32,
    pub last_computation_time_ms: u64,
}

/// Shortest Path Actor
pub struct ShortestPathActor {
    /// GPU state tracking
    gpu_state: GPUState,

    /// Shared GPU context
    shared_context: Option<Arc<SharedGPUContext>>,

    /// Computation statistics
    stats: ShortestPathStats,
}

impl ShortestPathActor {
    pub fn new() -> Self {
        Self {
            gpu_state: GPUState::default(),
            shared_context: None,
            stats: ShortestPathStats {
                total_sssp_computations: 0,
                total_apsp_computations: 0,
                avg_sssp_time_ms: 0.0,
                avg_apsp_time_ms: 0.0,
                last_computation_time_ms: 0,
            },
        }
    }

    /// Update statistics with new computation time
    fn update_stats(&mut self, is_sssp: bool, time_ms: u64) {
        self.stats.last_computation_time_ms = time_ms;

        if is_sssp {
            let total = self.stats.total_sssp_computations as f32;
            self.stats.avg_sssp_time_ms =
                (self.stats.avg_sssp_time_ms * total + time_ms as f32) / (total + 1.0);
            self.stats.total_sssp_computations += 1;
        } else {
            let total = self.stats.total_apsp_computations as f32;
            self.stats.avg_apsp_time_ms =
                (self.stats.avg_apsp_time_ms * total + time_ms as f32) / (total + 1.0);
            self.stats.total_apsp_computations += 1;
        }
    }
}

impl Default for ShortestPathActor {
    fn default() -> Self {
        Self::new()
    }
}

impl Actor for ShortestPathActor {
    type Context = Context<Self>;

    fn started(&mut self, ctx: &mut Self::Context) {
        info!("ShortestPathActor started");
        ctx.notify(InitializeActor);
    }

    fn stopped(&mut self, _ctx: &mut Self::Context) {
        info!("ShortestPathActor stopped");
    }
}

// Message Handlers

impl Handler<InitializeActor> for ShortestPathActor {
    type Result = ();

    fn handle(&mut self, _msg: InitializeActor, _ctx: &mut Self::Context) -> Self::Result {
        info!("ShortestPathActor: Initializing");
        self.gpu_state.is_initialized = true;
    }
}

impl Handler<SetSharedGPUContext> for ShortestPathActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: SetSharedGPUContext, _ctx: &mut Self::Context) -> Self::Result {
        info!("ShortestPathActor: Setting GPU context");
        self.shared_context = Some(msg.context);
        self.gpu_state.is_initialized = true;
        Ok(())
    }
}

impl Handler<ComputeSSP> for ShortestPathActor {
    type Result = Result<SSSPResult, String>;

    fn handle(&mut self, msg: ComputeSSP, _ctx: &mut Self::Context) -> Self::Result {
        info!("ShortestPathActor: Computing SSSP from node {}", msg.source_idx);

        // Acquire lock, compute, then drop lock before calling update_stats
        let (filtered_distances, nodes_reached, max_distance, computation_time) = {
            let mut unified_compute = match &self.shared_context {
                Some(ctx) => ctx
                    .unified_compute
                    .lock()
                    .map_err(|e| format!("Failed to acquire GPU compute lock: {}", e))?,
                None => {
                    return Err("GPU context not initialized".to_string());
                }
            };

            let start_time = Instant::now();

            // Call the existing GPU SSSP implementation
            let distances = unified_compute
                .run_sssp(msg.source_idx)
                .map_err(|e| {
                    error!("GPU SSSP computation failed: {}", e);
                    format!("SSSP computation failed: {}", e)
                })?;

            let computation_time = start_time.elapsed().as_millis() as u64;

            // Calculate statistics
            let mut nodes_reached = 0;
            let mut max_distance = 0.0f32;

            for &dist in &distances {
                if dist < f32::MAX {
                    nodes_reached += 1;
                    max_distance = max_distance.max(dist);
                }
            }

            // Apply max_distance filter if specified
            let filtered_distances = if let Some(max_dist) = msg.max_distance {
                distances.into_iter().map(|d| {
                    if d <= max_dist { d } else { f32::MAX }
                }).collect()
            } else {
                distances
            };

            (filtered_distances, nodes_reached, max_distance, computation_time)
        }; // unified_compute lock dropped here

        // Now we can safely call update_stats with mutable borrow
        self.update_stats(true, computation_time);

        info!(
            "ShortestPathActor: SSSP completed in {}ms, reached {}/{} nodes",
            computation_time, nodes_reached, filtered_distances.len()
        );

        Ok(SSSPResult {
            distances: filtered_distances,
            source_idx: msg.source_idx,
            nodes_reached,
            max_distance,
            computation_time_ms: computation_time,
        })
    }
}

impl Handler<ComputeAPSP> for ShortestPathActor {
    type Result = Result<APSPResult, String>;

    fn handle(&mut self, msg: ComputeAPSP, _ctx: &mut Self::Context) -> Self::Result {
        info!("ShortestPathActor: Computing APSP with {} landmarks", msg.num_landmarks);

        // Acquire lock, compute, then drop lock before calling update_stats
        let (apsp_distances, num_nodes, landmarks, computation_time) = {
            let mut unified_compute = match &self.shared_context {
                Some(ctx) => ctx
                    .unified_compute
                    .lock()
                    .map_err(|e| format!("Failed to acquire GPU compute lock: {}", e))?,
                None => {
                    return Err("GPU context not initialized".to_string());
                }
            };

            let start_time = Instant::now();

            // Get graph size
            let num_nodes = unified_compute.get_num_nodes();

            if msg.num_landmarks >= num_nodes {
                return Err(format!(
                    "Number of landmarks ({}) must be less than number of nodes ({})",
                    msg.num_landmarks, num_nodes
                ));
            }

            // Select landmark nodes (stratified sampling)
            let mut landmarks = Vec::with_capacity(msg.num_landmarks);
            let stride = num_nodes / msg.num_landmarks;
            let seed = msg.seed.unwrap_or(42);

            for i in 0..msg.num_landmarks {
                let landmark = (i * stride + ((seed + i as u64) % stride as u64) as usize) % num_nodes;
                landmarks.push(landmark);
            }

            // Run SSSP from each landmark
            let mut landmark_distances = Vec::with_capacity(msg.num_landmarks * num_nodes);

            for &landmark in &landmarks {
                let distances = unified_compute
                    .run_sssp(landmark)
                    .map_err(|e| {
                        error!("GPU SSSP computation failed for landmark {}: {}", landmark, e);
                        format!("SSSP computation failed: {}", e)
                    })?;
                landmark_distances.extend(distances);
            }

            // Approximate all-pairs distances using triangle inequality
            // d(i,j)  min_k(d(k,i) + d(k,j)) over landmarks k
            let mut apsp_distances = vec![f32::MAX; num_nodes * num_nodes];

            for i in 0..num_nodes {
                apsp_distances[i * num_nodes + i] = 0.0; // Distance to self is 0

                for j in (i + 1)..num_nodes {
                    let mut min_dist = f32::MAX;

                    for (k_idx, &_k) in landmarks.iter().enumerate() {
                        let dist_ki = landmark_distances[k_idx * num_nodes + i];
                        let dist_kj = landmark_distances[k_idx * num_nodes + j];

                        if dist_ki < f32::MAX && dist_kj < f32::MAX {
                            min_dist = min_dist.min(dist_ki + dist_kj);
                        }
                    }

                    // Set symmetric distances
                    apsp_distances[i * num_nodes + j] = min_dist;
                    apsp_distances[j * num_nodes + i] = min_dist;
                }
            }

            let computation_time = start_time.elapsed().as_millis() as u64;

            (apsp_distances, num_nodes, landmarks, computation_time)
        }; // unified_compute lock dropped here

        // Now we can safely call update_stats with mutable borrow
        self.update_stats(false, computation_time);

        // Estimate approximation error (simplified)
        let avg_error_estimate = 0.15; // Typical 15% error for landmark-based APSP

        info!(
            "ShortestPathActor: APSP completed in {}ms with {} landmarks",
            computation_time, msg.num_landmarks
        );

        Ok(APSPResult {
            distances: apsp_distances,
            num_nodes,
            num_landmarks: msg.num_landmarks,
            landmarks,
            avg_error_estimate,
            computation_time_ms: computation_time,
        })
    }
}

/// Get shortest path statistics
#[derive(Debug, Clone, Serialize, Deserialize, Message)]
#[rtype(result = "ShortestPathStats")]
pub struct GetShortestPathStats;

impl Handler<GetShortestPathStats> for ShortestPathActor {
    type Result = MessageResult<GetShortestPathStats>;

    fn handle(&mut self, _msg: GetShortestPathStats, _ctx: &mut Self::Context) -> Self::Result {
        MessageResult(self.stats.clone())
    }
}

--------------------------------------------------------------------------------
FILE: src/actors/gpu/constraint_actor.rs
PURPOSE: Physics constraint enforcement actor
--------------------------------------------------------------------------------
//! Constraint Actor - Handles constraint management and updates

use actix::prelude::*;
use log::{debug, error, info};
use std::sync::Arc;

use super::shared::{GPUState, SharedGPUContext};
use crate::actors::messages::*;
use crate::models::constraints::{Constraint, ConstraintData, ConstraintKind, ConstraintSet};

///
pub struct ConstraintActor {
    
    gpu_state: GPUState,

    
    shared_context: Option<Arc<SharedGPUContext>>,

    
    constraints: Vec<Constraint>,
}

impl ConstraintActor {
    pub fn new() -> Self {
        Self {
            gpu_state: GPUState::default(),
            shared_context: None,
            constraints: Vec::new(),
        }
    }

    
    fn update_constraints(&mut self, new_constraints: Vec<Constraint>) -> Result<(), String> {
        info!(
            "ConstraintActor: Updating constraints - {} current, {} new",
            self.constraints.len(),
            new_constraints.len()
        );

        
        self.constraints = new_constraints;

        
        if self.shared_context.is_some() {
            self.upload_constraints_to_gpu()?;
        } else {
            info!("ConstraintActor: GPU not initialized, constraints stored locally");
        }

        info!(
            "ConstraintActor: Constraint update completed - {} total constraints",
            self.constraints.len()
        );
        Ok(())
    }

    
    fn upload_constraints_to_gpu(&self) -> Result<(), String> {
        info!(
            "ConstraintActor: Uploading {} constraints to GPU",
            self.constraints.len()
        );

        let mut unified_compute = match &self.shared_context {
            Some(ctx) => ctx
                .unified_compute
                .lock()
                .map_err(|e| format!("Failed to acquire GPU compute lock: {}", e))?,
            None => {
                return Err("GPU context not initialized".to_string());
            }
        };

        
        let constraint_data = self.convert_constraints_to_gpu_format()?;

        if constraint_data.is_empty() {
            info!("ConstraintActor: No constraints to upload, clearing GPU constraints");
            unified_compute
                .clear_constraints()
                .map_err(|e| format!("Failed to clear GPU constraints: {}", e))?;
        } else {
            
            unified_compute
                .upload_constraints(&constraint_data)
                .map_err(|e| format!("Failed to upload constraints to GPU: {}", e))?;

            info!(
                "ConstraintActor: Successfully uploaded {} constraint entries to GPU",
                constraint_data.len()
            );
        }

        Ok(())
    }

    
    fn convert_constraints_to_gpu_format(&self) -> Result<Vec<ConstraintData>, String> {
        let mut constraint_data = Vec::new();

        
        for constraint in self.constraints.iter() {
            
            if constraint.active {
                
                for &node_idx in &constraint.node_indices {
                    if node_idx >= self.gpu_state.num_nodes {
                        error!(
                            "ConstraintActor: Node index {} out of range (max: {})",
                            node_idx,
                            self.gpu_state.num_nodes - 1
                        );
                        continue;
                    }
                }

                
                let gpu_constraint = ConstraintData::from_constraint(constraint);
                constraint_data.push(gpu_constraint);
            }
        }

        info!(
            "ConstraintActor: Converted {} active constraints to {} GPU constraint entries",
            self.constraints.iter().filter(|c| c.active).count(),
            constraint_data.len()
        );

        Ok(constraint_data)
    }

    
    fn get_current_constraints(&self) -> ConstraintSet {
        ConstraintSet {
            constraints: self.constraints.clone(),
            groups: std::collections::HashMap::new(), 
        }
    }

    
    fn clear_constraints(&mut self) -> Result<(), String> {
        info!("ConstraintActor: Clearing all constraints");

        self.constraints.clear();

        
        if let Some(ctx) = &self.shared_context {
            let mut unified_compute = ctx
                .unified_compute
                .lock()
                .map_err(|e| format!("Failed to acquire GPU compute lock: {}", e))?;

            unified_compute
                .clear_constraints()
                .map_err(|e| format!("Failed to clear GPU constraints: {}", e))?;

            info!("ConstraintActor: GPU constraints cleared");
        }

        info!("ConstraintActor: All constraints cleared successfully");
        Ok(())
    }

    
    fn get_constraint_statistics(&self) -> ConstraintStatistics {
        let mut stats = ConstraintStatistics {
            total_constraints: self.constraints.len(),
            distance_constraints: 0,
            angle_constraints: 0,
            position_constraints: 0,
            cluster_constraints: 0,
            active_constraints: self.constraints.len(), 
        };

        
        for constraint in &self.constraints {
            if constraint.active {
                match constraint.kind {
                    ConstraintKind::Separation => stats.distance_constraints += 1,
                    ConstraintKind::FixedPosition => stats.position_constraints += 1,
                    ConstraintKind::Clustering => {
                        stats.cluster_constraints += 1;
                        
                        stats.total_constraints += constraint.node_indices.len().saturating_sub(1);
                    }
                    ConstraintKind::AlignmentHorizontal
                    | ConstraintKind::AlignmentVertical
                    | ConstraintKind::AlignmentDepth => stats.angle_constraints += 1, 
                    _ => {} 
                }
            }
        }

        stats
    }
}

impl Actor for ConstraintActor {
    type Context = Context<Self>;

    fn started(&mut self, _ctx: &mut Self::Context) {
        info!("Constraint Actor started");
    }

    fn stopped(&mut self, _ctx: &mut Self::Context) {
        info!("Constraint Actor stopped");
    }
}

// === Message Handlers ===

impl Handler<UpdateConstraints> for ConstraintActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: UpdateConstraints, _ctx: &mut Self::Context) -> Self::Result {
        info!("ConstraintActor: UpdateConstraints received");

        
        let constraints =
            match serde_json::from_value::<Vec<Constraint>>(msg.constraint_data.clone()) {
                Ok(constraints) => constraints,
                Err(e) => {
                    
                    match serde_json::from_value::<ConstraintSet>(msg.constraint_data) {
                        Ok(constraint_set) => constraint_set.constraints,
                        Err(_) => {
                            error!("ConstraintActor: Failed to parse constraint_data: {}", e);
                            return Err(format!("Failed to parse constraints: {}", e));
                        }
                    }
                }
            };

        self.update_constraints(constraints)
    }
}

impl Handler<GetConstraints> for ConstraintActor {
    type Result = Result<ConstraintSet, String>;

    fn handle(&mut self, _msg: GetConstraints, _ctx: &mut Self::Context) -> Self::Result {
        debug!("ConstraintActor: GetConstraints request");
        Ok(self.get_current_constraints())
    }
}

impl Handler<UploadConstraintsToGPU> for ConstraintActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: UploadConstraintsToGPU, _ctx: &mut Self::Context) -> Self::Result {
        info!(
            "ConstraintActor: UploadConstraintsToGPU received - {} constraint entries",
            msg.constraint_data.len()
        );

        let mut unified_compute = match &self.shared_context {
            Some(ctx) => ctx
                .unified_compute
                .lock()
                .map_err(|e| format!("Failed to acquire GPU compute lock: {}", e))?,
            None => {
                return Err("GPU context not initialized".to_string());
            }
        };

        
        unified_compute
            .upload_constraints(&msg.constraint_data)
            .map_err(|e| format!("Failed to upload constraints to GPU: {}", e))?;

        info!(
            "ConstraintActor: Successfully uploaded {} constraint entries to GPU",
            msg.constraint_data.len()
        );
        Ok(())
    }
}

// Custom message handlers for constraint management
impl Handler<ClearConstraints> for ConstraintActor {
    type Result = Result<(), String>;

    fn handle(&mut self, _msg: ClearConstraints, _ctx: &mut Self::Context) -> Self::Result {
        self.clear_constraints()
    }
}

impl Handler<GetConstraintStatistics> for ConstraintActor {
    type Result = Result<ConstraintStatistics, String>;

    fn handle(&mut self, _msg: GetConstraintStatistics, _ctx: &mut Self::Context) -> Self::Result {
        Ok(self.get_constraint_statistics())
    }
}

// Custom messages for constraint management
#[derive(Message)]
#[rtype(result = "Result<(), String>")]
pub struct ClearConstraints;

#[derive(Message)]
#[rtype(result = "Result<ConstraintStatistics, String>")]
pub struct GetConstraintStatistics;

///
impl Handler<SetSharedGPUContext> for ConstraintActor {
    type Result = Result<(), String>;

    fn handle(&mut self, msg: SetSharedGPUContext, _ctx: &mut Self::Context) -> Self::Result {
        info!("ConstraintActor: Received SharedGPUContext from ResourceActor");
        self.shared_context = Some(msg.context);
        
        info!("ConstraintActor: SharedGPUContext stored successfully");
        Ok(())
    }
}

// Constraint statistics structure
#[derive(Debug, Clone)]
pub struct ConstraintStatistics {
    pub total_constraints: usize,
    pub distance_constraints: usize,
    pub angle_constraints: usize,
    pub position_constraints: usize,
    pub cluster_constraints: usize,
    pub active_constraints: usize,
}

--------------------------------------------------------------------------------
FILE: src/actors/gpu/shared.rs
PURPOSE: Shared GPU context and UnifiedGPUCompute
--------------------------------------------------------------------------------
//! Shared data structures and utilities for GPU actors

use super::cuda_stream_wrapper::SafeCudaStream;
use actix::Addr;
use cudarc::driver::CudaDevice;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use tokio::sync::RwLock;

use crate::models::constraints::Constraint;
use crate::models::simulation_params::SimulationParams;

// Public re-exports for GPU compute types
pub use crate::utils::unified_gpu_compute::{SimParams, UnifiedGPUCompute};

// Import the child actors for address storage
// use super::{GPUResourceActor, ForceComputeActor, ClusteringActor,
//            AnomalyDetectionActor, StressMajorizationActor, ConstraintActor};

///

///
#[derive(Debug, Clone)]
pub struct GPUResourceMetrics {
    pub kernel_launch_count: u64,
    pub total_wait_time_ms: u64,
    pub average_utilization_percent: f32,
    pub concurrent_access_attempts: u64,
    pub batched_operations_count: u64,
    pub last_operation_timestamp: Option<Instant>,
}

impl Default for GPUResourceMetrics {
    fn default() -> Self {
        Self {
            kernel_launch_count: 0,
            total_wait_time_ms: 0,
            average_utilization_percent: 0.0,
            concurrent_access_attempts: 0,
            batched_operations_count: 0,
            last_operation_timestamp: None,
        }
    }
}

///
#[derive(Debug, Clone)]
pub struct GPUOperationBatch {
    pub operations: Vec<GPUOperation>,
    pub priority: GPUOperationPriority,
    pub batch_size_limit: usize,
    pub flush_timeout_ms: u64,
    pub created_at: Instant,
}

#[derive(Debug, Clone)]
pub enum GPUOperation {
    ForceComputation,
    PositionUpdate,
    VelocityUpdate,
    Clustering,
    AnomalyDetection,
    StressMajorization,
    OntologyConstraints,
}

#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord)]
pub enum GPUOperationPriority {
    Low = 0,
    Normal = 1,
    High = 2,
    Critical = 3,
}

impl GPUOperationBatch {
    pub fn new(priority: GPUOperationPriority) -> Self {
        Self {
            operations: Vec::new(),
            priority,
            batch_size_limit: 10,
            flush_timeout_ms: 16, 
            created_at: Instant::now(),
        }
    }

    pub fn should_flush(&self) -> bool {
        self.operations.len() >= self.batch_size_limit
            || self.created_at.elapsed().as_millis() >= self.flush_timeout_ms as u128
    }

    pub fn add_operation(&mut self, operation: GPUOperation) {
        self.operations.push(operation);
    }
}

///
// Note: SafeCudaStream provides thread safety guarantees
pub struct SharedGPUContext {
    pub device: Arc<CudaDevice>,
    pub stream: Arc<std::sync::Mutex<SafeCudaStream>>,
    pub unified_compute: Arc<std::sync::Mutex<UnifiedGPUCompute>>,

    
    
    pub gpu_access_lock: Arc<RwLock<()>>,
    pub resource_metrics: Arc<Mutex<GPUResourceMetrics>>,
    pub operation_batch: Arc<Mutex<Vec<GPUOperation>>>,
    pub batch_timeout: Duration,
}

/// Type alias for SharedGPUContext for backwards compatibility
pub type GPUContext = SharedGPUContext;

///
#[derive(Debug, Clone)]
pub struct GPUState {
    pub num_nodes: u32,
    pub num_edges: u32,
    pub node_indices: HashMap<u32, usize>,
    pub simulation_params: SimulationParams,
    pub unified_params: SimParams,
    pub constraints: Vec<Constraint>,
    pub iteration_count: u32,
    pub gpu_failure_count: u32,
    pub is_initialized: bool,

    
    pub graph_structure_hash: u64,
    pub positions_hash: u64,
    pub csr_structure_uploaded: bool,

    
    pub active_operations: Vec<GPUOperation>,
    pub last_sync_timestamp: Option<Instant>,
    pub gpu_utilization_history: Vec<f32>, 
    pub operation_queue_depth: usize,
    pub average_kernel_time_ms: f32,
    pub peak_memory_usage_bytes: usize,
    pub concurrent_access_count: u32,
}

impl Default for GPUState {
    fn default() -> Self {
        Self {
            num_nodes: 0,
            num_edges: 0,
            node_indices: HashMap::new(),
            simulation_params: SimulationParams::default(),
            unified_params: SimParams::default(),
            constraints: Vec::new(),
            iteration_count: 0,
            gpu_failure_count: 0,
            is_initialized: false,
            graph_structure_hash: 0,
            positions_hash: 0,
            csr_structure_uploaded: false,

            
            active_operations: Vec::new(),
            last_sync_timestamp: None,
            gpu_utilization_history: Vec::with_capacity(60), 
            operation_queue_depth: 0,
            average_kernel_time_ms: 0.0,
            peak_memory_usage_bytes: 0,
            concurrent_access_count: 0,
        }
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StressMajorizationSafety {
    
    pub max_displacement_threshold: f32,
    
    pub max_position_magnitude: f32,
    
    pub max_consecutive_failures: u32,
    
    pub convergence_threshold: f32,
    
    pub max_stress_threshold: f32,

    
    pub consecutive_failures: u32,
    pub last_stress_values: Vec<f32>,
    pub last_displacement_values: Vec<f32>,
    pub total_runs: u64,
    pub successful_runs: u64,
    pub total_computation_time_ms: u64,
    pub is_emergency_stopped: bool,
    pub last_emergency_stop_reason: String,
}

impl StressMajorizationSafety {
    pub fn new() -> Self {
        Self {
            max_displacement_threshold: 1000.0,
            max_position_magnitude: 5000.0,
            max_consecutive_failures: 3,
            convergence_threshold: 0.01,
            max_stress_threshold: 1e6,

            consecutive_failures: 0,
            last_stress_values: Vec::with_capacity(10),
            last_displacement_values: Vec::with_capacity(10),
            total_runs: 0,
            successful_runs: 0,
            total_computation_time_ms: 0,
            is_emergency_stopped: false,
            last_emergency_stop_reason: String::new(),
        }
    }

    pub fn is_safe_to_run(&self) -> bool {
        !self.is_emergency_stopped && self.consecutive_failures < self.max_consecutive_failures
    }

    pub fn record_failure(&mut self, reason: String) {
        self.consecutive_failures += 1;
        self.total_runs += 1;
        if self.consecutive_failures >= self.max_consecutive_failures {
            self.is_emergency_stopped = true;
            self.last_emergency_stop_reason = reason;
        }
    }

    pub fn record_success(&mut self, computation_time_ms: u64) {
        self.consecutive_failures = 0;
        self.total_runs += 1;
        self.successful_runs += 1;
        self.total_computation_time_ms += computation_time_ms;
    }

    pub fn record_iteration(&mut self, stress: f32, displacement: f32, _converged: bool) {
        self.last_stress_values.push(stress);
        if self.last_stress_values.len() > 10 {
            self.last_stress_values.remove(0);
        }

        self.last_displacement_values.push(displacement);
        if self.last_displacement_values.len() > 10 {
            self.last_displacement_values.remove(0);
        }

        
        if stress > self.max_stress_threshold {
            self.record_failure(format!("Stress exceeded threshold: {}", stress));
        }

        if displacement > self.max_displacement_threshold {
            self.record_failure(format!("Displacement exceeded threshold: {}", displacement));
        }
    }

    pub fn clamp_position(&self, position: &[f32; 3]) -> [f32; 3] {
        let magnitude = (position[0].powi(2) + position[1].powi(2) + position[2].powi(2)).sqrt();
        if magnitude > self.max_position_magnitude {
            let scale = self.max_position_magnitude / magnitude;
            [
                position[0] * scale,
                position[1] * scale,
                position[2] * scale,
            ]
        } else {
            *position
        }
    }

    pub fn get_stats(
        &self,
    ) -> crate::actors::gpu::stress_majorization_actor::StressMajorizationStats {
        crate::actors::gpu::stress_majorization_actor::StressMajorizationStats {
            stress_value: 0.0, 
            iterations_performed: self.total_runs as u32,
            converged: !self.is_emergency_stopped,
            computation_time_ms: if self.successful_runs > 0 {
                self.total_computation_time_ms / self.successful_runs
            } else {
                0
            },
        }
    }

    pub fn reset_safety_state(&mut self) {
        self.consecutive_failures = 0;
        self.is_emergency_stopped = false;
        self.last_emergency_stop_reason.clear();
    }

    pub fn should_disable(&self) -> bool {
        self.is_emergency_stopped
    }
}

impl SharedGPUContext {
    
    pub async fn acquire_gpu_access_qos(
        &self,
        operation: GPUOperation,
        priority: GPUOperationPriority,
    ) -> Result<(), String> {
        let start_time = Instant::now();

        
        {
            let mut metrics = self
                .resource_metrics
                .lock()
                .map_err(|e| format!("Failed to lock metrics: {}", e))?;
            metrics.concurrent_access_attempts += 1;
        }

        
        if matches!(priority, GPUOperationPriority::Critical) {
            let _guard = self.gpu_access_lock.write().await;
            drop(_guard);
        } else {
            let _guard = self.gpu_access_lock.read().await;
            drop(_guard);
        }

        
        let should_batch = self.should_batch_operation(&operation);
        if should_batch {
            self.add_to_batch(operation.clone())?;
            return Ok(());
        }

        
        let wait_time = start_time.elapsed();
        {
            let mut metrics = self
                .resource_metrics
                .lock()
                .map_err(|e| format!("Failed to lock metrics: {}", e))?;
            metrics.total_wait_time_ms += wait_time.as_millis() as u64;
            metrics.kernel_launch_count += 1;
            metrics.last_operation_timestamp = Some(Instant::now());
        }

        Ok(())
    }

    
    fn should_batch_operation(&self, operation: &GPUOperation) -> bool {
        
        match operation {
            GPUOperation::ForceComputation => false, 
            GPUOperation::PositionUpdate | GPUOperation::VelocityUpdate => true, 
            GPUOperation::Clustering | GPUOperation::AnomalyDetection => false, 
            GPUOperation::StressMajorization => false, 
            GPUOperation::OntologyConstraints => false, 
        }
    }

    
    fn add_to_batch(&self, operation: GPUOperation) -> Result<(), String> {
        let mut batch = self
            .operation_batch
            .lock()
            .map_err(|e| format!("Failed to lock batch: {}", e))?;
        batch.push(operation);

        
        if let Ok(mut metrics) = self.resource_metrics.lock() {
            metrics.batched_operations_count += 1;
        }

        Ok(())
    }

    
    pub fn try_flush_batch(&self) -> Result<Vec<GPUOperation>, String> {
        let mut batch = self
            .operation_batch
            .lock()
            .map_err(|e| format!("Failed to lock batch: {}", e))?;

        if !batch.is_empty() {
            let operations = batch.clone();
            batch.clear();
            Ok(operations)
        } else {
            Ok(Vec::new())
        }
    }

    
    pub fn update_utilization(&self, utilization_percent: f32) -> Result<(), String> {
        let mut metrics = self
            .resource_metrics
            .lock()
            .map_err(|e| format!("Failed to lock metrics: {}", e))?;

        
        if metrics.average_utilization_percent == 0.0 {
            metrics.average_utilization_percent = utilization_percent;
        } else {
            metrics.average_utilization_percent =
                metrics.average_utilization_percent * 0.9 + utilization_percent * 0.1;
        }

        Ok(())
    }

    
    pub async fn acquire_gpu_access(&self) -> Result<tokio::sync::RwLockReadGuard<()>, String> {
        let start_time = Instant::now();
        let guard = self.gpu_access_lock.read().await;

        if let Ok(mut metrics) = self.resource_metrics.lock() {
            metrics.total_wait_time_ms += start_time.elapsed().as_millis() as u64;
        }

        Ok(guard)
    }

    
    
    pub async fn batch_operations(&self) -> Result<Vec<GPUOperation>, String> {
        let start_time = Instant::now();

        
        tokio::time::sleep(self.batch_timeout).await;

        let operations = self.try_flush_batch()?;

        if !operations.is_empty() {
            
            let _guard = self.gpu_access_lock.read().await;

            
            if let Ok(mut metrics) = self.resource_metrics.lock() {
                metrics.kernel_launch_count += 1; 
                metrics.total_wait_time_ms += start_time.elapsed().as_millis() as u64;
                metrics.last_operation_timestamp = Some(Instant::now());
            }
        }

        Ok(operations)
    }

    
    
    pub async fn acquire_exclusive_access(
        &self,
    ) -> Result<tokio::sync::RwLockWriteGuard<()>, String> {
        let start_time = Instant::now();

        
        let guard = self.gpu_access_lock.write().await;

        
        if let Ok(mut metrics) = self.resource_metrics.lock() {
            metrics.total_wait_time_ms += start_time.elapsed().as_millis() as u64;
            metrics.concurrent_access_attempts += 1;
        }

        Ok(guard)
    }
}

impl GPUState {
    
    pub fn start_operation(&mut self, operation: GPUOperation) {
        self.active_operations.push(operation);
        self.concurrent_access_count += 1;
        self.last_sync_timestamp = Some(Instant::now());
    }

    
    pub fn complete_operation(&mut self, operation: &GPUOperation) {
        self.active_operations.retain(|op| {
            !matches!(
                (op, operation),
                (
                    GPUOperation::ForceComputation,
                    GPUOperation::ForceComputation
                ) | (GPUOperation::PositionUpdate, GPUOperation::PositionUpdate)
                    | (GPUOperation::VelocityUpdate, GPUOperation::VelocityUpdate)
                    | (GPUOperation::Clustering, GPUOperation::Clustering)
                    | (
                        GPUOperation::AnomalyDetection,
                        GPUOperation::AnomalyDetection
                    )
                    | (
                        GPUOperation::StressMajorization,
                        GPUOperation::StressMajorization
                    )
                    | (
                        GPUOperation::OntologyConstraints,
                        GPUOperation::OntologyConstraints
                    )
            )
        });
        if self.concurrent_access_count > 0 {
            self.concurrent_access_count -= 1;
        }
    }

    
    pub fn record_utilization(&mut self, utilization_percent: f32) {
        self.gpu_utilization_history.push(utilization_percent);
        
        if self.gpu_utilization_history.len() > 60 {
            self.gpu_utilization_history.remove(0);
        }
    }

    
    pub fn get_average_utilization(&self) -> f32 {
        if self.gpu_utilization_history.is_empty() {
            0.0
        } else {
            self.gpu_utilization_history.iter().sum::<f32>()
                / self.gpu_utilization_history.len() as f32
        }
    }

    
    pub fn is_gpu_overloaded(&self) -> bool {
        
        
        self.concurrent_access_count > 5 && self.get_average_utilization() > 80.0
    }
}

/// Child actor addresses for all GPU actors managed by PhysicsOrchestratorActor
#[derive(Clone)]
pub struct ChildActorAddresses {
    pub resource_actor: Addr<super::GPUResourceActor>,
    pub force_compute_actor: Addr<super::ForceComputeActor>,
    pub clustering_actor: Addr<super::ClusteringActor>,
    pub anomaly_detection_actor: Addr<super::AnomalyDetectionActor>,
    pub stress_majorization_actor: Addr<super::StressMajorizationActor>,
    pub constraint_actor: Addr<super::ConstraintActor>,
    pub ontology_constraint_actor: Addr<super::OntologyConstraintActor>,

    // P2 GPU Analytics Actors
    pub pagerank_actor: Addr<super::PageRankActor>,
    pub shortest_path_actor: Addr<super::ShortestPathActor>,
    pub connected_components_actor: Addr<super::ConnectedComponentsActor>,
}

================================================================================
                    SECTION 8: CONSTRAINTS & PHYSICS
================================================================================

--------------------------------------------------------------------------------
FILE: src/constraints/mod.rs
PURPOSE: Constraint system module exports
--------------------------------------------------------------------------------
// Constraint Translation System - Module Root
// Week 3 Deliverable: OWL Axiom  Physics Constraint Translation

pub mod physics_constraint;
pub mod axiom_mapper;
pub mod priority_resolver;
pub mod constraint_blender;
pub mod gpu_converter;
pub mod constraint_lod;

// Semantic physics extensions
pub mod semantic_physics_types;
pub mod semantic_axiom_translator;
pub mod semantic_gpu_buffer;

// Re-export main types
pub use physics_constraint::{
    PhysicsConstraint,
    PhysicsConstraintType,
    NodeId,
    PRIORITY_USER_DEFINED,
    PRIORITY_INFERRED,
    PRIORITY_ASSERTED,
    PRIORITY_DEFAULT,
};

pub use axiom_mapper::{
    AxiomMapper,
    AxiomType,
    OWLAxiom,
    TranslationConfig,
};

pub use priority_resolver::{
    PriorityResolver,
    NodePair,
    ConstraintGroup,
};

pub use constraint_blender::{
    ConstraintBlender,
    BlendingStrategy,
    BlenderConfig,
};

pub use gpu_converter::{
    ConstraintData,
    GPUConstraintBuffer,
    ConstraintStats,
    to_gpu_constraint_data,
    to_gpu_constraint_batch,
    gpu_constraint_kind,
};

pub use constraint_lod::{
    ConstraintLOD,
    LODLevel,
    LODConfig,
    LODStats,
};

pub use semantic_physics_types::{
    SemanticPhysicsConstraint,
    Axis,
    SemanticConstraintBuilder,
};

pub use semantic_axiom_translator::{
    SemanticAxiomTranslator,
    SemanticPhysicsConfig,
    PriorityBlendingStrategy,
};

pub use semantic_gpu_buffer::{
    SemanticGPUConstraintBuffer,
    SemanticGPUConstraint,
    SemanticConstraintStats,
    gpu_semantic_types,
};

///
///
///
///
///
///
///
///
///
///
pub struct ConstraintPipeline {
    mapper: AxiomMapper,
    resolver: PriorityResolver,
    blender: ConstraintBlender,
    lod: ConstraintLOD,
}

impl ConstraintPipeline {
    
    pub fn new() -> Self {
        Self {
            mapper: AxiomMapper::new(),
            resolver: PriorityResolver::new(),
            blender: ConstraintBlender::new(),
            lod: ConstraintLOD::new(),
        }
    }

    
    pub fn with_configs(
        translation_config: TranslationConfig,
        blender_config: BlenderConfig,
        lod_config: LODConfig,
    ) -> Self {
        Self {
            mapper: AxiomMapper::with_config(translation_config),
            resolver: PriorityResolver::new(),
            blender: ConstraintBlender::with_config(blender_config),
            lod: ConstraintLOD::with_config(lod_config),
        }
    }

    
    
    
    
    
    
    
    
    pub fn process(
        &mut self,
        axioms: &[OWLAxiom],
        zoom_level: f32,
    ) -> GPUConstraintBuffer {
        
        let constraints = self.mapper.translate_axioms(axioms);

        
        self.resolver.clear();
        self.resolver.add_constraints(constraints);
        let resolved = self.resolver.resolve();

        
        let blended: Vec<PhysicsConstraint> = self.resolver
            .get_groups()
            .iter()
            .filter_map(|group| {
                self.blender.blend_constraints(&group.constraints)
            })
            .collect();

        
        self.lod.set_constraints(blended);
        self.lod.update_zoom(zoom_level);
        let active = self.lod.get_active_constraints();

        
        let mut buffer = GPUConstraintBuffer::new(active.len());
        buffer.add_constraints(active).unwrap();

        buffer
    }

    
    pub fn update_frame_time(&mut self, frame_time_ms: f32) {
        self.lod.update_frame_time(frame_time_ms);
    }

    
    pub fn get_lod_stats(&self) -> LODStats {
        self.lod.get_stats()
    }

    
    pub fn get_constraint_stats(&self, buffer: &GPUConstraintBuffer) -> ConstraintStats {
        ConstraintStats::from_buffer(buffer)
    }

    
    pub fn get_lod_level(&self) -> LODLevel {
        self.lod.get_current_level()
    }
}

impl Default for ConstraintPipeline {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_complete_pipeline() {
        let mut pipeline = ConstraintPipeline::new();

        let axioms = vec![
            OWLAxiom::asserted(AxiomType::SubClassOf {
                subclass: 1,
                superclass: 2,
            }),
            OWLAxiom::asserted(AxiomType::DisjointClasses {
                classes: vec![3, 4],
            }),
            OWLAxiom::inferred(AxiomType::SubClassOf {
                subclass: 5,
                superclass: 2,
            }),
        ];

        
        let buffer = pipeline.process(&axioms, 5.0);

        assert!(buffer.len() > 0);
        assert_eq!(pipeline.get_lod_level(), LODLevel::Close);
    }

    #[test]
    fn test_lod_reduction() {
        let mut pipeline = ConstraintPipeline::new();

        let axioms = vec![
            OWLAxiom::asserted(AxiomType::SubClassOf {
                subclass: 1,
                superclass: 2,
            }),
            OWLAxiom::asserted(AxiomType::DisjointClasses {
                classes: vec![3, 4],
            }),
        ];

        
        let buffer_far = pipeline.process(&axioms, 2000.0);
        assert_eq!(pipeline.get_lod_level(), LODLevel::Far);

        
        let buffer_close = pipeline.process(&axioms, 5.0);
        assert_eq!(pipeline.get_lod_level(), LODLevel::Close);

        
        assert!(buffer_far.len() <= buffer_close.len());
    }

    #[test]
    fn test_adaptive_lod() {
        let mut pipeline = ConstraintPipeline::new();

        let axioms = vec![
            OWLAxiom::asserted(AxiomType::SubClassOf {
                subclass: 1,
                superclass: 2,
            }),
        ];

        pipeline.process(&axioms, 5.0);

        
        pipeline.update_frame_time(30.0);

        let stats = pipeline.get_lod_stats();
        assert!(stats.frame_time_ms > stats.target_frame_time_ms);
    }
}

--------------------------------------------------------------------------------
FILE: src/constraints/physics_constraint.rs
PURPOSE: PhysicsConstraint type and ConstraintKind enum
--------------------------------------------------------------------------------
// Physics Constraint System - Core Types
// Week 3 Deliverable: OWL Axiom  Physics Constraint Translation

use serde::{Deserialize, Serialize};
use std::fmt;

///
pub type NodeId = i64;

///
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum PhysicsConstraintType {
    
    
    Separation {
        min_distance: f32,
        strength: f32,
    },

    
    
    Clustering {
        ideal_distance: f32,
        stiffness: f32,
    },

    
    
    Colocation {
        target_distance: f32,
        strength: f32,
    },

    
    
    Boundary {
        bounds: [f32; 6], 
        strength: f32,
    },

    
    
    HierarchicalLayer {
        z_level: f32,
        strength: f32,
    },

    
    
    Containment {
        parent_node: NodeId,
        radius: f32,
        strength: f32,
    },
}

///
///
pub const PRIORITY_USER_DEFINED: u8 = 1; 
pub const PRIORITY_INFERRED: u8 = 3;     
pub const PRIORITY_ASSERTED: u8 = 5;     
pub const PRIORITY_DEFAULT: u8 = 8;      

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PhysicsConstraint {
    
    pub constraint_type: PhysicsConstraintType,

    
    pub nodes: Vec<NodeId>,

    
    
    
    
    
    pub priority: u8,

    
    pub user_defined: bool,

    
    pub activation_frame: Option<i32>,

    
    pub axiom_id: Option<i64>,
}

impl PhysicsConstraint {
    
    pub fn separation(
        nodes: Vec<NodeId>,
        min_distance: f32,
        strength: f32,
        priority: u8,
    ) -> Self {
        Self {
            constraint_type: PhysicsConstraintType::Separation {
                min_distance,
                strength,
            },
            nodes,
            priority,
            user_defined: false,
            activation_frame: None,
            axiom_id: None,
        }
    }

    
    pub fn clustering(
        nodes: Vec<NodeId>,
        ideal_distance: f32,
        stiffness: f32,
        priority: u8,
    ) -> Self {
        Self {
            constraint_type: PhysicsConstraintType::Clustering {
                ideal_distance,
                stiffness,
            },
            nodes,
            priority,
            user_defined: false,
            activation_frame: None,
            axiom_id: None,
        }
    }

    
    pub fn colocation(
        nodes: Vec<NodeId>,
        target_distance: f32,
        strength: f32,
        priority: u8,
    ) -> Self {
        Self {
            constraint_type: PhysicsConstraintType::Colocation {
                target_distance,
                strength,
            },
            nodes,
            priority,
            user_defined: false,
            activation_frame: None,
            axiom_id: None,
        }
    }

    
    pub fn boundary(
        nodes: Vec<NodeId>,
        bounds: [f32; 6],
        strength: f32,
        priority: u8,
    ) -> Self {
        Self {
            constraint_type: PhysicsConstraintType::Boundary { bounds, strength },
            nodes,
            priority,
            user_defined: false,
            activation_frame: None,
            axiom_id: None,
        }
    }

    
    pub fn hierarchical_layer(
        nodes: Vec<NodeId>,
        z_level: f32,
        strength: f32,
        priority: u8,
    ) -> Self {
        Self {
            constraint_type: PhysicsConstraintType::HierarchicalLayer { z_level, strength },
            nodes,
            priority,
            user_defined: false,
            activation_frame: None,
            axiom_id: None,
        }
    }

    
    pub fn containment(
        nodes: Vec<NodeId>,
        parent_node: NodeId,
        radius: f32,
        strength: f32,
        priority: u8,
    ) -> Self {
        Self {
            constraint_type: PhysicsConstraintType::Containment {
                parent_node,
                radius,
                strength,
            },
            nodes,
            priority,
            user_defined: false,
            activation_frame: None,
            axiom_id: None,
        }
    }

    
    pub fn mark_user_defined(mut self) -> Self {
        self.user_defined = true;
        self.priority = PRIORITY_USER_DEFINED;
        self
    }

    
    pub fn with_axiom_id(mut self, axiom_id: i64) -> Self {
        self.axiom_id = Some(axiom_id);
        self
    }

    
    pub fn with_activation_frame(mut self, frame: i32) -> Self {
        self.activation_frame = Some(frame);
        self
    }

    
    
    
    
    pub fn priority_weight(&self) -> f32 {
        10.0_f32.powf(-(self.priority as f32 - 1.0) / 9.0)
    }

    
    pub fn node_count(&self) -> usize {
        self.nodes.len()
    }

    
    pub fn affects_node(&self, node_id: NodeId) -> bool {
        self.nodes.contains(&node_id)
    }

    
    pub fn strength(&self) -> f32 {
        match &self.constraint_type {
            PhysicsConstraintType::Separation { strength, .. } => *strength,
            PhysicsConstraintType::Clustering { stiffness, .. } => *stiffness,
            PhysicsConstraintType::Colocation { strength, .. } => *strength,
            PhysicsConstraintType::Boundary { strength, .. } => *strength,
            PhysicsConstraintType::HierarchicalLayer { strength, .. } => *strength,
            PhysicsConstraintType::Containment { strength, .. } => *strength,
        }
    }
}

impl fmt::Display for PhysicsConstraint {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let type_str = match &self.constraint_type {
            PhysicsConstraintType::Separation { min_distance, .. } => {
                format!("Separation(min_dist={})", min_distance)
            }
            PhysicsConstraintType::Clustering { ideal_distance, .. } => {
                format!("Clustering(ideal_dist={})", ideal_distance)
            }
            PhysicsConstraintType::Colocation { target_distance, .. } => {
                format!("Colocation(target_dist={})", target_distance)
            }
            PhysicsConstraintType::Boundary { bounds, .. } => {
                format!("Boundary({:?})", bounds)
            }
            PhysicsConstraintType::HierarchicalLayer { z_level, .. } => {
                format!("HierarchicalLayer(z={})", z_level)
            }
            PhysicsConstraintType::Containment { parent_node, radius, .. } => {
                format!("Containment(parent={}, r={})", parent_node, radius)
            }
        };

        write!(
            f,
            "{} [nodes={}, priority={}, user={}]",
            type_str,
            self.nodes.len(),
            self.priority,
            self.user_defined
        )
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_separation_constraint_creation() {
        let constraint = PhysicsConstraint::separation(
            vec![1, 2],
            35.0,
            0.8,
            PRIORITY_ASSERTED,
        );

        assert_eq!(constraint.nodes.len(), 2);
        assert_eq!(constraint.priority, PRIORITY_ASSERTED);
        assert!(!constraint.user_defined);

        match constraint.constraint_type {
            PhysicsConstraintType::Separation { min_distance, strength } => {
                assert_eq!(min_distance, 35.0);
                assert_eq!(strength, 0.8);
            }
            _ => panic!("Wrong constraint type"),
        }
    }

    #[test]
    fn test_priority_weight_calculation() {
        let c1 = PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 1);
        let c2 = PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 5);
        let c3 = PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 10);

        assert!((c1.priority_weight() - 1.0).abs() < 0.001);
        assert!(c1.priority_weight() > c2.priority_weight());
        assert!(c2.priority_weight() > c3.priority_weight());
        assert!((c3.priority_weight() - 0.1).abs() < 0.001);
    }

    #[test]
    fn test_user_defined_override() {
        let constraint = PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 5)
            .mark_user_defined();

        assert!(constraint.user_defined);
        assert_eq!(constraint.priority, PRIORITY_USER_DEFINED);
    }

    #[test]
    fn test_clustering_constraint() {
        let constraint = PhysicsConstraint::clustering(
            vec![10, 20, 30],
            20.0,
            0.6,
            PRIORITY_INFERRED,
        );

        assert_eq!(constraint.nodes.len(), 3);
        assert_eq!(constraint.priority, PRIORITY_INFERRED);
        assert_eq!(constraint.strength(), 0.6);
    }

    #[test]
    fn test_constraint_affects_node() {
        let constraint = PhysicsConstraint::separation(vec![1, 2, 3], 10.0, 0.5, 5);

        assert!(constraint.affects_node(1));
        assert!(constraint.affects_node(2));
        assert!(constraint.affects_node(3));
        assert!(!constraint.affects_node(4));
    }

    #[test]
    fn test_with_axiom_id() {
        let constraint = PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 5)
            .with_axiom_id(123);

        assert_eq!(constraint.axiom_id, Some(123));
    }

    #[test]
    fn test_with_activation_frame() {
        let constraint = PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 5)
            .with_activation_frame(60);

        assert_eq!(constraint.activation_frame, Some(60));
    }

    #[test]
    fn test_hierarchical_layer_constraint() {
        let constraint = PhysicsConstraint::hierarchical_layer(
            vec![1, 2, 3],
            100.0,
            0.7,
            PRIORITY_ASSERTED,
        );

        match constraint.constraint_type {
            PhysicsConstraintType::HierarchicalLayer { z_level, strength } => {
                assert_eq!(z_level, 100.0);
                assert_eq!(strength, 0.7);
            }
            _ => panic!("Wrong constraint type"),
        }
    }

    #[test]
    fn test_containment_constraint() {
        let constraint = PhysicsConstraint::containment(
            vec![1, 2, 3],
            100,
            50.0,
            0.8,
            PRIORITY_ASSERTED,
        );

        match constraint.constraint_type {
            PhysicsConstraintType::Containment { parent_node, radius, strength } => {
                assert_eq!(parent_node, 100);
                assert_eq!(radius, 50.0);
                assert_eq!(strength, 0.8);
            }
            _ => panic!("Wrong constraint type"),
        }
    }
}

--------------------------------------------------------------------------------
FILE: src/constraints/axiom_mapper.rs
PURPOSE: OWL axiom to physics constraint translation
--------------------------------------------------------------------------------
// Axiom Mapper - OWL Axiom  Physics Constraint Translation
// Week 3 Deliverable: Translation Rules for All Axiom Types

use super::physics_constraint::*;
use std::collections::HashMap;

///
#[derive(Debug, Clone, PartialEq)]
pub enum AxiomType {
    
    SubClassOf {
        subclass: NodeId,
        superclass: NodeId,
    },

    
    DisjointClasses {
        classes: Vec<NodeId>,
    },

    
    EquivalentClasses {
        class1: NodeId,
        class2: NodeId,
    },

    
    SameAs {
        individual1: NodeId,
        individual2: NodeId,
    },

    
    DifferentFrom {
        individual1: NodeId,
        individual2: NodeId,
    },

    
    PropertyDomainRange {
        property: NodeId,
        domain: NodeId,
        range: NodeId,
    },

    
    FunctionalProperty {
        property: NodeId,
        nodes: Vec<NodeId>,
    },

    
    DisjointUnion {
        union_class: NodeId,
        disjoint_classes: Vec<NodeId>,
    },

    
    PartOf {
        part: NodeId,
        whole: NodeId,
    },
}

///
#[derive(Debug, Clone)]
pub struct OWLAxiom {
    pub id: Option<i64>,
    pub axiom_type: AxiomType,
    pub inferred: bool, 
    pub user_defined: bool,
}

impl OWLAxiom {
    
    pub fn asserted(axiom_type: AxiomType) -> Self {
        Self {
            id: None,
            axiom_type,
            inferred: false,
            user_defined: false,
        }
    }

    
    pub fn inferred(axiom_type: AxiomType) -> Self {
        Self {
            id: None,
            axiom_type,
            inferred: true,
            user_defined: false,
        }
    }

    
    pub fn user_defined(axiom_type: AxiomType) -> Self {
        Self {
            id: None,
            axiom_type,
            inferred: false,
            user_defined: true,
        }
    }

    
    pub fn with_id(mut self, id: i64) -> Self {
        self.id = Some(id);
        self
    }
}

///
#[derive(Debug, Clone)]
pub struct TranslationConfig {
    
    pub disjoint_separation_distance: f32,
    pub disjoint_separation_strength: f32,

    
    pub subclass_clustering_distance: f32,
    pub subclass_clustering_stiffness: f32,

    
    pub equivalent_colocation_distance: f32,
    pub equivalent_colocation_strength: f32,

    
    pub hierarchical_layer_spacing: f32,
    pub hierarchical_layer_strength: f32,

    
    pub containment_radius_multiplier: f32,
    pub containment_strength: f32,

    
    pub boundary_size: f32,
    pub boundary_strength: f32,
}

impl Default for TranslationConfig {
    fn default() -> Self {
        Self {
            
            disjoint_separation_distance: 35.0,
            disjoint_separation_strength: 0.8,

            
            subclass_clustering_distance: 20.0,
            subclass_clustering_stiffness: 0.6,

            
            equivalent_colocation_distance: 2.0,
            equivalent_colocation_strength: 0.9,

            
            hierarchical_layer_spacing: 50.0,
            hierarchical_layer_strength: 0.7,

            
            containment_radius_multiplier: 1.5,
            containment_strength: 0.8,

            
            boundary_size: 20.0,
            boundary_strength: 0.7,
        }
    }
}

///
pub struct AxiomMapper {
    config: TranslationConfig,
    
    hierarchy_cache: HashMap<NodeId, Vec<NodeId>>,
}

impl AxiomMapper {
    
    pub fn new() -> Self {
        Self {
            config: TranslationConfig::default(),
            hierarchy_cache: HashMap::new(),
        }
    }

    
    pub fn with_config(config: TranslationConfig) -> Self {
        Self {
            config,
            hierarchy_cache: HashMap::new(),
        }
    }

    
    pub fn update_hierarchy_cache(&mut self, subclass: NodeId, superclass: NodeId) {
        self.hierarchy_cache
            .entry(superclass)
            .or_insert_with(Vec::new)
            .push(subclass);
    }

    
    pub fn get_subclasses(&self, superclass: NodeId) -> Vec<NodeId> {
        self.hierarchy_cache
            .get(&superclass)
            .cloned()
            .unwrap_or_default()
    }

    
    pub fn translate_axiom(&mut self, axiom: &OWLAxiom) -> Vec<PhysicsConstraint> {
        let priority = if axiom.user_defined {
            PRIORITY_USER_DEFINED
        } else if axiom.inferred {
            PRIORITY_INFERRED
        } else {
            PRIORITY_ASSERTED
        };

        match &axiom.axiom_type {
            AxiomType::DisjointClasses { classes } => {
                self.translate_disjoint_classes(classes, priority, axiom.id)
            }

            AxiomType::SubClassOf { subclass, superclass } => {
                self.translate_subclass_of(*subclass, *superclass, priority, axiom.id)
            }

            AxiomType::EquivalentClasses { class1, class2 } => {
                self.translate_equivalent_classes(*class1, *class2, priority, axiom.id)
            }

            AxiomType::SameAs { individual1, individual2 } => {
                self.translate_same_as(*individual1, *individual2, priority, axiom.id)
            }

            AxiomType::DifferentFrom { individual1, individual2 } => {
                self.translate_different_from(*individual1, *individual2, priority, axiom.id)
            }

            AxiomType::PropertyDomainRange { property, domain, range } => {
                self.translate_property_domain_range(*property, *domain, *range, priority, axiom.id)
            }

            AxiomType::FunctionalProperty { property, nodes } => {
                self.translate_functional_property(*property, nodes, priority, axiom.id)
            }

            AxiomType::DisjointUnion { union_class, disjoint_classes } => {
                self.translate_disjoint_union(*union_class, disjoint_classes, priority, axiom.id)
            }

            AxiomType::PartOf { part, whole } => {
                self.translate_part_of(*part, *whole, priority, axiom.id)
            }
        }
    }

    
    fn translate_disjoint_classes(
        &self,
        classes: &[NodeId],
        priority: u8,
        axiom_id: Option<i64>,
    ) -> Vec<PhysicsConstraint> {
        let mut constraints = Vec::new();

        
        for i in 0..classes.len() {
            for j in (i + 1)..classes.len() {
                let mut constraint = PhysicsConstraint::separation(
                    vec![classes[i], classes[j]],
                    self.config.disjoint_separation_distance,
                    self.config.disjoint_separation_strength,
                    priority,
                );

                if let Some(id) = axiom_id {
                    constraint = constraint.with_axiom_id(id);
                }

                constraints.push(constraint);
            }
        }

        constraints
    }

    
    fn translate_subclass_of(
        &mut self,
        subclass: NodeId,
        superclass: NodeId,
        priority: u8,
        axiom_id: Option<i64>,
    ) -> Vec<PhysicsConstraint> {
        
        self.update_hierarchy_cache(subclass, superclass);

        
        let mut constraint = PhysicsConstraint::clustering(
            vec![subclass, superclass],
            self.config.subclass_clustering_distance,
            self.config.subclass_clustering_stiffness,
            priority,
        );

        if let Some(id) = axiom_id {
            constraint = constraint.with_axiom_id(id);
        }

        vec![constraint]
    }

    
    fn translate_equivalent_classes(
        &self,
        class1: NodeId,
        class2: NodeId,
        priority: u8,
        axiom_id: Option<i64>,
    ) -> Vec<PhysicsConstraint> {
        let mut constraint = PhysicsConstraint::colocation(
            vec![class1, class2],
            self.config.equivalent_colocation_distance,
            self.config.equivalent_colocation_strength,
            priority,
        );

        if let Some(id) = axiom_id {
            constraint = constraint.with_axiom_id(id);
        }

        vec![constraint]
    }

    
    fn translate_same_as(
        &self,
        individual1: NodeId,
        individual2: NodeId,
        priority: u8,
        axiom_id: Option<i64>,
    ) -> Vec<PhysicsConstraint> {
        let mut constraint = PhysicsConstraint::colocation(
            vec![individual1, individual2],
            self.config.equivalent_colocation_distance,
            self.config.equivalent_colocation_strength,
            priority,
        );

        if let Some(id) = axiom_id {
            constraint = constraint.with_axiom_id(id);
        }

        vec![constraint]
    }

    
    fn translate_different_from(
        &self,
        individual1: NodeId,
        individual2: NodeId,
        priority: u8,
        axiom_id: Option<i64>,
    ) -> Vec<PhysicsConstraint> {
        let mut constraint = PhysicsConstraint::separation(
            vec![individual1, individual2],
            self.config.disjoint_separation_distance,
            self.config.disjoint_separation_strength,
            priority,
        );

        if let Some(id) = axiom_id {
            constraint = constraint.with_axiom_id(id);
        }

        vec![constraint]
    }

    
    fn translate_property_domain_range(
        &self,
        _property: NodeId,
        domain: NodeId,
        range: NodeId,
        priority: u8,
        axiom_id: Option<i64>,
    ) -> Vec<PhysicsConstraint> {
        let bounds = [
            -self.config.boundary_size,
            self.config.boundary_size,
            -self.config.boundary_size,
            self.config.boundary_size,
            -self.config.boundary_size,
            self.config.boundary_size,
        ];

        let mut constraints = vec![
            PhysicsConstraint::boundary(
                vec![domain],
                bounds,
                self.config.boundary_strength,
                priority,
            ),
            PhysicsConstraint::boundary(
                vec![range],
                bounds,
                self.config.boundary_strength,
                priority,
            ),
        ];

        if let Some(id) = axiom_id {
            constraints[0] = constraints[0].clone().with_axiom_id(id);
            constraints[1] = constraints[1].clone().with_axiom_id(id);
        }

        constraints
    }

    
    fn translate_functional_property(
        &self,
        _property: NodeId,
        nodes: &[NodeId],
        priority: u8,
        axiom_id: Option<i64>,
    ) -> Vec<PhysicsConstraint> {
        let bounds = [
            -self.config.boundary_size,
            self.config.boundary_size,
            -self.config.boundary_size,
            self.config.boundary_size,
            -self.config.boundary_size,
            self.config.boundary_size,
        ];

        let mut constraint = PhysicsConstraint::boundary(
            nodes.to_vec(),
            bounds,
            self.config.boundary_strength,
            priority,
        );

        if let Some(id) = axiom_id {
            constraint = constraint.with_axiom_id(id);
        }

        vec![constraint]
    }

    
    fn translate_disjoint_union(
        &self,
        union_class: NodeId,
        disjoint_classes: &[NodeId],
        priority: u8,
        axiom_id: Option<i64>,
    ) -> Vec<PhysicsConstraint> {
        let mut constraints = Vec::new();

        
        constraints.extend(self.translate_disjoint_classes(disjoint_classes, priority, axiom_id));

        
        for &disjoint_class in disjoint_classes {
            let mut constraint = PhysicsConstraint::clustering(
                vec![disjoint_class, union_class],
                self.config.subclass_clustering_distance,
                self.config.subclass_clustering_stiffness,
                priority,
            );

            if let Some(id) = axiom_id {
                constraint = constraint.with_axiom_id(id);
            }

            constraints.push(constraint);
        }

        constraints
    }

    
    fn translate_part_of(
        &self,
        part: NodeId,
        whole: NodeId,
        priority: u8,
        axiom_id: Option<i64>,
    ) -> Vec<PhysicsConstraint> {
        let mut constraint = PhysicsConstraint::containment(
            vec![part],
            whole,
            self.config.subclass_clustering_distance * self.config.containment_radius_multiplier,
            self.config.containment_strength,
            priority,
        );

        if let Some(id) = axiom_id {
            constraint = constraint.with_axiom_id(id);
        }

        vec![constraint]
    }

    
    pub fn translate_axioms(&mut self, axioms: &[OWLAxiom]) -> Vec<PhysicsConstraint> {
        axioms
            .iter()
            .flat_map(|axiom| self.translate_axiom(axiom))
            .collect()
    }
}

impl Default for AxiomMapper {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_disjoint_classes_translation() {
        let mapper = AxiomMapper::new();
        let axiom = OWLAxiom::asserted(AxiomType::DisjointClasses {
            classes: vec![1, 2, 3],
        });

        let constraints = mapper.translate_disjoint_classes(&vec![1, 2, 3], PRIORITY_ASSERTED, None);

        
        assert_eq!(constraints.len(), 3);

        for constraint in &constraints {
            assert_eq!(constraint.nodes.len(), 2);
            assert_eq!(constraint.priority, PRIORITY_ASSERTED);
            match &constraint.constraint_type {
                PhysicsConstraintType::Separation { min_distance, strength } => {
                    assert_eq!(*min_distance, 35.0);
                    assert_eq!(*strength, 0.8);
                }
                _ => panic!("Wrong constraint type"),
            }
        }
    }

    #[test]
    fn test_subclass_of_translation() {
        let mut mapper = AxiomMapper::new();
        let axiom = OWLAxiom::asserted(AxiomType::SubClassOf {
            subclass: 10,
            superclass: 20,
        });

        let constraints = mapper.translate_axiom(&axiom);

        assert_eq!(constraints.len(), 1);
        assert_eq!(constraints[0].nodes, vec![10, 20]);

        match &constraints[0].constraint_type {
            PhysicsConstraintType::Clustering { ideal_distance, stiffness } => {
                assert_eq!(*ideal_distance, 20.0);
                assert_eq!(*stiffness, 0.6);
            }
            _ => panic!("Wrong constraint type"),
        }

        
        assert_eq!(mapper.get_subclasses(20), vec![10]);
    }

    #[test]
    fn test_equivalent_classes_translation() {
        let mapper = AxiomMapper::new();
        let axiom = OWLAxiom::asserted(AxiomType::EquivalentClasses {
            class1: 5,
            class2: 6,
        });

        let constraints = mapper.translate_equivalent_classes(5, 6, PRIORITY_ASSERTED, None);

        assert_eq!(constraints.len(), 1);
        assert_eq!(constraints[0].nodes, vec![5, 6]);

        match &constraints[0].constraint_type {
            PhysicsConstraintType::Colocation { target_distance, strength } => {
                assert_eq!(*target_distance, 2.0);
                assert_eq!(*strength, 0.9);
            }
            _ => panic!("Wrong constraint type"),
        }
    }

    #[test]
    fn test_inferred_axiom_priority() {
        let mut mapper = AxiomMapper::new();
        let axiom = OWLAxiom::inferred(AxiomType::SubClassOf {
            subclass: 1,
            superclass: 2,
        });

        let constraints = mapper.translate_axiom(&axiom);

        assert_eq!(constraints[0].priority, PRIORITY_INFERRED);
    }

    #[test]
    fn test_user_defined_axiom_priority() {
        let mut mapper = AxiomMapper::new();
        let axiom = OWLAxiom::user_defined(AxiomType::SubClassOf {
            subclass: 1,
            superclass: 2,
        });

        let constraints = mapper.translate_axiom(&axiom);

        assert_eq!(constraints[0].priority, PRIORITY_USER_DEFINED);
    }

    #[test]
    fn test_disjoint_union_translation() {
        let mapper = AxiomMapper::new();
        let axiom = OWLAxiom::asserted(AxiomType::DisjointUnion {
            union_class: 1,
            disjoint_classes: vec![2, 3, 4],
        });

        let constraints = mapper.translate_disjoint_union(1, &vec![2, 3, 4], PRIORITY_ASSERTED, None);

        
        assert_eq!(constraints.len(), 6);
    }

    #[test]
    fn test_part_of_translation() {
        let mapper = AxiomMapper::new();
        let axiom = OWLAxiom::asserted(AxiomType::PartOf {
            part: 10,
            whole: 20,
        });

        let constraints = mapper.translate_part_of(10, 20, PRIORITY_ASSERTED, None);

        assert_eq!(constraints.len(), 1);
        match &constraints[0].constraint_type {
            PhysicsConstraintType::Containment { parent_node, radius, .. } => {
                assert_eq!(*parent_node, 20);
                assert!(*radius > 0.0);
            }
            _ => panic!("Wrong constraint type"),
        }
    }

    #[test]
    fn test_batch_translation() {
        let mut mapper = AxiomMapper::new();
        let axioms = vec![
            OWLAxiom::asserted(AxiomType::SubClassOf {
                subclass: 1,
                superclass: 2,
            }),
            OWLAxiom::asserted(AxiomType::DisjointClasses {
                classes: vec![1, 3],
            }),
        ];

        let constraints = mapper.translate_axioms(&axioms);

        
        assert_eq!(constraints.len(), 2);
    }

    #[test]
    fn test_custom_config() {
        let config = TranslationConfig {
            disjoint_separation_distance: 50.0,
            disjoint_separation_strength: 0.9,
            ..Default::default()
        };

        let mapper = AxiomMapper::with_config(config);
        let constraints = mapper.translate_disjoint_classes(&vec![1, 2], PRIORITY_ASSERTED, None);

        match &constraints[0].constraint_type {
            PhysicsConstraintType::Separation { min_distance, strength } => {
                assert_eq!(*min_distance, 50.0);
                assert_eq!(*strength, 0.9);
            }
            _ => panic!("Wrong constraint type"),
        }
    }
}

--------------------------------------------------------------------------------
FILE: src/constraints/gpu_converter.rs
PURPOSE: Convert constraints to GPU-compatible format
--------------------------------------------------------------------------------
// GPU Converter - Convert Physics Constraints to CUDA Format
// Week 3 Deliverable: CUDA-Compatible Data Structures

use super::physics_constraint::*;

///
///
#[repr(C)]
#[derive(Debug, Clone, Copy)]
pub struct ConstraintData {
    
    pub kind: i32,

    
    pub count: i32,

    
    
    
    pub node_idx: [i32; 4],

    
    
    
    
    
    
    
    pub params: [f32; 4],

    
    
    pub params2: [f32; 4],

    
    pub weight: f32,

    
    
    pub activation_frame: i32,

    
    _padding: [f32; 2],
}

///
///
pub mod gpu_constraint_kind {
    pub const NONE: i32 = 0;
    pub const SEPARATION: i32 = 1;
    pub const CLUSTERING: i32 = 2;
    pub const COLOCATION: i32 = 3;
    pub const BOUNDARY: i32 = 4;
    pub const HIERARCHICAL_LAYER: i32 = 5;
    pub const CONTAINMENT: i32 = 6;
}

impl Default for ConstraintData {
    fn default() -> Self {
        Self {
            kind: gpu_constraint_kind::NONE,
            count: 0,
            node_idx: [-1; 4],
            params: [0.0; 4],
            params2: [0.0; 4],
            weight: 1.0,
            activation_frame: -1,
            _padding: [0.0; 2],
        }
    }
}

///
pub fn to_gpu_constraint_data(constraint: &PhysicsConstraint) -> ConstraintData {
    let mut data = ConstraintData::default();

    
    data.count = constraint.nodes.len().min(4) as i32;
    for (i, &node_id) in constraint.nodes.iter().take(4).enumerate() {
        data.node_idx[i] = node_id as i32;
    }

    
    data.weight = constraint.priority_weight();

    
    data.activation_frame = constraint.activation_frame.unwrap_or(-1);

    
    match &constraint.constraint_type {
        PhysicsConstraintType::Separation { min_distance, strength } => {
            data.kind = gpu_constraint_kind::SEPARATION;
            data.params[0] = *min_distance;
            data.params[1] = *strength;
        }

        PhysicsConstraintType::Clustering { ideal_distance, stiffness } => {
            data.kind = gpu_constraint_kind::CLUSTERING;
            data.params[0] = *ideal_distance;
            data.params[1] = *stiffness;
        }

        PhysicsConstraintType::Colocation { target_distance, strength } => {
            data.kind = gpu_constraint_kind::COLOCATION;
            data.params[0] = *target_distance;
            data.params[1] = *strength;
        }

        PhysicsConstraintType::Boundary { bounds, strength } => {
            data.kind = gpu_constraint_kind::BOUNDARY;
            data.params[0] = bounds[0]; 
            data.params[1] = bounds[1]; 
            data.params[2] = bounds[2]; 
            data.params[3] = bounds[3]; 
            data.params2[0] = bounds[4]; 
            data.params2[1] = bounds[5]; 
            data.params2[2] = *strength;
        }

        PhysicsConstraintType::HierarchicalLayer { z_level, strength } => {
            data.kind = gpu_constraint_kind::HIERARCHICAL_LAYER;
            data.params[0] = *z_level;
            data.params[1] = *strength;
        }

        PhysicsConstraintType::Containment { parent_node, radius, strength } => {
            data.kind = gpu_constraint_kind::CONTAINMENT;
            data.params[0] = *parent_node as f32;
            data.params[1] = *radius;
            data.params[2] = *strength;
        }
    }

    data
}

///
pub fn to_gpu_constraint_batch(constraints: &[PhysicsConstraint]) -> Vec<ConstraintData> {
    constraints
        .iter()
        .map(to_gpu_constraint_data)
        .collect()
}

///
pub struct GPUConstraintBuffer {
    
    pub data: Vec<ConstraintData>,

    
    pub count: usize,

    
    pub capacity: usize,
}

impl GPUConstraintBuffer {
    
    pub fn new(capacity: usize) -> Self {
        Self {
            data: Vec::with_capacity(capacity),
            count: 0,
            capacity,
        }
    }

    
    pub fn add_constraints(&mut self, constraints: &[PhysicsConstraint]) -> Result<(), String> {
        if self.count + constraints.len() > self.capacity {
            return Err(format!(
                "Buffer overflow: {} + {} > {}",
                self.count,
                constraints.len(),
                self.capacity
            ));
        }

        let gpu_data = to_gpu_constraint_batch(constraints);
        self.data.extend(gpu_data);
        self.count += constraints.len();

        Ok(())
    }

    
    pub fn clear(&mut self) {
        self.data.clear();
        self.count = 0;
    }

    
    pub fn as_ptr(&self) -> *const ConstraintData {
        self.data.as_ptr()
    }

    
    pub fn size_bytes(&self) -> usize {
        self.count * std::mem::size_of::<ConstraintData>()
    }

    
    pub fn is_empty(&self) -> bool {
        self.count == 0
    }

    
    pub fn len(&self) -> usize {
        self.count
    }
}

///
#[derive(Debug, Clone)]
pub struct ConstraintStats {
    pub total_constraints: usize,
    pub separation_count: usize,
    pub clustering_count: usize,
    pub colocation_count: usize,
    pub boundary_count: usize,
    pub hierarchical_count: usize,
    pub containment_count: usize,
    pub user_defined_count: usize,
    pub progressive_count: usize,
    pub total_weight: f32,
}

impl ConstraintStats {
    
    pub fn from_buffer(buffer: &GPUConstraintBuffer) -> Self {
        let mut stats = Self {
            total_constraints: buffer.count,
            separation_count: 0,
            clustering_count: 0,
            colocation_count: 0,
            boundary_count: 0,
            hierarchical_count: 0,
            containment_count: 0,
            user_defined_count: 0,
            progressive_count: 0,
            total_weight: 0.0,
        };

        for constraint_data in &buffer.data {
            match constraint_data.kind {
                gpu_constraint_kind::SEPARATION => stats.separation_count += 1,
                gpu_constraint_kind::CLUSTERING => stats.clustering_count += 1,
                gpu_constraint_kind::COLOCATION => stats.colocation_count += 1,
                gpu_constraint_kind::BOUNDARY => stats.boundary_count += 1,
                gpu_constraint_kind::HIERARCHICAL_LAYER => stats.hierarchical_count += 1,
                gpu_constraint_kind::CONTAINMENT => stats.containment_count += 1,
                _ => {}
            }

            stats.total_weight += constraint_data.weight;

            if constraint_data.activation_frame >= 0 {
                stats.progressive_count += 1;
            }

            
            if (constraint_data.weight - 1.0).abs() < 0.001 {
                stats.user_defined_count += 1;
            }
        }

        stats
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_separation_constraint_conversion() {
        let constraint = PhysicsConstraint::separation(vec![1, 2], 35.0, 0.8, 5);
        let gpu_data = to_gpu_constraint_data(&constraint);

        assert_eq!(gpu_data.kind, gpu_constraint_kind::SEPARATION);
        assert_eq!(gpu_data.count, 2);
        assert_eq!(gpu_data.node_idx[0], 1);
        assert_eq!(gpu_data.node_idx[1], 2);
        assert_eq!(gpu_data.node_idx[2], -1);
        assert_eq!(gpu_data.params[0], 35.0);
        assert_eq!(gpu_data.params[1], 0.8);
        assert!(gpu_data.weight > 0.0);
    }

    #[test]
    fn test_clustering_constraint_conversion() {
        let constraint = PhysicsConstraint::clustering(vec![10, 20], 20.0, 0.6, 3);
        let gpu_data = to_gpu_constraint_data(&constraint);

        assert_eq!(gpu_data.kind, gpu_constraint_kind::CLUSTERING);
        assert_eq!(gpu_data.count, 2);
        assert_eq!(gpu_data.params[0], 20.0);
        assert_eq!(gpu_data.params[1], 0.6);
    }

    #[test]
    fn test_boundary_constraint_conversion() {
        let bounds = [-20.0, 20.0, -20.0, 20.0, -20.0, 20.0];
        let constraint = PhysicsConstraint::boundary(vec![1], bounds, 0.7, 5);
        let gpu_data = to_gpu_constraint_data(&constraint);

        assert_eq!(gpu_data.kind, gpu_constraint_kind::BOUNDARY);
        assert_eq!(gpu_data.params[0], -20.0); 
        assert_eq!(gpu_data.params[1], 20.0);  
        assert_eq!(gpu_data.params[2], -20.0); 
        assert_eq!(gpu_data.params[3], 20.0);  
        assert_eq!(gpu_data.params2[0], -20.0); 
        assert_eq!(gpu_data.params2[1], 20.0);  
        assert_eq!(gpu_data.params2[2], 0.7);   
    }

    #[test]
    fn test_hierarchical_layer_conversion() {
        let constraint = PhysicsConstraint::hierarchical_layer(vec![1, 2, 3], 100.0, 0.7, 5);
        let gpu_data = to_gpu_constraint_data(&constraint);

        assert_eq!(gpu_data.kind, gpu_constraint_kind::HIERARCHICAL_LAYER);
        assert_eq!(gpu_data.count, 3);
        assert_eq!(gpu_data.params[0], 100.0);
        assert_eq!(gpu_data.params[1], 0.7);
    }

    #[test]
    fn test_containment_conversion() {
        let constraint = PhysicsConstraint::containment(vec![1, 2], 100, 50.0, 0.8, 5);
        let gpu_data = to_gpu_constraint_data(&constraint);

        assert_eq!(gpu_data.kind, gpu_constraint_kind::CONTAINMENT);
        assert_eq!(gpu_data.params[0], 100.0); 
        assert_eq!(gpu_data.params[1], 50.0);  
        assert_eq!(gpu_data.params[2], 0.8);   
    }

    #[test]
    fn test_activation_frame() {
        let constraint = PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 5)
            .with_activation_frame(60);

        let gpu_data = to_gpu_constraint_data(&constraint);
        assert_eq!(gpu_data.activation_frame, 60);
    }

    #[test]
    fn test_priority_weight() {
        let c1 = PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 1);
        let c2 = PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 10);

        let gpu1 = to_gpu_constraint_data(&c1);
        let gpu2 = to_gpu_constraint_data(&c2);

        assert!(gpu1.weight > gpu2.weight);
        assert!((gpu1.weight - 1.0).abs() < 0.001);
        assert!((gpu2.weight - 0.1).abs() < 0.001);
    }

    #[test]
    fn test_batch_conversion() {
        let constraints = vec![
            PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 5),
            PhysicsConstraint::clustering(vec![2, 3], 20.0, 0.6, 3),
            PhysicsConstraint::colocation(vec![3, 4], 2.0, 0.9, 1),
        ];

        let gpu_batch = to_gpu_constraint_batch(&constraints);
        assert_eq!(gpu_batch.len(), 3);
        assert_eq!(gpu_batch[0].kind, gpu_constraint_kind::SEPARATION);
        assert_eq!(gpu_batch[1].kind, gpu_constraint_kind::CLUSTERING);
        assert_eq!(gpu_batch[2].kind, gpu_constraint_kind::COLOCATION);
    }

    #[test]
    fn test_gpu_buffer() {
        let mut buffer = GPUConstraintBuffer::new(100);

        let constraints = vec![
            PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 5),
            PhysicsConstraint::clustering(vec![2, 3], 20.0, 0.6, 3),
        ];

        assert!(buffer.add_constraints(&constraints).is_ok());
        assert_eq!(buffer.len(), 2);
        assert!(!buffer.is_empty());

        let size = buffer.size_bytes();
        assert_eq!(size, 2 * std::mem::size_of::<ConstraintData>());

        buffer.clear();
        assert_eq!(buffer.len(), 0);
        assert!(buffer.is_empty());
    }

    #[test]
    fn test_buffer_overflow() {
        let mut buffer = GPUConstraintBuffer::new(2);

        let constraints = vec![
            PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 5),
            PhysicsConstraint::clustering(vec![2, 3], 20.0, 0.6, 3),
            PhysicsConstraint::colocation(vec![3, 4], 2.0, 0.9, 1),
        ];

        assert!(buffer.add_constraints(&constraints).is_err());
    }

    #[test]
    fn test_constraint_stats() {
        let mut buffer = GPUConstraintBuffer::new(100);

        let constraints = vec![
            PhysicsConstraint::separation(vec![1, 2], 10.0, 0.5, 5),
            PhysicsConstraint::separation(vec![2, 3], 15.0, 0.6, 5),
            PhysicsConstraint::clustering(vec![3, 4], 20.0, 0.6, 3),
            PhysicsConstraint::colocation(vec![4, 5], 2.0, 0.9, 1).mark_user_defined(),
        ];

        buffer.add_constraints(&constraints).unwrap();

        let stats = ConstraintStats::from_buffer(&buffer);
        assert_eq!(stats.total_constraints, 4);
        assert_eq!(stats.separation_count, 2);
        assert_eq!(stats.clustering_count, 1);
        assert_eq!(stats.colocation_count, 1);
        assert_eq!(stats.user_defined_count, 1);
    }

    #[test]
    fn test_constraint_data_size() {
        
        let size = std::mem::size_of::<ConstraintData>();

        
        assert_eq!(size % 16, 0);
    }
}

--------------------------------------------------------------------------------
FILE: src/constraints/semantic_axiom_translator.rs
PURPOSE: Semantic axiom to physics constraint translator
--------------------------------------------------------------------------------
// Semantic Axiom Translator - Enhanced OWL Axiom to Physics Constraint Translation
// Maps OWL semantics to physics-based layout constraints with priority blending

use super::axiom_mapper::{AxiomType, OWLAxiom, TranslationConfig};
use super::physics_constraint::*;
use super::semantic_physics_types::*;
use std::collections::HashMap;

/// Configuration for semantic physics translation
#[derive(Debug, Clone)]
pub struct SemanticPhysicsConfig {
    /// Base configuration for standard translation
    pub base_config: TranslationConfig,

    /// Multiplier for DisjointWith separation (repel_k * multiplier)
    pub disjoint_repel_multiplier: f32,

    /// Multiplier for SubClassOf attraction (spring_k * multiplier)
    pub subclass_spring_multiplier: f32,

    /// Enable automatic axis alignment for hierarchies
    pub enable_hierarchy_alignment: bool,

    /// Enable bidirectional constraints for symmetric relations
    pub enable_bidirectional_constraints: bool,

    /// Priority blending strategy
    pub priority_blending: PriorityBlendingStrategy,
}

impl Default for SemanticPhysicsConfig {
    fn default() -> Self {
        Self {
            base_config: TranslationConfig::default(),
            disjoint_repel_multiplier: 2.0,
            subclass_spring_multiplier: 0.5,
            enable_hierarchy_alignment: true,
            enable_bidirectional_constraints: true,
            priority_blending: PriorityBlendingStrategy::Weighted,
        }
    }
}

/// Priority blending strategies for conflicting constraints
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum PriorityBlendingStrategy {
    /// Weighted average by priority
    Weighted,
    /// Take highest priority (lowest number)
    HighestPriority,
    /// Take strongest constraint
    Strongest,
    /// Blend all equally
    Equal,
}

/// Semantic axiom translator with enhanced constraint generation
pub struct SemanticAxiomTranslator {
    config: SemanticPhysicsConfig,
    /// Cache of class IRI to NodeId mappings
    class_to_node: HashMap<String, NodeId>,
    /// Cache of parent-child relationships for hierarchy alignment
    hierarchy_cache: HashMap<NodeId, Vec<NodeId>>,
    /// Next available node ID
    next_node_id: NodeId,
}

impl SemanticAxiomTranslator {
    /// Create new translator with default config
    pub fn new() -> Self {
        Self {
            config: SemanticPhysicsConfig::default(),
            class_to_node: HashMap::new(),
            hierarchy_cache: HashMap::new(),
            next_node_id: 1,
        }
    }

    /// Create translator with custom config
    pub fn with_config(config: SemanticPhysicsConfig) -> Self {
        Self {
            config,
            class_to_node: HashMap::new(),
            hierarchy_cache: HashMap::new(),
            next_node_id: 1,
        }
    }

    /// Get or create node ID for class IRI
    pub fn get_or_create_node_id(&mut self, class_iri: &str) -> NodeId {
        if let Some(&node_id) = self.class_to_node.get(class_iri) {
            node_id
        } else {
            let node_id = self.next_node_id;
            self.next_node_id += 1;
            self.class_to_node.insert(class_iri.to_string(), node_id);
            node_id
        }
    }

    /// Translate OWL axioms to semantic physics constraints
    pub fn translate_axioms(&mut self, axioms: &[OWLAxiom]) -> Vec<SemanticPhysicsConstraint> {
        axioms
            .iter()
            .flat_map(|axiom| self.translate_axiom(axiom))
            .collect()
    }

    /// Translate single axiom to semantic constraints
    pub fn translate_axiom(&mut self, axiom: &OWLAxiom) -> Vec<SemanticPhysicsConstraint> {
        let priority = self.calculate_priority(axiom);

        match &axiom.axiom_type {
            AxiomType::DisjointClasses { classes } => {
                self.translate_disjoint_classes(classes, priority)
            }
            AxiomType::SubClassOf { subclass, superclass } => {
                self.translate_subclass_of(*subclass, *superclass, priority)
            }
            AxiomType::EquivalentClasses { class1, class2 } => {
                self.translate_equivalent_classes(*class1, *class2, priority)
            }
            AxiomType::SameAs { individual1, individual2 } => {
                self.translate_same_as(*individual1, *individual2, priority)
            }
            AxiomType::DifferentFrom { individual1, individual2 } => {
                self.translate_different_from(*individual1, *individual2, priority)
            }
            AxiomType::PropertyDomainRange { property, domain, range } => {
                self.translate_property_domain_range(*property, *domain, *range, priority)
            }
            AxiomType::PartOf { part, whole } => {
                self.translate_part_of(*part, *whole, priority)
            }
            _ => vec![],
        }
    }

    /// Calculate priority for axiom (1-10, lower is higher priority)
    fn calculate_priority(&self, axiom: &OWLAxiom) -> u8 {
        if axiom.user_defined {
            1 // Highest priority
        } else if axiom.inferred {
            7 // Lower priority
        } else {
            5 // Medium priority (asserted)
        }
    }

    /// Translate DisjointClasses to Separation constraints
    fn translate_disjoint_classes(
        &mut self,
        classes: &[NodeId],
        priority: u8,
    ) -> Vec<SemanticPhysicsConstraint> {
        let mut constraints = Vec::new();

        // Create pairwise separation constraints
        for i in 0..classes.len() {
            for j in (i + 1)..classes.len() {
                let class_a = format!("node_{}", classes[i]);
                let class_b = format!("node_{}", classes[j]);

                let min_distance = self.config.base_config.disjoint_separation_distance
                    * self.config.disjoint_repel_multiplier;
                let strength = self.config.base_config.disjoint_separation_strength;

                constraints.push(SemanticPhysicsConstraint::Separation {
                    class_a,
                    class_b,
                    min_distance,
                    strength,
                    priority,
                });
            }
        }

        constraints
    }

    /// Translate SubClassOf to HierarchicalAttraction constraints
    fn translate_subclass_of(
        &mut self,
        subclass: NodeId,
        superclass: NodeId,
        priority: u8,
    ) -> Vec<SemanticPhysicsConstraint> {
        // Update hierarchy cache
        self.hierarchy_cache
            .entry(superclass)
            .or_insert_with(Vec::new)
            .push(subclass);

        let child_class = format!("node_{}", subclass);
        let parent_class = format!("node_{}", superclass);

        let ideal_distance = self.config.base_config.subclass_clustering_distance;
        let strength = self.config.base_config.subclass_clustering_stiffness
            * self.config.subclass_spring_multiplier;

        let mut constraints = vec![SemanticPhysicsConstraint::HierarchicalAttraction {
            child_class: child_class.clone(),
            parent_class,
            ideal_distance,
            strength,
            priority,
        }];

        // Add axis alignment if enabled
        if self.config.enable_hierarchy_alignment {
            // Align child on Y axis relative to parent depth
            constraints.push(SemanticPhysicsConstraint::Alignment {
                class_iri: child_class,
                axis: Axis::Y,
                target_position: 0.0, // Will be calculated based on hierarchy depth
                strength: 0.5,
                priority: priority + 2, // Lower priority than main constraint
            });
        }

        constraints
    }

    /// Translate EquivalentClasses to Colocation and BidirectionalEdge
    fn translate_equivalent_classes(
        &mut self,
        class1: NodeId,
        class2: NodeId,
        priority: u8,
    ) -> Vec<SemanticPhysicsConstraint> {
        let class_a = format!("node_{}", class1);
        let class_b = format!("node_{}", class2);

        let target_distance = self.config.base_config.equivalent_colocation_distance;
        let strength = self.config.base_config.equivalent_colocation_strength;

        let mut constraints = vec![SemanticPhysicsConstraint::Colocation {
            class_a: class_a.clone(),
            class_b: class_b.clone(),
            target_distance,
            strength,
            priority,
        }];

        // Add bidirectional edge if enabled
        if self.config.enable_bidirectional_constraints {
            constraints.push(SemanticPhysicsConstraint::BidirectionalEdge {
                class_a,
                class_b,
                strength: 0.9,
                priority,
            });
        }

        constraints
    }

    /// Translate SameAs to Colocation
    fn translate_same_as(
        &mut self,
        individual1: NodeId,
        individual2: NodeId,
        priority: u8,
    ) -> Vec<SemanticPhysicsConstraint> {
        let class_a = format!("node_{}", individual1);
        let class_b = format!("node_{}", individual2);

        vec![SemanticPhysicsConstraint::Colocation {
            class_a,
            class_b,
            target_distance: 0.0, // Complete overlap
            strength: 1.0,        // Maximum strength
            priority,
        }]
    }

    /// Translate DifferentFrom to Separation
    fn translate_different_from(
        &mut self,
        individual1: NodeId,
        individual2: NodeId,
        priority: u8,
    ) -> Vec<SemanticPhysicsConstraint> {
        let class_a = format!("node_{}", individual1);
        let class_b = format!("node_{}", individual2);

        let min_distance = self.config.base_config.disjoint_separation_distance;
        let strength = self.config.base_config.disjoint_separation_strength;

        vec![SemanticPhysicsConstraint::Separation {
            class_a,
            class_b,
            min_distance,
            strength,
            priority,
        }]
    }

    /// Translate PropertyDomainRange to Alignment constraints
    fn translate_property_domain_range(
        &mut self,
        _property: NodeId,
        domain: NodeId,
        range: NodeId,
        priority: u8,
    ) -> Vec<SemanticPhysicsConstraint> {
        let domain_class = format!("node_{}", domain);
        let range_class = format!("node_{}", range);

        vec![
            // Align domain on left (X = -50)
            SemanticPhysicsConstraint::Alignment {
                class_iri: domain_class,
                axis: Axis::X,
                target_position: -50.0,
                strength: 0.6,
                priority,
            },
            // Align range on right (X = 50)
            SemanticPhysicsConstraint::Alignment {
                class_iri: range_class,
                axis: Axis::X,
                target_position: 50.0,
                strength: 0.6,
                priority,
            },
        ]
    }

    /// Translate PartOf to Containment
    fn translate_part_of(
        &mut self,
        part: NodeId,
        whole: NodeId,
        priority: u8,
    ) -> Vec<SemanticPhysicsConstraint> {
        let child_class = format!("node_{}", part);
        let parent_class = format!("node_{}", whole);

        let radius = self.config.base_config.subclass_clustering_distance
            * self.config.base_config.containment_radius_multiplier;
        let strength = self.config.base_config.containment_strength;

        vec![SemanticPhysicsConstraint::Containment {
            child_class,
            parent_class,
            radius,
            strength,
            priority,
        }]
    }

    /// Convert semantic constraints to standard physics constraints
    pub fn to_physics_constraints(
        &self,
        semantic_constraints: &[SemanticPhysicsConstraint],
    ) -> Vec<PhysicsConstraint> {
        semantic_constraints
            .iter()
            .filter_map(|sc| self.semantic_to_physics(sc))
            .collect()
    }

    /// Convert single semantic constraint to physics constraint
    fn semantic_to_physics(&self, semantic: &SemanticPhysicsConstraint) -> Option<PhysicsConstraint> {
        match semantic {
            SemanticPhysicsConstraint::Separation {
                class_a,
                class_b,
                min_distance,
                strength,
                priority,
            } => {
                let node_a = self.class_to_node.get(class_a)?;
                let node_b = self.class_to_node.get(class_b)?;
                Some(PhysicsConstraint::separation(
                    vec![*node_a, *node_b],
                    *min_distance,
                    *strength,
                    *priority,
                ))
            }
            SemanticPhysicsConstraint::HierarchicalAttraction {
                child_class,
                parent_class,
                ideal_distance,
                strength,
                priority,
            } => {
                let child = self.class_to_node.get(child_class)?;
                let parent = self.class_to_node.get(parent_class)?;
                Some(PhysicsConstraint::clustering(
                    vec![*child, *parent],
                    *ideal_distance,
                    *strength,
                    *priority,
                ))
            }
            SemanticPhysicsConstraint::Colocation {
                class_a,
                class_b,
                target_distance,
                strength,
                priority,
            } => {
                let node_a = self.class_to_node.get(class_a)?;
                let node_b = self.class_to_node.get(class_b)?;
                Some(PhysicsConstraint::colocation(
                    vec![*node_a, *node_b],
                    *target_distance,
                    *strength,
                    *priority,
                ))
            }
            SemanticPhysicsConstraint::Containment {
                child_class,
                parent_class,
                radius,
                strength,
                priority,
            } => {
                let child = self.class_to_node.get(child_class)?;
                let parent = self.class_to_node.get(parent_class)?;
                Some(PhysicsConstraint::containment(
                    vec![*child],
                    *parent,
                    *radius,
                    *strength,
                    *priority,
                ))
            }
            // Alignment and BidirectionalEdge need special handling
            _ => None,
        }
    }

    /// Get hierarchy depth for a node
    pub fn get_hierarchy_depth(&self, node: NodeId) -> usize {
        let mut depth = 0;
        let mut current = node;

        // Traverse up the hierarchy
        loop {
            let parent = self
                .hierarchy_cache
                .iter()
                .find(|(_, children)| children.contains(&current))
                .map(|(parent, _)| *parent);

            match parent {
                Some(p) => {
                    depth += 1;
                    current = p;
                }
                None => break,
            }
        }

        depth
    }
}

impl Default for SemanticAxiomTranslator {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_disjoint_classes_translation() {
        let mut translator = SemanticAxiomTranslator::new();
        let axiom = OWLAxiom::asserted(AxiomType::DisjointClasses {
            classes: vec![1, 2, 3],
        });

        let constraints = translator.translate_axiom(&axiom);

        // Should create 3 pairwise separation constraints
        assert_eq!(constraints.len(), 3);

        for constraint in &constraints {
            match constraint {
                SemanticPhysicsConstraint::Separation { min_distance, strength, .. } => {
                    // Check multiplier is applied (2.0x)
                    assert!(*min_distance > 35.0);
                    assert_eq!(*strength, 0.8);
                }
                _ => panic!("Wrong constraint type"),
            }
        }
    }

    #[test]
    fn test_subclass_of_translation() {
        let mut translator = SemanticAxiomTranslator::new();
        let axiom = OWLAxiom::asserted(AxiomType::SubClassOf {
            subclass: 10,
            superclass: 20,
        });

        let constraints = translator.translate_axiom(&axiom);

        // Should create hierarchical attraction + alignment
        assert!(!constraints.is_empty());

        let has_attraction = constraints.iter().any(|c| {
            matches!(c, SemanticPhysicsConstraint::HierarchicalAttraction { .. })
        });
        assert!(has_attraction);
    }

    #[test]
    fn test_priority_calculation() {
        let translator = SemanticAxiomTranslator::new();

        let user_axiom = OWLAxiom::user_defined(AxiomType::SubClassOf {
            subclass: 1,
            superclass: 2,
        });
        assert_eq!(translator.calculate_priority(&user_axiom), 1);

        let inferred_axiom = OWLAxiom::inferred(AxiomType::SubClassOf {
            subclass: 1,
            superclass: 2,
        });
        assert_eq!(translator.calculate_priority(&inferred_axiom), 7);

        let asserted_axiom = OWLAxiom::asserted(AxiomType::SubClassOf {
            subclass: 1,
            superclass: 2,
        });
        assert_eq!(translator.calculate_priority(&asserted_axiom), 5);
    }

    #[test]
    fn test_equivalent_classes_with_bidirectional() {
        let mut translator = SemanticAxiomTranslator::new();
        let axiom = OWLAxiom::asserted(AxiomType::EquivalentClasses {
            class1: 5,
            class2: 6,
        });

        let constraints = translator.translate_axiom(&axiom);

        // Should have colocation + bidirectional edge
        assert_eq!(constraints.len(), 2);

        let has_colocation = constraints.iter().any(|c| {
            matches!(c, SemanticPhysicsConstraint::Colocation { .. })
        });
        let has_bidirectional = constraints.iter().any(|c| {
            matches!(c, SemanticPhysicsConstraint::BidirectionalEdge { .. })
        });

        assert!(has_colocation);
        assert!(has_bidirectional);
    }

    #[test]
    fn test_part_of_translation() {
        let mut translator = SemanticAxiomTranslator::new();
        let axiom = OWLAxiom::asserted(AxiomType::PartOf {
            part: 10,
            whole: 20,
        });

        let constraints = translator.translate_axiom(&axiom);

        assert_eq!(constraints.len(), 1);
        match &constraints[0] {
            SemanticPhysicsConstraint::Containment { radius, strength, .. } => {
                assert!(*radius > 0.0);
                assert_eq!(*strength, 0.8);
            }
            _ => panic!("Wrong constraint type"),
        }
    }

    #[test]
    fn test_node_id_mapping() {
        let mut translator = SemanticAxiomTranslator::new();

        let id1 = translator.get_or_create_node_id("ClassA");
        let id2 = translator.get_or_create_node_id("ClassB");
        let id3 = translator.get_or_create_node_id("ClassA"); // Should reuse

        assert_ne!(id1, id2);
        assert_eq!(id1, id3);
    }
}

--------------------------------------------------------------------------------
FILE: src/physics/mod.rs
PURPOSE: Physics engine module
--------------------------------------------------------------------------------
//! Physics engine modules for advanced knowledge graph layout optimization
//!
//! This module provides sophisticated physics-based algorithms for knowledge graph
//! layout optimization, including stress majorization and semantic constraint generation.
//! The physics engine integrates with the GPU compute pipeline for high-performance
//! real-time graph visualization and layout optimization.
//!
//! ## Architecture
//!
//! The physics module is organized into specialized components:
//!
//! - **Stress Majorization**: Implements stress majorization algorithms for global
//!   layout optimization, minimizing the stress function to achieve visually pleasing
//!   node positions that satisfy multiple constraint types.
//!
//! - **Semantic Constraints**: Generates constraints based on semantic relationships,
//!   topic similarity, hierarchical structures, and domain knowledge to create
//!   meaningful spatial arrangements.
//!
//! - **Ontology Constraints**: Translates OWL axioms and logical inferences into
//!   physics constraints, bridging semantic reasoning with physical simulation to
//!   enforce ontological relationships in graph layout.
//!
//! ## Integration
//!
//! This module integrates with:
//! - GPU compute kernels for high-performance matrix operations
//! - Constraint system defined in `models::constraints`
//! - Graph data structures and node/edge representations
//! - Real-time visualization pipeline
//!
//! ## Usage
//!
//! ```rust
//! use crate::physics::{StressMajorizationSolver, SemanticConstraintGenerator, OntologyConstraintTranslator};
//! use crate::models::constraints::ConstraintSet;
//! use crate::models::graph::GraphData;
//!
//! 
//! let mut solver = StressMajorizationSolver::new(params);
//!
//! 
//! let constraint_generator = SemanticConstraintGenerator::new();
//! let semantic_constraints = constraint_generator.generate_constraints(&graph_data)?;
//!
//! 
//! let mut ontology_translator = OntologyConstraintTranslator::new();
//! let ontology_constraints = ontology_translator.apply_ontology_constraints(&graph_data, &reasoning_report)?;
//!
//! 
//! let mut combined_constraints = semantic_constraints.constraints;
//! combined_constraints.extend(ontology_constraints.constraints);
//!
//! let final_constraint_set = ConstraintSet {
//!     constraints: combined_constraints,
//!     advanced_params: ontology_constraints.advanced_params
//! };
//!
//! solver.optimize(&mut graph_data, &final_constraint_set)?;
//! ```

pub mod ontology_constraints;
pub mod semantic_constraints;
pub mod stress_majorization;

#[cfg(test)]
mod integration_tests;

pub use ontology_constraints::{
    OWLAxiom, OWLAxiomType, OntologyConstraintTranslator, OntologyInference,
    OntologyReasoningReport,
};
pub use semantic_constraints::SemanticConstraintGenerator;
pub use stress_majorization::StressMajorizationSolver;

///
pub use crate::models::constraints::{AdvancedParams, Constraint, ConstraintKind, ConstraintSet};
pub use crate::models::graph::GraphData;
pub use crate::models::metadata::Metadata;
pub use crate::models::node::Node;

--------------------------------------------------------------------------------
FILE: src/physics/stress_majorization.rs
PURPOSE: Stress majorization layout optimization
--------------------------------------------------------------------------------
//! Stress majorization solver for knowledge graph layout optimization
//!
//! This module implements a stress majorization algorithm that optimizes node positions
//! to satisfy multiple constraint types while minimizing layout stress. The solver uses
//! efficient matrix operations and integrates with the GPU physics pipeline for
//! high-performance real-time optimization.
//!
//! ## Algorithm Overview
//!
//! Stress majorization works by:
//! 1. Computing the stress function based on distance differences between ideal and actual positions
//! 2. Using majorization to create a convex approximation of the stress function
//! 3. Iteratively minimizing the majorized function to find optimal positions
//! 4. Incorporating constraints through penalty methods or Lagrange multipliers
//!
//! ## Performance Features
//!
//! - GPU-accelerated matrix operations for large graphs
//! - Sparse matrix representations for efficient computation
//! - Adaptive step sizing and convergence detection
//! - Multi-threaded CPU fallback for smaller graphs
//! - Memory-efficient algorithms for very large datasets

use cudarc::driver::CudaDevice;
use log::{debug, info, trace, warn};
use nalgebra::DMatrix;
use std::collections::HashMap;
use std::sync::Arc;

use crate::models::{
    constraints::{AdvancedParams, Constraint, ConstraintKind, ConstraintSet},
    graph::GraphData,
};

///
#[derive(Debug, Clone)]
pub struct StressMajorizationConfig {
    
    pub max_iterations: u32,
    
    pub tolerance: f32,
    
    pub step_size: f32,
    
    pub adaptive_step: bool,
    
    pub constraint_weight: f32,
    
    pub use_gpu: bool,
    
    pub min_improvement: f32,
    
    pub convergence_check_interval: u32,
}

impl Default for StressMajorizationConfig {
    fn default() -> Self {
        Self {
            max_iterations: 1000,
            tolerance: 1e-6,
            step_size: 0.1,
            adaptive_step: true,
            constraint_weight: 1.0,
            use_gpu: true,
            min_improvement: 1e-8,
            convergence_check_interval: 10,
        }
    }
}

///
#[derive(Debug, Clone)]
pub struct OptimizationResult {
    
    pub final_stress: f32,
    
    pub iterations: u32,
    
    pub converged: bool,
    
    pub constraint_scores: HashMap<ConstraintKind, f32>,
    
    pub computation_time: u64,
}

///
pub struct StressMajorizationSolver {
    config: StressMajorizationConfig,
    _gpu_context: Option<Arc<CudaDevice>>,
    cached_distance_matrix: Option<DMatrix<f32>>,
    cached_weight_matrix: Option<DMatrix<f32>>,
    iteration_history: Vec<f32>,
}

impl Clone for StressMajorizationSolver {
    fn clone(&self) -> Self {
        Self {
            config: self.config.clone(),
            _gpu_context: self._gpu_context.clone(), 
            cached_distance_matrix: self.cached_distance_matrix.clone(),
            cached_weight_matrix: self.cached_weight_matrix.clone(),
            iteration_history: self.iteration_history.clone(),
        }
    }
}

impl StressMajorizationSolver {
    
    pub fn new() -> Self {
        Self::with_config(StressMajorizationConfig::default())
    }

    
    pub fn with_config(config: StressMajorizationConfig) -> Self {
        let gpu_context = if config.use_gpu {
            match Self::initialize_gpu() {
                Ok(device) => Some(device),
                Err(e) => {
                    warn!("Failed to initialize GPU, falling back to CPU: {}", e);
                    None
                }
            }
        } else {
            None
        };

        Self {
            config,
            _gpu_context: gpu_context,
            cached_distance_matrix: None,
            cached_weight_matrix: None,
            iteration_history: Vec::new(),
        }
    }

    
    pub fn from_advanced_params(params: &AdvancedParams) -> Self {
        let config = StressMajorizationConfig {
            max_iterations: params.stress_step_interval_frames * 10,
            constraint_weight: params.constraint_force_weight,
            step_size: 0.05,
            tolerance: 1e-5,
            adaptive_step: params.adaptive_force_scaling,
            ..Default::default()
        };

        Self::with_config(config)
    }

    
    fn initialize_gpu() -> Result<Arc<CudaDevice>, Box<dyn std::error::Error>> {
        info!("Initializing GPU device for stress majorization");
        let device = CudaDevice::new(0)?;
        info!("Successfully initialized CUDA device for stress majorization");
        Ok(device)
    }

    
    pub fn optimize(
        &mut self,
        graph_data: &mut GraphData,
        constraints: &ConstraintSet,
    ) -> Result<OptimizationResult, Box<dyn std::error::Error>> {
        let start_time = std::time::Instant::now();
        info!(
            "Starting stress majorization optimization for {} nodes",
            graph_data.nodes.len()
        );

        
        if graph_data.nodes.is_empty() {
            return Err("Cannot optimize empty graph".into());
        }

        
        self.compute_distance_matrix(graph_data)?;
        self.compute_weight_matrix(graph_data)?;

        
        self.initialize_positions(graph_data)?;

        let mut best_stress = f32::INFINITY;
        let mut current_positions = self.extract_positions(graph_data);
        let mut iterations = 0;
        let mut converged = false;

        info!(
            "Beginning iterative optimization with {} constraints",
            constraints.constraints.len()
        );

        
        while iterations < self.config.max_iterations && !converged {
            
            let current_stress = self.compute_stress(&current_positions, graph_data)?;

            
            if current_stress < best_stress {
                best_stress = current_stress;
                self.apply_positions(graph_data, &current_positions)?;
            }

            
            let gradient = self.compute_gradient(&current_positions, graph_data, constraints)?;
            let new_positions = self.update_positions(&current_positions, &gradient)?;

            
            if iterations % self.config.convergence_check_interval == 0 {
                let improvement = (best_stress - current_stress) / best_stress.max(1e-10);
                converged = improvement < self.config.tolerance;

                if iterations % 100 == 0 {
                    debug!(
                        "Iteration {}: stress = {:.6}, improvement = {:.8}",
                        iterations, current_stress, improvement
                    );
                }
            }

            current_positions = new_positions;
            iterations += 1;
            self.iteration_history.push(current_stress);
        }

        
        self.apply_positions(graph_data, &current_positions)?;

        
        let constraint_scores = self.compute_constraint_scores(graph_data, constraints)?;

        let result = OptimizationResult {
            final_stress: best_stress,
            iterations,
            converged,
            constraint_scores,
            computation_time: start_time.elapsed().as_millis() as u64,
        };

        info!(
            "Stress majorization completed: {} iterations, stress = {:.6}, converged = {}",
            iterations, best_stress, converged
        );

        Ok(result)
    }

    
    fn compute_distance_matrix(
        &mut self,
        graph_data: &GraphData,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let n = graph_data.nodes.len();
        let mut distance_matrix = DMatrix::zeros(n, n);

        
        
        for (i, node_a) in graph_data.nodes.iter().enumerate() {
            for (j, node_b) in graph_data.nodes.iter().enumerate() {
                if i == j {
                    distance_matrix[(i, j)] = 0.0;
                } else {
                    
                    let direct_distance = graph_data
                        .edges
                        .iter()
                        .find(|edge| {
                            (edge.source == node_a.id && edge.target == node_b.id)
                                || (edge.source == node_b.id && edge.target == node_a.id)
                        })
                        .map(|_| 1.0) 
                        .unwrap_or(f32::INFINITY);

                    distance_matrix[(i, j)] = direct_distance;
                }
            }
        }

        
        
        let num_landmarks = (n as f32).sqrt().ceil() as usize;
        let num_landmarks = num_landmarks.min(n).max(10); 

        let mut landmarks = Vec::new();
        let stride = n / num_landmarks;
        for i in 0..num_landmarks {
            landmarks.push(i * stride);
        }

        
        let mut landmark_distances = vec![vec![f32::INFINITY; n]; num_landmarks];
        for (k_idx, &landmark) in landmarks.iter().enumerate() {
            
            let mut dist = vec![f32::INFINITY; n];
            dist[landmark] = 0.0;

            
            let mut queue = std::collections::VecDeque::new();
            queue.push_back(landmark);

            while let Some(u) = queue.pop_front() {
                for v in 0..n {
                    if distance_matrix[(u, v)] < f32::INFINITY && distance_matrix[(u, v)] > 0.0 {
                        let new_dist = dist[u] + distance_matrix[(u, v)];
                        if new_dist < dist[v] {
                            dist[v] = new_dist;
                            queue.push_back(v);
                        }
                    }
                }
            }

            landmark_distances[k_idx] = dist;
        }

        
        for i in 0..n {
            for j in 0..n {
                if i != j {
                    let mut min_dist = f32::INFINITY;
                    for k_idx in 0..num_landmarks {
                        let dist_ki = landmark_distances[k_idx][i];
                        let dist_kj = landmark_distances[k_idx][j];
                        if dist_ki < f32::INFINITY && dist_kj < f32::INFINITY {
                            min_dist = min_dist.min(dist_ki + dist_kj);
                        }
                    }
                    
                    if min_dist < distance_matrix[(i, j)] {
                        distance_matrix[(i, j)] = min_dist;
                    }
                }
            }
        }

        
        for i in 0..n {
            for j in 0..n {
                if distance_matrix[(i, j)].is_infinite() {
                    distance_matrix[(i, j)] = (n as f32) * 2.0; 
                }
            }
        }

        self.cached_distance_matrix = Some(distance_matrix);
        trace!("Computed distance matrix for {} nodes", n);
        Ok(())
    }

    
    fn compute_weight_matrix(
        &mut self,
        graph_data: &GraphData,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let distance_matrix = self
            .cached_distance_matrix
            .as_ref()
            .ok_or("Distance matrix must be computed first")?;

        let n = graph_data.nodes.len();
        let mut weight_matrix = DMatrix::zeros(n, n);

        
        for i in 0..n {
            for j in 0..n {
                if i != j {
                    let distance = distance_matrix[(i, j)];
                    if distance > 0.0 {
                        weight_matrix[(i, j)] = 1.0 / (distance * distance);
                    }
                }
            }
        }

        self.cached_weight_matrix = Some(weight_matrix);
        trace!("Computed weight matrix for {} nodes", n);
        Ok(())
    }

    
    fn initialize_positions(
        &self,
        graph_data: &mut GraphData,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let mut rng = rand::thread_rng();

        for node in &mut graph_data.nodes {
            
            if node.data.x.abs() < f32::EPSILON
                && node.data.y.abs() < f32::EPSILON
                && node.data.z.abs() < f32::EPSILON
            {
                
                use rand::Rng;
                let theta = rng.gen_range(0.0..2.0 * std::f32::consts::PI);
                let phi = rng.gen_range(0.0..std::f32::consts::PI);
                let radius = rng.gen_range(50.0..200.0);

                node.data.x = radius * phi.sin() * theta.cos();
                node.data.y = radius * phi.sin() * theta.sin();
                node.data.z = radius * phi.cos();
            }
        }

        trace!("Initialized positions for {} nodes", graph_data.nodes.len());
        Ok(())
    }

    
    fn extract_positions(&self, graph_data: &GraphData) -> DMatrix<f32> {
        let n = graph_data.nodes.len();
        let mut positions = DMatrix::zeros(n, 3);

        for (i, node) in graph_data.nodes.iter().enumerate() {
            positions[(i, 0)] = node.data.x;
            positions[(i, 1)] = node.data.y;
            positions[(i, 2)] = node.data.z;
        }

        positions
    }

    
    fn apply_positions(
        &self,
        graph_data: &mut GraphData,
        positions: &DMatrix<f32>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        if positions.nrows() != graph_data.nodes.len() || positions.ncols() != 3 {
            return Err("Position matrix dimensions don't match graph data".into());
        }

        for (i, node) in graph_data.nodes.iter_mut().enumerate() {
            node.data.x = positions[(i, 0)];
            node.data.y = positions[(i, 1)];
            node.data.z = positions[(i, 2)];
        }

        Ok(())
    }

    
    fn compute_stress(
        &self,
        positions: &DMatrix<f32>,
        graph_data: &GraphData,
    ) -> Result<f32, Box<dyn std::error::Error>> {
        let distance_matrix = self
            .cached_distance_matrix
            .as_ref()
            .ok_or("Distance matrix not computed")?;
        let weight_matrix = self
            .cached_weight_matrix
            .as_ref()
            .ok_or("Weight matrix not computed")?;

        let n = graph_data.nodes.len();
        let mut stress = 0.0;

        for i in 0..n {
            for j in i + 1..n {
                let ideal_distance = distance_matrix[(i, j)];
                let current_distance = self.euclidean_distance(positions, i, j);
                let weight = weight_matrix[(i, j)];

                let diff = ideal_distance - current_distance;
                stress += weight * diff * diff;
            }
        }

        Ok(stress)
    }

    
    fn compute_gradient(
        &self,
        positions: &DMatrix<f32>,
        graph_data: &GraphData,
        constraints: &ConstraintSet,
    ) -> Result<DMatrix<f32>, Box<dyn std::error::Error>> {
        let distance_matrix = self
            .cached_distance_matrix
            .as_ref()
            .ok_or("Distance matrix not computed")?;
        let weight_matrix = self
            .cached_weight_matrix
            .as_ref()
            .ok_or("Weight matrix not computed")?;

        let n = graph_data.nodes.len();
        let mut gradient = DMatrix::zeros(n, 3);

        
        for i in 0..n {
            for j in 0..n {
                if i == j {
                    continue;
                }

                let ideal_distance = distance_matrix[(i, j)];
                let current_distance = self.euclidean_distance(positions, i, j);

                if current_distance > f32::EPSILON {
                    let weight = weight_matrix[(i, j)];
                    let factor = 2.0 * weight * (1.0 - ideal_distance / current_distance);

                    for dim in 0..3 {
                        let diff = positions[(i, dim)] - positions[(j, dim)];
                        gradient[(i, dim)] += factor * diff;
                    }
                }
            }
        }

        
        for constraint in constraints.active_constraints() {
            self.add_constraint_gradient(&mut gradient, positions, constraint)?;
        }

        Ok(gradient)
    }

    
    fn add_constraint_gradient(
        &self,
        gradient: &mut DMatrix<f32>,
        positions: &DMatrix<f32>,
        constraint: &Constraint,
    ) -> Result<(), Box<dyn std::error::Error>> {
        match constraint.kind {
            ConstraintKind::FixedPosition => {
                if let Some(&node_idx) = constraint.node_indices.first() {
                    if constraint.params.len() >= 3 && node_idx < positions.nrows() as u32 {
                        let node_idx = node_idx as usize;
                        let weight = constraint.weight * self.config.constraint_weight;

                        gradient[(node_idx, 0)] +=
                            weight * 2.0 * (positions[(node_idx, 0)] - constraint.params[0]);
                        gradient[(node_idx, 1)] +=
                            weight * 2.0 * (positions[(node_idx, 1)] - constraint.params[1]);
                        gradient[(node_idx, 2)] +=
                            weight * 2.0 * (positions[(node_idx, 2)] - constraint.params[2]);
                    }
                }
            }

            ConstraintKind::Separation => {
                if constraint.node_indices.len() >= 2 && !constraint.params.is_empty() {
                    let i = constraint.node_indices[0] as usize;
                    let j = constraint.node_indices[1] as usize;
                    let min_distance = constraint.params[0];

                    if i < positions.nrows() && j < positions.nrows() {
                        let current_distance = self.euclidean_distance(positions, i, j);

                        if current_distance < min_distance && current_distance > f32::EPSILON {
                            let weight = constraint.weight * self.config.constraint_weight;
                            let factor =
                                weight * (min_distance - current_distance) / current_distance;

                            for dim in 0..3 {
                                let diff = positions[(i, dim)] - positions[(j, dim)];
                                gradient[(i, dim)] -= factor * diff;
                                gradient[(j, dim)] += factor * diff;
                            }
                        }
                    }
                }
            }

            ConstraintKind::AlignmentHorizontal => {
                if !constraint.params.is_empty() {
                    let target_y = constraint.params[0];
                    let weight = constraint.weight * self.config.constraint_weight;

                    for &node_idx in &constraint.node_indices {
                        if node_idx < positions.nrows() as u32 {
                            let node_idx = node_idx as usize;
                            gradient[(node_idx, 1)] +=
                                weight * 2.0 * (positions[(node_idx, 1)] - target_y);
                        }
                    }
                }
            }

            ConstraintKind::Clustering => {
                if constraint.params.len() >= 2 {
                    let strength = constraint.params[1];
                    let weight = constraint.weight * self.config.constraint_weight * strength;

                    
                    let mut centroid = [0.0f32; 3];
                    let mut valid_nodes = 0;

                    for &node_idx in &constraint.node_indices {
                        if node_idx < positions.nrows() as u32 {
                            let node_idx = node_idx as usize;
                            for dim in 0..3 {
                                centroid[dim] += positions[(node_idx, dim)];
                            }
                            valid_nodes += 1;
                        }
                    }

                    if valid_nodes > 0 {
                        for dim in 0..3 {
                            centroid[dim] /= valid_nodes as f32;
                        }

                        
                        for &node_idx in &constraint.node_indices {
                            if node_idx < positions.nrows() as u32 {
                                let node_idx = node_idx as usize;
                                for dim in 0..3 {
                                    gradient[(node_idx, dim)] +=
                                        weight * (centroid[dim] - positions[(node_idx, dim)]);
                                }
                            }
                        }
                    }
                }
            }

            _ => {
                
                debug!(
                    "Constraint type {:?} not yet implemented in gradient computation",
                    constraint.kind
                );
            }
        }

        Ok(())
    }

    
    fn update_positions(
        &self,
        positions: &DMatrix<f32>,
        gradient: &DMatrix<f32>,
    ) -> Result<DMatrix<f32>, Box<dyn std::error::Error>> {
        let mut new_positions = positions.clone();
        let step_size = self.config.step_size;

        for i in 0..positions.nrows() {
            for j in 0..positions.ncols() {
                new_positions[(i, j)] -= step_size * gradient[(i, j)];
            }
        }

        Ok(new_positions)
    }

    
    fn euclidean_distance(&self, positions: &DMatrix<f32>, i: usize, j: usize) -> f32 {
        let mut sum = 0.0;
        for dim in 0..3 {
            let diff = positions[(i, dim)] - positions[(j, dim)];
            sum += diff * diff;
        }
        sum.sqrt()
    }

    
    fn compute_constraint_scores(
        &self,
        graph_data: &GraphData,
        constraints: &ConstraintSet,
    ) -> Result<HashMap<ConstraintKind, f32>, Box<dyn std::error::Error>> {
        let mut scores = HashMap::new();
        let positions = self.extract_positions(graph_data);

        for constraint in constraints.active_constraints() {
            let score = match constraint.kind {
                ConstraintKind::FixedPosition => {
                    self.score_fixed_position(&positions, constraint)?
                }
                ConstraintKind::Separation => self.score_separation(&positions, constraint)?,
                ConstraintKind::AlignmentHorizontal => {
                    self.score_alignment_horizontal(&positions, constraint)?
                }
                ConstraintKind::Clustering => self.score_clustering(&positions, constraint)?,
                _ => 0.5, 
            };

            scores
                .entry(constraint.kind)
                .and_modify(|e| *e = (*e + score) / 2.0)
                .or_insert(score);
        }

        Ok(scores)
    }

    
    fn score_fixed_position(
        &self,
        positions: &DMatrix<f32>,
        constraint: &Constraint,
    ) -> Result<f32, Box<dyn std::error::Error>> {
        if let Some(&node_idx) = constraint.node_indices.first() {
            if constraint.params.len() >= 3 && node_idx < positions.nrows() as u32 {
                let node_idx = node_idx as usize;
                let distance = ((positions[(node_idx, 0)] - constraint.params[0]).powi(2)
                    + (positions[(node_idx, 1)] - constraint.params[1]).powi(2)
                    + (positions[(node_idx, 2)] - constraint.params[2]).powi(2))
                .sqrt();

                
                return Ok((1.0 / (1.0 + distance / 10.0)).max(0.0).min(1.0));
            }
        }
        Ok(0.0)
    }

    
    fn score_separation(
        &self,
        positions: &DMatrix<f32>,
        constraint: &Constraint,
    ) -> Result<f32, Box<dyn std::error::Error>> {
        if constraint.node_indices.len() >= 2 && !constraint.params.is_empty() {
            let i = constraint.node_indices[0] as usize;
            let j = constraint.node_indices[1] as usize;
            let min_distance = constraint.params[0];

            if i < positions.nrows() && j < positions.nrows() {
                let current_distance = self.euclidean_distance(positions, i, j);
                return Ok(if current_distance >= min_distance {
                    1.0
                } else {
                    current_distance / min_distance
                });
            }
        }
        Ok(0.0)
    }

    
    fn score_alignment_horizontal(
        &self,
        positions: &DMatrix<f32>,
        constraint: &Constraint,
    ) -> Result<f32, Box<dyn std::error::Error>> {
        if !constraint.params.is_empty() {
            let target_y = constraint.params[0];
            let mut total_deviation = 0.0;
            let mut count = 0;

            for &node_idx in &constraint.node_indices {
                if node_idx < positions.nrows() as u32 {
                    let node_idx = node_idx as usize;
                    total_deviation += (positions[(node_idx, 1)] - target_y).abs();
                    count += 1;
                }
            }

            if count > 0 {
                let avg_deviation = total_deviation / count as f32;
                return Ok((1.0 / (1.0 + avg_deviation / 10.0)).max(0.0).min(1.0));
            }
        }
        Ok(0.0)
    }

    
    fn score_clustering(
        &self,
        positions: &DMatrix<f32>,
        constraint: &Constraint,
    ) -> Result<f32, Box<dyn std::error::Error>> {
        if constraint.node_indices.len() > 1 {
            
            let mut total_distance = 0.0;
            let mut count = 0;

            for i in 0..constraint.node_indices.len() {
                for j in i + 1..constraint.node_indices.len() {
                    let node_i = constraint.node_indices[i] as usize;
                    let node_j = constraint.node_indices[j] as usize;

                    if node_i < positions.nrows() && node_j < positions.nrows() {
                        total_distance += self.euclidean_distance(positions, node_i, node_j);
                        count += 1;
                    }
                }
            }

            if count > 0 {
                let avg_distance = total_distance / count as f32;
                
                return Ok((1.0 / (1.0 + avg_distance / 50.0)).max(0.0).min(1.0));
            }
        }
        Ok(0.0)
    }

    
    pub fn get_iteration_history(&self) -> &[f32] {
        &self.iteration_history
    }

    
    pub fn clear_cache(&mut self) {
        self.cached_distance_matrix = None;
        self.cached_weight_matrix = None;
        self.iteration_history.clear();
        trace!("Cleared stress majorization cache");
    }

    
    pub fn update_config(&mut self, config: StressMajorizationConfig) {
        self.config = config;
        info!("Updated stress majorization configuration");
    }
}

impl Default for StressMajorizationSolver {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::models::{edge::Edge, graph::GraphData, node::Node};
    use crate::utils::socket_flow_messages::BinaryNodeData;

    fn create_test_graph() -> GraphData {
        let mut graph = GraphData {
            nodes: vec![
                Node::new_with_id("test1".to_string(), Some(1)),
                Node::new_with_id("test2".to_string(), Some(2)),
                Node::new_with_id("test3".to_string(), Some(3)),
            ],
            edges: vec![Edge::new(1, 2, 1.0), Edge::new(2, 3, 1.0)],
            metadata: crate::models::metadata::MetadataStore::new(),
            id_to_metadata: std::collections::HashMap::new(),
        };

        
        graph.nodes[0].data.x = 0.0;
        graph.nodes[0].data.y = 0.0;
        graph.nodes[0].data.z = 0.0;

        graph.nodes[1].data.x = 100.0;
        graph.nodes[1].data.y = 0.0;
        graph.nodes[1].data.z = 0.0;

        graph.nodes[2].data.x = 50.0;
        graph.nodes[2].data.y = 100.0;
        graph.nodes[2].data.z = 0.0;

        graph
    }

    #[test]
    fn test_solver_creation() {
        let solver = StressMajorizationSolver::new();
        assert_eq!(solver.config.max_iterations, 1000);
        assert!(solver.config.tolerance > 0.0);
    }

    #[test]
    fn test_distance_matrix_computation() {
        let mut solver = StressMajorizationSolver::new();
        let graph = create_test_graph();

        solver.compute_distance_matrix(&graph).unwrap();
        assert!(solver.cached_distance_matrix.is_some());

        let distance_matrix = solver.cached_distance_matrix.as_ref().expect("Expected value to be present");
        assert_eq!(distance_matrix.nrows(), 3);
        assert_eq!(distance_matrix.ncols(), 3);

        
        for i in 0..3 {
            assert_eq!(distance_matrix[(i, i)], 0.0);
        }
    }

    #[test]
    fn test_position_extraction_and_application() {
        let solver = StressMajorizationSolver::new();
        let mut graph = create_test_graph();

        let positions = solver.extract_positions(&graph);
        assert_eq!(positions.nrows(), 3);
        assert_eq!(positions.ncols(), 3);
        assert_eq!(positions[(0, 0)], 0.0);
        assert_eq!(positions[(1, 0)], 100.0);

        
        let mut new_positions = positions.clone();
        new_positions[(0, 0)] = 50.0;

        solver.apply_positions(&mut graph, &new_positions).unwrap();
        assert_eq!(graph.nodes[0].data.x, 50.0);
    }

    #[test]
    fn test_constraint_score_computation() {
        let solver = StressMajorizationSolver::new();
        let graph = create_test_graph();
        let mut constraint_set = ConstraintSet::default();

        
        constraint_set.add(Constraint::separation(1, 2, 50.0));

        let scores = solver
            .compute_constraint_scores(&graph, &constraint_set)
            .unwrap();
        assert!(scores.contains_key(&ConstraintKind::Separation));

        let sep_score = scores[&ConstraintKind::Separation];
        assert!(sep_score >= 0.0 && sep_score <= 1.0);
    }
}

--------------------------------------------------------------------------------
FILE: src/physics/ontology_constraints.rs
PURPOSE: OWL axiom to physics constraint translation
--------------------------------------------------------------------------------
//! Ontology constraints translator for converting OWL axioms into physics constraints
//!
//! This module provides a bridge between semantic ontology reasoning and physics-based
//! graph layout optimization. It converts OWL axioms and logical inferences into
//! constraint forces that can be applied to knowledge graph nodes in 3D space.
//!
//! ## Core Concepts
//!
//! - **Axiom Translation**: Converts logical axioms (DisjointClasses, SubClassOf, etc.)
//!   into specific physics constraints with appropriate force parameters
//! - **Inference Integration**: Applies reasoning results as dynamic constraints
//!   that adapt as the ontology evolves
//! - **Constraint Grouping**: Organizes ontology-derived constraints into logical
//!   categories for efficient processing and debugging
//!
//! ## Translation Mappings
//!
//! | OWL Axiom           | Physics Constraint      | Effect                    |
//! |---------------------|-------------------------|---------------------------|
//! | DisjointClasses(A,B)| Separation force        | Push A and B instances apart |
//! | SubClassOf(A,B)     | Hierarchical alignment  | Group A instances near B    |
//! | InverseOf(P,Q)      | Bidirectional edges     | Symmetric relationship forces|
//! | SameAs(a,b)         | Co-location/merge       | Pull a and b together       |
//! | FunctionalProperty  | Cardinality boundaries  | Limit connections per node  |
//!
//! ## Usage
//!
//! ```rust
//! use crate::physics::ontology_constraints::OntologyConstraintTranslator;
//! use crate::models::constraints::ConstraintSet;
//!
//! let translator = OntologyConstraintTranslator::new();
//!
//! 
//! let constraints = translator.axioms_to_constraints(&axioms, &nodes)?;
//!
//! 
//! let constraint_set = translator.apply_ontology_constraints(&graph, &reasoning_report)?;
//! ```

use log::{debug, info, trace, warn};
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};

use crate::models::{
    constraints::{Constraint, ConstraintKind, ConstraintSet},
    graph::GraphData,
    node::Node,
};

///
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum OWLAxiomType {
    
    DisjointClasses,
    
    SubClassOf,
    
    EquivalentClasses,
    
    SameAs,
    
    DifferentFrom,
    
    InverseOf,
    
    FunctionalProperty,
    
    InverseFunctionalProperty,
    
    TransitiveProperty,
    
    SymmetricProperty,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OWLAxiom {
    pub axiom_type: OWLAxiomType,
    pub subject: String,
    pub object: Option<String>,
    pub property: Option<String>,
    pub confidence: f32, 
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OntologyInference {
    pub inferred_axiom: OWLAxiom,
    pub premise_axioms: Vec<String>, 
    pub reasoning_confidence: f32,
    pub is_derived: bool,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OntologyConstraintConfig {
    
    pub disjoint_separation_strength: f32,
    
    pub hierarchy_alignment_strength: f32,
    
    pub sameas_colocation_strength: f32,
    
    pub cardinality_boundary_strength: f32,
    
    pub max_separation_distance: f32,
    
    pub min_colocation_distance: f32,
    
    pub enable_constraint_caching: bool,
    
    pub cache_invalidation_enabled: bool,
}

impl Default for OntologyConstraintConfig {
    fn default() -> Self {
        Self {
            disjoint_separation_strength: 0.8,
            hierarchy_alignment_strength: 0.6,
            sameas_colocation_strength: 0.9,
            cardinality_boundary_strength: 0.7,
            max_separation_distance: 50.0,
            min_colocation_distance: 2.0,
            enable_constraint_caching: true,
            cache_invalidation_enabled: true,
        }
    }
}

///
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum OntologyConstraintGroup {
    
    OntologySeparation,
    
    OntologyAlignment,
    
    OntologyBoundaries,
    
    OntologyIdentity,
}

///
#[derive(Debug, Clone)]
struct ConstraintCacheEntry {
    constraints: Vec<Constraint>,
    axiom_hash: u64,
    last_updated: std::time::Instant,
}

///
pub struct OntologyConstraintTranslator {
    config: OntologyConstraintConfig,
    constraint_cache: HashMap<String, ConstraintCacheEntry>,
    node_type_cache: HashMap<u32, HashSet<String>>, 
}

impl OntologyConstraintTranslator {
    
    pub fn new() -> Self {
        Self::with_config(OntologyConstraintConfig::default())
    }

    
    pub fn with_config(config: OntologyConstraintConfig) -> Self {
        Self {
            config,
            constraint_cache: HashMap::new(),
            node_type_cache: HashMap::new(),
        }
    }

    
    pub fn axioms_to_constraints(
        &mut self,
        axioms: &[OWLAxiom],
        nodes: &[Node],
    ) -> Result<Vec<Constraint>, Box<dyn std::error::Error>> {
        info!(
            "Converting {} OWL axioms to physics constraints",
            axioms.len()
        );

        
        let node_by_id: HashMap<String, &Node> = nodes
            .iter()
            .map(|node| (node.metadata_id.clone(), node))
            .collect();

        self.update_node_type_cache(nodes);

        let mut constraints = Vec::new();

        for axiom in axioms {
            trace!("Processing axiom: {:?}", axiom);

            match self.translate_single_axiom(axiom, &node_by_id) {
                Ok(mut axiom_constraints) => {
                    constraints.append(&mut axiom_constraints);
                }
                Err(e) => {
                    warn!("Failed to translate axiom {:?}: {}", axiom, e);
                }
            }
        }

        info!(
            "Generated {} constraints from {} axioms",
            constraints.len(),
            axioms.len()
        );
        Ok(constraints)
    }

    
    pub fn inferences_to_constraints(
        &mut self,
        inferences: &[OntologyInference],
        graph: &GraphData,
    ) -> Result<Vec<Constraint>, Box<dyn std::error::Error>> {
        info!(
            "Converting {} ontology inferences to constraints",
            inferences.len()
        );

        let mut constraints = Vec::new();

        
        let mut inference_constraints = Vec::new();

        for inference in inferences {
            let mut single_inference_constraints =
                self.axioms_to_constraints(&[inference.inferred_axiom.clone()], &graph.nodes)?;

            
            for constraint in &mut single_inference_constraints {
                constraint.weight *= inference.reasoning_confidence;
            }

            inference_constraints.push(single_inference_constraints);
        }

        for mut batch in inference_constraints {
            constraints.append(&mut batch);
        }

        info!(
            "Generated {} constraints from {} inferences",
            constraints.len(),
            inferences.len()
        );
        Ok(constraints)
    }

    
    pub fn apply_ontology_constraints(
        &mut self,
        graph: &GraphData,
        reasoning_report: &OntologyReasoningReport,
    ) -> Result<ConstraintSet, Box<dyn std::error::Error>> {
        info!(
            "Applying ontology constraints to graph with {} nodes",
            graph.nodes.len()
        );

        let mut all_constraints = Vec::new();

        
        let mut axiom_constraints =
            self.axioms_to_constraints(&reasoning_report.axioms, &graph.nodes)?;
        all_constraints.append(&mut axiom_constraints);

        
        let mut inference_constraints =
            self.inferences_to_constraints(&reasoning_report.inferences, graph)?;
        all_constraints.append(&mut inference_constraints);

        
        let mut constraint_set = ConstraintSet {
            constraints: all_constraints,
            groups: std::collections::HashMap::new(),
        };

        
        let grouped_constraints = self.group_constraints_by_category(&constraint_set.constraints);
        for (group, indices) in grouped_constraints {
            let group_name = match group {
                OntologyConstraintGroup::OntologySeparation => "ontology_separation",
                OntologyConstraintGroup::OntologyAlignment => "ontology_alignment",
                OntologyConstraintGroup::OntologyBoundaries => "ontology_boundaries",
                OntologyConstraintGroup::OntologyIdentity => "ontology_identity",
            };
            constraint_set
                .groups
                .insert(group_name.to_string(), indices);
        }

        info!(
            "Applied {} total ontology constraints",
            constraint_set.constraints.len()
        );
        Ok(constraint_set)
    }

    
    pub fn get_constraint_strength(&self, axiom_type: &OWLAxiomType) -> f32 {
        match axiom_type {
            OWLAxiomType::DisjointClasses | OWLAxiomType::DifferentFrom => {
                self.config.disjoint_separation_strength
            }
            OWLAxiomType::SubClassOf => self.config.hierarchy_alignment_strength,
            OWLAxiomType::SameAs | OWLAxiomType::EquivalentClasses => {
                self.config.sameas_colocation_strength
            }
            OWLAxiomType::FunctionalProperty | OWLAxiomType::InverseFunctionalProperty => {
                self.config.cardinality_boundary_strength
            }
            _ => 0.5, 
        }
    }

    
    pub fn clear_cache(&mut self) {
        self.constraint_cache.clear();
        self.node_type_cache.clear();
        debug!("Cleared ontology constraint cache");
    }

    
    pub fn get_cache_stats(&self) -> OntologyConstraintCacheStats {
        let total_entries = self.constraint_cache.len();
        let total_cached_constraints: usize = self
            .constraint_cache
            .values()
            .map(|entry| entry.constraints.len())
            .sum();

        OntologyConstraintCacheStats {
            total_cache_entries: total_entries,
            total_cached_constraints,
            node_type_entries: self.node_type_cache.len(),
        }
    }

    

    
    pub fn update_node_type_cache(&mut self, nodes: &[Node]) {
        for node in nodes {
            let mut types = HashSet::new();

            
            if let Some(node_type) = &node.node_type {
                types.insert(node_type.clone());
            }

            if let Some(group) = &node.group {
                types.insert(group.clone());
            }

            
            for (key, value) in &node.metadata {
                if key.contains("type") || key.contains("class") || key.contains("category") {
                    types.insert(value.clone());
                }
            }

            self.node_type_cache.insert(node.id, types);
        }
    }

    
    fn translate_single_axiom(
        &self,
        axiom: &OWLAxiom,
        node_lookup: &HashMap<String, &Node>,
    ) -> Result<Vec<Constraint>, Box<dyn std::error::Error>> {
        let base_strength = self.get_constraint_strength(&axiom.axiom_type) * axiom.confidence;

        match axiom.axiom_type {
            OWLAxiomType::DisjointClasses => {
                self.create_disjoint_class_constraints(axiom, node_lookup, base_strength)
            }
            OWLAxiomType::SubClassOf => {
                self.create_subclass_constraints(axiom, node_lookup, base_strength)
            }
            OWLAxiomType::SameAs => {
                self.create_sameas_constraints(axiom, node_lookup, base_strength)
            }
            OWLAxiomType::DifferentFrom => {
                self.create_different_from_constraints(axiom, node_lookup, base_strength)
            }
            OWLAxiomType::FunctionalProperty => {
                self.create_functional_property_constraints(axiom, node_lookup, base_strength)
            }
            OWLAxiomType::InverseOf => {
                self.create_inverse_property_constraints(axiom, node_lookup, base_strength)
            }
            _ => {
                debug!("Axiom type {:?} not yet supported", axiom.axiom_type);
                Ok(Vec::new())
            }
        }
    }

    
    fn create_disjoint_class_constraints(
        &self,
        axiom: &OWLAxiom,
        node_lookup: &HashMap<String, &Node>,
        strength: f32,
    ) -> Result<Vec<Constraint>, Box<dyn std::error::Error>> {
        let object = axiom
            .object
            .as_ref()
            .ok_or("DisjointClasses axiom missing object")?;

        
        let class_a_nodes = self.find_nodes_of_type(&axiom.subject, node_lookup);
        let class_b_nodes = self.find_nodes_of_type(object, node_lookup);

        let mut constraints = Vec::new();

        
        for &node_a in &class_a_nodes {
            for &node_b in &class_b_nodes {
                constraints.push(Constraint {
                    kind: ConstraintKind::Separation,
                    node_indices: vec![node_a.id, node_b.id],
                    params: vec![self.config.max_separation_distance * 0.7], 
                    weight: strength,
                    active: true,
                });
            }
        }

        debug!(
            "Created {} disjoint class constraints between {} and {} nodes",
            constraints.len(),
            class_a_nodes.len(),
            class_b_nodes.len()
        );

        Ok(constraints)
    }

    
    fn create_subclass_constraints(
        &self,
        axiom: &OWLAxiom,
        node_lookup: &HashMap<String, &Node>,
        strength: f32,
    ) -> Result<Vec<Constraint>, Box<dyn std::error::Error>> {
        let superclass = axiom
            .object
            .as_ref()
            .ok_or("SubClassOf axiom missing superclass")?;

        let subclass_nodes = self.find_nodes_of_type(&axiom.subject, node_lookup);
        let superclass_nodes = self.find_nodes_of_type(superclass, node_lookup);

        let mut constraints = Vec::new();

        if !superclass_nodes.is_empty() {
            
            let superclass_centroid = self.calculate_node_centroid(&superclass_nodes);

            
            for &node in &subclass_nodes {
                constraints.push(Constraint {
                    kind: ConstraintKind::Clustering,
                    node_indices: vec![node.id],
                    params: vec![
                        0.0, 
                        strength,
                        superclass_centroid.0, 
                        superclass_centroid.1, 
                        superclass_centroid.2, 
                    ],
                    weight: strength,
                    active: true,
                });
            }
        }

        debug!(
            "Created {} subclass alignment constraints",
            constraints.len()
        );
        Ok(constraints)
    }

    
    fn create_sameas_constraints(
        &self,
        axiom: &OWLAxiom,
        node_lookup: &HashMap<String, &Node>,
        strength: f32,
    ) -> Result<Vec<Constraint>, Box<dyn std::error::Error>> {
        let object = axiom.object.as_ref().ok_or("SameAs axiom missing object")?;

        if let (Some(&node_a), Some(&node_b)) =
            (node_lookup.get(&axiom.subject), node_lookup.get(object))
        {
            
            Ok(vec![Constraint {
                kind: ConstraintKind::Clustering,
                node_indices: vec![node_a.id, node_b.id],
                params: vec![
                    0.0, 
                    strength,
                    self.config.min_colocation_distance, 
                ],
                weight: strength,
                active: true,
            }])
        } else {
            debug!("SameAs constraint: one or both nodes not found");
            Ok(Vec::new())
        }
    }

    
    fn create_different_from_constraints(
        &self,
        axiom: &OWLAxiom,
        node_lookup: &HashMap<String, &Node>,
        _strength: f32,
    ) -> Result<Vec<Constraint>, Box<dyn std::error::Error>> {
        let object = axiom
            .object
            .as_ref()
            .ok_or("DifferentFrom axiom missing object")?;

        if let (Some(&node_a), Some(&node_b)) =
            (node_lookup.get(&axiom.subject), node_lookup.get(object))
        {
            Ok(vec![Constraint::separation(
                node_a.id,
                node_b.id,
                self.config.max_separation_distance * 0.5,
            )])
        } else {
            debug!("DifferentFrom constraint: one or both nodes not found");
            Ok(Vec::new())
        }
    }

    
    fn create_functional_property_constraints(
        &self,
        axiom: &OWLAxiom,
        node_lookup: &HashMap<String, &Node>,
        strength: f32,
    ) -> Result<Vec<Constraint>, Box<dyn std::error::Error>> {
        
        
        

        let property_name = &axiom.subject;
        let affected_nodes: Vec<&Node> = node_lookup
            .values()
            .filter(|node| {
                
                node.metadata.contains_key(property_name)
                    || node.metadata.values().any(|v| v.contains(property_name))
            })
            .cloned()
            .collect();

        let mut constraints = Vec::new();

        
        for &node in &affected_nodes {
            constraints.push(Constraint {
                kind: ConstraintKind::Boundary,
                node_indices: vec![node.id],
                params: vec![
                    -20.0, 20.0, 
                    -20.0, 20.0, 
                    -10.0, 10.0, 
                ],
                weight: strength,
                active: true,
            });
        }

        debug!(
            "Created {} functional property boundary constraints",
            constraints.len()
        );
        Ok(constraints)
    }

    
    fn create_inverse_property_constraints(
        &self,
        _axiom: &OWLAxiom,
        _node_lookup: &HashMap<String, &Node>,
        _strength: f32,
    ) -> Result<Vec<Constraint>, Box<dyn std::error::Error>> {
        
        
        

        debug!("Inverse property constraints not fully implemented yet");
        Ok(Vec::new())
    }

    
    fn find_nodes_of_type<'a>(
        &self,
        type_name: &str,
        node_lookup: &HashMap<String, &'a Node>,
    ) -> Vec<&'a Node> {
        node_lookup
            .values()
            .filter(|node| {
                
                node.node_type.as_ref().map_or(false, |t| t == type_name)
                    || node.group.as_ref().map_or(false, |g| g == type_name)
                    || node.metadata.values().any(|v| v == type_name)
                    || node.metadata_id.contains(type_name)
            })
            .cloned()
            .collect()
    }

    
    fn calculate_node_centroid(&self, nodes: &[&Node]) -> (f32, f32, f32) {
        if nodes.is_empty() {
            return (0.0, 0.0, 0.0);
        }

        let count = nodes.len() as f32;
        let sum = nodes.iter().fold((0.0, 0.0, 0.0), |acc, node| {
            let pos = node.data.position();
            (acc.0 + pos.x, acc.1 + pos.y, acc.2 + pos.z)
        });

        (sum.0 / count, sum.1 / count, sum.2 / count)
    }

    
    fn group_constraints_by_category(
        &self,
        constraints: &[Constraint],
    ) -> HashMap<OntologyConstraintGroup, Vec<usize>> {
        let mut groups: HashMap<OntologyConstraintGroup, Vec<usize>> = HashMap::new();

        for (idx, constraint) in constraints.iter().enumerate() {
            let group = match constraint.kind {
                ConstraintKind::Separation => OntologyConstraintGroup::OntologySeparation,
                ConstraintKind::Clustering => OntologyConstraintGroup::OntologyAlignment,
                ConstraintKind::Boundary => OntologyConstraintGroup::OntologyBoundaries,
                ConstraintKind::FixedPosition => OntologyConstraintGroup::OntologyIdentity,
                _ => OntologyConstraintGroup::OntologyAlignment, 
            };

            groups.entry(group).or_insert_with(Vec::new).push(idx);
        }

        debug!(
            "Grouped constraints: {:?}",
            groups.iter().map(|(k, v)| (k, v.len())).collect::<Vec<_>>()
        );

        groups
    }
}

impl Default for OntologyConstraintTranslator {
    fn default() -> Self {
        Self::new()
    }
}

///
#[derive(Debug, Serialize, Deserialize)]
pub struct OntologyReasoningReport {
    pub axioms: Vec<OWLAxiom>,
    pub inferences: Vec<OntologyInference>,
    pub consistency_checks: Vec<ConsistencyCheck>,
    pub reasoning_time_ms: u64,
}

///
#[derive(Debug, Serialize, Deserialize)]
pub struct ConsistencyCheck {
    pub is_consistent: bool,
    pub conflicting_axioms: Vec<String>,
    pub suggested_resolution: Option<String>,
}

///
#[derive(Debug, Serialize, Deserialize)]
pub struct OntologyConstraintCacheStats {
    pub total_cache_entries: usize,
    pub total_cached_constraints: usize,
    pub node_type_entries: usize,
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::models::node::Node;
    use crate::types::vec3::Vec3Data;
    use crate::utils::socket_flow_messages::BinaryNodeData;

    fn create_test_node(id: u32, metadata_id: String, node_type: Option<String>) -> Node {
        Node {
            id,
            metadata_id,
            label: format!("Test Node {}", id),
            data: BinaryNodeData {
                node_id: id,
                x: 0.0,
                y: 0.0,
                z: 0.0,
                vx: 0.0,
                vy: 0.0,
                vz: 0.0,
            },
            x: Some(0.0),
            y: Some(0.0),
            z: Some(0.0),
            vx: Some(0.0),
            vy: Some(0.0),
            vz: Some(0.0),
            mass: Some(1.0),
            owl_class_iri: None,
            metadata: HashMap::new(),
            file_size: 0,
            node_type,
            size: None,
            color: None,
            weight: None,
            group: None,
            user_data: None,
        }
    }

    #[test]
    fn test_disjoint_classes_translation() {
        let mut translator = OntologyConstraintTranslator::new();

        let nodes = vec![
            create_test_node(1, "animal1".to_string(), Some("Animal".to_string())),
            create_test_node(2, "plant1".to_string(), Some("Plant".to_string())),
            create_test_node(3, "animal2".to_string(), Some("Animal".to_string())),
        ];

        let axiom = OWLAxiom {
            axiom_type: OWLAxiomType::DisjointClasses,
            subject: "Animal".to_string(),
            object: Some("Plant".to_string()),
            property: None,
            confidence: 1.0,
        };

        let constraints = translator.axioms_to_constraints(&[axiom], &nodes).unwrap();

        
        assert!(!constraints.is_empty());
        assert!(constraints
            .iter()
            .all(|c| c.kind == ConstraintKind::Separation));
    }

    #[test]
    fn test_sameas_translation() {
        let mut translator = OntologyConstraintTranslator::new();

        let nodes = vec![
            create_test_node(1, "person1".to_string(), None),
            create_test_node(2, "person2".to_string(), None),
        ];

        let axiom = OWLAxiom {
            axiom_type: OWLAxiomType::SameAs,
            subject: "person1".to_string(),
            object: Some("person2".to_string()),
            property: None,
            confidence: 1.0,
        };

        let constraints = translator.axioms_to_constraints(&[axiom], &nodes).unwrap();

        
        assert_eq!(constraints.len(), 1);
        assert_eq!(constraints[0].kind, ConstraintKind::Clustering);
    }

    #[test]
    fn test_constraint_strength_calculation() {
        let translator = OntologyConstraintTranslator::new();

        let disjoint_strength = translator.get_constraint_strength(&OWLAxiomType::DisjointClasses);
        let sameas_strength = translator.get_constraint_strength(&OWLAxiomType::SameAs);

        assert!(disjoint_strength > 0.0);
        assert!(sameas_strength > 0.0);
        assert!(sameas_strength > disjoint_strength); 
    }

    #[test]
    fn test_cache_functionality() {
        let mut translator = OntologyConstraintTranslator::new();

        let nodes = vec![create_test_node(1, "test".to_string(), None)];
        translator.update_node_type_cache(&nodes);

        let stats = translator.get_cache_stats();
        assert_eq!(stats.node_type_entries, 1);

        translator.clear_cache();
        let stats_after_clear = translator.get_cache_stats();
        assert_eq!(stats_after_clear.node_type_entries, 0);
    }
}

================================================================================
                    SECTION 9: GPU COMPUTE UTILITIES
================================================================================

--------------------------------------------------------------------------------
FILE: src/gpu/mod.rs
PURPOSE: GPU computation module exports
--------------------------------------------------------------------------------
//! GPU computation modules for visual analytics and high-performance graph processing
//!
//! All GPU modules now include comprehensive safety measures, bounds checking,
//! and error handling by default.

// Canonical GPU type definitions (AUTHORITATIVE)
pub mod types;

// Primary safe implementations (formerly safe_*)
pub mod semantic_forces;
pub mod streaming_pipeline;
pub mod visual_analytics;

// REMOVED: hybrid_sssp module - contained only stub implementations, archived to archive/legacy_code_2025_11_03/

// GPU conversion utilities
pub mod conversion_utils;

// Unified GPU memory management
pub mod memory_manager;
pub mod dynamic_buffer_manager; // Legacy - use memory_manager instead

// Canonical type exports (AUTHORITATIVE SOURCE)
pub use types::{BinaryNodeData, RenderData};

// Primary exports (safe by default)
pub use visual_analytics::{
    IsolationLayer, PerformanceMetrics, TSEdge, TSNode, Vec4, VisualAnalyticsBuilder,
    VisualAnalyticsEngine, VisualAnalyticsGPU, VisualAnalyticsParams,
};

pub use streaming_pipeline::{
    ClientConnection, ClientLOD, ClientStats, CompressedEdge, DeltaCompressor, FrameBuffer,
    PipelineStats, SimplifiedNode, StreamMessage, StreamingPipeline,
};

// REMOVED: Hybrid SSSP exports - module contained only stub implementations

// GPU conversion utilities exports
pub use conversion_utils::{
    allocate_gpu_buffer, calculate_buffer_size, calculate_memory_footprint,
    extract_position_3d, extract_position_vec4, from_gpu_buffer, get_element_count,
    gpu_buffer_to_nodes, gpu_to_positions, gpu_to_positions_4d, nodes_to_gpu_buffer,
    positions_4d_to_gpu, positions_to_gpu, to_gpu_buffer, validate_buffer_size,
    validate_buffer_stride, validate_render_data, ConversionError, GpuNode,
};

// Unified memory management exports (NEW - recommended)
pub use memory_manager::{
    BufferConfig, BufferStats, GpuBuffer, GpuMemoryManager, MemoryStats,
};

// Semantic forces exports
pub use semantic_forces::{
    AttributeSpringConfig, CollisionConfig, DAGConfig, SemanticConfig,
    SemanticForcesEngine, TypeClusterConfig,
    // Dynamic relationship buffer management (schema-code decoupling)
    DynamicForceConfigGPU, DynamicRelationshipBufferManager,
};

// Broadcast optimization module
pub mod broadcast_optimizer;
pub use broadcast_optimizer::{
    BroadcastConfig, BroadcastOptimizer, BroadcastPerformanceStats,
    CompressionStats, SpatialCuller,
};

// Network backpressure control module
pub mod backpressure;
pub use backpressure::{
    BackpressureConfig, BackpressureMetrics, NetworkBackpressure, TokenBucket,
};
--------------------------------------------------------------------------------
FILE: src/gpu/types.rs
PURPOSE: GPU data types (BinaryNodeData, RenderData)
--------------------------------------------------------------------------------
// src/gpu/types.rs
//! Canonical GPU Type Definitions
//!
//! This module contains the authoritative struct definitions for GPU operations.
//! All other modules should import from here to ensure consistency.

use serde::{Deserialize, Serialize};
use crate::utils::gpu_safety::GPUSafetyError;

// =============================================================================
// RenderData - CANONICAL DEFINITION
// =============================================================================

/// Canonical GPU render data structure used for streaming and visual analytics
///
/// This is the **authoritative** definition. Other modules must import this type.
///
/// # Layout
/// - `positions`: Vec<f32> with length = num_nodes * 4 (x, y, z, w components)
/// - `colors`: Vec<f32> with length = num_nodes * 4 (r, g, b, a components)
/// - `importance`: Vec<f32> with length = num_nodes (importance scores)
/// - `frame`: u32 frame number
///
/// # Used By
/// - src/gpu/streaming_pipeline.rs
/// - src/gpu/visual_analytics.rs
/// - src/gpu/conversion_utils.rs
///
/// # Validation
/// Use `validate()` before GPU operations to ensure data integrity.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RenderData {
    /// Node positions as [x, y, z, w] components (w typically 1.0)
    pub positions: Vec<f32>,

    /// Node colors as [r, g, b, a] components
    pub colors: Vec<f32>,

    /// Per-node importance scores (0.0 to 1.0)
    pub importance: Vec<f32>,

    /// Frame number for synchronization
    pub frame: u32,
}

impl RenderData {
    /// Create new validated RenderData
    pub fn new(
        positions: Vec<f32>,
        colors: Vec<f32>,
        importance: Vec<f32>,
        frame: u32,
    ) -> Result<Self, GPUSafetyError> {
        let data = Self {
            positions,
            colors,
            importance,
            frame,
        };
        data.validate()?;
        Ok(data)
    }

    /// Validate RenderData structure
    pub fn validate(&self) -> Result<(), GPUSafetyError> {
        use crate::gpu::conversion_utils::validate_render_data;

        validate_render_data(&self.positions, &self.colors, &self.importance)
            .map(|_node_count| ())
            .map_err(|e| GPUSafetyError::InvalidKernelParams {
                reason: format!("RenderData validation failed: {}", e),
            })?;

        // Additional validation: check for non-finite values
        for (i, &val) in self.positions.iter().enumerate() {
            if !val.is_finite() {
                return Err(GPUSafetyError::InvalidKernelParams {
                    reason: format!("Invalid position value at index {}: {}", i, val),
                });
            }
        }

        for (i, &val) in self.colors.iter().enumerate() {
            if !val.is_finite() {
                return Err(GPUSafetyError::InvalidKernelParams {
                    reason: format!("Invalid color value at index {}: {}", i, val),
                });
            }
        }

        for (i, &val) in self.importance.iter().enumerate() {
            if !val.is_finite() || val < 0.0 {
                return Err(GPUSafetyError::InvalidKernelParams {
                    reason: format!("Invalid importance value at index {}: {}", i, val),
                });
            }
        }

        Ok(())
    }

    /// Get the number of nodes represented
    pub fn node_count(&self) -> usize {
        self.positions.len() / 4
    }

    /// Create empty RenderData for a given number of nodes
    pub fn empty(num_nodes: usize) -> Self {
        Self {
            positions: vec![0.0; num_nodes * 4],
            colors: vec![0.0; num_nodes * 4],
            importance: vec![0.0; num_nodes],
            frame: 0,
        }
    }
}

// =============================================================================
// BinaryNodeData - CANONICAL DEFINITION
// =============================================================================

/// Canonical binary node data structure for network transmission and GPU operations
///
/// This replaces multiple duplicate definitions across the codebase.
///
/// # Layout (28 bytes)
/// - node_id: u32 (4 bytes)
/// - x, y, z: f32 (12 bytes)
/// - vx, vy, vz: f32 (12 bytes)
///
/// # Used By
/// - src/utils/socket_flow_messages.rs
/// - src/utils/binary_protocol.rs
/// - GPU streaming operations
///
/// # See Also
/// - BinaryNodeDataGPU for extended GPU-side data
#[repr(C)]
#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct BinaryNodeData {
    pub node_id: u32,
    pub x: f32,
    pub y: f32,
    pub z: f32,
    pub vx: f32,
    pub vy: f32,
    pub vz: f32,
}

impl BinaryNodeData {
    pub fn new(
        node_id: u32,
        position: [f32; 3],
        velocity: [f32; 3],
    ) -> Self {
        Self {
            node_id,
            x: position[0],
            y: position[1],
            z: position[2],
            vx: velocity[0],
            vy: velocity[1],
            vz: velocity[2],
        }
    }

    pub fn position(&self) -> [f32; 3] {
        [self.x, self.y, self.z]
    }

    pub fn velocity(&self) -> [f32; 3] {
        [self.vx, self.vy, self.vz]
    }

    pub fn validate(&self) -> Result<(), GPUSafetyError> {
        // Check for finite values
        let values = [self.x, self.y, self.z, self.vx, self.vy, self.vz];
        for (i, &val) in values.iter().enumerate() {
            if !val.is_finite() {
                return Err(GPUSafetyError::InvalidKernelParams {
                    reason: format!("BinaryNodeData: non-finite value at index {}: {}", i, val),
                });
            }
        }

        // Check for reasonable bounds (prevent overflow)
        const MAX_COORD: f32 = 1e6;
        if self.x.abs() > MAX_COORD || self.y.abs() > MAX_COORD || self.z.abs() > MAX_COORD {
            return Err(GPUSafetyError::InvalidKernelParams {
                reason: format!(
                    "BinaryNodeData: position coordinates exceed safe bounds: ({}, {}, {})",
                    self.x, self.y, self.z
                ),
            });
        }

        Ok(())
    }
}

// Ensure correct size at compile time
static_assertions::const_assert_eq!(std::mem::size_of::<BinaryNodeData>(), 28);

// =============================================================================
// Migration Helpers
// =============================================================================

/// Migration helper for code using old import paths
pub mod legacy {
    use super::*;

    /// Re-export for backwards compatibility with streaming_pipeline
    pub type StreamingPipelineRenderData = RenderData;

    /// Re-export for backwards compatibility with visual_analytics
    pub type VisualAnalyticsRenderData = RenderData;

    /// Re-export for backwards compatibility with socket messages
    pub type BinaryNodeDataClient = BinaryNodeData;
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_render_data_validation() {
        // Valid data
        let valid_data = RenderData {
            positions: vec![1.0f32; 40], // 10 nodes * 4
            colors: vec![0.5f32; 40],
            importance: vec![0.8f32; 10],
            frame: 1,
        };
        assert!(valid_data.validate().is_ok());

        // Invalid: positions not divisible by 4
        let invalid_data = RenderData {
            positions: vec![1.0f32; 39],
            colors: vec![0.5f32; 40],
            importance: vec![0.8f32; 10],
            frame: 1,
        };
        assert!(invalid_data.validate().is_err());

        // Invalid: mismatched node counts
        let mismatched_data = RenderData {
            positions: vec![1.0f32; 40],
            colors: vec![0.5f32; 40],
            importance: vec![0.8f32; 15], // Wrong count
            frame: 1,
        };
        assert!(mismatched_data.validate().is_err());

        // Invalid: NaN value
        let mut nan_data = RenderData {
            positions: vec![1.0f32; 40],
            colors: vec![0.5f32; 40],
            importance: vec![0.8f32; 10],
            frame: 1,
        };
        nan_data.positions[0] = f32::NAN;
        assert!(nan_data.validate().is_err());
    }

    #[test]
    fn test_binary_node_data_validation() {
        // Valid data
        let valid = BinaryNodeData::new(
            1,
            [10.0, 20.0, 30.0],
            [1.0, 2.0, 3.0],
        );
        assert!(valid.validate().is_ok());

        // Invalid: NaN
        let invalid = BinaryNodeData {
            node_id: 1,
            x: f32::NAN,
            y: 0.0,
            z: 0.0,
            vx: 0.0,
            vy: 0.0,
            vz: 0.0,
        };
        assert!(invalid.validate().is_err());

        // Invalid: extreme coordinates
        let extreme = BinaryNodeData {
            node_id: 1,
            x: 1e7,
            y: 0.0,
            z: 0.0,
            vx: 0.0,
            vy: 0.0,
            vz: 0.0,
        };
        assert!(extreme.validate().is_err());
    }

    #[test]
    fn test_render_data_node_count() {
        let data = RenderData::empty(100);
        assert_eq!(data.node_count(), 100);
        assert_eq!(data.positions.len(), 400);
        assert_eq!(data.colors.len(), 400);
        assert_eq!(data.importance.len(), 100);
    }
}

--------------------------------------------------------------------------------
FILE: src/gpu/memory_manager.rs
PURPOSE: Unified GPU memory management
--------------------------------------------------------------------------------
//! # Unified GPU Memory Manager
//!
//! This module consolidates three overlapping GPU memory management implementations:
//! 1. `src/utils/gpu_memory.rs` - Memory tracking and leak detection
//! 2. `src/gpu/dynamic_buffer_manager.rs` - Dynamic resizing and pool management
//! 3. `src/utils/unified_gpu_compute.rs` - Async transfers and double buffering
//!
//! ## Key Features
//!
//! - **Pool-based allocation** with configurable growth strategies
//! - **Automatic resizing** when capacity is exceeded
//! - **Memory leak detection** with named buffer tracking
//! - **Async transfers** with double buffering (2.8-4.4x speedup)
//! - **Performance metrics** for monitoring and optimization
//! - **Thread-safe** operations with minimal overhead
//!
//! ## Usage Example
//!
//! ```rust
//! use crate::gpu::memory_manager::{GpuMemoryManager, BufferConfig};
//!
//! // Create manager
//! let mut manager = GpuMemoryManager::new()?;
//!
//! // Allocate buffer with dynamic resizing
//! let config = BufferConfig::for_positions();
//! manager.allocate("positions", 1000, config)?;
//!
//! // Resize automatically when needed
//! manager.ensure_capacity("positions", 5000)?;
//!
//! // Async transfer to host
//! manager.start_async_download("positions")?;
//! // ... do other work ...
//! let data = manager.wait_for_download::<f32>("positions")?;
//!
//! // Check for memory leaks
//! let leaks = manager.check_leaks();
//! assert!(leaks.is_empty());
//! ```

use cust::error::CudaError;
use cust::event::{Event, EventFlags};
use cust::memory::{AsyncCopyDestination, CopyDestination, DeviceBuffer};
use cust::stream::{Stream, StreamFlags};
use log::{debug, error, info, warn};
use std::cell::Cell;
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use std::sync::atomic::{AtomicUsize, Ordering};
use std::time::Instant;

/// Configuration for buffer growth and size limits
#[derive(Debug, Clone)]
pub struct BufferConfig {
    /// Bytes per element (e.g., 12 for f32x3)
    pub bytes_per_element: usize,
    /// Growth multiplier when resizing (e.g., 1.5 = 50% growth)
    pub growth_factor: f32,
    /// Maximum buffer size in bytes
    pub max_size_bytes: usize,
    /// Minimum buffer size in bytes
    pub min_size_bytes: usize,
    /// Enable async transfer support
    pub enable_async: bool,
}

impl Default for BufferConfig {
    fn default() -> Self {
        Self {
            bytes_per_element: 4, // f32
            growth_factor: 1.5,
            max_size_bytes: 1024 * 1024 * 1024, // 1GB
            min_size_bytes: 4096,                // 4KB
            enable_async: false,
        }
    }
}

impl BufferConfig {
    /// Configuration for 3D position buffers (f32x3)
    pub fn for_positions() -> Self {
        Self {
            bytes_per_element: 12, // 3 * sizeof(f32)
            growth_factor: 1.3,
            max_size_bytes: 512 * 1024 * 1024,
            min_size_bytes: 4096,
            enable_async: true, // Enable async for frequent reads
        }
    }

    /// Configuration for 3D velocity buffers (f32x3)
    pub fn for_velocities() -> Self {
        Self {
            bytes_per_element: 12,
            growth_factor: 1.3,
            max_size_bytes: 512 * 1024 * 1024,
            min_size_bytes: 4096,
            enable_async: true,
        }
    }

    /// Configuration for edge data (larger growth for graphs)
    pub fn for_edges() -> Self {
        Self {
            bytes_per_element: 32, // Edge metadata
            growth_factor: 2.0,
            max_size_bytes: 2048 * 1024 * 1024,
            min_size_bytes: 8192,
            enable_async: false,
        }
    }

    /// Configuration for grid/spatial structures
    pub fn for_grid_cells() -> Self {
        Self {
            bytes_per_element: 8,
            growth_factor: 1.5,
            max_size_bytes: 256 * 1024 * 1024,
            min_size_bytes: 2048,
            enable_async: false,
        }
    }
}

/// GPU buffer with automatic resizing and async transfer support
pub struct GpuBuffer<T: cust_core::DeviceCopy> {
    /// Device buffer
    device_buffer: DeviceBuffer<T>,

    /// Buffer name for debugging
    name: String,

    /// Current capacity in elements
    capacity_elements: usize,

    /// Configuration
    config: BufferConfig,

    /// Allocation timestamp
    allocated_at: Instant,

    /// Last access timestamp (using Cell for interior mutability)
    last_accessed: Cell<Instant>,

    // Async transfer state (double buffering)
    host_buffer_a: Option<Vec<T>>,
    host_buffer_b: Option<Vec<T>>,
    current_host_buffer: bool, // true = A, false = B
    transfer_pending: bool,
    transfer_event: Option<Event>,
}

impl<T: cust_core::DeviceCopy + Clone + Default> GpuBuffer<T> {
    /// Create new GPU buffer with specified capacity
    fn new(name: String, capacity: usize, config: BufferConfig) -> Result<Self, CudaError> {
        let device_buffer = DeviceBuffer::from_slice(&vec![T::default(); capacity])?;

        // Initialize async buffers if enabled
        let (host_buffer_a, host_buffer_b) = if config.enable_async {
            (Some(vec![T::default(); capacity]), Some(vec![T::default(); capacity]))
        } else {
            (None, None)
        };

        Ok(Self {
            device_buffer,
            name,
            capacity_elements: capacity,
            config,
            allocated_at: Instant::now(),
            last_accessed: Cell::new(Instant::now()),
            host_buffer_a,
            host_buffer_b,
            current_host_buffer: true,
            transfer_pending: false,
            transfer_event: None,
        })
    }

    /// Get current capacity in elements
    pub fn capacity(&self) -> usize {
        self.capacity_elements
    }

    /// Get buffer size in bytes
    pub fn size_bytes(&self) -> usize {
        self.capacity_elements * std::mem::size_of::<T>()
    }

    /// Get device buffer reference
    pub fn device_buffer(&self) -> &DeviceBuffer<T> {
        self.last_accessed.set(Instant::now());
        &self.device_buffer
    }

    /// Get mutable device buffer reference
    pub fn device_buffer_mut(&mut self) -> &mut DeviceBuffer<T> {
        self.last_accessed.set(Instant::now());
        &mut self.device_buffer
    }

    /// Resize buffer to new capacity, preserving existing data
    fn resize(&mut self, new_capacity: usize) -> Result<(), CudaError> {
        if new_capacity == self.capacity_elements {
            return Ok(());
        }

        debug!(
            "Resizing buffer '{}' from {} to {} elements",
            self.name, self.capacity_elements, new_capacity
        );

        // Create new buffer
        let mut new_buffer = DeviceBuffer::from_slice(&vec![T::default(); new_capacity])?;

        // Copy old data
        let copy_count = self.capacity_elements.min(new_capacity);
        if copy_count > 0 {
            // Copy old data to host buffer first, then to new device buffer
            let mut temp_host = vec![T::default(); copy_count];
            self.device_buffer.copy_to(&mut temp_host)?;

            // Create stream for async copy from host to device
            let stream = Stream::new(StreamFlags::NON_BLOCKING, None)?;
            unsafe {
                new_buffer.async_copy_from(&temp_host, &stream)?;
            }
            stream.synchronize()?;
        }

        // Update state
        self.device_buffer = new_buffer;
        self.capacity_elements = new_capacity;

        // Resize host buffers for async transfers
        if self.config.enable_async {
            if let Some(ref mut buf_a) = self.host_buffer_a {
                buf_a.resize(new_capacity, T::default());
            }
            if let Some(ref mut buf_b) = self.host_buffer_b {
                buf_b.resize(new_capacity, T::default());
            }
        }

        Ok(())
    }

    /// Start async download to host (non-blocking)
    fn start_async_download(&mut self, stream: &Stream) -> Result<(), CudaError> {
        if !self.config.enable_async {
            error!("Async transfers not enabled for buffer '{}'", self.name);
            return Err(CudaError::InvalidValue);
        }

        // Select target host buffer (ping-pong)
        let target_buffer = if self.current_host_buffer {
            match self.host_buffer_a.as_mut() {
                Some(buf) => buf,
                None => {
                    error!("Host buffer A not initialized for async buffer '{}'", self.name);
                    return Err(CudaError::InvalidValue);
                }
            }
        } else {
            match self.host_buffer_b.as_mut() {
                Some(buf) => buf,
                None => {
                    error!("Host buffer B not initialized for async buffer '{}'", self.name);
                    return Err(CudaError::InvalidValue);
                }
            }
        };

        // Start async copy from device to host
        stream.synchronize()?; // Ensure previous operations complete
        unsafe {
            self.device_buffer.async_copy_to(target_buffer, stream)?;
        }

        // Record event for synchronization
        let event = Event::new(EventFlags::DEFAULT)?;
        event.record(stream)?;
        self.transfer_event = Some(event);
        self.transfer_pending = true;

        Ok(())
    }

    /// Wait for async download to complete and return data
    fn wait_for_download(&mut self) -> Result<Vec<T>, CudaError> {
        if !self.transfer_pending {
            error!("No async transfer pending for buffer '{}'", self.name);
            return Err(CudaError::InvalidValue);
        }

        // Wait for transfer event
        if let Some(ref event) = self.transfer_event {
            event.synchronize()?;
        }

        // Get completed buffer
        let result_buffer = if self.current_host_buffer {
            match self.host_buffer_a.as_ref() {
                Some(buf) => buf,
                None => {
                    error!("Host buffer A not initialized for buffer '{}'", self.name);
                    return Err(CudaError::InvalidValue);
                }
            }
        } else {
            match self.host_buffer_b.as_ref() {
                Some(buf) => buf,
                None => {
                    error!("Host buffer B not initialized for buffer '{}'", self.name);
                    return Err(CudaError::InvalidValue);
                }
            }
        };

        // Flip buffers for next transfer
        self.current_host_buffer = !self.current_host_buffer;
        self.transfer_pending = false;

        Ok(result_buffer.clone())
    }

    /// Get statistics for this buffer
    pub fn stats(&self) -> BufferStats {
        BufferStats {
            name: self.name.clone(),
            capacity_bytes: self.size_bytes(),
            allocated_bytes: self.size_bytes(),
            utilization: 1.0, // Assume fully utilized
            age_seconds: self.allocated_at.elapsed().as_secs_f32(),
            last_access_seconds: self.last_accessed.get().elapsed().as_secs_f32(),
        }
    }
}

/// Buffer statistics for monitoring
#[derive(Debug, Clone)]
pub struct BufferStats {
    pub name: String,
    pub capacity_bytes: usize,
    pub allocated_bytes: usize,
    pub utilization: f32,
    pub age_seconds: f32,
    pub last_access_seconds: f32,
}

/// Memory allocation tracking entry
#[derive(Debug, Clone)]
struct AllocationEntry {
    size_bytes: usize,
    timestamp: Instant,
}

/// Unified GPU Memory Manager
pub struct GpuMemoryManager {
    /// Named buffer storage (using Box for type erasure)
    buffers: HashMap<String, Box<dyn std::any::Any>>,

    /// Buffer configurations
    configs: HashMap<String, BufferConfig>,

    /// Allocation tracking for leak detection
    allocations: Arc<Mutex<HashMap<String, AllocationEntry>>>,

    /// Total allocated memory (atomic for thread-safety)
    total_allocated: Arc<AtomicUsize>,

    /// Peak memory usage
    peak_allocated: Arc<AtomicUsize>,

    /// Maximum total memory limit
    max_total_memory: usize,

    /// Dedicated stream for async transfers
    transfer_stream: Stream,

    /// Performance metrics
    allocation_count: AtomicUsize,
    resize_count: AtomicUsize,
    async_transfer_count: AtomicUsize,
}

impl GpuMemoryManager {
    /// Create new memory manager with default settings
    pub fn new() -> Result<Self, CudaError> {
        Self::with_limit(6 * 1024 * 1024 * 1024) // 6GB default limit
    }

    /// Create memory manager with custom memory limit
    pub fn with_limit(max_memory_bytes: usize) -> Result<Self, CudaError> {
        Ok(Self {
            buffers: HashMap::new(),
            configs: HashMap::new(),
            allocations: Arc::new(Mutex::new(HashMap::new())),
            total_allocated: Arc::new(AtomicUsize::new(0)),
            peak_allocated: Arc::new(AtomicUsize::new(0)),
            max_total_memory: max_memory_bytes,
            transfer_stream: Stream::new(StreamFlags::NON_BLOCKING, None)?,
            allocation_count: AtomicUsize::new(0),
            resize_count: AtomicUsize::new(0),
            async_transfer_count: AtomicUsize::new(0),
        })
    }

    /// Allocate a new GPU buffer
    pub fn allocate<T: cust_core::DeviceCopy + Clone + Default + 'static>(
        &mut self,
        name: &str,
        capacity_elements: usize,
        config: BufferConfig,
    ) -> Result<(), CudaError> {
        // Check if buffer already exists
        if self.buffers.contains_key(name) {
            warn!("Buffer '{}' already exists, skipping allocation", name);
            return Ok(());
        }

        let size_bytes = capacity_elements * std::mem::size_of::<T>();

        // Check memory limit
        let current = self.total_allocated.load(Ordering::Relaxed);
        if current + size_bytes > self.max_total_memory {
            return Err(CudaError::InvalidMemoryAllocation);
        }

        // Create buffer
        let buffer = GpuBuffer::<T>::new(name.to_string(), capacity_elements, config.clone())?;

        // Track allocation
        self.track_allocation(name, size_bytes);

        // Store buffer
        self.buffers.insert(name.to_string(), Box::new(buffer));
        self.configs.insert(name.to_string(), config);

        self.allocation_count.fetch_add(1, Ordering::Relaxed);

        info!(
            "Allocated GPU buffer '{}': {} elements ({} bytes)",
            name, capacity_elements, size_bytes
        );

        Ok(())
    }

    /// Ensure buffer has sufficient capacity, resizing if needed
    pub fn ensure_capacity<T: cust_core::DeviceCopy + Clone + Default + 'static>(
        &mut self,
        name: &str,
        required_elements: usize,
    ) -> Result<(), CudaError> {
        // Get buffer
        let buffer_any = self.buffers.get_mut(name).ok_or(CudaError::NotFound)?;
        let buffer = buffer_any
            .downcast_mut::<GpuBuffer<T>>()
            .ok_or(CudaError::InvalidValue)?;

        // Check if resize needed
        if buffer.capacity() >= required_elements {
            return Ok(());
        }

        // Calculate new capacity
        let config = self.configs.get(name).ok_or(CudaError::NotFound)?;
        let current_capacity = buffer.capacity();
        let mut new_capacity = if current_capacity == 0 {
            (config.min_size_bytes / std::mem::size_of::<T>()).max(required_elements)
        } else {
            let grown = (current_capacity as f32 * config.growth_factor) as usize;
            grown.max(required_elements)
        };

        // Enforce maximum size
        let max_elements = config.max_size_bytes / std::mem::size_of::<T>();
        new_capacity = new_capacity.min(max_elements);

        if required_elements > new_capacity {
            return Err(CudaError::InvalidMemoryAllocation);
        }

        // Track old size for memory accounting
        let old_size = buffer.size_bytes();

        // Resize
        buffer.resize(new_capacity)?;

        // Update allocation tracking
        let new_size = buffer.size_bytes();
        let delta = new_size as i64 - old_size as i64;

        if delta > 0 {
            self.track_allocation(&format!("{}_resize", name), delta as usize);
        } else if delta < 0 {
            self.track_deallocation(&format!("{}_resize", name), (-delta) as usize);
        }

        self.resize_count.fetch_add(1, Ordering::Relaxed);

        info!(
            "Resized buffer '{}' from {} to {} elements",
            name, current_capacity, new_capacity
        );

        Ok(())
    }

    /// Get device buffer reference
    pub fn get_buffer<T: cust_core::DeviceCopy + Clone + Default + 'static>(
        &self,
        name: &str,
    ) -> Result<&DeviceBuffer<T>, CudaError> {
        let buffer_any = self.buffers.get(name).ok_or(CudaError::NotFound)?;
        let buffer = buffer_any
            .downcast_ref::<GpuBuffer<T>>()
            .ok_or(CudaError::InvalidValue)?;
        Ok(buffer.device_buffer())
    }

    /// Get mutable device buffer reference
    pub fn get_buffer_mut<T: cust_core::DeviceCopy + Clone + Default + 'static>(
        &mut self,
        name: &str,
    ) -> Result<&mut DeviceBuffer<T>, CudaError> {
        let buffer_any = self.buffers.get_mut(name).ok_or(CudaError::NotFound)?;
        let buffer = buffer_any
            .downcast_mut::<GpuBuffer<T>>()
            .ok_or(CudaError::InvalidValue)?;
        Ok(buffer.device_buffer_mut())
    }

    /// Start async download (non-blocking)
    pub fn start_async_download<T: cust_core::DeviceCopy + Clone + Default + 'static>(
        &mut self,
        name: &str,
    ) -> Result<(), CudaError> {
        let buffer_any = self.buffers.get_mut(name).ok_or(CudaError::NotFound)?;
        let buffer = buffer_any
            .downcast_mut::<GpuBuffer<T>>()
            .ok_or(CudaError::InvalidValue)?;

        buffer.start_async_download(&self.transfer_stream)?;
        self.async_transfer_count.fetch_add(1, Ordering::Relaxed);

        Ok(())
    }

    /// Wait for async download to complete
    pub fn wait_for_download<T: cust_core::DeviceCopy + Clone + Default + 'static>(
        &mut self,
        name: &str,
    ) -> Result<Vec<T>, CudaError> {
        let buffer_any = self.buffers.get_mut(name).ok_or(CudaError::NotFound)?;
        let buffer = buffer_any
            .downcast_mut::<GpuBuffer<T>>()
            .ok_or(CudaError::InvalidValue)?;

        buffer.wait_for_download()
    }

    /// Free a buffer
    pub fn free(&mut self, name: &str) -> Result<(), CudaError> {
        if let Some(buffer_any) = self.buffers.remove(name) {
            // Type-erased, but Drop will handle cleanup
            self.configs.remove(name);
            self.track_deallocation(name, 0); // Size tracked in allocations map

            info!("Freed GPU buffer '{}'", name);
            Ok(())
        } else {
            Err(CudaError::NotFound)
        }
    }

    /// Get memory statistics
    pub fn stats(&self) -> MemoryStats {
        let buffer_stats: Vec<BufferStats> = vec![]; // Would need to iterate type-erased buffers

        MemoryStats {
            total_allocated_bytes: self.total_allocated.load(Ordering::Relaxed),
            peak_allocated_bytes: self.peak_allocated.load(Ordering::Relaxed),
            buffer_count: self.buffers.len(),
            allocation_count: self.allocation_count.load(Ordering::Relaxed),
            resize_count: self.resize_count.load(Ordering::Relaxed),
            async_transfer_count: self.async_transfer_count.load(Ordering::Relaxed),
            buffer_stats,
        }
    }

    /// Check for memory leaks
    pub fn check_leaks(&self) -> Vec<String> {
        match self.allocations.lock() {
            Ok(allocations) => {
                if allocations.is_empty() {
                    debug!("No GPU memory leaks detected");
                    return Vec::new();
                }

                let leaks: Vec<String> = allocations.keys().cloned().collect();
                error!(
                    "GPU memory leaks detected: {} buffers still allocated",
                    leaks.len()
                );
                for (name, entry) in allocations.iter() {
                    error!(
                        "  Leaked buffer '{}': {} bytes (age: {:.2}s)",
                        name,
                        entry.size_bytes,
                        entry.timestamp.elapsed().as_secs_f32()
                    );
                }
                leaks
            }
            Err(e) => {
                error!("Lock poisoned while checking for leaks: {} - Cannot determine leak status", e);
                Vec::new() // Return empty, cannot verify
            }
        }
    }

    // Internal tracking methods

    fn track_allocation(&self, name: &str, size_bytes: usize) {
        if let Ok(mut allocations) = self.allocations.lock() {
            allocations.insert(
                name.to_string(),
                AllocationEntry {
                    size_bytes,
                    timestamp: Instant::now(),
                },
            );

            let new_total = self.total_allocated.fetch_add(size_bytes, Ordering::Relaxed) + size_bytes;

            // Update peak
            let mut peak = self.peak_allocated.load(Ordering::Relaxed);
            while new_total > peak {
                match self.peak_allocated.compare_exchange_weak(
                    peak,
                    new_total,
                    Ordering::Relaxed,
                    Ordering::Relaxed,
                ) {
                    Ok(_) => break,
                    Err(current) => peak = current,
                }
            }

            debug!(
                "GPU Memory: +{} bytes for '{}', total: {} bytes",
                size_bytes, name, new_total
            );
        }
    }

    fn track_deallocation(&self, name: &str, size_bytes: usize) {
        if let Ok(mut allocations) = self.allocations.lock() {
            let actual_size = if size_bytes == 0 {
                allocations.get(name).map(|e| e.size_bytes).unwrap_or(0)
            } else {
                size_bytes
            };

            if allocations.remove(name).is_some() {
                let new_total = self.total_allocated.fetch_sub(actual_size, Ordering::Relaxed) - actual_size;
                debug!(
                    "GPU Memory: -{} bytes for '{}', total: {} bytes",
                    actual_size, name, new_total
                );
            } else {
                warn!("Attempted to free untracked GPU buffer: {}", name);
            }
        }
    }
}

/// Memory statistics
#[derive(Debug, Clone)]
pub struct MemoryStats {
    pub total_allocated_bytes: usize,
    pub peak_allocated_bytes: usize,
    pub buffer_count: usize,
    pub allocation_count: usize,
    pub resize_count: usize,
    pub async_transfer_count: usize,
    pub buffer_stats: Vec<BufferStats>,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_buffer_config_defaults() {
        let config = BufferConfig::default();
        assert_eq!(config.bytes_per_element, 4);
        assert_eq!(config.growth_factor, 1.5);
        assert_eq!(config.min_size_bytes, 4096);
    }

    #[test]
    fn test_buffer_config_presets() {
        let pos_config = BufferConfig::for_positions();
        assert_eq!(pos_config.bytes_per_element, 12);
        assert!(pos_config.enable_async);

        let edge_config = BufferConfig::for_edges();
        assert_eq!(edge_config.bytes_per_element, 32);
        assert!(!edge_config.enable_async);
    }

    #[test]
    #[ignore] // Requires CUDA device
    fn test_memory_manager_creation() {
        let manager = GpuMemoryManager::new();
        assert!(manager.is_ok());
    }

    #[test]
    #[ignore] // Requires CUDA device
    fn test_allocation_and_free() {
        let mut manager = GpuMemoryManager::new().unwrap();

        // Allocate buffer
        let config = BufferConfig::default();
        manager.allocate::<f32>("test_buffer", 1000, config).unwrap();

        // Verify allocation
        let stats = manager.stats();
        assert_eq!(stats.buffer_count, 1);

        // Free buffer
        manager.free("test_buffer").unwrap();

        // Verify freed
        let stats = manager.stats();
        assert_eq!(stats.buffer_count, 0);
    }

    #[test]
    #[ignore] // Requires CUDA device
    fn test_dynamic_resizing() {
        let mut manager = GpuMemoryManager::new().unwrap();

        let config = BufferConfig::for_positions();
        manager.allocate::<f32>("positions", 100, config).unwrap();

        // Resize to larger capacity
        manager.ensure_capacity::<f32>("positions", 500).unwrap();

        // Verify resize happened
        let stats = manager.stats();
        assert!(stats.resize_count > 0);
    }

    #[test]
    #[ignore] // Requires CUDA device
    fn test_memory_limit_enforcement() {
        let mut manager = GpuMemoryManager::with_limit(1024).unwrap(); // 1KB limit

        let config = BufferConfig::default();
        let result = manager.allocate::<f32>("huge_buffer", 1_000_000, config);

        // Should fail due to memory limit
        assert!(result.is_err());
    }

    #[test]
    #[ignore] // Requires CUDA device
    fn test_leak_detection() {
        let mut manager = GpuMemoryManager::new().unwrap();

        let config = BufferConfig::default();
        manager.allocate::<f32>("leaked_buffer", 100, config).unwrap();

        // Don't free the buffer
        let leaks = manager.check_leaks();
        assert_eq!(leaks.len(), 1);
        assert_eq!(leaks[0], "leaked_buffer");
    }

    #[test]
    #[ignore] // Requires CUDA device
    fn test_async_transfers() {
        let mut manager = GpuMemoryManager::new().unwrap();

        let mut config = BufferConfig::for_positions();
        config.enable_async = true;

        manager.allocate::<f32>("async_buffer", 100, config).unwrap();

        // Start async download
        manager.start_async_download::<f32>("async_buffer").unwrap();

        // Wait for completion
        let data = manager.wait_for_download::<f32>("async_buffer").unwrap();
        assert_eq!(data.len(), 100);
    }
}

--------------------------------------------------------------------------------
FILE: src/gpu/semantic_forces.rs
PURPOSE: Semantic forces engine for ontology-aware physics
--------------------------------------------------------------------------------
//! Semantic Forces Engine
//!
//! GPU-accelerated semantic physics forces for knowledge graph layout.
//! Implements DAG layout, type clustering, collision detection, and attribute-weighted springs.

use crate::models::graph::GraphData;
use crate::models::graph_types::{NodeType, EdgeType};
use crate::services::semantic_type_registry::{SemanticTypeRegistry, RelationshipForceConfig};
use log::{debug, info, warn};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;

// =============================================================================
// Configuration Structures
// =============================================================================

/// DAG layout configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DAGConfig {
    /// Vertical separation between hierarchy levels
    pub vertical_spacing: f32,
    /// Minimum horizontal separation within a level
    pub horizontal_spacing: f32,
    /// Strength of attraction to target level
    pub level_attraction: f32,
    /// Repulsion between nodes at same level
    pub sibling_repulsion: f32,
    /// Enable DAG layout forces
    pub enabled: bool,
}

impl Default for DAGConfig {
    fn default() -> Self {
        Self {
            vertical_spacing: 100.0,
            horizontal_spacing: 50.0,
            level_attraction: 0.5,
            sibling_repulsion: 0.3,
            enabled: false,
        }
    }
}

/// Type clustering configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TypeClusterConfig {
    /// Attraction between nodes of same type
    pub cluster_attraction: f32,
    /// Target radius for type clusters
    pub cluster_radius: f32,
    /// Repulsion between different type clusters
    pub inter_cluster_repulsion: f32,
    /// Enable type clustering
    pub enabled: bool,
}

impl Default for TypeClusterConfig {
    fn default() -> Self {
        Self {
            cluster_attraction: 0.4,
            cluster_radius: 150.0,
            inter_cluster_repulsion: 0.2,
            enabled: false,
        }
    }
}

/// Collision detection configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CollisionConfig {
    /// Minimum allowed distance between nodes
    pub min_distance: f32,
    /// Force strength when colliding
    pub collision_strength: f32,
    /// Default node radius
    pub node_radius: f32,
    /// Enable collision detection
    pub enabled: bool,
}

impl Default for CollisionConfig {
    fn default() -> Self {
        Self {
            min_distance: 5.0,
            collision_strength: 1.0,
            node_radius: 10.0,
            enabled: true,
        }
    }
}

/// Attribute-weighted spring configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AttributeSpringConfig {
    /// Base spring constant
    pub base_spring_k: f32,
    /// Multiplier for edge weight influence
    pub weight_multiplier: f32,
    /// Minimum rest length
    pub rest_length_min: f32,
    /// Maximum rest length
    pub rest_length_max: f32,
    /// Enable attribute-weighted springs
    pub enabled: bool,
}

impl Default for AttributeSpringConfig {
    fn default() -> Self {
        Self {
            base_spring_k: 0.01,
            weight_multiplier: 0.5,
            rest_length_min: 30.0,
            rest_length_max: 200.0,
            enabled: false,
        }
    }
}

/// Ontology relationship forces configuration
///
/// NOTE: The `enabled` field is used as a feature toggle for the CPU fallback.
/// Force parameters in this struct are legacy defaults - actual force configs
/// are now loaded dynamically from SemanticTypeRegistry at runtime.
/// GPU uses DynamicRelationshipBuffer for ontology-to-code decoupling.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OntologyRelationshipConfig {
    /// Legacy: "requires" strength (actual config from SemanticTypeRegistry)
    pub requires_strength: f32,
    /// Legacy: "requires" rest length
    pub requires_rest_length: f32,
    /// Legacy: "enables" strength
    pub enables_strength: f32,
    /// Legacy: "enables" rest length
    pub enables_rest_length: f32,
    /// Legacy: "has-part" strength
    pub has_part_strength: f32,
    /// Legacy: "has-part" orbit radius
    pub has_part_orbit_radius: f32,
    /// Legacy: "bridges-to" strength
    pub bridges_to_strength: f32,
    /// Legacy: "bridges-to" rest length
    pub bridges_to_rest_length: f32,
    /// Enable ontology relationship forces (feature toggle for CPU fallback)
    pub enabled: bool,
}

impl Default for OntologyRelationshipConfig {
    fn default() -> Self {
        Self {
            requires_strength: 0.7,
            requires_rest_length: 80.0,
            enables_strength: 0.4,
            enables_rest_length: 120.0,
            has_part_strength: 0.9,
            has_part_orbit_radius: 60.0,
            bridges_to_strength: 0.3,
            bridges_to_rest_length: 250.0,
            enabled: true,
        }
    }
}

/// Physicality-based clustering configuration (VirtualEntity, PhysicalEntity, ConceptualEntity)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PhysicalityClusterConfig {
    /// Attraction between nodes of same physicality
    pub cluster_attraction: f32,
    /// Target radius for physicality clusters
    pub cluster_radius: f32,
    /// Repulsion between different physicality types
    pub inter_physicality_repulsion: f32,
    /// Enable physicality clustering
    pub enabled: bool,
}

impl Default for PhysicalityClusterConfig {
    fn default() -> Self {
        Self {
            cluster_attraction: 0.5,
            cluster_radius: 180.0,
            inter_physicality_repulsion: 0.25,
            enabled: true,
        }
    }
}

/// Role-based clustering configuration (Process, Agent, Resource, Concept)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RoleClusterConfig {
    /// Attraction between nodes of same role
    pub cluster_attraction: f32,
    /// Target radius for role clusters
    pub cluster_radius: f32,
    /// Repulsion between different roles
    pub inter_role_repulsion: f32,
    /// Enable role clustering
    pub enabled: bool,
}

impl Default for RoleClusterConfig {
    fn default() -> Self {
        Self {
            cluster_attraction: 0.45,
            cluster_radius: 160.0,
            inter_role_repulsion: 0.2,
            enabled: true,
        }
    }
}

/// Maturity-based layout configuration (emerging  mature  declining)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MaturityLayoutConfig {
    /// Vertical spacing between maturity stages
    pub vertical_spacing: f32,
    /// Attraction to target maturity level
    pub level_attraction: f32,
    /// Maturity stage ordering: emerging=0, mature=1, declining=2
    pub stage_separation: f32,
    /// Enable maturity-based layout
    pub enabled: bool,
}

impl Default for MaturityLayoutConfig {
    fn default() -> Self {
        Self {
            vertical_spacing: 150.0,
            level_attraction: 0.4,
            stage_separation: 100.0,
            enabled: true,
        }
    }
}

/// Cross-domain link strength configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CrossDomainConfig {
    /// Base strength for cross-domain links
    pub base_strength: f32,
    /// Multiplier based on link count (more links = stronger forces)
    pub link_count_multiplier: f32,
    /// Maximum strength boost from link count
    pub max_strength_boost: f32,
    /// Rest length for cross-domain connections
    pub rest_length: f32,
    /// Enable cross-domain forces
    pub enabled: bool,
}

impl Default for CrossDomainConfig {
    fn default() -> Self {
        Self {
            base_strength: 0.3,
            link_count_multiplier: 0.1,
            max_strength_boost: 2.0,
            rest_length: 200.0,
            enabled: true,
        }
    }
}

/// Unified semantic configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SemanticConfig {
    pub dag: DAGConfig,
    pub type_cluster: TypeClusterConfig,
    pub collision: CollisionConfig,
    pub attribute_spring: AttributeSpringConfig,
    pub ontology_relationship: OntologyRelationshipConfig,
    pub physicality_cluster: PhysicalityClusterConfig,
    pub role_cluster: RoleClusterConfig,
    pub maturity_layout: MaturityLayoutConfig,
    pub cross_domain: CrossDomainConfig,
}

impl Default for SemanticConfig {
    fn default() -> Self {
        Self {
            dag: DAGConfig::default(),
            type_cluster: TypeClusterConfig::default(),
            collision: CollisionConfig::default(),
            attribute_spring: AttributeSpringConfig::default(),
            ontology_relationship: OntologyRelationshipConfig::default(),
            physicality_cluster: PhysicalityClusterConfig::default(),
            role_cluster: RoleClusterConfig::default(),
            maturity_layout: MaturityLayoutConfig::default(),
            cross_domain: CrossDomainConfig::default(),
        }
    }
}

// =============================================================================
// Semantic Forces Engine
// =============================================================================

/// GPU-accelerated semantic forces engine
pub struct SemanticForcesEngine {
    config: SemanticConfig,
    node_hierarchy_levels: Vec<i32>,
    node_types: Vec<i32>,
    type_centroids: HashMap<i32, (f32, f32, f32)>,
    edge_types: Vec<i32>,
    // New ontology-based node properties
    node_physicality: Vec<i32>, // 0=None, 1=VirtualEntity, 2=PhysicalEntity, 3=ConceptualEntity
    physicality_centroids: HashMap<i32, (f32, f32, f32)>,
    node_role: Vec<i32>, // 0=None, 1=Process, 2=Agent, 3=Resource, 4=Concept
    role_centroids: HashMap<i32, (f32, f32, f32)>,
    node_maturity: Vec<i32>, // 0=None, 1=emerging, 2=mature, 3=declining
    node_cross_domain_count: Vec<i32>, // Count of cross-domain links per node
    initialized: bool,
    /// Dynamic semantic type registry for ontology-code decoupling
    registry: Arc<SemanticTypeRegistry>,
}

impl SemanticForcesEngine {
    /// Create a new semantic forces engine
    pub fn new(config: SemanticConfig) -> Self {
        Self {
            config,
            node_hierarchy_levels: Vec::new(),
            node_types: Vec::new(),
            type_centroids: HashMap::new(),
            edge_types: Vec::new(),
            node_physicality: Vec::new(),
            physicality_centroids: HashMap::new(),
            node_role: Vec::new(),
            role_centroids: HashMap::new(),
            node_maturity: Vec::new(),
            node_cross_domain_count: Vec::new(),
            initialized: false,
            registry: Arc::new(SemanticTypeRegistry::new()),
        }
    }

    /// Create a new semantic forces engine with custom registry
    pub fn with_registry(config: SemanticConfig, registry: Arc<SemanticTypeRegistry>) -> Self {
        Self {
            config,
            node_hierarchy_levels: Vec::new(),
            node_types: Vec::new(),
            type_centroids: HashMap::new(),
            edge_types: Vec::new(),
            node_physicality: Vec::new(),
            physicality_centroids: HashMap::new(),
            node_role: Vec::new(),
            role_centroids: HashMap::new(),
            node_maturity: Vec::new(),
            node_cross_domain_count: Vec::new(),
            initialized: false,
            registry,
        }
    }

    /// Get a reference to the semantic type registry
    pub fn registry(&self) -> &SemanticTypeRegistry {
        &self.registry
    }

    /// Build GPU buffer of relationship force configurations
    pub fn build_relationship_gpu_buffer(&self) -> Vec<RelationshipForceConfig> {
        self.registry.build_gpu_buffer()
    }

    /// Initialize engine with graph data
    pub fn initialize(&mut self, graph: &GraphData) -> Result<(), String> {
        info!("Initializing SemanticForcesEngine with {} nodes, {} edges",
              graph.nodes.len(), graph.edges.len());

        // Extract node types
        self.node_types = graph.nodes.iter()
            .map(|node| self.node_type_to_int(&node.node_type))
            .collect();

        // Extract ontology-based properties
        self.node_physicality = graph.nodes.iter()
            .map(|node| self.extract_physicality(node))
            .collect();

        self.node_role = graph.nodes.iter()
            .map(|node| self.extract_role(node))
            .collect();

        self.node_maturity = graph.nodes.iter()
            .map(|node| self.extract_maturity(node))
            .collect();

        // Count cross-domain links per node
        self.node_cross_domain_count = self.calculate_cross_domain_counts(graph);

        // Extract edge types
        self.edge_types = graph.edges.iter()
            .map(|edge| self.edge_type_to_int(&edge.edge_type))
            .collect();

        // Calculate hierarchy levels if DAG is enabled
        if self.config.dag.enabled {
            self.calculate_hierarchy_levels(graph)?;
        }

        // Calculate type centroids if type clustering is enabled
        if self.config.type_cluster.enabled {
            self.calculate_type_centroids(graph)?;
        }

        // Calculate physicality centroids if physicality clustering is enabled
        if self.config.physicality_cluster.enabled {
            self.calculate_physicality_centroids(graph)?;
        }

        // Calculate role centroids if role clustering is enabled
        if self.config.role_cluster.enabled {
            self.calculate_role_centroids(graph)?;
        }

        self.initialized = true;
        info!("SemanticForcesEngine initialized successfully");
        Ok(())
    }

    /// Update configuration
    pub fn update_config(&mut self, config: SemanticConfig) {
        self.config = config;
        debug!("Semantic forces configuration updated");
    }

    /// Get current configuration
    pub fn config(&self) -> &SemanticConfig {
        &self.config
    }

    /// Check if engine is initialized
    pub fn is_initialized(&self) -> bool {
        self.initialized
    }

    /// Get node hierarchy levels
    pub fn hierarchy_levels(&self) -> &[i32] {
        &self.node_hierarchy_levels
    }

    /// Get node types
    pub fn node_types(&self) -> &[i32] {
        &self.node_types
    }

    /// Get type centroids
    pub fn type_centroids(&self) -> &HashMap<i32, (f32, f32, f32)> {
        &self.type_centroids
    }

    // Private helper methods

    fn node_type_to_int(&self, node_type: &Option<String>) -> i32 {
        match node_type.as_deref() {
            None | Some("generic") => 0,
            Some("person") => 1,
            Some("organization") => 2,
            Some("project") => 3,
            Some("task") => 4,
            Some("concept") => 5,
            Some("class") => 6,
            Some("individual") => 7,
            Some(_) => 8, // Custom types
        }
    }

    /// Convert edge type to integer using dynamic registry lookup
    /// Decouples ontology from CUDA compilation - new types are registered at runtime
    fn edge_type_to_int(&self, edge_type: &Option<String>) -> i32 {
        self.registry.edge_type_to_int(edge_type)
    }

    /// Get force configuration for an edge type
    fn get_edge_force_config(&self, edge_type_id: i32) -> Option<RelationshipForceConfig> {
        self.registry.get_config(edge_type_id as u32)
    }

    /// Extract physicality classification from node metadata
    fn extract_physicality(&self, node: &crate::models::node::Node) -> i32 {
        // Check owl:physicality metadata
        if let Some(physicality) = node.metadata.get("owl:physicality")
            .or_else(|| node.metadata.get("physicality"))
        {
            return match physicality.as_str() {
                "VirtualEntity" => 1,
                "PhysicalEntity" => 2,
                "ConceptualEntity" => 3,
                _ => 0,
            };
        }
        0 // None
    }

    /// Extract role classification from node metadata
    fn extract_role(&self, node: &crate::models::node::Node) -> i32 {
        // Check owl:role metadata
        if let Some(role) = node.metadata.get("owl:role")
            .or_else(|| node.metadata.get("role"))
        {
            return match role.as_str() {
                "Process" => 1,
                "Agent" => 2,
                "Resource" => 3,
                "Concept" => 4,
                _ => 0,
            };
        }
        0 // None
    }

    /// Extract maturity stage from node metadata
    fn extract_maturity(&self, node: &crate::models::node::Node) -> i32 {
        // Check maturity metadata
        if let Some(maturity) = node.metadata.get("maturity") {
            return match maturity.as_str() {
                "emerging" => 1,
                "mature" => 2,
                "declining" => 3,
                _ => 0,
            };
        }
        0 // None
    }

    /// Calculate cross-domain link counts for each node
    fn calculate_cross_domain_counts(&self, graph: &GraphData) -> Vec<i32> {
        let mut counts = vec![0; graph.nodes.len()];

        // Build node ID to index map
        let node_id_to_idx: HashMap<u32, usize> = graph.nodes.iter()
            .enumerate()
            .map(|(idx, node)| (node.id, idx))
            .collect();

        // Count cross-domain links in metadata
        for (idx, node) in graph.nodes.iter().enumerate() {
            if let Some(links) = node.metadata.get("cross-domain-links") {
                // Count comma-separated links
                counts[idx] = links.split(',').filter(|s| !s.trim().is_empty()).count() as i32;
            }
        }

        // Also count edges with type "bridges-to"
        for edge in &graph.edges {
            if edge.edge_type.as_deref() == Some("bridges-to") {
                if let Some(&src_idx) = node_id_to_idx.get(&edge.source) {
                    counts[src_idx] += 1;
                }
                if let Some(&tgt_idx) = node_id_to_idx.get(&edge.target) {
                    counts[tgt_idx] += 1;
                }
            }
        }

        counts
    }

    fn calculate_hierarchy_levels(&mut self, graph: &GraphData) -> Result<(), String> {
        debug!("Calculating hierarchy levels for {} nodes", graph.nodes.len());

        // Initialize all levels to -1 (not in DAG)
        self.node_hierarchy_levels = vec![-1; graph.nodes.len()];

        // Build adjacency list for hierarchy edges
        let mut children: HashMap<u32, Vec<u32>> = HashMap::new();
        let mut has_parent: HashMap<u32, bool> = HashMap::new();

        for edge in &graph.edges {
            if edge.edge_type.as_deref() == Some("hierarchy") {
                children.entry(edge.source).or_insert_with(Vec::new).push(edge.target);
                has_parent.insert(edge.target, true);
            }
        }

        // Find root nodes (nodes without parents)
        let mut roots = Vec::new();
        for (i, node) in graph.nodes.iter().enumerate() {
            if !has_parent.contains_key(&node.id) {
                // Check if this node has any hierarchy children
                if children.contains_key(&node.id) {
                    roots.push(i);
                    self.node_hierarchy_levels[i] = 0;
                }
            }
        }

        debug!("Found {} root nodes for DAG layout", roots.len());

        // BFS to assign levels
        let mut queue = roots.clone();
        let mut processed = 0;

        while !queue.is_empty() && processed < graph.nodes.len() * 2 {
            let mut next_queue = Vec::new();

            for node_idx in &queue {
                let node_id = graph.nodes[*node_idx].id;
                let current_level = self.node_hierarchy_levels[*node_idx];

                if let Some(child_ids) = children.get(&node_id) {
                    for child_id in child_ids {
                        // Find child index
                        if let Some(child_idx) = graph.nodes.iter().position(|n| n.id == *child_id) {
                            let new_level = current_level + 1;
                            if self.node_hierarchy_levels[child_idx] < new_level {
                                self.node_hierarchy_levels[child_idx] = new_level;
                                next_queue.push(child_idx);
                            }
                        }
                    }
                }
            }

            queue = next_queue;
            processed += 1;
        }

        let nodes_in_dag = self.node_hierarchy_levels.iter().filter(|&&l| l >= 0).count();
        info!("Hierarchy levels calculated: {} nodes in DAG", nodes_in_dag);

        Ok(())
    }

    fn calculate_type_centroids(&mut self, graph: &GraphData) -> Result<(), String> {
        debug!("Calculating type centroids");

        // Group nodes by type
        let mut type_positions: HashMap<i32, Vec<(f32, f32, f32)>> = HashMap::new();

        for (i, node) in graph.nodes.iter().enumerate() {
            let node_type = self.node_types[i];
            let pos = (
                node.data.x,
                node.data.y,
                node.data.z,
            );
            type_positions.entry(node_type).or_insert_with(Vec::new).push(pos);
        }

        // Calculate centroids
        self.type_centroids.clear();
        for (node_type, positions) in type_positions {
            if !positions.is_empty() {
                let sum: (f32, f32, f32) = positions.iter()
                    .fold((0.0, 0.0, 0.0), |acc, &pos| {
                        (acc.0 + pos.0, acc.1 + pos.1, acc.2 + pos.2)
                    });
                let count = positions.len() as f32;
                let centroid = (sum.0 / count, sum.1 / count, sum.2 / count);
                self.type_centroids.insert(node_type, centroid);
            }
        }

        info!("Calculated centroids for {} node types", self.type_centroids.len());
        Ok(())
    }

    fn calculate_physicality_centroids(&mut self, graph: &GraphData) -> Result<(), String> {
        debug!("Calculating physicality centroids");

        // Group nodes by physicality
        let mut physicality_positions: HashMap<i32, Vec<(f32, f32, f32)>> = HashMap::new();

        for (i, node) in graph.nodes.iter().enumerate() {
            let physicality = self.node_physicality[i];
            if physicality > 0 {
                let pos = (node.data.x, node.data.y, node.data.z);
                physicality_positions.entry(physicality).or_insert_with(Vec::new).push(pos);
            }
        }

        // Calculate centroids
        self.physicality_centroids.clear();
        for (physicality, positions) in physicality_positions {
            if !positions.is_empty() {
                let sum: (f32, f32, f32) = positions.iter()
                    .fold((0.0, 0.0, 0.0), |acc, &pos| {
                        (acc.0 + pos.0, acc.1 + pos.1, acc.2 + pos.2)
                    });
                let count = positions.len() as f32;
                let centroid = (sum.0 / count, sum.1 / count, sum.2 / count);
                self.physicality_centroids.insert(physicality, centroid);
            }
        }

        info!("Calculated centroids for {} physicality types", self.physicality_centroids.len());
        Ok(())
    }

    fn calculate_role_centroids(&mut self, graph: &GraphData) -> Result<(), String> {
        debug!("Calculating role centroids");

        // Group nodes by role
        let mut role_positions: HashMap<i32, Vec<(f32, f32, f32)>> = HashMap::new();

        for (i, node) in graph.nodes.iter().enumerate() {
            let role = self.node_role[i];
            if role > 0 {
                let pos = (node.data.x, node.data.y, node.data.z);
                role_positions.entry(role).or_insert_with(Vec::new).push(pos);
            }
        }

        // Calculate centroids
        self.role_centroids.clear();
        for (role, positions) in role_positions {
            if !positions.is_empty() {
                let sum: (f32, f32, f32) = positions.iter()
                    .fold((0.0, 0.0, 0.0), |acc, &pos| {
                        (acc.0 + pos.0, acc.1 + pos.1, acc.2 + pos.2)
                    });
                let count = positions.len() as f32;
                let centroid = (sum.0 / count, sum.1 / count, sum.2 / count);
                self.role_centroids.insert(role, centroid);
            }
        }

        info!("Calculated centroids for {} role types", self.role_centroids.len());
        Ok(())
    }

    /// Apply semantic forces to graph (CPU fallback implementation)
    /// In production, this would call CUDA kernels
    pub fn apply_semantic_forces(
        &self,
        graph: &mut GraphData,
    ) -> Result<(), String> {
        if !self.initialized {
            return Err("Engine not initialized".to_string());
        }

        // CPU implementation as fallback
        // In production, this would delegate to CUDA kernels

        // Apply DAG forces
        if self.config.dag.enabled {
            self.apply_dag_forces_cpu(graph);
        }

        // Apply type clustering forces
        if self.config.type_cluster.enabled {
            self.apply_type_cluster_forces_cpu(graph);
        }

        // Apply collision forces
        if self.config.collision.enabled {
            self.apply_collision_forces_cpu(graph);
        }

        // Apply attribute-weighted spring forces
        if self.config.attribute_spring.enabled {
            self.apply_attribute_spring_forces_cpu(graph);
        }

        // Apply ontology relationship forces
        if self.config.ontology_relationship.enabled {
            self.apply_ontology_relationship_forces_cpu(graph);
        }

        // Apply physicality clustering forces
        if self.config.physicality_cluster.enabled {
            self.apply_physicality_cluster_forces_cpu(graph);
        }

        // Apply role clustering forces
        if self.config.role_cluster.enabled {
            self.apply_role_cluster_forces_cpu(graph);
        }

        // Apply maturity layout forces
        if self.config.maturity_layout.enabled {
            self.apply_maturity_layout_forces_cpu(graph);
        }

        // Apply cross-domain forces
        if self.config.cross_domain.enabled {
            self.apply_cross_domain_forces_cpu(graph);
        }

        Ok(())
    }

    // CPU fallback implementations (simplified)

    fn apply_dag_forces_cpu(&self, graph: &mut GraphData) {
        // Simplified CPU implementation
        // Real implementation would use CUDA kernel
        for (i, node) in graph.nodes.iter_mut().enumerate() {
            let level = self.node_hierarchy_levels[i];
            if level >= 0 {
                let target_y = level as f32 * self.config.dag.vertical_spacing;
                let dy = target_y - node.data.y;
                node.data.vy += dy * self.config.dag.level_attraction * 0.01;
            }
        }
    }

    fn apply_type_cluster_forces_cpu(&self, graph: &mut GraphData) {
        // Simplified CPU implementation
        for (i, node) in graph.nodes.iter_mut().enumerate() {
            let node_type = self.node_types[i];
            if let Some(&centroid) = self.type_centroids.get(&node_type) {
                let dx = centroid.0 - node.data.x;
                let dy = centroid.1 - node.data.y;
                let dz = centroid.2 - node.data.z;
                let dist = (dx * dx + dy * dy + dz * dz).sqrt();

                if dist > self.config.type_cluster.cluster_radius {
                    let force = self.config.type_cluster.cluster_attraction * 0.01;
                    node.data.vx += dx * force;
                    node.data.vy += dy * force;
                    node.data.vz += dz * force;
                }
            }
        }
    }

    fn apply_collision_forces_cpu(&self, graph: &mut GraphData) {
        // Simplified CPU implementation
        let node_count = graph.nodes.len();
        for i in 0..node_count {
            for j in (i + 1)..node_count {
                let dx = graph.nodes[i].data.x - graph.nodes[j].data.x;
                let dy = graph.nodes[i].data.y - graph.nodes[j].data.y;
                let dz = graph.nodes[i].data.z - graph.nodes[j].data.z;
                let dist = (dx * dx + dy * dy + dz * dz).sqrt();

                let min_dist = 2.0 * self.config.collision.node_radius + self.config.collision.min_distance;
                if dist < min_dist && dist > 0.001 {
                    let force = self.config.collision.collision_strength * (min_dist - dist) / dist * 0.01;
                    graph.nodes[i].data.vx += dx * force;
                    graph.nodes[i].data.vy += dy * force;
                    graph.nodes[i].data.vz += dz * force;
                    graph.nodes[j].data.vx -= dx * force;
                    graph.nodes[j].data.vy -= dy * force;
                    graph.nodes[j].data.vz -= dz * force;
                }
            }
        }
    }

    fn apply_attribute_spring_forces_cpu(&self, graph: &mut GraphData) {
        // Simplified CPU implementation
        for edge in &graph.edges {
            // Find source and target nodes
            let src_idx = graph.nodes.iter().position(|n| n.id == edge.source);
            let tgt_idx = graph.nodes.iter().position(|n| n.id == edge.target);

            if let (Some(src_idx), Some(tgt_idx)) = (src_idx, tgt_idx) {
                let dx = graph.nodes[tgt_idx].data.x - graph.nodes[src_idx].data.x;
                let dy = graph.nodes[tgt_idx].data.y - graph.nodes[src_idx].data.y;
                let dz = graph.nodes[tgt_idx].data.z - graph.nodes[src_idx].data.z;
                let dist = (dx * dx + dy * dy + dz * dz).sqrt();

                if dist > 0.001 {
                    let weight = edge.weight;
                    let spring_k = self.config.attribute_spring.base_spring_k *
                                  (1.0 + weight * self.config.attribute_spring.weight_multiplier);

                    let rest_length = self.config.attribute_spring.rest_length_max -
                                    (weight * (self.config.attribute_spring.rest_length_max -
                                             self.config.attribute_spring.rest_length_min));

                    let displacement = dist - rest_length;
                    let force = spring_k * displacement / dist * 0.01;

                    // Would need mutable access to both nodes - skipping for CPU fallback
                    // Real implementation uses CUDA with atomic operations
                }
            }
        }
    }

    /// Apply ontology relationship forces using CPU fallback.
    /// Uses SemanticTypeRegistry for dynamic force configuration lookup.
    /// Gated by `config.ontology_relationship.enabled` feature toggle.
    fn apply_ontology_relationship_forces_cpu(&self, graph: &mut GraphData) {
        // Build node ID to index map
        let node_id_to_idx: HashMap<u32, usize> = graph.nodes.iter()
            .enumerate()
            .map(|(idx, node)| (node.id, idx))
            .collect();

        for (edge_idx, edge) in graph.edges.iter().enumerate() {
            let edge_type_id = self.edge_types[edge_idx];

            // Get force configuration from registry (dynamic lookup)
            let force_config = match self.get_edge_force_config(edge_type_id) {
                Some(config) => config,
                None => continue, // Skip edges with unknown types
            };

            // Skip generic type (id=0) unless it has meaningful config
            if edge_type_id == 0 && force_config.strength < 0.1 {
                continue;
            }

            let (src_idx, tgt_idx) = match (
                node_id_to_idx.get(&edge.source),
                node_id_to_idx.get(&edge.target)
            ) {
                (Some(&src), Some(&tgt)) => (src, tgt),
                _ => continue,
            };

            let dx = graph.nodes[tgt_idx].data.x - graph.nodes[src_idx].data.x;
            let dy = graph.nodes[tgt_idx].data.y - graph.nodes[src_idx].data.y;
            let dz = graph.nodes[tgt_idx].data.z - graph.nodes[src_idx].data.z;
            let dist = (dx * dx + dy * dy + dz * dz).sqrt();

            if dist < 0.001 {
                continue;
            }

            // Use registry-based force configuration
            let strength = force_config.strength;
            let rest_length = force_config.rest_length;
            let is_directional = force_config.is_directional;

            // Hooke's law: F = -k * (x - x0)
            let displacement = dist - rest_length;
            let force_mag = strength * displacement / dist * 0.01;

            if is_directional {
                // For directional edges: target attracts source (dependency pulls toward prerequisite)
                graph.nodes[src_idx].data.vx += dx * force_mag;
                graph.nodes[src_idx].data.vy += dy * force_mag;
                graph.nodes[src_idx].data.vz += dz * force_mag;
            } else {
                // Bidirectional spring force
                graph.nodes[src_idx].data.vx += dx * force_mag;
                graph.nodes[src_idx].data.vy += dy * force_mag;
                graph.nodes[src_idx].data.vz += dz * force_mag;
                graph.nodes[tgt_idx].data.vx -= dx * force_mag;
                graph.nodes[tgt_idx].data.vy -= dy * force_mag;
                graph.nodes[tgt_idx].data.vz -= dz * force_mag;
            }
        }
    }

    fn apply_physicality_cluster_forces_cpu(&self, graph: &mut GraphData) {
        let node_count = graph.nodes.len();
        let mut forces: Vec<(f32, f32, f32)> = vec![(0.0, 0.0, 0.0); node_count];

        for i in 0..node_count {
            let physicality = self.node_physicality[i];
            if physicality == 0 {
                continue;
            }

            let node_x = graph.nodes[i].data.x;
            let node_y = graph.nodes[i].data.y;
            let node_z = graph.nodes[i].data.z;

            if let Some(&centroid) = self.physicality_centroids.get(&physicality) {
                let dx = centroid.0 - node_x;
                let dy = centroid.1 - node_y;
                let dz = centroid.2 - node_z;
                let dist = (dx * dx + dy * dy + dz * dz).sqrt();

                if dist > self.config.physicality_cluster.cluster_radius {
                    let force = self.config.physicality_cluster.cluster_attraction * 0.01;
                    forces[i].0 += dx * force;
                    forces[i].1 += dy * force;
                    forces[i].2 += dz * force;
                }
            }

            // Repulsion from nodes of different physicality
            for j in 0..node_count {
                if i == j {
                    continue;
                }
                let other_physicality = self.node_physicality[j];
                if other_physicality == 0 || other_physicality == physicality {
                    continue;
                }

                let dx = node_x - graph.nodes[j].data.x;
                let dy = node_y - graph.nodes[j].data.y;
                let dz = node_z - graph.nodes[j].data.z;
                let dist = (dx * dx + dy * dy + dz * dz).sqrt();

                if dist < self.config.physicality_cluster.cluster_radius * 2.0 && dist > 0.001 {
                    let force = self.config.physicality_cluster.inter_physicality_repulsion / (dist * dist) * 0.01;
                    forces[i].0 += dx * force / dist;
                    forces[i].1 += dy * force / dist;
                    forces[i].2 += dz * force / dist;
                }
            }
        }

        for (i, node) in graph.nodes.iter_mut().enumerate() {
            node.data.vx += forces[i].0;
            node.data.vy += forces[i].1;
            node.data.vz += forces[i].2;
        }
    }

    fn apply_role_cluster_forces_cpu(&self, graph: &mut GraphData) {
        let node_count = graph.nodes.len();
        let mut forces: Vec<(f32, f32, f32)> = vec![(0.0, 0.0, 0.0); node_count];

        for i in 0..node_count {
            let role = self.node_role[i];
            if role == 0 {
                continue;
            }

            let node_x = graph.nodes[i].data.x;
            let node_y = graph.nodes[i].data.y;
            let node_z = graph.nodes[i].data.z;

            if let Some(&centroid) = self.role_centroids.get(&role) {
                let dx = centroid.0 - node_x;
                let dy = centroid.1 - node_y;
                let dz = centroid.2 - node_z;
                let dist = (dx * dx + dy * dy + dz * dz).sqrt();

                if dist > self.config.role_cluster.cluster_radius {
                    let force = self.config.role_cluster.cluster_attraction * 0.01;
                    forces[i].0 += dx * force;
                    forces[i].1 += dy * force;
                    forces[i].2 += dz * force;
                }
            }

            // Repulsion from nodes of different roles
            for j in 0..node_count {
                if i == j {
                    continue;
                }
                let other_role = self.node_role[j];
                if other_role == 0 || other_role == role {
                    continue;
                }

                let dx = node_x - graph.nodes[j].data.x;
                let dy = node_y - graph.nodes[j].data.y;
                let dz = node_z - graph.nodes[j].data.z;
                let dist = (dx * dx + dy * dy + dz * dz).sqrt();

                if dist < self.config.role_cluster.cluster_radius * 2.0 && dist > 0.001 {
                    let force = self.config.role_cluster.inter_role_repulsion / (dist * dist) * 0.01;
                    forces[i].0 += dx * force / dist;
                    forces[i].1 += dy * force / dist;
                    forces[i].2 += dz * force / dist;
                }
            }
        }

        for (i, node) in graph.nodes.iter_mut().enumerate() {
            node.data.vx += forces[i].0;
            node.data.vy += forces[i].1;
            node.data.vz += forces[i].2;
        }
    }

    fn apply_maturity_layout_forces_cpu(&self, graph: &mut GraphData) {
        for (i, node) in graph.nodes.iter_mut().enumerate() {
            let maturity = self.node_maturity[i];
            if maturity == 0 {
                continue;
            }

            // Calculate target Z position based on maturity stage
            // emerging=1  z=-stage_separation
            // mature=2    z=0
            // declining=3  z=+stage_separation
            let target_z = match maturity {
                1 => -self.config.maturity_layout.stage_separation,
                2 => 0.0,
                3 => self.config.maturity_layout.stage_separation,
                _ => 0.0,
            };

            let dz = target_z - node.data.z;
            node.data.vz += dz * self.config.maturity_layout.level_attraction * 0.01;
        }
    }

    fn apply_cross_domain_forces_cpu(&self, graph: &mut GraphData) {
        // Build node ID to index map
        let node_id_to_idx: HashMap<u32, usize> = graph.nodes.iter()
            .enumerate()
            .map(|(idx, node)| (node.id, idx))
            .collect();

        for (edge_idx, edge) in graph.edges.iter().enumerate() {
            let edge_type = self.edge_types[edge_idx];

            // Only process bridges-to edges
            if edge_type != 10 {
                continue;
            }

            let (src_idx, tgt_idx) = match (
                node_id_to_idx.get(&edge.source),
                node_id_to_idx.get(&edge.target)
            ) {
                (Some(&src), Some(&tgt)) => (src, tgt),
                _ => continue,
            };

            // Calculate strength based on cross-domain link count
            let src_count = self.node_cross_domain_count[src_idx] as f32;
            let tgt_count = self.node_cross_domain_count[tgt_idx] as f32;
            let avg_count = (src_count + tgt_count) / 2.0;

            let strength_boost = (1.0 + avg_count * self.config.cross_domain.link_count_multiplier)
                .min(self.config.cross_domain.max_strength_boost);
            let strength = self.config.cross_domain.base_strength * strength_boost;

            let dx = graph.nodes[tgt_idx].data.x - graph.nodes[src_idx].data.x;
            let dy = graph.nodes[tgt_idx].data.y - graph.nodes[src_idx].data.y;
            let dz = graph.nodes[tgt_idx].data.z - graph.nodes[src_idx].data.z;
            let dist = (dx * dx + dy * dy + dz * dz).sqrt();

            if dist < 0.001 {
                continue;
            }

            // Long-range spring force
            let displacement = dist - self.config.cross_domain.rest_length;
            let force_mag = strength * displacement / dist * 0.01;

            graph.nodes[src_idx].data.vx += dx * force_mag;
            graph.nodes[src_idx].data.vy += dy * force_mag;
            graph.nodes[src_idx].data.vz += dz * force_mag;
            graph.nodes[tgt_idx].data.vx -= dx * force_mag;
            graph.nodes[tgt_idx].data.vy -= dy * force_mag;
            graph.nodes[tgt_idx].data.vz -= dz * force_mag;
        }
    }
}

impl Default for SemanticForcesEngine {
    fn default() -> Self {
        Self::new(SemanticConfig::default())
    }
}

// =============================================================================
// Dynamic GPU Buffer Management for Schema-Code Decoupling
// =============================================================================

/// GPU-compatible dynamic force configuration
/// Matches DynamicForceConfig struct in semantic_forces.cu
#[repr(C)]
#[derive(Clone, Copy, Debug)]
pub struct DynamicForceConfigGPU {
    pub strength: f32,
    pub rest_length: f32,
    pub is_directional: i32,
    pub force_type: u32,
}

impl Default for DynamicForceConfigGPU {
    fn default() -> Self {
        Self {
            strength: 0.5,
            rest_length: 100.0,
            is_directional: 0,
            force_type: 0,
        }
    }
}

impl From<&RelationshipForceConfig> for DynamicForceConfigGPU {
    fn from(config: &RelationshipForceConfig) -> Self {
        Self {
            strength: config.strength,
            rest_length: config.rest_length,
            is_directional: if config.is_directional { 1 } else { 0 },
            force_type: config.force_type,
        }
    }
}

// FFI declarations for dynamic relationship buffer management
extern "C" {
    fn set_dynamic_relationship_buffer(
        configs: *const DynamicForceConfigGPU,
        num_types: i32,
        enabled: bool,
    ) -> i32;

    fn update_dynamic_relationship_config(
        type_id: i32,
        config: *const DynamicForceConfigGPU,
    ) -> i32;

    fn set_dynamic_relationships_enabled(enabled: bool) -> i32;

    fn get_dynamic_relationship_buffer_version() -> i32;

    fn get_max_relationship_types() -> i32;
}

/// Manager for dynamic relationship buffer on GPU
/// Enables hot-reload of ontology force configurations without CUDA recompilation
pub struct DynamicRelationshipBufferManager {
    /// Current buffer version (for change detection)
    current_version: i32,
    /// Whether dynamic mode is enabled
    enabled: bool,
    /// Last uploaded configuration count
    last_type_count: usize,
}

impl DynamicRelationshipBufferManager {
    /// Create a new buffer manager
    pub fn new() -> Self {
        Self {
            current_version: 0,
            enabled: false,
            last_type_count: 0,
        }
    }

    /// Upload relationship configurations from registry to GPU
    /// Call this whenever ontology changes to enable new relationship types
    pub fn upload_from_registry(&mut self, registry: &SemanticTypeRegistry) -> Result<(), String> {
        let buffer = registry.build_gpu_buffer();
        let gpu_buffer: Vec<DynamicForceConfigGPU> = buffer
            .iter()
            .map(|c| DynamicForceConfigGPU::from(c))
            .collect();

        self.upload_buffer(&gpu_buffer)
    }

    /// Upload a raw buffer of configurations to GPU
    pub fn upload_buffer(&mut self, configs: &[DynamicForceConfigGPU]) -> Result<(), String> {
        let max_types = unsafe { get_max_relationship_types() } as usize;

        if configs.len() > max_types {
            return Err(format!(
                "Too many relationship types: {} (max: {})",
                configs.len(),
                max_types
            ));
        }

        let result = unsafe {
            set_dynamic_relationship_buffer(
                if configs.is_empty() { std::ptr::null() } else { configs.as_ptr() },
                configs.len() as i32,
                true,
            )
        };

        if result != 0 {
            return Err(format!("CUDA error uploading relationship buffer: {}", result));
        }

        self.current_version = unsafe { get_dynamic_relationship_buffer_version() };
        self.enabled = true;
        self.last_type_count = configs.len();

        info!(
            "Uploaded {} relationship types to GPU (version {})",
            configs.len(),
            self.current_version
        );

        Ok(())
    }

    /// Hot-reload a single relationship type configuration
    /// More efficient than full buffer upload for single changes
    pub fn update_single_type(
        &mut self,
        type_id: u32,
        config: &DynamicForceConfigGPU,
    ) -> Result<(), String> {
        let max_types = unsafe { get_max_relationship_types() } as usize;

        if type_id as usize >= max_types {
            return Err(format!(
                "Type ID {} exceeds maximum ({})",
                type_id, max_types
            ));
        }

        let result = unsafe { update_dynamic_relationship_config(type_id as i32, config) };

        if result != 0 {
            return Err(format!("CUDA error updating relationship config: {}", result));
        }

        self.current_version = unsafe { get_dynamic_relationship_buffer_version() };

        debug!(
            "Hot-reloaded relationship type {} (version {})",
            type_id, self.current_version
        );

        Ok(())
    }

    /// Enable or disable dynamic relationship forces on GPU
    pub fn set_enabled(&mut self, enabled: bool) -> Result<(), String> {
        let result = unsafe { set_dynamic_relationships_enabled(enabled) };

        if result != 0 {
            return Err(format!("CUDA error setting dynamic relationships enabled: {}", result));
        }

        self.enabled = enabled;
        info!("Dynamic relationship forces {}", if enabled { "enabled" } else { "disabled" });

        Ok(())
    }

    /// Check if dynamic mode is enabled
    pub fn is_enabled(&self) -> bool {
        self.enabled
    }

    /// Get current buffer version
    pub fn version(&self) -> i32 {
        self.current_version
    }

    /// Get last uploaded type count
    pub fn type_count(&self) -> usize {
        self.last_type_count
    }

    /// Get maximum supported relationship types
    pub fn max_types(&self) -> usize {
        unsafe { get_max_relationship_types() as usize }
    }
}

impl Default for DynamicRelationshipBufferManager {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::models::node::Node;
    use crate::models::edge::Edge;

    #[test]
    fn test_semantic_config_defaults() {
        let config = SemanticConfig::default();
        assert!(!config.dag.enabled);
        assert!(!config.type_cluster.enabled);
        assert!(config.collision.enabled);
        assert!(!config.attribute_spring.enabled);
    }

    #[test]
    fn test_engine_creation() {
        let config = SemanticConfig::default();
        let engine = SemanticForcesEngine::new(config);
        assert!(!engine.is_initialized());
    }

    #[test]
    fn test_engine_initialization() {
        let mut engine = SemanticForcesEngine::new(SemanticConfig::default());

        let mut graph = GraphData::new();
        let mut node1 = Node::new("node1".to_string());
        node1.node_type = Some("person".to_string());
        graph.nodes.push(node1);

        let result = engine.initialize(&graph);
        assert!(result.is_ok());
        assert!(engine.is_initialized());
        assert_eq!(engine.node_types().len(), 1);
    }

    #[test]
    fn test_hierarchy_calculation() {
        let mut config = SemanticConfig::default();
        config.dag.enabled = true;

        let mut engine = SemanticForcesEngine::new(config);

        let mut graph = GraphData::new();
        let mut parent = Node::new("parent".to_string());
        parent = parent.with_label("Parent".to_string());
        let parent_id = parent.id;
        graph.nodes.push(parent);

        let mut child = Node::new("child".to_string());
        child = child.with_label("Child".to_string());
        let child_id = child.id;
        graph.nodes.push(child);

        let mut edge = Edge::new(parent_id, child_id, 1.0);
        edge.edge_type = Some("hierarchy".to_string());
        graph.edges.push(edge);

        engine.initialize(&graph).unwrap();

        let levels = engine.hierarchy_levels();
        assert_eq!(levels.len(), 2);
        // Parent should be at level 0
        assert_eq!(levels[0], 0);
        // Child should be at level 1
        assert_eq!(levels[1], 1);
    }

    #[test]
    fn test_type_clustering() {
        let mut config = SemanticConfig::default();
        config.type_cluster.enabled = true;

        let mut engine = SemanticForcesEngine::new(config);

        let mut graph = GraphData::new();
        for i in 0..5 {
            let mut node = Node::new(format!("node{}", i));
            node.node_type = Some("person".to_string());
            graph.nodes.push(node);
        }

        engine.initialize(&graph).unwrap();

        let centroids = engine.type_centroids();
        assert_eq!(centroids.len(), 1); // Only one type
        assert!(centroids.contains_key(&1)); // person type
    }

    // ==========================================================================
    // Dynamic GPU Buffer Tests
    // ==========================================================================

    #[test]
    fn test_dynamic_force_config_default() {
        let config = DynamicForceConfigGPU::default();
        assert_eq!(config.strength, 0.5);
        assert_eq!(config.rest_length, 100.0);
        assert_eq!(config.is_directional, 0);
        assert_eq!(config.force_type, 0);
    }

    #[test]
    fn test_dynamic_force_config_from_relationship_config() {
        let relationship_config = RelationshipForceConfig {
            strength: 0.8,
            rest_length: 75.0,
            is_directional: true,
            force_type: 2,
        };

        let gpu_config = DynamicForceConfigGPU::from(&relationship_config);

        assert_eq!(gpu_config.strength, 0.8);
        assert_eq!(gpu_config.rest_length, 75.0);
        assert_eq!(gpu_config.is_directional, 1);
        assert_eq!(gpu_config.force_type, 2);
    }

    #[test]
    fn test_dynamic_buffer_manager_creation() {
        let manager = DynamicRelationshipBufferManager::new();
        assert!(!manager.is_enabled());
        assert_eq!(manager.version(), 0);
        assert_eq!(manager.type_count(), 0);
    }

    #[test]
    fn test_dynamic_force_config_struct_size() {
        // Verify the struct layout matches CUDA expectations
        assert_eq!(std::mem::size_of::<DynamicForceConfigGPU>(), 16);
        assert_eq!(std::mem::align_of::<DynamicForceConfigGPU>(), 4);
    }
}

--------------------------------------------------------------------------------
FILE: src/gpu/streaming_pipeline.rs
PURPOSE: Real-time data streaming pipeline
--------------------------------------------------------------------------------
//! Streaming Pipeline - Optimized for headless GPU compute to lightweight clients
//!
//! Enhanced version with comprehensive GPU safety measures, memory bounds checking,
//! overflow protection, and Quest 3/VR client optimization.

use bytes::{BufMut, Bytes, BytesMut};
use log::{debug, error, info, warn};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::time::Instant;
use tokio::sync::{mpsc, RwLock};

use crate::utils::gpu_safety::{GPUSafetyConfig, GPUSafetyError, GPUSafetyValidator};
use crate::utils::memory_bounds::{MemoryBounds, SafeArrayAccess, ThreadSafeMemoryBoundsChecker};

///
#[repr(C)]
#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct SimplifiedNode {
    pub x: f32,
    pub y: f32,
    pub z: f32,
    pub color_index: u8,
    pub size: u8,
    pub importance: u8,
    pub flags: u8,
}

impl SimplifiedNode {
    
    pub fn validate(&self) -> Result<(), GPUSafetyError> {
        
        if !self.x.is_finite() || !self.y.is_finite() || !self.z.is_finite() {
            return Err(GPUSafetyError::InvalidKernelParams {
                reason: format!(
                    "Invalid position coordinates: ({}, {}, {})",
                    self.x, self.y, self.z
                ),
            });
        }

        
        const MAX_COORD: f32 = 1e6;
        if self.x.abs() > MAX_COORD || self.y.abs() > MAX_COORD || self.z.abs() > MAX_COORD {
            return Err(GPUSafetyError::InvalidKernelParams {
                reason: format!(
                    "Coordinates exceed safe bounds: ({}, {}, {})",
                    self.x, self.y, self.z
                ),
            });
        }

        Ok(())
    }

    
    pub fn new(
        x: f32,
        y: f32,
        z: f32,
        color_index: u8,
        size: u8,
        importance: u8,
        flags: u8,
    ) -> Result<Self, GPUSafetyError> {
        let node = Self {
            x,
            y,
            z,
            color_index,
            size,
            importance,
            flags,
        };
        node.validate()?;
        Ok(node)
    }
}

///
#[repr(C)]
#[derive(Debug, Clone, Copy)]
pub struct CompressedEdge {
    pub source: u16,
    pub target: u16,
    pub weight: u8,
    pub bundling_id: u8,
}

impl CompressedEdge {
    
    pub fn validate(&self, max_nodes: usize) -> Result<(), GPUSafetyError> {
        if self.source as usize >= max_nodes {
            return Err(GPUSafetyError::BufferBoundsExceeded {
                index: self.source as usize,
                size: max_nodes,
            });
        }

        if self.target as usize >= max_nodes {
            return Err(GPUSafetyError::BufferBoundsExceeded {
                index: self.target as usize,
                size: max_nodes,
            });
        }

        
        if self.source == self.target {
            return Err(GPUSafetyError::InvalidKernelParams {
                reason: format!(
                    "Self-loop detected in compressed edge: {} -> {}",
                    self.source, self.target
                ),
            });
        }

        Ok(())
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ClientLOD {
    Mobile {
        max_nodes: usize,
        max_edges: usize,
        update_rate: u32,
        compression: bool,
    },
    DesktopVR {
        max_nodes: usize,
        max_edges: usize,
        update_rate: u32,
        compression: bool,
    },
    Workstation {
        max_nodes: usize,
        max_edges: usize,
        update_rate: u32,
        compression: bool,
    },
}

impl ClientLOD {
    pub fn validate(&self) -> Result<(), GPUSafetyError> {
        let (max_nodes, max_edges, update_rate) = match self {
            ClientLOD::Mobile {
                max_nodes,
                max_edges,
                update_rate,
                ..
            } => (*max_nodes, *max_edges, *update_rate),
            ClientLOD::DesktopVR {
                max_nodes,
                max_edges,
                update_rate,
                ..
            } => (*max_nodes, *max_edges, *update_rate),
            ClientLOD::Workstation {
                max_nodes,
                max_edges,
                update_rate,
                ..
            } => (*max_nodes, *max_edges, *update_rate),
        };

        
        if max_nodes > 10_000_000 {
            return Err(GPUSafetyError::ResourceExhaustion {
                resource: "max_nodes".to_string(),
                current: max_nodes,
                limit: 10_000_000,
            });
        }

        if max_edges > 50_000_000 {
            return Err(GPUSafetyError::ResourceExhaustion {
                resource: "max_edges".to_string(),
                current: max_edges,
                limit: 50_000_000,
            });
        }

        if update_rate > 240 {
            return Err(GPUSafetyError::InvalidKernelParams {
                reason: format!("Update rate {} exceeds maximum of 240 FPS", update_rate),
            });
        }

        if update_rate == 0 {
            return Err(GPUSafetyError::InvalidKernelParams {
                reason: "Update rate must be greater than 0".to_string(),
            });
        }

        Ok(())
    }

    pub fn quest3() -> Result<Self, GPUSafetyError> {
        let lod = ClientLOD::Mobile {
            max_nodes: 1000,
            max_edges: 2000,
            update_rate: 30,
            compression: true,
        };
        lod.validate()?;
        Ok(lod)
    }

    pub fn max_nodes(&self) -> usize {
        match self {
            ClientLOD::Mobile { max_nodes, .. } => *max_nodes,
            ClientLOD::DesktopVR { max_nodes, .. } => *max_nodes,
            ClientLOD::Workstation { max_nodes, .. } => *max_nodes,
        }
    }

    pub fn max_edges(&self) -> usize {
        match self {
            ClientLOD::Mobile { max_edges, .. } => *max_edges,
            ClientLOD::DesktopVR { max_edges, .. } => *max_edges,
            ClientLOD::Workstation { max_edges, .. } => *max_edges,
        }
    }
}

///
pub struct FrameBuffer {
    current_frame: u32,
    positions: SafeArrayAccess<f32>,
    colors: SafeArrayAccess<f32>,
    importance: SafeArrayAccess<f32>,
    node_count: usize,
    bounds_checker: Arc<ThreadSafeMemoryBoundsChecker>,
}

impl FrameBuffer {
    pub fn new(
        max_nodes: usize,
        bounds_checker: Arc<ThreadSafeMemoryBoundsChecker>,
    ) -> Result<Self, GPUSafetyError> {
        
        if max_nodes > 10_000_000 {
            return Err(GPUSafetyError::ResourceExhaustion {
                resource: "max_nodes".to_string(),
                current: max_nodes,
                limit: 10_000_000,
            });
        }

        
        let positions_size =
            max_nodes
                .checked_mul(4)
                .ok_or_else(|| GPUSafetyError::InvalidBufferSize {
                    requested: max_nodes,
                    max_allowed: usize::MAX / 4,
                })?;

        let colors_size =
            max_nodes
                .checked_mul(4)
                .ok_or_else(|| GPUSafetyError::InvalidBufferSize {
                    requested: max_nodes,
                    max_allowed: usize::MAX / 4,
                })?;

        
        bounds_checker.register_allocation(MemoryBounds::new(
            "frame_buffer_positions".to_string(),
            positions_size * std::mem::size_of::<f32>(),
            std::mem::size_of::<f32>(),
            std::mem::align_of::<f32>(),
        ))?;

        bounds_checker.register_allocation(MemoryBounds::new(
            "frame_buffer_colors".to_string(),
            colors_size * std::mem::size_of::<f32>(),
            std::mem::size_of::<f32>(),
            std::mem::align_of::<f32>(),
        ))?;

        bounds_checker.register_allocation(MemoryBounds::new(
            "frame_buffer_importance".to_string(),
            max_nodes * std::mem::size_of::<f32>(),
            std::mem::size_of::<f32>(),
            std::mem::align_of::<f32>(),
        ))?;

        let positions = SafeArrayAccess::new(
            vec![0.0f32; positions_size],
            "frame_buffer_positions".to_string(),
        )
        .with_bounds_checker(bounds_checker.clone());

        let colors =
            SafeArrayAccess::new(vec![0.0f32; colors_size], "frame_buffer_colors".to_string())
                .with_bounds_checker(bounds_checker.clone());

        let importance = SafeArrayAccess::new(
            vec![0.0f32; max_nodes],
            "frame_buffer_importance".to_string(),
        )
        .with_bounds_checker(bounds_checker.clone());

        Ok(Self {
            current_frame: 0,
            positions,
            colors,
            importance,
            node_count: 0,
            bounds_checker,
        })
    }

    pub fn update_data(
        &mut self,
        positions: &[f32],
        colors: &[f32],
        importance: &[f32],
        frame: u32,
    ) -> Result<(), GPUSafetyError> {
        
        if positions.len() % 4 != 0 {
            return Err(GPUSafetyError::InvalidKernelParams {
                reason: format!(
                    "Position array length {} is not divisible by 4",
                    positions.len()
                ),
            });
        }

        if colors.len() % 4 != 0 {
            return Err(GPUSafetyError::InvalidKernelParams {
                reason: format!("Color array length {} is not divisible by 4", colors.len()),
            });
        }

        let node_count = positions.len() / 4;

        if colors.len() / 4 != node_count {
            return Err(GPUSafetyError::InvalidKernelParams {
                reason: format!(
                    "Color array represents {} nodes but position array represents {} nodes",
                    colors.len() / 4,
                    node_count
                ),
            });
        }

        if importance.len() != node_count {
            return Err(GPUSafetyError::InvalidKernelParams {
                reason: format!(
                    "Importance array length {} doesn't match node count {}",
                    importance.len(),
                    node_count
                ),
            });
        }

        
        if positions.len() > self.positions.len() {
            return Err(GPUSafetyError::BufferBoundsExceeded {
                index: positions.len(),
                size: self.positions.len(),
            });
        }

        if colors.len() > self.colors.len() {
            return Err(GPUSafetyError::BufferBoundsExceeded {
                index: colors.len(),
                size: self.colors.len(),
            });
        }

        if importance.len() > self.importance.len() {
            return Err(GPUSafetyError::BufferBoundsExceeded {
                index: importance.len(),
                size: self.importance.len(),
            });
        }

        
        for (i, &val) in positions.iter().enumerate() {
            if !val.is_finite() {
                return Err(GPUSafetyError::InvalidKernelParams {
                    reason: format!("Invalid position value at index {}: {}", i, val),
                });
            }
        }

        for (i, &val) in colors.iter().enumerate() {
            if !val.is_finite() {
                return Err(GPUSafetyError::InvalidKernelParams {
                    reason: format!("Invalid color value at index {}: {}", i, val),
                });
            }
        }

        for (i, &val) in importance.iter().enumerate() {
            if !val.is_finite() || val < 0.0 {
                return Err(GPUSafetyError::InvalidKernelParams {
                    reason: format!("Invalid importance value at index {}: {}", i, val),
                });
            }
        }

        
        self.current_frame = frame;
        self.node_count = node_count;

        
        for i in 0..positions.len() {
            *self
                .positions
                .get_mut(i)
                .map_err(|e| GPUSafetyError::DeviceError {
                    message: format!("Failed to update position {}: {}", i, e),
                })? = positions[i];
        }

        for i in 0..colors.len() {
            *self
                .colors
                .get_mut(i)
                .map_err(|e| GPUSafetyError::DeviceError {
                    message: format!("Failed to update color {}: {}", i, e),
                })? = colors[i];
        }

        for i in 0..importance.len() {
            *self
                .importance
                .get_mut(i)
                .map_err(|e| GPUSafetyError::DeviceError {
                    message: format!("Failed to update importance {}: {}", i, e),
                })? = importance[i];
        }

        debug!(
            "Frame buffer updated: frame={}, nodes={}",
            frame, node_count
        );
        Ok(())
    }

    pub fn get_current_frame(&self) -> u32 {
        self.current_frame
    }

    pub fn get_node_count(&self) -> usize {
        self.node_count
    }

    pub fn get_position(&self, node_index: usize, component: usize) -> Result<f32, GPUSafetyError> {
        if component >= 4 {
            return Err(GPUSafetyError::BufferBoundsExceeded {
                index: component,
                size: 4,
            });
        }

        let pos_index = node_index * 4 + component;
        self.positions
            .get(pos_index)
            .map(|&val| val)
            .map_err(|e| GPUSafetyError::DeviceError {
                message: format!("Failed to get position: {}", e),
            })
    }

    pub fn get_importance(&self, node_index: usize) -> Result<f32, GPUSafetyError> {
        self.importance
            .get(node_index)
            .map(|&val| val)
            .map_err(|e| GPUSafetyError::DeviceError {
                message: format!("Failed to get importance: {}", e),
            })
    }
}

///
pub struct ClientConnection {
    id: String,
    lod: ClientLOD,
    sender: mpsc::Sender<Bytes>,
    last_frame: u32,
    position: Option<[f32; 3]>,
    packet_count: u64,
    bytes_sent: u64,
    last_packet_time: Option<Instant>,
}

impl ClientConnection {
    pub fn new(
        id: String,
        lod: ClientLOD,
        sender: mpsc::Sender<Bytes>,
    ) -> Result<Self, GPUSafetyError> {
        lod.validate()?;

        if id.is_empty() {
            return Err(GPUSafetyError::InvalidKernelParams {
                reason: "Client ID cannot be empty".to_string(),
            });
        }

        Ok(Self {
            id,
            lod,
            sender,
            last_frame: 0,
            position: None,
            packet_count: 0,
            bytes_sent: 0,
            last_packet_time: None,
        })
    }

    pub fn update_position(&mut self, position: [f32; 3]) -> Result<(), GPUSafetyError> {
        
        for &coord in &position {
            if !coord.is_finite() {
                return Err(GPUSafetyError::InvalidKernelParams {
                    reason: format!("Invalid position coordinate: {}", coord),
                });
            }
        }

        self.position = Some(position);
        debug!("Updated client {} position: {:?}", self.id, position);
        Ok(())
    }

    pub async fn send_packet(&mut self, packet: Bytes) -> Result<(), GPUSafetyError> {
        
        const MAX_PACKET_SIZE: usize = 10 * 1024 * 1024; 
        if packet.len() > MAX_PACKET_SIZE {
            return Err(GPUSafetyError::ResourceExhaustion {
                resource: "packet_size".to_string(),
                current: packet.len(),
                limit: MAX_PACKET_SIZE,
            });
        }

        
        if self.sender.capacity() == 0 && self.sender.try_send(packet.clone()).is_err() {
            warn!("Client {} send queue full, dropping packet", self.id);
            return Ok(()); 
        }

        match self.sender.send(packet.clone()).await {
            Ok(()) => {
                self.packet_count += 1;
                self.bytes_sent += packet.len() as u64;
                self.last_packet_time = Some(Instant::now());
                debug!(
                    "Sent packet to client {}: {} bytes (total: {} packets, {} bytes)",
                    self.id,
                    packet.len(),
                    self.packet_count,
                    self.bytes_sent
                );
                Ok(())
            }
            Err(e) => {
                error!("Failed to send packet to client {}: {}", self.id, e);
                Err(GPUSafetyError::DeviceError {
                    message: format!("Failed to send packet: {}", e),
                })
            }
        }
    }

    pub fn should_update(&self, current_frame: u32) -> bool {
        let frame_delta = current_frame.saturating_sub(self.last_frame);

        match &self.lod {
            ClientLOD::Mobile { update_rate, .. } => {
                let threshold = 120 / update_rate.max(&1);
                frame_delta >= threshold
            }
            ClientLOD::DesktopVR { update_rate, .. } => {
                let threshold = 120 / update_rate.max(&1);
                frame_delta >= threshold
            }
            ClientLOD::Workstation { .. } => true,
        }
    }

    pub fn mark_frame_sent(&mut self, frame: u32) {
        self.last_frame = frame;
    }

    pub fn get_stats(&self) -> ClientStats {
        ClientStats {
            id: self.id.clone(),
            packet_count: self.packet_count,
            bytes_sent: self.bytes_sent,
            last_frame: self.last_frame,
            position: self.position,
            lod_type: match self.lod {
                ClientLOD::Mobile { .. } => "Mobile".to_string(),
                ClientLOD::DesktopVR { .. } => "DesktopVR".to_string(),
                ClientLOD::Workstation { .. } => "Workstation".to_string(),
            },
        }
    }
}

///
#[derive(Debug, Clone, Serialize)]
pub struct ClientStats {
    pub id: String,
    pub packet_count: u64,
    pub bytes_sent: u64,
    pub last_frame: u32,
    pub position: Option<[f32; 3]>,
    pub lod_type: String,
}

///
pub struct StreamingPipeline {
    gpu_receiver: mpsc::Receiver<RenderData>,
    clients: Arc<RwLock<Vec<ClientConnection>>>,
    frame_buffer: Arc<RwLock<FrameBuffer>>,
    importance_threshold: f32,
    safety_validator: Arc<GPUSafetyValidator>,
    bounds_checker: Arc<ThreadSafeMemoryBoundsChecker>,
    stats: Arc<RwLock<PipelineStats>>,
}

///
#[derive(Debug, Clone)]
pub struct PipelineStats {
    pub frames_processed: u64,
    pub total_packets_sent: u64,
    pub total_bytes_sent: u64,
    pub active_clients: usize,
    pub last_frame_time: Option<Instant>,
    pub average_frame_time_ms: f64,
    pub errors_count: u64,
}

impl Default for PipelineStats {
    fn default() -> Self {
        Self {
            frames_processed: 0,
            total_packets_sent: 0,
            total_bytes_sent: 0,
            active_clients: 0,
            last_frame_time: None,
            average_frame_time_ms: 0.0,
            errors_count: 0,
        }
    }
}

// Import canonical RenderData from gpu::types
pub use crate::gpu::types::RenderData;

impl StreamingPipeline {
    pub fn new(
        gpu_receiver: mpsc::Receiver<RenderData>,
        max_nodes: usize,
        safety_config: GPUSafetyConfig,
    ) -> Result<Self, GPUSafetyError> {
        let bounds_checker = Arc::new(ThreadSafeMemoryBoundsChecker::new(
            safety_config.max_memory_bytes,
        ));
        let safety_validator = Arc::new(GPUSafetyValidator::new(safety_config));

        let frame_buffer = Arc::new(RwLock::new(FrameBuffer::new(
            max_nodes,
            bounds_checker.clone(),
        )?));

        Ok(Self {
            gpu_receiver,
            clients: Arc::new(RwLock::new(Vec::new())),
            frame_buffer,
            importance_threshold: 0.1,
            safety_validator,
            bounds_checker,
            stats: Arc::new(RwLock::new(PipelineStats::default())),
        })
    }

    pub async fn add_client(
        &self,
        id: String,
        lod: ClientLOD,
    ) -> Result<mpsc::Receiver<Bytes>, GPUSafetyError> {
        let (tx, rx) = mpsc::channel(10);

        let client = ClientConnection::new(id.clone(), lod, tx)?;

        let mut clients = self.clients.write().await;
        clients.push(client);

        info!("Added safe client: {}", id);
        Ok(rx)
    }

    pub async fn run(&mut self) -> Result<(), GPUSafetyError> {
        info!("Starting safe streaming pipeline");

        while let Some(render_data) = self.gpu_receiver.recv().await {
            let frame_start = Instant::now();

            
            if let Err(e) = render_data.validate() {
                error!("Invalid render data received: {}", e);
                self.record_error().await;
                continue;
            }

            
            {
                let mut buffer = self.frame_buffer.write().await;
                if let Err(e) = buffer.update_data(
                    &render_data.positions,
                    &render_data.colors,
                    &render_data.importance,
                    render_data.frame,
                ) {
                    error!("Failed to update frame buffer: {}", e);
                    self.record_error().await;
                    continue;
                }
            }

            
            if let Err(e) = self.process_clients().await {
                error!("Error processing clients: {}", e);
                self.record_error().await;
            }

            
            self.update_stats(frame_start).await;
        }

        info!("Safe streaming pipeline stopped");
        Ok(())
    }

    async fn process_clients(&self) -> Result<(), GPUSafetyError> {
        let mut clients = self.clients.write().await;
        let buffer = self.frame_buffer.read().await;

        let current_frame = buffer.get_current_frame();
        let node_count = buffer.get_node_count();

        for client in clients.iter_mut() {
            if !client.should_update(current_frame) {
                continue;
            }

            let packet = match &client.lod {
                ClientLOD::Mobile { max_nodes, .. } => {
                    self.create_mobile_packet(&*buffer, *max_nodes, client.position, node_count)
                        .await?
                }
                ClientLOD::DesktopVR { max_nodes, .. } => {
                    self.create_desktop_packet(&*buffer, *max_nodes, client.position, node_count)
                        .await?
                }
                ClientLOD::Workstation { .. } => {
                    self.create_workstation_packet(&*buffer, node_count).await?
                }
            };

            if let Err(e) = client.send_packet(packet).await {
                warn!("Failed to send packet to client {}: {}", client.id, e);
                continue;
            }

            client.mark_frame_sent(current_frame);
        }

        Ok(())
    }

    async fn create_mobile_packet(
        &self,
        buffer: &FrameBuffer,
        max_nodes: usize,
        client_position: Option<[f32; 3]>,
        node_count: usize,
    ) -> Result<Bytes, GPUSafetyError> {
        let mut packet = BytesMut::new();

        
        packet.put_u8(1); 
        packet.put_u32_le(buffer.get_current_frame());

        
        let mut nodes: Vec<(usize, f32)> = Vec::new();

        for i in 0..node_count {
            let importance = buffer.get_importance(i)?;
            if importance > self.importance_threshold {
                nodes.push((i, importance));
            }
        }

        
        nodes.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
        nodes.truncate(max_nodes);

        
        if let Some(cam_pos) = client_position {
            nodes.retain(|(idx, _)| {
                let x = buffer.get_position(*idx, 0).unwrap_or(0.0);
                let y = buffer.get_position(*idx, 1).unwrap_or(0.0);
                let z = buffer.get_position(*idx, 2).unwrap_or(0.0);

                let dist_sq =
                    (x - cam_pos[0]).powi(2) + (y - cam_pos[1]).powi(2) + (z - cam_pos[2]).powi(2);

                dist_sq < 10000.0 
            });
        }

        
        if nodes.len() > u16::MAX as usize {
            return Err(GPUSafetyError::ResourceExhaustion {
                resource: "packet_nodes".to_string(),
                current: nodes.len(),
                limit: u16::MAX as usize,
            });
        }

        packet.put_u16_le(nodes.len() as u16);

        
        for (idx, importance) in nodes {
            let x = buffer.get_position(idx, 0)?;
            let y = buffer.get_position(idx, 1)?;
            let z = buffer.get_position(idx, 2)?;

            
            let quantized_x = (x * 100.0).clamp(i16::MIN as f32, i16::MAX as f32) as i16;
            let quantized_y = (y * 100.0).clamp(i16::MIN as f32, i16::MAX as f32) as i16;
            let quantized_z = (z * 100.0).clamp(i16::MIN as f32, i16::MAX as f32) as i16;

            packet.put_i16_le(quantized_x);
            packet.put_i16_le(quantized_y);
            packet.put_i16_le(quantized_z);

            
            let hue = buffer.get_position(idx, 0).unwrap_or(0.0);
            let color_index = (hue.abs() * 255.0).clamp(0.0, 255.0) as u8;
            packet.put_u8(color_index);

            
            let importance_quantized = (importance * 255.0).clamp(0.0, 255.0) as u8;
            packet.put_u8(importance_quantized);
        }

        Ok(packet.freeze())
    }

    async fn create_desktop_packet(
        &self,
        buffer: &FrameBuffer,
        max_nodes: usize,
        client_position: Option<[f32; 3]>,
        node_count: usize,
    ) -> Result<Bytes, GPUSafetyError> {
        let mut packet = BytesMut::new();

        
        packet.put_u8(2); 
        packet.put_u32_le(buffer.get_current_frame());

        
        let mut nodes: Vec<usize> = (0..node_count.min(max_nodes))
            .filter(|&i| buffer.get_importance(i).unwrap_or(0.0) > self.importance_threshold * 0.5)
            .collect();

        
        if let Some(cam_pos) = client_position {
            nodes.retain(|&idx| {
                let x = buffer.get_position(idx, 0).unwrap_or(0.0);
                let y = buffer.get_position(idx, 1).unwrap_or(0.0);
                let z = buffer.get_position(idx, 2).unwrap_or(0.0);

                let dist_sq =
                    (x - cam_pos[0]).powi(2) + (y - cam_pos[1]).powi(2) + (z - cam_pos[2]).powi(2);

                dist_sq < 40000.0 
            });
        }

        
        if nodes.len() > u32::MAX as usize {
            return Err(GPUSafetyError::ResourceExhaustion {
                resource: "packet_nodes".to_string(),
                current: nodes.len(),
                limit: u32::MAX as usize,
            });
        }

        packet.put_u32_le(nodes.len() as u32);

        
        for idx in nodes {
            
            packet.put_f32_le(buffer.get_position(idx, 0)?);
            packet.put_f32_le(buffer.get_position(idx, 1)?);
            packet.put_f32_le(buffer.get_position(idx, 2)?);

            
            let hue = buffer.get_position(idx, 0).unwrap_or(0.0);
            packet.put_u8((hue.abs() * 255.0).clamp(0.0, 255.0) as u8);
            packet.put_u8(128); 
            packet.put_u8(255); 

            
            let importance = buffer.get_importance(idx)?;
            packet.put_u8((importance * 255.0).clamp(0.0, 255.0) as u8);
        }

        Ok(packet.freeze())
    }

    async fn create_workstation_packet(
        &self,
        buffer: &FrameBuffer,
        node_count: usize,
    ) -> Result<Bytes, GPUSafetyError> {
        let mut packet = BytesMut::new();

        
        packet.put_u8(3); 
        packet.put_u32_le(buffer.get_current_frame());
        packet.put_u32_le(node_count as u32);

        
        for i in 0..node_count {
            
            packet.put_f32_le(buffer.get_position(i, 0)?);
            packet.put_f32_le(buffer.get_position(i, 1)?);
            packet.put_f32_le(buffer.get_position(i, 2)?);
            packet.put_f32_le(buffer.get_position(i, 3).unwrap_or(1.0)); 

            
            let hue = buffer.get_position(i, 0).unwrap_or(0.0);
            packet.put_f32_le(hue.abs()); 
            packet.put_f32_le(0.5); 
            packet.put_f32_le(1.0); 
            packet.put_f32_le(1.0); 

            
            packet.put_f32_le(buffer.get_importance(i)?);
        }

        Ok(packet.freeze())
    }

    async fn update_stats(&self, frame_start: Instant) {
        let mut stats = self.stats.write().await;
        stats.frames_processed += 1;

        let frame_time = frame_start.elapsed();
        let frame_time_ms = frame_time.as_secs_f64() * 1000.0;

        if stats.frames_processed == 1 {
            stats.average_frame_time_ms = frame_time_ms;
        } else {
            
            stats.average_frame_time_ms = stats.average_frame_time_ms * 0.9 + frame_time_ms * 0.1;
        }

        stats.last_frame_time = Some(frame_start);

        
        let clients = self.clients.read().await;
        stats.active_clients = clients.len();
    }

    async fn record_error(&self) {
        let mut stats = self.stats.write().await;
        stats.errors_count += 1;
        self.safety_validator.record_failure();
    }

    pub async fn get_pipeline_stats(&self) -> Option<PipelineStats> {
        let stats = self.stats.read().await;
        Some(stats.clone())
    }

    pub async fn get_client_stats(&self) -> Vec<ClientStats> {
        let clients = self.clients.read().await;
        clients.iter().map(|client| client.get_stats()).collect()
    }

    pub fn get_memory_usage(&self) -> Option<crate::utils::memory_bounds::MemoryUsageReport> {
        self.bounds_checker.get_usage_report()
    }
}

///
pub struct DeltaCompressor {
    previous_frame: Option<Vec<SimplifiedNode>>,
    keyframe_interval: u32,
    current_frame: u32,
}

impl DeltaCompressor {
    pub fn new(keyframe_interval: u32) -> Self {
        Self {
            previous_frame: None,
            keyframe_interval,
            current_frame: 0,
        }
    }

    pub fn compress(&mut self, nodes: Vec<SimplifiedNode>) -> Result<Bytes, GPUSafetyError> {
        self.current_frame += 1;

        let mut packet = BytesMut::new();

        
        for (i, node) in nodes.iter().enumerate() {
            node.validate()
                .map_err(|e| GPUSafetyError::InvalidKernelParams {
                    reason: format!("Node {} validation failed: {}", i, e),
                })?;
        }

        
        if self.current_frame % self.keyframe_interval == 0 || self.previous_frame.is_none() {
            
            packet.put_u8(0xFF); 

            
            if nodes.len() > u32::MAX as usize {
                return Err(GPUSafetyError::ResourceExhaustion {
                    resource: "keyframe_nodes".to_string(),
                    current: nodes.len(),
                    limit: u32::MAX as usize,
                });
            }

            packet.put_u32_le(nodes.len() as u32);

            for node in &nodes {
                packet.put_f32_le(node.x);
                packet.put_f32_le(node.y);
                packet.put_f32_le(node.z);
                packet.put_u8(node.color_index);
                packet.put_u8(node.size);
                packet.put_u8(node.importance);
                packet.put_u8(node.flags);
            }

            self.previous_frame = Some(nodes);
        } else {
            
            packet.put_u8(0xFE); 

            let prev = match self.previous_frame.as_ref() {
                Some(frame) => frame,
                None => {
                    warn!("Delta frame requested but no previous frame available, falling back to full frame");
                    
                    packet.clear();
                    packet.put_u8(0xFF); 

                    if nodes.len() > u32::MAX as usize {
                        return Err(GPUSafetyError::ResourceExhaustion {
                            resource: "fallback_keyframe_nodes".to_string(),
                            current: nodes.len(),
                            limit: u32::MAX as usize,
                        });
                    }

                    packet.put_u32_le(nodes.len() as u32);

                    for node in &nodes {
                        packet.put_f32_le(node.x);
                        packet.put_f32_le(node.y);
                        packet.put_f32_le(node.z);
                        packet.put_u8(node.color_index);
                        packet.put_u8(node.size);
                        packet.put_u8(node.importance);
                        packet.put_u8(node.flags);
                    }

                    self.previous_frame = Some(nodes);
                    return Ok(packet.freeze());
                }
            };

            
            if nodes.len() != prev.len() {
                return Err(GPUSafetyError::InvalidKernelParams {
                    reason: format!(
                        "Frame size mismatch: current={}, previous={}",
                        nodes.len(),
                        prev.len()
                    ),
                });
            }

            let mut deltas = Vec::new();

            for (i, (curr, prev)) in nodes.iter().zip(prev.iter()).enumerate() {
                let dx = curr.x - prev.x;
                let dy = curr.y - prev.y;
                let dz = curr.z - prev.z;

                
                if !dx.is_finite() || !dy.is_finite() || !dz.is_finite() {
                    return Err(GPUSafetyError::InvalidKernelParams {
                        reason: format!(
                            "Invalid delta values at node {}: dx={}, dy={}, dz={}",
                            i, dx, dy, dz
                        ),
                    });
                }

                
                if dx.abs() > 0.01
                    || dy.abs() > 0.01
                    || dz.abs() > 0.01
                    || curr.color_index != prev.color_index
                    || curr.importance != prev.importance
                {
                    if i > u16::MAX as usize {
                        return Err(GPUSafetyError::BufferBoundsExceeded {
                            index: i,
                            size: u16::MAX as usize,
                        });
                    }

                    deltas.push((i as u16, dx, dy, dz, curr.color_index, curr.importance));
                }
            }

            
            if deltas.len() > u16::MAX as usize {
                return Err(GPUSafetyError::ResourceExhaustion {
                    resource: "deltas".to_string(),
                    current: deltas.len(),
                    limit: u16::MAX as usize,
                });
            }

            packet.put_u16_le(deltas.len() as u16);

            for (idx, dx, dy, dz, color, importance) in deltas {
                packet.put_u16_le(idx);

                
                let quantized_dx = (dx * 1000.0).clamp(i16::MIN as f32, i16::MAX as f32) as i16;
                let quantized_dy = (dy * 1000.0).clamp(i16::MIN as f32, i16::MAX as f32) as i16;
                let quantized_dz = (dz * 1000.0).clamp(i16::MIN as f32, i16::MAX as f32) as i16;

                packet.put_i16_le(quantized_dx);
                packet.put_i16_le(quantized_dy);
                packet.put_i16_le(quantized_dz);
                packet.put_u8(color);
                packet.put_u8(importance);
            }

            self.previous_frame = Some(nodes);
        }

        Ok(packet.freeze())
    }
}

///
#[derive(Debug, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum StreamMessage {
    
    ClientCapability {
        device: String,
        lod: ClientLOD,
        position: Option<[f32; 3]>,
    },

    
    FocusRequest {
        node_id: Option<u32>,
        position: [f32; 3],
        radius: f32,
    },

    
    Metrics {
        fps: f32,
        latency_ms: f32,
        bandwidth_kbps: f32,
    },
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::sync::mpsc;

    #[test]
    fn test_simplified_node_validation() {
        
        let valid_node = SimplifiedNode::new(1.0, 2.0, 3.0, 10, 20, 30, 0);
        assert!(valid_node.is_ok());

        
        let invalid_node = SimplifiedNode::new(f32::NAN, 2.0, 3.0, 10, 20, 30, 0);
        assert!(invalid_node.is_err());

        
        let extreme_node = SimplifiedNode::new(1e7, 2.0, 3.0, 10, 20, 30, 0);
        assert!(extreme_node.is_err());
    }

    #[test]
    fn test_client_lod_validation() {
        
        let valid_lod = ClientLOD::Mobile {
            max_nodes: 1000,
            max_edges: 2000,
            update_rate: 30,
            compression: true,
        };
        assert!(valid_lod.validate().is_ok());

        
        let invalid_lod = ClientLOD::Mobile {
            max_nodes: 1000,
            max_edges: 2000,
            update_rate: 0,
            compression: true,
        };
        assert!(invalid_lod.validate().is_err());

        
        let excessive_lod = ClientLOD::Mobile {
            max_nodes: 20_000_000,
            max_edges: 2000,
            update_rate: 30,
            compression: true,
        };
        assert!(excessive_lod.validate().is_err());
    }

    #[tokio::test]
    async fn test_frame_buffer() {
        let bounds_checker = Arc::new(ThreadSafeMemoryBoundsChecker::new(1024 * 1024 * 1024));
        let mut buffer = FrameBuffer::new(100, bounds_checker).unwrap();

        let positions = vec![1.0f32; 400]; 
        let colors = vec![0.5f32; 400];
        let importance = vec![0.8f32; 100];

        assert!(buffer
            .update_data(&positions, &colors, &importance, 1)
            .is_ok());
        assert_eq!(buffer.get_current_frame(), 1);
        assert_eq!(buffer.get_node_count(), 100);

        
        assert!(buffer.get_position(150, 0).is_err());
        assert!(buffer.get_importance(150).is_err());

        
        assert!(buffer.get_position(50, 0).is_ok());
        assert!(buffer.get_importance(50).is_ok());
    }

    #[tokio::test]
    async fn test_render_data_validation() {
        
        let valid_data = RenderData {
            positions: vec![1.0f32; 40], 
            colors: vec![0.5f32; 40],
            importance: vec![0.8f32; 10],
            frame: 1,
        };
        assert!(valid_data.validate().is_ok());

        
        let invalid_data = RenderData {
            positions: vec![1.0f32; 39], 
            colors: vec![0.5f32; 40],
            importance: vec![0.8f32; 10],
            frame: 1,
        };
        assert!(invalid_data.validate().is_err());

        
        let mismatched_data = RenderData {
            positions: vec![1.0f32; 40], 
            colors: vec![0.5f32; 40],
            importance: vec![0.8f32; 15], 
            frame: 1,
        };
        assert!(mismatched_data.validate().is_err());
    }

    #[test]
    fn test_delta_compression() {
        let mut compressor = DeltaCompressor::new(30);

        let nodes = vec![SimplifiedNode {
            x: 1.0,
            y: 2.0,
            z: 3.0,
            color_index: 10,
            size: 50,
            importance: 128,
            flags: 0,
        }];

        let compressed = compressor.compress(nodes);
        assert!(compressed.is_ok());
        assert!(compressed.unwrap().len() > 0);
    }
}

--------------------------------------------------------------------------------
FILE: src/gpu/broadcast_optimizer.rs
PURPOSE: Network broadcast optimization
--------------------------------------------------------------------------------
//! GPU Physics Broadcast Optimization
//!
//! Reduces network bandwidth by 70-80% through:
//! - Adaptive broadcast frequency (20-30fps instead of 60fps)
//! - Delta compression (only send nodes that moved)
//! - Spatial partitioning (visibility culling)

use glam::Vec3;
use log::{debug, info};
use std::collections::HashMap;
use std::time::{Duration, Instant};

/// Configuration for broadcast optimization
#[derive(Debug, Clone)]
pub struct BroadcastConfig {
    /// Target broadcast rate in Hz (20-30 recommended)
    pub target_fps: u32,

    /// Delta threshold - nodes must move more than this to be broadcast
    pub delta_threshold: f32,

    /// Enable spatial visibility culling
    pub enable_spatial_culling: bool,

    /// Camera frustum bounds for culling (min, max)
    pub camera_bounds: Option<(Vec3, Vec3)>,
}

impl Default for BroadcastConfig {
    fn default() -> Self {
        Self {
            target_fps: 25, // 25fps broadcast, 60fps physics
            delta_threshold: 0.01, // 1cm movement threshold
            enable_spatial_culling: false,
            camera_bounds: None,
        }
    }
}

/// Tracks previous positions for delta compression
pub struct DeltaCompressor {
    previous_positions: HashMap<u32, Vec3>,
    previous_velocities: HashMap<u32, Vec3>,
    last_broadcast_time: Instant,
    broadcast_interval: Duration,
    frames_since_broadcast: u32,
}

impl DeltaCompressor {
    pub fn new(config: &BroadcastConfig) -> Self {
        let broadcast_interval = Duration::from_micros((1_000_000 / config.target_fps) as u64);

        Self {
            previous_positions: HashMap::new(),
            previous_velocities: HashMap::new(),
            last_broadcast_time: Instant::now(),
            broadcast_interval,
            frames_since_broadcast: 0,
        }
    }

    /// Check if we should broadcast this frame
    pub fn should_broadcast(&mut self) -> bool {
        self.frames_since_broadcast += 1;
        let elapsed = self.last_broadcast_time.elapsed();

        if elapsed >= self.broadcast_interval {
            self.last_broadcast_time = Instant::now();
            self.frames_since_broadcast = 0;
            true
        } else {
            false
        }
    }

    /// Filter updates to only nodes that moved significantly
    pub fn filter_delta_updates(
        &mut self,
        positions: &[(Vec3, Vec3)], // (position, velocity)
        node_ids: &[u32],
        threshold: f32,
    ) -> Vec<usize> {
        let mut changed_indices = Vec::new();

        for (idx, &node_id) in node_ids.iter().enumerate() {
            let (pos, vel) = positions[idx];

            // Check if node moved beyond threshold
            let should_update = if let Some(&prev_pos) = self.previous_positions.get(&node_id) {
                let distance = (pos - prev_pos).length();
                distance > threshold
            } else {
                true // First time seeing this node
            };

            if should_update {
                changed_indices.push(idx);
                self.previous_positions.insert(node_id, pos);
                self.previous_velocities.insert(node_id, vel);
            }
        }

        changed_indices
    }

    /// Get compression statistics
    pub fn get_stats(&self, total_nodes: usize, sent_nodes: usize) -> CompressionStats {
        let reduction_percent = if total_nodes > 0 {
            ((total_nodes - sent_nodes) as f32 / total_nodes as f32) * 100.0
        } else {
            0.0
        };

        CompressionStats {
            total_nodes,
            sent_nodes,
            reduction_percent,
            frames_since_broadcast: self.frames_since_broadcast,
        }
    }
}

/// Statistics for compression performance
#[derive(Debug, Clone)]
pub struct CompressionStats {
    pub total_nodes: usize,
    pub sent_nodes: usize,
    pub reduction_percent: f32,
    pub frames_since_broadcast: u32,
}

/// Spatial partitioning for visibility culling
pub struct SpatialCuller {
    enabled: bool,
    camera_bounds: Option<(Vec3, Vec3)>,
}

impl SpatialCuller {
    pub fn new(config: &BroadcastConfig) -> Self {
        Self {
            enabled: config.enable_spatial_culling,
            camera_bounds: config.camera_bounds,
        }
    }

    /// Update camera frustum bounds
    pub fn update_camera_bounds(&mut self, min: Vec3, max: Vec3) {
        self.camera_bounds = Some((min, max));
    }

    /// Filter positions to only visible nodes
    pub fn filter_visible(&self, positions: &[Vec3], node_ids: &[u32]) -> Vec<usize> {
        if !self.enabled {
            // Return all indices if culling disabled
            return (0..node_ids.len()).collect();
        }

        let Some((min, max)) = self.camera_bounds else {
            // No bounds set, return all
            return (0..node_ids.len()).collect();
        };

        let mut visible_indices = Vec::new();

        for (idx, pos) in positions.iter().enumerate() {
            // Simple AABB test
            if pos.x >= min.x && pos.x <= max.x
                && pos.y >= min.y && pos.y <= max.y
                && pos.z >= min.z && pos.z <= max.z
            {
                visible_indices.push(idx);
            }
        }

        visible_indices
    }
}

/// Main broadcast optimizer combining all techniques
pub struct BroadcastOptimizer {
    config: BroadcastConfig,
    delta_compressor: DeltaCompressor,
    spatial_culler: SpatialCuller,
    total_frames_processed: u64,
    total_nodes_sent: u64,
    total_nodes_processed: u64,
}

impl BroadcastOptimizer {
    pub fn new(config: BroadcastConfig) -> Self {
        let delta_compressor = DeltaCompressor::new(&config);
        let spatial_culler = SpatialCuller::new(&config);

        Self {
            config,
            delta_compressor,
            spatial_culler,
            total_frames_processed: 0,
            total_nodes_sent: 0,
            total_nodes_processed: 0,
        }
    }

    /// Process positions and return indices of nodes to broadcast
    ///
    /// Returns (should_broadcast, filtered_indices)
    pub fn process_frame(
        &mut self,
        positions: &[(Vec3, Vec3)], // (position, velocity)
        node_ids: &[u32],
    ) -> (bool, Vec<usize>) {
        self.total_frames_processed += 1;

        // Check if we should broadcast this frame
        if !self.delta_compressor.should_broadcast() {
            return (false, Vec::new());
        }

        // Apply spatial culling first (reduces delta work)
        let pos_only: Vec<Vec3> = positions.iter().map(|(p, _)| *p).collect();
        let visible_indices = self.spatial_culler.filter_visible(&pos_only, node_ids);

        if visible_indices.is_empty() {
            return (true, Vec::new());
        }

        // Filter visible nodes by delta threshold
        let visible_positions: Vec<(Vec3, Vec3)> = visible_indices
            .iter()
            .map(|&idx| positions[idx])
            .collect();
        let visible_ids: Vec<u32> = visible_indices
            .iter()
            .map(|&idx| node_ids[idx])
            .collect();

        let delta_indices = self.delta_compressor.filter_delta_updates(
            &visible_positions,
            &visible_ids,
            self.config.delta_threshold,
        );

        // Map back to original indices
        let final_indices: Vec<usize> = delta_indices
            .into_iter()
            .map(|i| visible_indices[i])
            .collect();

        self.total_nodes_sent += final_indices.len() as u64;
        self.total_nodes_processed += node_ids.len() as u64;

        (true, final_indices)
    }

    /// Get overall performance statistics
    pub fn get_performance_stats(&self) -> BroadcastPerformanceStats {
        let avg_reduction = if self.total_nodes_processed > 0 {
            ((self.total_nodes_processed - self.total_nodes_sent) as f64
                / self.total_nodes_processed as f64) * 100.0
        } else {
            0.0
        };

        BroadcastPerformanceStats {
            total_frames_processed: self.total_frames_processed,
            total_nodes_sent: self.total_nodes_sent,
            total_nodes_processed: self.total_nodes_processed,
            average_bandwidth_reduction: avg_reduction as f32,
            target_fps: self.config.target_fps,
            delta_threshold: self.config.delta_threshold,
        }
    }

    /// Update configuration at runtime
    pub fn update_config(&mut self, config: BroadcastConfig) {
        info!("BroadcastOptimizer: Updating configuration");
        info!("  Target FPS: {} -> {}", self.config.target_fps, config.target_fps);
        info!("  Delta threshold: {:.4} -> {:.4}", self.config.delta_threshold, config.delta_threshold);

        self.config = config;
        self.delta_compressor = DeltaCompressor::new(&self.config);
        self.spatial_culler = SpatialCuller::new(&self.config);
    }

    /// Update camera bounds for spatial culling
    pub fn update_camera_bounds(&mut self, min: Vec3, max: Vec3) {
        self.spatial_culler.update_camera_bounds(min, max);
        debug!("BroadcastOptimizer: Camera bounds updated to [{:?}, {:?}]", min, max);
    }
}

#[derive(Debug, Clone)]
pub struct BroadcastPerformanceStats {
    pub total_frames_processed: u64,
    pub total_nodes_sent: u64,
    pub total_nodes_processed: u64,
    pub average_bandwidth_reduction: f32,
    pub target_fps: u32,
    pub delta_threshold: f32,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_delta_compression_threshold() {
        let config = BroadcastConfig {
            target_fps: 30,
            delta_threshold: 0.01,
            enable_spatial_culling: false,
            camera_bounds: None,
        };

        let mut compressor = DeltaCompressor::new(&config);

        // First update - all nodes should be sent
        let positions = vec![
            (Vec3::new(0.0, 0.0, 0.0), Vec3::ZERO),
            (Vec3::new(1.0, 0.0, 0.0), Vec3::ZERO),
        ];
        let node_ids = vec![0, 1];

        let changed = compressor.filter_delta_updates(&positions, &node_ids, 0.01);
        assert_eq!(changed.len(), 2, "First update should send all nodes");

        // Second update - no movement, nothing sent
        let changed = compressor.filter_delta_updates(&positions, &node_ids, 0.01);
        assert_eq!(changed.len(), 0, "No movement, nothing sent");

        // Third update - small movement below threshold
        let positions = vec![
            (Vec3::new(0.005, 0.0, 0.0), Vec3::ZERO),
            (Vec3::new(1.0, 0.0, 0.0), Vec3::ZERO),
        ];
        let changed = compressor.filter_delta_updates(&positions, &node_ids, 0.01);
        assert_eq!(changed.len(), 0, "Movement below threshold");

        // Fourth update - movement above threshold
        let positions = vec![
            (Vec3::new(0.02, 0.0, 0.0), Vec3::ZERO),
            (Vec3::new(1.0, 0.0, 0.0), Vec3::ZERO),
        ];
        let changed = compressor.filter_delta_updates(&positions, &node_ids, 0.01);
        assert_eq!(changed.len(), 1, "One node moved above threshold");
    }

    #[test]
    fn test_spatial_culling() {
        let config = BroadcastConfig {
            target_fps: 30,
            delta_threshold: 0.01,
            enable_spatial_culling: true,
            camera_bounds: Some((Vec3::new(-10.0, -10.0, -10.0), Vec3::new(10.0, 10.0, 10.0))),
        };

        let culler = SpatialCuller::new(&config);

        let positions = vec![
            Vec3::new(0.0, 0.0, 0.0),    // Inside
            Vec3::new(15.0, 0.0, 0.0),   // Outside
            Vec3::new(5.0, 5.0, 5.0),    // Inside
            Vec3::new(0.0, 20.0, 0.0),   // Outside
        ];
        let node_ids = vec![0, 1, 2, 3];

        let visible = culler.filter_visible(&positions, &node_ids);
        assert_eq!(visible.len(), 2, "Only 2 nodes should be visible");
        assert!(visible.contains(&0));
        assert!(visible.contains(&2));
    }

    #[test]
    fn test_broadcast_optimizer_integration() {
        let config = BroadcastConfig {
            target_fps: 60, // High rate for testing
            delta_threshold: 0.01,
            enable_spatial_culling: false,
            camera_bounds: None,
        };

        let mut optimizer = BroadcastOptimizer::new(config);

        // Simulate multiple frames
        let positions = vec![
            (Vec3::new(0.0, 0.0, 0.0), Vec3::ZERO),
            (Vec3::new(1.0, 0.0, 0.0), Vec3::ZERO),
        ];
        let node_ids = vec![0, 1];

        // First frame should broadcast
        std::thread::sleep(Duration::from_millis(20));
        let (should_broadcast, indices) = optimizer.process_frame(&positions, &node_ids);
        assert!(should_broadcast, "First frame should broadcast");
        assert_eq!(indices.len(), 2, "All nodes in first frame");

        // Second frame with no movement
        std::thread::sleep(Duration::from_millis(20));
        let (should_broadcast, indices) = optimizer.process_frame(&positions, &node_ids);
        if should_broadcast {
            assert_eq!(indices.len(), 0, "No movement, no nodes sent");
        }
    }
}

--------------------------------------------------------------------------------
FILE: src/utils/binary_protocol.rs
PURPOSE: Binary WebSocket protocol implementation
--------------------------------------------------------------------------------
use crate::models::constraints::{AdvancedParams, Constraint};
use crate::types::vec3::Vec3Data;
use crate::utils::socket_flow_messages::BinaryNodeData;
use log::{debug, trace};
use serde::{Deserialize, Serialize};
use serde_json;
use std::collections::HashMap;

// Protocol versions for wire format (V1 REMOVED - no backward compatibility)
const PROTOCOL_V2: u8 = 2;
const PROTOCOL_V3: u8 = 3; // Analytics extension protocol (P0-4) - CURRENT
const PROTOCOL_V4: u8 = 4; // Delta encoding protocol

// Node type flag constants for u32 (server-side)
const AGENT_NODE_FLAG: u32 = 0x80000000; 
const KNOWLEDGE_NODE_FLAG: u32 = 0x40000000; 

// Ontology node type flags (bits 26-28, only valid when GraphType::Ontology)
const ONTOLOGY_TYPE_MASK: u32 = 0x1C000000; 
const ONTOLOGY_CLASS_FLAG: u32 = 0x04000000; 
const ONTOLOGY_INDIVIDUAL_FLAG: u32 = 0x08000000; 
const ONTOLOGY_PROPERTY_FLAG: u32 = 0x10000000; 

const NODE_ID_MASK: u32 = 0x3FFFFFFF; 

// V1 wire format constants REMOVED - caused node ID truncation bugs
// V2+ uses full u32 IDs with no truncation

// Node type flag constants for u32 (wire format v2)
const WIRE_V2_AGENT_FLAG: u32 = 0x80000000; 
const WIRE_V2_KNOWLEDGE_FLAG: u32 = 0x40000000; 
const WIRE_V2_NODE_ID_MASK: u32 = 0x3FFFFFFF; 

// WireNodeDataItemV1 REMOVED - V1 protocol no longer supported

///
/// Wire format V2 - 36 bytes per node
/// Basic pathfinding + node type flags
///
pub struct WireNodeDataItemV2 {
    pub id: u32,
    pub position: Vec3Data,
    pub velocity: Vec3Data,
    pub sssp_distance: f32,
    pub sssp_parent: i32,

}

///
/// Wire format V3 - 48 bytes per node (P0-4 Analytics Extension)
/// Adds clustering, anomaly detection, and community detection
///
pub struct WireNodeDataItemV3 {
    pub id: u32,
    pub position: Vec3Data,
    pub velocity: Vec3Data,
    pub sssp_distance: f32,
    pub sssp_parent: i32,
    pub cluster_id: u32,
    pub anomaly_score: f32,
    pub community_id: u32,
}

// Backwards compatibility alias - now defaults to V3
pub type WireNodeDataItem = WireNodeDataItemV3;

// ============================================================================
// DELTA ENCODING (Protocol V4) - P1-3 Feature
// ============================================================================

/// Delta-encoded position update (16 bytes per changed node)
/// Used in frames 1-59 to send only changes from previous frame
/// Achieves 60-80% bandwidth reduction compared to full state updates
#[repr(C)]
#[derive(Debug, Clone, Copy)]
pub struct DeltaNodeData {
    pub id: u32,            // 4 bytes - node ID with flags
    pub change_flags: u8,   // 1 byte - bits indicate which fields changed
    pub _padding: [u8; 3],  // 3 bytes - alignment padding
    pub dx: i16,            // 2 bytes - delta position x (scaled)
    pub dy: i16,            // 2 bytes - delta position y (scaled)
    pub dz: i16,            // 2 bytes - delta position z (scaled)
    pub dvx: i16,           // 2 bytes - delta velocity x (scaled)
    pub dvy: i16,           // 2 bytes - delta velocity y (scaled)
    pub dvz: i16,           // 2 bytes - delta velocity z (scaled)
}

// Change flags for delta encoding
const DELTA_POSITION_CHANGED: u8 = 0x01;
const DELTA_VELOCITY_CHANGED: u8 = 0x02;
const DELTA_ALL_CHANGED: u8 = DELTA_POSITION_CHANGED | DELTA_VELOCITY_CHANGED;

// Delta encoding constants
const DELTA_SCALE_FACTOR: f32 = 100.0; // Scale factor for i16 precision
const DELTA_ITEM_SIZE: usize = 16;     // Size of DeltaNodeData in bytes
const DELTA_RESYNC_INTERVAL: u64 = 60; // Full state every 60 frames

// Constants for wire format sizes (V1 removed)
const WIRE_V2_ID_SIZE: usize = 4;
const WIRE_VEC3_SIZE: usize = 12;
const WIRE_F32_SIZE: usize = 4;
const WIRE_I32_SIZE: usize = 4;
const WIRE_U32_SIZE: usize = 4;
const WIRE_V2_ITEM_SIZE: usize =
    WIRE_V2_ID_SIZE + WIRE_VEC3_SIZE + WIRE_VEC3_SIZE + WIRE_F32_SIZE + WIRE_I32_SIZE;
const WIRE_V3_ITEM_SIZE: usize =
    WIRE_V2_ID_SIZE + WIRE_VEC3_SIZE + WIRE_VEC3_SIZE + WIRE_F32_SIZE + WIRE_I32_SIZE +
    WIRE_U32_SIZE + WIRE_F32_SIZE + WIRE_U32_SIZE; // V2 + cluster_id + anomaly_score + community_id 

// Backwards compatibility alias - now defaults to V3
const WIRE_ID_SIZE: usize = WIRE_V2_ID_SIZE;
const WIRE_ITEM_SIZE: usize = WIRE_V3_ITEM_SIZE;

// Binary format (explicit):
//
// PROTOCOL V3 (CURRENT - P0-4 Analytics Extension):
// - Wire format sent to client (48 bytes total):
//   - Node Index: 4 bytes (u32) - Bits 30-31 for flags, bits 0-29 for ID
//   - Position: 3  4 bytes = 12 bytes
//   - Velocity: 3  4 bytes = 12 bytes
//   - SSSP Distance: 4 bytes (f32)
//   - SSSP Parent: 4 bytes (i32)
//   - Cluster ID: 4 bytes (u32) - K-means cluster assignment
//   - Anomaly Score: 4 bytes (f32) - LOF anomaly score (0.0-1.0)
//   - Community ID: 4 bytes (u32) - Louvain community assignment
// Total: 48 bytes per node
// Supports node IDs: 0 to 1,073,741,823 (2^30 - 1)
//
// PROTOCOL V2 (STABLE - FIXES node ID truncation bug):
// - Wire format sent to client (36 bytes total):
//   - Node Index: 4 bytes (u32) - Bits 30-31 for flags, bits 0-29 for ID
//   - Position: 3  4 bytes = 12 bytes
//   - Velocity: 3  4 bytes = 12 bytes
//   - SSSP Distance: 4 bytes (f32)
//   - SSSP Parent: 4 bytes (i32)
// Total: 36 bytes per node (NOT 38 - that was a documentation error!)
// Supports node IDs: 0 to 1,073,741,823 (2^30 - 1)
//
// PROTOCOL V1 REMOVED - Had node ID truncation bug (IDs > 16383 were corrupted)
//
// - Server format (BinaryNodeData - 28 bytes total):
//   - Node ID: 4 bytes (u32)
//   - Position: 3  4 bytes = 12 bytes
//   - Velocity: 3  4 bytes = 12 bytes
// Total: 28 bytes per node
//
// Node Type Flags:
// - V2/V3: Bits 30-31 of u32 ID (Bit 31 = Agent, Bit 30 = Knowledge)
// - V2/V3: Bits 26-28 of u32 ID for Ontology types (Bit 26 = Class, Bit 27 = Individual, Bit 28 = Property)
// This allows the client to distinguish between different node types for visualization.

///
pub fn set_agent_flag(node_id: u32) -> u32 {
    (node_id & NODE_ID_MASK) | AGENT_NODE_FLAG
}

pub fn set_knowledge_flag(node_id: u32) -> u32 {
    (node_id & NODE_ID_MASK) | KNOWLEDGE_NODE_FLAG
}

pub fn clear_agent_flag(node_id: u32) -> u32 {
    node_id & !AGENT_NODE_FLAG
}

pub fn clear_all_flags(node_id: u32) -> u32 {
    node_id & NODE_ID_MASK
}

pub fn is_agent_node(node_id: u32) -> bool {
    (node_id & AGENT_NODE_FLAG) != 0
}

pub fn is_knowledge_node(node_id: u32) -> bool {
    (node_id & KNOWLEDGE_NODE_FLAG) != 0
}

pub fn get_actual_node_id(node_id: u32) -> u32 {
    node_id & NODE_ID_MASK
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum NodeType {
    Knowledge,
    Agent,
    OntologyClass,
    OntologyIndividual,
    OntologyProperty,
    Unknown,
}

pub fn get_node_type(node_id: u32) -> NodeType {
    if is_agent_node(node_id) {
        NodeType::Agent
    } else if is_knowledge_node(node_id) {
        NodeType::Knowledge
    } else if is_ontology_class(node_id) {
        NodeType::OntologyClass
    } else if is_ontology_individual(node_id) {
        NodeType::OntologyIndividual
    } else if is_ontology_property(node_id) {
        NodeType::OntologyProperty
    } else {
        NodeType::Unknown
    }
}

///
pub fn set_ontology_class_flag(node_id: u32) -> u32 {
    (node_id & NODE_ID_MASK) | ONTOLOGY_CLASS_FLAG
}

pub fn set_ontology_individual_flag(node_id: u32) -> u32 {
    (node_id & NODE_ID_MASK) | ONTOLOGY_INDIVIDUAL_FLAG
}

pub fn set_ontology_property_flag(node_id: u32) -> u32 {
    (node_id & NODE_ID_MASK) | ONTOLOGY_PROPERTY_FLAG
}

pub fn is_ontology_class(node_id: u32) -> bool {
    (node_id & ONTOLOGY_TYPE_MASK) == ONTOLOGY_CLASS_FLAG
}

pub fn is_ontology_individual(node_id: u32) -> bool {
    (node_id & ONTOLOGY_TYPE_MASK) == ONTOLOGY_INDIVIDUAL_FLAG
}

pub fn is_ontology_property(node_id: u32) -> bool {
    (node_id & ONTOLOGY_TYPE_MASK) == ONTOLOGY_PROPERTY_FLAG
}

pub fn is_ontology_node(node_id: u32) -> bool {
    (node_id & ONTOLOGY_TYPE_MASK) != 0
}

// to_wire_id_v1 and from_wire_id_v1 REMOVED - V1 protocol no longer supported
// Use to_wire_id_v2/from_wire_id_v2 for full 32-bit node ID support

///
///
pub fn to_wire_id_v2(node_id: u32) -> u32 {
    
    
    node_id
}

///
///
pub fn from_wire_id_v2(wire_id: u32) -> u32 {
    
    wire_id
}

// Backwards compatibility aliases - use V2 by default
pub fn to_wire_id(node_id: u32) -> u32 {
    to_wire_id_v2(node_id)
}

pub fn from_wire_id(wire_id: u32) -> u32 {
    from_wire_id_v2(wire_id)
}

/// Convert BinaryNodeData to wire format V3
impl BinaryNodeData {
    pub fn to_wire_format(&self, node_id: u32) -> WireNodeDataItem {
        WireNodeDataItem {
            id: to_wire_id(node_id),
            position: self.position(),
            velocity: self.velocity(),
            sssp_distance: f32::INFINITY,
            sssp_parent: -1,
            cluster_id: 0,      // V3 analytics fields - default values
            anomaly_score: 0.0,
            community_id: 0,
        }
    }
}

///
///
pub fn needs_v2_protocol(nodes: &[(u32, BinaryNodeData)]) -> bool {
    nodes.iter().any(|(node_id, _)| {
        let actual_id = get_actual_node_id(*node_id);
        actual_id > 0x3FFF 
    })
}

///
///
///
pub fn encode_node_data_with_types(
    nodes: &[(u32, BinaryNodeData)],
    agent_node_ids: &[u32],
    knowledge_node_ids: &[u32],
) -> Vec<u8> {
    encode_node_data_extended(nodes, agent_node_ids, knowledge_node_ids, &[], &[], &[])
}

///
pub fn encode_node_data_extended(
    nodes: &[(u32, BinaryNodeData)],
    agent_node_ids: &[u32],
    knowledge_node_ids: &[u32],
    ontology_class_ids: &[u32],
    ontology_individual_ids: &[u32],
    ontology_property_ids: &[u32],
) -> Vec<u8> {
    // Always use V3 as the default protocol (P0-4 Analytics Extension)
    let protocol_version = PROTOCOL_V3;
    let item_size = WIRE_V3_ITEM_SIZE;

    
    if nodes.len() > 0 {
        trace!(
            "Encoding {} nodes with agent flags using protocol v{} (item_size={})",
            nodes.len(),
            protocol_version,
            item_size
        );
    }

    
    let mut buffer = Vec::with_capacity(1 + nodes.len() * item_size);

    
    buffer.push(protocol_version);

    
    let sample_size = std::cmp::min(3, nodes.len());
    if sample_size > 0 {
        trace!(
            "Sample of nodes being encoded with agent flags (protocol v{}):",
            protocol_version
        );
    }

    for (node_id, node) in nodes {
        
        
        let flagged_id = if agent_node_ids.contains(node_id) {
            set_agent_flag(*node_id)
        } else if knowledge_node_ids.contains(node_id) {
            set_knowledge_flag(*node_id)
        } else if ontology_class_ids.contains(node_id) {
            set_ontology_class_flag(*node_id)
        } else if ontology_individual_ids.contains(node_id) {
            set_ontology_individual_flag(*node_id)
        } else if ontology_property_ids.contains(node_id) {
            set_ontology_property_flag(*node_id)
        } else {
            *node_id 
        };

        
        if sample_size > 0 && *node_id < sample_size as u32 {
            trace!(
                "Encoding node {}: pos=[{:.3},{:.3},{:.3}], vel=[{:.3},{:.3},{:.3}], is_agent={}",
                node_id,
                node.x,
                node.y,
                node.z,
                node.vx,
                node.vy,
                node.vz,
                agent_node_ids.contains(node_id)
            );
        }

        // V3 always uses u32 IDs
        let wire_id = to_wire_id_v2(flagged_id);
        buffer.extend_from_slice(&wire_id.to_le_bytes());

        // Position (12 bytes)
        buffer.extend_from_slice(&node.x.to_le_bytes());
        buffer.extend_from_slice(&node.y.to_le_bytes());
        buffer.extend_from_slice(&node.z.to_le_bytes());

        // Velocity (12 bytes)
        buffer.extend_from_slice(&node.vx.to_le_bytes());
        buffer.extend_from_slice(&node.vy.to_le_bytes());
        buffer.extend_from_slice(&node.vz.to_le_bytes());

        // SSSP data (8 bytes)
        buffer.extend_from_slice(&f32::INFINITY.to_le_bytes());
        buffer.extend_from_slice(&(-1i32).to_le_bytes());

        // Analytics data (12 bytes) - V3 extension with default values
        buffer.extend_from_slice(&0u32.to_le_bytes());   // cluster_id
        buffer.extend_from_slice(&0.0f32.to_le_bytes()); // anomaly_score
        buffer.extend_from_slice(&0u32.to_le_bytes());   // community_id
    }

    
    if nodes.len() > 0 {
        trace!(
            "Encoded binary data with agent flags (v{}): {} bytes for {} nodes",
            protocol_version,
            buffer.len(),
            nodes.len()
        );
    }
    buffer
}

///
pub fn encode_node_data_with_flags(
    nodes: &[(u32, BinaryNodeData)],
    agent_node_ids: &[u32],
) -> Vec<u8> {
    encode_node_data_with_types(nodes, agent_node_ids, &[])
}

///
/// Encode node data with analytics (Protocol V3 - P0-4)
/// Extends V2 with cluster_id, anomaly_score, and community_id
///
pub fn encode_node_data_with_analytics(
    nodes: &[(u32, BinaryNodeData)],
    agent_node_ids: &[u32],
    knowledge_node_ids: &[u32],
    ontology_class_ids: &[u32],
    ontology_individual_ids: &[u32],
    ontology_property_ids: &[u32],
    analytics: &HashMap<u32, (u32, f32, u32)>, // (cluster_id, anomaly_score, community_id)
) -> Vec<u8> {
    let protocol_version = PROTOCOL_V3;
    let item_size = WIRE_V3_ITEM_SIZE;

    if nodes.len() > 0 {
        trace!(
            "Encoding {} nodes with analytics using protocol v{} (item_size={})",
            nodes.len(),
            protocol_version,
            item_size
        );
    }

    let mut buffer = Vec::with_capacity(1 + nodes.len() * item_size);
    buffer.push(protocol_version);

    for (node_id, node) in nodes {
        // Apply node type flags
        let flagged_id = if agent_node_ids.contains(node_id) {
            set_agent_flag(*node_id)
        } else if knowledge_node_ids.contains(node_id) {
            set_knowledge_flag(*node_id)
        } else if ontology_class_ids.contains(node_id) {
            set_ontology_class_flag(*node_id)
        } else if ontology_individual_ids.contains(node_id) {
            set_ontology_individual_flag(*node_id)
        } else if ontology_property_ids.contains(node_id) {
            set_ontology_property_flag(*node_id)
        } else {
            *node_id
        };

        let wire_id = to_wire_id_v2(flagged_id);
        buffer.extend_from_slice(&wire_id.to_le_bytes());

        // Position (12 bytes)
        buffer.extend_from_slice(&node.x.to_le_bytes());
        buffer.extend_from_slice(&node.y.to_le_bytes());
        buffer.extend_from_slice(&node.z.to_le_bytes());

        // Velocity (12 bytes)
        buffer.extend_from_slice(&node.vx.to_le_bytes());
        buffer.extend_from_slice(&node.vy.to_le_bytes());
        buffer.extend_from_slice(&node.vz.to_le_bytes());

        // SSSP data (8 bytes)
        buffer.extend_from_slice(&f32::INFINITY.to_le_bytes());
        buffer.extend_from_slice(&(-1i32).to_le_bytes());

        // Analytics data (12 bytes) - NEW in V3
        let (cluster_id, anomaly_score, community_id) = analytics
            .get(node_id)
            .copied()
            .unwrap_or((0, 0.0, 0)); // Default values if no analytics

        buffer.extend_from_slice(&cluster_id.to_le_bytes());
        buffer.extend_from_slice(&anomaly_score.to_le_bytes());
        buffer.extend_from_slice(&community_id.to_le_bytes());
    }

    if nodes.len() > 0 {
        trace!(
            "Encoded binary data with analytics (v{}): {} bytes for {} nodes",
            protocol_version,
            buffer.len(),
            nodes.len()
        );
    }

    buffer
}

///
///
pub fn encode_node_data(nodes: &[(u32, BinaryNodeData)]) -> Vec<u8> {
    encode_node_data_with_types(nodes, &[], &[])
}

pub fn decode_node_data(data: &[u8]) -> Result<Vec<(u32, BinaryNodeData)>, String> {
    if data.is_empty() {
        return Ok(Vec::new());
    }

    
    if data.len() < 1 {
        return Err("Data too small for protocol version".to_string());
    }

    let protocol_version = data[0];
    let payload = &data[1..];

    match protocol_version {
        1 => Err("Protocol V1 is no longer supported. Please upgrade client.".to_string()),
        PROTOCOL_V2 => decode_node_data_v2(payload),
        PROTOCOL_V3 => decode_node_data_v3(payload),
        v => Err(format!("Unknown protocol version: {}", v)),
    }
}

// decode_node_data_v1 REMOVED - V1 protocol no longer supported

///
fn decode_node_data_v2(data: &[u8]) -> Result<Vec<(u32, BinaryNodeData)>, String> {
    
    if data.len() % WIRE_V2_ITEM_SIZE != 0 {
        return Err(format!(
            "Data size {} is not a multiple of V2 wire item size {}",
            data.len(),
            WIRE_V2_ITEM_SIZE
        ));
    }

    let expected_nodes = data.len() / WIRE_V2_ITEM_SIZE;
    debug!(
        "Decoding V2 binary data: size={} bytes, expected nodes={}",
        data.len(),
        expected_nodes
    );

    let mut updates = Vec::with_capacity(expected_nodes);
    let max_samples = 3;
    let mut samples_logged = 0;

    
    for chunk in data.chunks_exact(WIRE_V2_ITEM_SIZE) {
        let mut cursor = 0;

        
        let wire_id = u32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;

        
        let pos_x = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let pos_y = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let pos_z = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;

        
        let vel_x = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let vel_y = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let vel_z = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;

        
        let _sssp_distance = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let _sssp_parent = i32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);

        
        let full_node_id = from_wire_id_v2(wire_id);

        if samples_logged < max_samples {
            let is_agent = is_agent_node(full_node_id);
            let actual_id = get_actual_node_id(full_node_id);
            debug!(
                "Decoded V2 node wire_id={} -> full_id={} (actual_id={}, is_agent={}): pos=[{:.3},{:.3},{:.3}], vel=[{:.3},{:.3},{:.3}]",
                wire_id, full_node_id, actual_id, is_agent,
                pos_x, pos_y, pos_z,
                vel_x, vel_y, vel_z
            );
            samples_logged += 1;
        }

        let actual_id = get_actual_node_id(full_node_id);
        let server_node_data = BinaryNodeData {
            node_id: actual_id,
            x: pos_x,
            y: pos_y,
            z: pos_z,
            vx: vel_x,
            vy: vel_y,
            vz: vel_z,
        };

        updates.push((actual_id, server_node_data));
    }

    debug!(
        "Successfully decoded {} V2 nodes from binary data",
        updates.len()
    );
    Ok(updates)
}

///
/// Decode Protocol V3 with analytics data (P0-4)
/// Returns standard BinaryNodeData (analytics data is discarded in basic decode)
///
fn decode_node_data_v3(data: &[u8]) -> Result<Vec<(u32, BinaryNodeData)>, String> {
    if data.len() % WIRE_V3_ITEM_SIZE != 0 {
        return Err(format!(
            "Data size {} is not a multiple of V3 wire item size {}",
            data.len(),
            WIRE_V3_ITEM_SIZE
        ));
    }

    let expected_nodes = data.len() / WIRE_V3_ITEM_SIZE;
    debug!(
        "Decoding V3 binary data with analytics: size={} bytes, expected nodes={}",
        data.len(),
        expected_nodes
    );

    let mut updates = Vec::with_capacity(expected_nodes);
    let max_samples = 3;
    let mut samples_logged = 0;

    for chunk in data.chunks_exact(WIRE_V3_ITEM_SIZE) {
        let mut cursor = 0;

        // Node ID (4 bytes)
        let wire_id = u32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;

        // Position (12 bytes)
        let pos_x = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let pos_y = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let pos_z = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;

        // Velocity (12 bytes)
        let vel_x = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let vel_y = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let vel_z = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;

        // SSSP data (8 bytes) - read but not used
        let _sssp_distance = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let _sssp_parent = i32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;

        // Analytics data (12 bytes) - NEW in V3
        let _cluster_id = u32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let _anomaly_score = f32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);
        cursor += 4;
        let _community_id = u32::from_le_bytes([
            chunk[cursor],
            chunk[cursor + 1],
            chunk[cursor + 2],
            chunk[cursor + 3],
        ]);

        let full_node_id = from_wire_id_v2(wire_id);

        if samples_logged < max_samples {
            let is_agent = is_agent_node(full_node_id);
            let actual_id = get_actual_node_id(full_node_id);
            debug!(
                "Decoded V3 node wire_id={} -> full_id={} (actual_id={}, is_agent={}): pos=[{:.3},{:.3},{:.3}], vel=[{:.3},{:.3},{:.3}], cluster={}, anomaly={:.3}, community={}",
                wire_id, full_node_id, actual_id, is_agent,
                pos_x, pos_y, pos_z,
                vel_x, vel_y, vel_z,
                _cluster_id, _anomaly_score, _community_id
            );
            samples_logged += 1;
        }

        let actual_id = get_actual_node_id(full_node_id);
        let server_node_data = BinaryNodeData {
            node_id: actual_id,
            x: pos_x,
            y: pos_y,
            z: pos_z,
            vx: vel_x,
            vy: vel_y,
            vz: vel_z,
        };

        updates.push((actual_id, server_node_data));
    }

    debug!(
        "Successfully decoded {} V3 nodes with analytics from binary data",
        updates.len()
    );
    Ok(updates)
}

pub fn calculate_message_size(updates: &[(u32, BinaryNodeData)]) -> usize {
    // V3 is now the default protocol (48 bytes per node)
    1 + updates.len() * WIRE_V3_ITEM_SIZE
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_wire_format_size() {
        // V1 REMOVED - was 34 bytes, caused node ID truncation
        // V2: 4 + 12 + 12 + 4 + 4 = 36 bytes
        assert_eq!(WIRE_V2_ITEM_SIZE, 36);
        // V3: 4 + 12 + 12 + 4 + 4 + 4 + 4 + 4 = 48 bytes (CURRENT)
        assert_eq!(WIRE_V3_ITEM_SIZE, 48);
        assert_eq!(WIRE_ITEM_SIZE, WIRE_V3_ITEM_SIZE); // Default is now V3
        assert_eq!(
            WIRE_ID_SIZE + WIRE_VEC3_SIZE + WIRE_VEC3_SIZE + WIRE_F32_SIZE + WIRE_I32_SIZE +
            WIRE_U32_SIZE + WIRE_F32_SIZE + WIRE_U32_SIZE,
            48
        );
    }

    #[test]
    fn test_encode_decode_roundtrip() {
        let nodes = vec![
            (
                1u32,
                BinaryNodeData {
                    node_id: 1,
                    x: 1.0,
                    y: 2.0,
                    z: 3.0,
                    vx: 0.1,
                    vy: 0.2,
                    vz: 0.3,
                },
            ),
            (
                2u32,
                BinaryNodeData {
                    node_id: 2,
                    x: 4.0,
                    y: 5.0,
                    z: 6.0,
                    vx: 0.4,
                    vy: 0.5,
                    vz: 0.6,
                },
            ),
        ];

        let encoded = encode_node_data(&nodes);

        // V3 is now the default: 1 header byte + nodes * 48 bytes
        assert_eq!(encoded.len(), 1 + nodes.len() * WIRE_V3_ITEM_SIZE);

        let decoded = decode_node_data(&encoded).unwrap();
        assert_eq!(nodes.len(), decoded.len());

        for ((orig_id, orig_data), (dec_id, dec_data)) in nodes.iter().zip(decoded.iter()) {
            assert_eq!(orig_id, dec_id);
            assert_eq!(orig_data.position(), dec_data.position());
            assert_eq!(orig_data.velocity(), dec_data.velocity());
        }
    }

    #[test]
    fn test_decode_invalid_data() {
        
        let mut data = vec![PROTOCOL_V2]; 
        data.extend_from_slice(&[0u8; 37]); 
        let result = decode_node_data(&data);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("not a multiple of"));

        
        let result = decode_node_data(&[PROTOCOL_V2]);
        assert!(result.is_ok());
        assert_eq!(result.unwrap().len(), 0);
    }

    #[test]
    fn test_message_size_calculation() {
        let nodes = vec![(
            1u32,
            BinaryNodeData {
                node_id: 1,
                x: 1.0,
                y: 2.0,
                z: 3.0,
                vx: 0.1,
                vy: 0.2,
                vz: 0.3,
            },
        )];

        let size = calculate_message_size(&nodes);
        // V3: 1 header + 48 bytes per node
        assert_eq!(size, 1 + 48);

        let encoded = encode_node_data(&nodes);
        assert_eq!(encoded.len(), size);
    }

    #[test]
    fn test_agent_flag_functions() {
        let node_id = 42u32;

        
        let flagged_id = set_agent_flag(node_id);
        assert_eq!(flagged_id, node_id | AGENT_NODE_FLAG);
        assert!(is_agent_node(flagged_id));

        
        let actual_id = get_actual_node_id(flagged_id);
        assert_eq!(actual_id, node_id);

        
        let cleared_id = clear_agent_flag(flagged_id);
        assert_eq!(cleared_id, node_id);
        assert!(!is_agent_node(cleared_id));

        
        assert!(!is_agent_node(node_id));
    }

    #[test]
    fn test_wire_id_conversion() {
        
        let node_id = 42u32;
        let wire_id = to_wire_id(node_id);
        assert_eq!(wire_id, 42u32); 
        assert_eq!(from_wire_id(wire_id), node_id);

        
        let agent_id = set_agent_flag(node_id);
        let agent_wire_id = to_wire_id(agent_id);
        assert_eq!(agent_wire_id & WIRE_V2_NODE_ID_MASK, 42u32);
        assert!((agent_wire_id & WIRE_V2_AGENT_FLAG) != 0);
        assert_eq!(from_wire_id(agent_wire_id), agent_id);

        
        let knowledge_id = set_knowledge_flag(node_id);
        let knowledge_wire_id = to_wire_id(knowledge_id);
        assert_eq!(knowledge_wire_id & WIRE_V2_NODE_ID_MASK, 42u32);
        assert!((knowledge_wire_id & WIRE_V2_KNOWLEDGE_FLAG) != 0);
        assert_eq!(from_wire_id(knowledge_wire_id), knowledge_id);

        
        let large_id = 0x5432u32;
        let wire_id = to_wire_id(large_id);
        assert_eq!(wire_id, 0x5432u32); 
        assert_eq!(from_wire_id(wire_id), large_id);
    }

    #[test]
    fn test_encode_with_agent_flags() {
        let nodes = vec![
            (
                1u32,
                BinaryNodeData {
                    node_id: 1,
                    x: 1.0,
                    y: 2.0,
                    z: 3.0,
                    vx: 0.1,
                    vy: 0.2,
                    vz: 0.3,
                },
            ),
            (
                2u32,
                BinaryNodeData {
                    node_id: 2,
                    x: 4.0,
                    y: 5.0,
                    z: 6.0,
                    vx: 0.4,
                    vy: 0.5,
                    vz: 0.6,
                },
            ),
        ];

        // Mark node 2 as agent
        let agent_ids = vec![2u32];
        let encoded = encode_node_data_with_flags(&nodes, &agent_ids);

        // V3 format: 1 header + nodes * 48 bytes
        assert_eq!(encoded.len(), 1 + nodes.len() * WIRE_V3_ITEM_SIZE);

        let decoded = decode_node_data(&encoded).unwrap();
        assert_eq!(nodes.len(), decoded.len());

        
        for ((orig_id, orig_data), (dec_id, dec_data)) in nodes.iter().zip(decoded.iter()) {
            assert_eq!(orig_id, dec_id); 
            assert_eq!(orig_data.position(), dec_data.position());
            assert_eq!(orig_data.velocity(), dec_data.velocity());
        }
    }

    #[test]
    fn test_large_node_id_no_truncation() {
        
        let large_nodes = vec![
            (
                20000u32,
                BinaryNodeData {
                    node_id: 20000,
                    x: 1.0,
                    y: 2.0,
                    z: 3.0,
                    vx: 0.1,
                    vy: 0.2,
                    vz: 0.3,
                },
            ),
            (
                100000u32,
                BinaryNodeData {
                    node_id: 100000,
                    x: 4.0,
                    y: 5.0,
                    z: 6.0,
                    vx: 0.4,
                    vy: 0.5,
                    vz: 0.6,
                },
            ),
        ];

        
        assert!(needs_v2_protocol(&large_nodes));

        let encoded = encode_node_data(&large_nodes);

        // V3 is now the default protocol
        assert_eq!(encoded[0], PROTOCOL_V3);

        let decoded = decode_node_data(&encoded).unwrap();
        assert_eq!(large_nodes.len(), decoded.len());

        
        assert_eq!(decoded[0].0, 20000u32);
        assert_eq!(decoded[1].0, 100000u32);
    }

    #[test]
    fn test_ontology_node_flags() {
        let node_id = 123u32;

        
        let class_id = set_ontology_class_flag(node_id);
        assert!(is_ontology_class(class_id));
        assert!(is_ontology_node(class_id));
        assert!(!is_ontology_individual(class_id));
        assert!(!is_ontology_property(class_id));
        assert_eq!(get_actual_node_id(class_id), node_id);
        assert_eq!(get_node_type(class_id), NodeType::OntologyClass);

        
        let individual_id = set_ontology_individual_flag(node_id);
        assert!(is_ontology_individual(individual_id));
        assert!(is_ontology_node(individual_id));
        assert!(!is_ontology_class(individual_id));
        assert!(!is_ontology_property(individual_id));
        assert_eq!(get_actual_node_id(individual_id), node_id);
        assert_eq!(get_node_type(individual_id), NodeType::OntologyIndividual);

        
        let property_id = set_ontology_property_flag(node_id);
        assert!(is_ontology_property(property_id));
        assert!(is_ontology_node(property_id));
        assert!(!is_ontology_class(property_id));
        assert!(!is_ontology_individual(property_id));
        assert_eq!(get_actual_node_id(property_id), node_id);
        assert_eq!(get_node_type(property_id), NodeType::OntologyProperty);

        
        assert!(!is_ontology_node(node_id));
        assert!(!is_ontology_class(node_id));
        assert!(!is_ontology_individual(node_id));
        assert!(!is_ontology_property(node_id));
    }

    #[test]
    fn test_encode_with_ontology_types() {
        let nodes = vec![
            (
                1u32,
                BinaryNodeData {
                    node_id: 1,
                    x: 1.0,
                    y: 2.0,
                    z: 3.0,
                    vx: 0.1,
                    vy: 0.2,
                    vz: 0.3,
                },
            ),
            (
                2u32,
                BinaryNodeData {
                    node_id: 2,
                    x: 4.0,
                    y: 5.0,
                    z: 6.0,
                    vx: 0.4,
                    vy: 0.5,
                    vz: 0.6,
                },
            ),
            (
                3u32,
                BinaryNodeData {
                    node_id: 3,
                    x: 7.0,
                    y: 8.0,
                    z: 9.0,
                    vx: 0.7,
                    vy: 0.8,
                    vz: 0.9,
                },
            ),
        ];

        
        let class_ids = vec![1u32];
        let individual_ids = vec![2u32];
        let property_ids = vec![3u32];

        let encoded =
            encode_node_data_extended(&nodes, &[], &[], &class_ids, &individual_ids, &property_ids);

        // V3 format: 1 header + nodes * 48 bytes
        assert_eq!(encoded.len(), 1 + nodes.len() * WIRE_V3_ITEM_SIZE);

        let decoded = decode_node_data(&encoded).unwrap();
        assert_eq!(nodes.len(), decoded.len());

        
        for ((orig_id, orig_data), (dec_id, dec_data)) in nodes.iter().zip(decoded.iter()) {
            assert_eq!(orig_id, dec_id);
            assert_eq!(orig_data.position(), dec_data.position());
            assert_eq!(orig_data.velocity(), dec_data.velocity());
        }
    }

    #[test]
    fn test_ontology_flags_preserved_in_wire_format() {
        let nodes = vec![(
            100u32,
            BinaryNodeData {
                node_id: 100,
                x: 1.0,
                y: 2.0,
                z: 3.0,
                vx: 0.1,
                vy: 0.2,
                vz: 0.3,
            },
        )];

        let class_ids = vec![100u32];
        let encoded = encode_node_data_extended(&nodes, &[], &[], &class_ids, &[], &[]);

        // V3 is now the default protocol
        assert_eq!(encoded[0], PROTOCOL_V3);

        // Wire ID is at offset 1
        let wire_id = u32::from_le_bytes([encoded[1], encoded[2], encoded[3], encoded[4]]);

        
        assert_eq!(wire_id & ONTOLOGY_TYPE_MASK, ONTOLOGY_CLASS_FLAG);
        assert_eq!(wire_id & NODE_ID_MASK, 100u32);
    }

    #[test]
    fn test_v1_protocol_rejected() {
        // V1 protocol should be rejected with clear error message
        let v1_encoded = vec![1u8]; // Protocol version 1
        let result = decode_node_data(&v1_encoded);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("no longer supported"));
    }
}

// Control frame structures for constraint and parameter updates

///
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum ControlFrame {
    
    #[serde(rename = "constraints_update")]
    ConstraintsUpdate {
        version: u32,
        constraints: Vec<Constraint>,
        #[serde(skip_serializing_if = "Option::is_none")]
        advanced_params: Option<AdvancedParams>,
    },

    
    #[serde(rename = "lens_request")]
    LensRequest {
        lens_type: String,
        parameters: serde_json::Value,
    },

    
    #[serde(rename = "control_ack")]
    ControlAck {
        frame_type: String,
        success: bool,
        #[serde(skip_serializing_if = "Option::is_none")]
        message: Option<String>,
    },

    
    #[serde(rename = "physics_params")]
    PhysicsParams { advanced_params: AdvancedParams },

    
    #[serde(rename = "preset_request")]
    PresetRequest { preset_name: String },
}

impl ControlFrame {
    
    pub fn to_bytes(&self) -> Result<Vec<u8>, serde_json::Error> {
        serde_json::to_vec(self)
    }

    
    pub fn from_bytes(bytes: &[u8]) -> Result<Self, serde_json::Error> {
        serde_json::from_slice(bytes)
    }

    
    pub fn constraints_update(
        constraints: Vec<Constraint>,
        params: Option<AdvancedParams>,
    ) -> Self {
        ControlFrame::ConstraintsUpdate {
            version: 1,
            constraints,
            advanced_params: params,
        }
    }

    
    pub fn ack(frame_type: &str, success: bool, message: Option<String>) -> Self {
        ControlFrame::ControlAck {
            frame_type: frame_type.to_string(),
            success,
            message,
        }
    }
}

///
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum MessageType {

    BinaryPositions = 0,

    GraphUpdate = 0x01,

    VoiceData = 0x02,

    ControlFrame = 0x03,

    /// Delta-encoded position updates (Protocol V4)
    /// Frame 0: FULL state, Frames 1-59: DELTA, Frame 60: FULL resync
    PositionDelta = 0x04,

    /// Client acknowledgement of position broadcast (Protocol V3 backpressure)
    /// Enables true end-to-end flow control vs queue-only confirmation
    BroadcastAck = 0x34,
}

///
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum GraphType {
    KnowledgeGraph = 0,
    Ontology = 1,
}

impl GraphType {
    pub fn from_u8(value: u8) -> Result<Self, String> {
        match value {
            0 => Ok(GraphType::KnowledgeGraph),
            1 => Ok(GraphType::Ontology),
            _ => Err(format!("Invalid graph type: {}", value)),
        }
    }

    pub fn to_u8(self) -> u8 {
        match self {
            GraphType::KnowledgeGraph => 0,
            GraphType::Ontology => 1,
        }
    }
}

///
#[derive(Debug, Clone, PartialEq)]
pub enum Message {
    
    GraphUpdate {
        graph_type: GraphType,
        nodes: Vec<(String, [f32; 6])>, 
    },

    VoiceData { audio: Vec<u8> },

    /// Client acknowledgement of position broadcast for backpressure flow control
    BroadcastAck {
        sequence_id: u64,    // Correlates with server broadcast sequence
        nodes_received: u32, // Number of nodes client processed
        timestamp: u64,      // Client receive timestamp (ms since epoch)
    },
}

#[derive(Debug)]
pub enum ProtocolError {
    InvalidMessageType(u8),
    InvalidGraphType(u8),
    InvalidPayloadSize(String),
    EncodingError(String),
    DecodingError(String),
}

impl std::fmt::Display for ProtocolError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            ProtocolError::InvalidMessageType(t) => write!(f, "Invalid message type: {}", t),
            ProtocolError::InvalidGraphType(t) => write!(f, "Invalid graph type: {}", t),
            ProtocolError::InvalidPayloadSize(s) => write!(f, "Invalid payload size: {}", s),
            ProtocolError::EncodingError(s) => write!(f, "Encoding error: {}", s),
            ProtocolError::DecodingError(s) => write!(f, "Decoding error: {}", s),
        }
    }
}

impl std::error::Error for ProtocolError {}

///
pub struct BinaryProtocol;

impl BinaryProtocol {
    
    
    pub fn encode_graph_update(graph_type: GraphType, nodes: &[(String, [f32; 6])]) -> Vec<u8> {
        
        let buffer_size = 2 + nodes.len() * 7 * 4;
        let mut buffer = Vec::with_capacity(buffer_size);

        
        buffer.push(MessageType::GraphUpdate as u8);

        
        buffer.push(graph_type.to_u8());

        
        for (node_id, data) in nodes {
            
            let node_id_f32 = node_id.parse::<f32>().unwrap_or_else(|_| {
                
                let hash = node_id
                    .bytes()
                    .fold(0u32, |acc, b| acc.wrapping_mul(31).wrapping_add(b as u32));
                hash as f32
            });

            buffer.extend_from_slice(&node_id_f32.to_le_bytes());
            buffer.extend_from_slice(&data[0].to_le_bytes()); 
            buffer.extend_from_slice(&data[1].to_le_bytes()); 
            buffer.extend_from_slice(&data[2].to_le_bytes()); 
            buffer.extend_from_slice(&data[3].to_le_bytes()); 
            buffer.extend_from_slice(&data[4].to_le_bytes()); 
            buffer.extend_from_slice(&data[5].to_le_bytes()); 
        }

        buffer
    }

    
    pub fn decode_message(data: &[u8]) -> Result<Message, ProtocolError> {
        if data.is_empty() {
            return Err(ProtocolError::DecodingError("Empty message".to_string()));
        }

        let message_type = data[0];

        match message_type {
            0x01 => Self::decode_graph_update(&data[1..]),
            0x02 => Self::decode_voice_data(&data[1..]),
            0x34 => Self::decode_broadcast_ack(&data[1..]),
            _ => Err(ProtocolError::InvalidMessageType(message_type)),
        }
    }

    
    fn decode_graph_update(data: &[u8]) -> Result<Message, ProtocolError> {
        if data.is_empty() {
            return Err(ProtocolError::InvalidPayloadSize(
                "Empty graph update payload".to_string(),
            ));
        }

        let graph_type =
            GraphType::from_u8(data[0]).map_err(|_| ProtocolError::InvalidGraphType(data[0]))?;

        let payload = &data[1..];

        
        if payload.len() % 28 != 0 {
            return Err(ProtocolError::InvalidPayloadSize(format!(
                "Graph update payload size {} is not a multiple of 28",
                payload.len()
            )));
        }

        let node_count = payload.len() / 28;
        let mut nodes = Vec::with_capacity(node_count);

        for i in 0..node_count {
            let offset = i * 28;
            let chunk = &payload[offset..offset + 28];

            
            let node_id_f32 = f32::from_le_bytes([chunk[0], chunk[1], chunk[2], chunk[3]]);
            let node_id = format!("{:.0}", node_id_f32); 

            
            let x = f32::from_le_bytes([chunk[4], chunk[5], chunk[6], chunk[7]]);
            let y = f32::from_le_bytes([chunk[8], chunk[9], chunk[10], chunk[11]]);
            let z = f32::from_le_bytes([chunk[12], chunk[13], chunk[14], chunk[15]]);
            let vx = f32::from_le_bytes([chunk[16], chunk[17], chunk[18], chunk[19]]);
            let vy = f32::from_le_bytes([chunk[20], chunk[21], chunk[22], chunk[23]]);
            let vz = f32::from_le_bytes([chunk[24], chunk[25], chunk[26], chunk[27]]);

            nodes.push((node_id, [x, y, z, vx, vy, vz]));
        }

        Ok(Message::GraphUpdate { graph_type, nodes })
    }


    fn decode_voice_data(data: &[u8]) -> Result<Message, ProtocolError> {
        Ok(Message::VoiceData {
            audio: data.to_vec(),
        })
    }

    /// Decode client broadcast acknowledgement for backpressure flow control
    /// Payload: 8 bytes sequence_id + 4 bytes nodes_received + 8 bytes timestamp = 20 bytes
    fn decode_broadcast_ack(data: &[u8]) -> Result<Message, ProtocolError> {
        if data.len() < 20 {
            return Err(ProtocolError::InvalidPayloadSize(format!(
                "BroadcastAck payload size {} is less than required 20 bytes",
                data.len()
            )));
        }

        // Decode sequence_id (u64, little-endian)
        let sequence_id = u64::from_le_bytes([
            data[0], data[1], data[2], data[3],
            data[4], data[5], data[6], data[7],
        ]);

        // Decode nodes_received (u32, little-endian)
        let nodes_received = u32::from_le_bytes([
            data[8], data[9], data[10], data[11],
        ]);

        // Decode timestamp (u64, little-endian)
        let timestamp = u64::from_le_bytes([
            data[12], data[13], data[14], data[15],
            data[16], data[17], data[18], data[19],
        ]);

        Ok(Message::BroadcastAck {
            sequence_id,
            nodes_received,
            timestamp,
        })
    }

    
    
    pub fn encode_voice_data(audio: &[u8]) -> Vec<u8> {
        let mut buffer = Vec::with_capacity(1 + audio.len());
        buffer.push(MessageType::VoiceData as u8);
        buffer.extend_from_slice(audio);
        buffer
    }
}

///
pub struct MultiplexedMessage {
    pub msg_type: MessageType,
    pub data: Vec<u8>,
}

impl MultiplexedMessage {
    
    pub fn positions(node_data: &[(u32, BinaryNodeData)]) -> Self {
        Self {
            msg_type: MessageType::BinaryPositions,
            data: encode_node_data(node_data),
        }
    }

    
    pub fn control(frame: &ControlFrame) -> Result<Self, serde_json::Error> {
        Ok(Self {
            msg_type: MessageType::ControlFrame,
            data: frame.to_bytes()?,
        })
    }

    
    pub fn encode(&self) -> Vec<u8> {
        let mut result = Vec::with_capacity(1 + self.data.len());
        result.push(self.msg_type as u8);
        result.extend_from_slice(&self.data);
        result
    }

    
    pub fn decode(data: &[u8]) -> Result<Self, String> {
        if data.is_empty() {
            return Err("Empty message".to_string());
        }

        let msg_type = match data[0] {
            0 => MessageType::BinaryPositions,
            0x01 => MessageType::GraphUpdate,
            0x02 => MessageType::VoiceData,
            0x03 => MessageType::ControlFrame,
            t => return Err(format!("Unknown message type: {}", t)),
        };

        Ok(Self {
            msg_type,
            data: data[1..].to_vec(),
        })
    }
}

#[cfg(test)]
mod control_frame_tests {
    use super::*;
    use crate::models::constraints::ConstraintKind;

    #[test]
    fn test_control_frame_serialization() {
        let constraint = Constraint {
            kind: ConstraintKind::Separation,
            node_indices: vec![1, 2],
            params: vec![100.0],
            weight: 0.8,
            active: true,
        };

        let frame = ControlFrame::constraints_update(vec![constraint], None);
        let bytes = frame.to_bytes().expect("Serialization failed");
        let decoded = ControlFrame::from_bytes(&bytes).expect("Deserialization failed");

        match decoded {
            ControlFrame::ConstraintsUpdate {
                version,
                constraints,
                ..
            } => {
                assert_eq!(version, 1);
                assert_eq!(constraints.len(), 1);
                assert_eq!(constraints[0].kind, ConstraintKind::Separation);
            }
            _ => panic!("Wrong frame type"),
        }
    }

    #[test]
    fn test_multiplexed_message() {
        let nodes = vec![(
            1u32,
            BinaryNodeData {
                node_id: 1,
                x: 1.0,
                y: 2.0,
                z: 3.0,
                vx: 0.1,
                vy: 0.2,
                vz: 0.3,
            },
        )];

        let msg = MultiplexedMessage::positions(&nodes);
        let encoded = msg.encode();

        assert_eq!(encoded[0], 0); 

        let decoded = MultiplexedMessage::decode(&encoded).expect("Decode failed");
        assert_eq!(decoded.msg_type, MessageType::BinaryPositions);
    }

    #[test]
    fn test_simplified_protocol_graph_update() {
        let nodes = vec![
            ("1".to_string(), [1.0, 2.0, 3.0, 0.1, 0.2, 0.3]),
            ("2".to_string(), [4.0, 5.0, 6.0, 0.4, 0.5, 0.6]),
        ];

        
        let encoded = BinaryProtocol::encode_graph_update(GraphType::KnowledgeGraph, &nodes);
        assert_eq!(encoded[0], 0x01); 
        assert_eq!(encoded[1], 0); 
        assert_eq!(encoded.len(), 2 + nodes.len() * 28); 

        
        let decoded = BinaryProtocol::decode_message(&encoded).expect("Message decode failed");
        match decoded {
            Message::GraphUpdate {
                graph_type,
                nodes: decoded_nodes,
            } => {
                assert_eq!(graph_type, GraphType::KnowledgeGraph);
                assert_eq!(decoded_nodes.len(), 2);
                assert_eq!(decoded_nodes[0].1, [1.0, 2.0, 3.0, 0.1, 0.2, 0.3]);
                assert_eq!(decoded_nodes[1].1, [4.0, 5.0, 6.0, 0.4, 0.5, 0.6]);
            }
            _ => panic!("Expected GraphUpdate message"),
        }

        
        let encoded_ont = BinaryProtocol::encode_graph_update(GraphType::Ontology, &nodes);
        assert_eq!(encoded_ont[0], 0x01);
        assert_eq!(encoded_ont[1], 1); 

        let decoded_ont = BinaryProtocol::decode_message(&encoded_ont).expect("Message decode failed");
        match decoded_ont {
            Message::GraphUpdate { graph_type, .. } => {
                assert_eq!(graph_type, GraphType::Ontology);
            }
            _ => panic!("Expected GraphUpdate message"),
        }
    }

    #[test]
    fn test_simplified_protocol_voice_data() {
        let audio = vec![0x12, 0x34, 0x56, 0x78];

        let encoded = BinaryProtocol::encode_voice_data(&audio);
        assert_eq!(encoded[0], 0x02); 
        assert_eq!(encoded.len(), 1 + audio.len());

        let decoded = BinaryProtocol::decode_message(&encoded).expect("Message decode failed");
        match decoded {
            Message::VoiceData {
                audio: decoded_audio,
            } => {
                assert_eq!(decoded_audio, audio);
            }
            _ => panic!("Expected VoiceData message"),
        }
    }

    #[test]
    fn test_protocol_error_handling() {
        
        let result = BinaryProtocol::decode_message(&[]);
        assert!(matches!(result, Err(ProtocolError::DecodingError(_))));

        
        let result = BinaryProtocol::decode_message(&[0xFF]);
        assert!(matches!(
            result,
            Err(ProtocolError::InvalidMessageType(0xFF))
        ));

        
        let result = BinaryProtocol::decode_message(&[0x01, 0xFF]);
        assert!(matches!(result, Err(ProtocolError::InvalidGraphType(0xFF))));

        
        let result = BinaryProtocol::decode_message(&[0x01, 0x00, 0x01, 0x02]); 
        assert!(matches!(result, Err(ProtocolError::InvalidPayloadSize(_))));
    }

    #[test]
    fn test_graph_type_conversions() {
        assert_eq!(GraphType::KnowledgeGraph.to_u8(), 0);
        assert_eq!(GraphType::Ontology.to_u8(), 1);

        assert_eq!(GraphType::from_u8(0).unwrap(), GraphType::KnowledgeGraph);
        assert_eq!(GraphType::from_u8(1).unwrap(), GraphType::Ontology);
        assert!(GraphType::from_u8(2).is_err());
    }
}

--------------------------------------------------------------------------------
FILE: src/utils/nip98.rs
PURPOSE: Nostr NIP-98 HTTP authentication
--------------------------------------------------------------------------------
//! NIP-98 HTTP Authentication for Solid Server Integration
//!
//! Generates Nostr events for HTTP authentication as defined in:
//! - NIP-98: https://nips.nostr.com/98
//! - JIP-0001: https://github.com/JavaScriptSolidServer/jips/blob/main/jip-0001.md
//!
//! Authorization header format: "Nostr <base64-encoded-event>"

use base64::{engine::general_purpose::STANDARD as BASE64, Engine};
use log::{debug, error};
use nostr_sdk::prelude::*;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use thiserror::Error;

/// NIP-98 HTTP Auth event kind (references RFC 7235)
const HTTP_AUTH_KIND: u16 = 27235;

/// Errors from NIP-98 operations
#[derive(Debug, Error)]
pub enum Nip98Error {
    #[error("Failed to create Nostr keys: {0}")]
    KeyCreation(String),
    #[error("Failed to build event: {0}")]
    EventBuild(String),
    #[error("Failed to sign event: {0}")]
    EventSign(String),
    #[error("Failed to serialize event: {0}")]
    Serialization(#[from] serde_json::Error),
}

/// NIP-98 event structure for serialization
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Nip98Event {
    pub id: String,
    pub pubkey: String,
    pub created_at: i64,
    pub kind: u16,
    pub tags: Vec<Vec<String>>,
    pub content: String,
    pub sig: String,
}

/// Configuration for generating NIP-98 tokens
#[derive(Debug, Clone)]
pub struct Nip98Config {
    /// Target URL for the request
    pub url: String,
    /// HTTP method (GET, POST, PUT, DELETE, PATCH, HEAD)
    pub method: String,
    /// Optional request body for payload hash
    pub body: Option<String>,
}

/// Generate a NIP-98 authentication token for a request
///
/// Returns a base64-encoded Nostr event that can be used in the
/// Authorization header as: `Authorization: Nostr <token>`
///
/// # Arguments
/// * `keys` - The Nostr Keys (secret key) to sign with
/// * `config` - Configuration for the NIP-98 request
///
/// # Returns
/// Base64-encoded event string
pub fn generate_nip98_token(keys: &Keys, config: &Nip98Config) -> Result<String, Nip98Error> {
    // Build tags
    let mut tags: Vec<Tag> = vec![
        Tag::custom(TagKind::Custom("u".into()), vec![config.url.clone()]),
        Tag::custom(
            TagKind::Custom("method".into()),
            vec![config.method.to_uppercase()],
        ),
    ];

    // Add payload hash if body is provided
    if let Some(body) = &config.body {
        let hash = compute_payload_hash(body);
        tags.push(Tag::custom(
            TagKind::Custom("payload".into()),
            vec![hash],
        ));
    }

    // Build the event
    let event = EventBuilder::new(Kind::Custom(HTTP_AUTH_KIND), "")
        .tags(tags)
        .sign_with_keys(keys)
        .map_err(|e| Nip98Error::EventSign(e.to_string()))?;

    // Convert to our serialization format
    let nip98_event = Nip98Event {
        id: event.id.to_hex(),
        pubkey: event.pubkey.to_hex(),
        created_at: event.created_at.as_u64() as i64,
        kind: HTTP_AUTH_KIND,
        tags: event
            .tags
            .iter()
            .map(|t| t.as_slice().iter().map(|s| s.to_string()).collect())
            .collect(),
        content: event.content.clone(),
        sig: event.sig.to_string(),
    };

    // Serialize to JSON and base64 encode
    let json = serde_json::to_string(&nip98_event)?;
    let token = BASE64.encode(json.as_bytes());

    debug!(
        "Generated NIP-98 token for {} {} (pubkey: {}...)",
        config.method,
        config.url,
        &nip98_event.pubkey[..16]
    );

    Ok(token)
}

/// Generate NIP-98 token from hex secret key
///
/// # Arguments
/// * `secret_key_hex` - 64-character hex secret key
/// * `config` - Configuration for the NIP-98 request
pub fn generate_nip98_token_from_hex(
    secret_key_hex: &str,
    config: &Nip98Config,
) -> Result<String, Nip98Error> {
    let secret_key = SecretKey::from_hex(secret_key_hex)
        .map_err(|e| Nip98Error::KeyCreation(e.to_string()))?;
    let keys = Keys::new(secret_key);
    generate_nip98_token(&keys, config)
}

/// Compute SHA256 hash of payload for the 'payload' tag
fn compute_payload_hash(body: &str) -> String {
    let mut hasher = Sha256::new();
    hasher.update(body.as_bytes());
    let result = hasher.finalize();
    hex::encode(result)
}

/// Build the Authorization header value
///
/// # Arguments
/// * `token` - The base64-encoded NIP-98 token
///
/// # Returns
/// Full header value: "Nostr <token>"
pub fn build_auth_header(token: &str) -> String {
    format!("Nostr {}", token)
}

/// Extract pubkey from a NIP-98 token (for validation/logging)
pub fn extract_pubkey_from_token(token: &str) -> Option<String> {
    let decoded = BASE64.decode(token).ok()?;
    let json_str = String::from_utf8(decoded).ok()?;
    let event: Nip98Event = serde_json::from_str(&json_str).ok()?;
    Some(event.pubkey)
}

/// Maximum age for NIP-98 tokens (60 seconds per spec)
const TOKEN_MAX_AGE_SECONDS: i64 = 60;

/// Result of NIP-98 token validation
#[derive(Debug, Clone)]
pub struct Nip98ValidationResult {
    pub pubkey: String,
    pub url: String,
    pub method: String,
    pub created_at: i64,
    pub payload_hash: Option<String>,
}

/// Errors specific to token validation
#[derive(Debug, Error)]
pub enum Nip98ValidationError {
    #[error("Invalid base64 encoding")]
    InvalidBase64,
    #[error("Invalid UTF-8 in token")]
    InvalidUtf8,
    #[error("Invalid JSON structure: {0}")]
    InvalidJson(String),
    #[error("Invalid event kind: expected {HTTP_AUTH_KIND}, got {0}")]
    InvalidKind(u16),
    #[error("Token expired: created {0}s ago (max {TOKEN_MAX_AGE_SECONDS}s)")]
    TokenExpired(i64),
    #[error("Missing required tag: {0}")]
    MissingTag(String),
    #[error("URL mismatch: expected {expected}, got {actual}")]
    UrlMismatch { expected: String, actual: String },
    #[error("Method mismatch: expected {expected}, got {actual}")]
    MethodMismatch { expected: String, actual: String },
    #[error("Payload hash mismatch")]
    PayloadHashMismatch,
    #[error("Invalid signature")]
    InvalidSignature,
    #[error("Failed to verify event: {0}")]
    VerificationFailed(String),
}

/// Validate a NIP-98 token from an Authorization header
///
/// # Arguments
/// * `token` - The base64-encoded token (without "Nostr " prefix)
/// * `expected_url` - The URL the request was made to
/// * `expected_method` - The HTTP method used
/// * `request_body` - Optional request body for payload verification
///
/// # Returns
/// Validation result with pubkey and metadata, or validation error
pub fn validate_nip98_token(
    token: &str,
    expected_url: &str,
    expected_method: &str,
    request_body: Option<&str>,
) -> Result<Nip98ValidationResult, Nip98ValidationError> {
    // Decode base64
    let decoded = BASE64
        .decode(token)
        .map_err(|_| Nip98ValidationError::InvalidBase64)?;

    let json_str =
        String::from_utf8(decoded).map_err(|_| Nip98ValidationError::InvalidUtf8)?;

    // Parse the event
    let nip98_event: Nip98Event = serde_json::from_str(&json_str)
        .map_err(|e| Nip98ValidationError::InvalidJson(e.to_string()))?;

    // Verify event kind
    if nip98_event.kind != HTTP_AUTH_KIND {
        return Err(Nip98ValidationError::InvalidKind(nip98_event.kind));
    }

    // Check timestamp (60 second window)
    let now = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs() as i64;
    let age = now - nip98_event.created_at;

    if age > TOKEN_MAX_AGE_SECONDS {
        return Err(Nip98ValidationError::TokenExpired(age));
    }

    // Also reject tokens from the future (clock skew protection)
    if age < -TOKEN_MAX_AGE_SECONDS {
        return Err(Nip98ValidationError::TokenExpired(age));
    }

    // Extract and validate tags
    let mut url: Option<String> = None;
    let mut method: Option<String> = None;
    let mut payload_hash: Option<String> = None;

    for tag in &nip98_event.tags {
        if tag.len() >= 2 {
            match tag[0].as_str() {
                "u" => url = Some(tag[1].clone()),
                "method" => method = Some(tag[1].clone()),
                "payload" => payload_hash = Some(tag[1].clone()),
                _ => {}
            }
        }
    }

    let url = url.ok_or_else(|| Nip98ValidationError::MissingTag("u".to_string()))?;
    let method = method.ok_or_else(|| Nip98ValidationError::MissingTag("method".to_string()))?;

    // Validate URL matches (normalize for comparison)
    let normalized_expected = normalize_url(expected_url);
    let normalized_actual = normalize_url(&url);
    if normalized_expected != normalized_actual {
        return Err(Nip98ValidationError::UrlMismatch {
            expected: expected_url.to_string(),
            actual: url,
        });
    }

    // Validate method matches
    if method.to_uppercase() != expected_method.to_uppercase() {
        return Err(Nip98ValidationError::MethodMismatch {
            expected: expected_method.to_string(),
            actual: method,
        });
    }

    // Validate payload hash if body provided
    if let Some(body) = request_body {
        let computed_hash = compute_payload_hash(body);
        if let Some(ref token_hash) = payload_hash {
            if &computed_hash != token_hash {
                return Err(Nip98ValidationError::PayloadHashMismatch);
            }
        }
    }

    // Verify the Nostr event signature
    let nostr_event = Event::from_json(&json_str)
        .map_err(|e| Nip98ValidationError::VerificationFailed(e.to_string()))?;

    nostr_event
        .verify()
        .map_err(|_| Nip98ValidationError::InvalidSignature)?;

    debug!(
        "Validated NIP-98 token for {} {} (pubkey: {}...)",
        method,
        url,
        &nip98_event.pubkey[..16.min(nip98_event.pubkey.len())]
    );

    Ok(Nip98ValidationResult {
        pubkey: nip98_event.pubkey,
        url,
        method,
        created_at: nip98_event.created_at,
        payload_hash,
    })
}

/// Parse Authorization header and extract NIP-98 token
///
/// # Arguments
/// * `auth_header` - Full Authorization header value (e.g., "Nostr <base64>")
///
/// # Returns
/// The base64 token portion if valid Nostr auth, None otherwise
pub fn parse_auth_header(auth_header: &str) -> Option<&str> {
    let trimmed = auth_header.trim();
    if trimmed.starts_with("Nostr ") {
        Some(trimmed.strip_prefix("Nostr ")?.trim())
    } else {
        None
    }
}

/// Normalize URL for comparison (remove trailing slashes, lowercase scheme/host)
fn normalize_url(url: &str) -> String {
    let mut normalized = url.trim().to_string();

    // Remove trailing slash for comparison
    while normalized.ends_with('/') && normalized.len() > 1 {
        normalized.pop();
    }

    // Lowercase the scheme and host portion
    if let Some(idx) = normalized.find("://") {
        let (scheme, rest) = normalized.split_at(idx);
        let rest = &rest[3..]; // Skip "://"

        if let Some(path_idx) = rest.find('/') {
            let host = &rest[..path_idx];
            let path = &rest[path_idx..];
            normalized = format!("{}://{}{}", scheme.to_lowercase(), host.to_lowercase(), path);
        } else {
            normalized = format!("{}://{}", scheme.to_lowercase(), rest.to_lowercase());
        }
    }

    normalized
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_generate_nip98_token() {
        let keys = Keys::generate();
        let config = Nip98Config {
            url: "http://localhost:3030/pods/test/".to_string(),
            method: "GET".to_string(),
            body: None,
        };

        let token = generate_nip98_token(&keys, &config).expect("Failed to generate token");
        assert!(!token.is_empty());

        // Verify we can extract the pubkey
        let pubkey = extract_pubkey_from_token(&token).expect("Failed to extract pubkey");
        assert_eq!(pubkey, keys.public_key().to_hex());
    }

    #[test]
    fn test_generate_nip98_token_with_body() {
        let keys = Keys::generate();
        let config = Nip98Config {
            url: "http://localhost:3030/pods/test/data.jsonld".to_string(),
            method: "PUT".to_string(),
            body: Some(r#"{"@context": "https://schema.org"}"#.to_string()),
        };

        let token = generate_nip98_token(&keys, &config).expect("Failed to generate token");
        assert!(!token.is_empty());
    }

    #[test]
    fn test_payload_hash() {
        let body = r#"{"test": "data"}"#;
        let hash = compute_payload_hash(body);
        assert_eq!(hash.len(), 64); // SHA256 hex is 64 chars
    }

    #[test]
    fn test_build_auth_header() {
        let token = "dGVzdA==";
        let header = build_auth_header(token);
        assert_eq!(header, "Nostr dGVzdA==");
    }

    #[test]
    fn test_parse_auth_header() {
        assert_eq!(parse_auth_header("Nostr abc123"), Some("abc123"));
        assert_eq!(parse_auth_header("  Nostr xyz  "), Some("xyz"));
        assert_eq!(parse_auth_header("Bearer abc123"), None);
        assert_eq!(parse_auth_header("nostr abc123"), None); // case sensitive
    }

    #[test]
    fn test_normalize_url() {
        assert_eq!(
            normalize_url("HTTP://LOCALHOST:3030/pods/test/"),
            "http://localhost:3030/pods/test"
        );
        assert_eq!(
            normalize_url("https://Example.COM/path"),
            "https://example.com/path"
        );
        assert_eq!(normalize_url("http://a.com///"), "http://a.com");
    }

    #[test]
    fn test_validate_nip98_token_valid() {
        let keys = Keys::generate();
        let url = "http://localhost:3030/pods/test/";
        let method = "GET";
        let config = Nip98Config {
            url: url.to_string(),
            method: method.to_string(),
            body: None,
        };

        let token = generate_nip98_token(&keys, &config).expect("Failed to generate token");
        let result = validate_nip98_token(&token, url, method, None);

        assert!(result.is_ok(), "Validation failed: {:?}", result.err());
        let validation = result.unwrap();
        assert_eq!(validation.pubkey, keys.public_key().to_hex());
        assert_eq!(validation.method.to_uppercase(), method);
    }

    #[test]
    fn test_validate_nip98_token_with_payload() {
        let keys = Keys::generate();
        let url = "http://localhost:3030/pods/test/data.jsonld";
        let method = "PUT";
        let body = r#"{"@context": "https://schema.org"}"#;
        let config = Nip98Config {
            url: url.to_string(),
            method: method.to_string(),
            body: Some(body.to_string()),
        };

        let token = generate_nip98_token(&keys, &config).expect("Failed to generate token");
        let result = validate_nip98_token(&token, url, method, Some(body));

        assert!(result.is_ok(), "Validation failed: {:?}", result.err());
        let validation = result.unwrap();
        assert!(validation.payload_hash.is_some());
    }

    #[test]
    fn test_validate_nip98_token_url_mismatch() {
        let keys = Keys::generate();
        let config = Nip98Config {
            url: "http://localhost:3030/pods/alice/".to_string(),
            method: "GET".to_string(),
            body: None,
        };

        let token = generate_nip98_token(&keys, &config).expect("Failed to generate token");
        let result = validate_nip98_token(&token, "http://localhost:3030/pods/bob/", "GET", None);

        assert!(matches!(result, Err(Nip98ValidationError::UrlMismatch { .. })));
    }

    #[test]
    fn test_validate_nip98_token_method_mismatch() {
        let keys = Keys::generate();
        let config = Nip98Config {
            url: "http://localhost:3030/pods/test/".to_string(),
            method: "GET".to_string(),
            body: None,
        };

        let token = generate_nip98_token(&keys, &config).expect("Failed to generate token");
        let result = validate_nip98_token(&token, "http://localhost:3030/pods/test/", "POST", None);

        assert!(matches!(
            result,
            Err(Nip98ValidationError::MethodMismatch { .. })
        ));
    }

    #[test]
    fn test_validate_nip98_token_invalid_base64() {
        let result = validate_nip98_token("not-valid-base64!!!", "http://test.com", "GET", None);
        assert!(matches!(result, Err(Nip98ValidationError::InvalidBase64)));
    }
}

================================================================================
                    SECTION 10: CQRS & EVENT SYSTEM
================================================================================

--------------------------------------------------------------------------------
FILE: src/cqrs/mod.rs
PURPOSE: CQRS module exports
--------------------------------------------------------------------------------
// src/cqrs/mod.rs
//! CQRS (Command Query Responsibility Segregation) Application Layer
//!
//! This module implements the CQRS pattern to separate read and write operations.
//! It provides a clean application layer between API handlers and repositories/adapters.
//!
//! # Architecture
//!
//! ```text
//! API Handlers
//!     
//! Command/Query Bus
//!     
//! Command/Query Handlers
//!     
//! Repositories/Adapters
//! ```
//!
//! # Usage
//!
//! ```rust
//! use crate::cqrs::{CommandBus, QueryBus};
//! use crate::cqrs::commands::AddNodeCommand;
//! use crate::cqrs::queries::GetNodeQuery;
//!
//! 
//! let command = AddNodeCommand { node };
//! let node_id = command_bus.execute(command).await?;
//!
//! 
//! let query = GetNodeQuery { node_id };
//! let node = query_bus.execute(query).await?;
//! ```

pub mod bus;
pub mod commands;
pub mod handlers;
pub mod queries;
pub mod types;

// Re-export main types
pub use bus::{CommandBus, QueryBus};
pub use types::{Command, CommandHandler, Query, QueryHandler, Result};

--------------------------------------------------------------------------------
FILE: src/cqrs/bus.rs
PURPOSE: Command and Query bus implementations
--------------------------------------------------------------------------------
// src/cqrs/bus.rs
//! Command and Query Bus Implementation
//!
//! The bus routes commands and queries to their respective handlers.
//! It provides middleware support for cross-cutting concerns.

use crate::cqrs::types::{
    Command, CommandHandler, CommandMiddleware, Query, QueryHandler, QueryMiddleware, Result,
};
use async_trait::async_trait;
use std::any::{Any, TypeId};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;

///
///
///
///
pub struct CommandBus {
    handlers: Arc<RwLock<HashMap<TypeId, Box<dyn Any + Send + Sync>>>>,
    middleware: Arc<Vec<Box<dyn CommandMiddleware>>>,
}

impl CommandBus {
    
    pub fn new() -> Self {
        Self {
            handlers: Arc::new(RwLock::new(HashMap::new())),
            middleware: Arc::new(Vec::new()),
        }
    }

    
    pub fn with_middleware(middleware: Vec<Box<dyn CommandMiddleware>>) -> Self {
        Self {
            handlers: Arc::new(RwLock::new(HashMap::new())),
            middleware: Arc::new(middleware),
        }
    }

    
    pub async fn register<C: Command + 'static>(&self, handler: Box<dyn CommandHandler<C>>) {
        let type_id = TypeId::of::<C>();
        let mut handlers = self.handlers.write().await;
        handlers.insert(type_id, Box::new(handler));
    }

    
    
    
    
    
    
    
    
    pub async fn execute<C: Command + 'static>(&self, command: C) -> Result<C::Result>
    where
        C::Result: 'static,
    {
        let command_name = command.name();

        
        for mw in self.middleware.iter() {
            mw.before_execute(command_name).await?;
        }

        
        let result = async {
            let type_id = TypeId::of::<C>();
            let handlers = self.handlers.read().await;

            let handler = handlers.get(&type_id).ok_or_else(|| {
                anyhow::anyhow!("No handler registered for command: {}", command_name)
            })?;

            let handler = handler
                .downcast_ref::<Box<dyn CommandHandler<C>>>()
                .ok_or_else(|| {
                    anyhow::anyhow!("Handler type mismatch for command: {}", command_name)
                })?;

            handler.handle(command).await
        }
        .await;

        
        match &result {
            Ok(_) => {
                for mw in self.middleware.iter() {
                    mw.after_execute(command_name).await?;
                }
            }
            Err(e) => {
                for mw in self.middleware.iter() {
                    mw.on_error(command_name, e).await?;
                }
            }
        }

        result
    }
}

impl Default for CommandBus {
    fn default() -> Self {
        Self::new()
    }
}

///
///
///
///
pub struct QueryBus {
    handlers: Arc<RwLock<HashMap<TypeId, Box<dyn Any + Send + Sync>>>>,
    middleware: Arc<Vec<Box<dyn QueryMiddleware>>>,
}

impl QueryBus {
    
    pub fn new() -> Self {
        Self {
            handlers: Arc::new(RwLock::new(HashMap::new())),
            middleware: Arc::new(Vec::new()),
        }
    }

    
    pub fn with_middleware(middleware: Vec<Box<dyn QueryMiddleware>>) -> Self {
        Self {
            handlers: Arc::new(RwLock::new(HashMap::new())),
            middleware: Arc::new(middleware),
        }
    }

    
    pub async fn register<Q: Query + 'static>(&self, handler: Box<dyn QueryHandler<Q>>) {
        let type_id = TypeId::of::<Q>();
        let mut handlers = self.handlers.write().await;
        handlers.insert(type_id, Box::new(handler));
    }

    
    
    
    
    
    
    
    
    pub async fn execute<Q: Query + 'static>(&self, query: Q) -> Result<Q::Result>
    where
        Q::Result: 'static,
    {
        let query_name = query.name();

        
        for mw in self.middleware.iter() {
            mw.before_execute(query_name).await?;
        }

        
        let result = async {
            let type_id = TypeId::of::<Q>();
            let handlers = self.handlers.read().await;

            let handler = handlers.get(&type_id).ok_or_else(|| {
                anyhow::anyhow!("No handler registered for query: {}", query_name)
            })?;

            let handler = handler
                .downcast_ref::<Box<dyn QueryHandler<Q>>>()
                .ok_or_else(|| {
                    anyhow::anyhow!("Handler type mismatch for query: {}", query_name)
                })?;

            handler.handle(query).await
        }
        .await;

        
        match &result {
            Ok(_) => {
                for mw in self.middleware.iter() {
                    mw.after_execute(query_name).await?;
                }
            }
            Err(e) => {
                for mw in self.middleware.iter() {
                    mw.on_error(query_name, e).await?;
                }
            }
        }

        result
    }
}

impl Default for QueryBus {
    fn default() -> Self {
        Self::new()
    }
}

///
pub struct MetricsMiddleware {
    command_counts: Arc<RwLock<HashMap<String, u64>>>,
    query_counts: Arc<RwLock<HashMap<String, u64>>>,
}

impl MetricsMiddleware {
    pub fn new() -> Self {
        Self {
            command_counts: Arc::new(RwLock::new(HashMap::new())),
            query_counts: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    pub async fn get_command_count(&self, command_name: &str) -> u64 {
        let counts = self.command_counts.read().await;
        *counts.get(command_name).unwrap_or(&0)
    }

    pub async fn get_query_count(&self, query_name: &str) -> u64 {
        let counts = self.query_counts.read().await;
        *counts.get(query_name).unwrap_or(&0)
    }
}

impl Default for MetricsMiddleware {
    fn default() -> Self {
        Self::new()
    }
}

#[async_trait]
impl CommandMiddleware for MetricsMiddleware {
    async fn after_execute(&self, command_name: &str) -> Result<()> {
        let mut counts = self.command_counts.write().await;
        *counts.entry(command_name.to_string()).or_insert(0) += 1;
        Ok(())
    }
}

#[async_trait]
impl QueryMiddleware for MetricsMiddleware {
    async fn after_execute(&self, query_name: &str) -> Result<()> {
        let mut counts = self.query_counts.write().await;
        *counts.entry(query_name.to_string()).or_insert(0) += 1;
        Ok(())
    }
}

// NOTE: Tests disabled due to:
// 1. MetricsMiddleware doesn't implement CommandMiddleware trait
// To re-enable: Implement CommandMiddleware trait for MetricsMiddleware
/*
#[cfg(test)]
mod tests {
    use super::*;
    use crate::cqrs::types::Command;

    #[derive(Debug, Clone)]
    struct TestCommand {
        value: String,
    }

    impl Command for TestCommand {
        type Result = String;

        fn name(&self) -> &'static str {
            "TestCommand"
        }

        fn validate(&self) -> Result<()> {
            if self.value.is_empty() {
                return Err(anyhow::anyhow!("Value cannot be empty"));
            }
            Ok(())
        }
    }

    struct TestCommandHandler;

    #[async_trait]
    impl CommandHandler<TestCommand> for TestCommandHandler {
        async fn handle(&self, command: TestCommand) -> Result<String> {
            command.validate()?;
            Ok(format!("Handled: {}", command.value))
        }
    }

    #[tokio::test]
    async fn test_command_bus_execute() {
        let bus = CommandBus::new();
        bus.register(Box::new(TestCommandHandler)).await;

        let command = TestCommand {
            value: "test".to_string(),
        };
        let result = bus.execute(command).await;
        assert!(result.is_ok());
        assert_eq!(result.unwrap(), "Handled: test");
    }

    #[tokio::test]
    async fn test_command_bus_validation() {
        let bus = CommandBus::new();
        bus.register(Box::new(TestCommandHandler)).await;

        let command = TestCommand {
            value: "".to_string(),
        };
        let result = bus.execute(command).await;
        assert!(result.is_err());
    }

    #[tokio::test]
    async fn test_command_bus_no_handler() {
        let bus = CommandBus::new();

        let command = TestCommand {
            value: "test".to_string(),
        };
        let result = bus.execute(command).await;
        assert!(result.is_err());
    }

    #[tokio::test]
    async fn test_metrics_middleware() {
        let metrics = Arc::new(MetricsMiddleware::new());
        let bus = CommandBus::with_middleware(vec![Box::new(metrics.clone())]);
        bus.register(Box::new(TestCommandHandler)).await;

        let command = TestCommand {
            value: "test".to_string(),
        };
        bus.execute(command).await.unwrap();

        let count = metrics.get_command_count("TestCommand").await;
        assert_eq!(count, 1);
    }
}
*/

--------------------------------------------------------------------------------
FILE: src/cqrs/types.rs
PURPOSE: CQRS type definitions (Command, Query traits)
--------------------------------------------------------------------------------
// src/cqrs/types.rs
//! CQRS Base Types and Traits
//!
//! Defines the fundamental traits for the Command Query Responsibility Segregation pattern.
//! Commands represent write operations, Queries represent read operations.

use async_trait::async_trait;
use std::fmt::Debug;

///
pub type Result<T> = anyhow::Result<T>;

///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
pub trait Command: Send + Sync + Debug {
    
    type Result: Send;

    
    fn name(&self) -> &'static str;

    
    
    
    
    fn validate(&self) -> Result<()> {
        Ok(())
    }
}

///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
///
pub trait Query: Send + Sync + Debug {
    
    type Result: Send;

    
    fn name(&self) -> &'static str;

    
    fn validate(&self) -> Result<()> {
        Ok(())
    }
}

///
///
///
///
#[async_trait]
pub trait CommandHandler<C: Command>: Send + Sync {
    
    
    
    
    async fn handle(&self, command: C) -> Result<C::Result>;
}

///
///
///
///
#[async_trait]
pub trait QueryHandler<Q: Query>: Send + Sync {
    
    
    
    
    async fn handle(&self, query: Q) -> Result<Q::Result>;
}

///
///
///
///
#[async_trait]
pub trait CommandMiddleware: Send + Sync {
    
    async fn before_execute(&self, command_name: &str) -> Result<()> {
        Ok(())
    }

    
    async fn after_execute(&self, command_name: &str) -> Result<()> {
        Ok(())
    }

    
    async fn on_error(&self, command_name: &str, error: &anyhow::Error) -> Result<()> {
        Ok(())
    }
}

///
#[async_trait]
pub trait QueryMiddleware: Send + Sync {
    
    async fn before_execute(&self, query_name: &str) -> Result<()> {
        Ok(())
    }

    
    async fn after_execute(&self, query_name: &str) -> Result<()> {
        Ok(())
    }

    
    async fn on_error(&self, query_name: &str, error: &anyhow::Error) -> Result<()> {
        Ok(())
    }
}

///
pub struct LoggingMiddleware;

#[async_trait]
impl CommandMiddleware for LoggingMiddleware {
    async fn before_execute(&self, command_name: &str) -> Result<()> {
        tracing::info!(command = %command_name, "Executing command");
        Ok(())
    }

    async fn after_execute(&self, command_name: &str) -> Result<()> {
        tracing::info!(command = %command_name, "Command executed successfully");
        Ok(())
    }

    async fn on_error(&self, command_name: &str, error: &anyhow::Error) -> Result<()> {
        tracing::error!(command = %command_name, error = %error, "Command execution failed");
        Ok(())
    }
}

#[async_trait]
impl QueryMiddleware for LoggingMiddleware {
    async fn before_execute(&self, query_name: &str) -> Result<()> {
        tracing::debug!(query = %query_name, "Executing query");
        Ok(())
    }

    async fn after_execute(&self, query_name: &str) -> Result<()> {
        tracing::debug!(query = %query_name, "Query executed successfully");
        Ok(())
    }

    async fn on_error(&self, query_name: &str, error: &anyhow::Error) -> Result<()> {
        tracing::warn!(query = %query_name, error = %error, "Query execution failed");
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[derive(Debug, Clone)]
    struct TestCommand {
        value: String,
    }

    impl Command for TestCommand {
        type Result = ();

        fn name(&self) -> &'static str {
            "TestCommand"
        }

        fn validate(&self) -> Result<()> {
            if self.value.is_empty() {
                return Err(anyhow::anyhow!("Value cannot be empty"));
            }
            Ok(())
        }
    }

    #[derive(Debug, Clone)]
    struct TestQuery {
        id: u32,
    }

    impl Query for TestQuery {
        type Result = String;

        fn name(&self) -> &'static str {
            "TestQuery"
        }
    }

    #[test]
    fn test_command_validation() {
        let valid = TestCommand {
            value: "test".to_string(),
        };
        assert!(valid.validate().is_ok());

        let invalid = TestCommand {
            value: "".to_string(),
        };
        assert!(invalid.validate().is_err());
    }

    #[test]
    fn test_command_name() {
        let cmd = TestCommand {
            value: "test".to_string(),
        };
        assert_eq!(cmd.name(), "TestCommand");
    }

    #[test]
    fn test_query_name() {
        let query = TestQuery { id: 1 };
        assert_eq!(query.name(), "TestQuery");
    }
}

--------------------------------------------------------------------------------
FILE: src/events/mod.rs
PURPOSE: Event system module exports
--------------------------------------------------------------------------------
pub mod bus;
pub mod domain_events;
pub mod handlers;
pub mod middleware;
pub mod store;
pub mod types;

// Phase 7: Inference triggers
pub mod inference_triggers;

pub use types::{
    DomainEvent, EventError, EventHandler, EventMetadata, EventMiddleware, EventResult,
    EventSnapshot, StoredEvent,
};

pub use domain_events::*;

pub use bus::EventBus;

// Re-export EventBus in event_bus module for backward compatibility
pub mod event_bus {
    pub use super::bus::EventBus;
}

pub use store::{EventRepository, EventStore, InMemoryEventRepository};

pub use middleware::{
    EnrichmentMiddleware, LoggingMiddleware, MetricsMiddleware, RetryMiddleware,
    ValidationMiddleware,
};

pub use handlers::{
    AuditEventHandler, GraphEventHandler, NotificationEventHandler, OntologyEventHandler,
};

pub use inference_triggers::{
    InferenceTriggerHandler, AutoInferenceConfig, OntologyEvent,
    register_inference_triggers,
};

--------------------------------------------------------------------------------
FILE: src/events/bus.rs
PURPOSE: EventBus for publish/subscribe
--------------------------------------------------------------------------------
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;

use crate::events::types::{
    DomainEvent, EventError, EventHandler, EventMetadata, EventMiddleware, EventResult, StoredEvent,
};

///
pub struct EventBus {
    
    subscribers: Arc<RwLock<HashMap<String, Vec<Arc<dyn EventHandler>>>>>,

    
    middleware: Arc<RwLock<Vec<Arc<dyn EventMiddleware>>>>,

    
    sequence: Arc<RwLock<i64>>,

    
    enabled: Arc<RwLock<bool>>,
}

impl EventBus {
    
    pub fn new() -> Self {
        Self {
            subscribers: Arc::new(RwLock::new(HashMap::new())),
            middleware: Arc::new(RwLock::new(Vec::new())),
            sequence: Arc::new(RwLock::new(0)),
            enabled: Arc::new(RwLock::new(true)),
        }
    }

    
    pub async fn publish<E: DomainEvent>(&self, event: E) -> EventResult<()> {
        
        if !*self.enabled.read().await {
            return Ok(());
        }

        
        let metadata = EventMetadata::new(
            event.aggregate_id().to_string(),
            event.aggregate_type().to_string(),
            event.event_type().to_string(),
        );

        
        let data = event.to_json_string().map_err(|e| EventError::Serialization(e.to_string()))?;

        
        let mut seq = self.sequence.write().await;
        *seq += 1;
        let sequence = *seq;
        drop(seq);

        
        let mut stored_event = StoredEvent {
            metadata,
            data,
            sequence,
        };

        
        let middleware = self.middleware.read().await;
        for mw in middleware.iter() {
            mw.before_publish(&mut stored_event).await?;
        }
        drop(middleware);

        
        let subscribers = self.subscribers.read().await;
        let handlers = subscribers
            .get(event.event_type())
            .cloned()
            .unwrap_or_default();
        drop(subscribers);

        
        let handler_count = handlers.len();
        let mut errors = Vec::new();
        for handler in handlers {
            match self.execute_handler(handler.clone(), &stored_event).await {
                Ok(_) => {}
                Err(e) => {
                    eprintln!("Handler {} failed: {}", handler.handler_id(), e);
                    errors.push((handler.handler_id().to_string(), e));
                }
            }
        }

        
        let middleware = self.middleware.read().await;
        for mw in middleware.iter() {
            mw.after_publish(&stored_event).await?;
        }
        drop(middleware);

        
        if !errors.is_empty() && errors.len() == handler_count {
            return Err(EventError::Handler(format!(
                "All {} handlers failed",
                errors.len()
            )));
        }

        Ok(())
    }

    
    pub async fn subscribe(&self, handler: Arc<dyn EventHandler>) {
        let event_type = handler.event_type().to_string();
        let mut subscribers = self.subscribers.write().await;

        subscribers
            .entry(event_type)
            .or_insert_with(Vec::new)
            .push(handler);
    }

    
    pub async fn unsubscribe(&self, handler_id: &str, event_type: &str) {
        let mut subscribers = self.subscribers.write().await;

        if let Some(handlers) = subscribers.get_mut(event_type) {
            handlers.retain(|h| h.handler_id() != handler_id);
        }
    }

    
    pub async fn add_middleware(&self, middleware: Arc<dyn EventMiddleware>) {
        let mut mw_list = self.middleware.write().await;
        mw_list.push(middleware);
    }

    
    async fn execute_handler(
        &self,
        handler: Arc<dyn EventHandler>,
        event: &StoredEvent,
    ) -> EventResult<()> {
        let handler_id = handler.handler_id();
        let max_retries = handler.max_retries();

        
        let middleware = self.middleware.read().await;
        for mw in middleware.iter() {
            mw.before_handle(event, handler_id).await?;
        }
        drop(middleware);

        
        let mut last_error = None;
        for attempt in 0..=max_retries {
            match handler.handle(event).await {
                Ok(_) => {
                    
                    let middleware = self.middleware.read().await;
                    for mw in middleware.iter() {
                        mw.after_handle(event, handler_id, &Ok(())).await?;
                    }
                    return Ok(());
                }
                Err(e) => {
                    last_error = Some(e);
                    if attempt < max_retries {
                        
                        let delay = std::time::Duration::from_millis(100 * 2_u64.pow(attempt));
                        tokio::time::sleep(delay).await;
                    }
                }
            }
        }

        
        let error = last_error.unwrap();
        let result = Err(error.clone());

        
        let middleware = self.middleware.read().await;
        for mw in middleware.iter() {
            let _ = mw.after_handle(event, handler_id, &result).await;
        }

        Err(error)
    }

    
    pub async fn subscriber_count(&self, event_type: &str) -> usize {
        let subscribers = self.subscribers.read().await;
        subscribers.get(event_type).map(|h| h.len()).unwrap_or(0)
    }

    
    pub async fn clear_subscribers(&self) {
        let mut subscribers = self.subscribers.write().await;
        subscribers.clear();
    }

    
    pub async fn set_enabled(&self, enabled: bool) {
        let mut flag = self.enabled.write().await;
        *flag = enabled;
    }

    
    pub async fn is_enabled(&self) -> bool {
        *self.enabled.read().await
    }

    
    pub async fn current_sequence(&self) -> i64 {
        *self.sequence.read().await
    }
}

impl Default for EventBus {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use async_trait::async_trait;
    use chrono::Utc;
    use crate::events::domain_events::NodeAddedEvent;
    use std::sync::atomic::{AtomicUsize, Ordering};
use crate::utils::time;

    struct TestHandler {
        id: String,
        call_count: Arc<AtomicUsize>,
    }

    #[async_trait]
    impl EventHandler for TestHandler {
        fn event_type(&self) -> &'static str {
            "NodeAdded"
        }

        fn handler_id(&self) -> &str {
            &self.id
        }

        async fn handle(&self, _event: &StoredEvent) -> Result<(), EventError> {
            self.call_count.fetch_add(1, Ordering::SeqCst);
            Ok(())
        }
    }

    #[tokio::test]
    async fn test_event_bus_publish() {
        let bus = EventBus::new();
        let call_count = Arc::new(AtomicUsize::new(0));

        let handler = Arc::new(TestHandler {
            id: "test-handler".to_string(),
            call_count: call_count.clone(),
        });

        bus.subscribe(handler).await;

        let event = NodeAddedEvent {
            node_id: "node-1".to_string(),
            label: "Test".to_string(),
            node_type: "Person".to_string(),
            properties: HashMap::new(),
            timestamp: time::now(),
        };

        bus.publish(event).await.unwrap();

        assert_eq!(call_count.load(Ordering::SeqCst), 1);
    }

    #[tokio::test]
    async fn test_multiple_subscribers() {
        let bus = EventBus::new();
        let count1 = Arc::new(AtomicUsize::new(0));
        let count2 = Arc::new(AtomicUsize::new(0));

        bus.subscribe(Arc::new(TestHandler {
            id: "handler-1".to_string(),
            call_count: count1.clone(),
        }))
        .await;

        bus.subscribe(Arc::new(TestHandler {
            id: "handler-2".to_string(),
            call_count: count2.clone(),
        }))
        .await;

        let event = NodeAddedEvent {
            node_id: "node-1".to_string(),
            label: "Test".to_string(),
            node_type: "Person".to_string(),
            properties: HashMap::new(),
            timestamp: time::now(),
        };

        bus.publish(event).await.unwrap();

        assert_eq!(count1.load(Ordering::SeqCst), 1);
        assert_eq!(count2.load(Ordering::SeqCst), 1);
    }

    #[tokio::test]
    async fn test_unsubscribe() {
        let bus = EventBus::new();
        let call_count = Arc::new(AtomicUsize::new(0));

        let handler = Arc::new(TestHandler {
            id: "test-handler".to_string(),
            call_count: call_count.clone(),
        });

        bus.subscribe(handler).await;
        assert_eq!(bus.subscriber_count("NodeAdded").await, 1);

        bus.unsubscribe("test-handler", "NodeAdded").await;
        assert_eq!(bus.subscriber_count("NodeAdded").await, 0);
    }

    #[tokio::test]
    async fn test_disabled_bus() {
        let bus = EventBus::new();
        bus.set_enabled(false).await;

        let call_count = Arc::new(AtomicUsize::new(0));
        bus.subscribe(Arc::new(TestHandler {
            id: "test-handler".to_string(),
            call_count: call_count.clone(),
        }))
        .await;

        let event = NodeAddedEvent {
            node_id: "node-1".to_string(),
            label: "Test".to_string(),
            node_type: "Person".to_string(),
            properties: HashMap::new(),
            timestamp: time::now(),
        };

        bus.publish(event).await.unwrap();
        assert_eq!(call_count.load(Ordering::SeqCst), 0);
    }
}

--------------------------------------------------------------------------------
FILE: src/events/types.rs
PURPOSE: Event type definitions (DomainEvent trait)
--------------------------------------------------------------------------------
use async_trait::async_trait;
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::fmt::Debug;
use crate::utils::time;

///
///
pub trait DomainEvent: Send + Sync + Debug {
    
    fn event_type(&self) -> &'static str;

    
    fn aggregate_id(&self) -> &str;

    
    fn timestamp(&self) -> DateTime<Utc>;

    
    fn aggregate_type(&self) -> &'static str;

    
    fn version(&self) -> u32 {
        1
    }

    
    fn to_json_string(&self) -> Result<String, serde_json::Error>;
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EventMetadata {
    
    pub event_id: String,

    
    pub aggregate_id: String,

    
    pub aggregate_type: String,

    
    pub event_type: String,

    
    pub timestamp: DateTime<Utc>,

    
    pub causation_id: Option<String>,

    
    pub correlation_id: Option<String>,

    
    pub user_id: Option<String>,

    
    pub version: u32,
}

impl EventMetadata {
    pub fn new(aggregate_id: String, aggregate_type: String, event_type: String) -> Self {
        Self {
            event_id: uuid::Uuid::new_v4().to_string(),
            aggregate_id,
            aggregate_type,
            event_type,
            timestamp: time::now(),
            causation_id: None,
            correlation_id: None,
            user_id: None,
            version: 1,
        }
    }

    pub fn with_causation(mut self, causation_id: String) -> Self {
        self.causation_id = Some(causation_id);
        self
    }

    pub fn with_correlation(mut self, correlation_id: String) -> Self {
        self.correlation_id = Some(correlation_id);
        self
    }

    pub fn with_user(mut self, user_id: String) -> Self {
        self.user_id = Some(user_id);
        self
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StoredEvent {
    
    pub metadata: EventMetadata,

    
    pub data: String,

    
    pub sequence: i64,
}

///
#[async_trait]
pub trait EventHandler: Send + Sync {
    
    fn event_type(&self) -> &'static str;

    
    fn handler_id(&self) -> &str;

    
    async fn handle(&self, event: &StoredEvent) -> Result<(), EventError>;

    
    fn is_async(&self) -> bool {
        true
    }

    
    fn max_retries(&self) -> u32 {
        3
    }
}

///
#[async_trait]
pub trait EventMiddleware: Send + Sync {
    
    async fn before_publish(&self, event: &mut StoredEvent) -> Result<(), EventError>;

    
    async fn after_publish(&self, event: &StoredEvent) -> Result<(), EventError>;

    
    async fn before_handle(&self, event: &StoredEvent, handler_id: &str) -> Result<(), EventError>;

    
    async fn after_handle(
        &self,
        event: &StoredEvent,
        handler_id: &str,
        result: &Result<(), EventError>,
    ) -> Result<(), EventError>;
}

///
#[derive(Debug, Clone, thiserror::Error)]
pub enum EventError {
    #[error("Serialization error: {0}")]
    Serialization(String),

    #[error("Handler error: {0}")]
    Handler(String),

    #[error("Storage error: {0}")]
    Storage(String),

    #[error("Bus error: {0}")]
    Bus(String),

    #[error("Middleware error: {0}")]
    Middleware(String),

    #[error("Event not found: {0}")]
    NotFound(String),

    #[error("Validation error: {0}")]
    Validation(String),

    #[error("Concurrency error: {0}")]
    Concurrency(String),
}

pub type EventResult<T> = Result<T, EventError>;

///
pub struct EventEnvelope {
    pub metadata: EventMetadata,
    pub event: Box<dyn std::any::Any + Send + Sync>,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EventSnapshot {
    pub aggregate_id: String,
    pub aggregate_type: String,
    pub sequence: i64,
    pub timestamp: DateTime<Utc>,
    pub state: String,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_event_metadata_creation() {
        let metadata = EventMetadata::new(
            "node-123".to_string(),
            "Node".to_string(),
            "NodeAdded".to_string(),
        );

        assert_eq!(metadata.aggregate_id, "node-123");
        assert_eq!(metadata.aggregate_type, "Node");
        assert_eq!(metadata.event_type, "NodeAdded");
        assert!(metadata.causation_id.is_none());
    }

    #[test]
    fn test_event_metadata_builder() {
        let metadata = EventMetadata::new(
            "node-123".to_string(),
            "Node".to_string(),
            "NodeAdded".to_string(),
        )
        .with_causation("cmd-456".to_string())
        .with_correlation("corr-789".to_string())
        .with_user("user-1".to_string());

        assert_eq!(metadata.causation_id, Some("cmd-456".to_string()));
        assert_eq!(metadata.correlation_id, Some("corr-789".to_string()));
        assert_eq!(metadata.user_id, Some("user-1".to_string()));
    }
}

--------------------------------------------------------------------------------
FILE: src/events/inference_triggers.rs
PURPOSE: Inference trigger handler for automatic reasoning
--------------------------------------------------------------------------------
// src/events/inference_triggers.rs
//! Automatic Inference Triggers
//!
//! Event-driven inference that automatically runs reasoning when ontology changes occur.

use std::sync::Arc;
use tokio::sync::RwLock;
use tracing::{debug, info, warn, instrument};

use crate::application::inference_service::InferenceService;
use crate::events::EventBus;

///
#[derive(Debug, Clone)]
pub enum OntologyEvent {
    
    OntologyImported {
        ontology_id: String,
        class_count: usize,
        axiom_count: usize,
    },

    
    ClassAdded {
        ontology_id: String,
        class_iri: String,
    },

    
    AxiomAdded {
        ontology_id: String,
        axiom_id: String,
    },

    
    OntologyModified {
        ontology_id: String,
        change_type: String,
    },
}

///
#[derive(Debug, Clone)]
pub struct AutoInferenceConfig {
    
    pub auto_on_import: bool,

    
    pub auto_on_class_add: bool,

    
    pub auto_on_axiom_add: bool,

    
    pub min_delay_ms: u64,

    
    pub batch_changes: bool,
}

impl Default for AutoInferenceConfig {
    fn default() -> Self {
        Self {
            auto_on_import: true,
            auto_on_class_add: false, 
            auto_on_axiom_add: false, 
            min_delay_ms: 1000,       
            batch_changes: true,
        }
    }
}

///
pub struct InferenceTriggerHandler {
    
    inference_service: Arc<RwLock<InferenceService>>,

    
    config: AutoInferenceConfig,

    
    last_inference: Arc<RwLock<std::collections::HashMap<String, std::time::Instant>>>,
}

impl InferenceTriggerHandler {
    
    pub fn new(
        inference_service: Arc<RwLock<InferenceService>>,
        config: AutoInferenceConfig,
    ) -> Self {
        Self {
            inference_service,
            config,
            last_inference: Arc::new(RwLock::new(std::collections::HashMap::new())),
        }
    }

    
    #[instrument(skip(self), level = "debug")]
    pub async fn handle_event(&self, event: OntologyEvent) {
        match event {
            OntologyEvent::OntologyImported { ontology_id, .. } => {
                if self.config.auto_on_import {
                    info!("Auto-triggering inference for imported ontology: {}", ontology_id);
                    self.trigger_inference(&ontology_id).await;
                }
            }

            OntologyEvent::ClassAdded { ontology_id, .. } => {
                if self.config.auto_on_class_add {
                    debug!("Auto-triggering inference for class addition: {}", ontology_id);
                    self.trigger_incremental_inference(&ontology_id).await;
                }
            }

            OntologyEvent::AxiomAdded { ontology_id, .. } => {
                if self.config.auto_on_axiom_add {
                    debug!("Auto-triggering inference for axiom addition: {}", ontology_id);
                    self.trigger_incremental_inference(&ontology_id).await;
                }
            }

            OntologyEvent::OntologyModified { ontology_id, .. } => {
                debug!("Ontology modified, considering inference: {}", ontology_id);
                self.trigger_incremental_inference(&ontology_id).await;
            }
        }
    }

    
    async fn trigger_inference(&self, ontology_id: &str) {
        
        if !self.should_run_inference(ontology_id).await {
            debug!("Skipping inference due to rate limiting: {}", ontology_id);
            return;
        }

        let service = self.inference_service.read().await;

        match service.run_inference(ontology_id).await {
            Ok(results) => {
                info!(
                    "Auto-inference completed for {}: {} inferred axioms in {}ms",
                    ontology_id,
                    results.inferred_axioms.len(),
                    results.inference_time_ms
                );

                
                self.update_last_inference(ontology_id).await;
            }
            Err(e) => {
                warn!("Auto-inference failed for {}: {:?}", ontology_id, e);
            }
        }
    }

    
    async fn trigger_incremental_inference(&self, ontology_id: &str) {
        
        
        if self.config.batch_changes {
            debug!("Batching changes for: {}", ontology_id);
            
        } else {
            self.trigger_inference(ontology_id).await;
        }
    }

    
    async fn should_run_inference(&self, ontology_id: &str) -> bool {
        let last_inference = self.last_inference.read().await;

        if let Some(last_time) = last_inference.get(ontology_id) {
            let elapsed = last_time.elapsed().as_millis() as u64;
            elapsed >= self.config.min_delay_ms
        } else {
            true 
        }
    }

    
    async fn update_last_inference(&self, ontology_id: &str) {
        let mut last_inference = self.last_inference.write().await;
        last_inference.insert(ontology_id.to_string(), std::time::Instant::now());
    }
}

///
pub async fn register_inference_triggers(
    event_bus: Arc<RwLock<EventBus>>,
    inference_service: Arc<RwLock<InferenceService>>,
    config: AutoInferenceConfig,
) {
    let handler = Arc::new(InferenceTriggerHandler::new(inference_service, config));

    
    

    info!("Inference triggers registered with event bus");
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_auto_inference_config_default() {
        let config = AutoInferenceConfig::default();
        assert!(config.auto_on_import);
        assert!(!config.auto_on_class_add);
        assert!(config.batch_changes);
    }

    #[tokio::test]
    async fn test_rate_limiting() {
        let config = AutoInferenceConfig {
            min_delay_ms: 100,
            ..Default::default()
        };

        
        
    }
}

--------------------------------------------------------------------------------
FILE: src/inference/mod.rs
PURPOSE: OWL 2 DL reasoning module
--------------------------------------------------------------------------------
// src/inference/mod.rs
//! Inference Module
//!
//! Provides OWL 2 DL ontology reasoning and inference capabilities using whelk-rs.
//! This module includes OWL parsers, inference types, caching, and optimization.

pub mod owl_parser;
pub mod types;
pub mod cache;
pub mod optimization;

pub use owl_parser::{OWLParser, OWLFormat, ParseResult, ParseError};
pub use types::{
    Inference, InferenceType, InferenceExplanation, ValidationResult,
    ClassificationResult, ConsistencyReport, UnsatisfiableClass
};
pub use cache::{InferenceCache, CacheConfig, CacheEntry, CacheStatistics};
pub use optimization::{
    InferenceOptimizer, BatchInferenceRequest, IncrementalInference,
    ParallelClassification, OptimizationMetrics
};

--------------------------------------------------------------------------------
FILE: src/inference/types.rs
PURPOSE: Inference types (InferenceType, ClassificationResult)
--------------------------------------------------------------------------------
// src/inference/types.rs
//! Inference Result Types
//!
//! Domain types for representing inference results, explanations, and validation outcomes.

use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use chrono::{DateTime, Utc};
use crate::ports::ontology_repository::OwlAxiom;
use crate::utils::time;

///
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum InferenceType {
    
    ClassAssertion,

    
    SubClassOf,

    
    EquivalentClass,

    
    DisjointClasses,

    
    PropertyAssertion,

    
    PropertyDomain,

    
    PropertyRange,

    
    InverseProperty,

    
    TransitiveProperty,
}

impl std::fmt::Display for InferenceType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::ClassAssertion => write!(f, "Class Assertion"),
            Self::SubClassOf => write!(f, "SubClass Of"),
            Self::EquivalentClass => write!(f, "Equivalent Class"),
            Self::DisjointClasses => write!(f, "Disjoint Classes"),
            Self::PropertyAssertion => write!(f, "Property Assertion"),
            Self::PropertyDomain => write!(f, "Property Domain"),
            Self::PropertyRange => write!(f, "Property Range"),
            Self::InverseProperty => write!(f, "Inverse Property"),
            Self::TransitiveProperty => write!(f, "Transitive Property"),
        }
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Inference {
    
    pub id: Option<String>,

    
    pub inference_type: InferenceType,

    
    pub subject: String,

    
    pub predicate: String,

    
    pub object: String,

    
    pub confidence: f32,

    
    pub explanation: Vec<OwlAxiom>,

    
    pub metadata: HashMap<String, String>,

    
    pub computed_at: DateTime<Utc>,
}

impl Inference {
    
    pub fn new(
        inference_type: InferenceType,
        subject: String,
        predicate: String,
        object: String,
    ) -> Self {
        Self {
            id: None,
            inference_type,
            subject,
            predicate,
            object,
            confidence: 1.0, 
            explanation: Vec::new(),
            metadata: HashMap::new(),
            computed_at: time::now(),
        }
    }

    
    pub fn with_explanation(mut self, axioms: Vec<OwlAxiom>) -> Self {
        self.explanation = axioms;
        self
    }

    
    pub fn with_confidence(mut self, confidence: f32) -> Self {
        self.confidence = confidence.clamp(0.0, 1.0);
        self
    }

    
    pub fn with_metadata(mut self, key: String, value: String) -> Self {
        self.metadata.insert(key, value);
        self
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceExplanation {
    
    pub axiom: OwlAxiom,

    
    pub axiom_chain: Vec<OwlAxiom>,

    
    pub description: String,

    
    pub confidence: f32,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ValidationResult {
    
    pub consistent: bool,

    
    pub unsatisfiable: Vec<UnsatisfiableClass>,

    
    pub warnings: Vec<String>,

    
    pub errors: Vec<String>,

    
    pub validation_time_ms: u64,
}

impl ValidationResult {
    
    pub fn consistent() -> Self {
        Self {
            consistent: true,
            unsatisfiable: Vec::new(),
            warnings: Vec::new(),
            errors: Vec::new(),
            validation_time_ms: 0,
        }
    }

    
    pub fn inconsistent(unsatisfiable: Vec<UnsatisfiableClass>) -> Self {
        Self {
            consistent: false,
            unsatisfiable,
            warnings: Vec::new(),
            errors: Vec::new(),
            validation_time_ms: 0,
        }
    }

    
    pub fn has_issues(&self) -> bool {
        !self.warnings.is_empty() || !self.errors.is_empty() || !self.consistent
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UnsatisfiableClass {
    
    pub class_iri: String,

    
    pub reason: String,

    
    pub conflicting_axioms: Vec<OwlAxiom>,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClassificationResult {
    
    pub hierarchy: Vec<(String, String)>,

    
    pub equivalent_classes: Vec<Vec<String>>,

    
    pub classification_time_ms: u64,

    
    pub inferred_count: usize,
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConsistencyReport {
    
    pub is_consistent: bool,

    
    pub unsatisfiable_classes: Vec<UnsatisfiableClass>,

    
    pub classes_checked: usize,

    
    pub axioms_checked: usize,

    
    pub check_time_ms: u64,

    
    pub reasoner_version: String,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_inference_creation() {
        let inf = Inference::new(
            InferenceType::SubClassOf,
            "ex:Dog".to_string(),
            "rdfs:subClassOf".to_string(),
            "ex:Animal".to_string(),
        );

        assert_eq!(inf.inference_type, InferenceType::SubClassOf);
        assert_eq!(inf.confidence, 1.0);
        assert!(inf.explanation.is_empty());
    }

    #[test]
    fn test_inference_builder() {
        let inf = Inference::new(
            InferenceType::ClassAssertion,
            "ex:fido".to_string(),
            "rdf:type".to_string(),
            "ex:Dog".to_string(),
        )
        .with_confidence(0.95)
        .with_metadata("source".to_string(), "ml_classifier".to_string());

        assert_eq!(inf.confidence, 0.95);
        assert_eq!(inf.metadata.get("source").expect("Missing required key: source"), "ml_classifier");
    }

    #[test]
    fn test_validation_result_consistent() {
        let result = ValidationResult::consistent();
        assert!(result.consistent);
        assert!(!result.has_issues());
    }

    #[test]
    fn test_validation_result_inconsistent() {
        let unsat = UnsatisfiableClass {
            class_iri: "ex:Square  Circle".to_string(),
            reason: "Conflicting axioms".to_string(),
            conflicting_axioms: Vec::new(),
        };

        let result = ValidationResult::inconsistent(vec![unsat]);
        assert!(!result.consistent);
        assert!(result.has_issues());
        assert_eq!(result.unsatisfiable.len(), 1);
    }
}

--------------------------------------------------------------------------------
FILE: src/inference/cache.rs
PURPOSE: Inference result caching
--------------------------------------------------------------------------------
// src/inference/cache.rs
//! Inference Caching System
//!
//! LRU cache for inference results with TTL support and database persistence.
//! Automatically invalidates cache on ontology changes.

use std::sync::Arc;
use tokio::sync::RwLock;
use lru::LruCache;
use std::num::NonZeroUsize;
use chrono::{DateTime, Utc, Duration};
use serde::{Deserialize, Serialize};

use crate::ports::ontology_repository::InferenceResults;
use crate::utils::time;

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheConfig {
    
    pub max_entries: usize,

    
    pub ttl_seconds: i64,

    
    pub persist_to_db: bool,

    
    pub enable_stats: bool,
}

impl Default for CacheConfig {
    fn default() -> Self {
        Self {
            max_entries: 1000,
            ttl_seconds: 3600, 
            persist_to_db: true,
            enable_stats: true,
        }
    }
}

///
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheEntry {
    
    pub results: InferenceResults,

    
    pub ontology_checksum: String,

    
    pub created_at: DateTime<Utc>,

    
    pub accessed_at: DateTime<Utc>,

    
    pub access_count: u64,
}

impl CacheEntry {
    
    pub fn is_expired(&self, ttl: Duration) -> bool {
        time::now() - self.created_at > ttl
    }

    
    pub fn is_valid_for(&self, checksum: &str) -> bool {
        self.ontology_checksum == checksum
    }

    
    pub fn touch(&mut self) {
        self.accessed_at = time::now();
        self.access_count += 1;
    }
}

///
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct CacheStatistics {
    pub hits: u64,
    pub misses: u64,
    pub invalidations: u64,
    pub evictions: u64,
    pub current_size: usize,
    pub max_size: usize,
}

impl CacheStatistics {
    
    pub fn hit_rate(&self) -> f64 {
        let total = self.hits + self.misses;
        if total == 0 {
            0.0
        } else {
            self.hits as f64 / total as f64
        }
    }
}

///
pub struct InferenceCache {
    
    cache: Arc<RwLock<LruCache<String, CacheEntry>>>,

    
    config: CacheConfig,

    
    stats: Arc<RwLock<CacheStatistics>>,
}

impl InferenceCache {
    
    pub fn new(config: CacheConfig) -> Self {
        let capacity = NonZeroUsize::new(config.max_entries).unwrap();
        let cache = Arc::new(RwLock::new(LruCache::new(capacity)));

        let stats = Arc::new(RwLock::new(CacheStatistics {
            max_size: config.max_entries,
            ..Default::default()
        }));

        Self {
            cache,
            config,
            stats,
        }
    }

    
    pub async fn get(&self, ontology_id: &str, checksum: &str) -> Option<InferenceResults> {
        let mut cache = self.cache.write().await;
        let mut stats = self.stats.write().await;

        if let Some(entry) = cache.get_mut(ontology_id) {
            
            let ttl = Duration::seconds(self.config.ttl_seconds);

            if entry.is_valid_for(checksum) && !entry.is_expired(ttl) {
                entry.touch();
                stats.hits += 1;
                return Some(entry.results.clone());
            } else {
                
                cache.pop(ontology_id);
                stats.invalidations += 1;
            }
        }

        stats.misses += 1;
        None
    }

    
    pub async fn put(
        &self,
        ontology_id: String,
        checksum: String,
        results: InferenceResults,
    ) {
        let mut cache = self.cache.write().await;
        let mut stats = self.stats.write().await;

        let entry = CacheEntry {
            results,
            ontology_checksum: checksum,
            created_at: time::now(),
            accessed_at: time::now(),
            access_count: 0,
        };

        
        if cache.len() >= self.config.max_entries && !cache.contains(&ontology_id) {
            stats.evictions += 1;
        }

        cache.put(ontology_id, entry);
        stats.current_size = cache.len();
    }

    
    pub async fn invalidate(&self, ontology_id: &str) {
        let mut cache = self.cache.write().await;
        let mut stats = self.stats.write().await;

        if cache.pop(ontology_id).is_some() {
            stats.invalidations += 1;
            stats.current_size = cache.len();
        }
    }

    
    pub async fn clear(&self) {
        let mut cache = self.cache.write().await;
        let mut stats = self.stats.write().await;

        cache.clear();
        stats.current_size = 0;
        stats.invalidations += cache.len() as u64;
    }

    
    pub async fn get_statistics(&self) -> CacheStatistics {
        self.stats.read().await.clone()
    }

    
    pub async fn cleanup_expired(&self) {
        let mut cache = self.cache.write().await;
        let ttl = Duration::seconds(self.config.ttl_seconds);

        let expired_keys: Vec<String> = cache
            .iter()
            .filter(|(_, entry)| entry.is_expired(ttl))
            .map(|(key, _)| key.clone())
            .collect();

        let mut stats = self.stats.write().await;
        for key in expired_keys {
            cache.pop(&key);
            stats.invalidations += 1;
        }

        stats.current_size = cache.len();
    }

    
    pub async fn get_cached_ids(&self) -> Vec<String> {
        let cache = self.cache.read().await;
        cache.iter().map(|(key, _)| key.clone()).collect()
    }
}

impl Default for InferenceCache {
    fn default() -> Self {
        Self::new(CacheConfig::default())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::ports::ontology_repository::InferenceResults;

    fn create_test_results() -> InferenceResults {
        InferenceResults {
            timestamp: time::now(),
            inferred_axioms: Vec::new(),
            inference_time_ms: 100,
            reasoner_version: "test-1.0".to_string(),
        }
    }

    #[tokio::test]
    async fn test_cache_put_and_get() {
        let cache = InferenceCache::default();
        let results = create_test_results();

        cache
            .put("ont1".to_string(), "checksum1".to_string(), results.clone())
            .await;

        let retrieved = cache.get("ont1", "checksum1").await;
        assert!(retrieved.is_some());
    }

    #[tokio::test]
    async fn test_cache_miss() {
        let cache = InferenceCache::default();
        let retrieved = cache.get("nonexistent", "checksum").await;
        assert!(retrieved.is_none());
    }

    #[tokio::test]
    async fn test_cache_invalidation_on_checksum_mismatch() {
        let cache = InferenceCache::default();
        let results = create_test_results();

        cache
            .put("ont1".to_string(), "checksum1".to_string(), results.clone())
            .await;

        
        let retrieved = cache.get("ont1", "checksum2").await;
        assert!(retrieved.is_none());

        
        let stats = cache.get_statistics().await;
        assert_eq!(stats.invalidations, 1);
    }

    #[tokio::test]
    async fn test_cache_invalidate() {
        let cache = InferenceCache::default();
        let results = create_test_results();

        cache
            .put("ont1".to_string(), "checksum1".to_string(), results.clone())
            .await;

        cache.invalidate("ont1").await;

        let retrieved = cache.get("ont1", "checksum1").await;
        assert!(retrieved.is_none());
    }

    #[tokio::test]
    async fn test_cache_clear() {
        let cache = InferenceCache::default();
        let results = create_test_results();

        cache
            .put("ont1".to_string(), "checksum1".to_string(), results.clone())
            .await;
        cache
            .put("ont2".to_string(), "checksum2".to_string(), results.clone())
            .await;

        cache.clear().await;

        let stats = cache.get_statistics().await;
        assert_eq!(stats.current_size, 0);
    }

    #[tokio::test]
    async fn test_cache_statistics() {
        let cache = InferenceCache::default();
        let results = create_test_results();

        cache
            .put("ont1".to_string(), "checksum1".to_string(), results.clone())
            .await;

        
        cache.get("ont1", "checksum1").await;

        
        cache.get("ont2", "checksum2").await;

        let stats = cache.get_statistics().await;
        assert_eq!(stats.hits, 1);
        assert_eq!(stats.misses, 1);
        assert!(stats.hit_rate() > 0.0);
    }

    #[tokio::test]
    async fn test_lru_eviction() {
        let config = CacheConfig {
            max_entries: 2,
            ..Default::default()
        };

        let cache = InferenceCache::new(config);
        let results = create_test_results();

        cache
            .put("ont1".to_string(), "checksum1".to_string(), results.clone())
            .await;
        cache
            .put("ont2".to_string(), "checksum2".to_string(), results.clone())
            .await;

        
        cache
            .put("ont3".to_string(), "checksum3".to_string(), results.clone())
            .await;

        let stats = cache.get_statistics().await;
        assert_eq!(stats.evictions, 1);
        assert_eq!(stats.current_size, 2);
    }
}

================================================================================
                    SECTION 11: MIDDLEWARE & CONFIG
================================================================================

--------------------------------------------------------------------------------
FILE: src/middleware/mod.rs
PURPOSE: Middleware module exports
--------------------------------------------------------------------------------
//! Middleware modules for request processing

pub mod auth;
pub mod rate_limit;
pub mod timeout;
pub mod validation;

pub use auth::{get_authenticated_user, AuthenticatedUser, RequireAuth};
pub use rate_limit::{RateLimit, RateLimitConfig};
pub use timeout::TimeoutMiddleware;
pub use validation::{ValidateInput, ValidationConfig, validators};

--------------------------------------------------------------------------------
FILE: src/middleware/auth.rs
PURPOSE: Authentication middleware (RequireAuth)
--------------------------------------------------------------------------------
//! Authentication Middleware
//!
//! Provides Actix-web middleware for enforcing authentication on protected routes.
//! Uses Nostr-based authentication with session validation.

use actix_web::{
    dev::{forward_ready, Service, ServiceRequest, ServiceResponse, Transform},
    Error, HttpMessage, HttpResponse,
};
use futures_util::future::LocalBoxFuture;
use log::{debug, warn};
use std::future::{ready, Ready};
use std::rc::Rc;

use crate::services::nostr_service::NostrService;
use crate::utils::auth::{verify_authenticated, verify_power_user, AccessLevel};

/// Authentication middleware that enforces Nostr-based session validation
///
/// # Example
/// ```
/// use actix_web::{web, App};
/// use crate::middleware::auth::RequireAuth;
///
/// App::new()
///     .wrap(RequireAuth::authenticated())  // Require any authenticated user
///     .route("/protected", web::get().to(handler))
/// ```
pub struct RequireAuth {
    level: AccessLevel,
}

impl RequireAuth {
    /// Require authenticated user (any valid session)
    pub fn authenticated() -> Self {
        Self {
            level: AccessLevel::Authenticated,
        }
    }

    /// Require power user access
    pub fn power_user() -> Self {
        Self {
            level: AccessLevel::PowerUser,
        }
    }
}

impl<S, B> Transform<S, ServiceRequest> for RequireAuth
where
    S: Service<ServiceRequest, Response = ServiceResponse<B>, Error = Error> + 'static,
    S::Future: 'static,
    B: actix_web::body::MessageBody + 'static,
{
    type Response = ServiceResponse<actix_web::body::BoxBody>;
    type Error = Error;
    type InitError = ();
    type Transform = AuthMiddleware<S>;
    type Future = Ready<Result<Self::Transform, Self::InitError>>;

    fn new_transform(&self, service: S) -> Self::Future {
        ready(Ok(AuthMiddleware {
            service: Rc::new(service),
            level: self.level.clone(),
        }))
    }
}

pub struct AuthMiddleware<S> {
    service: Rc<S>,
    level: AccessLevel,
}

impl<S, B> Service<ServiceRequest> for AuthMiddleware<S>
where
    S: Service<ServiceRequest, Response = ServiceResponse<B>, Error = Error> + 'static,
    S::Future: 'static,
    B: actix_web::body::MessageBody + 'static,
{
    type Response = ServiceResponse<actix_web::body::BoxBody>;
    type Error = Error;
    type Future = LocalBoxFuture<'static, Result<Self::Response, Self::Error>>;

    forward_ready!(service);

    fn call(&self, req: ServiceRequest) -> Self::Future {
        let svc = self.service.clone();
        let level = self.level.clone();

        Box::pin(async move {
            // Extract NostrService from app data
            let nostr_service = match req.app_data::<actix_web::web::Data<NostrService>>() {
                Some(service) => service.clone(),
                None => {
                    warn!("NostrService not found in app data - authentication cannot proceed");
                    let resp = HttpResponse::InternalServerError()
                        .body("Authentication service not configured");
                    return Ok(req.into_response(resp).map_into_boxed_body());
                }
            };

            // Verify access level
            let result = match level {
                AccessLevel::Authenticated => {
                    verify_authenticated(req.request(), &nostr_service).await
                }
                AccessLevel::PowerUser => {
                    verify_power_user(req.request(), &nostr_service).await
                }
            };

            match result {
                Ok(pubkey) => {
                    // Store authenticated pubkey in request extensions for handlers to use
                    req.extensions_mut().insert(AuthenticatedUser { pubkey });

                    debug!("Authentication successful, proceeding with request");

                    // Continue to the actual handler
                    let resp = svc.call(req).await?;
                    Ok(resp.map_into_boxed_body())
                }
                Err(response) => {
                    // Authentication failed - return error response
                    Ok(req.into_response(response).map_into_boxed_body())
                }
            }
        })
    }
}

/// Authenticated user information stored in request extensions
#[derive(Clone, Debug)]
pub struct AuthenticatedUser {
    pub pubkey: String,
}

/// Extract authenticated user from request extensions (for use in handlers)
///
/// # Example
/// ```
/// use actix_web::{web, HttpRequest};
/// use crate::middleware::auth::get_authenticated_user;
///
/// async fn handler(req: HttpRequest) -> impl Responder {
///     let user = get_authenticated_user(&req)?;
///     // Use user.pubkey
/// }
/// ```
pub fn get_authenticated_user(req: &actix_web::HttpRequest) -> Option<AuthenticatedUser> {
    req.extensions().get::<AuthenticatedUser>().cloned()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_require_auth_levels() {
        let auth = RequireAuth::authenticated();
        assert!(matches!(auth.level, AccessLevel::Authenticated));

        let power = RequireAuth::power_user();
        assert!(matches!(power.level, AccessLevel::PowerUser));
    }
}

--------------------------------------------------------------------------------
FILE: src/config/mod.rs
PURPOSE: Application configuration with validation
--------------------------------------------------------------------------------
use config::ConfigError;
use log::{debug, error, info};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::collections::HashMap;

// New imports for enhanced validation and type generation
use lazy_static::lazy_static;
use regex::Regex;
use specta::Type;
use validator::{Validate, ValidationError};

pub mod dev_config;
pub mod path_access;

// Import the trait and functions we need
use path_access::{parse_path, PathAccessible};

// Centralized validation patterns
lazy_static! {
    
    static ref HEX_COLOR_REGEX: Regex = Regex::new(r"^#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{8})$").expect("Invalid regex pattern");

    
    static ref URL_REGEX: Regex = Regex::new(r"^https?://[^\s/$.?#].[^\s]*$").expect("Invalid regex pattern");

    
    static ref FILE_PATH_REGEX: Regex = Regex::new(r"^[a-zA-Z0-9._/\\-]+$").expect("Invalid regex pattern");

    
    static ref DOMAIN_REGEX: Regex = Regex::new(r"^[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?(\.[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?)*$").expect("Invalid regex pattern");
}

///
///
pub fn validate_hex_color(color: &str) -> Result<(), ValidationError> {
    if !HEX_COLOR_REGEX.is_match(color) {
        return Err(ValidationError::new("invalid_hex_color"));
    }
    Ok(())
}

///
pub fn validate_width_range(range: &[f32]) -> Result<(), ValidationError> {
    if range.len() != 2 {
        return Err(ValidationError::new("width_range_length"));
    }
    if range[0] >= range[1] {
        return Err(ValidationError::new("width_range_order"));
    }
    Ok(())
}

///
pub fn validate_port(port: u16) -> Result<(), ValidationError> {
    if port == 0 {
        return Err(ValidationError::new("invalid_port"));
    }
    Ok(())
}

///
pub fn validate_percentage(value: f32) -> Result<(), ValidationError> {
    if !(0.0..=100.0).contains(&value) {
        return Err(ValidationError::new("invalid_percentage"));
    }
    Ok(())
}

///
///
pub fn validate_bloom_glow_settings(
    glow: &GlowSettings,
    bloom: &BloomSettings,
) -> Result<(), ValidationError> {
    
    if glow.intensity < 0.0 || glow.intensity > 10.0 {
        return Err(ValidationError::new("glow_intensity_out_of_range"));
    }
    if glow.radius < 0.0 || glow.radius > 10.0 {
        return Err(ValidationError::new("glow_radius_out_of_range"));
    }
    if glow.threshold < 0.0 || glow.threshold > 1.0 {
        return Err(ValidationError::new("glow_threshold_out_of_range"));
    }
    if glow.opacity < 0.0 || glow.opacity > 1.0 {
        return Err(ValidationError::new("glow_opacity_out_of_range"));
    }

    
    validate_hex_color(&glow.base_color)?;
    validate_hex_color(&glow.emission_color)?;

    
    if !glow.intensity.is_finite() {
        return Err(ValidationError::new("glow_intensity_not_finite"));
    }
    if !glow.radius.is_finite() {
        return Err(ValidationError::new("glow_radius_not_finite"));
    }
    if !glow.threshold.is_finite() {
        return Err(ValidationError::new("glow_threshold_not_finite"));
    }

    
    if bloom.intensity < 0.0 || bloom.intensity > 10.0 {
        return Err(ValidationError::new("bloom_intensity_out_of_range"));
    }
    if bloom.radius < 0.0 || bloom.radius > 10.0 {
        return Err(ValidationError::new("bloom_radius_out_of_range"));
    }
    if bloom.threshold < 0.0 || bloom.threshold > 1.0 {
        return Err(ValidationError::new("bloom_threshold_out_of_range"));
    }
    if bloom.strength < 0.0 || bloom.strength > 1.0 {
        return Err(ValidationError::new("bloom_strength_out_of_range"));
    }
    if bloom.knee < 0.0 || bloom.knee > 2.0 {
        return Err(ValidationError::new("bloom_knee_out_of_range"));
    }

    
    validate_hex_color(&bloom.color)?;
    validate_hex_color(&bloom.tint_color)?;

    
    if !bloom.intensity.is_finite() {
        return Err(ValidationError::new("bloom_intensity_not_finite"));
    }
    if !bloom.radius.is_finite() {
        return Err(ValidationError::new("bloom_radius_not_finite"));
    }
    if !bloom.threshold.is_finite() {
        return Err(ValidationError::new("bloom_threshold_not_finite"));
    }

    Ok(())
}

///
fn to_camel_case(snake_str: &str) -> String {
    let mut result = String::new();
    let mut capitalize_next = false;

    for ch in snake_str.chars() {
        if ch == '_' {
            capitalize_next = true;
        } else if capitalize_next {
            result.push(ch.to_ascii_uppercase());
            capitalize_next = false;
        } else {
            result.push(ch);
        }
    }

    result
}

fn default_auto_balance_interval() -> u32 {
    500
}

fn default_constraint_ramp_frames() -> u32 {
    60 
}

fn default_constraint_max_force_per_node() -> f32 {
    50.0 
}

fn default_glow_color() -> String {
    "#00ffff".to_string()
}

fn default_glow_opacity() -> f32 {
    0.8
}

fn default_bounds_size() -> f32 {
    1000.0
}

pub mod feature_access;
// pub mod tests;

// Types are already public in this module, no need to re-export

// Helper function to convert empty strings to null for Option<String> fields
fn convert_empty_strings_to_null(value: Value) -> Value {
    match value {
        Value::Object(map) => {
            let new_map = map
                .into_iter()
                .map(|(k, v)| {
                    let new_v = match v {
                        Value::String(s) if s.is_empty() => {
                            
                            
                            
                            let required_string_fields = vec![
                                "base_color",
                                "color",
                                "background_color",
                                "text_color",
                                "text_outline_color",
                                "billboard_mode",
                                "quality",
                                "mode",
                                "context",
                                "cookie_samesite",
                                "audit_log_path",
                                "bind_address",
                                "domain",
                                "min_tls_version",
                                "tunnel_id",
                                "provider",
                                "ring_color",
                                "hand_mesh_color",
                                "hand_ray_color",
                                "teleport_ray_color",
                                "controller_ray_color",
                                "plane_color",
                                "portal_edge_color",
                                "space_type",
                                "locomotion_method",
                            ];

                            if required_string_fields.contains(&k.as_str()) {
                                
                                Value::String(s)
                            } else {
                                
                                Value::Null
                            }
                        }
                        Value::Object(_) => convert_empty_strings_to_null(v),
                        Value::Array(_) => convert_empty_strings_to_null(v),
                        _ => v,
                    };
                    (k, new_v)
                })
                .collect();
            Value::Object(new_map)
        }
        Value::Array(arr) => {
            Value::Array(arr.into_iter().map(convert_empty_strings_to_null).collect())
        }
        _ => value,
    }
}

// Helper function to merge two JSON values
fn merge_json_values(base: Value, update: Value) -> Value {
    use serde_json::map::Entry;
use crate::utils::json::{from_json, to_json};

    match (base, update) {
        (Value::Object(mut base_map), Value::Object(update_map)) => {
            for (key, update_value) in update_map {
                match base_map.entry(key) {
                    Entry::Occupied(mut entry) => {
                        let merged = merge_json_values(entry.get().clone(), update_value);
                        entry.insert(merged);
                    }
                    Entry::Vacant(entry) => {
                        entry.insert(update_value);
                    }
                }
            }
            Value::Object(base_map)
        }
        (_, update) => update, 
    }
}

///
static FIELD_MAPPINGS: std::sync::LazyLock<std::collections::HashMap<&'static str, &'static str>> =
    std::sync::LazyLock::new(|| {
        let mut field_mappings = std::collections::HashMap::new();

        
        field_mappings.insert("base_color", "baseColor");
        field_mappings.insert("emission_color", "emissionColor");
        field_mappings.insert("node_size", "nodeSize");
        field_mappings.insert("enable_instancing", "enableInstancing");
        field_mappings.insert("enable_hologram", "enableHologram");
        field_mappings.insert("enable_metadata_shape", "enableMetadataShape");
        field_mappings.insert(
            "enable_metadata_visualisation",
            "enableMetadataVisualisation",
        );

        
        field_mappings.insert("arrow_size", "arrowSize");
        field_mappings.insert("base_width", "baseWidth");
        field_mappings.insert("edge_color", "color");
        field_mappings.insert("edge_opacity", "opacity");
        field_mappings.insert("edge_width", "edgeWidth");
        field_mappings.insert("enable_arrows", "enableArrows");
        field_mappings.insert("width_range", "widthRange");

        
        field_mappings.insert("ambient_light_intensity", "ambientLightIntensity");
        field_mappings.insert("background_color", "backgroundColor");
        field_mappings.insert("directional_light_intensity", "directionalLightIntensity");
        field_mappings.insert("enable_ambient_occlusion", "enableAmbientOcclusion");
        field_mappings.insert("enable_antialiasing", "enableAntialiasing");
        field_mappings.insert("enable_shadows", "enableShadows");
        field_mappings.insert("environment_intensity", "environmentIntensity");
        field_mappings.insert("shadow_map_size", "shadowMapSize");
        field_mappings.insert("shadow_bias", "shadowBias");

        
        field_mappings.insert("enable_motion_blur", "enableMotionBlur");
        field_mappings.insert("enable_node_animations", "enableNodeAnimations");
        field_mappings.insert("motion_blur_strength", "motionBlurStrength");
        field_mappings.insert("animation_speed", "animationSpeed");

        
        field_mappings.insert(
            "equilibrium_velocity_threshold",
            "equilibriumVelocityThreshold",
        );
        field_mappings.insert("equilibrium_check_frames", "equilibriumCheckFrames");
        field_mappings.insert("equilibrium_energy_threshold", "equilibriumEnergyThreshold");
        field_mappings.insert("pause_on_equilibrium", "pauseOnEquilibrium");
        field_mappings.insert("resume_on_interaction", "resumeOnInteraction");

        
        field_mappings.insert("stability_variance_threshold", "stabilityVarianceThreshold");
        field_mappings.insert("stability_frame_count", "stabilityFrameCount");
        field_mappings.insert(
            "clustering_distance_threshold",
            "clusteringDistanceThreshold",
        );
        field_mappings.insert("clustering_hysteresis_buffer", "clusteringHysteresisBuffer");
        field_mappings.insert("bouncing_node_percentage", "bouncingNodePercentage");
        field_mappings.insert("boundary_min_distance", "boundaryMinDistance");
        field_mappings.insert("boundary_max_distance", "boundaryMaxDistance");
        field_mappings.insert("extreme_distance_threshold", "extremeDistanceThreshold");
        field_mappings.insert("explosion_distance_threshold", "explosionDistanceThreshold");
        field_mappings.insert("spreading_distance_threshold", "spreadingDistanceThreshold");
        field_mappings.insert("spreading_hysteresis_buffer", "spreadingHysteresisBuffer");
        field_mappings.insert("oscillation_detection_frames", "oscillationDetectionFrames");
        field_mappings.insert("oscillation_change_threshold", "oscillationChangeThreshold");
        field_mappings.insert("min_oscillation_changes", "minOscillationChanges");
        field_mappings.insert("parameter_adjustment_rate", "parameterAdjustmentRate");
        field_mappings.insert("max_adjustment_factor", "maxAdjustmentFactor");
        field_mappings.insert("min_adjustment_factor", "minAdjustmentFactor");
        field_mappings.insert("adjustment_cooldown_ms", "adjustmentCooldownMs");
        field_mappings.insert("state_change_cooldown_ms", "stateChangeCooldownMs");
        field_mappings.insert("parameter_dampening_factor", "parameterDampeningFactor");
        field_mappings.insert("hysteresis_delay_frames", "hysteresisDelayFrames");
        field_mappings.insert("grid_cell_size_min", "gridCellSizeMin");
        field_mappings.insert("grid_cell_size_max", "gridCellSizeMax");
        field_mappings.insert("repulsion_cutoff_min", "repulsionCutoffMin");
        field_mappings.insert("repulsion_cutoff_max", "repulsionCutoffMax");
        field_mappings.insert("repulsion_softening_min", "repulsionSofteningMin");
        field_mappings.insert("repulsion_softening_max", "repulsionSofteningMax");
        field_mappings.insert("center_gravity_min", "centerGravityMin");
        field_mappings.insert("center_gravity_max", "centerGravityMax");
        field_mappings.insert(
            "spatial_hash_efficiency_threshold",
            "spatialHashEfficiencyThreshold",
        );
        field_mappings.insert("cluster_density_threshold", "clusterDensityThreshold");
        field_mappings.insert(
            "numerical_instability_threshold",
            "numericalInstabilityThreshold",
        );

        
        field_mappings.insert("bounds_size", "boundsSize");
        field_mappings.insert("separation_radius", "separationRadius");
        field_mappings.insert("enable_bounds", "enableBounds");
        field_mappings.insert("max_velocity", "maxVelocity");
        field_mappings.insert("max_force", "maxForce");
        field_mappings.insert("repel_k", "repelK");
        field_mappings.insert("spring_k", "springK");
        field_mappings.insert("mass_scale", "massScale");
        field_mappings.insert("boundary_damping", "boundaryDamping");
        field_mappings.insert("update_threshold", "updateThreshold");
        field_mappings.insert("stress_weight", "stressWeight");
        field_mappings.insert("stress_alpha", "stressAlpha");
        field_mappings.insert("boundary_limit", "boundaryLimit");
        field_mappings.insert("alignment_strength", "alignmentStrength");
        field_mappings.insert("cluster_strength", "clusterStrength");
        field_mappings.insert("compute_mode", "computeMode");
        field_mappings.insert("rest_length", "restLength");
        field_mappings.insert("repulsion_cutoff", "repulsionCutoff");
        field_mappings.insert("repulsion_softening_epsilon", "repulsionSofteningEpsilon");
        field_mappings.insert("center_gravity_k", "centerGravityK");
        field_mappings.insert("grid_cell_size", "gridCellSize");
        field_mappings.insert("warmup_iterations", "warmupIterations");
        field_mappings.insert("cooling_rate", "coolingRate");
        field_mappings.insert("boundary_extreme_multiplier", "boundaryExtremeMultiplier");
        field_mappings.insert(
            "boundary_extreme_force_multiplier",
            "boundaryExtremeForceMultiplier",
        );
        field_mappings.insert("boundary_velocity_damping", "boundaryVelocityDamping");
        field_mappings.insert("min_distance", "minDistance");
        field_mappings.insert("max_repulsion_dist", "maxRepulsionDist");
        field_mappings.insert("boundary_margin", "boundaryMargin");
        field_mappings.insert("boundary_force_strength", "boundaryForceStrength");
        field_mappings.insert("warmup_curve", "warmupCurve");
        field_mappings.insert("zero_velocity_iterations", "zeroVelocityIterations");

        
        field_mappings.insert("host_port", "hostPort");
        field_mappings.insert("log_level", "logLevel");
        field_mappings.insert("persist_settings", "persistSettings");
        field_mappings.insert("gpu_memory_limit", "gpuMemoryLimit");

        field_mappings
    });

///
///
///
///
///
///
///
///
///
///
fn normalize_field_names_to_camel_case(value: Value) -> Result<Value, String> {
    normalize_object_fields(value, &FIELD_MAPPINGS)
}

///
fn normalize_object_fields(
    value: Value,
    mappings: &std::collections::HashMap<&str, &str>,
) -> Result<Value, String> {
    match value {
        Value::Object(map) => {
            let mut new_map = serde_json::Map::new();

            for (key, val) in map {
                
                let normalized_key = if let Some(&camel_case_key) = mappings.get(key.as_str()) {
                    
                    camel_case_key.to_string()
                } else {
                    
                    key
                };

                
                let normalized_value = normalize_object_fields(val, mappings)?;
                new_map.insert(normalized_key, normalized_value);
            }

            Ok(Value::Object(new_map))
        }
        Value::Array(arr) => {
            let normalized_array: Result<Vec<Value>, String> = arr
                .into_iter()
                .map(|item| normalize_object_fields(item, mappings))
                .collect();
            Ok(Value::Array(normalized_array?))
        }
        
        _ => Ok(value),
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type)]
#[serde(rename_all = "camelCase")]
pub struct MovementAxes {
    #[serde(alias = "horizontal")]
    pub horizontal: i32,
    #[serde(alias = "vertical")]
    pub vertical: i32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, PartialEq, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct NodeSettings {
    #[validate(custom(function = "validate_hex_color"))]
    #[serde(alias = "base_color")]
    pub base_color: String,
    #[validate(range(min = 0.0, max = 1.0))]
    #[serde(alias = "metalness")]
    pub metalness: f32,
    #[validate(range(min = 0.0, max = 1.0))]
    #[serde(alias = "opacity")]
    pub opacity: f32,
    #[validate(range(min = 0.0, max = 1.0))]
    #[serde(alias = "roughness")]
    pub roughness: f32,
    #[validate(range(min = 0.1, max = 100.0))]
    #[serde(alias = "node_size")]
    pub node_size: f32,
    #[serde(alias = "quality")]
    pub quality: String,
    #[serde(alias = "enable_instancing")]
    pub enable_instancing: bool,
    #[serde(alias = "enable_hologram")]
    pub enable_hologram: bool,
    #[serde(alias = "enable_metadata_shape")]
    pub enable_metadata_shape: bool,
    #[serde(alias = "enable_metadata_visualisation")]
    pub enable_metadata_visualisation: bool,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, PartialEq, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct EdgeSettings {
    #[validate(range(min = 0.01, max = 5.0))]
    #[serde(alias = "arrow_size")]
    pub arrow_size: f32,
    #[validate(range(min = 0.01, max = 5.0))]
    #[serde(alias = "base_width")]
    pub base_width: f32,
    #[validate(custom(function = "validate_hex_color"))]
    #[serde(alias = "color")]
    pub color: String,
    #[serde(alias = "enable_arrows")]
    pub enable_arrows: bool,
    #[validate(range(min = 0.0, max = 1.0))]
    #[serde(alias = "opacity")]
    pub opacity: f32,
    #[validate(custom(function = "validate_width_range"))]
    #[serde(alias = "width_range")]
    pub width_range: Vec<f32>,
    #[serde(alias = "quality")]
    pub quality: String,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct AutoPauseConfig {
    #[serde(alias = "enabled")]
    pub enabled: bool,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(alias = "equilibrium_velocity_threshold")]
    pub equilibrium_velocity_threshold: f32,
    #[validate(range(min = 1, max = 300))]
    #[serde(alias = "equilibrium_check_frames")]
    pub equilibrium_check_frames: u32,
    #[validate(range(min = 0.0, max = 1.0))]
    #[serde(alias = "equilibrium_energy_threshold")]
    pub equilibrium_energy_threshold: f32,
    #[serde(alias = "pause_on_equilibrium")]
    pub pause_on_equilibrium: bool,
    #[serde(alias = "resume_on_interaction")]
    pub resume_on_interaction: bool,
}

impl AutoPauseConfig {
    pub fn default() -> Self {
        Self {
            enabled: true,
            equilibrium_velocity_threshold: 0.1,
            equilibrium_check_frames: 30,
            equilibrium_energy_threshold: 0.01,
            pause_on_equilibrium: true,
            resume_on_interaction: true,
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct AutoBalanceConfig {
    #[serde(alias = "stability_variance_threshold")]
    pub stability_variance_threshold: f32,
    #[serde(alias = "stability_frame_count")]
    pub stability_frame_count: u32,
    #[serde(alias = "clustering_distance_threshold")]
    pub clustering_distance_threshold: f32,
    #[serde(alias = "clustering_hysteresis_buffer")]
    pub clustering_hysteresis_buffer: f32,
    #[serde(alias = "bouncing_node_percentage")]
    pub bouncing_node_percentage: f32,
    #[serde(alias = "boundary_min_distance")]
    pub boundary_min_distance: f32,
    #[serde(alias = "boundary_max_distance")]
    pub boundary_max_distance: f32,
    #[serde(alias = "extreme_distance_threshold")]
    pub extreme_distance_threshold: f32,
    #[serde(alias = "explosion_distance_threshold")]
    pub explosion_distance_threshold: f32,
    #[serde(alias = "spreading_distance_threshold")]
    pub spreading_distance_threshold: f32,
    #[serde(alias = "spreading_hysteresis_buffer")]
    pub spreading_hysteresis_buffer: f32,
    #[serde(alias = "oscillation_detection_frames")]
    pub oscillation_detection_frames: usize,
    #[serde(alias = "oscillation_change_threshold")]
    pub oscillation_change_threshold: f32,
    #[serde(alias = "min_oscillation_changes")]
    pub min_oscillation_changes: usize,

    
    #[serde(alias = "parameter_adjustment_rate")]
    pub parameter_adjustment_rate: f32,
    #[serde(alias = "max_adjustment_factor")]
    pub max_adjustment_factor: f32,
    #[serde(alias = "min_adjustment_factor")]
    pub min_adjustment_factor: f32,
    #[serde(alias = "adjustment_cooldown_ms")]
    pub adjustment_cooldown_ms: u64,
    #[serde(alias = "state_change_cooldown_ms")]
    pub state_change_cooldown_ms: u64,
    #[serde(alias = "parameter_dampening_factor")]
    pub parameter_dampening_factor: f32,
    #[serde(alias = "hysteresis_delay_frames")]
    pub hysteresis_delay_frames: u32,

    
    #[serde(alias = "grid_cell_size_min")]
    pub grid_cell_size_min: f32,
    #[serde(alias = "grid_cell_size_max")]
    pub grid_cell_size_max: f32,
    #[serde(alias = "repulsion_cutoff_min")]
    pub repulsion_cutoff_min: f32,
    #[serde(alias = "repulsion_cutoff_max")]
    pub repulsion_cutoff_max: f32,
    #[serde(alias = "repulsion_softening_min")]
    pub repulsion_softening_min: f32,
    #[serde(alias = "repulsion_softening_max")]
    pub repulsion_softening_max: f32,
    #[serde(alias = "center_gravity_min")]
    pub center_gravity_min: f32,
    #[serde(alias = "center_gravity_max")]
    pub center_gravity_max: f32,

    
    #[serde(alias = "spatial_hash_efficiency_threshold")]
    pub spatial_hash_efficiency_threshold: f32,
    #[serde(alias = "cluster_density_threshold")]
    pub cluster_density_threshold: f32,
    #[serde(alias = "numerical_instability_threshold")]
    pub numerical_instability_threshold: f32,
}

impl AutoBalanceConfig {
    pub fn default() -> Self {
        Self {
            stability_variance_threshold: 100.0,
            stability_frame_count: 180,
            clustering_distance_threshold: 20.0,
            clustering_hysteresis_buffer: 5.0,
            bouncing_node_percentage: 0.33,
            boundary_min_distance: 90.0,
            boundary_max_distance: 110.0,
            extreme_distance_threshold: 1000.0,
            explosion_distance_threshold: 10000.0,
            spreading_distance_threshold: 500.0,
            spreading_hysteresis_buffer: 50.0,
            oscillation_detection_frames: 20,
            oscillation_change_threshold: 10.0,
            min_oscillation_changes: 8,

            
            parameter_adjustment_rate: 0.1,
            max_adjustment_factor: 0.2,
            min_adjustment_factor: -0.2,
            adjustment_cooldown_ms: 2000,
            state_change_cooldown_ms: 1000,
            parameter_dampening_factor: 0.05,
            hysteresis_delay_frames: 30,

            
            grid_cell_size_min: 1.0,
            grid_cell_size_max: 50.0,
            repulsion_cutoff_min: 5.0,
            repulsion_cutoff_max: 200.0,
            repulsion_softening_min: 1e-6,
            repulsion_softening_max: 1.0,
            center_gravity_min: 0.0,
            center_gravity_max: 0.1,

            
            spatial_hash_efficiency_threshold: 0.3, 
            cluster_density_threshold: 50.0,        
            numerical_instability_threshold: 1e-3,  
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct PhysicsSettings {
    #[serde(default, alias = "auto_balance")]
    pub auto_balance: bool,
    #[serde(
        default = "default_auto_balance_interval",
        alias = "auto_balance_interval_ms"
    )]
    pub auto_balance_interval_ms: u32,
    #[serde(default, alias = "auto_balance_config")]
    #[validate(nested)]
    pub auto_balance_config: AutoBalanceConfig,
    #[serde(default, alias = "auto_pause")]
    #[validate(nested)]
    pub auto_pause: AutoPauseConfig,
    #[serde(default = "default_bounds_size", alias = "bounds_size")]
    pub bounds_size: f32,
    #[serde(alias = "separation_radius")]
    pub separation_radius: f32,
    #[serde(alias = "damping")]
    pub damping: f32,
    #[serde(alias = "enable_bounds")]
    pub enable_bounds: bool,
    #[serde(alias = "enabled")]
    pub enabled: bool,
    #[serde(alias = "iterations")]
    pub iterations: u32,
    #[serde(alias = "max_velocity")]
    pub max_velocity: f32,
    #[serde(alias = "max_force")]
    pub max_force: f32,
    #[serde(alias = "repel_k")]
    pub repel_k: f32,
    #[serde(alias = "spring_k")]
    pub spring_k: f32,
    #[serde(alias = "mass_scale")]
    pub mass_scale: f32,
    #[serde(alias = "boundary_damping")]
    pub boundary_damping: f32,
    #[serde(alias = "update_threshold")]
    pub update_threshold: f32,
    #[serde(alias = "dt")]
    pub dt: f32,
    #[serde(alias = "temperature")]
    pub temperature: f32,
    #[serde(alias = "gravity")]
    pub gravity: f32,
    
    #[serde(alias = "stress_weight")]
    pub stress_weight: f32,
    #[serde(alias = "stress_alpha")]
    pub stress_alpha: f32,
    #[serde(alias = "boundary_limit")]
    pub boundary_limit: f32,
    #[serde(alias = "alignment_strength")]
    pub alignment_strength: f32,
    #[serde(alias = "cluster_strength")]
    pub cluster_strength: f32,
    #[serde(alias = "compute_mode")]
    pub compute_mode: i32,

    
    #[serde(alias = "rest_length")]
    pub rest_length: f32,
    #[serde(alias = "repulsion_cutoff")]
    pub repulsion_cutoff: f32,
    #[serde(alias = "repulsion_softening_epsilon")]
    pub repulsion_softening_epsilon: f32,
    #[serde(alias = "center_gravity_k")]
    pub center_gravity_k: f32,
    #[serde(alias = "grid_cell_size")]
    pub grid_cell_size: f32,
    #[serde(alias = "warmup_iterations")]
    pub warmup_iterations: u32,
    #[serde(alias = "cooling_rate")]
    pub cooling_rate: f32,
    #[serde(alias = "boundary_extreme_multiplier")]
    pub boundary_extreme_multiplier: f32,
    #[serde(alias = "boundary_extreme_force_multiplier")]
    pub boundary_extreme_force_multiplier: f32,
    #[serde(alias = "boundary_velocity_damping")]
    pub boundary_velocity_damping: f32,
    
    #[serde(alias = "min_distance")]
    pub min_distance: f32,
    #[serde(alias = "max_repulsion_dist")]
    pub max_repulsion_dist: f32,
    #[serde(alias = "boundary_margin")]
    pub boundary_margin: f32,
    #[serde(alias = "boundary_force_strength")]
    pub boundary_force_strength: f32,
    #[serde(alias = "warmup_curve")]
    pub warmup_curve: String,
    #[serde(alias = "zero_velocity_iterations")]
    pub zero_velocity_iterations: u32,

    
    #[serde(
        alias = "constraint_ramp_frames",
        default = "default_constraint_ramp_frames"
    )]
    pub constraint_ramp_frames: u32,
    #[serde(
        alias = "constraint_max_force_per_node",
        default = "default_constraint_max_force_per_node"
    )]
    pub constraint_max_force_per_node: f32,

    
    #[serde(alias = "clustering_algorithm")]
    pub clustering_algorithm: String,
    #[serde(alias = "cluster_count")]
    pub cluster_count: u32,
    #[serde(alias = "clustering_resolution")]
    pub clustering_resolution: f32,
    #[serde(alias = "clustering_iterations")]
    pub clustering_iterations: u32,
}

impl Default for PhysicsSettings {
    fn default() -> Self {
        Self {
            auto_balance: false,
            auto_balance_interval_ms: 500,
            auto_balance_config: AutoBalanceConfig::default(),
            auto_pause: AutoPauseConfig::default(),
            bounds_size: 500.0,
            separation_radius: 2.0,
            damping: 0.95,
            enable_bounds: true,
            enabled: true,
            iterations: 100,
            max_velocity: 1.0,
            max_force: 100.0,
            repel_k: 50.0,
            spring_k: 0.005,
            mass_scale: 1.0,
            boundary_damping: 0.95,
            update_threshold: 0.01,
            dt: 0.016,
            temperature: 0.01,
            gravity: 0.0001,
            stress_weight: 0.1,
            stress_alpha: 0.1,
            boundary_limit: 490.0,
            alignment_strength: 0.0,
            cluster_strength: 0.0,
            compute_mode: 0,
            
            rest_length: 50.0,
            repulsion_cutoff: 50.0,
            repulsion_softening_epsilon: 0.0001,
            center_gravity_k: 0.0,
            grid_cell_size: 50.0,
            warmup_iterations: 100,
            cooling_rate: 0.001,
            boundary_extreme_multiplier: 2.0,
            boundary_extreme_force_multiplier: 10.0,
            boundary_velocity_damping: 0.5,
            
            min_distance: 0.15,
            max_repulsion_dist: 50.0,
            boundary_margin: 0.85,
            boundary_force_strength: 2.0,
            warmup_curve: "quadratic".to_string(),
            zero_velocity_iterations: 5,
            
            constraint_ramp_frames: default_constraint_ramp_frames(),
            constraint_max_force_per_node: default_constraint_max_force_per_node(),
            
            clustering_algorithm: "none".to_string(),
            cluster_count: 5,
            clustering_resolution: 1.0,
            clustering_iterations: 30,
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct RenderingSettings {
    #[serde(alias = "ambient_light_intensity")]
    pub ambient_light_intensity: f32,
    #[serde(alias = "background_color")]
    pub background_color: String,
    #[serde(alias = "directional_light_intensity")]
    pub directional_light_intensity: f32,
    #[serde(alias = "enable_ambient_occlusion")]
    pub enable_ambient_occlusion: bool,
    #[serde(alias = "enable_antialiasing")]
    pub enable_antialiasing: bool,
    #[serde(alias = "enable_shadows")]
    pub enable_shadows: bool,
    #[serde(alias = "environment_intensity")]
    pub environment_intensity: f32,
    #[serde(skip_serializing_if = "Option::is_none", alias = "shadow_map_size")]
    pub shadow_map_size: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "shadow_bias")]
    pub shadow_bias: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "context")]
    pub context: Option<String>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct AnimationSettings {
    #[serde(alias = "enable_motion_blur")]
    pub enable_motion_blur: bool,
    #[serde(alias = "enable_node_animations")]
    pub enable_node_animations: bool,
    #[serde(alias = "motion_blur_strength")]
    pub motion_blur_strength: f32,
    #[serde(alias = "selection_wave_enabled")]
    pub selection_wave_enabled: bool,
    #[serde(alias = "pulse_enabled")]
    pub pulse_enabled: bool,
    #[serde(alias = "pulse_speed")]
    pub pulse_speed: f32,
    #[serde(alias = "pulse_strength")]
    pub pulse_strength: f32,
    #[serde(alias = "wave_speed")]
    pub wave_speed: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, PartialEq, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct LabelSettings {
    #[serde(alias = "desktop_font_size")]
    pub desktop_font_size: f32,
    #[serde(alias = "enable_labels")]
    pub enable_labels: bool,
    #[serde(alias = "text_color")]
    pub text_color: String,
    #[serde(alias = "text_outline_color")]
    pub text_outline_color: String,
    #[serde(alias = "text_outline_width")]
    pub text_outline_width: f32,
    #[serde(alias = "text_resolution")]
    pub text_resolution: u32,
    #[serde(alias = "text_padding")]
    pub text_padding: f32,
    #[serde(alias = "billboard_mode")]
    pub billboard_mode: String,
    #[serde(skip_serializing_if = "Option::is_none", alias = "show_metadata")]
    pub show_metadata: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "max_label_width")]
    pub max_label_width: Option<f32>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct GlowSettings {
    #[serde(alias = "enabled")]
    pub enabled: bool,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(alias = "intensity")]
    pub intensity: f32,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(alias = "radius")]
    pub radius: f32,
    #[validate(range(min = 0.0, max = 1.0))]
    #[serde(alias = "threshold")]
    pub threshold: f32,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(default, alias = "diffuse_strength")]
    pub diffuse_strength: f32,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(default, alias = "atmospheric_density")]
    pub atmospheric_density: f32,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(default, alias = "volumetric_intensity")]
    pub volumetric_intensity: f32,
    #[validate(custom(function = "validate_hex_color"))]
    #[serde(
        skip_serializing_if = "String::is_empty",
        default = "default_glow_color",
        alias = "base_color"
    )]
    pub base_color: String,
    #[validate(custom(function = "validate_hex_color"))]
    #[serde(
        skip_serializing_if = "String::is_empty",
        default = "default_glow_color",
        alias = "emission_color"
    )]
    pub emission_color: String,
    #[validate(range(min = 0.0, max = 1.0))]
    #[serde(default = "default_glow_opacity", alias = "opacity")]
    pub opacity: f32,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(default, alias = "pulse_speed")]
    pub pulse_speed: f32,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(default, alias = "flow_speed")]
    pub flow_speed: f32,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(default, alias = "node_glow_strength")]
    pub node_glow_strength: f32,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(default, alias = "edge_glow_strength")]
    pub edge_glow_strength: f32,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(default, alias = "environment_glow_strength")]
    pub environment_glow_strength: f32,
}

///
fn default_bloom_intensity() -> f32 {
    1.0
}

///
fn default_bloom_radius() -> f32 {
    0.8
}

///
fn default_bloom_threshold() -> f32 {
    0.15
}

///
fn default_bloom_color() -> String {
    "#ffffff".to_string()
}

#[derive(Debug, Serialize, Deserialize, Clone, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct BloomSettings {
    #[serde(alias = "enabled")]
    pub enabled: bool,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(default = "default_bloom_intensity", alias = "intensity")]
    pub intensity: f32,
    #[validate(range(min = 0.0, max = 10.0))]
    #[serde(default = "default_bloom_radius", alias = "radius")]
    pub radius: f32,
    #[validate(range(min = 0.0, max = 1.0))]
    #[serde(default = "default_bloom_threshold", alias = "threshold")]
    pub threshold: f32,
    #[validate(custom(function = "validate_hex_color"))]
    #[serde(
        skip_serializing_if = "String::is_empty",
        default = "default_bloom_color",
        alias = "color"
    )]
    pub color: String,
    #[validate(custom(function = "validate_hex_color"))]
    #[serde(
        skip_serializing_if = "String::is_empty",
        default = "default_bloom_color",
        alias = "tint_color"
    )]
    pub tint_color: String,
    #[validate(range(min = 0.0, max = 1.0))]
    #[serde(default, alias = "strength")]
    pub strength: f32,
    #[validate(range(min = 0.0, max = 5.0))]
    #[serde(default, alias = "blur_passes")]
    pub blur_passes: f32,
    #[validate(range(min = 0.0, max = 2.0))]
    #[serde(default, alias = "knee")]
    pub knee: f32,
}

impl Default for BloomSettings {
    fn default() -> Self {
        Self {
            enabled: true,
            intensity: default_bloom_intensity(),
            radius: default_bloom_radius(),
            threshold: default_bloom_threshold(),
            color: default_bloom_color(),
            tint_color: default_bloom_color(),
            strength: 0.8,
            blur_passes: 1.0,
            knee: 0.7,
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct HologramSettings {
    #[serde(alias = "ring_count")]
    pub ring_count: u32,
    #[serde(alias = "ring_color")]
    pub ring_color: String,
    #[serde(alias = "ring_opacity")]
    pub ring_opacity: f32,
    #[serde(alias = "sphere_sizes")]
    pub sphere_sizes: Vec<f32>,
    #[serde(alias = "ring_rotation_speed")]
    pub ring_rotation_speed: f32,
    #[serde(alias = "enable_buckminster")]
    pub enable_buckminster: bool,
    #[serde(alias = "buckminster_size")]
    pub buckminster_size: f32,
    #[serde(alias = "buckminster_opacity")]
    pub buckminster_opacity: f32,
    #[serde(alias = "enable_geodesic")]
    pub enable_geodesic: bool,
    #[serde(alias = "geodesic_size")]
    pub geodesic_size: f32,
    #[serde(alias = "geodesic_opacity")]
    pub geodesic_opacity: f32,
    #[serde(alias = "enable_triangle_sphere")]
    pub enable_triangle_sphere: bool,
    #[serde(alias = "triangle_sphere_size")]
    pub triangle_sphere_size: f32,
    #[serde(alias = "triangle_sphere_opacity")]
    pub triangle_sphere_opacity: f32,
    #[serde(alias = "global_rotation_speed")]
    pub global_rotation_speed: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct CameraSettings {
    #[serde(alias = "fov")]
    pub fov: f32,
    #[serde(alias = "near")]
    pub near: f32,
    #[serde(alias = "far")]
    pub far: f32,
    #[serde(alias = "position")]
    pub position: Position,
    #[serde(alias = "look_at")]
    pub look_at: Position,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type)]
#[serde(rename_all = "camelCase")]
pub struct Position {
    #[serde(alias = "x")]
    pub x: f32,
    #[serde(alias = "y")]
    pub y: f32,
    #[serde(alias = "z")]
    pub z: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct SpacePilotSettings {
    #[serde(alias = "enabled")]
    pub enabled: bool,
    #[serde(alias = "mode")]
    pub mode: String,
    #[serde(alias = "sensitivity")]
    pub sensitivity: Sensitivity,
    #[serde(alias = "smoothing")]
    pub smoothing: f32,
    #[serde(alias = "deadzone")]
    pub deadzone: f32,
    #[serde(alias = "button_functions")]
    pub button_functions: std::collections::HashMap<String, String>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type)]
#[serde(rename_all = "camelCase")]
pub struct Sensitivity {
    #[serde(alias = "translation")]
    pub translation: f32,
    #[serde(alias = "rotation")]
    pub rotation: f32,
}

// Graph-specific settings
#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct GraphSettings {
    #[validate(nested)]
    pub nodes: NodeSettings,
    #[validate(nested)]
    pub edges: EdgeSettings,
    #[validate(nested)]
    pub labels: LabelSettings,
    #[validate(nested)]
    pub physics: PhysicsSettings,
}

// Multi-graph container
#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct GraphsSettings {
    #[validate(nested)]
    pub logseq: GraphSettings,
    #[validate(nested)]
    pub visionflow: GraphSettings,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct VisualisationSettings {
    
    #[validate(nested)]
    pub rendering: RenderingSettings,
    #[validate(nested)]
    pub animations: AnimationSettings,
    #[validate(nested)]
    pub glow: GlowSettings,
    #[validate(nested)]
    pub bloom: BloomSettings,
    #[validate(nested)]
    pub hologram: HologramSettings,
    #[validate(nested)]
    pub graphs: GraphsSettings,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub camera: Option<CameraSettings>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub space_pilot: Option<SpacePilotSettings>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct NetworkSettings {
    #[serde(alias = "bind_address")]
    pub bind_address: String,
    #[serde(alias = "domain")]
    pub domain: String,
    #[serde(alias = "enable_http2")]
    pub enable_http2: bool,
    #[serde(alias = "enable_rate_limiting")]
    pub enable_rate_limiting: bool,
    #[serde(alias = "enable_tls")]
    pub enable_tls: bool,
    #[serde(alias = "max_request_size")]
    pub max_request_size: usize,
    #[serde(alias = "min_tls_version")]
    pub min_tls_version: String,
    #[serde(alias = "port")]
    pub port: u16,
    #[serde(alias = "rate_limit_requests")]
    pub rate_limit_requests: u32,
    #[serde(alias = "rate_limit_window")]
    pub rate_limit_window: u32,
    #[serde(alias = "tunnel_id")]
    pub tunnel_id: String,
    #[serde(alias = "api_client_timeout")]
    pub api_client_timeout: u64,
    #[serde(alias = "enable_metrics")]
    pub enable_metrics: bool,
    #[serde(alias = "max_concurrent_requests")]
    pub max_concurrent_requests: u32,
    #[serde(alias = "max_retries")]
    pub max_retries: u32,
    #[serde(alias = "metrics_port")]
    pub metrics_port: u16,
    #[serde(alias = "retry_delay")]
    pub retry_delay: u32,
}

impl Default for NetworkSettings {
    fn default() -> Self {
        Self {
            bind_address: "0.0.0.0".to_string(), 
            port: 8080,                          
            domain: String::new(),
            enable_http2: false,
            enable_rate_limiting: false,
            enable_tls: false,
            max_request_size: 10485760, 
            min_tls_version: "1.2".to_string(),
            rate_limit_requests: 100,
            rate_limit_window: 60,
            tunnel_id: String::new(),
            api_client_timeout: 30,
            enable_metrics: true,
            max_concurrent_requests: 1000,
            max_retries: 3,
            metrics_port: 9090,
            retry_delay: 1000, 
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct WebSocketSettings {
    #[serde(alias = "binary_chunk_size")]
    pub binary_chunk_size: usize,
    #[serde(alias = "binary_update_rate")]
    pub binary_update_rate: u32,
    #[serde(alias = "min_update_rate")]
    pub min_update_rate: u32,
    #[serde(alias = "max_update_rate")]
    pub max_update_rate: u32,
    #[serde(alias = "motion_threshold")]
    pub motion_threshold: f32,
    #[serde(alias = "motion_damping")]
    pub motion_damping: f32,
    #[serde(alias = "binary_message_version")]
    pub binary_message_version: u32,
    #[serde(alias = "compression_enabled")]
    pub compression_enabled: bool,
    #[serde(alias = "compression_threshold")]
    pub compression_threshold: usize,
    #[serde(alias = "heartbeat_interval")]
    pub heartbeat_interval: u64,
    #[serde(alias = "heartbeat_timeout")]
    pub heartbeat_timeout: u64,
    #[serde(alias = "max_connections")]
    pub max_connections: usize,
    #[serde(alias = "max_message_size")]
    pub max_message_size: usize,
    #[serde(alias = "reconnect_attempts")]
    pub reconnect_attempts: u32,
    #[serde(alias = "reconnect_delay")]
    pub reconnect_delay: u64,
    #[serde(alias = "update_rate")]
    pub update_rate: u32,
}

impl Default for WebSocketSettings {
    fn default() -> Self {
        Self {
            binary_chunk_size: 2048,
            binary_update_rate: 30,
            min_update_rate: 5,
            max_update_rate: 60,
            motion_threshold: 0.05,
            motion_damping: 0.9,
            binary_message_version: 1,
            compression_enabled: false,
            compression_threshold: 512,
            heartbeat_interval: 10000,
            heartbeat_timeout: 600000,
            max_connections: 100,
            max_message_size: 10485760,
            reconnect_attempts: 5,
            reconnect_delay: 1000,
            update_rate: 60,
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct SecuritySettings {
    #[serde(alias = "allowed_origins")]
    pub allowed_origins: Vec<String>,
    #[serde(alias = "audit_log_path")]
    pub audit_log_path: String,
    #[serde(alias = "cookie_httponly")]
    pub cookie_httponly: bool,
    #[serde(alias = "cookie_samesite")]
    pub cookie_samesite: String,
    #[serde(alias = "cookie_secure")]
    pub cookie_secure: bool,
    #[serde(alias = "csrf_token_timeout")]
    pub csrf_token_timeout: u32,
    #[serde(alias = "enable_audit_logging")]
    pub enable_audit_logging: bool,
    #[serde(alias = "enable_request_validation")]
    pub enable_request_validation: bool,
    #[serde(alias = "session_timeout")]
    pub session_timeout: u32,
}

// Simple debug settings for server-side control
#[derive(Debug, Serialize, Deserialize, Clone, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct DebugSettings {
    #[serde(default, alias = "enabled")]
    pub enabled: bool,
}

impl Default for DebugSettings {
    fn default() -> Self {
        Self { enabled: false }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct SystemSettings {
    #[validate(nested)]
    #[serde(alias = "network")]
    pub network: NetworkSettings,
    #[validate(nested)]
    #[serde(alias = "websocket")]
    pub websocket: WebSocketSettings,
    #[validate(nested)]
    #[serde(alias = "security")]
    pub security: SecuritySettings,
    #[validate(nested)]
    #[serde(alias = "debug")]
    pub debug: DebugSettings,
    #[serde(default, alias = "persist_settings")]
    pub persist_settings: bool,
    #[serde(skip_serializing_if = "Option::is_none", alias = "custom_backend_url")]
    pub custom_backend_url: Option<String>,
}

impl Default for SystemSettings {
    fn default() -> Self {
        Self {
            network: NetworkSettings::default(),
            websocket: WebSocketSettings::default(),
            security: SecuritySettings::default(),
            debug: DebugSettings::default(),
            persist_settings: false,
            custom_backend_url: None,
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct XRSettings {
    #[serde(skip_serializing_if = "Option::is_none", alias = "enabled")]
    pub enabled: Option<bool>,
    #[serde(
        skip_serializing_if = "Option::is_none",
        alias = "client_side_enable_xr"
    )]
    pub client_side_enable_xr: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "mode")]
    pub mode: Option<String>,
    #[serde(alias = "room_scale")]
    pub room_scale: f32,
    #[serde(alias = "space_type")]
    pub space_type: String,
    #[serde(alias = "quality")]
    pub quality: String,
    #[serde(skip_serializing_if = "Option::is_none", alias = "render_scale")]
    pub render_scale: Option<f32>,
    #[serde(alias = "interaction_distance")]
    pub interaction_distance: f32,
    #[serde(alias = "locomotion_method")]
    pub locomotion_method: String,
    #[serde(alias = "teleport_ray_color")]
    pub teleport_ray_color: String,
    #[serde(alias = "controller_ray_color")]
    pub controller_ray_color: String,
    #[serde(skip_serializing_if = "Option::is_none", alias = "controller_model")]
    pub controller_model: Option<String>,

    #[serde(alias = "enable_hand_tracking")]
    pub enable_hand_tracking: bool,
    #[serde(alias = "hand_mesh_enabled")]
    pub hand_mesh_enabled: bool,
    #[serde(alias = "hand_mesh_color")]
    pub hand_mesh_color: String,
    #[serde(alias = "hand_mesh_opacity")]
    pub hand_mesh_opacity: f32,
    #[serde(alias = "hand_point_size")]
    pub hand_point_size: f32,
    #[serde(alias = "hand_ray_enabled")]
    pub hand_ray_enabled: bool,
    #[serde(alias = "hand_ray_color")]
    pub hand_ray_color: String,
    #[serde(alias = "hand_ray_width")]
    pub hand_ray_width: f32,
    #[serde(alias = "gesture_smoothing")]
    pub gesture_smoothing: f32,

    #[serde(alias = "enable_haptics")]
    pub enable_haptics: bool,
    #[serde(alias = "haptic_intensity")]
    pub haptic_intensity: f32,
    #[serde(alias = "drag_threshold")]
    pub drag_threshold: f32,
    #[serde(alias = "pinch_threshold")]
    pub pinch_threshold: f32,
    #[serde(alias = "rotation_threshold")]
    pub rotation_threshold: f32,
    #[serde(alias = "interaction_radius")]
    pub interaction_radius: f32,
    #[serde(alias = "movement_speed")]
    pub movement_speed: f32,
    #[serde(alias = "dead_zone")]
    pub dead_zone: f32,
    #[serde(alias = "movement_axes")]
    pub movement_axes: MovementAxes,

    #[serde(alias = "enable_light_estimation")]
    pub enable_light_estimation: bool,
    #[serde(alias = "enable_plane_detection")]
    pub enable_plane_detection: bool,
    #[serde(alias = "enable_scene_understanding")]
    pub enable_scene_understanding: bool,
    #[serde(alias = "plane_color")]
    pub plane_color: String,
    #[serde(alias = "plane_opacity")]
    pub plane_opacity: f32,
    #[serde(alias = "plane_detection_distance")]
    pub plane_detection_distance: f32,
    #[serde(alias = "show_plane_overlay")]
    pub show_plane_overlay: bool,
    #[serde(alias = "snap_to_floor")]
    pub snap_to_floor: bool,

    #[serde(alias = "enable_passthrough_portal")]
    pub enable_passthrough_portal: bool,
    #[serde(alias = "passthrough_opacity")]
    pub passthrough_opacity: f32,
    #[serde(alias = "passthrough_brightness")]
    pub passthrough_brightness: f32,
    #[serde(alias = "passthrough_contrast")]
    pub passthrough_contrast: f32,
    #[serde(alias = "portal_size")]
    pub portal_size: f32,
    #[serde(alias = "portal_edge_color")]
    pub portal_edge_color: String,
    #[serde(alias = "portal_edge_width")]
    pub portal_edge_width: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct AuthSettings {
    #[serde(alias = "enabled")]
    pub enabled: bool,
    #[serde(alias = "provider")]
    pub provider: String,
    #[serde(alias = "required")]
    pub required: bool,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct RagFlowSettings {
    #[serde(skip_serializing_if = "Option::is_none", alias = "api_key")]
    pub api_key: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "agent_id")]
    pub agent_id: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "api_base_url")]
    pub api_base_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "timeout")]
    pub timeout: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "max_retries")]
    pub max_retries: Option<u32>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "chat_id")]
    pub chat_id: Option<String>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct PerplexitySettings {
    #[serde(skip_serializing_if = "Option::is_none", alias = "api_key")]
    pub api_key: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "model")]
    pub model: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "api_url")]
    pub api_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "max_tokens")]
    pub max_tokens: Option<u32>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "temperature")]
    pub temperature: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "top_p")]
    pub top_p: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "presence_penalty")]
    pub presence_penalty: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "frequency_penalty")]
    pub frequency_penalty: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "timeout")]
    pub timeout: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "rate_limit")]
    pub rate_limit: Option<u32>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct OpenAISettings {
    #[serde(skip_serializing_if = "Option::is_none", alias = "api_key")]
    pub api_key: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "base_url")]
    pub base_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "timeout")]
    pub timeout: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "rate_limit")]
    pub rate_limit: Option<u32>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct KokoroSettings {
    #[serde(skip_serializing_if = "Option::is_none", alias = "api_url")]
    pub api_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "default_voice")]
    pub default_voice: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "default_format")]
    pub default_format: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "default_speed")]
    pub default_speed: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "timeout")]
    pub timeout: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "stream")]
    pub stream: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "return_timestamps")]
    pub return_timestamps: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "sample_rate")]
    pub sample_rate: Option<u32>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct WhisperSettings {
    #[serde(skip_serializing_if = "Option::is_none", alias = "api_url")]
    pub api_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "default_model")]
    pub default_model: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "default_language")]
    pub default_language: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "timeout")]
    pub timeout: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "temperature")]
    pub temperature: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "return_timestamps")]
    pub return_timestamps: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "vad_filter")]
    pub vad_filter: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "word_timestamps")]
    pub word_timestamps: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "initial_prompt")]
    pub initial_prompt: Option<String>,
}

// Constraint system structures
// Note: ConstraintData has been moved to models/constraints.rs for GPU compatibility
// The old simple structure has been replaced with a GPU-optimized version

// Legacy constraint system for web API compatibility
#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct LegacyConstraintData {
    #[serde(alias = "constraint_type")]
    pub constraint_type: i32, 
    #[serde(alias = "strength")]
    pub strength: f32,
    #[serde(alias = "param1")]
    pub param1: f32,
    #[serde(alias = "param2")]
    pub param2: f32,
    #[serde(alias = "node_mask")]
    pub node_mask: i32, 
    #[serde(alias = "enabled")]
    pub enabled: bool,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct ConstraintSystem {
    #[serde(alias = "separation")]
    pub separation: LegacyConstraintData,
    #[serde(alias = "boundary")]
    pub boundary: LegacyConstraintData,
    #[serde(alias = "alignment")]
    pub alignment: LegacyConstraintData,
    #[serde(alias = "cluster")]
    pub cluster: LegacyConstraintData,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct ClusteringConfiguration {
    #[serde(alias = "algorithm")]
    pub algorithm: String,
    #[serde(alias = "num_clusters")]
    pub num_clusters: u32,
    #[serde(alias = "resolution")]
    pub resolution: f32,
    #[serde(alias = "iterations")]
    pub iterations: u32,
    #[serde(alias = "export_assignments")]
    pub export_assignments: bool,
    #[serde(alias = "auto_update")]
    pub auto_update: bool,
}

// Helper struct for physics updates
#[derive(Debug, Serialize, Deserialize, Clone, Default, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct PhysicsUpdate {
    #[serde(alias = "damping")]
    pub damping: Option<f32>,
    #[serde(alias = "spring_k")]
    pub spring_k: Option<f32>,
    #[serde(alias = "repel_k")]
    pub repel_k: Option<f32>,
    #[serde(alias = "iterations")]
    pub iterations: Option<u32>,
    #[serde(alias = "enabled")]
    pub enabled: Option<bool>,
    #[serde(alias = "bounds_size")]
    pub bounds_size: Option<f32>,
    #[serde(alias = "enable_bounds")]
    pub enable_bounds: Option<bool>,
    #[serde(alias = "max_velocity")]
    pub max_velocity: Option<f32>,
    #[serde(alias = "max_force")]
    pub max_force: Option<f32>,
    #[serde(alias = "separation_radius")]
    pub separation_radius: Option<f32>,
    #[serde(alias = "mass_scale")]
    pub mass_scale: Option<f32>,
    #[serde(alias = "boundary_damping")]
    pub boundary_damping: Option<f32>,
    #[serde(alias = "dt")]
    pub dt: Option<f32>,
    #[serde(alias = "temperature")]
    pub temperature: Option<f32>,
    #[serde(alias = "gravity")]
    pub gravity: Option<f32>,
    #[serde(alias = "update_threshold")]
    pub update_threshold: Option<f32>,
    
    #[serde(alias = "stress_weight")]
    pub stress_weight: Option<f32>,
    #[serde(alias = "stress_alpha")]
    pub stress_alpha: Option<f32>,
    #[serde(alias = "boundary_limit")]
    pub boundary_limit: Option<f32>,
    #[serde(alias = "alignment_strength")]
    pub alignment_strength: Option<f32>,
    #[serde(alias = "cluster_strength")]
    pub cluster_strength: Option<f32>,
    #[serde(alias = "compute_mode")]
    pub compute_mode: Option<i32>,
    
    #[serde(alias = "min_distance")]
    pub min_distance: Option<f32>,
    #[serde(alias = "max_repulsion_dist")]
    pub max_repulsion_dist: Option<f32>,
    #[serde(alias = "boundary_margin")]
    pub boundary_margin: Option<f32>,
    #[serde(alias = "boundary_force_strength")]
    pub boundary_force_strength: Option<f32>,
    #[serde(alias = "warmup_iterations")]
    pub warmup_iterations: Option<u32>,
    #[serde(alias = "warmup_curve")]
    pub warmup_curve: Option<String>,
    #[serde(alias = "zero_velocity_iterations")]
    pub zero_velocity_iterations: Option<u32>,
    #[serde(alias = "cooling_rate")]
    pub cooling_rate: Option<f32>,
    
    #[serde(alias = "clustering_algorithm")]
    pub clustering_algorithm: Option<String>,
    #[serde(alias = "cluster_count")]
    pub cluster_count: Option<u32>,
    #[serde(alias = "clustering_resolution")]
    pub clustering_resolution: Option<f32>,
    #[serde(alias = "clustering_iterations")]
    pub clustering_iterations: Option<u32>,
    
    #[serde(alias = "repulsion_softening_epsilon")]
    pub repulsion_softening_epsilon: Option<f32>,
    #[serde(alias = "center_gravity_k")]
    pub center_gravity_k: Option<f32>,
    #[serde(alias = "grid_cell_size")]
    pub grid_cell_size: Option<f32>,
    #[serde(alias = "rest_length")]
    pub rest_length: Option<f32>,
}

// User preferences configuration
#[derive(Debug, Clone, Deserialize, Serialize, Type, Validate, Default)]
#[serde(rename_all = "camelCase")]
pub struct UserPreferences {
    #[serde(default)]
    pub comfort_level: Option<f32>, 
    #[serde(default)]
    pub interaction_style: Option<String>, 
    #[serde(default)]
    pub ar_preference: Option<bool>, 
    #[serde(default)]
    pub theme: Option<String>, 
    #[serde(default)]
    pub language: Option<String>, 
}

// Feature flags for experimental or optional features
#[derive(Debug, Clone, Deserialize, Serialize, Type, Default)]
#[serde(rename_all = "camelCase")]
pub struct FeatureFlags {
    #[serde(default)]
    pub gpu_clustering: bool,
    #[serde(default)]
    pub ontology_validation: bool,
    #[serde(default)]
    pub gpu_anomaly_detection: bool,
    #[serde(default)]
    pub real_time_insights: bool,
    #[serde(default)]
    pub advanced_visualizations: bool,
    #[serde(default)]
    pub performance_monitoring: bool,
    #[serde(default)]
    pub stress_majorization: bool,
    #[serde(default)]
    pub semantic_constraints: bool,
    #[serde(default)]
    pub sssp_integration: bool,
}

// Developer and debugging configuration
#[derive(Debug, Clone, Deserialize, Serialize, Type, Default)]
#[serde(rename_all = "camelCase")]
pub struct DeveloperConfig {
    #[serde(default)]
    pub debug_mode: bool,
    #[serde(default)]
    pub show_performance_stats: bool,
    #[serde(default)]
    pub enable_profiling: bool,
    #[serde(default)]
    pub verbose_logging: bool,
    #[serde(default)]
    pub dev_tools_enabled: bool,
}

// Single unified settings struct
#[derive(Debug, Clone, Deserialize, Serialize, Type, Validate)]
#[serde(rename_all = "camelCase")]
pub struct AppFullSettings {
    #[validate(nested)]
    #[serde(alias = "visualisation")]
    pub visualisation: VisualisationSettings,
    #[validate(nested)]
    #[serde(alias = "system")]
    pub system: SystemSettings,
    #[validate(nested)]
    #[serde(alias = "xr")]
    pub xr: XRSettings,
    #[validate(nested)]
    #[serde(alias = "auth")]
    pub auth: AuthSettings,
    #[serde(skip_serializing_if = "Option::is_none", alias = "ragflow")]
    pub ragflow: Option<RagFlowSettings>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "perplexity")]
    pub perplexity: Option<PerplexitySettings>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "openai")]
    pub openai: Option<OpenAISettings>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "kokoro")]
    pub kokoro: Option<KokoroSettings>,
    #[serde(skip_serializing_if = "Option::is_none", alias = "whisper")]
    pub whisper: Option<WhisperSettings>,
    #[serde(default = "default_version", alias = "version")]
    pub version: String,
    
    #[serde(default, alias = "user_preferences")]
    #[validate(nested)]
    pub user_preferences: UserPreferences,
    #[serde(default, alias = "physics")]
    #[validate(nested)]
    pub physics: PhysicsSettings,
    #[serde(default, alias = "feature_flags")]
    pub feature_flags: FeatureFlags,
    #[serde(default, alias = "developer_config")]
    pub developer_config: DeveloperConfig,
}

fn default_version() -> String {
    "1.0.0".to_string()
}

impl Default for AppFullSettings {
    fn default() -> Self {
        Self {
            visualisation: VisualisationSettings::default(),
            system: SystemSettings::default(),
            xr: XRSettings::default(),
            auth: AuthSettings::default(),
            ragflow: None,
            perplexity: None,
            openai: None,
            kokoro: None,
            whisper: None,
            version: default_version(),
            user_preferences: UserPreferences::default(),
            physics: PhysicsSettings::default(),
            feature_flags: FeatureFlags::default(),
            developer_config: DeveloperConfig::default(),
        }
    }
}

impl AppFullSettings {
    
    
    pub fn new() -> Result<Self, ConfigError> {
        debug!("Initializing AppFullSettings with defaults (database-first architecture)");
        info!("IMPORTANT: Settings should be loaded from database via DatabaseService");
        info!("Legacy YAML file loading has been removed - all settings are now in Neo4j");


        Ok(Self::default())
    }



    pub fn save(&self) -> Result<(), String> {
        debug!("save() called but ignored - settings are now automatically persisted to database");
        info!("Legacy YAML file saving has been removed - all settings are now in Neo4j");
        Ok(())
    }

    
    
    
    
    
    pub fn get_physics(&self, graph: &str) -> &PhysicsSettings {
        match graph {
            "logseq" | "knowledge" => &self.visualisation.graphs.logseq.physics,
            "visionflow" | "agent" | "bots" => &self.visualisation.graphs.visionflow.physics,
            _ => {
                log::debug!(
                    "Unknown graph type '{}', defaulting to logseq (knowledge graph)",
                    graph
                );
                &self.visualisation.graphs.logseq.physics
            }
        }
    }

    
    

    
    pub fn merge_update(&mut self, update: serde_json::Value) -> Result<(), String> {
        
        if crate::utils::logging::is_debug_enabled() {
            debug!(
                "merge_update: Incoming update (camelCase): {}",
                crate::utils::json::to_json_pretty(&update)
                    .unwrap_or_else(|_| "Could not serialize".to_string())
            );
        }

        
        let processed_update = convert_empty_strings_to_null(update.clone());
        if crate::utils::logging::is_debug_enabled() {
            debug!(
                "merge_update: After null conversion: {}",
                crate::utils::json::to_json_pretty(&processed_update)
                    .unwrap_or_else(|_| "Could not serialize".to_string())
            );
        }

        
        
        let current_value = serde_json::to_value(&self)
            .map_err(|e| format!("Failed to serialize current settings: {}", e))?;

        
        let normalized_current = normalize_field_names_to_camel_case(current_value)?;
        let normalized_update = normalize_field_names_to_camel_case(processed_update)?;

        if crate::utils::logging::is_debug_enabled() {
            debug!(
                "merge_update: After field normalization (current): {}",
                crate::utils::json::to_json_pretty(&normalized_current)
                    .unwrap_or_else(|_| "Could not serialize".to_string())
            );
            debug!(
                "merge_update: After field normalization (update): {}",
                crate::utils::json::to_json_pretty(&normalized_update)
                    .unwrap_or_else(|_| "Could not serialize".to_string())
            );
        }

        let merged = merge_json_values(normalized_current, normalized_update);
        if crate::utils::logging::is_debug_enabled() {
            debug!(
                "merge_update: After merge: {}",
                crate::utils::json::to_json_pretty(&merged)
                    .unwrap_or_else(|_| "Could not serialize".to_string())
            );
        }

        
        *self = serde_json::from_value(merged.clone()).map_err(|e| {
            if crate::utils::logging::is_debug_enabled() {
                error!(
                    "merge_update: Failed to deserialize merged JSON: {}",
                    crate::utils::json::to_json_pretty(&merged)
                        .unwrap_or_else(|_| "Could not serialize".to_string())
                );
                error!(
                    "merge_update: Original update was: {}",
                    crate::utils::json::to_json_pretty(&update)
                        .unwrap_or_else(|_| "Could not serialize".to_string())
                );
            }
            format!("Failed to deserialize merged settings: {}", e)
        })?;

        Ok(())
    }

    
    pub fn validate_config_camel_case(&self) -> Result<(), validator::ValidationErrors> {
        
        self.validate()?;

        
        self.validate_cross_field_constraints()?;

        Ok(())
    }

    
    fn validate_cross_field_constraints(&self) -> Result<(), validator::ValidationErrors> {
        let mut errors = validator::ValidationErrors::new();

        
        if self.visualisation.graphs.logseq.physics.gravity != 0.0
            && !self.visualisation.graphs.logseq.physics.enabled
        {
            errors.add("physics", ValidationError::new("physics_enabled_required"));
        }

        
        if let Err(validation_error) =
            validate_bloom_glow_settings(&self.visualisation.glow, &self.visualisation.bloom)
        {
            errors.add("visualisation.bloom_glow", validation_error);
        }

        if errors.is_empty() {
            Ok(())
        } else {
            Err(errors)
        }
    }

    
    pub fn get_validation_errors_camel_case(
        errors: &validator::ValidationErrors,
    ) -> HashMap<String, Vec<String>> {
        let mut result = HashMap::new();

        for (field, field_errors) in errors.field_errors() {
            let camel_case_field = to_camel_case(field);
            let messages: Vec<String> = field_errors
                .iter()
                .map(|error| match error.code.as_ref() {
                    "invalid_hex_color" => {
                        "Must be a valid hex color (#RRGGBB or #RRGGBBAA)".to_string()
                    }
                    "width_range_length" => "Width range must have exactly 2 values".to_string(),
                    "width_range_order" => {
                        "Width range minimum must be less than maximum".to_string()
                    }
                    "invalid_port" => "Port must be between 1 and 65535".to_string(),
                    "invalid_percentage" => "Value must be between 0 and 100".to_string(),
                    "physics_enabled_required" => {
                        "Physics must be enabled when gravity is configured".to_string()
                    }
                    _ => format!("Invalid value for {}", camel_case_field),
                })
                .collect();

            result.insert(camel_case_field, messages);
        }

        result
    }
}

// PathAccessible implementation for AppFullSettings
impl PathAccessible for AppFullSettings {
    fn get_by_path(&self, path: &str) -> Result<Box<dyn std::any::Any>, String> {
        let segments = parse_path(path)?;

        match segments[0] {
            "visualisation" => {
                if segments.len() == 1 {
                    Ok(Box::new(self.visualisation.clone()))
                } else {
                    let remaining = segments[1..].join(".");
                    self.visualisation.get_by_path(&remaining)
                }
            }
            "system" => {
                if segments.len() == 1 {
                    Ok(Box::new(self.system.clone()))
                } else {
                    let remaining = segments[1..].join(".");
                    self.system.get_by_path(&remaining)
                }
            }
            "xr" => {
                if segments.len() == 1 {
                    Ok(Box::new(self.xr.clone()))
                } else {
                    let remaining = segments[1..].join(".");
                    self.xr.get_by_path(&remaining)
                }
            }
            "auth" => {
                if segments.len() == 1 {
                    Ok(Box::new(self.auth.clone()))
                } else {
                    Err("Auth fields are not deeply accessible".to_string())
                }
            }
            _ => Err(format!("Unknown top-level field: {}", segments[0])),
        }
    }

    fn set_by_path(&mut self, path: &str, value: Box<dyn std::any::Any>) -> Result<(), String> {
        let segments = parse_path(path)?;

        match segments[0] {
            "visualisation" => {
                if segments.len() == 1 {
                    match value.downcast::<VisualisationSettings>() {
                        Ok(v) => {
                            self.visualisation = *v;
                            Ok(())
                        }
                        Err(_) => Err("Type mismatch for visualisation field".to_string()),
                    }
                } else {
                    let remaining = segments[1..].join(".");
                    self.visualisation.set_by_path(&remaining, value)
                }
            }
            "system" => {
                if segments.len() == 1 {
                    match value.downcast::<SystemSettings>() {
                        Ok(v) => {
                            self.system = *v;
                            Ok(())
                        }
                        Err(_) => Err("Type mismatch for system field".to_string()),
                    }
                } else {
                    let remaining = segments[1..].join(".");
                    self.system.set_by_path(&remaining, value)
                }
            }
            "xr" => {
                if segments.len() == 1 {
                    match value.downcast::<XRSettings>() {
                        Ok(v) => {
                            self.xr = *v;
                            Ok(())
                        }
                        Err(_) => Err("Type mismatch for xr field".to_string()),
                    }
                } else {
                    let remaining = segments[1..].join(".");
                    self.xr.set_by_path(&remaining, value)
                }
            }
            "auth" => {
                if segments.len() == 1 {
                    match value.downcast::<AuthSettings>() {
                        Ok(v) => {
                            self.auth = *v;
                            Ok(())
                        }
                        Err(_) => Err("Type mismatch for auth field".to_string()),
                    }
                } else {
                    Err("Auth nested fields are not modifiable".to_string())
                }
            }
            _ => Err(format!("Unknown top-level field: {}", segments[0])),
        }
    }
}

// Basic PathAccessible implementations for nested structures
impl PathAccessible for VisualisationSettings {
    fn get_by_path(&self, path: &str) -> Result<Box<dyn std::any::Any>, String> {
        let segments = parse_path(path)?;

        match segments[0] {
            "graphs" => {
                if segments.len() == 1 {
                    Ok(Box::new(self.graphs.clone()))
                } else {
                    let remaining = segments[1..].join(".");
                    self.graphs.get_by_path(&remaining)
                }
            }
            _ => Err(format!(
                "Only graphs field is currently supported: {}",
                segments[0]
            )),
        }
    }

    fn set_by_path(&mut self, path: &str, value: Box<dyn std::any::Any>) -> Result<(), String> {
        let segments = parse_path(path)?;

        match segments[0] {
            "graphs" => {
                if segments.len() == 1 {
                    match value.downcast::<GraphsSettings>() {
                        Ok(v) => {
                            self.graphs = *v;
                            Ok(())
                        }
                        Err(_) => Err("Type mismatch for graphs field".to_string()),
                    }
                } else {
                    let remaining = segments[1..].join(".");
                    self.graphs.set_by_path(&remaining, value)
                }
            }
            _ => Err("Only graphs field is currently supported for modification".to_string()),
        }
    }
}

impl PathAccessible for GraphsSettings {
    fn get_by_path(&self, path: &str) -> Result<Box<dyn std::any::Any>, String> {
        let segments = parse_path(path)?;

        match segments[0] {
            "logseq" => {
                if segments.len() == 1 {
                    Ok(Box::new(self.logseq.clone()))
                } else {
                    let remaining = segments[1..].join(".");
                    self.logseq.get_by_path(&remaining)
                }
            }
            "visionflow" => {
                if segments.len() == 1 {
                    Ok(Box::new(self.visionflow.clone()))
                } else {
                    let remaining = segments[1..].join(".");
                    self.visionflow.get_by_path(&remaining)
                }
            }
            _ => Err(format!("Unknown graph type: {}", segments[0])),
        }
    }

    fn set_by_path(&mut self, path: &str, value: Box<dyn std::any::Any>) -> Result<(), String> {
        let segments = parse_path(path)?;

        match segments[0] {
            "logseq" => {
                if segments.len() == 1 {
                    match value.downcast::<GraphSettings>() {
                        Ok(v) => {
                            self.logseq = *v;
                            Ok(())
                        }
                        Err(_) => Err("Type mismatch for logseq field".to_string()),
                    }
                } else {
                    let remaining = segments[1..].join(".");
                    self.logseq.set_by_path(&remaining, value)
                }
            }
            "visionflow" => {
                if segments.len() == 1 {
                    match value.downcast::<GraphSettings>() {
                        Ok(v) => {
                            self.visionflow = *v;
                            Ok(())
                        }
                        Err(_) => Err("Type mismatch for visionflow field".to_string()),
                    }
                } else {
                    let remaining = segments[1..].join(".");
                    self.visionflow.set_by_path(&remaining, value)
                }
            }
            _ => Err(format!("Unknown graph type: {}", segments[0])),
        }
    }
}

impl PathAccessible for GraphSettings {
    fn get_by_path(&self, path: &str) -> Result<Box<dyn std::any::Any>, String> {
        let segments = parse_path(path)?;

        match segments[0] {
            "physics" => {
                if segments.len() == 1 {
                    Ok(Box::new(self.physics.clone()))
                } else {
                    let remaining = segments[1..].join(".");
                    self.physics.get_by_path(&remaining)
                }
            }
            _ => Err(format!(
                "Only physics is supported currently: {}",
                segments[0]
            )),
        }
    }

    fn set_by_path(&mut self, path: &str, value: Box<dyn std::any::Any>) -> Result<(), String> {
        let segments = parse_path(path)?;

        match segments[0] {
            "physics" => {
                if segments.len() == 1 {
                    match value.downcast::<PhysicsSettings>() {
                        Ok(v) => {
                            self.physics = *v;
                            Ok(())
                        }
                        Err(_) => Err("Type mismatch for physics field".to_string()),
                    }
                } else {
                    let remaining = segments[1..].join(".");
                    self.physics.set_by_path(&remaining, value)
                }
            }
            _ => Err("Only physics field is currently supported for modification".to_string()),
        }
    }
}

// Critical: PhysicsSettings PathAccessible implementation for performance fix
impl PathAccessible for PhysicsSettings {
    fn get_by_path(&self, path: &str) -> Result<Box<dyn std::any::Any>, String> {
        let segments = parse_path(path)?;

        match segments[0] {
            "damping" => Ok(Box::new(self.damping)),
            "springK" => Ok(Box::new(self.spring_k)),
            "repelK" => Ok(Box::new(self.repel_k)),
            "enabled" => Ok(Box::new(self.enabled)),
            "iterations" => Ok(Box::new(self.iterations)),
            "maxVelocity" => Ok(Box::new(self.max_velocity)),
            "boundsSize" => Ok(Box::new(self.bounds_size)),
            "gravity" => Ok(Box::new(self.gravity)),
            "temperature" => Ok(Box::new(self.temperature)),
            _ => Err(format!("Unknown physics field: {}", segments[0])),
        }
    }

    fn set_by_path(&mut self, path: &str, value: Box<dyn std::any::Any>) -> Result<(), String> {
        let segments = parse_path(path)?;

        match segments[0] {
            "damping" => match value.downcast::<f32>() {
                Ok(v) => {
                    self.damping = *v;
                    Ok(())
                }
                Err(_) => Err("Type mismatch for damping field".to_string()),
            },
            "springK" => match value.downcast::<f32>() {
                Ok(v) => {
                    self.spring_k = *v;
                    Ok(())
                }
                Err(_) => Err("Type mismatch for springK field".to_string()),
            },
            "repelK" => match value.downcast::<f32>() {
                Ok(v) => {
                    self.repel_k = *v;
                    Ok(())
                }
                Err(_) => Err("Type mismatch for repelK field".to_string()),
            },
            "enabled" => match value.downcast::<bool>() {
                Ok(v) => {
                    self.enabled = *v;
                    Ok(())
                }
                Err(_) => Err("Type mismatch for enabled field".to_string()),
            },
            "iterations" => match value.downcast::<u32>() {
                Ok(v) => {
                    self.iterations = *v;
                    Ok(())
                }
                Err(_) => Err("Type mismatch for iterations field".to_string()),
            },
            "maxVelocity" => match value.downcast::<f32>() {
                Ok(v) => {
                    self.max_velocity = *v;
                    Ok(())
                }
                Err(_) => Err("Type mismatch for maxVelocity field".to_string()),
            },
            "boundsSize" => match value.downcast::<f32>() {
                Ok(v) => {
                    self.bounds_size = *v;
                    Ok(())
                }
                Err(_) => Err("Type mismatch for boundsSize field".to_string()),
            },
            "gravity" => match value.downcast::<f32>() {
                Ok(v) => {
                    self.gravity = *v;
                    Ok(())
                }
                Err(_) => Err("Type mismatch for gravity field".to_string()),
            },
            "temperature" => match value.downcast::<f32>() {
                Ok(v) => {
                    self.temperature = *v;
                    Ok(())
                }
                Err(_) => Err("Type mismatch for temperature field".to_string()),
            },
            _ => Err(format!("Unknown physics field: {}", segments[0])),
        }
    }
}

// Implementation for SystemSettings path access
impl PathAccessible for SystemSettings {
    fn get_by_path(&self, path: &str) -> Result<Box<dyn std::any::Any>, String> {
        match path {
            "network" => Ok(Box::new(self.network.clone())),
            "websocket" => Ok(Box::new(self.websocket.clone())),
            "security" => Ok(Box::new(self.security.clone())),
            "debug" => Ok(Box::new(self.debug.clone())),
            "persist_settings" => Ok(Box::new(self.persist_settings)),
            "custom_backend_url" => Ok(Box::new(self.custom_backend_url.clone())),
            _ => Err(format!("Unknown SystemSettings field: {}", path)),
        }
    }

    fn set_by_path(&mut self, path: &str, value: Box<dyn std::any::Any>) -> Result<(), String> {
        match path {
            "persist_settings" => {
                if let Some(val) = value.downcast_ref::<bool>() {
                    self.persist_settings = *val;
                    Ok(())
                } else {
                    Err("Invalid type for persist_settings, expected bool".to_string())
                }
            }
            "custom_backend_url" => {
                if let Some(val) = value.downcast_ref::<Option<String>>() {
                    self.custom_backend_url = val.clone();
                    Ok(())
                } else {
                    Err("Invalid type for custom_backend_url, expected Option<String>".to_string())
                }
            }
            _ => Err(format!("Setting {} not supported for SystemSettings", path)),
        }
    }
}

impl PathAccessible for XRSettings {
    fn get_by_path(&self, path: &str) -> Result<Box<dyn std::any::Any>, String> {
        match path {
            "enabled" => Ok(Box::new(self.enabled.clone())),
            "client_side_enable_xr" => Ok(Box::new(self.client_side_enable_xr.clone())),
            "mode" => Ok(Box::new(self.mode.clone())),
            "room_scale" => Ok(Box::new(self.room_scale)),
            "space_type" => Ok(Box::new(self.space_type.clone())),
            "quality" => Ok(Box::new(self.quality.clone())),
            "render_scale" => Ok(Box::new(self.render_scale.clone())),
            "interaction_distance" => Ok(Box::new(self.interaction_distance)),
            "locomotion_method" => Ok(Box::new(self.locomotion_method.clone())),
            "teleport_ray_color" => Ok(Box::new(self.teleport_ray_color.clone())),
            "controller_ray_color" => Ok(Box::new(self.controller_ray_color.clone())),
            _ => Err(format!("Unknown XRSettings field: {}", path)),
        }
    }

    fn set_by_path(&mut self, path: &str, value: Box<dyn std::any::Any>) -> Result<(), String> {
        match path {
            "enabled" => {
                if let Some(val) = value.downcast_ref::<Option<bool>>() {
                    self.enabled = val.clone();
                    Ok(())
                } else {
                    Err("Invalid type for enabled, expected Option<bool>".to_string())
                }
            }
            "room_scale" => {
                if let Some(val) = value.downcast_ref::<f32>() {
                    self.room_scale = *val;
                    Ok(())
                } else {
                    Err("Invalid type for room_scale, expected f32".to_string())
                }
            }
            "space_type" => {
                if let Some(val) = value.downcast_ref::<String>() {
                    self.space_type = val.clone();
                    Ok(())
                } else {
                    Err("Invalid type for space_type, expected String".to_string())
                }
            }
            "quality" => {
                if let Some(val) = value.downcast_ref::<String>() {
                    self.quality = val.clone();
                    Ok(())
                } else {
                    Err("Invalid type for quality, expected String".to_string())
                }
            }
            "interaction_distance" => {
                if let Some(val) = value.downcast_ref::<f32>() {
                    self.interaction_distance = *val;
                    Ok(())
                } else {
                    Err("Invalid type for interaction_distance, expected f32".to_string())
                }
            }
            "locomotion_method" => {
                if let Some(val) = value.downcast_ref::<String>() {
                    self.locomotion_method = val.clone();
                    Ok(())
                } else {
                    Err("Invalid type for locomotion_method, expected String".to_string())
                }
            }
            _ => Err(format!("Setting {} not supported for XRSettings", path)),
        }
    }
}

--------------------------------------------------------------------------------
FILE: src/app_state.rs
PURPOSE: Global application state
--------------------------------------------------------------------------------
use actix::prelude::*;
use actix_web::web;
use log::{info, warn};
use std::sync::{
    atomic::{AtomicUsize, Ordering},
    Arc,
};
use tokio::sync::RwLock;

// Neo4j feature imports - now the primary graph repository
use crate::adapters::neo4j_adapter::{Neo4jAdapter, Neo4jConfig};

// CQRS Phase 1D: Graph domain imports
use crate::adapters::actor_graph_repository::ActorGraphRepository;
use crate::application::graph::*;

// CQRS Phase 4: Command/Query/Event buses and Application Services
use crate::cqrs::{CommandBus, QueryBus};
use crate::events::EventBus;

use crate::actors::gpu;
use crate::actors::gpu::GPUContextBus;
use crate::actors::graph_service_supervisor::GraphServiceSupervisor;
use crate::actors::ontology_actor::OntologyActor;
use crate::actors::GPUManagerActor;
use crate::actors::{
    AgentMonitorActor, ClientCoordinatorActor, MetadataActor, OptimizedSettingsActor,
    ProtectedSettingsActor, TaskOrchestratorActor, WorkspaceActor,
};
use crate::config::feature_access::FeatureAccess;
use crate::config::AppFullSettings; 
use crate::models::metadata::MetadataStore;
use crate::models::protected_settings::{ApiKeys, NostrUser, ProtectedSettings};
use crate::services::bots_client::BotsClient;
use crate::services::github::content_enhanced::EnhancedContentAPI;
use crate::services::github::{ContentAPI, GitHubClient};
use crate::services::github_sync_service::GitHubSyncService;
use crate::services::management_api_client::ManagementApiClient;
use crate::services::nostr_service::NostrService;
use crate::services::perplexity_service::PerplexityService;
use crate::services::ragflow_service::RAGFlowService;
use crate::services::speech_service::SpeechService;
use crate::utils::client_message_extractor::ClientMessage;
use tokio::sync::mpsc;
use tokio::time::Duration;

// Repository trait imports for hexagonal architecture
use crate::adapters::neo4j_settings_repository::Neo4jSettingsRepository;
use crate::adapters::neo4j_ontology_repository::{Neo4jOntologyRepository, Neo4jOntologyConfig};
use crate::ports::settings_repository::SettingsRepository;

// CQRS Phase 1D: Graph query handlers struct
#[derive(Clone)]
pub struct GraphQueryHandlers {
    pub get_graph_data: Arc<GetGraphDataHandler>,
    pub get_node_map: Arc<GetNodeMapHandler>,
    pub get_physics_state: Arc<GetPhysicsStateHandler>,
    pub get_auto_balance_notifications: Arc<GetAutoBalanceNotificationsHandler>,
    pub get_bots_graph_data: Arc<GetBotsGraphDataHandler>,
    pub get_constraints: Arc<GetConstraintsHandler>,
    pub get_equilibrium_status: Arc<GetEquilibriumStatusHandler>,
    pub compute_shortest_paths: Arc<ComputeShortestPathsHandler>,
}

// Phase 7: GPU Subsystem Decomposition
// Independent subsystems that receive GPU context via event bus

/// Physics simulation subsystem actors
#[derive(Clone)]
pub struct PhysicsSubsystem {
    pub force_compute: Option<Addr<gpu::ForceComputeActor>>,
    pub stress_major: Option<Addr<gpu::StressMajorizationActor>>,
    pub constraint: Option<Addr<gpu::ConstraintActor>>,
}

/// Analytics and ML subsystem actors
#[derive(Clone)]
pub struct AnalyticsSubsystem {
    pub clustering: Option<Addr<gpu::ClusteringActor>>,
    pub anomaly: Option<Addr<gpu::AnomalyDetectionActor>>,
    pub pagerank: Option<Addr<gpu::PageRankActor>>,
}

/// Graph algorithm subsystem actors
#[derive(Clone)]
pub struct GraphSubsystem {
    pub shortest_path: Option<Addr<gpu::ShortestPathActor>>,
    pub components: Option<Addr<gpu::ConnectedComponentsActor>>,
}

impl Default for PhysicsSubsystem {
    fn default() -> Self {
        Self {
            force_compute: None,
            stress_major: None,
            constraint: None,
        }
    }
}

impl Default for AnalyticsSubsystem {
    fn default() -> Self {
        Self {
            clustering: None,
            anomaly: None,
            pagerank: None,
        }
    }
}

impl Default for GraphSubsystem {
    fn default() -> Self {
        Self {
            shortest_path: None,
            components: None,
        }
    }
}

impl PhysicsSubsystem {
    /// Check if any physics actors are initialized
    pub fn is_initialized(&self) -> bool {
        self.force_compute.is_some() || self.stress_major.is_some() || self.constraint.is_some()
    }

    /// Get count of active actors
    pub fn active_count(&self) -> usize {
        [
            self.force_compute.is_some(),
            self.stress_major.is_some(),
            self.constraint.is_some(),
        ]
        .iter()
        .filter(|&&x| x)
        .count()
    }
}

impl AnalyticsSubsystem {
    /// Check if any analytics actors are initialized
    pub fn is_initialized(&self) -> bool {
        self.clustering.is_some() || self.anomaly.is_some() || self.pagerank.is_some()
    }

    /// Get count of active actors
    pub fn active_count(&self) -> usize {
        [
            self.clustering.is_some(),
            self.anomaly.is_some(),
            self.pagerank.is_some(),
        ]
        .iter()
        .filter(|&&x| x)
        .count()
    }
}

impl GraphSubsystem {
    /// Check if any graph algorithm actors are initialized
    pub fn is_initialized(&self) -> bool {
        self.shortest_path.is_some() || self.components.is_some()
    }

    /// Get count of active actors
    pub fn active_count(&self) -> usize {
        [self.shortest_path.is_some(), self.components.is_some()]
            .iter()
            .filter(|&&x| x)
            .count()
    }
}

#[derive(Clone)]
pub struct AppState {
    pub graph_service_addr: Addr<GraphServiceSupervisor>,
    pub gpu_manager_addr: Option<Addr<GPUManagerActor>>,
    pub gpu_compute_addr: Option<Addr<gpu::ForceComputeActor>>,
    pub stress_majorization_addr: Option<Addr<gpu::StressMajorizationActor>>,
    pub shortest_path_actor: Option<Addr<gpu::ShortestPathActor>>,
    pub connected_components_actor: Option<Addr<gpu::ConnectedComponentsActor>>,

    // Phase 7: Decomposed GPU subsystems (direct access, bypassing GPUManagerActor)
    pub physics: PhysicsSubsystem,
    pub analytics: AnalyticsSubsystem,
    pub graph_ops: GraphSubsystem,

    // Event bus for GPU context distribution to independent subsystems
    pub gpu_context_bus: Arc<GPUContextBus>,

    pub settings_repository: Arc<dyn SettingsRepository>,

    // Concrete Neo4j settings repository for user-specific operations (filters, etc.)
    pub neo4j_settings_repository: Arc<Neo4jSettingsRepository>,

    // Neo4j is now the primary knowledge graph repository
    pub neo4j_adapter: Arc<Neo4jAdapter>,

    // Neo4j ontology repository (replaces UnifiedOntologyRepository)
    pub ontology_repository: Arc<Neo4jOntologyRepository>,

    pub graph_repository: Arc<ActorGraphRepository>,
    pub graph_query_handlers: GraphQueryHandlers,
    
    pub command_bus: Arc<RwLock<CommandBus>>,
    pub query_bus: Arc<RwLock<QueryBus>>,
    pub event_bus: Arc<RwLock<EventBus>>,
    
    
    pub settings_addr: Addr<OptimizedSettingsActor>,
    pub protected_settings_addr: Addr<ProtectedSettingsActor>,
    pub metadata_addr: Addr<MetadataActor>,
    pub client_manager_addr: Addr<ClientCoordinatorActor>,
    pub agent_monitor_addr: Addr<AgentMonitorActor>,
    pub workspace_addr: Addr<WorkspaceActor>,
    pub ontology_actor_addr: Option<Addr<OntologyActor>>,
    pub github_client: Arc<GitHubClient>,
    pub content_api: Arc<ContentAPI>,
    pub perplexity_service: Option<Arc<PerplexityService>>,
    pub ragflow_service: Option<Arc<RAGFlowService>>,
    pub speech_service: Option<Arc<SpeechService>>,
    pub nostr_service: Option<web::Data<NostrService>>,
    pub feature_access: web::Data<FeatureAccess>,
    pub ragflow_session_id: String,
    pub active_connections: Arc<AtomicUsize>,
    pub bots_client: Arc<BotsClient>,
    pub task_orchestrator_addr: Addr<TaskOrchestratorActor>,
    pub debug_enabled: bool,
    pub client_message_tx: mpsc::UnboundedSender<ClientMessage>,
    pub client_message_rx: Arc<tokio::sync::Mutex<mpsc::UnboundedReceiver<ClientMessage>>>,
    pub ontology_pipeline_service: Option<Arc<crate::services::ontology_pipeline_service::OntologyPipelineService>>,
}

impl AppState {
    pub async fn new(
        settings: AppFullSettings,
        github_client: Arc<GitHubClient>,
        content_api: Arc<ContentAPI>,
        perplexity_service: Option<Arc<PerplexityService>>,
        ragflow_service: Option<Arc<RAGFlowService>>,
        speech_service: Option<Arc<SpeechService>>,
        ragflow_session_id: String,
    ) -> Result<Self, Box<dyn std::error::Error + Send + Sync>> {
        info!("[AppState::new] Initializing actor system");
        tokio::time::sleep(Duration::from_millis(50)).await;


        info!("[AppState::new] Creating repository adapters for hexagonal architecture");

        // Phase 3: Using Neo4j settings repository
        use crate::adapters::neo4j_settings_repository::Neo4jSettingsConfig;
        let settings_config = Neo4jSettingsConfig::default();
        let neo4j_settings_repository = Arc::new(
            Neo4jSettingsRepository::new(settings_config)
                .await
                .map_err(|e| format!("Failed to create Neo4j settings repository: {}", e))?,
        );
        // Keep both trait object and concrete type for different use cases
        let settings_repository: Arc<dyn SettingsRepository> = neo4j_settings_repository.clone();

        info!("[AppState::new] Creating Neo4j ontology repository...");
        let ontology_config = Neo4jOntologyConfig::default();
        let ontology_repository: Arc<Neo4jOntologyRepository> = Arc::new(
            Neo4jOntologyRepository::new(ontology_config)
                .await
                .map_err(|e| format!("Failed to create Neo4j ontology repository: {}", e))?,
        );

        info!("[AppState::new] Neo4j ontology repository initialized successfully");
        info!("[AppState::new] Database and settings service initialized successfully");
        info!(
            "[AppState::new] IMPORTANT: UI now connects directly to database via SettingsService"
        );

        // Neo4j is now the primary graph repository
        let neo4j_adapter = {
            info!("[AppState::new] Initializing Neo4j as primary knowledge graph repository");
            let config = Neo4jConfig::default();
            let adapter = Neo4jAdapter::new(config).await
                .map_err(|e| format!("Failed to initialize Neo4j adapter: {}", e))?;
            info!(" Neo4j adapter initialized successfully");
            Arc::new(adapter)
        };

        // Create ontology pipeline service with semantic physics
        info!("[AppState::new] Creating ontology pipeline service");
        let mut pipeline_service = crate::services::ontology_pipeline_service::OntologyPipelineService::new(
            crate::services::ontology_pipeline_service::SemanticPhysicsConfig::default()
        );

        // CRITICAL: Set graph repository for IRI  node ID resolution
        pipeline_service.set_graph_repository(neo4j_adapter.clone());

        let ontology_pipeline_service = Some(Arc::new(pipeline_service));



        info!("[AppState::new] Initializing GitHubSyncService for data ingestion");

        let enhanced_content_api = Arc::new(EnhancedContentAPI::new(github_client.clone()));
        let mut github_sync_service = GitHubSyncService::new(
            enhanced_content_api,
            neo4j_adapter.clone(),
            ontology_repository.clone(),
        );

        // Connect pipeline service to GitHub sync
        if let Some(ref pipeline) = ontology_pipeline_service {
            github_sync_service.set_pipeline_service(pipeline.clone());
            info!("[AppState::new] Ontology pipeline connected to GitHub sync");
        }

        let github_sync_service = Arc::new(github_sync_service);

        info!("[AppState::new] Starting GitHub data sync in background (non-blocking)...");

        let sync_service_clone = github_sync_service.clone();

        // Will be initialized before spawn
        let graph_service_addr_ref: std::sync::Arc<tokio::sync::Mutex<Option<Addr<GraphServiceSupervisor>>>> =
            std::sync::Arc::new(tokio::sync::Mutex::new(None));
        let graph_service_addr_clone_for_sync = graph_service_addr_ref.clone();

        let sync_handle = tokio::spawn(async move {
            info!(" Background GitHub sync task spawned successfully");
            info!(" Task ID: {:?}", std::thread::current().id());
            info!(" Starting sync_graphs() execution...");



            info!(" Calling sync_service.sync_graphs()...");
            let sync_start = std::time::Instant::now();

            match sync_service_clone.sync_graphs().await {
                Ok(stats) => {
                    let elapsed = sync_start.elapsed();
                    info!(" GitHub sync complete! (elapsed: {:?})", elapsed);
                    info!("   Total files scanned: {}", stats.total_files);
                    info!("   Knowledge graph files: {}", stats.kg_files_processed);
                    info!("    Ontology files: {}", stats.ontology_files_processed);
                    info!("    Duration: {:?}", stats.duration);
                    if !stats.errors.is_empty() {
                        warn!("    Errors encountered: {}", stats.errors.len());
                        for (i, error) in stats.errors.iter().enumerate().take(5) {
                            warn!("    {}. {}", i + 1, error);
                        }
                        if stats.errors.len() > 5 {
                            warn!("    ... and {} more errors", stats.errors.len() - 5);
                        }
                    }

                    // Load synced data into graph actor (if it's ready)
                    if let Some(graph_addr) = &*graph_service_addr_clone_for_sync.lock().await {
                        info!(" [GitHub Sync] Notifying GraphServiceActor to reload synced data...");
                        graph_addr.do_send(crate::actors::messages::ReloadGraphFromDatabase);
                        info!(" [GitHub Sync] Reload notification sent to GraphServiceActor");
                    } else {
                        info!("  [GitHub Sync] Graph service not yet initialized - will load on startup");
                    }
                }
                Err(e) => {
                    let elapsed = sync_start.elapsed();
                    log::error!(" Background GitHub sync failed after {:?}: {}", elapsed, e);
                    log::error!(" Error details: {:?}", e);
                    log::error!("  Databases may have partial data - use manual import API if needed");
                }
            }
        });

        
        tokio::spawn(async move {
            tokio::time::sleep(Duration::from_millis(100)).await;
            info!(" GitHub sync monitor: Checking task status...");

            
            let timeout_duration = Duration::from_secs(300); 
            match tokio::time::timeout(timeout_duration, sync_handle).await {
                Ok(join_result) => {
                    match join_result {
                        Ok(_sync_result) => {
                            info!(" GitHub sync monitor: Task completed successfully");
                        }
                        Err(join_error) => {
                            if join_error.is_cancelled() {
                                log::error!(" GitHub sync monitor: Task was CANCELLED");
                            } else if join_error.is_panic() {
                                log::error!(" GitHub sync monitor: Task PANICKED");
                                log::error!(" JoinError details: {:?}", join_error);
                            } else {
                                log::error!(" GitHub sync monitor: Task failed with unknown error");
                                log::error!(" JoinError: {:?}", join_error);
                            }
                        }
                    }
                }
                Err(_timeout_error) => {
                    log::error!(" GitHub sync monitor: Task TIMED OUT after {:?}", timeout_duration);
                    log::error!(" This likely indicates a deadlock or infinite loop in sync_graphs()");
                }
            }

            info!(" GitHub sync monitor: Monitoring complete");
        });

        info!("[AppState::new] GitHub sync running in background with enhanced monitoring, proceeding with actor initialization");


        info!("[AppState::new] Starting ClientCoordinatorActor");
        let mut client_coordinator = ClientCoordinatorActor::new();
        client_coordinator.set_neo4j_repository(neo4j_settings_repository.clone());
        let client_manager_addr = client_coordinator.start();


        let physics_settings = settings.visualisation.graphs.logseq.physics.clone();

        info!("[AppState::new] Starting MetadataActor");
        let metadata_addr = MetadataActor::new(MetadataStore::new()).start();


        info!("[AppState::new] Starting GraphServiceSupervisor (refactored architecture)");








        let graph_service_addr = GraphServiceSupervisor::new(neo4j_adapter.clone()).start();

        // Neo4j feature is now required - removed legacy SQLite path

        // Store graph service address in Arc for GitHub sync task to use
        let graph_service_addr_clone = graph_service_addr.clone();
        tokio::spawn(async move {
            let mut addr_guard = graph_service_addr_ref.lock().await;
            *addr_guard = Some(graph_service_addr_clone);
            info!("[AppState::new] GitHub sync task notified - graph service address available");
        });


        info!("[AppState::new] Retrieving GraphStateActor from GraphServiceSupervisor for CQRS");
        let graph_actor_addr = graph_service_addr
            .send(crate::actors::messages::GetGraphStateActor)
            .await
            .map_err(|e| format!("Failed to send GetGraphStateActor message: {}", e))?
            .ok_or_else(|| "GraphStateActor not initialized in supervisor".to_string())?;

        info!("[AppState::new] Creating Neo4j graph repository adapter (CQRS Phase 2: Direct Query)");
        // Professional, scalable approach: Query Neo4j directly with intelligent caching
        let neo4j_graph_repository = Arc::new(crate::adapters::Neo4jGraphRepository::new(neo4j_adapter.graph().clone()));

        // Create ActorGraphRepository using the graph actor
        let graph_repository = Arc::new(crate::adapters::ActorGraphRepository::new(graph_actor_addr.clone()));

        // Load existing data from Neo4j into repository cache on startup
        info!("[AppState::new] Loading graph data from Neo4j into repository cache...");
        neo4j_graph_repository.load_graph().await
            .map_err(|e| format!("Failed to load graph from Neo4j: {:?}", e))?;

        // Get node count by calling the trait method through the GraphRepository trait
        let node_count = {
            use crate::ports::graph_repository::GraphRepository;
            graph_repository.get_graph().await
                .map(|g| g.nodes.len())
                .unwrap_or(0)
        };
        info!("[AppState::new]  Graph data loaded from Neo4j ({} nodes)", node_count);

        info!("[AppState::new] Initializing CQRS query handlers for graph domain");
        let graph_query_handlers = GraphQueryHandlers {
            get_graph_data: Arc::new(GetGraphDataHandler::new(graph_repository.clone())),
            get_node_map: Arc::new(GetNodeMapHandler::new(graph_repository.clone())),
            get_physics_state: Arc::new(GetPhysicsStateHandler::new(graph_repository.clone())),
            get_auto_balance_notifications: Arc::new(GetAutoBalanceNotificationsHandler::new(
                graph_repository.clone(),
            )),
            get_bots_graph_data: Arc::new(GetBotsGraphDataHandler::new(graph_repository.clone())),
            get_constraints: Arc::new(GetConstraintsHandler::new(graph_repository.clone())),
            get_equilibrium_status: Arc::new(GetEquilibriumStatusHandler::new(
                graph_repository.clone(),
            )),
            compute_shortest_paths: Arc::new(ComputeShortestPathsHandler::new(
                graph_repository.clone(),
            )),
        };

        
        info!("[AppState::new] Initializing CQRS buses (Phase 4)");
        let command_bus = Arc::new(RwLock::new(CommandBus::new()));
        let query_bus = Arc::new(RwLock::new(QueryBus::new()));
        let event_bus = Arc::new(RwLock::new(EventBus::new()));

        
        info!("[AppState::new] Linking ClientCoordinatorActor to GraphServiceSupervisor for settling fix");
        
        let graph_supervisor_clone = graph_service_addr.clone();
        let client_manager_clone = client_manager_addr.clone();
        actix::spawn(async move {
            
            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;

            // Set the GraphServiceSupervisor address in ClientManagerActor
            info!("Setting GraphServiceSupervisor address in ClientManagerActor");
            client_manager_clone
                .do_send(crate::actors::messages::SetGraphServiceAddress { addr: graph_supervisor_clone.clone() });
        });


        let (gpu_manager_addr, stress_majorization_addr, shortest_path_actor, connected_components_actor) = {
            info!("[AppState::new] Starting GPUManagerActor (modular architecture)");
            let gpu_manager = GPUManagerActor::new().start();

            // P2 Feature: Initialize ShortestPathActor and ConnectedComponentsActor
            info!("[AppState::new] Starting ShortestPathActor and ConnectedComponentsActor for P2 features");
            let shortest_path = gpu::ShortestPathActor::new().start();
            let connected_components = gpu::ConnectedComponentsActor::new().start();

            // Extract StressMajorizationActor from GPUManagerActor's child actors
            // Note: The actor is spawned by GPUManagerActor, so we'll retrieve it after initialization
            info!("[AppState::new] StressMajorizationActor will be available after GPU initialization");

            (Some(gpu_manager), None, Some(shortest_path), Some(connected_components))
        };


        {
            use crate::actors::messages::InitializeGPUConnection;
            
            info!("[AppState] Initializing GPU connection with GPUManagerActor for proper message delegation");
            if let Some(ref gpu_manager) = gpu_manager_addr {
                graph_service_addr.do_send(InitializeGPUConnection {
                    gpu_manager: Some(gpu_manager.clone()),
                });
            } else {
                warn!("[AppState] GPUManagerActor not available - GPU physics will be disabled");
            }
        }

        info!("[AppState::new] Starting OptimizedSettingsActor with repository injection (hexagonal architecture)");

        // Phase 3: Using Neo4j settings repository for actor (reusing config from above)
        let actor_config = Neo4jSettingsConfig::default();
        let actor_settings_repository = Arc::new(
            Neo4jSettingsRepository::new(actor_config)
                .await
                .map_err(|e| format!("Failed to create Neo4j actor settings repository: {}", e))?,
        );

        let settings_actor = OptimizedSettingsActor::with_actors(
            actor_settings_repository,
            Some(graph_service_addr.clone()),
            None,
        )
        .map_err(|e| {
            log::error!("Failed to create OptimizedSettingsActor: {}", e);
            e
        })?;
        let settings_addr = settings_actor.start();

        
        info!("[AppState::new] Starting settings hot-reload watcher");
        
        
        
        
        
        
        
        
        
        
        info!(
            "[AppState::new] Settings hot-reload watcher DISABLED (was causing database deadlocks)"
        );

        info!("[AppState::new] Starting AgentMonitorActor for MCP monitoring");
        let mcp_host =
            std::env::var("MCP_HOST").unwrap_or_else(|_| "agentic-workstation".to_string());
        let mcp_port = std::env::var("MCP_TCP_PORT")
            .unwrap_or_else(|_| "9500".to_string())
            .parse::<u16>()
            .unwrap_or(9500);

        info!(
            "[AppState::new] AgentMonitorActor will poll MCP at {}:{}",
            mcp_host, mcp_port
        );
        let claude_flow_client =
            crate::types::claude_flow::ClaudeFlowClient::new(mcp_host, mcp_port);
        let agent_monitor_addr =
            AgentMonitorActor::new(claude_flow_client, graph_service_addr.clone()).start();

        
        
        
        let sim_params =
            crate::models::simulation_params::SimulationParams::from(&physics_settings);

        let update_msg = crate::actors::messages::UpdateSimulationParams { params: sim_params };


        graph_service_addr.do_send(update_msg.clone());


        if let Some(ref _gpu_addr) = gpu_manager_addr {


        }

        info!("[AppState::new] Starting ProtectedSettingsActor");
        let protected_settings_addr =
            ProtectedSettingsActor::new(ProtectedSettings::default()).start();

        info!("[AppState::new] Starting WorkspaceActor");
        let workspace_addr = WorkspaceActor::new().start();

        info!("[AppState::new] Starting OntologyActor");
        let ontology_actor_addr = {
            info!("[AppState] OntologyActor initialized successfully");
            Some(OntologyActor::new().start())
        };

        info!("[AppState::new] Initializing BotsClient with graph service");
        let bots_client = Arc::new(BotsClient::with_graph_service(graph_service_addr.clone()));

        info!("[AppState::new] Initializing TaskOrchestratorActor with Management API");
        let mgmt_api_host = std::env::var("MANAGEMENT_API_HOST")
            .unwrap_or_else(|_| "agentic-workstation".to_string());
        let mgmt_api_port = std::env::var("MANAGEMENT_API_PORT")
            .unwrap_or_else(|_| "9090".to_string())
            .parse::<u16>()
            .unwrap_or(9090);
        let mgmt_api_key = std::env::var("MANAGEMENT_API_KEY").unwrap_or_else(|_| {
            // Generate a secure random key if not set, but warn loudly
            if std::env::var("ALLOW_INSECURE_DEFAULTS").is_ok() {
                warn!("[AppState] MANAGEMENT_API_KEY not set, using insecure default (dev mode)");
                "change-this-secret-key".to_string()
            } else {
                // Generate a secure random API key for this session
                let random_key = format!("auto-{}", uuid::Uuid::new_v4());
                warn!("[AppState] MANAGEMENT_API_KEY not set - generated session key: {}...", &random_key[..16]);
                warn!("[AppState] Set MANAGEMENT_API_KEY in production for consistent key across restarts");
                random_key
            }
        });

        let mgmt_client = ManagementApiClient::new(mgmt_api_host, mgmt_api_port, mgmt_api_key);
        let task_orchestrator_addr = TaskOrchestratorActor::new(mgmt_client).start();

        
        
        info!("[AppState] GPU manager will self-initialize when needed");


        info!("[AppState::new] Actor system initialization complete (GPU initialization sent earlier)");

        
        let debug_enabled = crate::utils::logging::is_debug_enabled();

        info!("[AppState::new] Debug mode enabled: {}", debug_enabled);

        
        let (client_message_tx, client_message_rx) = mpsc::unbounded_channel::<ClientMessage>();
        info!("[AppState::new] Client message channel created");

        // Phase 7: Initialize GPU context bus for event-based distribution
        info!("[AppState::new] Creating GPU context bus for subsystem distribution");
        let gpu_context_bus = Arc::new(GPUContextBus::new());

        // Phase 7: Initialize decomposed GPU subsystems
        // These will receive GPU context via the event bus when GPUManagerActor initializes
        let physics = PhysicsSubsystem {
            force_compute: None,
            stress_major: None,
            constraint: None,
        };

        let analytics = AnalyticsSubsystem {
            clustering: None,
            anomaly: None,
            pagerank: None,
        };

        // Graph ops subsystem initialized with the actors we already created
        let graph_ops = GraphSubsystem {
            shortest_path: shortest_path_actor.clone(),
            components: connected_components_actor.clone(),
        };

        info!("[AppState::new] GPU subsystems initialized (physics={}, analytics={}, graph_ops={})",
            physics.active_count(), analytics.active_count(), graph_ops.active_count());

        let state = Self {
            graph_service_addr,
            gpu_manager_addr,
            gpu_compute_addr: None,
            stress_majorization_addr,
            shortest_path_actor,
            connected_components_actor,

            // Phase 7: Decomposed subsystems
            physics,
            analytics,
            graph_ops,
            gpu_context_bus,

            settings_repository,
            neo4j_settings_repository,

            neo4j_adapter,

            ontology_repository,

            graph_repository,
            graph_query_handlers,

            command_bus,
            query_bus,
            event_bus,


            settings_addr,
            protected_settings_addr,
            metadata_addr,
            client_manager_addr,
            agent_monitor_addr,
            workspace_addr,
            ontology_actor_addr,
            github_client,
            content_api,
            perplexity_service,
            ragflow_service,
            speech_service,
            nostr_service: None,
            feature_access: web::Data::new(FeatureAccess::from_env()),
            ragflow_session_id,
            active_connections: Arc::new(AtomicUsize::new(0)),
            bots_client,
            task_orchestrator_addr,
            debug_enabled,
            client_message_tx,
            client_message_rx: Arc::new(tokio::sync::Mutex::new(client_message_rx)),
            ontology_pipeline_service,
        };

        // Validate optional actor addresses
        info!("[AppState::new] Validating actor initialization");
        let validation_report = state.validate();
        validation_report.log();

        if !validation_report.is_valid() {
            return Err(format!("AppState validation failed: {:?}", validation_report.errors).into());
        }

        info!("[AppState::new]  All validation checks passed");

        Ok(state)
    }

    /// Validate that all optional actors and services are properly initialized
    /// based on feature flags and environment configuration.
    pub fn validate(&self) -> crate::validation::ValidationReport {
        use crate::validation::*;
        let mut report = ValidationReport::new();

        // GPU-related actors
        {
            report.add(ValidationItem {
                name: "GPUManagerActor".to_string(),
                expected: true,
                present: self.gpu_manager_addr.is_some(),
                severity: Severity::Warning,
                reason: "GPU feature is enabled".to_string(),
            });

            report.add(ValidationItem {
                name: "gpu_compute_addr".to_string(),
                expected: false,
                present: self.gpu_compute_addr.is_some(),
                severity: Severity::Info,
                reason: "Initialized after GPU manager starts".to_string(),
            });

            report.add(ValidationItem {
                name: "stress_majorization_addr".to_string(),
                expected: false,
                present: self.stress_majorization_addr.is_some(),
                severity: Severity::Info,
                reason: "Initialized after GPU manager starts".to_string(),
            });
        }

        // Ontology actor
        {
            let present = self.ontology_actor_addr.is_some();
            report.add(ValidationItem {
                name: "OntologyActor".to_string(),
                expected: true,
                present,
                severity: Severity::Warning,
                reason: "Ontology feature is enabled".to_string(),
            });
        }

        // Perplexity service (environment-dependent)
        let perplexity_expected = env_is_set("PERPLEXITY_API_KEY");
        report.add(ValidationItem {
            name: "PerplexityService".to_string(),
            expected: perplexity_expected,
            present: self.perplexity_service.is_some(),
            severity: if perplexity_expected { Severity::Warning } else { Severity::Info },
            reason: if perplexity_expected {
                "PERPLEXITY_API_KEY is set".to_string()
            } else {
                "PERPLEXITY_API_KEY not set".to_string()
            },
        });

        // RAGFlow service (environment-dependent)
        let ragflow_expected = env_is_set("RAGFLOW_API_KEY");
        report.add(ValidationItem {
            name: "RAGFlowService".to_string(),
            expected: ragflow_expected,
            present: self.ragflow_service.is_some(),
            severity: if ragflow_expected { Severity::Warning } else { Severity::Info },
            reason: if ragflow_expected {
                "RAGFLOW_API_KEY is set".to_string()
            } else {
                "RAGFLOW_API_KEY not set".to_string()
            },
        });

        // Speech service (environment-dependent)
        let speech_expected = env_is_set("SPEECH_SERVICE_ENABLED");
        report.add(ValidationItem {
            name: "SpeechService".to_string(),
            expected: speech_expected,
            present: self.speech_service.is_some(),
            severity: if speech_expected { Severity::Warning } else { Severity::Info },
            reason: if speech_expected {
                "SPEECH_SERVICE_ENABLED is set".to_string()
            } else {
                "SPEECH_SERVICE_ENABLED not set".to_string()
            },
        });

        // Nostr service (set later via set_nostr_service)
        report.add(ValidationItem {
            name: "NostrService".to_string(),
            expected: false,
            present: self.nostr_service.is_some(),
            severity: Severity::Info,
            reason: "Set later via set_nostr_service()".to_string(),
        });

        // Ontology pipeline service
        report.add(ValidationItem {
            name: "OntologyPipelineService".to_string(),
            expected: true,
            present: self.ontology_pipeline_service.is_some(),
            severity: Severity::Warning,
            reason: "Required for semantic physics".to_string(),
        });

        report
    }

    pub fn increment_connections(&self) -> usize {
        self.active_connections.fetch_add(1, Ordering::SeqCst)
    }

    pub fn decrement_connections(&self) -> usize {
        self.active_connections.fetch_sub(1, Ordering::SeqCst)
    }

    pub async fn get_api_keys(&self, pubkey: &str) -> ApiKeys {
        use crate::actors::protected_settings_actor::GetApiKeys;
        self.protected_settings_addr
            .send(GetApiKeys {
                pubkey: pubkey.to_string(),
            })
            .await
            .unwrap_or_else(|_| ApiKeys::default())
    }

    pub async fn get_nostr_user(&self, pubkey: &str) -> Option<NostrUser> {
        if let Some(nostr_service) = &self.nostr_service {
            nostr_service.get_user(pubkey).await
        } else {
            None
        }
    }

    pub async fn validate_nostr_session(&self, pubkey: &str, token: &str) -> bool {
        if let Some(nostr_service) = &self.nostr_service {
            nostr_service.validate_session(pubkey, token).await
        } else {
            false
        }
    }

    pub async fn update_nostr_user_api_keys(
        &self,
        pubkey: &str,
        api_keys: ApiKeys,
    ) -> Result<NostrUser, String> {
        if let Some(nostr_service) = &self.nostr_service {
            nostr_service
                .update_user_api_keys(pubkey, api_keys)
                .await
                .map_err(|e| e.to_string())
        } else {
            Err("Nostr service not initialized".to_string())
        }
    }

    pub fn set_nostr_service(&mut self, service: NostrService) {
        self.nostr_service = Some(web::Data::new(service));
    }

    pub fn is_power_user(&self, pubkey: &str) -> bool {
        self.feature_access.is_power_user(pubkey)
    }

    pub fn can_sync_settings(&self, pubkey: &str) -> bool {
        self.feature_access.can_sync_settings(pubkey)
    }

    pub fn has_feature_access(&self, pubkey: &str, feature: &str) -> bool {
        self.feature_access.has_feature_access(pubkey, feature)
    }

    pub fn get_available_features(&self, pubkey: &str) -> Vec<String> {
        self.feature_access.get_available_features(pubkey)
    }

    pub fn get_client_manager_addr(&self) -> &Addr<ClientCoordinatorActor> {
        &self.client_manager_addr
    }

    pub fn get_graph_service_addr(&self) -> &Addr<GraphServiceSupervisor> {
        &self.graph_service_addr
    }

    pub fn get_settings_addr(&self) -> &Addr<OptimizedSettingsActor> {
        &self.settings_addr
    }

    pub fn get_metadata_addr(&self) -> &Addr<MetadataActor> {
        &self.metadata_addr
    }

    pub fn get_workspace_addr(&self) -> &Addr<WorkspaceActor> {
        &self.workspace_addr
    }

    pub fn get_ontology_actor_addr(&self) -> Option<&Addr<OntologyActor>> {
        self.ontology_actor_addr.as_ref()
    }

    pub fn get_task_orchestrator_addr(&self) -> &Addr<TaskOrchestratorActor> {
        &self.task_orchestrator_addr
    }
}

--------------------------------------------------------------------------------
FILE: src/types/claude_flow.rs
PURPOSE: Claude Flow agent types (AgentStatus, Vec3)
--------------------------------------------------------------------------------
//! Types for claude flow integration via TCP
//! These replace the local claude_flow module types

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use serde_json::json;
use tokio::time::{timeout, Duration};

use crate::utils::time;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Vec3 {
    pub x: f32,
    pub y: f32,
    pub z: f32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentStatus {
    
    #[serde(rename = "id")]
    pub agent_id: String,
    pub profile: AgentProfile,
    pub status: String,

    
    pub active_tasks_count: u32,
    pub completed_tasks_count: u32,
    pub failed_tasks_count: u32,
    pub success_rate: f32,
    pub timestamp: DateTime<Utc>,
    pub current_task: Option<TaskReference>,

    
    #[serde(rename = "type")]
    pub agent_type: String,

    #[serde(rename = "currentTask")]
    pub current_task_description: Option<String>,

    pub capabilities: Vec<String>,

    
    pub position: Option<Vec3>,

    
    #[serde(rename = "cpuUsage")]
    pub cpu_usage: f32,

    #[serde(rename = "memoryUsage")]
    pub memory_usage: f32,

    pub health: f32,
    pub activity: f32,

    #[serde(rename = "tasksActive")]
    pub tasks_active: u32,

    #[serde(rename = "tasksCompleted")]
    pub tasks_completed: u32,

    #[serde(rename = "successRate")]
    pub success_rate_normalized: f32,

    pub tokens: u64,

    #[serde(rename = "tokenRate")]
    pub token_rate: f32,

    
    pub performance_metrics: PerformanceMetrics,
    pub token_usage: TokenUsage,

    #[serde(rename = "swarmId")]
    pub swarm_id: Option<String>,

    #[serde(rename = "agentMode")]
    pub agent_mode: Option<String>,

    #[serde(rename = "parentQueenId")]
    pub parent_queen_id: Option<String>,

    #[serde(rename = "processingLogs")]
    pub processing_logs: Option<Vec<String>>,

    #[serde(rename = "createdAt")]
    pub created_at: String,

    pub age: u64,
    pub workload: Option<f32>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceMetrics {
    pub tasks_completed: u32,
    pub success_rate: f32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TokenUsage {
    pub total: u64,
    pub token_rate: f32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentProfile {
    pub name: String,
    pub agent_type: AgentType,
    pub capabilities: Vec<String>,
    pub description: Option<String>,
    pub version: String,
    pub tags: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum AgentType {
    Coordinator,
    Researcher,
    Coder,
    Analyst,
    Architect,
    Tester,
    Reviewer,
    Optimizer,
    Documenter,
    Generic,
}

impl ToString for AgentType {
    fn to_string(&self) -> String {
        match self {
            AgentType::Coordinator => "coordinator".to_string(),
            AgentType::Researcher => "researcher".to_string(),
            AgentType::Coder => "coder".to_string(),
            AgentType::Analyst => "analyst".to_string(),
            AgentType::Architect => "architect".to_string(),
            AgentType::Tester => "tester".to_string(),
            AgentType::Reviewer => "reviewer".to_string(),
            AgentType::Optimizer => "optimizer".to_string(),
            AgentType::Documenter => "documenter".to_string(),
            AgentType::Generic => "generic".to_string(),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum TaskPriority {
    Low,
    Medium,
    High,
    Critical,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskReference {
    pub task_id: String,
    pub description: String,
    pub priority: TaskPriority,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct McpRequest {
    pub jsonrpc: String,
    pub id: String,
    pub method: String,
    pub params: serde_json::Value,
}

// TCP Client for communicating with external claude flow service
#[derive(Clone)]
pub struct ClaudeFlowClient {
    host: String,
    port: u16,
    
}

impl ClaudeFlowClient {
    pub fn new(host: String, port: u16) -> Self {
        Self { host, port }
    }

    pub async fn connect(&mut self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        use tokio::net::TcpStream;
        use tokio::time::{timeout, Duration};

        log::info!("Connecting to Claude Flow at {}:{}", self.host, self.port);

        let addr = format!("{}:{}", self.host, self.port);
        let stream = timeout(Duration::from_secs(10), TcpStream::connect(&addr)).await??;

        log::info!("Successfully connected to Claude Flow at {}", addr);

        
        drop(stream); 
        Ok(())
    }

    pub async fn get_agent_statuses(
        &self,
    ) -> Result<Vec<AgentStatus>, Box<dyn std::error::Error + Send + Sync>> {
        use tokio::io::{AsyncReadExt, AsyncWriteExt};
        use tokio::net::TcpStream;
        use tokio::time::{timeout, Duration};

        let addr = format!("{}:{}", self.host, self.port);
        let mut stream = timeout(Duration::from_secs(5), TcpStream::connect(&addr)).await??;

        
        let request = json!({
            "jsonrpc": "2.0",
            "method": "list_agents",
            "id": 1
        });

        let request_str = format!("{}\n", request.to_string());
        stream.write_all(request_str.as_bytes()).await?;

        
        let mut buffer = vec![0; 8192];
        let bytes_read = timeout(Duration::from_secs(5), stream.read(&mut buffer)).await??;

        if bytes_read == 0 {
            return Ok(vec![]); 
        }

        let response_str = String::from_utf8_lossy(&buffer[..bytes_read]);

        
        if let Ok(response_json) = serde_json::from_str::<serde_json::Value>(&response_str) {
            if let Some(agents_array) = response_json.get("result").and_then(|r| r.as_array()) {
                let mut statuses = Vec::new();
                for agent_data in agents_array {
                    if let Ok(status) = self.parse_agent_status(agent_data) {
                        statuses.push(status);
                    }
                }
                return Ok(statuses);
            }
        }

        log::debug!("No valid agents found in TCP response");
        Ok(vec![])
    }

    fn parse_agent_status(
        &self,
        agent_data: &serde_json::Value,
    ) -> Result<AgentStatus, Box<dyn std::error::Error + Send + Sync>> {
        let agent_id = agent_data
            .get("id")
            .and_then(|v| v.as_str())
            .unwrap_or("unknown")
            .to_string();
        let agent_type = agent_data
            .get("type")
            .and_then(|v| v.as_str())
            .unwrap_or("generic")
            .to_string();
        let status = agent_data
            .get("status")
            .and_then(|v| v.as_str())
            .unwrap_or("idle")
            .to_string();

        
        let position = if let (Some(x), Some(y), Some(z)) = (
            agent_data.get("x").and_then(|v| v.as_f64()),
            agent_data.get("y").and_then(|v| v.as_f64()),
            agent_data.get("z").and_then(|v| v.as_f64()),
        ) {
            Some(Vec3 {
                x: x as f32,
                y: y as f32,
                z: z as f32,
            })
        } else if let Some(pos) = agent_data.get("position") {
            Some(Vec3 {
                x: pos.get("x").and_then(|v| v.as_f64()).unwrap_or(0.0) as f32,
                y: pos.get("y").and_then(|v| v.as_f64()).unwrap_or(0.0) as f32,
                z: pos.get("z").and_then(|v| v.as_f64()).unwrap_or(0.0) as f32,
            })
        } else {
            None
        };

        
        let current_task_description = agent_data
            .get("current_task")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string())
            .or_else(|| {
                agent_data
                    .get("currentTask")
                    .and_then(|v| v.as_str())
                    .map(|s| s.to_string())
            });

        
        let capabilities = agent_data
            .get("capabilities")
            .and_then(|v| v.as_array())
            .map(|arr| {
                arr.iter()
                    .filter_map(|v| v.as_str())
                    .map(|s| s.to_string())
                    .collect()
            })
            .unwrap_or_else(|| vec![agent_type.clone()]);

        
        let success_rate_raw = agent_data
            .get("success_rate")
            .and_then(|v| v.as_f64())
            .unwrap_or(0.95) as f32;
        let success_rate_normalized = if success_rate_raw > 1.0 {
            success_rate_raw / 100.0
        } else {
            success_rate_raw
        };

        
        let cpu_usage_raw = agent_data
            .get("cpu_usage")
            .and_then(|v| v.as_f64())
            .unwrap_or(25.0) as f32;
        let cpu_usage = if cpu_usage_raw > 1.0 {
            cpu_usage_raw / 100.0
        } else {
            cpu_usage_raw
        };

        let memory_usage_raw = agent_data
            .get("memory_usage")
            .and_then(|v| v.as_f64())
            .unwrap_or(128.0) as f32;
        let memory_usage = if memory_usage_raw > 1.0 {
            memory_usage_raw / 100.0
        } else {
            memory_usage_raw
        };

        let now = time::now();
        let created_at = now.to_rfc3339();

        Ok(AgentStatus {
            agent_id: agent_id.clone(),
            profile: AgentProfile {
                name: agent_id.clone(),
                agent_type: match agent_type.as_str() {
                    "coordinator" => AgentType::Coordinator,
                    "researcher" => AgentType::Researcher,
                    "coder" => AgentType::Coder,
                    "analyst" => AgentType::Analyst,
                    "architect" => AgentType::Architect,
                    "tester" => AgentType::Tester,
                    "reviewer" => AgentType::Reviewer,
                    "optimizer" => AgentType::Optimizer,
                    "documenter" => AgentType::Documenter,
                    _ => AgentType::Generic,
                },
                capabilities: capabilities.clone(),
                description: Some(format!("{} agent", agent_type)),
                version: "1.0.0".to_string(),
                tags: vec!["general".to_string()],
            },
            status: status.clone(),

            
            active_tasks_count: agent_data
                .get("active_tasks")
                .and_then(|v| v.as_u64())
                .unwrap_or(0) as u32,
            completed_tasks_count: agent_data
                .get("completed_tasks")
                .and_then(|v| v.as_u64())
                .unwrap_or(0) as u32,
            failed_tasks_count: agent_data
                .get("failed_tasks")
                .and_then(|v| v.as_u64())
                .unwrap_or(0) as u32,
            success_rate: success_rate_raw,
            timestamp: now,
            current_task: current_task_description
                .as_ref()
                .map(|task_desc| TaskReference {
                    task_id: format!("task_{}", uuid::Uuid::new_v4()),
                    description: task_desc.clone(),
                    priority: TaskPriority::Medium,
                }),

            
            agent_type: agent_type.clone(),
            current_task_description,
            capabilities,
            position,
            cpu_usage,
            memory_usage,
            health: agent_data
                .get("health")
                .and_then(|v| v.as_f64())
                .unwrap_or(0.9) as f32,
            activity: agent_data
                .get("activity")
                .and_then(|v| v.as_f64())
                .unwrap_or(0.5) as f32,
            tasks_active: agent_data
                .get("tasks_active")
                .and_then(|v| v.as_u64())
                .unwrap_or(1) as u32,
            tasks_completed: agent_data
                .get("completed_tasks")
                .and_then(|v| v.as_u64())
                .unwrap_or(0) as u32,
            success_rate_normalized,
            tokens: agent_data
                .get("total_tokens")
                .and_then(|v| v.as_u64())
                .unwrap_or(1500),
            token_rate: agent_data
                .get("token_rate")
                .and_then(|v| v.as_f64())
                .unwrap_or(0.1) as f32,

            
            performance_metrics: PerformanceMetrics {
                tasks_completed: agent_data
                    .get("completed_tasks")
                    .and_then(|v| v.as_u64())
                    .unwrap_or(0) as u32,
                success_rate: success_rate_normalized,
            },
            token_usage: TokenUsage {
                total: agent_data
                    .get("total_tokens")
                    .and_then(|v| v.as_u64())
                    .unwrap_or(1500),
                token_rate: agent_data
                    .get("token_rate")
                    .and_then(|v| v.as_f64())
                    .unwrap_or(0.1) as f32,
            },
            swarm_id: agent_data
                .get("swarm_id")
                .and_then(|v| v.as_str())
                .map(|s| s.to_string()),
            agent_mode: agent_data
                .get("agent_mode")
                .and_then(|v| v.as_str())
                .map(|s| s.to_string()),
            parent_queen_id: agent_data
                .get("parent_queen_id")
                .and_then(|v| v.as_str())
                .map(|s| s.to_string()),
            processing_logs: Some(vec![]),
            created_at,
            age: 0, 
            workload: agent_data
                .get("workload")
                .and_then(|v| v.as_f64())
                .map(|v| v as f32),
        })
    }

    
    pub async fn send_mcp_request(
        &self,
        request: &McpRequest,
    ) -> Result<serde_json::Value, Box<dyn std::error::Error + Send + Sync>> {
        use tokio::io::{AsyncReadExt, AsyncWriteExt};
        use tokio::net::TcpStream;
use crate::utils::json::{from_json, to_json};
use crate::utils::time;

        let addr = format!("{}:{}", self.host, self.port);
        let mut stream = timeout(Duration::from_secs(5), TcpStream::connect(&addr)).await??;

        
        let json_request = json!({
            "jsonrpc": "2.0",
            "method": request.method,
            "params": request.params,
            "id": uuid::Uuid::new_v4().to_string()
        });

        let request_str = format!("{}\n", json_request.to_string());
        stream.write_all(request_str.as_bytes()).await?;

        
        let mut buffer = vec![0; 16384];
        let bytes_read = timeout(Duration::from_secs(10), stream.read(&mut buffer)).await??;

        if bytes_read == 0 {
            return Err("No response received from TCP server".into());
        }

        let response_str = String::from_utf8_lossy(&buffer[..bytes_read]);

        
        match serde_json::from_str::<serde_json::Value>(&response_str) {
            Ok(json_response) => {
                if let Some(error) = json_response.get("error") {
                    return Err(format!("MCP request failed: {}", error).into());
                }
                Ok(json_response
                    .get("result")
                    .cloned()
                    .unwrap_or(serde_json::Value::Null))
            }
            Err(e) => {
                log::error!(
                    "Failed to parse TCP response: {} (raw: {})",
                    e,
                    response_str
                );
                Err(format!("Invalid JSON response: {}", e).into())
            }
        }
    }
}

// Error types
#[derive(Debug)]
pub enum ConnectorError {
    NotConnected,
    NetworkError(String),
    ParseError(String),
}

impl std::fmt::Display for ConnectorError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            ConnectorError::NotConnected => write!(f, "Not connected to Claude Flow service"),
            ConnectorError::NetworkError(msg) => write!(f, "Network error: {}", msg),
            ConnectorError::ParseError(msg) => write!(f, "Parse error: {}", msg),
        }
    }
}

impl std::error::Error for ConnectorError {}

--------------------------------------------------------------------------------
FILE: src/main.rs
PURPOSE: Application entry point with Actix-web server setup
--------------------------------------------------------------------------------
// Rebuild: KE velocity fix applied
use actix::Actor;
use webxr::ports::ontology_repository::OntologyRepository;
use webxr::services::nostr_service::NostrService;
use webxr::settings::settings_actor::SettingsActor;
use webxr::adapters::neo4j_settings_repository::{Neo4jSettingsRepository, Neo4jSettingsConfig};
use webxr::actors::messages::ReloadGraphFromDatabase;
use webxr::{
    config::AppFullSettings,
    handlers::{
        admin_sync_handler,
        api_handler,
        bots_visualization_handler,
        client_log_handler,
        client_messages_handler,
        consolidated_health_handler,
        graph_export_handler,
        mcp_relay_handler::mcp_relay_handler,
        multi_mcp_websocket_handler,
        nostr_handler,
        pages_handler,
        socket_flow_handler::{socket_flow_handler, PreReadSocketSettings}, 
        speech_socket_handler::speech_socket_handler,
        
        
        workspace_handler,
    },
    services::speech_service::SpeechService,
    services::{
        
        github::{content_enhanced::EnhancedContentAPI, ContentAPI, GitHubClient, GitHubConfig},
        github_sync_service::GitHubSyncService, 
        ragflow_service::RAGFlowService,        
    },
    
    AppState,
};

use actix_cors::Cors;
use actix_web::{middleware, web, App, HttpServer};
use utoipa::OpenApi;
use utoipa_swagger_ui::SwaggerUi;
// DEPRECATED: std::future imports removed (were for ErrorRecoveryMiddleware)
// DEPRECATED: Actix dev imports removed (were for ErrorRecoveryMiddleware)
// DEPRECATED: LocalBoxFuture import removed (was for ErrorRecoveryMiddleware)
// use actix_files::Files; 
use dotenvy::dotenv;
use log::{debug, error, info};
use std::sync::Arc;
use tokio::signal::unix::{signal, SignalKind};
use tokio::sync::RwLock;
use tokio::time::Duration;
use webxr::middleware::TimeoutMiddleware;
use webxr::telemetry::agent_telemetry::init_telemetry_logger;
use webxr::utils::advanced_logging::init_advanced_logging;
use webxr::utils::json::{to_json, from_json};
// REMOVED: use webxr::utils::logging::init_logging; - legacy logging superseded by advanced_logging

// DEPRECATED: ErrorRecoveryMiddleware removed - NetworkRecoveryManager deleted


#[actix_web::main]
async fn main() -> std::io::Result<()> {

    dotenv().ok();

    info!("--- Configuration Verification ---");
    info!("MARKDOWN_DIR: {}", webxr::services::file_service::MARKDOWN_DIR);
    info!("METADATA_PATH: {}", "/workspace/ext/data/metadata/metadata.json");
    info!("---------------------------------");

    // REMOVED: init_logging()? call - using advanced_logging instead
    if let Err(e) = init_advanced_logging() {
        error!("Failed to initialize advanced logging: {}", e);
        return Err(std::io::Error::new(
            std::io::ErrorKind::Other,
            format!("Advanced logging initialization failed: {}", e),
        ));
    } else {
        info!("Advanced logging system initialized successfully");
    }

    
    
    let log_dir = if std::path::Path::new("/app/logs").exists() {
        "/app/logs".to_string()
    } else if std::path::Path::new("/workspace/ext/logs").exists() {
        "/workspace/ext/logs".to_string()
    } else {
        
        std::env::temp_dir()
            .join("webxr_telemetry")
            .to_string_lossy()
            .to_string()
    };

    let log_dir = std::env::var("TELEMETRY_LOG_DIR").unwrap_or(log_dir);

    if let Err(e) = init_telemetry_logger(&log_dir, 100) {
        error!("Failed to initialize telemetry logger: {}", e);
    } else {
        info!("Telemetry logger initialized with directory: {}", log_dir);
    }

    
    let settings = match AppFullSettings::new() {
        Ok(s) => {
            info!(
                " AppFullSettings loaded successfully from: {}",
                std::env::var("SETTINGS_FILE_PATH")
                    .unwrap_or_else(|_| "/app/settings.yaml".to_string())
            );

            
            match to_json(&s.visualisation.rendering) {
                Ok(json_output) => {
                    info!(
                        " SERDE ALIAS FIX WORKS! JSON serialization (camelCase): {}",
                        json_output
                    );

                    
                    if json_output.contains("ambientLightIntensity")
                        && !json_output.contains("ambient_light_intensity")
                    {
                        info!(" CONFIRMED: JSON uses camelCase field names for REST API compatibility");
                    }

                    
                    info!(" CONFIRMED: Values loaded from snake_case YAML:");
                    info!(
                        "   - ambient_light_intensity -> {}",
                        s.visualisation.rendering.ambient_light_intensity
                    );
                    info!(
                        "   - enable_ambient_occlusion -> {}",
                        s.visualisation.rendering.enable_ambient_occlusion
                    );
                    info!(
                        "   - background_color -> {}",
                        s.visualisation.rendering.background_color
                    );
                    info!(" SERDE ALIAS FIX IS WORKING: YAML (snake_case) loads successfully, JSON serializes as camelCase!");
                }
                Err(e) => {
                    error!(" JSON serialization failed: {}", e);
                }
            }

            Arc::new(RwLock::new(s)) 
        }
        Err(e) => {
            error!(" Failed to load AppFullSettings: {:?}", e);
            return Err(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("Failed to initialize AppFullSettings: {:?}", e),
            ));
        }
    };

    
    info!("GPU compute will be initialized by GPUComputeActor when needed");

    debug!("Successfully loaded AppFullSettings");

    info!("Starting WebXR application...");
    debug!("main: Beginning application startup sequence.");

    // Phase 3: Initialize Neo4j settings repository and actor
    info!("Initializing SettingsActor with Neo4j");
    let settings_config = Neo4jSettingsConfig::default();
    let settings_repository = match Neo4jSettingsRepository::new(settings_config).await {
        Ok(repo) => Arc::new(repo),
        Err(e) => {
            error!("Failed to create Neo4j settings repository: {}", e);
            return Err(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("Failed to create Neo4j settings repository: {}", e),
            ));
        }
    };

    let settings_actor = SettingsActor::new(settings_repository.clone()).start();
    let settings_actor_data = web::Data::new(settings_actor);
    let neo4j_repo_data = web::Data::new(settings_repository.clone());
    info!("SettingsActor initialized successfully");



    let settings_data = web::Data::new(settings.clone());

    
    let github_config = match GitHubConfig::from_env() {
        Ok(config) => config,
        Err(e) => {
            return Err(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("Failed to load GitHub config: {}", e),
            ))
        }
    };

    
    
    let github_client = match GitHubClient::new(github_config, settings.clone()).await {
        Ok(client) => Arc::new(client),
        Err(e) => {
            return Err(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("Failed to initialize GitHub client: {}", e),
            ))
        }
    };

    let content_api = Arc::new(ContentAPI::new(github_client.clone()));

    
    
    let speech_service = {
        let service = SpeechService::new(settings.clone());
        Some(Arc::new(service))
    };

    
    info!("[main] Attempting to initialize RAGFlowService...");
    let ragflow_service_option = match RAGFlowService::new(settings.clone()).await {
        Ok(service) => {
            info!("[main] RAGFlowService::new SUCCEEDED. Service instance created.");
            Some(Arc::new(service))
        }
        Err(e) => {
            error!("[main] RAGFlowService::new FAILED. Error: {}", e);
            None
        }
    };

    if ragflow_service_option.is_some() {
        info!("[main] ragflow_service_option is Some after RAGFlowService::new attempt.");
    } else {
        error!("[main] ragflow_service_option is None after RAGFlowService::new attempt. Chat functionality will be unavailable.");
    }

    
    
    let settings_value = {
        let settings_read = settings.read().await;
        settings_read.clone()
    };

    let mut app_state = match AppState::new(
        settings_value,
        github_client.clone(),
        content_api.clone(),
        None,                   
        ragflow_service_option, 
        speech_service,
        "default_session".to_string(), 
    )
    .await
    {
        Ok(state) => {
            info!("[main] AppState::new completed successfully");
            state
        }
        Err(e) => {
            return Err(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("Failed to initialize app state: {}", e),
            ))
        }
    };

    info!("[main] About to initialize Nostr service");
    
    nostr_handler::init_nostr_service(&mut app_state);
    info!("[main] Nostr service initialized");

    
    info!("[main] Initializing GitHub Sync Service...");
    let enhanced_content_api = Arc::new(EnhancedContentAPI::new(github_client.clone()));
    let github_sync_service = Arc::new(GitHubSyncService::new(
        enhanced_content_api,
        app_state.neo4j_adapter.clone(),
        app_state.ontology_repository.clone(),
    ));
    info!("[main] GitHub Sync Service initialized");

    // Initialize SchemaService for natural language query support
    info!("[main] Initializing Schema Service...");
    let schema_service = Arc::new(webxr::services::schema_service::SchemaService::new());
    info!("[main] Schema Service initialized");
    // Initialize Natural Language Query Service
    info!("[main] Initializing Natural Language Query Service...");
    let perplexity_service = Arc::new(webxr::services::perplexity_service::PerplexityService::new());
    let nl_query_service = Arc::new(webxr::services::natural_language_query_service::NaturalLanguageQueryService::new(
        schema_service.clone(),
        perplexity_service.clone(),
    ));
    info!("[main] Natural Language Query Service initialized");

    // Initialize Semantic Pathfinding Service
    info!("[main] Initializing Semantic Pathfinding Service...");
    let pathfinding_service = Arc::new(webxr::services::semantic_pathfinding_service::SemanticPathfindingService::default());
    info!("[main] Semantic Pathfinding Service initialized");

    info!("--- Starting Data Orchestration Sequence ---");

    // Step 1: Sync Files from GitHub.
    info!("[Startup] Step 1: Syncing files from GitHub to local storage...");
    let github_sync_failed = if let Err(e) = webxr::services::file_service::FileService::initialize_local_storage(settings.clone()).await {
        error!("[Startup] FAILED to sync from GitHub: {}. Will try local files.", e);
        true
    } else {
        info!("[Startup] SUCCESS: Local file storage is synchronized with GitHub.");
        false
    };

    // Step 1b: If GitHub sync failed or metadata is empty, scan local files
    let metadata = webxr::services::file_service::FileService::load_or_create_metadata().unwrap_or_default();
    if github_sync_failed || metadata.is_empty() {
        info!("[Startup] Step 1b: Scanning local markdown files as fallback...");
        match webxr::services::file_service::FileService::scan_local_files_to_metadata() {
            Ok(local_metadata) => {
                info!("[Startup] SUCCESS: Scanned {} public files from local storage.", local_metadata.len());
            }
            Err(e) => {
                error!("[Startup] FAILED to scan local files: {}", e);
            }
        }
    }

    // Step 2: Load Files into Neo4j.
    info!("[Startup] Step 2: Populating Neo4j from local files...");
    if let Err(e) = webxr::services::file_service::FileService::load_graph_from_files_into_neo4j(&app_state.neo4j_adapter).await {
        error!("[Startup] FATAL: Failed to populate Neo4j: {}. The application may not function correctly.", e);
        // Optional: Exit if this step is critical
        // return Err(std::io::Error::new(std::io::ErrorKind::Other, e));
    } else {
        info!("[Startup] SUCCESS: Neo4j database is populated and ready.");
    }

    // Step 3: Notify Actors.
    info!("[Startup] Step 3: Notifying actors to reload graph state from database...");
    app_state.graph_service_addr.do_send(ReloadGraphFromDatabase);
    info!("[Startup] SUCCESS: Actors notified.");
    info!("--- Data Orchestration Sequence Complete ---");










    info!("Skipping bots orchestrator connection during startup (will connect on-demand)");


    info!("Loading ontology graph from Neo4j...");

    let graph_data_option = match app_state.ontology_repository.load_ontology_graph().await {
        Ok(graph_arc) => {
            let graph = graph_arc.as_ref();
            if !graph.nodes.is_empty() {
                info!(
                    " Loaded ontology graph from database: {} nodes, {} edges",
                    graph.nodes.len(),
                    graph.edges.len()
                );
                info!("  Ontology classes loaded but NOT sent to actor (KG nodes will be loaded via ReloadGraphFromDatabase)");
                Some((*graph_arc).clone())
            } else {
                info!(" Ontology database is empty - waiting for GitHub sync to populate");
                info!("  Ontology classes will be loaded after sync extracts OWL data");
                None
            }
        }
        Err(e) => {
            error!("  Failed to load ontology graph from database: {}", e);
            error!("  Graph will be empty until GitHub sync completes");
            None
        }
    };


    // CRITICAL FIX: Do NOT send ontology graph via UpdateGraphData!
    // This would overwrite the KG nodes that should be loaded via ReloadGraphFromDatabase.
    // The architecture is: KG nodes (from GitHub sync) with owl_class_iri links to ontology.
    // ReloadGraphFromDatabase (sent in app_state.rs) will load all KG nodes from database.
    // UpdateGraphData here would overwrite them with only the 1 ontology root node.
    //
    // Keeping graph_data_option for potential future use but not sending it to actor.

    if let Some(_graph_data) = graph_data_option {
        info!("  Ontology graph loaded but not sent to actor (will use KG nodes from ReloadGraphFromDatabase instead)");
        info!("  Ontology classes are available via API endpoints but nodes come from KG sync");
    } else {
        info!(" GraphServiceActor will be populated by ReloadGraphFromDatabase from existing KG nodes");
        info!("  If no KG nodes exist, you can trigger GitHub sync via /api/admin/sync endpoint");
    }

    info!("Starting HTTP server...");

    
    
    
    
    
    
    
    info!("Skipping redundant StartSimulation message to GraphServiceSupervisor for debugging stack overflow. Simulation should already be running from supervisor's started() method.");

    
    let app_state_data = web::Data::new(app_state);
    

    
    let bind_address = std::env::var("BIND_ADDRESS").unwrap_or_else(|_| "0.0.0.0".to_string());
    let port = std::env::var("SYSTEM_NETWORK_PORT")
        .ok()
        .and_then(|p| p.parse::<u16>().ok())
        .unwrap_or(4000);
    let bind_address = format!("{}:{}", bind_address, port);

    
    let pre_read_ws_settings = {
        let s = settings.read().await;
        PreReadSocketSettings {
            min_update_rate: s.system.websocket.min_update_rate,
            max_update_rate: s.system.websocket.max_update_rate,
            motion_threshold: s.system.websocket.motion_threshold,
            motion_damping: s.system.websocket.motion_damping,
            heartbeat_interval_ms: s.system.websocket.heartbeat_interval, 
            heartbeat_timeout_ms: s.system.websocket.heartbeat_timeout,   
        }
    };
    let pre_read_ws_settings_data = web::Data::new(pre_read_ws_settings);

    info!("Starting HTTP server on {}", bind_address);

    info!("main: All services and actors initialized. Configuring HTTP server.");
    let server =
        HttpServer::new(move || {
            // CORS configuration with security-aware origin handling
            // Production: Uses CORS_ALLOWED_ORIGINS environment variable
            // Development: Falls back to localhost origins with ALLOW_INSECURE_DEFAULTS
            let cors = {
                let allowed_origins = std::env::var("CORS_ALLOWED_ORIGINS")
                    .unwrap_or_else(|_| {
                        if std::env::var("ALLOW_INSECURE_DEFAULTS").is_ok() {
                            // Development mode: allow common local origins
                            "http://localhost:3000,http://localhost:3001,http://127.0.0.1:3000,http://localhost:5173".to_string()
                        } else {
                            // Production: require explicit configuration
                            log::warn!("  CORS_ALLOWED_ORIGINS not set - using restrictive defaults");
                            "http://localhost:3000".to_string()
                        }
                    });

                let mut cors_builder = Cors::default();

                for origin in allowed_origins.split(',').map(|s| s.trim()) {
                    if !origin.is_empty() {
                        cors_builder = cors_builder.allowed_origin(origin);
                    }
                }

                cors_builder
                    .allowed_methods(vec!["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"])
                    .allowed_headers(vec![
                        actix_web::http::header::AUTHORIZATION,
                        actix_web::http::header::CONTENT_TYPE,
                        actix_web::http::header::ACCEPT,
                        actix_web::http::header::ORIGIN,
                    ])
                    .supports_credentials()
                    .max_age(3600)
            };

            let app = App::new()
            .wrap(middleware::Logger::default())
            .wrap(cors)
            .wrap(middleware::Compress::default())
            .wrap(TimeoutMiddleware::new(Duration::from_secs(30))) 


            .app_data(settings_data.clone())
            .app_data(web::Data::new(github_client.clone()))
            .app_data(web::Data::new(content_api.clone()))
            .app_data(app_state_data.clone())
            .app_data(pre_read_ws_settings_data.clone())

            .app_data(web::Data::new(app_state_data.graph_service_addr.clone()))
            .app_data(web::Data::new(app_state_data.settings_addr.clone()))
            .app_data(web::Data::new(app_state_data.metadata_addr.clone()))
            .app_data(web::Data::new(app_state_data.client_manager_addr.clone()))
            .app_data(web::Data::new(app_state_data.workspace_addr.clone()))
            .app_data(web::Data::new(schema_service.clone()))
            .app_data(web::Data::new(nl_query_service.clone()))
            .app_data(web::Data::new(pathfinding_service.clone()))
            .app_data(app_state_data.nostr_service.clone().unwrap_or_else(|| web::Data::new(NostrService::default())))
            .app_data(app_state_data.feature_access.clone())
            .app_data(web::Data::new(github_sync_service.clone()))
            .app_data(settings_actor_data.clone())
            .app_data(neo4j_repo_data.clone()) 
            
            
            .route("/wss", web::get().to(socket_flow_handler)) 
            .route("/ws/speech", web::get().to(speech_socket_handler))
            .route("/ws/mcp-relay", web::get().to(mcp_relay_handler)) 
            
            .route("/ws/client-messages", web::get().to(client_messages_handler::websocket_client_messages))
            // OpenAPI/Swagger documentation
            .service(
                SwaggerUi::new("/swagger-ui/{_:.*}")
                    .url("/api-docs/openapi.json", webxr::openapi::ApiDoc::openapi())
            )
            .service(
                web::scope("/api")
                    // Client logs route - registered early to avoid scope conflicts
                    .route("/client-logs", web::post().to(client_log_handler::handle_client_logs))
                    .service(web::scope("/settings").configure(webxr::settings::api::configure_routes))
                    .configure(api_handler::config)
                    .configure(workspace_handler::config)
                    .configure(admin_sync_handler::configure_routes)

                    // Pipeline admin routes removed (SQLite-specific handlers deleted in Neo4j migration)
                    // Cypher query endpoint removed (handler deleted in Neo4j migration)

                    // Phase 5: Hexagonal architecture handlers
                    .configure(webxr::handlers::configure_physics_routes)
                    .configure(webxr::handlers::configure_schema_routes)
                    .configure(webxr::handlers::configure_nl_query_routes)
                    .configure(webxr::handlers::configure_pathfinding_routes)
                    .configure(webxr::handlers::configure_semantic_routes)
                    .configure(webxr::handlers::configure_inference_routes)

                    // Health and monitoring
                    .configure(consolidated_health_handler::configure_routes)

                    // Multi-MCP WebSocket
                    .configure(multi_mcp_websocket_handler::configure_multi_mcp_routes)

                    .service(web::scope("/pages").configure(pages_handler::config))
                    .service(web::scope("/bots").configure(api_handler::bots::config))
                    .configure(bots_visualization_handler::configure_routes)
                    .configure(graph_export_handler::configure_routes)

                    // JavaScript Solid Server (JSS) integration
                    .configure(webxr::handlers::configure_solid_routes)

            );

            app
        })
        .bind(&bind_address)?
        .workers(4) 
        .run();

    let server_handle = server.handle();

    
    let mut sigterm = signal(SignalKind::terminate())?;
    let mut sigint = signal(SignalKind::interrupt())?;

    tokio::spawn(async move {
        tokio::select! {
            _ = sigterm.recv() => {
                info!("Received SIGTERM signal");
            }
            _ = sigint.recv() => {
                info!("Received SIGINT signal");
            }
        }
        info!("Initiating graceful shutdown");
        server_handle.stop(true).await;
    });

    info!("main: HTTP server startup sequence complete. Server is now running.");
    server.await?;

    info!("HTTP server stopped");
    Ok(())
}

--------------------------------------------------------------------------------
FILE: src/lib.rs
PURPOSE: Library crate with module exports
--------------------------------------------------------------------------------
pub mod actors;
pub mod adapters;
pub mod app_state;
pub mod application;
pub mod client;
pub mod config;
pub mod constraints;
pub mod cqrs;
pub mod errors;
pub mod events;
pub mod gpu;
pub mod handlers;
pub mod inference;
pub mod middleware;
// pub mod migrations; // Removed in Phase 3 - Neo4j migration complete
pub mod models;
pub mod ontology;
pub mod openapi;
pub mod reasoning;
pub mod physics;
pub mod ports;
pub mod repositories;
pub mod services;
pub mod settings;
pub mod telemetry;
pub mod types;

// Import utils with macro_use to make response macros available everywhere
#[macro_use]
pub mod utils;
pub mod validation;

// #[cfg(test)]
// pub mod test_settings_fix;

pub use actors::{
    ClientCoordinatorActor, MetadataActor, OptimizedSettingsActor,
};
pub use app_state::AppState;
pub use models::metadata::MetadataStore;
pub use models::protected_settings::ProtectedSettings;
pub use models::simulation_params::SimulationParams;
// pub use models::ui_settings::UISettings;
pub use models::user_settings::UserSettings;

// Re-export commonly used utilities for easier access
pub use utils::json::{to_json, from_json};
pub use utils::result_helpers::safe_json_number;
pub use utils::time;
// Re-export HandlerResponse trait for response macros
pub use utils::handler_commons::HandlerResponse;

================================================================================
                    SECTION 12: CLIENT SERVICES (TypeScript)
================================================================================

--------------------------------------------------------------------------------
FILE: client/src/services/WebSocketService.ts
PURPOSE: Singleton WebSocket service with binary protocol support
--------------------------------------------------------------------------------
import { createLogger } from '../utils/loggerConfig';
import { createErrorMetadata } from '../utils/loggerConfig';
import { debugState } from '../utils/clientDebugState';
import { useSettingsStore } from '../store/settingsStore';
import { graphDataManager } from '../features/graph/managers/graphDataManager';
import { parseBinaryNodeData, isAgentNode, createBinaryNodeData, BinaryNodeData } from '../types/binaryProtocol';
import { NodePositionBatchQueue, createWebSocketBatchProcessor } from '../utils/BatchQueue';
import { validateNodePositions, createValidationMiddleware } from '../utils/validation';
import {
  WebSocketMessage,
  WebSocketEventHandlers,
  WebSocketConfig,
  WebSocketConnectionState,
  WebSocketError,
  WebSocketStatistics,
  Subscription,
  SubscriptionFilters,
  MessageHandler
} from '../types/websocketTypes';
import { binaryProtocol, MessageType, GraphTypeFlag } from './BinaryWebSocketProtocol';
import { nostrAuth } from './nostrAuthService';

const logger = createLogger('WebSocketService');

export interface WebSocketAdapter {
  send: (data: ArrayBuffer) => void;
  isReady: () => boolean;
}

// Legacy interface for backward compatibility
export interface LegacyWebSocketMessage {
  type: string;
  data?: any;
  error?: WebSocketErrorFrame;
}

export interface WebSocketErrorFrame {
  code: string;
  message: string;
  category: 'validation' | 'server' | 'protocol' | 'auth' | 'rate_limit';
  details?: any;
  retryable: boolean;
  retryAfter?: number;
  affectedPaths?: string[];
  timestamp: number;
}

export interface QueuedMessage {
  type: 'text' | 'binary';
  data: string | ArrayBuffer;
  timestamp: number;
  retries: number;
}

// Legacy interface - replaced by WebSocketConnectionState from websocketTypes
export interface ConnectionState {
  status: 'disconnected' | 'connecting' | 'connected' | 'reconnecting' | 'failed';
  lastConnected?: number;
  lastError?: string;
  reconnectAttempts: number;
}

// Solid notification types (solid-0.1 protocol)
export interface SolidNotification {
  type: 'pub' | 'ack';
  url: string;
}

export type SolidNotificationCallback = (notification: SolidNotification) => void;

// Legacy types for backward compatibility
type LegacyMessageHandler = (message: LegacyWebSocketMessage) => void;
type BinaryMessageHandler = (data: ArrayBuffer) => void;
type ConnectionStatusHandler = (connected: boolean) => void;
type ConnectionStateHandler = (state: ConnectionState) => void;
type EventHandler = (data: any) => void;

class WebSocketService {
  private static instance: WebSocketService;
  private socket: WebSocket | null = null;
  private messageHandlers: LegacyMessageHandler[] = [];
  private binaryMessageHandlers: BinaryMessageHandler[] = [];
  private connectionStatusHandlers: ConnectionStatusHandler[] = [];
  private eventHandlers: Map<string, EventHandler[]> = new Map();


  private subscriptions: Map<string, Subscription> = new Map();
  private subscriptionCounter: number = 0;
  private statistics: WebSocketStatistics;
  private config: WebSocketConfig;
  private reconnectInterval: number = 1000;
  private maxReconnectAttempts: number = 10;
  private reconnectAttempts: number = 0;
  private maxReconnectDelay: number = 30000;
  private reconnectTimeout: number | null = null;
  private isConnected: boolean = false;
  private isServerReady: boolean = false;
  private url: string;
  private messageQueue: QueuedMessage[] = [];
  private maxQueueSize: number = 100;
  private heartbeatInterval: number | null = null;
  private heartbeatTimeout: number | null = null;
  private heartbeatIntervalMs: number = 30000;
  private heartbeatTimeoutMs: number = 10000;
  private connectionState: ConnectionState = {
    status: 'disconnected',
    reconnectAttempts: 0
  };
  private connectionStateHandlers: ConnectionStateHandler[] = [];
  private positionBatchQueue: NodePositionBatchQueue | null = null;
  private binaryMessageCount: number = 0;

  // Backpressure flow control - client-side sequence tracking
  // Used to send ACKs back to server after processing position updates
  private positionUpdateSequence: number = 0;
  private lastAckSentSequence: number = 0;
  private ackBatchSize: number = 10; // Send ACK every N position updates

  // JSS/Solid WebSocket for notifications (solid-0.1 protocol)
  private solidSocket: WebSocket | null = null;
  private solidSubscriptions: Map<string, Set<SolidNotificationCallback>> = new Map();
  private solidReconnectAttempts: number = 0;
  private solidMaxReconnectAttempts: number = 5;
  private solidReconnectDelay: number = 1000;
  private solidReconnectTimeout: number | null = null;
  private isSolidConnected: boolean = false;


  private enhancedConnectionState: WebSocketConnectionState = {
    status: 'disconnected',
    reconnectAttempts: 0,
    serverFeatures: []
  };

  private constructor() {

    this.statistics = {
      messagesReceived: 0,
      messagesSent: 0,
      bytesReceived: 0,
      bytesSent: 0,
      connectionTime: 0,
      reconnections: 0,
      averageLatency: 0,
      messagesByType: {},
      errors: 0,
      lastActivity: Date.now()
    };


    this.config = {
      reconnect: {
        maxAttempts: 10,
        baseDelay: 1000,
        maxDelay: 30000,
        backoffFactor: 2
      },
      heartbeat: {
        interval: 30000,
        timeout: 10000
      },
      compression: true,
      binaryProtocol: true
    };


    this.url = this.determineWebSocketUrl();


    this.updateFromSettings();


    let previousCustomBackendUrl = useSettingsStore.getState().settings?.system?.customBackendUrl;
    useSettingsStore.subscribe((state) => {
      const newCustomBackendUrl = state.settings?.system?.customBackendUrl;
      if (newCustomBackendUrl !== previousCustomBackendUrl) {
        if (debugState.isEnabled()) {
          logger.info(`customBackendUrl setting changed from "${previousCustomBackendUrl}" to "${newCustomBackendUrl}", re-evaluating WebSocket URL.`);
        }
        previousCustomBackendUrl = newCustomBackendUrl;
        this.updateFromSettings();
        if (this.isConnected || (this.socket && this.socket.readyState === WebSocket.CONNECTING)) {
          logger.info('Reconnecting WebSocket due to customBackendUrl change.');
          this.close();
          setTimeout(() => {
            this.connect().catch(error => {
              logger.error('Failed to reconnect WebSocket after URL change:', createErrorMetadata(error));
            });
          }, 100);
        }
      }
    });
  }

  private updateFromSettings(): void {
    const state = useSettingsStore.getState();
    const settings = state.settings;
    let newUrl = this.determineWebSocketUrl();

    if (settings?.system?.websocket) {
      this.reconnectInterval = settings?.system?.websocket?.reconnectDelay || 2000;
      this.maxReconnectAttempts = settings.system.websocket.reconnectAttempts || 10;
    }


    if (settings?.system?.customBackendUrl &&
        settings.system.customBackendUrl.trim() !== '') {
      const customUrl = settings.system.customBackendUrl.trim();
      const protocol = customUrl.startsWith('https://') ? 'wss://' : 'ws://';
      const hostAndPath = customUrl.replace(/^(https?:\/\/)?/, '');
      newUrl = `${protocol}${hostAndPath.replace(/\/$/, '')}/wss`;
      if (debugState.isEnabled()) {
        logger.info(`Using custom backend WebSocket URL: ${newUrl}`);
      }
    } else {
      if (debugState.isEnabled()) {
        logger.info(`Using default WebSocket URL: ${newUrl}`);
      }
    }
    this.url = newUrl;
  }

  public static getInstance(): WebSocketService {
    if (!WebSocketService.instance) {
      WebSocketService.instance = new WebSocketService();
    }
    return WebSocketService.instance;
  }

  private determineWebSocketUrl(): string {
    const isDev = import.meta.env.DEV;
    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const host = window.location.hostname;



    const port = isDev ? '3001' : window.location.port;


    const baseUrl = `${protocol}//${host}:${port}`;
    const wsUrl = `${baseUrl}/wss`;

    if (debugState.isEnabled()) {
      logger.info(`Determined WebSocket URL (${isDev ? 'dev' : 'prod'}): ${wsUrl}`);
    }

    return wsUrl;
  }


  public setCustomBackendUrl(backendUrl: string | null): void {
    if (!backendUrl) {

      this.url = this.determineWebSocketUrl();
      if (debugState.isEnabled()) {
        logger.info(`Reset to default WebSocket URL: ${this.url}`);
      }
      return;
    }


    const protocol = backendUrl.startsWith('https://') ? 'wss://' : 'ws://';

    const hostWithProtocol = backendUrl.replace(/^(https?:\/\/)?/, '');

    this.url = `${protocol}${hostWithProtocol}/wss`;

    if (debugState.isEnabled()) {
      logger.info(`Set custom WebSocket URL: ${this.url}`);
    }


    if (this.isConnected && this.socket) {
      if (debugState.isEnabled()) {
        logger.info('Reconnecting with new WebSocket URL');
      }
      this.close();
      this.connect().catch(error => {
        logger.error('Failed to reconnect with new URL:', createErrorMetadata(error));
      });
    }
  }

  public async connect(): Promise<void> {

    if (this.socket && (this.socket.readyState === WebSocket.CONNECTING || this.socket.readyState === WebSocket.OPEN)) {
      return;
    }

    try {
      if (debugState.isEnabled()) {
        logger.info(`Connecting to WebSocket at ${this.url}`);
      }

      // Get auth token if available
      const token = nostrAuth.getSessionToken();
      const wsUrl = token ? `${this.url}?token=${token}` : this.url;

      this.socket = new WebSocket(wsUrl);


      this.socket.onopen = this.handleOpen.bind(this);
      this.socket.onmessage = this.handleMessage.bind(this);
      this.socket.onclose = this.handleClose.bind(this);
      this.socket.onerror = this.handleError.bind(this);


      return new Promise<void>((resolve, reject) => {
        if (!this.socket) {
          reject(new Error('Socket initialization failed'));
          return;
        }


        this.socket.addEventListener('open', () => resolve(), { once: true });


        this.socket.addEventListener('error', (event) => {

          if (this.socket && this.socket.readyState !== WebSocket.OPEN) {
            reject(new Error('WebSocket connection failed'));
          }
        }, { once: true });
      });
    } catch (error) {
      logger.error('Error establishing WebSocket connection:', createErrorMetadata(error));
      throw error;
    }
  }

  private handleOpen(event: Event): void {
    this.isConnected = true;
    this.reconnectAttempts = 0;
    this.updateConnectionState('connected', undefined, new Date().getTime());

    if (debugState.isEnabled()) {
      logger.info('WebSocket connection established');
    }

    // Send authentication message if token is available
    const token = nostrAuth.getSessionToken();
    const user = nostrAuth.getCurrentUser();
    if (token && user) {
      this.sendMessage('authenticate', {
        token,
        pubkey: user.pubkey
      });
    }

    // Send initial filter settings
    const currentFilter = useSettingsStore.getState().settings?.nodeFilter;
    if (currentFilter) {
      this.sendMessage('filter_update', {
        enabled: currentFilter.enabled,
        quality_threshold: currentFilter.qualityThreshold,
        authority_threshold: currentFilter.authorityThreshold,
        filter_by_quality: currentFilter.filterByQuality,
        filter_by_authority: currentFilter.filterByAuthority,
        filter_mode: currentFilter.filterMode,
      });
      if (debugState.isEnabled()) {
        logger.info('Initial filter settings sent to server');
      }
    }

    this.initializeBatchQueue();

    // Set up filter subscription to sync UI changes to server
    this.setupFilterSubscription();

    this.notifyConnectionStatusHandlers(true);
    this.startHeartbeat();
    this.processMessageQueue();
  }

  private handleMessage(event: MessageEvent): void {

    if (event.data === 'pong') {
      this.handleHeartbeatResponse();
      return;
    }


    if (event.data instanceof Blob) {
      if (debugState.isDataDebugEnabled()) {
        logger.debug('Received binary blob data');
      }

      event.data.arrayBuffer().then(buffer => {
        if (this.validateBinaryData(buffer)) {
          this.processBinaryData(buffer);
        } else {
          logger.warn('Invalid binary data received, skipping processing');
        }
      }).catch(error => {
        logger.error('Error converting Blob to ArrayBuffer:', createErrorMetadata(error));
      });
      return;
    }

    if (event.data instanceof ArrayBuffer) {
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Received binary ArrayBuffer data: ${event.data.byteLength} bytes`);
      }
      if (this.validateBinaryData(event.data)) {
        this.processBinaryData(event.data);
      } else {
        logger.warn('Invalid binary data received, skipping processing');
      }
      return;
    }


    try {

      if (typeof event.data !== 'string' || event.data.trim() === '') {
        logger.warn('Received empty or invalid message data');
        return;
      }

      const message = JSON.parse(event.data) as WebSocketMessage;


      if (!this.validateMessage(message)) {
        logger.warn('Received malformed message, skipping processing');
        return;
      }

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Received WebSocket message: ${message.type}`, (message as any).data);
      }


      if (message.type === 'connection_established') {
        this.isServerReady = true;
        if (debugState.isEnabled()) {
          logger.info('Server connection established and ready');
        }
      }


      if (message.type === 'error' && (message as any).error) {
        this.handleErrorFrame((message as any).error as WebSocketErrorFrame);
        return;
      }

      // Handle filter confirmation from server
      if (message.type === 'filter_confirmed') {
        if (debugState.isEnabled()) {
          logger.info(`Filter applied: ${message.data?.visible_nodes}/${message.data?.total_nodes} nodes visible`);
        }
        this.emit('filterApplied', {
          visibleNodes: message.data?.visible_nodes,
          totalNodes: message.data?.total_nodes
        });
      }

      // Handle initialGraphLoad - this is sent when server provides new graph data (e.g., after filtering)
      if (message.type === 'initialGraphLoad') {
        const nodes = message.nodes || [];
        const edges = message.edges || [];
        logger.info(`[WebSocket] Received initialGraphLoad with ${nodes.length} nodes, ${edges.length} edges - updating graph`);

        // Transform server node format to client format
        const transformedNodes = nodes.map((node: any) => ({
          id: String(node.id),
          label: node.label || node.name || String(node.id),
          position: node.position || { x: node.x || 0, y: node.y || 0, z: node.z || 0 },
          metadata: {
            ...node.metadata,
            quality_score: node.quality_score ?? node.metadata?.quality_score,
            authority_score: node.authority_score ?? node.metadata?.authority_score,
          },
          color: node.color,
          size: node.size,
        }));

        const transformedEdges = edges.map((edge: any) => ({
          id: edge.id || `${edge.source}-${edge.target}`,
          source: String(edge.source),
          target: String(edge.target),
          weight: edge.weight,
          label: edge.label,
        }));

        // Update the graph data manager with the new filtered data
        graphDataManager.setGraphData({
          nodes: transformedNodes,
          edges: transformedEdges,
        }).then(() => {
          logger.info(`[WebSocket] Graph updated with ${transformedNodes.length} nodes from server filter`);
          this.emit('graphDataUpdated', {
            nodeCount: transformedNodes.length,
            edgeCount: transformedEdges.length,
            source: 'websocket_filter'
          });
        }).catch(error => {
          logger.error('[WebSocket] Failed to update graph data from initialGraphLoad:', createErrorMetadata(error));
        });
      }

      this.messageHandlers.forEach(handler => {
        try {
          handler(message as any);
        } catch (error) {
          logger.error('Error in message handler:', createErrorMetadata(error));
        }
      });
    } catch (error) {
      logger.error('Error parsing WebSocket message:', createErrorMetadata(error));
    }
  }


  private async processBinaryData(data: ArrayBuffer): Promise<void> {
    try {
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Processing binary data: ${data.byteLength} bytes`);
      }


      const header = binaryProtocol.parseHeader(data);
      if (!header) {
        logger.error('Failed to parse binary message header');
        return;
      }


      switch (header.type) {
        case MessageType.GRAPH_UPDATE:
          await this.handleGraphUpdate(data, header);
          break;

        case MessageType.VOICE_DATA:
          await this.handleVoiceData(data, header);
          break;

        case MessageType.POSITION_UPDATE:
        case MessageType.AGENT_POSITIONS:
          await this.handlePositionUpdate(data, header);
          break;

        default:

          await this.handleLegacyBinaryData(data);
          break;
      }


      this.binaryMessageHandlers.forEach(handler => {
        try {
          handler(data);
        } catch (error) {
          logger.error('Error in binary message handler:', createErrorMetadata(error));
        }
      });
    } catch (error) {
      logger.error('Error processing binary data:', createErrorMetadata(error));
    }
  }

  private async handleGraphUpdate(data: ArrayBuffer, header: any): Promise<void> {
    const graphTypeFlag = header.graphTypeFlag as GraphTypeFlag;
    const currentMode = useSettingsStore.getState().get<'knowledge_graph' | 'ontology'>('visualisation.graphs.mode') || 'knowledge_graph';


    const shouldProcess =
      (currentMode === 'knowledge_graph' && graphTypeFlag === GraphTypeFlag.KNOWLEDGE_GRAPH) ||
      (currentMode === 'ontology' && graphTypeFlag === GraphTypeFlag.ONTOLOGY);

    if (!shouldProcess) {
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Skipping graph update - mode mismatch: current=${currentMode}, flag=${graphTypeFlag}`);
      }
      return;
    }

    const payload = binaryProtocol.extractPayload(data, header);


    this.emit('graph-update', {
      graphType: graphTypeFlag === GraphTypeFlag.ONTOLOGY ? 'ontology' : 'knowledge_graph',
      data: payload
    });

    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Processed graph update: mode=${currentMode}, size=${payload.byteLength}`);
    }
  }

  private async handleVoiceData(data: ArrayBuffer, header: any): Promise<void> {
    const payload = binaryProtocol.extractPayload(data, header);


    this.emit('voice-data', payload);

    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Processed voice data: size=${payload.byteLength}`);
    }
  }

  private async handlePositionUpdate(data: ArrayBuffer, header: any): Promise<void> {
    const payload = binaryProtocol.extractPayload(data, header);

    // Estimate node count from payload (48 bytes per node in Protocol V3)
    const estimatedNodeCount = Math.floor(payload.byteLength / 48);

    const hasBotsData = this.detectBotsData(payload);

    if (hasBotsData) {

      this.emit('bots-position-update', payload);
      if (debugState.isDataDebugEnabled()) {
        logger.debug('Emitted bots-position-update event');
      }
    }


    const graphType = graphDataManager.getGraphType();


    this.binaryMessageCount = (this.binaryMessageCount || 0) + 1;
    if (this.binaryMessageCount % 100 === 1) {
      logger.debug('Position update received', { graphType, dataSize: payload.byteLength, msgCount: this.binaryMessageCount });
    }

    if (graphType === 'logseq') {
      try {
        await graphDataManager.updateNodePositions(payload);
        if (this.binaryMessageCount % 100 === 1) {
          logger.debug('Node positions updated successfully');
        }
      } catch (error) {
        console.error('[WebSocketService] Error updating positions:', error);
        logger.error('Error processing position data in graphDataManager:', createErrorMetadata(error));
      }
    } else if (this.binaryMessageCount % 100 === 1) {
      logger.debug('Skipping position update - graph type is', { graphType });
      if (debugState.isDataDebugEnabled()) {
        logger.debug('Skipping position data processing - not a Logseq graph');
      }
    }

    // Send backpressure ACK to server after processing position update
    // Batched to reduce ACK traffic (every ackBatchSize updates)
    this.positionUpdateSequence++;
    if (this.positionUpdateSequence - this.lastAckSentSequence >= this.ackBatchSize) {
      this.sendPositionAck(this.positionUpdateSequence, estimatedNodeCount);
      this.lastAckSentSequence = this.positionUpdateSequence;
    }
  }

  /**
   * Send backpressure acknowledgement to server after processing position updates
   * This enables true end-to-end flow control vs queue-only confirmation
   */
  private sendPositionAck(sequenceId: number, nodesReceived: number): void {
    if (!this.socket || this.socket.readyState !== WebSocket.OPEN) {
      return;
    }

    try {
      const ackMessage = binaryProtocol.createBroadcastAck(sequenceId, nodesReceived);
      this.socket.send(ackMessage);

      if (debugState.isDataDebugEnabled() && sequenceId % 100 === 0) {
        logger.debug(`Sent BroadcastAck: seq=${sequenceId}, nodes=${nodesReceived}`);
      }
    } catch (error) {
      logger.error('Error sending position ACK:', createErrorMetadata(error));
    }
  }

  private async handleLegacyBinaryData(data: ArrayBuffer): Promise<void> {
    // Estimate node count from data (28 bytes per node in legacy format)
    const estimatedNodeCount = Math.floor(data.byteLength / 28);

    const hasBotsData = this.detectBotsData(data);

    if (hasBotsData) {
      this.emit('bots-position-update', data);
      if (debugState.isDataDebugEnabled()) {
        logger.debug('Emitted bots-position-update event (legacy)');
      }
    }

    const graphType = graphDataManager.getGraphType();
    this.binaryMessageCount = (this.binaryMessageCount || 0) + 1;

    if (this.binaryMessageCount % 100 === 1) {
      logger.debug('Legacy binary data received', { graphType, dataSize: data.byteLength, msgCount: this.binaryMessageCount });
    }

    if (graphType === 'logseq') {
      try {
        await graphDataManager.updateNodePositions(data);
        if (this.binaryMessageCount % 100 === 1) {
          logger.debug('Node positions updated successfully (legacy)');
        }
      } catch (error) {
        logger.error('Error processing legacy binary data:', createErrorMetadata(error));
      }
    }

    // Send backpressure ACK to server after processing (same as handlePositionUpdate)
    this.positionUpdateSequence++;
    if (this.positionUpdateSequence - this.lastAckSentSequence >= this.ackBatchSize) {
      this.sendPositionAck(this.positionUpdateSequence, estimatedNodeCount);
      this.lastAckSentSequence = this.positionUpdateSequence;
    }
  }

  private detectBotsData(data: ArrayBuffer): boolean {
    try {

      const allNodes = parseBinaryNodeData(data);
      return allNodes.some(node => isAgentNode(node.nodeId));
    } catch (error) {
      logger.error('Error detecting bots data:', createErrorMetadata(error));
      return false;
    }
  }

  private handleClose(event: CloseEvent): void {
    this.isConnected = false;
    this.isServerReady = false;
    this.stopHeartbeat();

    if (debugState.isEnabled()) {
      logger.info(`WebSocket connection closed: ${event.code} ${event.reason}`);
    }

    this.notifyConnectionStatusHandlers(false);


    const isNormalClosure = event.code === 1000 || event.code === 1001;
    const wasCleanShutdown = event.wasClean;

    if (!isNormalClosure || !wasCleanShutdown) {
      this.updateConnectionState('reconnecting', event.reason);
      this.attemptReconnect();
    } else {
      this.updateConnectionState('disconnected');
    }
  }

  private handleError(event: Event): void {
    const errorMessage = event instanceof ErrorEvent ? event.message : 'Unknown WebSocket error';
    logger.error('WebSocket error:', { event, message: errorMessage });
    this.updateConnectionState('failed', errorMessage);

  }

  private attemptReconnect(): void {

    if (this.reconnectTimeout) {
      window.clearTimeout(this.reconnectTimeout);
      this.reconnectTimeout = null;
    }

    if (this.reconnectAttempts < this.maxReconnectAttempts) {
      this.reconnectAttempts++;


      const baseDelay = 1000;
      const exponentialDelay = baseDelay * Math.pow(2, this.reconnectAttempts - 1);
      const delay = Math.min(exponentialDelay, this.maxReconnectDelay);

      this.updateConnectionState('reconnecting', `Reconnecting in ${delay}ms`);

      if (debugState.isEnabled()) {
        logger.info(`Attempting to reconnect in ${delay}ms (attempt ${this.reconnectAttempts}/${this.maxReconnectAttempts})`);
      }

      this.reconnectTimeout = window.setTimeout(() => {
        this.connect().catch(error => {
          logger.error('Reconnect attempt failed:', createErrorMetadata(error));

          this.attemptReconnect();
        });
      }, delay);
    } else {
      logger.error(`Maximum reconnect attempts (${this.maxReconnectAttempts}) reached. Giving up.`);
      this.updateConnectionState('failed', 'Maximum reconnect attempts reached');
    }
  }

  public sendMessage(type: string, data?: any): void {
    const message = { type, data } as any;
    const messageStr = JSON.stringify(message);

    if (!this.isConnected || !this.socket) {

      this.queueMessage('text', messageStr);
      logger.warn(`Message queued: ${type} (WebSocket not connected)`);
      return;
    }

    try {
      this.socket.send(messageStr);

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Sent message: ${type}`);
      }
    } catch (error) {
      logger.error('Error sending WebSocket message:', createErrorMetadata(error));

      this.queueMessage('text', messageStr);
    }
  }

  public sendRawBinaryData(data: ArrayBuffer): void {
    if (!this.isConnected || !this.socket) {

      this.queueMessage('binary', data);
      logger.warn(`Binary data queued: ${data.byteLength} bytes (WebSocket not connected)`);
      return;
    }

    try {
      this.socket.send(data);

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Sent binary data: ${data.byteLength} bytes`);
      }
    } catch (error) {
      logger.error('Error sending binary data:', createErrorMetadata(error));

      this.queueMessage('binary', data);
    }
  }

  /**
   * Send filter settings update to server
   * Called when user changes filter settings in the UI
   */
  public sendFilterUpdate(filter: {
    enabled?: boolean;
    qualityThreshold?: number;
    authorityThreshold?: number;
    filterByQuality?: boolean;
    filterByAuthority?: boolean;
    filterMode?: string;
  }): void {
    if (!this.isConnected) {
      logger.warn('Cannot send filter update: WebSocket not connected');
      return;
    }

    this.sendMessage('filter_update', {
      enabled: filter.enabled,
      quality_threshold: filter.qualityThreshold,
      authority_threshold: filter.authorityThreshold,
      filter_by_quality: filter.filterByQuality,
      filter_by_authority: filter.filterByAuthority,
      filter_mode: filter.filterMode,
    });

    logger.info('Filter update sent to server', filter);
  }

  /**
   * Subscribe to settings store filter changes and sync to server
   */
  private filterSubscriptionSet = false;
  private lastFilterState: any = null;

  public setupFilterSubscription(): void {
    if (this.filterSubscriptionSet) return;
    this.filterSubscriptionSet = true;

    // Use the store's custom subscribe method for specific nodeFilter paths
    const filterPaths = [
      'nodeFilter.enabled',
      'nodeFilter.qualityThreshold',
      'nodeFilter.authorityThreshold',
      'nodeFilter.filterByQuality',
      'nodeFilter.filterByAuthority',
      'nodeFilter.filterMode',
    ] as const;

    // Subscribe to each filter path
    filterPaths.forEach(path => {
      useSettingsStore.getState().subscribe(path as any, () => {
        this.handleFilterChange();
      });
    });

    // Also use zustand's basic subscribe as a fallback
    useSettingsStore.subscribe((state) => {
      const nodeFilter = state.settings?.nodeFilter;
      if (nodeFilter && this.isConnected) {
        const current = JSON.stringify(nodeFilter);
        if (current !== this.lastFilterState) {
          this.lastFilterState = current;
          this.sendFilterUpdate({
            enabled: nodeFilter.enabled,
            qualityThreshold: nodeFilter.qualityThreshold,
            authorityThreshold: nodeFilter.authorityThreshold,
            filterByQuality: nodeFilter.filterByQuality,
            filterByAuthority: nodeFilter.filterByAuthority,
            filterMode: nodeFilter.filterMode,
          });
        }
      }
    });

    logger.info('Filter subscription set up - changes will sync to server');
  }

  private handleFilterChange(): void {
    if (!this.isConnected) return;

    const nodeFilter = useSettingsStore.getState().settings?.nodeFilter;
    if (nodeFilter) {
      this.sendFilterUpdate({
        enabled: nodeFilter.enabled,
        qualityThreshold: nodeFilter.qualityThreshold,
        authorityThreshold: nodeFilter.authorityThreshold,
        filterByQuality: nodeFilter.filterByQuality,
        filterByAuthority: nodeFilter.filterByAuthority,
        filterMode: nodeFilter.filterMode,
      });
    }
  }

  /**
   * Force refresh filter - clears local graph, then requests fresh filtered data from server
   * Called by the "Refresh Graph" button to force a complete graph reload with current filter
   */
  public async forceRefreshFilter(): Promise<void> {
    if (!this.isConnected) {
      logger.warn('Cannot force refresh filter: WebSocket not connected');
      return;
    }

    const nodeFilter = useSettingsStore.getState().settings?.nodeFilter;
    if (nodeFilter) {
      // Reset last filter state to force sending even if values haven't changed
      this.lastFilterState = null;

      logger.info('[Refresh] Clearing local graph and requesting fresh filtered data', nodeFilter);

      // Step 1: Clear the local graph completely - don't try to fill gaps
      await graphDataManager.setGraphData({ nodes: [], edges: [] });
      logger.info('[Refresh] Local graph cleared, awaiting server response...');

      // Step 2: Send filter update to server - server will respond with filtered initialGraphLoad
      this.sendFilterUpdate({
        enabled: nodeFilter.enabled,
        qualityThreshold: nodeFilter.qualityThreshold,
        authorityThreshold: nodeFilter.authorityThreshold,
        filterByQuality: nodeFilter.filterByQuality,
        filterByAuthority: nodeFilter.filterByAuthority,
        filterMode: nodeFilter.filterMode,
      });

      // The server will respond with initialGraphLoad containing the filtered, metadata-rich sparse dataset
      // The initialGraphLoad handler will populate the graph - no gap filling
    } else {
      logger.warn('No nodeFilter settings found in store');
    }
  }


  private initializeBatchQueue(): void {
    if (this.positionBatchQueue) {
      this.positionBatchQueue.destroy();
    }


    const validationMiddleware = createValidationMiddleware({
      maxNodes: 10000,
      maxCoordinate: 10000,
      minCoordinate: -10000,
      maxVelocity: 1000
    });


    const batchProcessor = createWebSocketBatchProcessor((data: ArrayBuffer) => {
      if (!this.isConnected || !this.socket) {
        logger.warn('Cannot send batch: WebSocket not connected');
        return;
      }

      try {
        this.socket.send(data);

        if (debugState.isDataDebugEnabled()) {
          logger.debug(`Sent binary batch: ${data.byteLength} bytes`);
        }
      } catch (error) {
        logger.error('Error sending batch:', createErrorMetadata(error));
        throw error;
      }
    });


    this.positionBatchQueue = new NodePositionBatchQueue({
      processBatch: async (batch: BinaryNodeData[]) => {

        const validatedBatch = validationMiddleware(batch);

        if (validatedBatch.length === 0) {
          logger.warn('All nodes in batch failed validation');
          return;
        }

        await batchProcessor.processBatch(validatedBatch);
      },
      onError: batchProcessor.onError,
      onSuccess: batchProcessor.onSuccess
    });

    logger.info('Position batch queue initialized');
  }


  public sendNodePositionUpdates(updates: Array<{nodeId: number, position: {x: number, y: number, z: number}, velocity?: {x: number, y: number, z: number}}>): void {
    if (!this.positionBatchQueue) {
      logger.warn('Position batch queue not initialized');
      return;
    }

    try {

      const binaryNodes: BinaryNodeData[] = updates.map(update => ({
        nodeId: update.nodeId,
        position: update.position,
        velocity: update.velocity || {x: 0, y: 0, z: 0},
        ssspDistance: 0,
        ssspParent: -1
      }));


      const validation = validateNodePositions(binaryNodes, {
        maxNodes: updates.length + 100
      });

      if (!validation.valid) {
        logger.error('Position updates failed validation:', validation.errors);
        return;
      }


      binaryNodes.forEach(node => {
        const priority = isAgentNode(node.nodeId) ? 10 : 0;
        this.positionBatchQueue!.enqueuePositionUpdate(node, priority);
      });

      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Queued ${updates.length} position updates for batching`);
      }
    } catch (error) {
      logger.error('Error queuing position updates:', createErrorMetadata(error));
    }
  }


  public flushPositionUpdates(): Promise<void> {
    if (this.positionBatchQueue) {
      return this.positionBatchQueue.flush();
    }
    return Promise.resolve();
  }


  public getPositionQueueMetrics() {
    if (this.positionBatchQueue) {
      return this.positionBatchQueue.getMetrics();
    }
    return null;
  }

  public onMessage(handler: MessageHandler): () => void {
    this.messageHandlers.push(handler as any);
    return () => {
      this.messageHandlers = this.messageHandlers.filter(h => h !== handler);
    };
  }

  public onBinaryMessage(handler: BinaryMessageHandler): () => void {
    this.binaryMessageHandlers.push(handler);
    return () => {
      this.binaryMessageHandlers = this.binaryMessageHandlers.filter(h => h !== handler);
    };
  }

  public onConnectionStatusChange(handler: ConnectionStatusHandler): () => void {
    this.connectionStatusHandlers.push(handler);

    handler(this.isConnected);
    return () => {
      this.connectionStatusHandlers = this.connectionStatusHandlers.filter(h => h !== handler);
    };
  }

  public onConnectionStateChange(handler: ConnectionStateHandler): () => void {
    this.connectionStateHandlers.push(handler);

    handler(this.connectionState);
    return () => {
      this.connectionStateHandlers = this.connectionStateHandlers.filter(h => h !== handler);
    };
  }

  private notifyConnectionStatusHandlers(connected: boolean): void {
    this.connectionStatusHandlers.forEach(handler => {
      try {
        handler(connected);
      } catch (error) {
        logger.error('Error in connection status handler:', createErrorMetadata(error));
      }
    });
  }

  private notifyConnectionStateHandlers(): void {
    this.connectionStateHandlers.forEach(handler => {
      try {
        handler(this.connectionState);
      } catch (error) {
        logger.error('Error in connection state handler:', createErrorMetadata(error));
      }
    });
  }

  private updateConnectionState(
    status: ConnectionState['status'],
    lastError?: string,
    lastConnected?: number
  ): void {
    this.connectionState = {
      ...this.connectionState,
      status,
      lastError,
      lastConnected,
      reconnectAttempts: this.reconnectAttempts
    };
    this.notifyConnectionStateHandlers();
  }

  public isReady(): boolean {
    return this.isConnected && this.isServerReady;
  }

  public getConnectionState(): ConnectionState {
    return { ...this.connectionState };
  }

  public getQueuedMessageCount(): number {
    return this.messageQueue.length;
  }

  public emit(eventName: string, data: any): void {
    const handlers = this.eventHandlers.get(eventName);
    if (handlers) {
      handlers.forEach(handler => {
        try {
          handler(data);
        } catch (error) {
          logger.error(`Error in event handler for ${eventName}:`, createErrorMetadata(error));
        }
      });
    }
  }

  public on(eventName: string, handler: EventHandler): () => void {
    if (!this.eventHandlers.has(eventName)) {
      this.eventHandlers.set(eventName, []);
    }
    this.eventHandlers.get(eventName)!.push(handler);

    return () => {
      const handlers = this.eventHandlers.get(eventName);
      if (handlers) {
        const index = handlers.indexOf(handler);
        if (index > -1) {
          handlers.splice(index, 1);
        }
      }
    };
  }

  public close(): void {
    if (this.socket) {

      if (this.reconnectTimeout) {
        window.clearTimeout(this.reconnectTimeout);
        this.reconnectTimeout = null;
      }

      this.stopHeartbeat();


      if (this.positionBatchQueue) {
        this.positionBatchQueue.destroy();
        this.positionBatchQueue = null;
      }

      try {

        this.socket.close(1000, 'Normal closure');
        if (debugState.isEnabled()) {
          logger.info('WebSocket connection closed by client');
        }
      } catch (error) {
        logger.error('Error closing WebSocket:', createErrorMetadata(error));
      } finally {
        this.socket = null;
        this.isConnected = false;
        this.isServerReady = false;
        this.reconnectAttempts = 0;
        this.messageQueue = [];
        this.updateConnectionState('disconnected');
        this.notifyConnectionStatusHandlers(false);
      }
    }
  }


  public disconnect(): void {
    this.close();
    this.disconnectSolid();
  }


  private validateMessage(message: any): message is WebSocketMessage {
    return (
      message &&
      typeof message === 'object' &&
      typeof message.type === 'string' &&
      message.type.length > 0 &&
      message.type.length <= 100
    );
  }

  private validateBinaryData(data: ArrayBuffer): boolean {
    try {

      if (!data || data.byteLength === 0) {
        return false;
      }


      if (data.byteLength > 50 * 1024 * 1024) {
        logger.warn(`Binary data too large: ${data.byteLength} bytes`);
        return false;
      }


      try {
        parseBinaryNodeData(data);
        return true;
      } catch (error) {

        logger.warn('Binary data parsing validation failed, but allowing through:', createErrorMetadata(error));
        return true;
      }
    } catch (error) {
      logger.error('Error validating binary data:', createErrorMetadata(error));
      return false;
    }
  }


  private queueMessage(type: 'text' | 'binary', data: string | ArrayBuffer): void {

    if (this.messageQueue.length >= this.maxQueueSize) {

      const removed = this.messageQueue.shift();
      logger.warn('Message queue full, removed oldest message');
    }

    const queuedMessage: QueuedMessage = {
      type,
      data,
      timestamp: Date.now(),
      retries: 0
    };

    this.messageQueue.push(queuedMessage);
  }

  private async processMessageQueue(): Promise<void> {
    if (!this.isConnected || !this.socket || this.messageQueue.length === 0) {
      return;
    }

    const messagesToProcess = [...this.messageQueue];
    this.messageQueue = [];

    for (const queuedMessage of messagesToProcess) {
      try {
        if (queuedMessage.type === 'text') {
          this.socket.send(queuedMessage.data as string);
        } else {
          this.socket.send(queuedMessage.data as ArrayBuffer);
        }

        if (debugState.isDataDebugEnabled()) {
          logger.debug(`Processed queued ${queuedMessage.type} message`);
        }
      } catch (error) {

        queuedMessage.retries++;
        if (queuedMessage.retries < 3) {
          this.messageQueue.push(queuedMessage);
          logger.warn(`Failed to send queued message, retry ${queuedMessage.retries}/3`);
        } else {
          logger.error('Failed to send queued message after 3 retries, dropping:', createErrorMetadata(error));
        }
      }
    }
  }


  private startHeartbeat(): void {
    this.stopHeartbeat();

    this.heartbeatInterval = window.setInterval(() => {
      this.sendHeartbeat();
    }, this.heartbeatIntervalMs);
  }

  private stopHeartbeat(): void {
    if (this.heartbeatInterval) {
      window.clearInterval(this.heartbeatInterval);
      this.heartbeatInterval = null;
    }
    if (this.heartbeatTimeout) {
      window.clearTimeout(this.heartbeatTimeout);
      this.heartbeatTimeout = null;
    }
  }

  private sendHeartbeat(): void {
    if (!this.isConnected || !this.socket) {
      return;
    }

    try {
      this.socket.send('ping');


      this.heartbeatTimeout = window.setTimeout(() => {
        logger.warn('Heartbeat timeout - server not responding');
        this.handleHeartbeatTimeout();
      }, this.heartbeatTimeoutMs);

      if (debugState.isDataDebugEnabled()) {
        logger.debug('Sent heartbeat ping');
      }
    } catch (error) {
      logger.error('Error sending heartbeat:', createErrorMetadata(error));
      this.handleHeartbeatTimeout();
    }
  }

  private handleHeartbeatResponse(): void {
    if (this.heartbeatTimeout) {
      window.clearTimeout(this.heartbeatTimeout);
      this.heartbeatTimeout = null;
    }

    if (debugState.isDataDebugEnabled()) {
      logger.debug('Received heartbeat pong');
    }
  }

  private handleHeartbeatTimeout(): void {
    logger.warn('Heartbeat timeout detected, connection may be dead');


    if (this.socket) {
      this.socket.close(4000, 'Heartbeat timeout');
    }
  }


  public forceReconnect(): void {
    logger.info('Forcing WebSocket reconnection');
    if (this.socket) {
      this.socket.close(4001, 'Forced reconnection');
    }

  }


  public clearMessageQueue(): void {
    const queueSize = this.messageQueue.length;
    this.messageQueue = [];
    if (queueSize > 0) {
      logger.info(`Cleared ${queueSize} messages from queue`);
    }
  }


  private handleErrorFrame(error: WebSocketErrorFrame): void {
    logger.error('Received error frame from server:', error);


    this.emit('error-frame', error);


    switch (error.category) {
      case 'validation':

        if (error.affectedPaths && error.affectedPaths.length > 0) {
          this.emit('validation-error', {
            paths: error.affectedPaths,
            message: error.message
          });
        }
        break;

      case 'rate_limit':

        if (error.retryAfter) {
          logger.warn(`Rate limited. Retry after ${error.retryAfter}ms`);
          this.emit('rate-limit', {
            retryAfter: error.retryAfter,
            message: error.message
          });
        }
        break;

      case 'auth':

        this.emit('auth-error', {
          code: error.code,
          message: error.message
        });
        break;

      case 'server':

        if (error.retryable && error.retryAfter) {
          setTimeout(() => {
            this.processMessageQueue();
          }, error.retryAfter);
        }
        break;

      case 'protocol':

        logger.error('Protocol error - considering reconnection');
        if (error.code === 'PROTOCOL_VERSION_MISMATCH') {
          this.forceReconnect();
        }
        break;
    }
  }


  public sendErrorFrame(error: Partial<WebSocketErrorFrame>): void {
    const errorFrame: WebSocketErrorFrame = {
      code: error.code || 'CLIENT_ERROR',
      message: error.message || 'Unknown client error',
      category: error.category || 'protocol',
      retryable: error.retryable ?? false,
      timestamp: Date.now(),
      ...error
    };

    this.sendMessage('error', { error: errorFrame });
  }

  // ============================================
  // JSS/Solid WebSocket Notifications (solid-0.1)
  // ============================================

  /**
   * Get the JSS WebSocket URL from environment
   */
  private getSolidWebSocketUrl(): string | null {
    return import.meta.env.VITE_JSS_WS_URL || null;
  }

  /**
   * Connect to JSS WebSocket for real-time Solid notifications
   * Uses solid-0.1 protocol for resource change notifications
   */
  public connectSolid(): void {
    const wsUrl = this.getSolidWebSocketUrl();

    if (!wsUrl) {
      logger.warn('JSS WebSocket URL not configured (VITE_JSS_WS_URL)');
      return;
    }

    if (this.solidSocket?.readyState === WebSocket.OPEN) {
      logger.debug('Solid WebSocket already connected');
      return;
    }

    try {
      logger.info(`Connecting to JSS WebSocket at ${wsUrl}`);
      this.solidSocket = new WebSocket(wsUrl);

      this.solidSocket.onopen = () => {
        logger.info('JSS WebSocket connected');
        this.isSolidConnected = true;
        this.solidReconnectAttempts = 0;

        // Emit connection event
        this.emit('solid-connected', { url: wsUrl });
      };

      this.solidSocket.onmessage = (event) => {
        const msg = event.data.toString().trim();
        this.handleSolidMessage(msg);
      };

      this.solidSocket.onerror = (error) => {
        logger.error('JSS WebSocket error', { error });
        this.emit('solid-error', { error });
      };

      this.solidSocket.onclose = (event) => {
        logger.info('JSS WebSocket disconnected', { code: event.code, reason: event.reason });
        this.isSolidConnected = false;
        this.emit('solid-disconnected', { code: event.code, reason: event.reason });
        this.attemptSolidReconnect();
      };
    } catch (error) {
      logger.error('Failed to connect Solid WebSocket', { error });
    }
  }

  /**
   * Handle incoming solid-0.1 protocol messages
   */
  private handleSolidMessage(msg: string): void {
    if (msg.startsWith('protocol ')) {
      // Protocol handshake complete (e.g., "protocol solid-0.1")
      const protocol = msg.slice(9);
      logger.debug('Solid WebSocket protocol handshake complete', { protocol });

      // Resubscribe to all tracked resources
      for (const url of this.solidSubscriptions.keys()) {
        this.solidSocket?.send(`sub ${url}`);
        logger.debug('Resubscribed to Solid resource', { url });
      }

      this.emit('solid-protocol', { protocol });
    } else if (msg.startsWith('ack ')) {
      // Subscription acknowledged
      const url = msg.slice(4);
      logger.debug('Solid subscription acknowledged', { url });
      this.notifySolidSubscribers(url, { type: 'ack', url });
    } else if (msg.startsWith('pub ')) {
      // Resource changed notification
      const url = msg.slice(4);
      logger.debug('Solid resource changed', { url });
      this.notifySolidSubscribers(url, { type: 'pub', url });

      // Also emit as general event for components to listen
      this.emit('solid-resource-changed', { url });
    } else if (msg.startsWith('error ')) {
      // Error from server
      const errorMsg = msg.slice(6);
      logger.error('Solid WebSocket error message', { error: errorMsg });
      this.emit('solid-error', { message: errorMsg });
    }
  }

  /**
   * Notify all subscribers for a given resource URL
   */
  private notifySolidSubscribers(url: string, notification: SolidNotification): void {
    // Notify exact URL subscribers
    const callbacks = this.solidSubscriptions.get(url);
    callbacks?.forEach((cb) => {
      try {
        cb(notification);
      } catch (error) {
        logger.error('Error in Solid notification callback', { url, error });
      }
    });

    // Also notify container subscribers (parent directory)
    const containerUrl = url.substring(0, url.lastIndexOf('/') + 1);
    if (containerUrl !== url) {
      const containerCallbacks = this.solidSubscriptions.get(containerUrl);
      containerCallbacks?.forEach((cb) => {
        try {
          cb(notification);
        } catch (error) {
          logger.error('Error in Solid container notification callback', { containerUrl, error });
        }
      });
    }
  }

  /**
   * Attempt to reconnect Solid WebSocket with exponential backoff
   */
  private attemptSolidReconnect(): void {
    if (this.solidReconnectTimeout) {
      window.clearTimeout(this.solidReconnectTimeout);
      this.solidReconnectTimeout = null;
    }

    if (this.solidReconnectAttempts >= this.solidMaxReconnectAttempts) {
      logger.warn('Max Solid WebSocket reconnect attempts reached');
      return;
    }

    this.solidReconnectAttempts++;
    const delay = this.solidReconnectDelay * Math.pow(2, this.solidReconnectAttempts - 1);

    logger.info(`Solid WebSocket reconnecting in ${delay}ms (attempt ${this.solidReconnectAttempts})`);

    this.solidReconnectTimeout = window.setTimeout(() => {
      this.connectSolid();
    }, delay);
  }

  /**
   * Subscribe to notifications for a Solid resource
   * @param resourceUrl The URL of the resource to subscribe to
   * @param callback Callback function called when resource changes
   * @returns Unsubscribe function
   */
  public subscribeSolidResource(resourceUrl: string, callback: SolidNotificationCallback): () => void {
    if (!this.solidSubscriptions.has(resourceUrl)) {
      this.solidSubscriptions.set(resourceUrl, new Set());

      // Send subscription if already connected
      if (this.solidSocket?.readyState === WebSocket.OPEN) {
        this.solidSocket.send(`sub ${resourceUrl}`);
        logger.debug('Subscribed to Solid resource', { url: resourceUrl });
      }
    }

    this.solidSubscriptions.get(resourceUrl)!.add(callback);

    // Return unsubscribe function
    return () => {
      this.unsubscribeSolidResourceCallback(resourceUrl, callback);
    };
  }

  /**
   * Unsubscribe a specific callback from a Solid resource
   */
  private unsubscribeSolidResourceCallback(resourceUrl: string, callback: SolidNotificationCallback): void {
    const callbacks = this.solidSubscriptions.get(resourceUrl);
    if (callbacks) {
      callbacks.delete(callback);

      // If no more callbacks for this URL, unsubscribe from server
      if (callbacks.size === 0) {
        if (this.solidSocket?.readyState === WebSocket.OPEN) {
          this.solidSocket.send(`unsub ${resourceUrl}`);
          logger.debug('Unsubscribed from Solid resource', { url: resourceUrl });
        }
        this.solidSubscriptions.delete(resourceUrl);
      }
    }
  }

  /**
   * Unsubscribe from all callbacks for a Solid resource
   */
  public unsubscribeSolidResource(resourceUrl: string): void {
    if (this.solidSubscriptions.has(resourceUrl)) {
      if (this.solidSocket?.readyState === WebSocket.OPEN) {
        this.solidSocket.send(`unsub ${resourceUrl}`);
        logger.debug('Unsubscribed from Solid resource (all callbacks)', { url: resourceUrl });
      }
      this.solidSubscriptions.delete(resourceUrl);
    }
  }

  /**
   * Disconnect Solid WebSocket and clear subscriptions
   */
  public disconnectSolid(): void {
    if (this.solidReconnectTimeout) {
      window.clearTimeout(this.solidReconnectTimeout);
      this.solidReconnectTimeout = null;
    }

    if (this.solidSocket) {
      try {
        this.solidSocket.close(1000, 'Normal closure');
        logger.info('Solid WebSocket disconnected by client');
      } catch (error) {
        logger.error('Error closing Solid WebSocket:', createErrorMetadata(error));
      }
      this.solidSocket = null;
    }

    this.solidSubscriptions.clear();
    this.isSolidConnected = false;
    this.solidReconnectAttempts = 0;
  }

  /**
   * Check if Solid WebSocket is connected
   */
  public isSolidWebSocketConnected(): boolean {
    return this.isSolidConnected && this.solidSocket?.readyState === WebSocket.OPEN;
  }

  /**
   * Get list of currently subscribed Solid resources
   */
  public getSolidSubscriptions(): string[] {
    return Array.from(this.solidSubscriptions.keys());
  }
}

// Create and export singleton instance
export const webSocketService = WebSocketService.getInstance();

export default WebSocketService;

--------------------------------------------------------------------------------
FILE: client/src/services/BinaryWebSocketProtocol.ts
PURPOSE: Binary message protocol implementation
--------------------------------------------------------------------------------


import { createLogger } from '../utils/loggerConfig';
import type { Vec3 } from '../types/binaryProtocol';

const logger = createLogger('BinaryWebSocketProtocol');

// Protocol versions (V1 removed - no backward compatibility)
export const PROTOCOL_V2 = 2;  // Supported
export const PROTOCOL_V3 = 3;  // CURRENT: Analytics extension (48 bytes/node)
export const PROTOCOL_VERSION = PROTOCOL_V3;  // Default to V3
export const SUPPORTED_PROTOCOLS = [PROTOCOL_V2, PROTOCOL_V3];  

// Message types (1 byte header)
export enum MessageType {

  GRAPH_UPDATE = 0x01,


  VOICE_DATA = 0x02,


  POSITION_UPDATE = 0x10,
  AGENT_POSITIONS = 0x11,
  VELOCITY_UPDATE = 0x12,


  AGENT_STATE_FULL = 0x20,
  AGENT_STATE_DELTA = 0x21,
  AGENT_HEALTH = 0x22,


  CONTROL_BITS = 0x30,
  SSSP_DATA = 0x31,
  HANDSHAKE = 0x32,
  HEARTBEAT = 0x33,


  VOICE_CHUNK = 0x40,
  VOICE_START = 0x41,
  VOICE_END = 0x42,

  // Backpressure flow control (Phase 7)
  BROADCAST_ACK = 0x34,      // Client acknowledgement of position broadcast

  // Multi-user sync messages (Phase 6)
  SYNC_UPDATE = 0x50,        // Graph operation sync
  ANNOTATION_UPDATE = 0x51,  // Annotation sync
  SELECTION_UPDATE = 0x52,   // Selection sync
  USER_POSITION = 0x53,      // User cursor/avatar position
  VR_PRESENCE = 0x54,        // VR head + hand tracking


  ERROR = 0xFF
}

// Graph type flags for GRAPH_UPDATE messages
// Values must match server: src/utils/binary_protocol.rs GraphType enum
export enum GraphTypeFlag {
  KNOWLEDGE_GRAPH = 0x00,
  ONTOLOGY = 0x01
}

// Agent state flags (bit field)
export enum AgentStateFlags {
  ACTIVE = 1 << 0,           
  IDLE = 1 << 1,             
  ERROR = 1 << 2,            
  VOICE_ACTIVE = 1 << 3,     
  HIGH_PRIORITY = 1 << 4,    
  POSITION_CHANGED = 1 << 5,  
  METADATA_CHANGED = 1 << 6,  
  RESERVED = 1 << 7          
}

// Control bit flags
export enum ControlFlags {
  PAUSE_UPDATES = 1 << 0,    
  HIGH_FREQUENCY = 1 << 1,   
  LOW_BANDWIDTH = 1 << 2,    
  VOICE_ENABLED = 1 << 3,    
  DEBUG_MODE = 1 << 4,       
  FORCE_FULL_UPDATE = 1 << 5, 
  USER_INTERACTING = 1 << 6,  
  BACKGROUND_MODE = 1 << 7    
}

// Binary data structures


export interface AgentPositionUpdate {
  agentId: number;      
  position: Vec3;       
  timestamp: number;    
  flags: number;        
}


export interface AgentStateData {
  agentId: number;       
  position: Vec3;        
  velocity: Vec3;        
  health: number;        
  cpuUsage: number;      
  memoryUsage: number;   
  workload: number;      
  tokens: number;        
  flags: number;         
}


export interface SSSPData {
  nodeId: number;        
  distance: number;      
  parentId: number;      
  flags: number;         
}


export interface VoiceChunk {
  agentId: number;       
  chunkId: number;       
  format: number;        
  dataLength: number;    
  audioData: ArrayBuffer; 
}


export interface MessageHeader {
  type: MessageType;
  version: number;
  payloadLength: number;
  graphTypeFlag?: GraphTypeFlag;
}

// Broadcast ACK data for backpressure flow control
export interface BroadcastAckData {
  sequenceId: number;     // 8 bytes - correlates with server broadcast sequence
  nodesReceived: number;  // 4 bytes - number of nodes client processed
  timestamp: number;      // 8 bytes - client receive timestamp (ms)
}


export interface GraphUpdateHeader extends MessageHeader {
  graphTypeFlag: GraphTypeFlag; 
}

// Constants for binary layout (V2+ only - V1 removed)
export const MESSAGE_HEADER_SIZE = 4;
export const GRAPH_UPDATE_HEADER_SIZE = 5;
export const AGENT_POSITION_SIZE_V2 = 21;  // 4 (u32 id) + 12 (pos) + 4 (timestamp) + 1 (flags)
export const AGENT_STATE_SIZE_V2 = 49;     // Full agent state with u32 IDs
export const SSSP_DATA_SIZE_V2 = 12;       // SSSP with u32 IDs

// Canonical sizes (V1 removed)
export const AGENT_POSITION_SIZE = AGENT_POSITION_SIZE_V2;
export const AGENT_STATE_SIZE = AGENT_STATE_SIZE_V2;
export const SSSP_DATA_SIZE = SSSP_DATA_SIZE_V2;

export const VOICE_HEADER_SIZE = 7; 


export class BinaryWebSocketProtocol {
  private static instance: BinaryWebSocketProtocol;
  private lastPositionUpdate: number = 0;
  private positionUpdateThrottle: number = 16; 
  private metadataUpdateThrottle: number = 100; 
  private isUserInteracting: boolean = false;
  private pendingPositionUpdates: AgentPositionUpdate[] = [];
  private voiceEnabled: boolean = false;

  private constructor() {}

  public static getInstance(): BinaryWebSocketProtocol {
    if (!BinaryWebSocketProtocol.instance) {
      BinaryWebSocketProtocol.instance = new BinaryWebSocketProtocol();
    }
    return BinaryWebSocketProtocol.instance;
  }

  
  public createMessage(type: MessageType, payload: ArrayBuffer, graphTypeFlag?: GraphTypeFlag): ArrayBuffer {
    const isGraphUpdate = type === MessageType.GRAPH_UPDATE;
    const headerSize = isGraphUpdate ? GRAPH_UPDATE_HEADER_SIZE : MESSAGE_HEADER_SIZE;
    const totalSize = headerSize + payload.byteLength;
    const buffer = new ArrayBuffer(totalSize);
    const view = new DataView(buffer);

    
    view.setUint8(0, type);
    view.setUint8(1, PROTOCOL_VERSION);
    view.setUint16(2, payload.byteLength, true);

    
    if (isGraphUpdate && graphTypeFlag !== undefined) {
      view.setUint8(4, graphTypeFlag);
    }

    
    new Uint8Array(buffer, headerSize).set(new Uint8Array(payload));

    return buffer;
  }

  
  public parseHeader(buffer: ArrayBuffer): MessageHeader | null {
    if (buffer.byteLength < MESSAGE_HEADER_SIZE) {
      logger.error('Buffer too small for message header');
      return null;
    }

    const view = new DataView(buffer);
    const type = view.getUint8(0) as MessageType;
    const header: MessageHeader = {
      type,
      version: view.getUint8(1),
      payloadLength: view.getUint16(2, true)
    };

    
    if (type === MessageType.GRAPH_UPDATE && buffer.byteLength >= GRAPH_UPDATE_HEADER_SIZE) {
      header.graphTypeFlag = view.getUint8(4) as GraphTypeFlag;
    }

    return header;
  }

  
  public extractPayload(buffer: ArrayBuffer, header?: MessageHeader): ArrayBuffer {
    const isGraphUpdate = header?.type === MessageType.GRAPH_UPDATE;
    const headerSize = isGraphUpdate ? GRAPH_UPDATE_HEADER_SIZE : MESSAGE_HEADER_SIZE;

    if (buffer.byteLength <= headerSize) {
      return new ArrayBuffer(0);
    }
    return buffer.slice(headerSize);
  }

  
  public encodePositionUpdates(updates: AgentPositionUpdate[]): ArrayBuffer | null {
    if (!this.isUserInteracting || updates.length === 0) {
      return null; 
    }

    
    const now = performance.now();
    if (now - this.lastPositionUpdate < this.positionUpdateThrottle) {
      
      this.pendingPositionUpdates.push(...updates);
      return null;
    }

    
    const allUpdates = [...this.pendingPositionUpdates, ...updates];
    this.pendingPositionUpdates = [];
    this.lastPositionUpdate = now;

    
    const payload = new ArrayBuffer(allUpdates.length * AGENT_POSITION_SIZE_V2);
    const view = new DataView(payload);

    allUpdates.forEach((update, index) => {
      const offset = index * AGENT_POSITION_SIZE_V2;

      
      view.setUint32(offset, update.agentId, true);
      view.setFloat32(offset + 4, update.position.x, true);
      view.setFloat32(offset + 8, update.position.y, true);
      view.setFloat32(offset + 12, update.position.z, true);
      view.setUint32(offset + 16, update.timestamp, true);
      view.setUint8(offset + 20, update.flags);
    });

    return this.createMessage(MessageType.POSITION_UPDATE, payload);
  }


  public decodePositionUpdates(payload: ArrayBuffer): AgentPositionUpdate[] {
    const updates: AgentPositionUpdate[] = [];

    // V2+ only - version byte detection
    if (payload.byteLength < 1) {
      logger.error('Empty position update payload');
      return updates;
    }

    const view = new DataView(payload);
    const version = view.getUint8(0);
    if (!SUPPORTED_PROTOCOLS.includes(version)) {
      logger.error(`Unsupported protocol version: ${version}. Only V2 and V3 are supported.`);
      return updates;
    }

    // Decode V2 format (V1 removed)
    const dataPayload = payload.byteLength > 1 ? payload.slice(1) : new ArrayBuffer(0);
    const dataView = new DataView(dataPayload);

    if ((dataPayload.byteLength % AGENT_POSITION_SIZE_V2) !== 0) {
      logger.error(`Invalid position update payload size: ${dataPayload.byteLength}`);
      return updates;
    }

    const updateCount = dataPayload.byteLength / AGENT_POSITION_SIZE_V2;
    for (let i = 0; i < updateCount; i++) {
      const offset = i * AGENT_POSITION_SIZE_V2;

      if (offset + AGENT_POSITION_SIZE_V2 > dataPayload.byteLength) {
        logger.warn('Truncated position update data');
        break;
      }

      updates.push({
        agentId: dataView.getUint32(offset, true),
        position: {
          x: dataView.getFloat32(offset + 4, true),
          y: dataView.getFloat32(offset + 8, true),
          z: dataView.getFloat32(offset + 12, true)
        },
        timestamp: dataView.getUint32(offset + 16, true),
        flags: dataView.getUint8(offset + 20)
      });
    }

    return updates;
  }

  
  public encodeAgentState(agents: AgentStateData[]): ArrayBuffer {
    const payload = new ArrayBuffer(agents.length * AGENT_STATE_SIZE_V2);
    const view = new DataView(payload);

    agents.forEach((agent, index) => {
      const offset = index * AGENT_STATE_SIZE_V2;

      
      view.setUint32(offset, agent.agentId, true);
      view.setFloat32(offset + 4, agent.position.x, true);
      view.setFloat32(offset + 8, agent.position.y, true);
      view.setFloat32(offset + 12, agent.position.z, true);
      view.setFloat32(offset + 16, agent.velocity.x, true);
      view.setFloat32(offset + 20, agent.velocity.y, true);
      view.setFloat32(offset + 24, agent.velocity.z, true);
      view.setFloat32(offset + 28, agent.health, true);
      view.setFloat32(offset + 32, agent.cpuUsage, true);
      view.setFloat32(offset + 36, agent.memoryUsage, true);
      view.setFloat32(offset + 40, agent.workload, true);
      view.setUint32(offset + 44, agent.tokens, true);
      view.setUint8(offset + 48, agent.flags);
    });

    return this.createMessage(MessageType.AGENT_STATE_FULL, payload);
  }


  public decodeAgentState(payload: ArrayBuffer): AgentStateData[] {
    const agents: AgentStateData[] = [];

    // V2+ only - version byte detection
    if (payload.byteLength < 1) {
      logger.error('Empty agent state payload');
      return agents;
    }

    const view = new DataView(payload);
    const version = view.getUint8(0);
    if (!SUPPORTED_PROTOCOLS.includes(version)) {
      logger.error(`Unsupported protocol version: ${version}. Only V2 and V3 are supported.`);
      return agents;
    }

    // Decode V2 format (V1 removed)
    const dataPayload = payload.byteLength > 1 ? payload.slice(1) : new ArrayBuffer(0);
    const dataView = new DataView(dataPayload);

    if ((dataPayload.byteLength % AGENT_STATE_SIZE_V2) !== 0) {
      logger.error(`Invalid agent state payload size: ${dataPayload.byteLength}`);
      return agents;
    }

    const agentCount = dataPayload.byteLength / AGENT_STATE_SIZE_V2;
    for (let i = 0; i < agentCount; i++) {
      const offset = i * AGENT_STATE_SIZE_V2;

      if (offset + AGENT_STATE_SIZE_V2 > dataPayload.byteLength) {
        logger.warn('Truncated agent state data');
        break;
      }

      agents.push({
        agentId: dataView.getUint32(offset, true),
        position: {
          x: dataView.getFloat32(offset + 4, true),
          y: dataView.getFloat32(offset + 8, true),
          z: dataView.getFloat32(offset + 12, true)
        },
        velocity: {
          x: dataView.getFloat32(offset + 16, true),
          y: dataView.getFloat32(offset + 20, true),
          z: dataView.getFloat32(offset + 24, true)
        },
        health: dataView.getFloat32(offset + 28, true),
        cpuUsage: dataView.getFloat32(offset + 32, true),
        memoryUsage: dataView.getFloat32(offset + 36, true),
        workload: dataView.getFloat32(offset + 40, true),
        tokens: dataView.getUint32(offset + 44, true),
        flags: dataView.getUint8(offset + 48)
      });
    }

    return agents;
  }

  
  public encodeSSSPData(nodes: SSSPData[]): ArrayBuffer {
    const payload = new ArrayBuffer(nodes.length * SSSP_DATA_SIZE);
    const view = new DataView(payload);

    nodes.forEach((node, index) => {
      const offset = index * SSSP_DATA_SIZE;

      view.setUint16(offset, node.nodeId, true);
      view.setFloat32(offset + 2, node.distance, true);
      view.setUint16(offset + 6, node.parentId, true);
      view.setUint16(offset + 8, node.flags, true);
    });

    return this.createMessage(MessageType.SSSP_DATA, payload);
  }

  
  public decodeSSSPData(payload: ArrayBuffer): SSSPData[] {
    const nodes: SSSPData[] = [];
    const view = new DataView(payload);
    const nodeCount = payload.byteLength / SSSP_DATA_SIZE;

    for (let i = 0; i < nodeCount; i++) {
      const offset = i * SSSP_DATA_SIZE;

      if (offset + SSSP_DATA_SIZE > payload.byteLength) {
        logger.warn('Truncated SSSP data');
        break;
      }

      nodes.push({
        nodeId: view.getUint16(offset, true),
        distance: view.getFloat32(offset + 2, true),
        parentId: view.getUint16(offset + 6, true),
        flags: view.getUint16(offset + 8, true)
      });
    }

    return nodes;
  }

  
  public encodeControlBits(flags: ControlFlags): ArrayBuffer {
    const payload = new ArrayBuffer(1);
    const view = new DataView(payload);
    view.setUint8(0, flags);
    return this.createMessage(MessageType.CONTROL_BITS, payload);
  }

  
  public decodeControlBits(payload: ArrayBuffer): ControlFlags {
    if (payload.byteLength < 1) {
      return 0 as ControlFlags;
    }
    const view = new DataView(payload);
    return view.getUint8(0) as ControlFlags;
  }

  
  public encodeVoiceChunk(chunk: VoiceChunk): ArrayBuffer {
    const totalSize = VOICE_HEADER_SIZE + chunk.audioData.byteLength;
    const payload = new ArrayBuffer(totalSize);
    const view = new DataView(payload);

    view.setUint16(0, chunk.agentId, true);
    view.setUint16(2, chunk.chunkId, true);
    view.setUint8(4, chunk.format);
    view.setUint16(5, chunk.dataLength, true);

    
    new Uint8Array(payload, VOICE_HEADER_SIZE).set(new Uint8Array(chunk.audioData));

    return this.createMessage(MessageType.VOICE_CHUNK, payload);
  }

  
  public decodeVoiceChunk(payload: ArrayBuffer): VoiceChunk | null {
    if (payload.byteLength < VOICE_HEADER_SIZE) {
      logger.error('Voice chunk payload too small');
      return null;
    }

    const view = new DataView(payload);
    const dataLength = view.getUint16(5, true);

    if (payload.byteLength < VOICE_HEADER_SIZE + dataLength) {
      logger.error('Voice chunk audio data truncated');
      return null;
    }

    return {
      agentId: view.getUint16(0, true),
      chunkId: view.getUint16(2, true),
      format: view.getUint8(4),
      dataLength: dataLength,
      audioData: payload.slice(VOICE_HEADER_SIZE, VOICE_HEADER_SIZE + dataLength)
    };
  }

  
  public setUserInteracting(interacting: boolean): void {
    this.isUserInteracting = interacting;
    logger.debug(`User interaction state: ${interacting}`);
  }

  
  public configureThrottling(positionMs: number, metadataMs: number): void {
    this.positionUpdateThrottle = positionMs;
    this.metadataUpdateThrottle = metadataMs;
    logger.info(`Throttling configured: position=${positionMs}ms, metadata=${metadataMs}ms`);
  }

  
  public setVoiceEnabled(enabled: boolean): void {
    this.voiceEnabled = enabled;
    logger.info(`Voice communication: ${enabled ? 'enabled' : 'disabled'}`);
  }

  /**
   * Create a broadcast acknowledgement message for backpressure flow control.
   * This should be sent after client processes a position update broadcast.
   *
   * @param sequenceId - Server broadcast sequence number (from position update header)
   * @param nodesReceived - Number of nodes successfully processed
   * @returns Binary message ready to send over WebSocket
   */
  public createBroadcastAck(sequenceId: number, nodesReceived: number): ArrayBuffer {
    // Payload: 8 bytes sequenceId + 4 bytes nodesReceived + 8 bytes timestamp = 20 bytes
    const payload = new ArrayBuffer(20);
    const view = new DataView(payload);

    // Write sequenceId as BigInt64 (8 bytes, little-endian)
    const lowBits = sequenceId >>> 0;
    const highBits = Math.floor(sequenceId / 0x100000000) >>> 0;
    view.setUint32(0, lowBits, true);
    view.setUint32(4, highBits, true);

    // Write nodesReceived (4 bytes, little-endian)
    view.setUint32(8, nodesReceived, true);

    // Write timestamp (8 bytes, little-endian)
    const timestamp = Date.now();
    const tsLowBits = timestamp >>> 0;
    const tsHighBits = Math.floor(timestamp / 0x100000000) >>> 0;
    view.setUint32(12, tsLowBits, true);
    view.setUint32(16, tsHighBits, true);

    return this.createMessage(MessageType.BROADCAST_ACK, payload);
  }

  /**
   * Decode a broadcast acknowledgement from server (for server-sent acks if needed)
   */
  public decodeBroadcastAck(payload: ArrayBuffer): BroadcastAckData | null {
    if (payload.byteLength < 20) {
      logger.error('Broadcast ACK payload too small');
      return null;
    }

    const view = new DataView(payload);

    // Read sequenceId (8 bytes, little-endian)
    const lowBits = view.getUint32(0, true);
    const highBits = view.getUint32(4, true);
    const sequenceId = lowBits + highBits * 0x100000000;

    // Read nodesReceived (4 bytes)
    const nodesReceived = view.getUint32(8, true);

    // Read timestamp (8 bytes)
    const tsLowBits = view.getUint32(12, true);
    const tsHighBits = view.getUint32(16, true);
    const timestamp = tsLowBits + tsHighBits * 0x100000000;

    return { sequenceId, nodesReceived, timestamp };
  }

  
  public calculateBandwidth(agentCount: number, updateRateHz: number): {
    positionOnly: number;    
    fullState: number;       
    withVoice: number;       
  } {
    const positionBandwidth = agentCount * AGENT_POSITION_SIZE * updateRateHz;
    const stateBandwidth = agentCount * AGENT_STATE_SIZE * updateRateHz;
    const voiceBandwidth = this.voiceEnabled ? agentCount * 8000 : 0; 

    return {
      positionOnly: positionBandwidth + MESSAGE_HEADER_SIZE * updateRateHz,
      fullState: stateBandwidth + MESSAGE_HEADER_SIZE * updateRateHz,
      withVoice: stateBandwidth + voiceBandwidth + MESSAGE_HEADER_SIZE * updateRateHz
    };
  }

  
  public validateMessage(buffer: ArrayBuffer): boolean {
    const header = this.parseHeader(buffer);
    if (!header) return false;

    
    if (header.version !== PROTOCOL_VERSION) {
      logger.warn(`Protocol version mismatch: expected ${PROTOCOL_VERSION}, got ${header.version}`);
      return false;
    }

    
    const expectedSize = MESSAGE_HEADER_SIZE + header.payloadLength;
    if (buffer.byteLength !== expectedSize) {
      logger.warn(`Message size mismatch: expected ${expectedSize}, got ${buffer.byteLength}`);
      return false;
    }

    return true;
  }
}

// Export singleton instance
export const binaryProtocol = BinaryWebSocketProtocol.getInstance();

// Export utility functions for bandwidth analysis
export function estimateDataSize(agentCount: number): {
  perUpdate: number;
  perSecondAt10Hz: number;
  perSecondAt60Hz: number;
  comparison: string;
} {
  const perUpdate = agentCount * AGENT_STATE_SIZE + MESSAGE_HEADER_SIZE;
  const perSecond10Hz = perUpdate * 10;
  const perSecond60Hz = perUpdate * 60;

  
  const jsonEstimate = agentCount * 200; 
  const comparison = perUpdate < jsonEstimate
    ? `${Math.round((1 - perUpdate/jsonEstimate) * 100)}% smaller than JSON`
    : `${Math.round((perUpdate/jsonEstimate - 1) * 100)}% larger than JSON`;

  return {
    perUpdate,
    perSecondAt10Hz: perSecond10Hz,
    perSecondAt60Hz: perSecond60Hz,
    comparison
  };
}
--------------------------------------------------------------------------------
FILE: client/src/services/nostrAuthService.ts
PURPOSE: Nostr authentication service
--------------------------------------------------------------------------------
import { unifiedApiClient } from './api/UnifiedApiClient';
import { createLogger } from '../utils/loggerConfig';
import { createErrorMetadata } from '../utils/loggerConfig';
import { Event, UnsignedEvent, nip19 } from 'nostr-tools';
import { v4 as uuidv4 } from 'uuid'; 
import type {} from '../types/nip07'; 

const logger = createLogger('NostrAuthService');

// --- Interfaces ---

// User info stored locally and used in AuthState
export interface SimpleNostrUser {
  pubkey: string; 
  npub?: string; 
  isPowerUser: boolean; 
}

// User info returned by backend
export interface BackendNostrUser {
  pubkey: string;
  npub?: string;
  isPowerUser: boolean; 
  
}

// Response from POST /auth/nostr
export interface AuthResponse {
  user: BackendNostrUser;
  token: string;
  expiresAt: number; 
  features?: string[]; 
}

// Response from POST /auth/nostr/verify
export interface VerifyResponse {
  valid: boolean;
  user?: BackendNostrUser;
  features?: string[];
}

// Payload for POST /auth/nostr (signed NIP-42 event)
export interface AuthEventPayload {
  id: string;
  pubkey: string;
  content: string;
  sig: string;
  created_at: number; 
  kind: number;
  tags: string[][];
}

// State exposed to the application
export interface AuthState {
  authenticated: boolean;
  user?: SimpleNostrUser;
  error?: string;
}

type AuthStateListener = (state: AuthState) => void;

// --- Service Implementation ---

class NostrAuthService {
  private static instance: NostrAuthService;
  private sessionToken: string | null = null;
  private currentUser: SimpleNostrUser | null = null;
  private authStateListeners: AuthStateListener[] = [];
  private initialized = false;

  private constructor() {}

  public static getInstance(): NostrAuthService {
    if (!NostrAuthService.instance) {
      NostrAuthService.instance = new NostrAuthService();
    }
    return NostrAuthService.instance;
  }

  
  public hasNip07Provider(): boolean {
    return typeof window !== 'undefined' && window.nostr !== undefined;
  }

  
  public async initialize(): Promise<void> {
    if (this.initialized) return;
    logger.debug('Initializing NostrAuthService...');

    // DEV MODE: Auto-login as power user when in development
    // SECURITY: Controlled via VITE_DEV_MODE_AUTH env var (default: false)
    const isDev = import.meta.env.DEV;
    const devModeAuthEnabled = import.meta.env.VITE_DEV_MODE_AUTH === 'true';
    if (isDev && devModeAuthEnabled) {
      logger.info('[DEV MODE] Auto-authenticating as power user');
      const devPowerUserPubkey = import.meta.env.VITE_DEV_POWER_USER_PUBKEY || 'bfcf20d472f0fb143b23cb5be3fa0a040d42176b71f73ca272f6912b1d62a452';
      this.sessionToken = 'dev-session-token';
      this.currentUser = {
        pubkey: devPowerUserPubkey,
        npub: this.hexToNpub(devPowerUserPubkey),
        isPowerUser: true,
      };
      this.initialized = true;
      this.notifyListeners(this.getCurrentAuthState());
      logger.info(`[DEV MODE] Authenticated as power user: ${devPowerUserPubkey}`);
      return;
    }

    const storedToken = localStorage.getItem('nostr_session_token');
    const storedUserJson = localStorage.getItem('nostr_user');

    if (storedToken && storedUserJson) {
      let storedUser: SimpleNostrUser | null = null;
      try {
        storedUser = JSON.parse(storedUserJson);
      } catch (parseError) {
        logger.error('Failed to parse stored user data:', createErrorMetadata(parseError));
        this.clearSession();
      }

      if (storedUser) {
        logger.info(`Verifying stored session for pubkey: ${storedUser.pubkey}`);
        try {
          
          const verificationResponse = await unifiedApiClient.postData<VerifyResponse>('/auth/nostr/verify', {
            pubkey: storedUser.pubkey,
            token: storedToken
          });

          if (verificationResponse.valid) { 
            this.sessionToken = storedToken;
            if (verificationResponse.user) { 
              this.currentUser = {
                pubkey: verificationResponse.user.pubkey,
                npub: verificationResponse.user.npub || this.hexToNpub(verificationResponse.user.pubkey),
                isPowerUser: verificationResponse.user.isPowerUser,
              };
              logger.info('Token verified and user details updated from backend.');
            } else if (storedUser) {
              
              
              this.currentUser = storedUser; 
              logger.info('Token verified, using stored user details as backend did not provide them on verify.');
            } else {
              
              logger.error('Token verified but no user details available from backend or local storage. Clearing session.');
              this.clearSession();
              this.notifyListeners({ authenticated: false, error: 'User details missing after verification' });
              return; 
            }
            this.storeCurrentUser(); 
            this.notifyListeners(this.getCurrentAuthState());
            logger.info('Restored and verified session from local storage.');
          } else {
            
            logger.warn('Stored session token is invalid (verification failed), clearing session.');
            this.clearSession();
            this.notifyListeners({ authenticated: false });
          }
        } catch (error) {
          logger.error('Failed to verify stored session with backend:', createErrorMetadata(error));
          this.clearSession();
          this.notifyListeners({ authenticated: false, error: 'Session verification failed' });
        }
      }
    } else {
      logger.info('No stored session found.');
      this.notifyListeners({ authenticated: false });
    }
    this.initialized = true;
    logger.debug('NostrAuthService initialized.');
  }

  
  public async login(): Promise<AuthState> {
    logger.info('Attempting NIP-07 login...');
    if (!this.hasNip07Provider()) {
      const errorMsg = 'Nostr NIP-07 provider (e.g., Alby) not found. Please install a compatible extension.';
      logger.error(errorMsg);
      this.notifyListeners({ authenticated: false, error: errorMsg });
      throw new Error(errorMsg);
    }

    try {
      
      const pubkey = await window.nostr!.getPublicKey();
      if (!pubkey) {
        throw new Error('Could not get public key from NIP-07 provider.');
      }
      logger.info(`Got pubkey via NIP-07: ${pubkey}`);

      
      const challenge = uuidv4(); 
      
      const relayUrl = 'wss://relay.damus.io';

      
      const unsignedNip07Event = {
        created_at: Math.floor(Date.now() / 1000),
        kind: 22242,
        tags: [
          ['relay', relayUrl],
          ['challenge', challenge]
        ],
        content: 'Authenticate to LogseqSpringThing' 
      };

      
      logger.debug('Requesting signature via NIP-07 for event:', unsignedNip07Event);
      const signedEvent: Event = await window.nostr!.signEvent(unsignedNip07Event);
      logger.debug('Event signed successfully via NIP-07.');

      
      const eventPayload: AuthEventPayload = {
        id: signedEvent.id,
        pubkey: signedEvent.pubkey, 
        content: signedEvent.content,
        sig: signedEvent.sig,
        created_at: signedEvent.created_at,
        kind: signedEvent.kind,
        tags: signedEvent.tags,
      };

      
      logger.info(`Sending auth event to backend for pubkey: ${pubkey}`);
      const response = await unifiedApiClient.postData<AuthResponse>('/auth/nostr', eventPayload);
      logger.info(`Backend auth successful for pubkey: ${response.user.pubkey}`);

      
      this.sessionToken = response.token;
      this.currentUser = {
        pubkey: response.user.pubkey,
        npub: response.user.npub || this.hexToNpub(response.user.pubkey),
        isPowerUser: response.user.isPowerUser,
      };

      this.storeSessionToken(response.token);
      this.storeCurrentUser(); 

      const newState = this.getCurrentAuthState();
      this.notifyListeners(newState);
      return newState;

    } catch (error: any) {
      const errorMeta = createErrorMetadata(error);
      logger.error(`NIP-07 login failed. Details: ${JSON.stringify(errorMeta, null, 2)}`);
      let errorMessage = 'Login failed';
      if (error?.response?.data?.error) { 
        errorMessage = error.response.data.error;
      } else if (error?.message) {
        errorMessage = error.message;
      } else if (typeof error === 'string') {
        errorMessage = error;
      }

      
      if (errorMessage.includes('User rejected') || errorMessage.includes('extension rejected')) {
        errorMessage = 'Login request rejected in Nostr extension.';
      } else if (errorMessage.includes('401') || errorMessage.includes('Invalid signature')) {
        errorMessage = 'Authentication failed: Invalid signature or credentials.';
      } else if (errorMessage.includes('Could not get public key')) {
        errorMessage = 'Failed to get public key from Nostr extension.';
      }

      const errorState: AuthState = { authenticated: false, error: errorMessage };
      this.notifyListeners(errorState);
      
      throw new Error(errorMessage);
    }
  }

  
  public async logout(): Promise<void> {
    logger.info('Attempting logout...');
    const token = this.sessionToken;
    const user = this.currentUser;

    
    const wasAuthenticated = this.isAuthenticated();
    this.clearSession();
    if (wasAuthenticated) {
        this.notifyListeners({ authenticated: false }); 
    }


    if (token && user) {
      try {
        logger.info(`Calling server logout for pubkey: ${user.pubkey}`);
        
        await unifiedApiClient.request<any>('DELETE', '/auth/nostr', {
          pubkey: user.pubkey,
          token: token
        });
        logger.info('Server logout successful.');
      } catch (error) {
        
        logger.error('Server logout call failed:', createErrorMetadata(error));
        
        
      }
    } else {
      logger.warn('Logout called but no active session found locally.');
    }
  }

  

  private storeSessionToken(token: string): void {
    localStorage.setItem('nostr_session_token', token);
  }

  private storeCurrentUser(): void {
    if (this.currentUser) {
      localStorage.setItem('nostr_user', JSON.stringify(this.currentUser));
    } else {
      localStorage.removeItem('nostr_user');
    }
  }

  private clearSession(): void {
    this.sessionToken = null;
    this.currentUser = null;
    localStorage.removeItem('nostr_session_token');
    localStorage.removeItem('nostr_user');
  }

  public onAuthStateChanged(listener: AuthStateListener): () => void {
    this.authStateListeners.push(listener);
    if (this.initialized) { 
      listener(this.getCurrentAuthState());
    }
    
    return () => {
      this.authStateListeners = this.authStateListeners.filter(l => l !== listener);
    };
  }

  private notifyListeners(state: AuthState): void {
    this.authStateListeners.forEach(listener => {
      try {
        listener(state);
      } catch (error) {
        logger.error('Error in auth state listener:', createErrorMetadata(error));
      }
    });
  }

  public getCurrentUser(): SimpleNostrUser | null {
    return this.currentUser;
  }

  public getSessionToken(): string | null {
    return this.sessionToken;
  }

  public isAuthenticated(): boolean {
    return !!this.sessionToken && !!this.currentUser;
  }

  public getCurrentAuthState(): AuthState {
    return {
      authenticated: this.isAuthenticated(),
      user: this.currentUser ? { ...this.currentUser } : undefined, 
      error: undefined 
    };
  }

  

  public hexToNpub(pubkey: string): string | undefined {
    if (!pubkey) return undefined;
    try {
      return nip19.npubEncode(pubkey);
    } catch (error) {
      logger.warn(`Failed to convert hex to npub: ${pubkey}`, createErrorMetadata(error));
      return undefined;
    }
  }

  public npubToHex(npub: string): string | undefined {
    if (!npub) return undefined;
    try {
      const decoded = nip19.decode(npub);
      if (decoded.type === 'npub') {
        return decoded.data;
      }
      throw new Error('Invalid npub format');
    } catch (error) {
      logger.warn(`Failed to convert npub to hex: ${npub}`, createErrorMetadata(error));
      return undefined;
    }
  }

  /**
   * Dev mode login - bypasses NIP-07 and logs in as power user
   * Only available in development mode on local network
   */
  public async devLogin(): Promise<AuthState> {
    // Security: Only allow in dev mode
    if (!import.meta.env.DEV) {
      throw new Error('Dev login is only available in development mode');
    }

    // Security: Only allow from local network IPs
    const hostname = window.location.hostname;
    const isLocalNetwork =
      hostname === 'localhost' ||
      hostname === '127.0.0.1' ||
      hostname.startsWith('192.168.') ||
      hostname.startsWith('10.') ||
      hostname.startsWith('172.16.') ||
      hostname.startsWith('172.17.') ||
      hostname.startsWith('172.18.') ||
      hostname.startsWith('172.19.') ||
      hostname.startsWith('172.2') ||
      hostname.startsWith('172.30.') ||
      hostname.startsWith('172.31.');

    if (!isLocalNetwork) {
      throw new Error('Dev login is only available on local network');
    }

    logger.info('[DEV MODE] Manual dev login triggered');
    const devPowerUserPubkey = import.meta.env.VITE_DEV_POWER_USER_PUBKEY ||
      'bfcf20d472f0fb143b23cb5be3fa0a040d42176b71f73ca272f6912b1d62a452';

    this.sessionToken = 'dev-session-token';
    this.currentUser = {
      pubkey: devPowerUserPubkey,
      npub: this.hexToNpub(devPowerUserPubkey),
      isPowerUser: true,
    };

    // Store in localStorage for persistence
    this.storeSessionToken(this.sessionToken);
    this.storeCurrentUser();

    const newState = this.getCurrentAuthState();
    this.notifyListeners(newState);
    logger.info(`[DEV MODE] Logged in as power user: ${devPowerUserPubkey}`);
    return newState;
  }

  /**
   * Check if dev login button should be shown
   */
  public isDevLoginAvailable(): boolean {
    if (!import.meta.env.DEV) return false;

    const hostname = window.location.hostname;
    return (
      hostname === 'localhost' ||
      hostname === '127.0.0.1' ||
      hostname.startsWith('192.168.') ||
      hostname.startsWith('10.') ||
      hostname.startsWith('172.')
    );
  }
}

// Export a singleton instance
export const nostrAuth = NostrAuthService.getInstance();

--------------------------------------------------------------------------------
FILE: client/src/services/SolidPodService.ts
PURPOSE: JSS pod management service
--------------------------------------------------------------------------------
/**
 * Solid Pod Service
 *
 * Provides integration with JavaScript Solid Server (JSS) for:
 * - Pod management (create, check, access)
 * - LDP CRUD operations
 * - WebSocket notifications (solid-0.1 protocol)
 * - Content negotiation (JSON-LD, Turtle)
 *
 * Works with VisionFlow's Nostr authentication system.
 */

import { createLogger } from '../utils/loggerConfig';
import { nostrAuth } from './nostrAuthService';

const logger = createLogger('SolidPodService');

// --- Interfaces ---

/**
 * Pod directory structure matching backend PodStructure
 */
export interface PodStructure {
  profile: string;
  ontology_contributions: string;
  ontology_proposals: string;
  ontology_annotations: string;
  preferences: string;
  inbox: string;
}

export interface PodInfo {
  exists: boolean;
  podUrl?: string;
  webId?: string;
  suggestedUrl?: string;
  structure?: PodStructure;
}

export interface PodCreationResult {
  success: boolean;
  podUrl?: string;
  webId?: string;
  created?: boolean;
  structure?: PodStructure;
  error?: string;
}

export interface PodInitResult {
  success: boolean;
  podUrl?: string;
  webId?: string;
  created: boolean;
  structure?: PodStructure;
  npub?: string;
  error?: string;
}

export interface JsonLdDocument {
  '@context': string | object;
  '@type'?: string;
  '@id'?: string;
  [key: string]: unknown;
}

export interface SolidNotification {
  type: 'pub' | 'ack';
  url: string;
}

type NotificationCallback = (notification: SolidNotification) => void;

// --- Configuration ---

const JSS_BASE_URL = import.meta.env.VITE_JSS_URL || '/solid';
const JSS_WS_URL = import.meta.env.VITE_JSS_WS_URL || null;

// --- Service Implementation ---

class SolidPodService {
  private static instance: SolidPodService;
  private wsConnection: WebSocket | null = null;
  private subscriptions: Map<string, Set<NotificationCallback>> = new Map();
  private reconnectAttempts = 0;
  private maxReconnectAttempts = 5;
  private reconnectDelay = 1000;

  private constructor() {}

  public static getInstance(): SolidPodService {
    if (!SolidPodService.instance) {
      SolidPodService.instance = new SolidPodService();
    }
    return SolidPodService.instance;
  }

  // --- Pod Management ---

  /**
   * Check if the current user has a pod
   */
  public async checkPodExists(): Promise<PodInfo> {
    try {
      const response = await this.fetchWithAuth(`${JSS_BASE_URL}/pods/check`);

      if (!response.ok) {
        throw new Error(`Failed to check pod: ${response.status}`);
      }

      return await response.json();
    } catch (error) {
      logger.error('Failed to check pod existence', { error });
      return { exists: false };
    }
  }

  /**
   * Create a pod for the current user
   */
  public async createPod(name?: string): Promise<PodCreationResult> {
    try {
      const response = await this.fetchWithAuth(`${JSS_BASE_URL}/pods`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ name }),
      });

      if (!response.ok) {
        const error = await response.json();
        return {
          success: false,
          error: error.error || 'Pod creation failed',
        };
      }

      const result = await response.json();
      logger.info('Pod created successfully', { podUrl: result.pod_url });

      return {
        success: true,
        podUrl: result.pod_url,
        webId: result.webid,
      };
    } catch (error) {
      logger.error('Failed to create pod', { error });
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
      };
    }
  }

  /**
   * Get the user's pod URL
   */
  public async getPodUrl(): Promise<string | null> {
    const info = await this.checkPodExists();
    return info.podUrl || null;
  }

  /**
   * Initialize pod for the current user (auto-provision if needed)
   * Call this on user login to ensure their pod exists with full structure
   */
  public async initPod(): Promise<PodInitResult> {
    try {
      const response = await this.fetchWithAuth(`${JSS_BASE_URL}/pods/init`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({}),
      });

      if (!response.ok) {
        const error = await response.json().catch(() => ({ error: 'Initialization failed' }));
        return {
          success: false,
          created: false,
          error: error.error || 'Pod initialization failed',
        };
      }

      const result = await response.json();
      logger.info('Pod initialized', {
        podUrl: result.pod_url,
        created: result.created,
      });

      return {
        success: true,
        podUrl: result.pod_url,
        webId: result.webid,
        created: result.created,
        structure: result.structure,
      };
    } catch (error) {
      logger.error('Failed to initialize pod', { error });
      return {
        success: false,
        created: false,
        error: error instanceof Error ? error.message : 'Unknown error',
      };
    }
  }

  /**
   * Ensure user's pod exists, creating if necessary
   * Convenience wrapper that checks and creates in one call
   */
  public async ensurePodExists(): Promise<PodInitResult> {
    return this.initPod();
  }

  /**
   * Get the structure of the user's pod (directory URLs)
   */
  public async getPodStructure(): Promise<PodStructure | null> {
    const result = await this.initPod();
    return result.structure || null;
  }

  /**
   * Store a preference in the user's preferences container
   */
  public async setPreference(key: string, value: unknown): Promise<boolean> {
    const structure = await this.getPodStructure();
    if (!structure) {
      logger.error('Cannot set preference: pod not initialized');
      return false;
    }

    const prefPath = `${structure.preferences}${key}.jsonld`;
    return this.putResource(prefPath, {
      '@context': 'https://www.w3.org/ns/ldp',
      '@type': 'Preference',
      key,
      value,
      modified: new Date().toISOString(),
    });
  }

  /**
   * Get a preference from the user's preferences container
   */
  public async getPreference(key: string): Promise<unknown | null> {
    const structure = await this.getPodStructure();
    if (!structure) {
      logger.error('Cannot get preference: pod not initialized');
      return null;
    }

    try {
      const prefPath = `${structure.preferences}${key}.jsonld`;
      const doc = await this.fetchJsonLd(prefPath);
      return (doc as { value?: unknown }).value ?? null;
    } catch {
      return null;
    }
  }

  /**
   * Submit an ontology contribution to the user's pod
   */
  public async submitOntologyContribution(contribution: {
    title: string;
    description: string;
    changes: unknown;
  }): Promise<string | null> {
    const structure = await this.getPodStructure();
    if (!structure) {
      logger.error('Cannot submit contribution: pod not initialized');
      return null;
    }

    const slug = `contrib-${Date.now()}`;
    return this.postResource(structure.ontology_contributions, {
      '@context': {
        '@vocab': 'https://narrativegoldmine.com/ontology#',
        schema: 'https://schema.org/',
      },
      '@type': 'OntologyContribution',
      'schema:name': contribution.title,
      'schema:description': contribution.description,
      changes: contribution.changes,
      status: 'draft',
      'schema:dateCreated': new Date().toISOString(),
    }, slug);
  }

  /**
   * Submit an ontology proposal for review
   */
  public async submitOntologyProposal(proposal: {
    title: string;
    description: string;
    contributionUrl: string;
  }): Promise<string | null> {
    const structure = await this.getPodStructure();
    if (!structure) {
      logger.error('Cannot submit proposal: pod not initialized');
      return null;
    }

    const slug = `proposal-${Date.now()}`;
    return this.postResource(structure.ontology_proposals, {
      '@context': {
        '@vocab': 'https://narrativegoldmine.com/ontology#',
        schema: 'https://schema.org/',
      },
      '@type': 'OntologyProposal',
      'schema:name': proposal.title,
      'schema:description': proposal.description,
      contribution: proposal.contributionUrl,
      status: 'pending',
      'schema:dateCreated': new Date().toISOString(),
    }, slug);
  }

  // --- Connection Methods ---

  /**
   * Connect to a user's pod by their npub (Nostr public key in bech32 format)
   * Sets up the pod context for subsequent operations
   * @param npub - Nostr public key in npub format (e.g., npub1...)
   * @returns Pod connection info
   */
  public async connectToPod(npub: string): Promise<PodInfo> {
    logger.info('Connecting to pod for npub', { npub });

    // Validate npub format
    if (!npub.startsWith('npub1')) {
      throw new Error('Invalid npub format. Expected npub1...');
    }

    try {
      const response = await this.fetchWithAuth(`${JSS_BASE_URL}/pods/connect`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ npub }),
      });

      if (!response.ok) {
        const error = await response.json().catch(() => ({ error: 'Connection failed' }));
        throw new Error(error.error || `Pod connection failed: ${response.status}`);
      }

      const info = await response.json();
      logger.info('Connected to pod', { podUrl: info.podUrl });

      // Auto-connect WebSocket if configured
      if (JSS_WS_URL && !this.wsConnection) {
        this.connectWebSocket();
      }

      return {
        exists: true,
        podUrl: info.podUrl || info.pod_url,
        webId: info.webId || info.webid,
      };
    } catch (error) {
      logger.error('Failed to connect to pod', { npub, error });
      throw error;
    }
  }

  // --- LDP Operations ---

  /**
   * Read a resource from the pod as JSON-LD
   * Alias for fetchJsonLd with enhanced error handling
   * @param path - Resource path relative to pod or absolute URL
   * @returns JSON-LD document
   */
  public async readResource(path: string): Promise<JsonLdDocument> {
    return this.fetchJsonLd(path);
  }

  /**
   * Write a resource to the pod
   * Alias for putResource with JSON-LD default and flexible content type
   * @param path - Resource path relative to pod or absolute URL
   * @param content - Content to write (object or string)
   * @returns Success status
   */
  public async writeResource(
    path: string,
    content: JsonLdDocument | Record<string, unknown> | string
  ): Promise<boolean> {
    // Convert plain objects to JSON-LD format
    const jsonLdContent = this.ensureJsonLd(content);
    return this.putResource(path, jsonLdContent);
  }

  /**
   * Subscribe to changes on a resource path
   * Wrapper around subscribe with simplified callback
   * @param path - Resource path to watch
   * @param callback - Function called when resource changes
   * @returns Unsubscribe function
   */
  public subscribeToChanges(
    path: string,
    callback: (url: string, type: 'created' | 'updated' | 'deleted') => void
  ): () => void {
    const resourceUrl = this.resolvePath(path);

    // Ensure WebSocket is connected
    if (!this.wsConnection) {
      this.connectWebSocket();
    }

    return this.subscribe(resourceUrl, (notification) => {
      if (notification.type === 'pub') {
        // Determine change type based on resource state
        callback(notification.url, 'updated');
      }
    });
  }

  /**
   * Fetch a resource as JSON-LD
   */
  public async fetchJsonLd(resourcePath: string): Promise<JsonLdDocument> {
    const url = this.resolvePath(resourcePath);
    const response = await this.fetchWithAuth(url, {
      headers: { Accept: 'application/ld+json' },
    });

    if (!response.ok) {
      throw new Error(`Failed to fetch ${resourcePath}: ${response.status}`);
    }

    return response.json();
  }

  /**
   * Fetch a resource as Turtle (for external tools)
   */
  public async fetchTurtle(resourcePath: string): Promise<string> {
    const url = this.resolvePath(resourcePath);
    const response = await this.fetchWithAuth(url, {
      headers: { Accept: 'text/turtle' },
    });

    if (!response.ok) {
      throw new Error(`Failed to fetch Turtle ${resourcePath}: ${response.status}`);
    }

    return response.text();
  }

  /**
   * Create or update a resource
   */
  public async putResource(
    resourcePath: string,
    data: JsonLdDocument | string,
    contentType: 'application/ld+json' | 'text/turtle' = 'application/ld+json'
  ): Promise<boolean> {
    const url = this.resolvePath(resourcePath);
    const body = typeof data === 'string' ? data : JSON.stringify(data);

    const response = await this.fetchWithAuth(url, {
      method: 'PUT',
      headers: { 'Content-Type': contentType },
      body,
    });

    if (!response.ok) {
      logger.error('PUT failed', { resourcePath, status: response.status });
      return false;
    }

    logger.debug('Resource updated', { resourcePath });
    return true;
  }

  /**
   * Create a resource in a container (POST)
   */
  public async postResource(
    containerPath: string,
    data: JsonLdDocument,
    slug?: string
  ): Promise<string | null> {
    const url = this.resolvePath(containerPath);
    const headers: Record<string, string> = {
      'Content-Type': 'application/ld+json',
    };

    if (slug) {
      headers['Slug'] = slug;
    }

    const response = await this.fetchWithAuth(url, {
      method: 'POST',
      headers,
      body: JSON.stringify(data),
    });

    if (!response.ok) {
      logger.error('POST failed', { containerPath, status: response.status });
      return null;
    }

    // Return the created resource URL from Location header
    return response.headers.get('Location');
  }

  /**
   * Delete a resource
   */
  public async deleteResource(resourcePath: string): Promise<boolean> {
    const url = this.resolvePath(resourcePath);

    const response = await this.fetchWithAuth(url, {
      method: 'DELETE',
    });

    if (!response.ok && response.status !== 404) {
      logger.error('DELETE failed', { resourcePath, status: response.status });
      return false;
    }

    return true;
  }

  /**
   * Check if a resource exists (HEAD)
   */
  public async resourceExists(resourcePath: string): Promise<boolean> {
    const url = this.resolvePath(resourcePath);

    try {
      const response = await this.fetchWithAuth(url, { method: 'HEAD' });
      return response.ok;
    } catch {
      return false;
    }
  }

  // --- WebSocket Notifications ---

  /**
   * Connect to JSS WebSocket for real-time notifications
   */
  public connectWebSocket(): void {
    if (!JSS_WS_URL) {
      logger.warn('JSS WebSocket URL not configured');
      return;
    }

    if (this.wsConnection?.readyState === WebSocket.OPEN) {
      logger.debug('WebSocket already connected');
      return;
    }

    try {
      this.wsConnection = new WebSocket(JSS_WS_URL);

      this.wsConnection.onopen = () => {
        logger.info('JSS WebSocket connected');
        this.reconnectAttempts = 0;
        // Protocol handshake will be handled in onmessage
      };

      this.wsConnection.onmessage = (event) => {
        const msg = event.data.toString().trim();
        this.handleWebSocketMessage(msg);
      };

      this.wsConnection.onerror = (error) => {
        logger.error('JSS WebSocket error', { error });
      };

      this.wsConnection.onclose = () => {
        logger.info('JSS WebSocket disconnected');
        this.handleReconnect();
      };
    } catch (error) {
      logger.error('Failed to connect WebSocket', { error });
    }
  }

  /**
   * Subscribe to notifications for a resource
   */
  public subscribe(resourceUrl: string, callback: NotificationCallback): () => void {
    if (!this.subscriptions.has(resourceUrl)) {
      this.subscriptions.set(resourceUrl, new Set());

      // Send subscription if connected
      if (this.wsConnection?.readyState === WebSocket.OPEN) {
        this.wsConnection.send(`sub ${resourceUrl}`);
      }
    }

    this.subscriptions.get(resourceUrl)!.add(callback);

    // Return unsubscribe function
    return () => {
      this.subscriptions.get(resourceUrl)?.delete(callback);

      if (this.subscriptions.get(resourceUrl)?.size === 0) {
        if (this.wsConnection?.readyState === WebSocket.OPEN) {
          this.wsConnection.send(`unsub ${resourceUrl}`);
        }
        this.subscriptions.delete(resourceUrl);
      }
    };
  }

  /**
   * Disconnect WebSocket
   */
  public disconnect(): void {
    if (this.wsConnection) {
      this.wsConnection.close();
      this.wsConnection = null;
    }
    this.subscriptions.clear();
  }

  // --- Private Methods ---

  /**
   * Ensure content is in JSON-LD format
   */
  private ensureJsonLd(
    content: JsonLdDocument | Record<string, unknown> | string
  ): JsonLdDocument {
    if (typeof content === 'string') {
      try {
        const parsed = JSON.parse(content);
        return this.ensureJsonLd(parsed);
      } catch {
        // Treat as plain text content
        return {
          '@context': 'https://www.w3.org/ns/ldp',
          '@type': 'Resource',
          content: content,
        };
      }
    }

    // Already has @context - return as-is
    if ('@context' in content && content['@context']) {
      return content as JsonLdDocument;
    }

    // Wrap plain object in JSON-LD structure
    const { '@context': _, '@type': __, ...rest } = content as Record<string, unknown>;
    return {
      '@context': {
        '@vocab': 'https://narrativegoldmine.com/ontology#',
        ldp: 'https://www.w3.org/ns/ldp#',
        xsd: 'http://www.w3.org/2001/XMLSchema#',
      },
      '@type': 'Resource',
      ...rest,
    };
  }

  private async fetchWithAuth(
    url: string,
    options: RequestInit = {}
  ): Promise<Response> {
    const token = nostrAuth.getSessionToken();

    const headers = new Headers(options.headers);

    if (token) {
      headers.set('Authorization', `Bearer ${token}`);
    }

    return fetch(url, {
      ...options,
      headers,
      credentials: 'include',
    });
  }

  private resolvePath(path: string): string {
    if (path.startsWith('http://') || path.startsWith('https://')) {
      return path;
    }

    // Remove leading slash if present
    const cleanPath = path.startsWith('/') ? path.slice(1) : path;
    return `${JSS_BASE_URL}/${cleanPath}`;
  }

  private handleWebSocketMessage(msg: string): void {
    if (msg.startsWith('protocol ')) {
      // Handshake complete, resubscribe to all resources
      logger.debug('WebSocket protocol handshake complete');
      for (const url of this.subscriptions.keys()) {
        this.wsConnection?.send(`sub ${url}`);
      }
    } else if (msg.startsWith('ack ')) {
      const url = msg.slice(4);
      logger.debug('Subscription acknowledged', { url });
      this.notifySubscribers(url, { type: 'ack', url });
    } else if (msg.startsWith('pub ')) {
      const url = msg.slice(4);
      logger.debug('Resource changed', { url });
      this.notifySubscribers(url, { type: 'pub', url });
    }
  }

  private notifySubscribers(url: string, notification: SolidNotification): void {
    // Notify exact URL subscribers
    const callbacks = this.subscriptions.get(url);
    callbacks?.forEach((cb) => cb(notification));

    // Also notify container subscribers (parent directory)
    const containerUrl = url.substring(0, url.lastIndexOf('/') + 1);
    if (containerUrl !== url) {
      const containerCallbacks = this.subscriptions.get(containerUrl);
      containerCallbacks?.forEach((cb) => cb(notification));
    }
  }

  private handleReconnect(): void {
    if (this.reconnectAttempts >= this.maxReconnectAttempts) {
      logger.warn('Max reconnect attempts reached');
      return;
    }

    this.reconnectAttempts++;
    const delay = this.reconnectDelay * Math.pow(2, this.reconnectAttempts - 1);

    logger.info(`Reconnecting in ${delay}ms (attempt ${this.reconnectAttempts})`);

    setTimeout(() => {
      this.connectWebSocket();
    }, delay);
  }
}

// Export singleton instance
const solidPodService = SolidPodService.getInstance();
export default solidPodService;

--------------------------------------------------------------------------------
FILE: client/src/services/VoiceWebSocketService.ts
PURPOSE: Voice WebSocket communication service
--------------------------------------------------------------------------------


import { AudioOutputService } from './AudioOutputService';
import { AudioInputService, AudioChunk, AudioInputState } from './AudioInputService';
import { useSettingsStore } from '../store/settingsStore';
import { gatedConsole } from '../utils/console';
import { createLogger } from '../utils/loggerConfig';

const logger = createLogger('VoiceWebSocketService');

export interface VoiceMessage {
  type: 'tts' | 'stt' | 'audio_chunk' | 'transcription' | 'error' | 'connected';
  data?: any;
}

export interface TTSRequest {
  text: string;
  voice?: string;
  speed?: number;
  stream?: boolean;
}

export interface TranscriptionResult {
  text: string;
  isFinal: boolean;
  confidence?: number;
  timestamp?: number;
}

export class VoiceWebSocketService {
  private static instance: VoiceWebSocketService;
  private socket: WebSocket | null = null;
  private audioOutput: AudioOutputService;
  private audioInput: AudioInputService;
  private isStreamingAudio = false;
  private transcriptionCallback?: (result: TranscriptionResult) => void;
  private listeners: Map<string, Set<Function>> = new Map();
  private reconnectAttempts = 0;
  private maxReconnectAttempts = 5;
  private reconnectDelay = 2000;

  private constructor() {
    this.audioOutput = AudioOutputService.getInstance();
    this.audioInput = AudioInputService.getInstance();

    
    this.setupAudioInputListeners();
  }

  static getInstance(): VoiceWebSocketService {
    if (!VoiceWebSocketService.instance) {
      VoiceWebSocketService.instance = new VoiceWebSocketService();
    }
    return VoiceWebSocketService.instance;
  }

  
  async connectToSpeech(baseUrl: string): Promise<void> {
    const wsUrl = baseUrl.replace(/^http/, 'ws') + '/ws/speech';
    await this.connect(wsUrl);
  }

  
  async connect(url: string): Promise<void> {
    
    if (this.socket && (this.socket.readyState === WebSocket.OPEN || this.socket.readyState === WebSocket.CONNECTING)) {
      return;
    }

    
    if (this.socket) {
      this.socket.close();
      this.socket = null;
    }

    return new Promise((resolve, reject) => {
      try {
        this.socket = new WebSocket(url);

        this.socket.onopen = () => {
          gatedConsole.voice.log('Voice WebSocket connected');
          this.reconnectAttempts = 0;
          this.emit('connected');
          resolve();
        };

        this.socket.onmessage = (event) => {
          this.handleMessage(event);
        };

        this.socket.onclose = (event) => {
          gatedConsole.voice.log('Voice WebSocket disconnected');
          this.emit('disconnected', event);
          if (event.code !== 1000) { 
            this.attemptReconnect(url);
          }
        };

        this.socket.onerror = (error) => {
          gatedConsole.voice.error('Voice WebSocket error:', error);
          this.emit('error', error);
          reject(error);
        };
      } catch (error) {
        reject(error);
      }
    });
  }

  
  private handleMessage(event: MessageEvent): void {
    
    if (event.data instanceof ArrayBuffer || event.data instanceof Blob) {
      this.handleAudioData(event.data);
      return;
    }

    
    try {
      const message: VoiceMessage = JSON.parse(event.data);
      
      
      if (message.type === 'error') {
        logger.error('Raw error message from server', message);
      }

      switch (message.type) {
        case 'connected':
          gatedConsole.voice.log('Connected to voice service:', message.data);
          this.emit('voiceConnected', message.data);
          break;

        case 'transcription':
          this.handleTranscription(message.data);
          break;

        case 'error':
          const errorMsg = (message as any).data || (message as any).error || 'Unknown voice service error';
          gatedConsole.voice.error('Voice service error:', errorMsg);
          this.emit('voiceError', errorMsg);
          break;

        default:
          this.emit('message', message);
      }
    } catch (error) {
      gatedConsole.voice.error('Failed to parse voice message:', error);
    }
  }

  
  private async handleAudioData(data: ArrayBuffer | Blob) {
    try {
      
      const buffer = data instanceof Blob ? await data.arrayBuffer() : data;

      
      await this.audioOutput.queueAudio(buffer);
      this.emit('audioReceived', buffer);
    } catch (error) {
      gatedConsole.voice.error('Failed to handle audio data:', error);
      this.emit('audioError', error);
    }
  }

  
  private handleTranscription(data: TranscriptionResult) {
    if (this.transcriptionCallback) {
      this.transcriptionCallback(data);
    }
    this.emit('transcription', data);
  }

  
  async sendTextForTTS(request: TTSRequest): Promise<void> {
    if (!this.isConnected()) {
      throw new Error('Not connected to voice service');
    }

    const message: VoiceMessage = {
      type: 'tts',
      data: request
    };

    this.send(JSON.stringify(message));
    this.emit('ttsSent', request);
  }

  
  async startAudioStreaming(options?: { language?: string; model?: string }): Promise<void> {
    if (!this.isConnected()) {
      throw new Error('Not connected to voice service');
    }

    if (this.isStreamingAudio) {
      gatedConsole.voice.warn('Audio streaming already active');
      return;
    }

    
    const support = AudioInputService.getBrowserSupport();
    logger.warn('DEVELOPER MODE: Browser support checks bypassed', support);
    
    
    
    
    
    
    
    
    
    
    
    
    
    

    try {
      
      const micAccess = await this.audioInput.requestMicrophoneAccess();
      if (!micAccess) {
        throw new Error('Microphone access denied');
      }

      
      await this.audioInput.startRecording();
      this.isStreamingAudio = true;

      
      const message = {
        type: 'stt',
        action: 'start',
        language: options?.language || 'en',
        model: options?.model || 'whisper-1',
        ...options
      };

      this.send(JSON.stringify(message));
      this.emit('audioStreamingStarted');
    } catch (error) {
      
      this.isStreamingAudio = false;
      this.audioInput.stopRecording();
      throw error;
    }
  }

  
  stopAudioStreaming() {
    if (!this.isStreamingAudio) {
      return;
    }

    
    this.audioInput.stopRecording();
    
    
    
    
    if (this.isConnected()) {
      
      const message = {
        type: 'stt',
        action: 'stop'
      };

      this.send(JSON.stringify(message));
    }

    
    setTimeout(() => {
      this.isStreamingAudio = false;
      this.emit('audioStreamingStopped');
    }, 100);
  }

  
  private setupAudioInputListeners() {
    
    this.audioInput.on('recordingComplete', async (completeAudio: Blob) => {
      logger.debug('Recording complete event received', { blobSize: completeAudio.size });
      if (this.isStreamingAudio && this.isConnected()) {
        
        try {
          const arrayBuffer = await completeAudio.arrayBuffer();
          logger.debug('Sending complete audio file', { bytes: arrayBuffer.byteLength });
          gatedConsole.voice.log('Sending complete audio file:', {
            size: arrayBuffer.byteLength,
            type: completeAudio.type
          });
          
          this.sendBinary(arrayBuffer);
        } catch (error) {
          console.error('[VoiceWebSocketService] Failed to send audio:', error);
          gatedConsole.voice.error('Failed to send audio:', error);
        }
      } else {
        logger.debug('Not sending audio', { streaming: this.isStreamingAudio, connected: this.isConnected() });
      }
    });

    
    this.audioInput.on('audioChunk', (chunk: AudioChunk) => {
      
      
    });

    this.audioInput.on('error', (error: any) => {
      gatedConsole.voice.error('Audio input error:', error);
      this.emit('audioInputError', error);
    });

    this.audioInput.on('audioLevel', (level: number) => {
      this.emit('audioLevel', level);
    });

    this.audioInput.on('stateChange', (state: AudioInputState) => {
      this.emit('audioInputStateChange', state);
    });
  }

  
  private isConnected(): boolean {
    return this.socket?.readyState === WebSocket.OPEN;
  }

  
  private send(data: string): void {
    if (this.socket?.readyState === WebSocket.OPEN) {
      this.socket.send(data);
    }
  }

  
  private sendBinary(data: ArrayBuffer): void {
    if (this.socket?.readyState === WebSocket.OPEN) {
      this.socket.send(data);
    }
  }

  
  private attemptReconnect(url: string) {
    if (this.reconnectAttempts < this.maxReconnectAttempts) {
      this.reconnectAttempts++;
      setTimeout(() => {
        gatedConsole.voice.log(`Attempting to reconnect voice WebSocket (${this.reconnectAttempts}/${this.maxReconnectAttempts})`);
        this.connect(url).catch((error) => gatedConsole.voice.error('Reconnect failed:', error));
      }, this.reconnectDelay);
    }
  }

  
  on(event: string, callback: Function) {
    if (!this.listeners.has(event)) {
      this.listeners.set(event, new Set());
    }
    this.listeners.get(event)!.add(callback);
  }

  off(event: string, callback: Function) {
    if (this.listeners.has(event)) {
      this.listeners.get(event)!.delete(callback);
    }
  }

  private emit(event: string, ...args: any[]) {
    if (this.listeners.has(event)) {
      this.listeners.get(event)!.forEach(callback => {
        callback(...args);
      });
    }
  }

  
  onTranscription(callback: (result: TranscriptionResult) => void) {
    this.transcriptionCallback = callback;
  }

  
  stopAllAudio() {
    this.stopAudioStreaming();
    this.audioOutput.stop();
  }

  
  async disconnect(): Promise<void> {
    this.stopAllAudio();
    if (this.socket) {
      this.socket.close(1000, 'Normal closure'); 
      this.socket = null;
    }
    
    this.reconnectAttempts = this.maxReconnectAttempts;
  }

  
  getAudioOutput(): AudioOutputService {
    return this.audioOutput;
  }

  
  getAudioInput(): AudioInputService {
    return this.audioInput;
  }
}
================================================================================
                    SECTION 13: CLIENT STORES (Zustand)
================================================================================

--------------------------------------------------------------------------------
FILE: client/src/store/settingsStore.ts
PURPOSE: Global settings state management (Zustand)
--------------------------------------------------------------------------------
import { create } from 'zustand'
import { persist, createJSONStorage } from 'zustand/middleware'
import { Settings, SettingsPath, DeepPartial } from '../features/settings/config/settings'
import { createLogger } from '../utils/loggerConfig'
import { createErrorMetadata } from '../utils/loggerConfig'
import { debugState } from '../utils/clientDebugState'
import { produce } from 'immer';
import { toast } from '../features/design-system/components/Toast';
import { isViewportSetting } from '../features/settings/config/viewportSettings';
import { settingsApi } from '../api/settingsApi';
import { nostrAuth } from '../services/nostrAuthService';
import { autoSaveManager } from './autoSaveManager';



const logger = createLogger('SettingsStore')

// Helper to wait for authentication to be ready
async function waitForAuthReady(maxWaitMs: number = 3000): Promise<void> {
  const startTime = Date.now();

  
  if (!nostrAuth['initialized']) {
    logger.info('Waiting for nostrAuth to initialize...');
    await nostrAuth.initialize();
  }

  
  return new Promise((resolve) => {
    const checkAuth = () => {
      const elapsed = Date.now() - startTime;

      
      if (elapsed >= maxWaitMs || !localStorage.getItem('nostr_session_token')) {
        logger.info('Proceeding with settings initialization', {
          authenticated: nostrAuth.isAuthenticated(),
          elapsed
        });
        resolve();
        return;
      }

      
      if (nostrAuth.isAuthenticated()) {
        logger.info('Auth ready, proceeding with settings initialization');
        resolve();
        return;
      }

      
      setTimeout(checkAuth, 100);
    };

    checkAuth();
  });
}

// Essential paths loaded at startup for fast initialization
const ESSENTIAL_PATHS = [
  'system.debug.enabled',
  'system.websocket.updateRate',
  'system.websocket.reconnectAttempts',
  'auth.enabled',
  'auth.required',
  'visualisation.rendering.context',
  'xr.enabled',
  'xr.mode',

  'visualisation.graphs.logseq.physics',
  'visualisation.graphs.visionflow.physics',

  // Node filtering settings - needed for visibility filtering
  'nodeFilter.enabled',
  'nodeFilter.qualityThreshold',
  'nodeFilter.authorityThreshold',
  'nodeFilter.filterByQuality',
  'nodeFilter.filterByAuthority',
  'nodeFilter.filterMode'
];


// Helper function to find changed paths between two objects
function findChangedPaths(oldObj: any, newObj: any, path: string = ''): string[] {
  const changedPaths: string[] = [];
  
  
  if (oldObj === newObj) return changedPaths;
  if (oldObj == null || newObj == null) {
    if (path) changedPaths.push(path);
    return changedPaths;
  }
  
  
  if (typeof oldObj !== 'object' || typeof newObj !== 'object') {
    if (oldObj !== newObj && path) {
      changedPaths.push(path);
    }
    return changedPaths;
  }
  
  
  const allKeys = new Set([...Object.keys(oldObj), ...Object.keys(newObj)]);
  
  for (const key of allKeys) {
    const currentPath = path ? `${path}.${key}` : key;
    const oldValue = oldObj[key];
    const newValue = newObj[key];
    
    if (typeof oldValue === 'object' && typeof newValue === 'object' && oldValue !== null && newValue !== null) {
      
      changedPaths.push(...findChangedPaths(oldValue, newValue, currentPath));
    } else if (oldValue !== newValue) {
      
      changedPaths.push(currentPath);
    }
  }
  
  return changedPaths;
}

export interface SettingsState {
  
  partialSettings: DeepPartial<Settings>
  loadedPaths: Set<string> 
  loadingSections: Set<string> 
  
  
  settings: DeepPartial<Settings> 
  
  initialized: boolean
  authenticated: boolean
  user: { isPowerUser: boolean; pubkey: string } | null
  isPowerUser: boolean 
  subscribers: Map<string, Set<() => void>>

  
  initialize: () => Promise<void>
  setAuthenticated: (authenticated: boolean) => void
  setUser: (user: { isPowerUser: boolean; pubkey: string } | null) => void
  get: <T>(path: SettingsPath) => T | undefined
  set: <T>(path: SettingsPath, value: T) => void
  subscribe: (path: SettingsPath, callback: () => void, immediate?: boolean) => () => void;
  unsubscribe: (path: SettingsPath, callback: () => void) => void;
  updateSettings: (updater: (draft: Settings) => void) => void;
  notifyViewportUpdate: (path: SettingsPath) => void; 
  
  
  ensureLoaded: (paths: string[]) => Promise<void>
  loadSection: (section: string) => Promise<void>
  isLoaded: (path: SettingsPath) => boolean
  
  
  getByPath: <T>(path: SettingsPath) => Promise<T>; 
  setByPath: <T>(path: SettingsPath, value: T) => void; 
  batchUpdate: (updates: Array<{path: SettingsPath, value: any}>) => void; 
  flushPendingUpdates: () => Promise<void>; 
  
  
  resetSettings: () => Promise<void>; 
  exportSettings: () => Promise<string>; 
  importSettings: (jsonString: string) => Promise<void>; 
  
  
  updateComputeMode: (mode: string) => void;
  updateClustering: (config: ClusteringConfig) => void;
  updateConstraints: (constraints: ConstraintConfig[]) => void;
  updatePhysics: (graphName: string, params: Partial<GPUPhysicsParams>) => void;
  updateWarmupSettings: (settings: WarmupSettings) => void;
  
  
  notifyPhysicsUpdate: (graphName: string, params: Partial<GPUPhysicsParams>) => void;
}

// GPU-specific interfaces for type safety
interface GPUPhysicsParams {
  springK: number;
  repelK: number;
  attractionK: number;
  gravity: number;
  dt: number;
  maxVelocity: number;
  damping: number;
  temperature: number;
  maxRepulsionDist: number;
  
  
  restLength: number;
  repulsionCutoff: number;
  repulsionSofteningEpsilon: number;
  centerGravityK: number;
  gridCellSize: number;
  featureFlags: number;
  
  
  warmupIterations: number;
  coolingRate: number;
  
  
  enableBounds?: boolean;
  boundsSize?: number;
  boundaryDamping?: number;
  collisionRadius?: number;
  
  
  iterations?: number;
  massScale?: number;
  updateThreshold?: number;
  
  
  
  boundaryExtremeMultiplier?: number;
  
  boundaryExtremeForceMultiplier?: number;
  
  boundaryVelocityDamping?: number;
  
  maxForce?: number;
  
  seed?: number;
  
  iteration?: number;
}

interface ClusteringConfig {
  algorithm: 'none' | 'kmeans' | 'spectral' | 'louvain';
  clusterCount: number;
  resolution: number;
  iterations: number;
  exportEnabled: boolean;
  importEnabled: boolean;
}

interface ConstraintConfig {
  id: string;
  name: string;
  enabled: boolean;
  description?: string;
  icon?: string;
}

interface WarmupSettings {
  warmupDuration: number;
  convergenceThreshold: number;
  enableAdaptiveCooling: boolean;
  warmupIterations?: number; 
  coolingRate?: number; 
}


export const useSettingsStore = create<SettingsState>()(
  persist(
    (set, get) => ({
      partialSettings: {},
      settings: {}, 
      loadedPaths: new Set(),
      loadingSections: new Set(),
      initialized: false,
      authenticated: false,
      user: null,
      isPowerUser: false,
      subscribers: new Map(),

      initialize: async () => {
        try {
          console.log('[SettingsStore] Starting initialization with essential paths');
          if (debugState.isEnabled()) {
            logger.info('Initializing settings store with essential paths only')
          }

          
          await waitForAuthReady();

          const isAuthenticated = nostrAuth.isAuthenticated();
          const user = nostrAuth.getCurrentUser();

          logger.info('Settings initialization with auth state', {
            authenticated: isAuthenticated,
            user: user?.pubkey?.slice(0, 8) + '...',
          });

          
          console.log('[SettingsStore] Calling settingsApi.getSettingsByPaths');
          const essentialSettings = await settingsApi.getSettingsByPaths(ESSENTIAL_PATHS);
          console.log('[SettingsStore] Essential settings loaded successfully');

          if (debugState.isEnabled()) {
            logger.info('Essential settings loaded:', { essentialSettings })
          }

          set(state => ({
            partialSettings: essentialSettings as DeepPartial<Settings>,
            settings: essentialSettings as DeepPartial<Settings>, 
            loadedPaths: new Set(ESSENTIAL_PATHS),
            initialized: true,
            authenticated: isAuthenticated,
            user: user ? { isPowerUser: user.isPowerUser, pubkey: user.pubkey } : null,
            isPowerUser: user?.isPowerUser || false
          }));

          
          autoSaveManager.setInitialized(true);

          if (debugState.isEnabled()) {
            logger.info('Settings store initialized with essential paths')
          }

        } catch (error) {
          console.error('[SettingsStore] Failed to initialize:', error);
          logger.error('Failed to initialize settings store:', createErrorMetadata(error))
          set({ initialized: false })
          throw error
        }
      },

      setAuthenticated: (authenticated: boolean) => set({ authenticated }),

      setUser: (user: { isPowerUser: boolean; pubkey: string } | null) => set({
        user,
        isPowerUser: user?.isPowerUser || false
      }),

      notifyViewportUpdate: (path: SettingsPath) => {
        
        const callbacks = get().subscribers.get('viewport.update')
        if (callbacks) {
          Array.from(callbacks).forEach(callback => {
            try {
              callback()
            } catch (error) {
              logger.error(`Error in viewport update subscriber:`, createErrorMetadata(error))
            }
          })
        }
      },

      
      get: <T>(path: SettingsPath): T | undefined => {
        const { partialSettings, loadedPaths } = get();

        if (!path?.trim()) {
          return partialSettings as unknown as T;
        }

        
        const isPathLoaded = loadedPaths.has(path) || 
          [...loadedPaths].some(loadedPath => 
            path.startsWith(loadedPath + '.') || loadedPath.startsWith(path + '.')
          );

        if (!isPathLoaded) {
          if (debugState.isEnabled()) {
            logger.warn(`Accessing unloaded path: ${path} - path should be loaded before access`);
          }
          
          
          return undefined as unknown as T;
        }

        
        const pathParts = path.split('.');
        let current: any = partialSettings;

        for (const part of pathParts) {
          if (current?.[part] === undefined) {
            return undefined;
          }
          current = current[part];
        }

        return current as T;
      },

      
      set: <T>(path: SettingsPath, value: T) => {
        if (!path?.trim()) {
          throw new Error('Path cannot be empty');
        }

        
        set(state => {
          const newPartialSettings = { ...state.partialSettings };
          setNestedValue(newPartialSettings, path, value);
          const newLoadedPaths = new Set(state.loadedPaths);
          newLoadedPaths.add(path);

          return {
            partialSettings: newPartialSettings,
            settings: newPartialSettings, 
            loadedPaths: newLoadedPaths
          };
        });

        
        settingsApi.updateSettingByPath(path, value).catch(error => {
          logger.error(`Failed to update setting ${path}:`, createErrorMetadata(error));
        });

        if (debugState.isEnabled()) {
          logger.info('Setting updated:', { path, value });
        }
      },

      subscribe: (path: SettingsPath, callback: () => void, immediate: boolean = true) => {
        set(state => {
          const subscribers = new Map(state.subscribers)

          if (!subscribers.has(path)) {
            subscribers.set(path, new Set())
          }

          subscribers.get(path)!.add(callback)

          return { subscribers }
        })

        
        if (immediate && get().initialized) {
          callback()
        }

        
        return () => get().unsubscribe(path, callback)
      },

      unsubscribe: (path: SettingsPath, callback: () => void) => {
        set(state => {
          const subscribers = new Map(state.subscribers)

          if (subscribers.has(path)) {
            const callbacks = subscribers.get(path)!
            callbacks.delete(callback)

            if (callbacks.size === 0) {
              subscribers.delete(path)
            }
          }

          return { subscribers }
        })
      },

      
      ensureLoaded: async (paths: string[]): Promise<void> => {
        const { loadedPaths } = get();
        const unloadedPaths = paths.filter(path => !loadedPaths.has(path));
        
        if (unloadedPaths.length === 0) {
          return; 
        }

        try {
          const pathSettings = await settingsApi.getSettingsByPaths(unloadedPaths);
          
          set(state => {
            const newPartialSettings = { ...state.partialSettings };
            const newLoadedPaths = new Set(state.loadedPaths);
            
            Object.entries(pathSettings).forEach(([path, value]) => {
              setNestedValue(newPartialSettings, path, value);
              newLoadedPaths.add(path);
            });

            return {
              partialSettings: newPartialSettings,
              settings: newPartialSettings, 
              loadedPaths: newLoadedPaths
            };
          });

          if (debugState.isEnabled()) {
            logger.info('Paths loaded on demand:', { paths: unloadedPaths });
          }
        } catch (error) {
          logger.error('Failed to load paths:', createErrorMetadata(error));
          throw error;
        }
      },

      
      loadSection: async (section: string): Promise<void> => {
        const { loadingSections } = get();
        if (loadingSections.has(section)) {
          return; 
        }

        const sectionPaths = getSectionPaths(section);
        if (sectionPaths.length === 0) {
          logger.warn(`Unknown section: ${section}`);
          return;
        }

        
        set(state => ({
          loadingSections: new Set(state.loadingSections).add(section)
        }));

        try {
          await get().ensureLoaded(sectionPaths);

          if (debugState.isEnabled()) {
            logger.info(`Section loaded: ${section}`, { paths: sectionPaths });
          }
        } finally {
          
          set(state => {
            const newLoadingSections = new Set(state.loadingSections);
            newLoadingSections.delete(section);
            return { loadingSections: newLoadingSections };
          });
        }
      },

      
      isLoaded: (path: SettingsPath): boolean => {
        const { loadedPaths } = get();
        return loadedPaths.has(path);
      },

      
      updateSettings: (updater: (draft: any) => void): void => {
        const { partialSettings } = get();
        
        
        const newSettings = produce(partialSettings, updater);
        
        
        const changedPaths = findChangedPaths(partialSettings, newSettings);
        
        if (changedPaths.length === 0) {
          return; 
        }

        
        set(state => {
          return {
            partialSettings: newSettings,
            settings: newSettings, 
            
            loadedPaths: new Set([...state.loadedPaths, ...changedPaths])
          };
        });

        
        changedPaths.forEach(path => {
          const pathParts = path.split('.');
          let current: any = newSettings;
          for (const part of pathParts) {
            current = current[part];
          }
          settingsApi.updateSettingByPath(path, current).catch(error => {
            logger.error(`Failed to update setting ${path}:`, createErrorMetadata(error));
          });
        });

        if (debugState.isEnabled()) {
          logger.info('Settings updated via updateSettings:', { changedPaths });
        }

        
        const state = get();
        
        
        const viewportUpdated = changedPaths.some(path => isViewportSetting(path));
        
        if (viewportUpdated) {
          
          state.notifyViewportUpdate('viewport.update');
          
          if (debugState.isEnabled()) {
            logger.info('Viewport settings updated, triggering immediate update', { 
              viewportPaths: changedPaths.filter(path => isViewportSetting(path))
            });
          }
        }

        
        const allCallbacks = new Set<() => void>();
        state.subscribers.forEach(callbacks => {
          callbacks.forEach(cb => allCallbacks.add(cb));
        });

        Array.from(allCallbacks).forEach(callback => {
          try {
            callback();
          } catch (error) {
            logger.error('Error in settings subscriber during updateSettings:', createErrorMetadata(error));
          }
        });
      },

      
      updateComputeMode: (mode: string) => {
        const state = get();
        state.updateSettings((draft: any) => {
          if (!draft.dashboard) {
            draft.dashboard = { computeMode: '' };
          }
          draft.dashboard.computeMode = mode;
        });
      },

      updateClustering: (config: ClusteringConfig) => {
        const state = get();
        state.updateSettings((draft) => {
          if (!draft.analytics) {
            (draft as any).analytics = {};
          }
          if (!(draft as any).analytics.clustering) {
            (draft as any).analytics.clustering = {};
          }
          Object.assign((draft as any).analytics.clustering, config);
        });
      },

      updateConstraints: (constraints: ConstraintConfig[]) => {
        const state = get();
        state.updateSettings((draft) => {
          if (!draft.developer) {
            (draft as any).developer = {};
          }
          if (!(draft as any).developer.constraints) {
            (draft as any).developer.constraints = {};
          }
          (draft as any).developer.constraints.active = constraints;
        });
      },

      updatePhysics: (graphName: string, params: Partial<GPUPhysicsParams>) => {
        const state = get();
        
        
        const validatedParams = { ...params };
        
        
        if (validatedParams.restLength !== undefined) {
          validatedParams.restLength = Math.max(0.1, Math.min(10.0, validatedParams.restLength));
        }
        if (validatedParams.repulsionCutoff !== undefined) {
          validatedParams.repulsionCutoff = Math.max(1.0, Math.min(1000.0, validatedParams.repulsionCutoff));
        }
        if (validatedParams.repulsionSofteningEpsilon !== undefined) {
          validatedParams.repulsionSofteningEpsilon = Math.max(0.001, Math.min(1.0, validatedParams.repulsionSofteningEpsilon));
        }
        if (validatedParams.centerGravityK !== undefined) {
          validatedParams.centerGravityK = Math.max(-1.0, Math.min(1.0, validatedParams.centerGravityK));
        }
        if (validatedParams.gridCellSize !== undefined) {
          validatedParams.gridCellSize = Math.max(1.0, Math.min(100.0, validatedParams.gridCellSize));
        }
        if (validatedParams.featureFlags !== undefined) {
          validatedParams.featureFlags = Math.max(0, Math.min(255, Math.floor(validatedParams.featureFlags)));
        }
        
        
        if ((validatedParams as any).arrow_size !== undefined) {
          (validatedParams as any).arrow_size = Math.max(0.01, Math.min(5.0, (validatedParams as any).arrow_size));
        }
        if ((validatedParams as any).arrowSize !== undefined) {
          (validatedParams as any).arrowSize = Math.max(0.01, Math.min(5.0, (validatedParams as any).arrowSize));
        }
        if ((validatedParams as any).base_width !== undefined) {
          (validatedParams as any).base_width = Math.max(0.01, Math.min(5.0, (validatedParams as any).base_width));
        }
        if ((validatedParams as any).baseWidth !== undefined) {
          (validatedParams as any).baseWidth = Math.max(0.01, Math.min(5.0, (validatedParams as any).baseWidth));
        }
        
        
        if (validatedParams.springK !== undefined) {
          validatedParams.springK = Math.max(0.001, Math.min(10.0, validatedParams.springK));
        }
        if (validatedParams.repelK !== undefined) {
          validatedParams.repelK = Math.max(0.001, Math.min(100.0, validatedParams.repelK));
        }
        if (validatedParams.attractionK !== undefined) {
          validatedParams.attractionK = Math.max(0.0, Math.min(1.0, validatedParams.attractionK));
        }
        if (validatedParams.gravity !== undefined) {
          validatedParams.gravity = Math.max(-1.0, Math.min(1.0, validatedParams.gravity));
        }
        if (validatedParams.warmupIterations !== undefined) {
          validatedParams.warmupIterations = Math.max(0, Math.min(1000, Math.floor(validatedParams.warmupIterations)));
        }
        if (validatedParams.coolingRate !== undefined) {
          validatedParams.coolingRate = Math.max(0.0001, Math.min(1.0, validatedParams.coolingRate));
        }
        
        state.updateSettings((draft: any) => {
          if (!draft.visualisation) draft.visualisation = { graphs: {} };
          if (!draft.visualisation.graphs) draft.visualisation.graphs = {};
          
          const graphs = draft.visualisation.graphs as any;
          if (!graphs[graphName]) graphs[graphName] = {};
          if (!graphs[graphName].physics) graphs[graphName].physics = {};
          
          const graphSettings = graphs[graphName];
          if (graphSettings && graphSettings.physics) {
            Object.assign(graphSettings.physics, validatedParams);
            
            if (debugState.isEnabled()) {
              logger.info('Physics parameters updated:', {
                graphName,
                updatedParams: validatedParams,
                newPhysicsState: graphSettings.physics
              });
            }
          }
        });
        
        
        state.notifyPhysicsUpdate(graphName, validatedParams);
      },

      updateWarmupSettings: (settings: WarmupSettings) => {
        const state = get();
        state.updateSettings((draft) => {
          if (!draft.performance) {
            (draft as any).performance = {};
          }
          Object.assign((draft as any).performance, settings);
        });
      },

      
      notifyPhysicsUpdate: (graphName: string, params: Partial<GPUPhysicsParams>) => {
        if (typeof window !== 'undefined') {
          try {
            
            const wsService = (window as any).webSocketService;
            if (wsService && wsService.isConnected && wsService.isConnected()) {
              const message = {
                type: 'physics_parameter_update',
                timestamp: Date.now(),
                graph: graphName,
                parameters: params
              };
              
              wsService.send(message);
              
              if (debugState.isEnabled()) {
                logger.info('Physics update sent via WebSocket:', {
                  graphName,
                  parameters: params,
                  messageType: 'physics_parameter_update'
                });
              }
            } else {
              if (debugState.isEnabled()) {
                logger.info('WebSocket not connected, physics update queued for next connection');
              }
            }
          } catch (error) {
            logger.warn('Failed to notify physics update via WebSocket:', createErrorMetadata(error));
          }
          
          
          const event = new CustomEvent('physicsParametersUpdated', {
            detail: { graphName, params }
          });
          window.dispatchEvent(event);
        }
      },

      
      
      getByPath: async <T>(path: SettingsPath): Promise<T> => {
        try {
          const value = await settingsApi.getSettingByPath(path);
          return value as T;
        } catch (error) {
          logger.error(`Failed to get setting by path ${path}:`, createErrorMetadata(error));
          const localValue = get().get<T>(path);
          return localValue as T;
        }
      },
      
      setByPath: <T>(path: SettingsPath, value: T) => {
        const state = get();

        
        state.set(path, value);

        
        settingsApi.updateSettingByPath(path, value).catch(error => {
          logger.error(`Failed to update setting ${path}:`, createErrorMetadata(error));
        });
      },
      
      batchUpdate: (updates: Array<{path: SettingsPath, value: any}>) => {
        const state = get();

        
        updates.forEach(({ path, value }) => {
          state.set(path, value);
        });

        
        settingsApi.updateSettingsByPaths(updates.map(u => ({ path: u.path, value: u.value }))).catch(error => {
          logger.error('Failed to batch update settings:', createErrorMetadata(error));
        });
      },
      
      flushPendingUpdates: async (): Promise<void> => {
        
        await settingsApi.flushPendingUpdates();
      },
      
      
      resetSettings: async (): Promise<void> => {
        try {
          
          await settingsApi.resetSettings();
          
          
          set({
            partialSettings: {},
            settings: {}, 
            loadedPaths: new Set()
          });
          
          
          await get().initialize();
          
          logger.info('Settings reset to defaults and essential paths reloaded');
        } catch (error) {
          logger.error('Failed to reset settings:', createErrorMetadata(error));
          throw error;
        }
      },
      
      exportSettings: async (): Promise<string> => {
        const { partialSettings, loadedPaths } = get();
        
        try {
          
          if (loadedPaths.size === ESSENTIAL_PATHS.length) {
            logger.info('Only essential settings loaded, fetching all settings for export...');
            
            
            const allPaths = getAllAvailableSettingsPaths();
            const allSettings = await settingsApi.getSettingsByPaths(allPaths);
            
            return settingsApi.exportSettings(allSettings as Settings);
          } else {
            
            return settingsApi.exportSettings(partialSettings as Settings);
          }
        } catch (error) {
          logger.error('Failed to export settings:', createErrorMetadata(error));
          throw error;
        }
      },
      
      importSettings: async (jsonString: string): Promise<void> => {
        try {
          
          const importedSettings = settingsApi.importSettings(jsonString);
          
          
          const allPaths = getAllSettingsPaths(importedSettings);
          const updates: Array<{path: string, value: any}> = [];
          
          for (const path of allPaths) {
            const value = path.split('.').reduce((obj, key) => obj?.[key], importedSettings);
            if (value !== undefined) {
              updates.push({ path, value });
            }
          }
          
          
          get().batchUpdate(updates);
          
          logger.info(`Successfully imported ${updates.length} settings using path-based updates`);
        } catch (error) {
          logger.error('Failed to import settings:', createErrorMetadata(error));
          throw error;
        }
      },
    }),
    {
      name: 'graph-viz-settings-v2',
      storage: createJSONStorage(() => localStorage),
      partialize: (state) => ({
        
        authenticated: state.authenticated,
        user: state.user,
        isPowerUser: state.isPowerUser,
        
        essentialPaths: ESSENTIAL_PATHS.reduce((acc, path) => {
          const value = (state.partialSettings as Record<string, unknown>)[path];
          if (value !== undefined) {
            acc[path] = value;
          }
          return acc;
        }, {} as Record<string, any>)
      }),
      merge: (persistedState: any, currentState: SettingsState): SettingsState => {
        if (!persistedState) return currentState;
        
        return {
          ...currentState,
          authenticated: persistedState.authenticated || false,
          user: persistedState.user || null,
          isPowerUser: persistedState.isPowerUser || false,
          
        };
      },
      onRehydrateStorage: () => (state) => {
        if (state) {
          if (debugState.isEnabled()) {
            logger.info('Settings store rehydrated from storage');
          }
        }
      }
    }
  )
)

// Helper function to get paths for a specific section
function getSectionPaths(section: string): string[] {
  const sectionPathMap: Record<string, string[]> = {
    'physics': [
      'visualisation.graphs.logseq.physics',
      'visualisation.graphs.visionflow.physics'
    ],
    'rendering': [
      'visualisation.rendering.ambientLightIntensity',
      'visualisation.rendering.backgroundColor',
      'visualisation.rendering.directionalLightIntensity',
      'visualisation.rendering.enableAmbientOcclusion',
      'visualisation.rendering.enableAntialiasing',
      'visualisation.rendering.enableShadows',
      'visualisation.rendering.environmentIntensity',
      'visualisation.rendering.shadowMapSize',
      'visualisation.rendering.shadowBias',
      'visualisation.rendering.context'
    ],
    'xr': [
      'xr.enabled',
      'xr.mode',
      'xr.enableHandTracking',
      'xr.enableHaptics',
      'xr.quality'
    ],
    'glow': [
      'visualisation.glow.enabled',
      'visualisation.glow.intensity',
      'visualisation.glow.radius',
      'visualisation.glow.threshold'
    ],
    'hologram': [
      'visualisation.hologram.ringCount',
      'visualisation.hologram.ringColor',
      'visualisation.hologram.globalRotationSpeed'
    ],
    'nodes': [
      'visualisation.graphs.logseq.nodes',
      'visualisation.graphs.visionflow.nodes'
    ],
    'edges': [
      'visualisation.graphs.logseq.edges',
      'visualisation.graphs.visionflow.edges'
    ],
    'labels': [
      'visualisation.graphs.logseq.labels',
      'visualisation.graphs.visionflow.labels'
    ]
  };

  return sectionPathMap[section] || [];
}

// Helper function to set nested value by dot notation path
function setNestedValue(obj: any, path: string, value: any): void {
  const keys = path.split('.');
  let current = obj;
  
  for (let i = 0; i < keys.length - 1; i++) {
    const key = keys[i];
    if (!(key in current) || typeof current[key] !== 'object' || current[key] === null) {
      current[key] = {};
    }
    current = current[key];
  }
  
  current[keys[keys.length - 1]] = value;
}

// Helper function to extract all paths from a settings object
function getAllSettingsPaths(obj: any, prefix: string = ''): string[] {
  const paths: string[] = [];
  
  if (obj && typeof obj === 'object') {
    for (const [key, value] of Object.entries(obj)) {
      const currentPath = prefix ? `${prefix}.${key}` : key;
      
      if (value && typeof value === 'object' && !Array.isArray(value)) {
        
        paths.push(...getAllSettingsPaths(value, currentPath));
      } else {
        
        paths.push(currentPath);
      }
    }
  }
  
  return paths;
}

// Helper function to get all available settings paths for comprehensive operations
function getAllAvailableSettingsPaths(): string[] {
  
  
  return [
    
    ...ESSENTIAL_PATHS,
    
    
    'visualisation.rendering.ambientLightIntensity',
    'visualisation.rendering.backgroundColor', 
    'visualisation.rendering.directionalLightIntensity',
    'visualisation.rendering.enableAmbientOcclusion',
    'visualisation.rendering.enableAntialiasing',
    'visualisation.rendering.enableShadows',
    'visualisation.rendering.environmentIntensity',
    'visualisation.rendering.shadowMapSize',
    'visualisation.rendering.shadowBias',
    
    
    'visualisation.graphs.logseq.nodes',
    'visualisation.graphs.logseq.edges', 
    'visualisation.graphs.logseq.labels',
    'visualisation.graphs.logseq.physics',
    'visualisation.graphs.visionflow.nodes',
    'visualisation.graphs.visionflow.edges',
    'visualisation.graphs.visionflow.labels', 
    'visualisation.graphs.visionflow.physics',
    
    
    'visualisation.glow.enabled',
    'visualisation.glow.intensity',
    'visualisation.glow.radius',
    'visualisation.glow.threshold',
    'visualisation.hologram.ringCount',
    'visualisation.hologram.ringColor',
    'visualisation.hologram.globalRotationSpeed',
    
    
    'xr.enableHandTracking',
    'xr.enableHaptics',
    'xr.quality',
    
    
    'system.performance.maxFPS',
    'system.performance.enableVSync',
    'system.websocket.url',
    'system.websocket.protocol',
    
    
  ];
}

// Export for testing and direct access
export const settingsStoreUtils = {
  getSectionPaths,
  setNestedValue,
  getAllSettingsPaths,
  getAllAvailableSettingsPaths
};

--------------------------------------------------------------------------------
FILE: client/src/store/multiUserStore.ts
PURPOSE: Multi-user collaboration state
--------------------------------------------------------------------------------
import { create } from 'zustand'
import { subscribeWithSelector } from 'zustand/middleware'
import { createLogger } from '../utils/loggerConfig'
import { useRef, useEffect } from 'react'

const logger = createLogger('MultiUserStore')

export interface UserData {
  id: string
  name?: string
  position: [number, number, number]
  rotation: [number, number, number]
  isSelecting: boolean
  selectedNodeId?: string
  lastUpdate: number
  color?: string
}

interface MultiUserState {
  localUserId: string
  users: Record<string, UserData>
  connectionStatus: 'disconnected' | 'connecting' | 'connected'

  
  setLocalUserId: (userId: string) => void
  updateUser: (userId: string, data: Partial<UserData>) => void
  removeUser: (userId: string) => void
  updateLocalPosition: (position: [number, number, number], rotation: [number, number, number]) => void
  updateLocalSelection: (isSelecting: boolean, selectedNodeId?: string) => void
  setConnectionStatus: (status: 'disconnected' | 'connecting' | 'connected') => void
  clearStaleUsers: (staleThreshold?: number) => void
}

export const useMultiUserStore = create<MultiUserState>()(
  subscribeWithSelector((set, get) => ({
    localUserId: '',
    users: {},
    connectionStatus: 'disconnected',

    setLocalUserId: (userId) => {
      set({ localUserId: userId })
      logger.info('Local user ID set:', userId)
    },

    updateUser: (userId, data) => {
      set((state) => ({
        users: {
          ...state.users,
          [userId]: {
            ...state.users[userId],
            ...data,
            id: userId,
            lastUpdate: Date.now()
          }
        }
      }))
    },

    removeUser: (userId) => {
      set((state) => {
        const { [userId]: removed, ...remaining } = state.users
        logger.info('User removed:', userId)
        return { users: remaining }
      })
    },

    updateLocalPosition: (position, rotation) => {
      const { localUserId, updateUser } = get()
      if (localUserId) {
        updateUser(localUserId, { position, rotation })
      }
    },

    updateLocalSelection: (isSelecting, selectedNodeId) => {
      const { localUserId, updateUser } = get()
      if (localUserId) {
        updateUser(localUserId, { isSelecting, selectedNodeId })
      }
    },

    setConnectionStatus: (status) => {
      set({ connectionStatus: status })
      logger.info('Connection status:', status)
    },

    clearStaleUsers: (staleThreshold = 30000) => {
      const now = Date.now()
      set((state) => {
        const activeUsers = Object.entries(state.users).reduce((acc, [userId, userData]) => {
          if (now - userData.lastUpdate < staleThreshold || userId === state.localUserId) {
            acc[userId] = userData
          } else {
            logger.info('Removing stale user:', userId)
          }
          return acc
        }, {} as Record<string, UserData>)

        return { users: activeUsers }
      })
    }
  }))
)

// WebSocket connection manager for multi-user synchronization
export class MultiUserConnection {
  private ws: WebSocket | null = null
  private reconnectInterval: NodeJS.Timeout | null = null
  private heartbeatInterval: NodeJS.Timeout | null = null

  constructor(private url: string) {}

  connect() {
    const store = useMultiUserStore.getState()
    store.setConnectionStatus('connecting')

    try {
      this.ws = new WebSocket(this.url)

      this.ws.onopen = () => {
        logger.info('WebSocket connected')
        store.setConnectionStatus('connected')
        this.startHeartbeat()

        
        const { localUserId } = store
        if (localUserId) {
          this.send({
            type: 'join',
            userId: localUserId,
            timestamp: Date.now()
          })
        }
      }

      this.ws.onmessage = (event) => {
        try {
          const message = JSON.parse(event.data)
          this.handleMessage(message)
        } catch (error) {
          logger.error('Failed to parse message:', error)
        }
      }

      this.ws.onclose = () => {
        logger.info('WebSocket disconnected')
        store.setConnectionStatus('disconnected')
        this.stopHeartbeat()
        this.scheduleReconnect()
      }

      this.ws.onerror = (error) => {
        logger.error('WebSocket error:', error)
      }
    } catch (error) {
      logger.error('Failed to connect:', error)
      store.setConnectionStatus('disconnected')
      this.scheduleReconnect()
    }
  }

  private handleMessage(message: any) {
    const store = useMultiUserStore.getState()

    switch (message.type) {
      case 'userUpdate':
        if (message.userId !== store.localUserId) {
          store.updateUser(message.userId, message.data)
        }
        break

      case 'userLeft':
        store.removeUser(message.userId)
        break

      case 'sync':
        
        Object.entries(message.users).forEach(([userId, userData]) => {
          if (userId !== store.localUserId) {
            store.updateUser(userId, userData as Partial<UserData>)
          }
        })
        break

      case 'pong':
        
        break

      default:
        logger.warn('Unknown message type:', message.type)
    }
  }

  send(data: any) {
    if (this.ws?.readyState === WebSocket.OPEN) {
      this.ws.send(JSON.stringify(data))
    }
  }

  disconnect() {
    this.stopHeartbeat()
    if (this.reconnectInterval) {
      clearInterval(this.reconnectInterval)
      this.reconnectInterval = null
    }
    if (this.ws) {
      this.ws.close()
      this.ws = null
    }
  }

  private startHeartbeat() {
    this.heartbeatInterval = setInterval(() => {
      this.send({ type: 'ping', timestamp: Date.now() })
    }, 5000)
  }

  private stopHeartbeat() {
    if (this.heartbeatInterval) {
      clearInterval(this.heartbeatInterval)
      this.heartbeatInterval = null
    }
  }

  private scheduleReconnect() {
    if (this.reconnectInterval) return

    this.reconnectInterval = setInterval(() => {
      logger.info('Attempting to reconnect...')
      this.connect()
    }, 5000)
  }
}

// Hook for tracking user position in XR
export const useXRUserTracking = () => {
  const updateLocalPosition = useMultiUserStore(state => state.updateLocalPosition)
  const updateLocalSelection = useMultiUserStore(state => state.updateLocalSelection)
  const connection = useRef<MultiUserConnection | null>(null)

  
  useEffect(() => {
    const unsubscribe = useMultiUserStore.subscribe(
      state => state.users[state.localUserId],
      (userData) => {
        if (userData && connection.current) {
          connection.current.send({
            type: 'userUpdate',
            userId: userData.id,
            data: {
              position: userData.position,
              rotation: userData.rotation,
              isSelecting: userData.isSelecting,
              selectedNodeId: userData.selectedNodeId
            }
          })
        }
      }
    )

    return unsubscribe
  }, [])

  return {
    updatePosition: updateLocalPosition,
    updateSelection: updateLocalSelection
  }
}
--------------------------------------------------------------------------------
FILE: client/src/store/autoSaveManager.ts
PURPOSE: Automatic settings persistence
--------------------------------------------------------------------------------
import { createLogger } from '../utils/loggerConfig';
import { toast } from '../features/design-system/components/Toast';
import { settingsApi } from '../api/settingsApi';

interface BatchOperation {
  path: string;
  value: any;
}

const logger = createLogger('AutoSaveManager');


export class AutoSaveManager {
  private pendingChanges: Map<string, any> = new Map();
  private saveDebounceTimer: NodeJS.Timeout | null = null;
  private isInitialized: boolean = false;
  private retryCount: Map<string, number> = new Map();
  private readonly MAX_RETRIES = 3;
  private readonly DEBOUNCE_DELAY = 500; 
  private readonly RETRY_DELAY = 1000; 

  
  private readonly CLIENT_ONLY_PATHS = [
    'auth.nostr.connected',
    'auth.nostr.publicKey',
  ];

  
  private isClientOnlyPath(path: string): boolean {
    return this.CLIENT_ONLY_PATHS.some(clientPath =>
      path === clientPath || path.startsWith(clientPath + '.')
    );
  }

  setInitialized(initialized: boolean) {
    this.isInitialized = initialized;
  }

  
  queueChange(path: string, value: any) {
    if (!this.isInitialized) return;

    
    if (this.isClientOnlyPath(path)) {
      logger.debug(`Skipping client-only path: ${path}`);
      return;
    }

    this.pendingChanges.set(path, value);
    this.resetRetryCount(path);
    this.scheduleFlush();
  }

  
  queueChanges(changes: Map<string, any>) {
    if (!this.isInitialized) return;

    changes.forEach((value, path) => {
      
      if (this.isClientOnlyPath(path)) {
        logger.debug(`Skipping client-only path: ${path}`);
        return;
      }

      this.pendingChanges.set(path, value);
      this.resetRetryCount(path);
    });
    this.scheduleFlush();
  }

  
  private scheduleFlush() {
    if (this.saveDebounceTimer) {
      clearTimeout(this.saveDebounceTimer);
    }
    
    this.saveDebounceTimer = setTimeout(() => {
      this.flushPendingChanges();
    }, this.DEBOUNCE_DELAY);
  }

  
  async forceFlush(): Promise<void> {
    if (this.saveDebounceTimer) {
      clearTimeout(this.saveDebounceTimer);
      this.saveDebounceTimer = null;
    }
    await this.flushPendingChanges();
  }

  
  private async flushPendingChanges(): Promise<void> {
    if (this.pendingChanges.size === 0) return;
    
    const updates: BatchOperation[] = Array.from(this.pendingChanges.entries())
      .map(([path, value]) => ({ path, value }));
    
    logger.debug('Auto-save: Attempting to flush changes', { count: updates.length, paths: updates.map(u => u.path) });
    
    try {
      await settingsApi.updateSettingsByPaths(updates);
      
      
      updates.forEach(({ path }) => {
        this.pendingChanges.delete(path);
        this.resetRetryCount(path);
      });
      
      logger.info('Auto-save: Successfully flushed pending changes', { count: updates.length });
    } catch (error) {
      logger.error('Auto-save: Failed to flush changes', { error, updatesCount: updates.length });
      
      
      await this.retryFailedChanges(updates, error);
    }
  }

  
  private async retryFailedChanges(failedUpdates: BatchOperation[], error: any): Promise<void> {
    let hasRetriableChanges = false;
    let hasMaxedOutChanges = false;
    
    for (const { path } of failedUpdates) {
      const currentRetries = this.retryCount.get(path) || 0;
      
      if (currentRetries < this.MAX_RETRIES) {
        this.retryCount.set(path, currentRetries + 1);
        hasRetriableChanges = true;
        
        
        const retryDelay = this.RETRY_DELAY * Math.pow(2, currentRetries);
        
        setTimeout(() => {
          if (this.pendingChanges.has(path)) {
            logger.info(`Auto-save: Retrying save for path ${path} (attempt ${currentRetries + 1}/${this.MAX_RETRIES})`);
            this.scheduleFlush();
          } else {
            logger.debug(`Auto-save: Path ${path} no longer pending, skipping retry`);
          }
        }, retryDelay);
      } else {
        
        hasMaxedOutChanges = true;
        logger.error(`Auto-save: Max retries exceeded for path ${path}`, { error, maxRetries: this.MAX_RETRIES });
        
        
        try {
          if (typeof toast === 'function') {
            (toast as any).error?.(`Failed to save setting: ${path.split('.').pop()}. Changes are queued for retry.`);
          } else if (toast && typeof (toast as any).error === 'function') {
            (toast as any).error(`Failed to save setting: ${path.split('.').pop()}. Changes are queued for retry.`);
          }
        } catch {
          // Silently ignore toast errors
        }
      }
    }
    
    
    if (hasRetriableChanges && hasMaxedOutChanges) {
      logger.warn(`Auto-save: Some changes will be retried, others have exceeded max retries`);
    } else if (hasRetriableChanges) {
      logger.info(`Auto-save: All failed changes scheduled for retry`);
    } else if (hasMaxedOutChanges) {
      logger.error(`Auto-save: All failed changes have exceeded max retries`);
    }
  }

  private resetRetryCount(path: string) {
    this.retryCount.delete(path);
  }

  
  hasPendingChanges(): boolean {
    return this.pendingChanges.size > 0;
  }

  
  getPendingCount(): number {
    return this.pendingChanges.size;
  }
}

// Export singleton instance
export const autoSaveManager = new AutoSaveManager();
================================================================================
                    SECTION 14: CLIENT TYPES
================================================================================

--------------------------------------------------------------------------------
FILE: client/src/types/websocketTypes.ts
PURPOSE: WebSocket message interfaces
--------------------------------------------------------------------------------


// Base WebSocket message structure
export interface BaseWebSocketMessage {
  type: string;
  timestamp: number;
  clientId?: string;
  sessionId?: string;
}

// Workspace-related messages
export interface WorkspaceUpdateMessage extends BaseWebSocketMessage {
  type: 'workspace_update';
  data: {
    workspaceId: string;
    changes: Partial<{
      name: string;
      description: string;
      status: 'active' | 'archived';
      memberCount: number;
      favorite: boolean;
      lastAccessed: string;
      settings: Record<string, any>;
    }>;
    userId?: string;
    operation: 'create' | 'update' | 'delete' | 'favorite' | 'archive';
  };
}

export interface WorkspaceDeletedMessage extends BaseWebSocketMessage {
  type: 'workspace_deleted';
  data: {
    workspaceId: string;
    userId?: string;
  };
}

export interface WorkspaceCollaborationMessage extends BaseWebSocketMessage {
  type: 'workspace_collaboration';
  data: {
    workspaceId: string;
    action: 'user_joined' | 'user_left' | 'permission_changed';
    userId: string;
    userName?: string;
    permissions?: string[];
  };
}

// Analysis-related messages
export interface AnalysisProgressMessage extends BaseWebSocketMessage {
  type: 'analysis_progress';
  data: {
    analysisId: string;
    graphId?: string;
    progress: number; 
    stage: string;
    estimatedTimeRemaining?: number;
    currentOperation: string;
    metrics?: {
      nodesProcessed: number;
      edgesProcessed: number;
      clustersFound?: number;
      similarityScore?: number;
    };
  };
}

export interface AnalysisCompleteMessage extends BaseWebSocketMessage {
  type: 'analysis_complete';
  data: {
    analysisId: string;
    graphId?: string;
    results: {
      similarity: {
        overall: number;
        structural: number;
        semantic: number;
      };
      matches: number;
      differences: number;
      clusters: number;
      centrality: {
        betweenness: number;
        closeness: number;
        eigenvector: number;
      };
      processing_time: number;
    };
    success: boolean;
    error?: string;
  };
}

export interface AnalysisErrorMessage extends BaseWebSocketMessage {
  type: 'analysis_error';
  data: {
    analysisId: string;
    graphId?: string;
    error: string;
    stage: string;
    retryable: boolean;
  };
}

// Optimization-related messages
export interface OptimizationUpdateMessage extends BaseWebSocketMessage {
  type: 'optimization_update';
  data: {
    optimizationId: string;
    graphId?: string;
    progress: number; 
    algorithm: string;
    currentIteration: number;
    totalIterations: number;
    metrics: {
      performanceGain: number;
      confidence: number;
      energyLevel?: number;
      convergence?: number;
    };
    recommendations?: Array<{
      type: string;
      priority: 'low' | 'medium' | 'high';
      description: string;
    }>;
  };
}

export interface OptimizationResultMessage extends BaseWebSocketMessage {
  type: 'optimization_result';
  data: {
    optimizationId: string;
    graphId?: string;
    algorithm: string;
    confidence: number;
    performanceGain: number;
    clusters: number;
    recommendations: Array<{
      type: string;
      priority: 'low' | 'medium' | 'high';
      description: string;
    }>;
    layoutChanges?: {
      nodesRepositioned: number;
      clustersFormed: number;
      edgesOptimized: number;
    };
    success: boolean;
    error?: string;
  };
}

// Export-related messages
export interface ExportProgressMessage extends BaseWebSocketMessage {
  type: 'export_progress';
  data: {
    exportId: string;
    graphId?: string;
    format: string;
    progress: number; 
    stage: 'preparing' | 'processing' | 'rendering' | 'finalizing' | 'uploading';
    size?: number;
    estimatedTimeRemaining?: number;
  };
}

export interface ExportReadyMessage extends BaseWebSocketMessage {
  type: 'export_ready';
  data: {
    exportId: string;
    graphId?: string;
    format: string;
    downloadUrl: string;
    size: number;
    expiresAt: string;
    metadata: {
      resolution?: string;
      compressionUsed: boolean;
      includedMetadata: boolean;
    };
  };
}

export interface ShareCreatedMessage extends BaseWebSocketMessage {
  type: 'share_created';
  data: {
    shareId: string;
    graphId?: string;
    shareUrl: string;
    expiresAt?: string;
    passwordProtected: boolean;
    permissions: string[];
    description?: string;
  };
}

export interface ShareAccessMessage extends BaseWebSocketMessage {
  type: 'share_access';
  data: {
    shareId: string;
    action: 'accessed' | 'downloaded' | 'expired';
    userId?: string;
    ipAddress?: string;
    userAgent?: string;
  };
}

// System and connection messages
export interface ConnectionStatusMessage extends BaseWebSocketMessage {
  type: 'connection_status';
  data: {
    status: 'connected' | 'disconnected' | 'reconnecting' | 'error';
    serverLoad?: number;
    latency?: number;
    features: string[];
  };
}

export interface SystemNotificationMessage extends BaseWebSocketMessage {
  type: 'system_notification';
  data: {
    level: 'info' | 'warning' | 'error';
    title: string;
    message: string;
    actions?: Array<{
      label: string;
      action: string;
    }>;
    persistent?: boolean;
  };
}

export interface UserActivityMessage extends BaseWebSocketMessage {
  type: 'user_activity';
  data: {
    userId: string;
    userName?: string;
    action: string;
    resource: string;
    resourceId?: string;
    metadata?: Record<string, any>;
  };
}

// Performance and metrics messages
export interface PerformanceMetricsMessage extends BaseWebSocketMessage {
  type: 'performance_metrics';
  data: {
    metrics: {
      cpu: number;
      memory: number;
      network: number;
      renderTime: number;
      frameRate: number;
    };
    graphId?: string;
    nodeCount?: number;
    edgeCount?: number;
  };
}

export interface ServerHealthMessage extends BaseWebSocketMessage {
  type: 'server_health';
  data: {
    status: 'healthy' | 'degraded' | 'unhealthy';
    services: Array<{
      name: string;
      status: 'up' | 'down' | 'degraded';
      latency?: number;
    }>;
    load: {
      cpu: number;
      memory: number;
      activeConnections: number;
    };
  };
}

// Graph Interaction messages
export interface GraphProcessingProgressMessage extends BaseWebSocketMessage {
  type: 'graph_processing_progress';
  data: {
    taskId: string;
    graphId?: string;
    progress: number; 
    stage: string;
    currentOperation: string;
    estimatedTimeRemaining?: number;
    metrics?: {
      stepsProcessed: number;
      totalSteps: number;
      currentStep: string;
      operationsCompleted: number;
    };
  };
}

export interface GraphProcessingCompleteMessage extends BaseWebSocketMessage {
  type: 'graph_processing_complete';
  data: {
    taskId: string;
    graphId?: string;
    success: boolean;
    results?: any;
    processedSteps?: number;
    totalTime?: number;
    error?: string;
  };
}

export interface GraphProcessingErrorMessage extends BaseWebSocketMessage {
  type: 'graph_processing_error';
  data: {
    taskId: string;
    graphId?: string;
    error: string;
    stage: string;
    retryable: boolean;
  };
}

export interface TimeTraverseProgressMessage extends BaseWebSocketMessage {
  type: 'time_traverse_progress';
  data: {
    taskId: string;
    graphId?: string;
    progress: number; 
    stage: string;
    currentStep: number;
    totalSteps: number;
    stepName?: string;
    estimatedTimeRemaining?: number;
  };
}

export interface TimeTraverseCompleteMessage extends BaseWebSocketMessage {
  type: 'time_traverse_complete';
  data: {
    taskId: string;
    graphId?: string;
    success: boolean;
    totalSteps: number;
    timeline?: any;
    processingTime?: number;
    error?: string;
  };
}

export interface CollaborationSessionMessage extends BaseWebSocketMessage {
  type: 'collaboration_session';
  data: {
    sessionId: string;
    action: 'created' | 'user_joined' | 'user_left' | 'ended';
    userId?: string;
    userName?: string;
    participantCount: number;
    shareUrl?: string;
  };
}

export interface VRARModeMessage extends BaseWebSocketMessage {
  type: 'vr_ar_mode';
  data: {
    sessionId: string;
    mode: 'vr' | 'ar' | 'disabled';
    userId?: string;
    features: {
      handTracking: boolean;
      hapticFeedback: boolean;
      spatialAudio?: boolean;
    };
  };
}

export interface ExplorationTourMessage extends BaseWebSocketMessage {
  type: 'exploration_tour';
  data: {
    tourId: string;
    action: 'created' | 'updated' | 'waypoint_added' | 'completed';
    waypoints?: Array<{
      nodeId: string;
      description: string;
      order: number;
    }>;
    progress?: number;
  };
}

// Connection and protocol messages
export interface ConnectionEstablishedMessage extends BaseWebSocketMessage {
  type: 'connection_established';
  data?: {
    serverVersion?: string;
    features?: string[];
  };
}

export interface ErrorMessage extends BaseWebSocketMessage {
  type: 'error';
  error: string;
  data?: Record<string, unknown>;
}

export interface FilterConfirmedMessage extends BaseWebSocketMessage {
  type: 'filter_confirmed';
  data: {
    visible_nodes: number;
    total_nodes: number;
  };
}

export interface InitialGraphLoadMessage extends BaseWebSocketMessage {
  type: 'initialGraphLoad';
  nodes: Array<{
    id: string | number;
    label?: string;
    name?: string;
    position?: { x: number; y: number; z: number };
    x?: number;
    y?: number;
    z?: number;
    metadata?: Record<string, unknown>;
    quality_score?: number;
    authority_score?: number;
    color?: string;
    size?: number;
  }>;
  edges: Array<{
    id?: string;
    source: string | number;
    target: string | number;
    weight?: number;
    label?: string;
  }>;
}

// Union type of all possible WebSocket messages
export type WebSocketMessage =
  | WorkspaceUpdateMessage
  | WorkspaceDeletedMessage
  | WorkspaceCollaborationMessage
  | AnalysisProgressMessage
  | AnalysisCompleteMessage
  | AnalysisErrorMessage
  | OptimizationUpdateMessage
  | OptimizationResultMessage
  | ExportProgressMessage
  | ExportReadyMessage
  | ShareCreatedMessage
  | ShareAccessMessage
  | ConnectionStatusMessage
  | SystemNotificationMessage
  | UserActivityMessage
  | PerformanceMetricsMessage
  | ServerHealthMessage
  | GraphProcessingProgressMessage
  | GraphProcessingCompleteMessage
  | GraphProcessingErrorMessage
  | TimeTraverseProgressMessage
  | TimeTraverseCompleteMessage
  | CollaborationSessionMessage
  | VRARModeMessage
  | ExplorationTourMessage
  | ConnectionEstablishedMessage
  | ErrorMessage
  | FilterConfirmedMessage
  | InitialGraphLoadMessage;

// Event handler types
export type MessageHandler<T extends WebSocketMessage = WebSocketMessage> = (message: T) => void;

export interface WebSocketEventHandlers {
  
  workspace_update: MessageHandler<WorkspaceUpdateMessage>;
  workspace_deleted: MessageHandler<WorkspaceDeletedMessage>;
  workspace_collaboration: MessageHandler<WorkspaceCollaborationMessage>;

  
  analysis_progress: MessageHandler<AnalysisProgressMessage>;
  analysis_complete: MessageHandler<AnalysisCompleteMessage>;
  analysis_error: MessageHandler<AnalysisErrorMessage>;

  
  optimization_update: MessageHandler<OptimizationUpdateMessage>;
  optimization_result: MessageHandler<OptimizationResultMessage>;

  
  export_progress: MessageHandler<ExportProgressMessage>;
  export_ready: MessageHandler<ExportReadyMessage>;
  share_created: MessageHandler<ShareCreatedMessage>;
  share_access: MessageHandler<ShareAccessMessage>;

  
  connection_status: MessageHandler<ConnectionStatusMessage>;
  system_notification: MessageHandler<SystemNotificationMessage>;
  user_activity: MessageHandler<UserActivityMessage>;
  performance_metrics: MessageHandler<PerformanceMetricsMessage>;
  server_health: MessageHandler<ServerHealthMessage>;

  
  graph_processing_progress: MessageHandler<GraphProcessingProgressMessage>;
  graph_processing_complete: MessageHandler<GraphProcessingCompleteMessage>;
  graph_processing_error: MessageHandler<GraphProcessingErrorMessage>;
  time_traverse_progress: MessageHandler<TimeTraverseProgressMessage>;
  time_traverse_complete: MessageHandler<TimeTraverseCompleteMessage>;
  collaboration_session: MessageHandler<CollaborationSessionMessage>;
  vr_ar_mode: MessageHandler<VRARModeMessage>;
  exploration_tour: MessageHandler<ExplorationTourMessage>;
}

// Configuration interfaces
export interface WebSocketConfig {
  url?: string;
  protocols?: string[];
  reconnect: {
    maxAttempts: number;
    baseDelay: number;
    maxDelay: number;
    backoffFactor: number;
  };
  heartbeat: {
    interval: number;
    timeout: number;
  };
  compression: boolean;
  binaryProtocol: boolean;
}

export interface WebSocketConnectionState {
  status: 'disconnected' | 'connecting' | 'connected' | 'reconnecting' | 'failed';
  lastConnected?: number;
  lastError?: string;
  reconnectAttempts: number;
  serverFeatures: string[];
  latency?: number;
}

// Subscription management
export interface Subscription {
  id: string;
  type: keyof WebSocketEventHandlers;
  handler: MessageHandler;
  options?: {
    once?: boolean;
    filter?: (message: WebSocketMessage) => boolean;
  };
}

export interface SubscriptionFilters {
  workspaceId?: string;
  userId?: string;
  graphId?: string;
  analysisId?: string;
  optimizationId?: string;
  exportId?: string;
}

// Error types
export interface WebSocketError {
  code: string;
  message: string;
  type: 'connection' | 'protocol' | 'auth' | 'rate_limit' | 'server' | 'client';
  retryable: boolean;
  retryAfter?: number;
  context?: Record<string, any>;
}

// Statistics and monitoring
export interface WebSocketStatistics {
  messagesReceived: number;
  messagesSent: number;
  bytesReceived: number;
  bytesSent: number;
  connectionTime: number;
  reconnections: number;
  averageLatency: number;
  messagesByType: Record<string, number>;
  errors: number;
  lastActivity: number;
}
--------------------------------------------------------------------------------
FILE: client/src/types/binaryProtocol.ts
PURPOSE: Binary protocol type definitions
--------------------------------------------------------------------------------


export interface Vec3 {
  x: number;
  y: number;
  z: number;
}

export interface BinaryNodeData {
  nodeId: number;
  position: Vec3;
  velocity: Vec3;
  ssspDistance: number;  
  ssspParent: number;    
}


export const BINARY_NODE_SIZE = 36;
export const BINARY_NODE_ID_OFFSET = 0;
export const BINARY_POSITION_OFFSET = 4;  
export const BINARY_VELOCITY_OFFSET = 16; 
export const BINARY_SSSP_DISTANCE_OFFSET = 28; 
export const BINARY_SSSP_PARENT_OFFSET = 32;   

// Node type flag constants (Protocol V2 - must match server)
export const AGENT_NODE_FLAG = 0x80000000;     
export const KNOWLEDGE_NODE_FLAG = 0x40000000; 
export const NODE_ID_MASK = 0x3FFFFFFF;        

export enum NodeType {
  Knowledge = 'knowledge',
  Agent = 'agent',
  Unknown = 'unknown'
}

export function getNodeType(nodeId: number): NodeType {
  if ((nodeId & AGENT_NODE_FLAG) !== 0) {
    return NodeType.Agent;
  } else if ((nodeId & KNOWLEDGE_NODE_FLAG) !== 0) {
    return NodeType.Knowledge;
  }
  return NodeType.Unknown;
}

export function getActualNodeId(nodeId: number): number {
  return nodeId & NODE_ID_MASK;
}

export function isAgentNode(nodeId: number): boolean {
  return (nodeId & AGENT_NODE_FLAG) !== 0;
}

export function isKnowledgeNode(nodeId: number): boolean {
  return (nodeId & KNOWLEDGE_NODE_FLAG) !== 0;
}


export function parseBinaryNodeData(buffer: ArrayBuffer): BinaryNodeData[] {
  if (!buffer || buffer.byteLength === 0) {
    return [];
  }

  
  const safeBuffer = buffer.slice(0);
  const view = new DataView(safeBuffer);
  const nodes: BinaryNodeData[] = [];

  try {
    
    let offset = 0;
    const nodeSize = BINARY_NODE_SIZE; 

    if (safeBuffer.byteLength > 0) {
      const firstByte = view.getUint8(0);

      
      if (firstByte === 2) {
        offset = 1; 
      } else if (firstByte === 1) {
        console.error('PROTOCOL_V1 is no longer supported. Please upgrade to V2.');
        return [];
      }
    }

    const dataLength = safeBuffer.byteLength - offset;

    
    if (dataLength % nodeSize !== 0) {
      console.warn(`Binary data length (${dataLength} bytes after version byte) is not a multiple of ${nodeSize}. This may indicate compressed data.`);
      console.warn(`First few bytes: ${new Uint8Array(safeBuffer.slice(0, Math.min(16, safeBuffer.byteLength))).join(', ')}`);

      
      const header = new Uint8Array(safeBuffer.slice(0, Math.min(4, safeBuffer.byteLength)));
      if (header[0] === 0x78 && (header[1] === 0x01 || header[1] === 0x5E || header[1] === 0x9C || header[1] === 0xDA)) {
        console.error("Data appears to be zlib compressed but decompression failed or wasn't attempted");
      }
    }

    
    const completeNodes = Math.floor(dataLength / nodeSize);

    if (completeNodes === 0) {
      console.warn(`Received binary data with insufficient length: ${dataLength} bytes (needed at least ${nodeSize} bytes per node)`);
      return [];
    }
    
    
    for (let i = 0; i < completeNodes; i++) {
      const nodeOffset = offset + (i * nodeSize);

      
      if (nodeOffset + nodeSize > safeBuffer.byteLength) {
        break;
      }

      
      const nodeId = view.getUint32(nodeOffset + BINARY_NODE_ID_OFFSET, true);
      const position: Vec3 = {
        x: view.getFloat32(nodeOffset + BINARY_POSITION_OFFSET, true),
        y: view.getFloat32(nodeOffset + BINARY_POSITION_OFFSET + 4, true),
        z: view.getFloat32(nodeOffset + BINARY_POSITION_OFFSET + 8, true)
      };
      const velocity: Vec3 = {
        x: view.getFloat32(nodeOffset + BINARY_VELOCITY_OFFSET, true),
        y: view.getFloat32(nodeOffset + BINARY_VELOCITY_OFFSET + 4, true),
        z: view.getFloat32(nodeOffset + BINARY_VELOCITY_OFFSET + 8, true)
      };
      const ssspDistance = view.getFloat32(nodeOffset + BINARY_SSSP_DISTANCE_OFFSET, true);
      const ssspParent = view.getInt32(nodeOffset + BINARY_SSSP_PARENT_OFFSET, true);

      
      const isValid =
        !isNaN(position.x) && isFinite(position.x) &&
        !isNaN(position.y) && isFinite(position.y) &&
        !isNaN(position.z) && isFinite(position.z) &&
        !isNaN(velocity.x) && isFinite(velocity.x) &&
        !isNaN(velocity.y) && isFinite(velocity.y) &&
        !isNaN(velocity.z) && isFinite(velocity.z);

      if (isValid) {
        nodes.push({ nodeId, position, velocity, ssspDistance, ssspParent });
      } else {
        console.warn(`Skipping corrupted node data at offset ${offset} (nodeId: ${nodeId})`);
      }
    }
  } catch (error) {
    console.error('Error parsing binary data:', error);
    
  }

  return nodes;
}


export function createBinaryNodeData(nodes: BinaryNodeData[]): ArrayBuffer {
  const buffer = new ArrayBuffer(nodes.length * BINARY_NODE_SIZE);
  const view = new DataView(buffer);
  
  nodes.forEach((node, i) => {
    const offset = i * BINARY_NODE_SIZE;

    
    view.setUint32(offset + BINARY_NODE_ID_OFFSET, node.nodeId, true);

    
    view.setFloat32(offset + BINARY_POSITION_OFFSET, node.position.x, true);
    view.setFloat32(offset + BINARY_POSITION_OFFSET + 4, node.position.y, true);
    view.setFloat32(offset + BINARY_POSITION_OFFSET + 8, node.position.z, true);

    
    view.setFloat32(offset + BINARY_VELOCITY_OFFSET, node.velocity.x, true);
    view.setFloat32(offset + BINARY_VELOCITY_OFFSET + 4, node.velocity.y, true);
    view.setFloat32(offset + BINARY_VELOCITY_OFFSET + 8, node.velocity.z, true);

    
    view.setFloat32(offset + BINARY_SSSP_DISTANCE_OFFSET, node.ssspDistance || Infinity, true);

    
    view.setInt32(offset + BINARY_SSSP_PARENT_OFFSET, node.ssspParent || -1, true);
  });
  
  return buffer;
}
--------------------------------------------------------------------------------
FILE: client/src/types/nip07.d.ts
PURPOSE: Nostr NIP-07 type definitions
--------------------------------------------------------------------------------
// Type definitions for NIP-07 window.nostr based on the specification
// https://github.com/nostr-protocol/nips/blob/master/07.md

import type { Event as NostrEvent, UnsignedEvent } from 'nostr-tools';

// Define the structure of the event object passed to signEvent
// Note: NIP-07 specifies the input event lacks id, pubkey, sig.
// nostr-tools' UnsignedEvent fits this description.
type Nip07Event = Omit<UnsignedEvent, 'pubkey'>; 

// Define the interface for the window.nostr object
interface NostrProvider {
  getPublicKey(): Promise<string>; 
  signEvent(event: Nip07Event): Promise<NostrEvent>; 

  
  nip44?: {
    encrypt(pubkey: string, plaintext: string): Promise<string>; 
    decrypt(pubkey: string, ciphertext: string): Promise<string>; 
  };

  
  nip04?: {
    encrypt(pubkey: string, plaintext: string): Promise<string>;
    decrypt(pubkey: string, ciphertext: string): Promise<string>;
  };

  
  getRelays?(): Promise<{ [url: string]: { read: boolean; write: boolean } }>;
}

// Augment the global Window interface
declare global {
  interface Window {
    nostr?: NostrProvider;
  }
}

// Export an empty object to ensure this is treated as a module
export {};
--------------------------------------------------------------------------------
FILE: client/src/features/graph/types/graphTypes.ts
PURPOSE: Graph node and edge types
--------------------------------------------------------------------------------


export type GraphType = 'logseq' | 'visionflow';

export interface GraphNode {
  id: string;
  label: string;
  position: {
    x: number;
    y: number;
    z: number;
  };
  metadata?: Record<string, any>;
  graphType?: GraphType;
  owlClassIri?: string;  // Ontology class IRI for semantic identity
  nodeType?: string;     // Visual node type for rendering
}

export interface GraphEdge {
  id: string;
  source: string;
  target: string;
  label?: string;
  weight?: number;
  metadata?: Record<string, any>;
  graphType?: GraphType; 
}

export interface TypedGraphData {
  nodes: GraphNode[];
  edges: GraphEdge[];
  graphType: GraphType;
  lastUpdate?: number;
}

// Message types for graph updates
export interface GraphUpdateMessage {
  type: 'node-update' | 'edge-update' | 'position-update' | 'bulk-update';
  graphType: GraphType;
  data: any;
  timestamp: number;
}

// Physics settings per graph type
export interface GraphPhysicsConfig {
  
  spring_k: number; 
  repel_k: number; 
  max_velocity: number; 
  damping: number; 
  
  
  rest_length: number; 
  repulsion_cutoff: number; 
  repulsion_softening_epsilon: number; 
  center_gravity_k: number; 
  grid_cell_size: number; 
  warmup_iterations: number; 
  cooling_rate: number; 
  feature_flags: number; 
  
  
  boundary_extreme_multiplier: number; 
  boundary_extreme_force_multiplier: number; 
  boundary_velocity_damping: number; 
  max_force: number; 
  seed: number; 
  iteration: number; 
  
  
  springStrength?: number;
  updateThreshold?: number;
  nodeRepulsion?: number;
  linkDistance?: number;
  gravityStrength?: number;
}

export interface GraphTypeConfig {
  logseq: {
    physics: GraphPhysicsConfig;
    rendering: {
      nodeSize: number;
      edgeWidth: number;
      labelSize: number;
    };
  };
  visionflow: {
    physics: GraphPhysicsConfig;
    rendering: {
      agentSize: number;
      connectionWidth: number;
      healthIndicator: boolean;
    };
  };
}

// Default configurations
export const DEFAULT_GRAPH_CONFIG: GraphTypeConfig = {
  logseq: {
    physics: {
      
      spring_k: 0.2,
      repel_k: 1.0,
      max_velocity: 5.0,
      damping: 0.95,
      
      
      rest_length: 50.0,
      repulsion_cutoff: 50.0,
      repulsion_softening_epsilon: 0.0001,
      center_gravity_k: 0.0,
      grid_cell_size: 50.0,
      warmup_iterations: 100,
      cooling_rate: 0.001,
      feature_flags: 7,
      
      
      boundary_extreme_multiplier: 2.0,
      boundary_extreme_force_multiplier: 5.0,
      boundary_velocity_damping: 0.5,
      max_force: 100,
      seed: 42,
      iteration: 0,
      
      
      springStrength: 0.2,
      updateThreshold: 0.05,
      nodeRepulsion: 10,
      linkDistance: 30
    },
    rendering: {
      nodeSize: 5,
      edgeWidth: 1,
      labelSize: 12
    }
  },
  visionflow: {
    physics: {
      
      spring_k: 0.3,
      repel_k: 2.0,
      max_velocity: 10.0,
      damping: 0.95,
      
      
      rest_length: 50.0,
      repulsion_cutoff: 50.0,
      repulsion_softening_epsilon: 0.0001,
      center_gravity_k: 0.1,
      grid_cell_size: 50.0,
      warmup_iterations: 100,
      cooling_rate: 0.001,
      feature_flags: 7,
      
      
      boundary_extreme_multiplier: 2.5,
      boundary_extreme_force_multiplier: 6.0,
      boundary_velocity_damping: 0.6,
      max_force: 120,
      seed: 42,
      iteration: 0,
      
      
      springStrength: 0.3,
      updateThreshold: 0.1,
      nodeRepulsion: 15,
      linkDistance: 20,
      gravityStrength: 0.1
    },
    rendering: {
      agentSize: 8,
      connectionWidth: 2,
      healthIndicator: true
    }
  }
};
--------------------------------------------------------------------------------
FILE: client/src/features/bots/types/BotsTypes.ts
PURPOSE: Agent/bot types for visualization
--------------------------------------------------------------------------------
// Bots visualization type definitions

// UPDATED: Enhanced agent types to match claude-flow hive-mind system (15+ types including Maestro specs-driven agents)
export interface BotsAgent {
  id: string;
  type: 'coordinator' | 'researcher' | 'coder' | 'analyst' | 'architect' | 'tester' | 'reviewer' | 'optimizer' | 'documenter' | 'monitor' | 'specialist' |
        'requirements_analyst' | 'design_architect' | 'task_planner' | 'implementation_coder' | 'quality_reviewer' | 'steering_documenter' | 'queen';
  status: 'idle' | 'busy' | 'active' | 'error' | 'initializing' | 'terminating' | 'offline';
  health: number; 
  cpuUsage: number; 
  memoryUsage: number; 
  workload?: number; 
  createdAt: string; 
  age: number; 
  name?: string;

  
  capabilities?: string[]; 
  currentTask?: string; 
  tasksActive?: number; 
  tasksCompleted?: number; 
  successRate?: number; 
  tokens?: number; 
  tokenRate?: number; 
  activity?: number; 

  
  position?: {
    x: number;
    y: number;
    z: number;
  };
  velocity?: {
    x: number;
    y: number;
    z: number;
  };

  
  ssspDistance?: number; 
  ssspParent?: number;   
  lastPositionUpdate?: number; 

  
  swarmId?: string; 
  agentMode?: 'centralized' | 'distributed' | 'strategic';
  parentQueenId?: string; 

  
  processingLogs?: string[]; 
}

export interface BotsCommunication {
  id: string;
  type: 'communication';
  timestamp: string;
  sender: string; 
  receivers: string[]; 
  metadata: {
    size: number; 
    type?: string; 
  };
}

export interface TokenUsage {
  total: number;
  byAgent: {
    [agentType: string]: number;
  };
}

export interface BotsEdge {
  id: string;
  source: string;
  target: string;
  dataVolume: number; 
  messageCount: number;
  lastMessageTime: number;
}

export interface BotsState {
  agents: Map<string, BotsAgent>;
  edges: Map<string, BotsEdge>;
  communications: BotsCommunication[];
  tokenUsage: TokenUsage;
  lastUpdate: number;
}

// MCP WebSocket message types
export interface MCPMessage {
  type: 'welcome' | 'mcp-update' | 'mcp-response' | 'ping' | 'pong';
  clientId?: string;
  data?: any;
  requestId?: string;
}

// Enhanced WebSocket message for full agent data updates
export interface BotsFullUpdateMessage {
  type: 'bots-full-update';
  agents: BotsAgent[];
  multiAgentMetrics: {
    totalAgents: number;
    activeAgents: number;
    totalTasks: number;
    completedTasks: number;
    avgSuccessRate: number;
    totalTokens: number;
  };
  timestamp: string; 
}

export interface MCPRequest {
  jsonrpc: '2.0';
  id: string;
  method: 'tools/call';
  params: {
    name: string;
    arguments: any;
  };
}

// UPDATED: Enhanced visual configuration for all claude-flow hive-mind agent types
export interface BotsVisualConfig {
  colors: {
    
    coordinator: string;
    researcher: string;
    coder: string;
    analyst: string;
    architect: string;
    tester: string;
    reviewer: string;
    optimizer: string;
    documenter: string;
    monitor: string;
    specialist: string;

    
    requirements_analyst: string;
    design_architect: string;
    task_planner: string;
    implementation_coder: string;
    quality_reviewer: string;
    steering_documenter: string;

    
    queen: string; 
  };

  
  physics: {
    springStrength: number;
    linkDistance: number;
    damping: number;
    nodeRepulsion: number;
    gravityStrength: number;
    maxVelocity: number;

    
    queenGravity: number; 
    multiAgentCohesion: number; 
    hierarchicalForce: number; 
  };

  
  sizes: {
    queen: number; 
    coordinator: number;
    architect: number;
    specialist: number;
    default: number; 
  };
}
================================================================================
                    SECTION 15: CLIENT FEATURE MODULES
================================================================================

--------------------------------------------------------------------------------
FILE: client/src/features/graph/managers/graphDataManager.ts
PURPOSE: Main graph data orchestration
--------------------------------------------------------------------------------
import { createLogger, createErrorMetadata } from '../../../utils/loggerConfig';
import { debugState, clientDebugState } from '../../../utils/clientDebugState';
import { unifiedApiClient } from '../../../services/api/UnifiedApiClient';
import { WebSocketAdapter } from '../../../services/WebSocketService';
import { useSettingsStore } from '../../../store/settingsStore';
import { BinaryNodeData, parseBinaryNodeData, createBinaryNodeData, Vec3, BINARY_NODE_SIZE } from '../../../types/binaryProtocol';
import { graphWorkerProxy } from './graphWorkerProxy';
import type { GraphData, Node, Edge } from './graphWorkerProxy';
import { startTransition } from 'react';

const logger = createLogger('GraphDataManager');

// Re-export types from worker proxy for compatibility
export type { Node, Edge, GraphData } from './graphWorkerProxy';

// Alias for backward compatibility
export type GraphNode = Node;

type GraphDataChangeListener = (data: GraphData) => void;
type PositionUpdateListener = (positions: Float32Array) => void;

class GraphDataManager {
  private static instance: GraphDataManager;
  private binaryUpdatesEnabled: boolean = false;
  public webSocketService: WebSocketAdapter | null = null;
  private graphDataListeners: GraphDataChangeListener[] = [];
  private positionUpdateListeners: PositionUpdateListener[] = [];
  private lastBinaryUpdateTime: number = 0;
  private retryTimeout: number | null = null;
  public nodeIdMap: Map<string, number> = new Map();
  private reverseNodeIdMap: Map<number, string> = new Map();
  private workerInitialized: boolean = false;
  private graphType: 'logseq' | 'visionflow' = 'logseq'; 
  private isUserInteracting: boolean = false; 
  private interactionTimeoutRef: number | null = null;
  private updateCount: number = 0; 

  private constructor() {
    
    this.waitForWorker();
  }

  private async waitForWorker(): Promise<void> {
    try {
      console.log('[GraphDataManager] Waiting for worker to be ready...');
      let attempts = 0;
      const maxAttempts = 300; // Increased from 50 to 300 (3 seconds total)


      while (!graphWorkerProxy.isReady() && attempts < maxAttempts) {
        await new Promise(resolve => setTimeout(resolve, 10));
        attempts++;
        // Log progress every 50 attempts
        if (attempts % 50 === 0) {
          console.log(`[GraphDataManager] Still waiting for worker... (${attempts}/${maxAttempts})`);
        }
      }

      if (!graphWorkerProxy.isReady()) {
        console.warn('[GraphDataManager] Worker not ready after timeout, continuing without worker');
        logger.warn('Graph worker proxy not ready after timeout, proceeding without worker');
        this.workerInitialized = false;
        return;
      }
      
      this.workerInitialized = true;
      console.log('[GraphDataManager] Worker is ready!');
      
      
      this.setupWorkerListeners();
      
      if (debugState.isEnabled()) {
        logger.info('Graph worker proxy is ready');
      }
    } catch (error) {
      console.error('[GraphDataManager] Failed to wait for worker:', error);
      logger.error('Failed to wait for graph worker proxy:', createErrorMetadata(error));
      this.workerInitialized = false;
    }
  }

  private setupWorkerListeners(): void {
    
    graphWorkerProxy.onGraphDataChange((data) => {
      this.graphDataListeners.forEach(listener => {
        try {
          startTransition(() => {
            listener(data);
          });
        } catch (error) {
          logger.error('Error in forwarded graph data listener:', createErrorMetadata(error));
        }
      });
    });

    
    graphWorkerProxy.onPositionUpdate((positions) => {
      this.positionUpdateListeners.forEach(listener => {
        try {
          listener(positions);
        } catch (error) {
          logger.error('Error in forwarded position update listener:', createErrorMetadata(error));
        }
      });
    });
  }

  public static getInstance(): GraphDataManager {
    if (!GraphDataManager.instance) {
      GraphDataManager.instance = new GraphDataManager();
    }
    return GraphDataManager.instance;
  }

  // Allow re-checking worker readiness after AppInitializer completes
  public async ensureWorkerReady(): Promise<boolean> {
    if (this.workerInitialized) {
      return true;
    }

    console.log('[GraphDataManager] ensureWorkerReady called, checking worker status...');

    if (graphWorkerProxy.isReady()) {
      this.workerInitialized = true;
      this.setupWorkerListeners();
      console.log('[GraphDataManager] Worker is now ready (late initialization)');
      return true;
    }

    // Wait a bit more for worker
    for (let i = 0; i < 100; i++) {
      await new Promise(resolve => setTimeout(resolve, 10));
      if (graphWorkerProxy.isReady()) {
        this.workerInitialized = true;
        this.setupWorkerListeners();
        console.log('[GraphDataManager] Worker became ready after additional wait');
        return true;
      }
    }

    console.warn('[GraphDataManager] Worker still not ready after ensureWorkerReady');
    return false;
  }

  
  public setWebSocketService(service: WebSocketAdapter): void {
    this.webSocketService = service;
    if (debugState.isDataDebugEnabled()) {
      logger.debug('WebSocket service set');
    }
  }

  
  public setGraphType(type: 'logseq' | 'visionflow'): void {
    this.graphType = type;
    if (debugState.isEnabled()) {
      logger.info(`Graph type set to: ${type}`);
    }
  }

  
  public getGraphType(): 'logseq' | 'visionflow' {
    return this.graphType;
  }

  
  
  public async fetchInitialData(): Promise<GraphData> {
    const maxRetries = 5;
    const initialDelay = 1000; 

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`[GraphDataManager] Fetching initial ${this.graphType} graph data with physics positions (Attempt ${attempt}/${maxRetries})`);
        if (debugState.isEnabled()) {
          logger.info(`Fetching initial ${this.graphType} graph data with physics positions (Attempt ${attempt}/${maxRetries})`);
        }

        const response = await unifiedApiClient.get('/graph/data');
        console.log(`[GraphDataManager] API response status: ${response.status}`);

        // Handle response structure: { success: true, data: { nodes: [], edges: [] } }
        const responseData = response.data.data || response.data;

        if (!responseData || typeof responseData !== 'object') {
          throw new Error('Invalid graph data format: data is not an object');
        }

        const nodes = Array.isArray(responseData.nodes) ? responseData.nodes : [];
        const edges = Array.isArray(responseData.edges) ? responseData.edges : [];
        const metadata = responseData.metadata || {};
        const settlementState = responseData.settlementState || { isSettled: false, stableFrameCount: 0, kineticEnergy: 0 };

        console.log(`[GraphDataManager] Received settlement state: settled=${settlementState.isSettled}, frames=${settlementState.stableFrameCount}, KE=${settlementState.kineticEnergy}`);

        
        
        const enrichedNodes = nodes.map((node: Node) => {
          const nodeAny = node as any;
          const nodeMetadata = metadata[nodeAny.metadata_id || nodeAny.metadataId];
          if (nodeMetadata) {
            return { ...node, metadata: { ...node.metadata, ...nodeMetadata } };
          }
          return node;
        });

        const validatedData = { nodes: enrichedNodes, edges };

        if (debugState.isEnabled()) {
          logger.info(`Received initial graph data: ${validatedData.nodes.length} nodes, ${validatedData.edges.length} edges (physics settled: ${settlementState.isSettled})`);
        }

        console.log(`[GraphDataManager] Setting validated graph data with ${validatedData.nodes.length} nodes at physics-settled positions`);
        await this.setGraphData(validatedData);

        const currentData = await graphWorkerProxy.getGraphData();
        console.log(`[GraphDataManager] Worker returned data with ${currentData.nodes.length} nodes - no position "pop-in" expected!`);
        return currentData;

      } catch (error) {
        logger.error(`Attempt ${attempt} failed to fetch initial graph data:`, createErrorMetadata(error));
        if (attempt === maxRetries) {
          logger.error('All attempts to fetch initial graph data failed.');
          throw error; 
        }

        const delay = initialDelay * Math.pow(2, attempt - 1);
        console.log(`[GraphDataManager] Retrying in ${delay}ms...`);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }

    
    return { nodes: [], edges: [] };
  }

  
  public async setGraphData(data: GraphData): Promise<void> {
    if (debugState.isEnabled()) {
      logger.info(`Setting ${this.graphType} graph data: ${data.nodes.length} nodes, ${data.edges.length} edges`);
    }

    
    let validatedData = data;
    if (data && data.nodes) {
      const validatedNodes = data.nodes.map(node => this.ensureNodeHasValidPosition(node));
      validatedData = {
        ...data,
        nodes: validatedNodes
      };
      
      if (debugState.isEnabled()) {
        logger.info(`Validated ${validatedNodes.length} nodes with positions`);
      }
    } else {
      
      validatedData = { nodes: [], edges: data?.edges || [] };
      logger.warn('Initialized with empty graph data');
    }
    
    
    this.nodeIdMap.clear();
    this.reverseNodeIdMap.clear();
    
    
    validatedData.nodes.forEach((node, index) => {
      const numericId = parseInt(node.id, 10);
      if (!isNaN(numericId) && numericId >= 0 && numericId <= 0xFFFFFFFF) {
        
        this.nodeIdMap.set(node.id, numericId);
        this.reverseNodeIdMap.set(numericId, node.id);
      } else {
        
        
        const mappedId = index + 1;
        this.nodeIdMap.set(node.id, mappedId);
        this.reverseNodeIdMap.set(mappedId, node.id);
      }
    });
    
    
    await graphWorkerProxy.setGraphData(validatedData);
    
    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Graph data updated: ${validatedData.nodes.length} nodes, ${validatedData.edges.length} edges`);
    }
  }

  
  private validateNodeMappings(nodes: Node[]): void {
    if (debugState.isDataDebugEnabled()) {
      logger.debug(`Validated ${nodes.length} nodes with ID mapping`);
    }
  }

  
  public enableBinaryUpdates(): void {
    if (!this.webSocketService) {
      logger.warn('Cannot enable binary updates: WebSocket service not set');
      return;
    }

    
    if (this.webSocketService.isReady()) {
      this.setBinaryUpdatesEnabled(true);
      return;
    }

    
    if (this.retryTimeout) {
      window.clearTimeout(this.retryTimeout);
    }

    this.retryTimeout = window.setTimeout(() => {
      if (this.webSocketService && this.webSocketService.isReady()) {
        this.setBinaryUpdatesEnabled(true);
        if (debugState.isEnabled()) {
          logger.info('WebSocket ready, binary updates enabled');
        }
      } else {
        if (debugState.isEnabled()) {
          logger.info('WebSocket not ready yet, retrying...');
        }
        this.enableBinaryUpdates();
      }
    }, 500);
  }

  public setBinaryUpdatesEnabled(enabled: boolean): void {
    this.binaryUpdatesEnabled = enabled;
    
    if (debugState.isEnabled()) {
      logger.info(`Binary updates ${enabled ? 'enabled' : 'disabled'}`);
    }
  }

  
  public async getGraphData(): Promise<GraphData> {
    // Check both local flag AND proxy ready state (handles race condition)
    if (!this.workerInitialized && !graphWorkerProxy.isReady()) {
      console.warn('[GraphDataManager] Worker not initialized, returning empty data');
      return { nodes: [], edges: [] };
    }

    // Update local flag if proxy is ready but we missed initialization
    if (!this.workerInitialized && graphWorkerProxy.isReady()) {
      console.log('[GraphDataManager] Proxy ready, updating workerInitialized flag');
      this.workerInitialized = true;
      this.setupWorkerListeners();
    }

    try {
      return await graphWorkerProxy.getGraphData();
    } catch (error) {
      console.error('[GraphDataManager] Error getting data from worker:', error);
      logger.error('Error getting graph data from worker:', createErrorMetadata(error));
      return { nodes: [], edges: [] };
    }
  }

  
  public async addNode(node: Node): Promise<void> {
    
    const numericId = parseInt(node.id, 10);
    if (!isNaN(numericId)) {
      this.nodeIdMap.set(node.id, numericId);
      this.reverseNodeIdMap.set(numericId, node.id);
    } else {
      
      const currentData = await graphWorkerProxy.getGraphData();
      const mappedId = currentData.nodes.length + 1;
      this.nodeIdMap.set(node.id, mappedId);
      this.reverseNodeIdMap.set(mappedId, node.id);
    }
    
    await graphWorkerProxy.updateNode(node);
  }

  
  public async addEdge(edge: Edge): Promise<void> {
    
    const currentData = await graphWorkerProxy.getGraphData();
    const existingIndex = currentData.edges.findIndex(e => e.id === edge.id);
    
    if (existingIndex >= 0) {
      currentData.edges[existingIndex] = {
        ...currentData.edges[existingIndex],
        ...edge
      };
    } else {
      currentData.edges.push(edge);
    }
    
    await graphWorkerProxy.setGraphData(currentData);
  }

  
  public async removeNode(nodeId: string): Promise<void> {
    
    const numericId = this.nodeIdMap.get(nodeId);
    
    await graphWorkerProxy.removeNode(nodeId);
    
    
    if (numericId !== undefined) {
      this.nodeIdMap.delete(nodeId);
      this.reverseNodeIdMap.delete(numericId);
    }
  }

  
  public async removeEdge(edgeId: string): Promise<void> {
    
    const currentData = await graphWorkerProxy.getGraphData();
    currentData.edges = currentData.edges.filter(edge => edge.id !== edgeId);
    await graphWorkerProxy.setGraphData(currentData);
  }

  
  public async updateNodePositions(positionData: ArrayBuffer): Promise<void> {
    
    this.updateCount = (this.updateCount || 0) + 1;
    if (this.updateCount % 100 === 1) { 
      console.log('[GraphDataManager] updateNodePositions called, size:', positionData?.byteLength, 'graph type:', this.graphType, 'count:', this.updateCount);
    }
    
    if (!positionData || positionData.byteLength === 0) {
      if (this.updateCount % 100 === 1) {
        console.log('[GraphDataManager] No position data, returning');
      }
      return;
    }

    
    if (this.graphType !== 'logseq') {
      if (this.updateCount % 100 === 1) {
        console.log('[GraphDataManager] Skipping - not logseq graph, type is:', this.graphType);
      }
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Skipping binary update for ${this.graphType} graph`);
      }
      return;
    }

    
    const now = Date.now();
    if (now - this.lastBinaryUpdateTime < 16) { 
      if (debugState.isDataDebugEnabled()) {
        logger.debug('Skipping duplicate position update');
      }
      return;
    }
    this.lastBinaryUpdateTime = now;

    try {
      
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Received binary data: ${positionData.byteLength} bytes`);
        
        
        const remainder = positionData.byteLength % BINARY_NODE_SIZE;
        if (remainder !== 0) {
          logger.warn(`Binary data size (${positionData.byteLength} bytes) is not a multiple of ${BINARY_NODE_SIZE}. Remainder: ${remainder} bytes`);
        }
      }
      
      
      if (this.updateCount % 100 === 1) {
        console.log('[GraphDataManager] Sending to worker proxy for processing');
      }
      await graphWorkerProxy.processBinaryData(positionData);
      if (this.updateCount % 100 === 1) {
        console.log('[GraphDataManager] Worker proxy processing complete');
      }
      
      
      const settings = useSettingsStore.getState().settings;
      const debugEnabled = settings?.system?.debug?.enabled;
      const physicsDebugEnabled = (settings?.system?.debug as any)?.enablePhysicsDebug;
      const nodeDebugEnabled = (settings?.system?.debug as any)?.enableNodeDebug;
      
      if (debugEnabled && (physicsDebugEnabled || nodeDebugEnabled)) {
        const view = new DataView(positionData);
        const nodeCount = Math.min(3, positionData.byteLength / BINARY_NODE_SIZE);
        for (let i = 0; i < nodeCount; i++) {
          const offset = i * BINARY_NODE_SIZE;
          const x = view.getFloat32(offset + 4, true);
          const y = view.getFloat32(offset + 8, true);
          const z = view.getFloat32(offset + 12, true);
          logger.info(`[Physics Debug] Node ${i}: position(${x.toFixed(2)}, ${y.toFixed(2)}, ${z.toFixed(2)})`);
        }
      }
      
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Processed binary data through worker`);
      }
    } catch (error) {
      logger.error('Error processing binary position data:', createErrorMetadata(error));
      
      
      if (debugState.isEnabled()) {
        try {
          
          const view = new DataView(positionData);
          const byteArray = [];
          const maxBytesToShow = Math.min(64, positionData.byteLength);
          
          for (let i = 0; i < maxBytesToShow; i++) {
            byteArray.push(view.getUint8(i).toString(16).padStart(2, '0'));
          }
          
          logger.debug(`First ${maxBytesToShow} bytes of binary data: ${byteArray.join(' ')}${positionData.byteLength > maxBytesToShow ? '...' : ''}`);
        } catch (e) {
          logger.debug('Could not display binary data preview:', e);
        }
      }
    }
  }

  
  
  public async sendNodePositions(): Promise<void> {
    if (!this.binaryUpdatesEnabled || !this.webSocketService || !this.isUserInteracting) {
      return;
    }

    try {
      
      const currentData = await graphWorkerProxy.getGraphData();
      
      
      const binaryNodes: BinaryNodeData[] = currentData.nodes
        .filter(node => node && node.id) 
        .map(node => {
          
          const validatedNode = this.ensureNodeHasValidPosition(node);
          
          
          const numericId = this.nodeIdMap.get(validatedNode.id) || 0;
          if (numericId === 0) {
            logger.warn(`No numeric ID found for node ${validatedNode.id}, skipping`);
            return null;
          }
          
          
          const velocity: Vec3 = (validatedNode.metadata?.velocity as Vec3) || { x: 0, y: 0, z: 0 };
          
          return {
            nodeId: numericId,
            position: {
              x: validatedNode.position.x || 0,
              y: validatedNode.position.y || 0,
              z: validatedNode.position.z || 0
            },
            velocity
          };
        })
        .filter((node): node is BinaryNodeData => node !== null);

      
      const buffer = createBinaryNodeData(binaryNodes);
      
      
      this.webSocketService.send(buffer);
      
      if (debugState.isDataDebugEnabled()) {
        logger.debug(`Sent positions for ${binaryNodes.length} nodes using binary protocol`);
      }
    } catch (error) {
      logger.error('Error sending node positions:', createErrorMetadata(error));
    }
  }

  
  public onGraphDataChange(listener: GraphDataChangeListener): () => void {
    console.log('[GraphDataManager] Adding graph data change listener');
    this.graphDataListeners.push(listener);
    
    
    console.log('[GraphDataManager] Getting current data for new listener');
    graphWorkerProxy.getGraphData().then(data => {
      console.log(`[GraphDataManager] Calling listener with current data: ${data.nodes.length} nodes`);
      listener(data);
    }).catch(error => {
      console.error('[GraphDataManager] Error getting initial graph data for listener:', error);
      logger.error('Error getting initial graph data for listener:', createErrorMetadata(error));
      
      listener({ nodes: [], edges: [] });
    });
    
    
    return () => {
      console.log('[GraphDataManager] Removing graph data change listener');
      this.graphDataListeners = this.graphDataListeners.filter(l => l !== listener);
    };
  }

  
  public onPositionUpdate(listener: PositionUpdateListener): () => void {
    this.positionUpdateListeners.push(listener);
    
    
    return () => {
      this.positionUpdateListeners = this.positionUpdateListeners.filter(l => l !== listener);
    };
  }

  
  private async notifyGraphDataListeners(): Promise<void> {
    try {
      const currentData = await graphWorkerProxy.getGraphData();
      this.graphDataListeners.forEach(listener => {
        try {
          listener(currentData);
        } catch (error) {
          logger.error('Error in graph data listener:', createErrorMetadata(error));
        }
      });
    } catch (error) {
      logger.error('Error getting graph data for listeners:', createErrorMetadata(error));
    }
  }

  
  private notifyPositionUpdateListeners(positions: Float32Array): void {
    this.positionUpdateListeners.forEach(listener => {
      try {
        listener(positions);
      } catch (error) {
        logger.error('Error in position update listener:', createErrorMetadata(error));
      }
    });
  }

  
  public ensureNodeHasValidPosition(node: Node): Node {
    if (!node.position) {
      
      console.warn(`[GraphDataManager] Node ${node.id} missing position - server should provide this!`);
      return {
        ...node,
        position: { x: 0, y: 0, z: 0 }
      };
    } else if (typeof node.position.x !== 'number' ||
               typeof node.position.y !== 'number' ||
               typeof node.position.z !== 'number') {
      
      console.warn(`[GraphDataManager] Node ${node.id} has invalid position coordinates - fixing`);
      node.position.x = typeof node.position.x === 'number' && isFinite(node.position.x) ? node.position.x : 0;
      node.position.y = typeof node.position.y === 'number' && isFinite(node.position.y) ? node.position.y : 0;
      node.position.z = typeof node.position.z === 'number' && isFinite(node.position.z) ? node.position.z : 0;
    }
    return node;
  }

  
  public subscribeToUpdates(listener: GraphDataChangeListener): () => void {
    return this.onGraphDataChange(listener);
  }

  
  public getVisibleNodes(): Node[] {
    
    let nodes: Node[] = [];
    graphWorkerProxy.getGraphData().then(data => {
      nodes = data.nodes;
    }).catch(error => {
      logger.error('Error getting visible nodes:', createErrorMetadata(error));
    });
    return nodes;
  }

  
  public setUserInteracting(isInteracting: boolean): void {
    if (this.isUserInteracting === isInteracting) {
      return; 
    }

    this.isUserInteracting = isInteracting;

    if (isInteracting) {
      
      if (this.interactionTimeoutRef) {
        window.clearTimeout(this.interactionTimeoutRef);
        this.interactionTimeoutRef = null;
      }

      if (debugState.isEnabled()) {
        logger.debug('User interaction started - WebSocket position updates enabled');
      }
    } else {
      
      
      this.interactionTimeoutRef = window.setTimeout(() => {
        this.isUserInteracting = false;
        this.interactionTimeoutRef = null;

        if (debugState.isEnabled()) {
          logger.debug('User interaction ended - WebSocket position updates disabled');
        }
      }, 200); 
    }
  }

  
  public isUserCurrentlyInteracting(): boolean {
    return this.isUserInteracting;
  }

  
  public dispose(): void {
    if (this.retryTimeout) {
      window.clearTimeout(this.retryTimeout);
      this.retryTimeout = null;
    }

    if (this.interactionTimeoutRef) {
      window.clearTimeout(this.interactionTimeoutRef);
      this.interactionTimeoutRef = null;
    }

    this.graphDataListeners = [];
    this.positionUpdateListeners = [];
    this.webSocketService = null;
    this.nodeIdMap.clear();
    this.reverseNodeIdMap.clear();
    this.isUserInteracting = false;

    if (debugState.isEnabled()) {
      logger.info('GraphDataManager disposed');
    }
  }
}

// Create singleton instance
export const graphDataManager = GraphDataManager.getInstance();


--------------------------------------------------------------------------------
FILE: client/src/features/ontology/store/useOntologyStore.ts
PURPOSE: Ontology state management
--------------------------------------------------------------------------------
import { create } from 'zustand';

export interface Violation {
  axiomType: string;
  description: string;
  severity: 'error' | 'warning';
  affectedEntities: string[];
}

export interface ConstraintGroup {
  id: string;
  name: string;
  enabled: boolean;
  strength: number;
  description: string;
  constraintCount: number;
  icon?: string;
}

export interface OntologyMetrics {
  axiomCount: number;
  classCount: number;
  propertyCount: number;
  individualCount: number;
  constraintsByType: Record<string, number>;
  cacheHitRate: number;
  validationTimeMs: number;
  lastValidated?: number;
}

export interface ClassNode {
  id: string;
  label: string;
  parentId?: string;
  level: number;
  depth: number;  // Alias for level, for compatibility
  childIds?: string[];
  childIris?: string[];  // Legacy alias for childIds
  instanceCount?: number;
}

export interface OntologyHierarchy {
  classes: Map<string, ClassNode>;
  roots: string[];
}

export interface OntologyState {
  loaded: boolean;
  validating: boolean;
  violations: Violation[];
  constraintGroups: ConstraintGroup[];
  metrics: OntologyMetrics;

  // Hierarchical visualization state
  hierarchy: OntologyHierarchy | null;
  semanticZoomLevel: number;
  expandedClasses: Set<string>;
  highlightedClass: string | null;

  setLoaded: (loaded: boolean) => void;
  setValidating: (validating: boolean) => void;
  setViolations: (violations: Violation[]) => void;
  setMetrics: (metrics: OntologyMetrics) => void;

  toggleConstraintGroup: (id: string) => void;
  updateStrength: (id: string, strength: number) => void;

  // Hierarchical navigation
  toggleClass: (classId: string) => void;
  setSemanticZoomLevel: (level: number) => void;
  setHighlightedClass: (classId: string | null) => void;
  setHierarchy: (hierarchy: OntologyHierarchy | null) => void;

  loadOntology: (fileUrl: string) => Promise<void>;
  validateOntology: () => Promise<void>;
}

export const useOntologyStore = create<OntologyState>((set, get) => ({
  loaded: false,
  validating: false,
  violations: [],
  constraintGroups: [
    {
      id: 'subsumption',
      name: 'Subsumption',
      enabled: true,
      strength: 0.8,
      description: 'Class hierarchy constraints',
      constraintCount: 0,
      icon: 'hierarchy'
    },
    {
      id: 'disjointness',
      name: 'Disjointness',
      enabled: true,
      strength: 1.0,
      description: 'Disjoint class constraints',
      constraintCount: 0,
      icon: 'split'
    },
    {
      id: 'property_domain',
      name: 'Property Domain',
      enabled: true,
      strength: 0.9,
      description: 'Property domain restrictions',
      constraintCount: 0,
      icon: 'arrow-right'
    },
    {
      id: 'property_range',
      name: 'Property Range',
      enabled: true,
      strength: 0.9,
      description: 'Property range restrictions',
      constraintCount: 0,
      icon: 'arrow-left'
    },
    {
      id: 'cardinality',
      name: 'Cardinality',
      enabled: false,
      strength: 0.7,
      description: 'Property cardinality constraints',
      constraintCount: 0,
      icon: 'hash'
    }
  ],
  metrics: {
    axiomCount: 0,
    classCount: 0,
    propertyCount: 0,
    individualCount: 0,
    constraintsByType: {},
    cacheHitRate: 0,
    validationTimeMs: 0
  },

  // Hierarchical visualization state
  hierarchy: null,
  semanticZoomLevel: 0,
  expandedClasses: new Set<string>(),
  highlightedClass: null,

  setLoaded: (loaded) => set({ loaded }),
  setValidating: (validating) => set({ validating }),
  setViolations: (violations) => set({ violations }),
  setMetrics: (metrics) => set({ metrics }),

  toggleConstraintGroup: (id) => set((state) => ({
    constraintGroups: state.constraintGroups.map(group =>
      group.id === id ? { ...group, enabled: !group.enabled } : group
    )
  })),

  updateStrength: (id, strength) => set((state) => ({
    constraintGroups: state.constraintGroups.map(group =>
      group.id === id ? { ...group, strength } : group
    )
  })),

  // Hierarchical navigation methods
  toggleClass: (classId) => set((state) => {
    const newExpanded = new Set(state.expandedClasses);
    if (newExpanded.has(classId)) {
      newExpanded.delete(classId);
    } else {
      newExpanded.add(classId);
    }
    return { expandedClasses: newExpanded };
  }),

  setSemanticZoomLevel: (level) => set({ semanticZoomLevel: level }),

  setHighlightedClass: (classId) => set({ highlightedClass: classId }),

  setHierarchy: (hierarchy) => set({ hierarchy }),

  loadOntology: async (fileUrl: string) => {
    set({ validating: true, violations: [] });
    try {
      const response = await fetch('/api/ontology/load', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ url: fileUrl })
      });

      if (!response.ok) {
        throw new Error(`Failed to load ontology: ${response.statusText}`);
      }

      const data = await response.json();
      set({
        loaded: true,
        metrics: data.metrics || get().metrics,
        constraintGroups: data.constraintGroups || get().constraintGroups
      });
    } catch (error) {
      console.error('Failed to load ontology:', error);
      throw error;
    } finally {
      set({ validating: false });
    }
  },

  validateOntology: async () => {
    set({ validating: true });
    try {
      const response = await fetch('/api/ontology/validate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          constraintGroups: get().constraintGroups.filter(g => g.enabled)
        })
      });

      if (!response.ok) {
        throw new Error(`Validation failed: ${response.statusText}`);
      }

      const data = await response.json();
      set({
        violations: data.violations || [],
        metrics: { ...get().metrics, ...data.metrics, lastValidated: Date.now() }
      });
    } catch (error) {
      console.error('Validation failed:', error);
      throw error;
    } finally {
      set({ validating: false });
    }
  }
}));

--------------------------------------------------------------------------------
FILE: client/src/features/ontology/services/JssOntologyService.ts
PURPOSE: JSS integration for ontology
--------------------------------------------------------------------------------
/**
 * JSS Ontology Service
 *
 * Provides live ontology data integration with JavaScript Solid Server (JSS).
 * Replaces static file loading with JSS LDP endpoints for:
 * - Native speed JSON-LD fetch (no parsing overhead)
 * - Content negotiation for Turtle (Protege compatibility)
 * - Real-time WebSocket updates via solid-0.1 protocol
 * - Live graph updates when ontology changes
 *
 * Architecture:
 * - Humans visiting ontology URLs get JSON-LD (native speed for React)
 * - Semantic tools (Protege, reasoners) get Turtle via Accept headers
 * - WebSocket subscriptions trigger graph re-renders on ontology changes
 */

import { createLogger, createErrorMetadata } from '../../../utils/loggerConfig';
import { debugState } from '../../../utils/clientDebugState';
import { nostrAuth } from '../../../services/nostrAuthService';
import { webSocketService, SolidNotification } from '../../../services/WebSocketService';
import { useOntologyStore, OntologyHierarchy, ClassNode, OntologyMetrics } from '../store/useOntologyStore';

const logger = createLogger('JssOntologyService');

// --- Configuration ---

const JSS_BASE_URL = import.meta.env.VITE_JSS_URL || '/solid';
const JSS_WS_URL = import.meta.env.VITE_JSS_WS_URL || null;
const ONTOLOGY_RESOURCE_PATH = import.meta.env.VITE_JSS_ONTOLOGY_PATH || '/public/ontology';

// --- Types ---

export interface JsonLdContext {
  '@vocab'?: string;
  [key: string]: string | object | undefined;
}

export interface JsonLdOntology {
  '@context': JsonLdContext | string;
  '@graph'?: JsonLdNode[];
  '@id'?: string;
  '@type'?: string | string[];
  [key: string]: unknown;
}

export interface JsonLdNode {
  '@id': string;
  '@type'?: string | string[];
  'rdfs:label'?: string | { '@value': string; '@language'?: string };
  'rdfs:subClassOf'?: { '@id': string } | Array<{ '@id': string }>;
  'rdfs:comment'?: string | { '@value': string };
  'owl:disjointWith'?: { '@id': string } | Array<{ '@id': string }>;
  'rdfs:domain'?: { '@id': string };
  'rdfs:range'?: { '@id': string };
  [key: string]: unknown;
}

export interface OntologyChangeEvent {
  type: 'class_added' | 'class_removed' | 'property_added' | 'property_removed' | 'full_refresh';
  resourceUrl: string;
  timestamp: number;
  data?: JsonLdNode;
}

export type OntologyChangeCallback = (event: OntologyChangeEvent) => void;

export interface FetchOptions {
  skipCache?: boolean;
  timeout?: number;
}

// --- Service Implementation ---

class JssOntologyService {
  private static instance: JssOntologyService;

  // Cache for ontology data
  private cachedJsonLd: JsonLdOntology | null = null;
  private cachedTurtle: string | null = null;
  private cacheTimestamp: number = 0;
  private readonly cacheTtlMs: number = 60000; // 1 minute cache

  // WebSocket subscription management
  private changeCallbacks: Set<OntologyChangeCallback> = new Set();
  private unsubscribeFn: (() => void) | null = null;
  private isSubscribed: boolean = false;

  // Metrics tracking
  private fetchCount: number = 0;
  private lastFetchDurationMs: number = 0;

  private constructor() {}

  public static getInstance(): JssOntologyService {
    if (!JssOntologyService.instance) {
      JssOntologyService.instance = new JssOntologyService();
    }
    return JssOntologyService.instance;
  }

  // --- JSON-LD Fetching (Native Speed) ---

  /**
   * Fetch ontology as JSON-LD from JSS
   * This is the native storage format - zero parsing overhead
   */
  public async fetchOntologyJsonLd(options: FetchOptions = {}): Promise<JsonLdOntology> {
    const { skipCache = false, timeout = 30000 } = options;

    // Return cached data if valid
    if (!skipCache && this.isCacheValid()) {
      if (debugState.isEnabled()) {
        logger.debug('Returning cached JSON-LD ontology');
      }
      return this.cachedJsonLd!;
    }

    const startTime = performance.now();
    const url = this.getOntologyUrl();

    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);

      const response = await this.fetchWithAuth(url, {
        headers: {
          'Accept': 'application/ld+json',
        },
        signal: controller.signal,
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`Failed to fetch ontology: ${response.status} ${response.statusText}`);
      }

      const data: JsonLdOntology = await response.json();

      // Update cache
      this.cachedJsonLd = data;
      this.cacheTimestamp = Date.now();
      this.lastFetchDurationMs = performance.now() - startTime;
      this.fetchCount++;

      if (debugState.isEnabled()) {
        logger.info('Fetched JSON-LD ontology', {
          durationMs: this.lastFetchDurationMs.toFixed(2),
          graphSize: data['@graph']?.length || 0,
        });
      }

      return data;
    } catch (error) {
      if (error instanceof Error && error.name === 'AbortError') {
        throw new Error(`Ontology fetch timeout after ${timeout}ms`);
      }
      logger.error('Failed to fetch JSON-LD ontology', createErrorMetadata(error));
      throw error;
    }
  }

  /**
   * Fetch ontology and convert to hierarchy structure for visualization
   */
  public async fetchOntologyHierarchy(options: FetchOptions = {}): Promise<OntologyHierarchy> {
    const jsonLd = await this.fetchOntologyJsonLd(options);
    return this.buildHierarchyFromJsonLd(jsonLd);
  }

  // --- Turtle Fetching (Content Negotiation for Protege) ---

  /**
   * Fetch ontology as Turtle via content negotiation
   * Used for Protege and other semantic web tools
   */
  public async fetchOntologyTurtle(options: FetchOptions = {}): Promise<string> {
    const { skipCache = false, timeout = 30000 } = options;

    // Return cached data if valid
    if (!skipCache && this.cachedTurtle && this.isCacheValid()) {
      if (debugState.isEnabled()) {
        logger.debug('Returning cached Turtle ontology');
      }
      return this.cachedTurtle;
    }

    const startTime = performance.now();
    const url = this.getOntologyUrl();

    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);

      const response = await this.fetchWithAuth(url, {
        headers: {
          'Accept': 'text/turtle',
        },
        signal: controller.signal,
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`Failed to fetch Turtle ontology: ${response.status} ${response.statusText}`);
      }

      const data = await response.text();

      // Update cache
      this.cachedTurtle = data;
      this.cacheTimestamp = Date.now();
      this.lastFetchDurationMs = performance.now() - startTime;
      this.fetchCount++;

      if (debugState.isEnabled()) {
        logger.info('Fetched Turtle ontology', {
          durationMs: this.lastFetchDurationMs.toFixed(2),
          sizeBytes: data.length,
        });
      }

      return data;
    } catch (error) {
      if (error instanceof Error && error.name === 'AbortError') {
        throw new Error(`Turtle fetch timeout after ${timeout}ms`);
      }
      logger.error('Failed to fetch Turtle ontology', createErrorMetadata(error));
      throw error;
    }
  }

  // --- WebSocket Real-time Updates ---

  /**
   * Connect to JSS WebSocket for real-time ontology updates
   * Uses solid-0.1 protocol
   */
  public connectWebSocket(): void {
    if (!JSS_WS_URL) {
      logger.warn('JSS WebSocket URL not configured (VITE_JSS_WS_URL)');
      return;
    }

    // Use the main WebSocketService's Solid connection
    webSocketService.connectSolid();

    // Subscribe to ontology resource if not already
    if (!this.isSubscribed) {
      this.subscribeToOntology();
    }
  }

  /**
   * Subscribe to ontology resource changes
   */
  private subscribeToOntology(): void {
    const ontologyUrl = this.getOntologyUrl();

    if (debugState.isEnabled()) {
      logger.info('Subscribing to ontology changes', { url: ontologyUrl });
    }

    // Unsubscribe from previous subscription if any
    if (this.unsubscribeFn) {
      this.unsubscribeFn();
    }

    // Subscribe to the ontology resource
    this.unsubscribeFn = webSocketService.subscribeSolidResource(
      ontologyUrl,
      (notification: SolidNotification) => {
        this.handleSolidNotification(notification);
      }
    );

    this.isSubscribed = true;
  }

  /**
   * Handle Solid notification for ontology changes
   */
  private async handleSolidNotification(notification: SolidNotification): Promise<void> {
    if (notification.type !== 'pub') {
      // Only process 'pub' (change) notifications, not 'ack'
      return;
    }

    if (debugState.isEnabled()) {
      logger.info('Ontology resource changed', { url: notification.url });
    }

    // Invalidate cache
    this.invalidateCache();

    // Fetch fresh data
    try {
      const jsonLd = await this.fetchOntologyJsonLd({ skipCache: true });
      const hierarchy = this.buildHierarchyFromJsonLd(jsonLd);

      // Update the store
      const store = useOntologyStore.getState();
      store.setHierarchy(hierarchy);
      store.setLoaded(true);

      // Notify all change callbacks
      const event: OntologyChangeEvent = {
        type: 'full_refresh',
        resourceUrl: notification.url,
        timestamp: Date.now(),
      };

      this.notifyChangeCallbacks(event);

      if (debugState.isEnabled()) {
        logger.info('Ontology store updated from WebSocket notification');
      }
    } catch (error) {
      logger.error('Failed to refresh ontology after change notification', createErrorMetadata(error));
    }
  }

  /**
   * Register a callback for ontology changes
   * @returns Unsubscribe function
   */
  public onResourceChange(callback: OntologyChangeCallback): () => void {
    this.changeCallbacks.add(callback);

    return () => {
      this.changeCallbacks.delete(callback);
    };
  }

  /**
   * Notify all registered change callbacks
   */
  private notifyChangeCallbacks(event: OntologyChangeEvent): void {
    this.changeCallbacks.forEach((callback) => {
      try {
        callback(event);
      } catch (error) {
        logger.error('Error in ontology change callback', createErrorMetadata(error));
      }
    });
  }

  /**
   * Disconnect WebSocket and clean up subscriptions
   */
  public disconnect(): void {
    if (this.unsubscribeFn) {
      this.unsubscribeFn();
      this.unsubscribeFn = null;
    }
    this.isSubscribed = false;
    this.changeCallbacks.clear();
  }

  // --- Store Integration ---

  /**
   * Load ontology into the store
   * Replaces static file loading with live JSS endpoint
   */
  public async loadIntoStore(options: FetchOptions = {}): Promise<void> {
    const store = useOntologyStore.getState();
    store.setValidating(true);

    try {
      const jsonLd = await this.fetchOntologyJsonLd(options);
      const hierarchy = this.buildHierarchyFromJsonLd(jsonLd);
      const metrics = this.extractMetricsFromJsonLd(jsonLd);

      store.setHierarchy(hierarchy);
      store.setMetrics(metrics);
      store.setLoaded(true);

      if (debugState.isEnabled()) {
        logger.info('Ontology loaded into store', {
          classCount: hierarchy.classes.size,
          rootCount: hierarchy.roots.length,
        });
      }
    } catch (error) {
      logger.error('Failed to load ontology into store', createErrorMetadata(error));
      throw error;
    } finally {
      store.setValidating(false);
    }
  }

  /**
   * Initialize service: load ontology and connect WebSocket
   */
  public async initialize(): Promise<void> {
    // Load initial data
    await this.loadIntoStore();

    // Connect for real-time updates
    this.connectWebSocket();
  }

  // --- Helper Methods ---

  private getOntologyUrl(): string {
    return `${JSS_BASE_URL}${ONTOLOGY_RESOURCE_PATH}`;
  }

  private async fetchWithAuth(
    url: string,
    options: RequestInit = {}
  ): Promise<Response> {
    const token = nostrAuth.getSessionToken();

    const headers = new Headers(options.headers);

    if (token) {
      headers.set('Authorization', `Bearer ${token}`);
    }

    return fetch(url, {
      ...options,
      headers,
      credentials: 'include',
    });
  }

  private isCacheValid(): boolean {
    if (!this.cachedJsonLd) return false;
    return Date.now() - this.cacheTimestamp < this.cacheTtlMs;
  }

  private invalidateCache(): void {
    this.cachedJsonLd = null;
    this.cachedTurtle = null;
    this.cacheTimestamp = 0;
  }

  /**
   * Build OntologyHierarchy from JSON-LD graph
   */
  private buildHierarchyFromJsonLd(jsonLd: JsonLdOntology): OntologyHierarchy {
    const classes = new Map<string, ClassNode>();
    const roots: string[] = [];
    const childMap = new Map<string, string[]>();

    const graph = jsonLd['@graph'] || [];

    // First pass: create all class nodes
    for (const node of graph) {
      if (!this.isOwlClass(node)) continue;

      const id = node['@id'];
      const label = this.extractLabel(node);
      const parentId = this.extractParentId(node);

      classes.set(id, {
        id,
        label,
        parentId,
        level: 0, // Will be computed in second pass
        depth: 0,
        childIds: [],
        instanceCount: 0,
      });

      // Track parent-child relationships
      if (parentId) {
        if (!childMap.has(parentId)) {
          childMap.set(parentId, []);
        }
        childMap.get(parentId)!.push(id);
      }
    }

    // Second pass: assign children and compute levels
    for (const [id, node] of classes) {
      const childIds = childMap.get(id) || [];
      node.childIds = childIds;
      node.childIris = childIds; // Legacy alias

      if (!node.parentId || !classes.has(node.parentId)) {
        roots.push(id);
      }
    }

    // Compute levels (depth from root)
    const computeLevel = (id: string, level: number): void => {
      const node = classes.get(id);
      if (node) {
        node.level = level;
        node.depth = level;
        for (const childId of node.childIds || []) {
          computeLevel(childId, level + 1);
        }
      }
    };

    for (const rootId of roots) {
      computeLevel(rootId, 0);
    }

    return { classes, roots };
  }

  private isOwlClass(node: JsonLdNode): boolean {
    const type = node['@type'];
    if (!type) return false;

    const types = Array.isArray(type) ? type : [type];
    return types.some(
      (t) =>
        t === 'owl:Class' ||
        t === 'http://www.w3.org/2002/07/owl#Class' ||
        t === 'rdfs:Class' ||
        t === 'http://www.w3.org/2000/01/rdf-schema#Class'
    );
  }

  private extractLabel(node: JsonLdNode): string {
    const label = node['rdfs:label'];

    if (!label) {
      // Extract local name from IRI
      const id = node['@id'];
      const hashIndex = id.lastIndexOf('#');
      const slashIndex = id.lastIndexOf('/');
      const index = Math.max(hashIndex, slashIndex);
      return index >= 0 ? id.slice(index + 1) : id;
    }

    if (typeof label === 'string') return label;
    if (typeof label === 'object' && '@value' in label) return label['@value'];

    return node['@id'];
  }

  private extractParentId(node: JsonLdNode): string | undefined {
    const subClassOf = node['rdfs:subClassOf'];
    if (!subClassOf) return undefined;

    if (Array.isArray(subClassOf)) {
      // Return the first non-blank node parent
      for (const parent of subClassOf) {
        if (typeof parent === 'object' && '@id' in parent) {
          const id = parent['@id'];
          if (!id.startsWith('_:')) return id;
        }
      }
      return undefined;
    }

    if (typeof subClassOf === 'object' && '@id' in subClassOf) {
      const id = subClassOf['@id'];
      if (!id.startsWith('_:')) return id;
    }

    return undefined;
  }

  /**
   * Extract metrics from JSON-LD ontology
   */
  private extractMetricsFromJsonLd(jsonLd: JsonLdOntology): OntologyMetrics {
    const graph = jsonLd['@graph'] || [];

    let classCount = 0;
    let propertyCount = 0;
    let individualCount = 0;
    const constraintsByType: Record<string, number> = {};

    for (const node of graph) {
      const types = this.getTypes(node);

      if (types.includes('owl:Class') || types.includes('rdfs:Class')) {
        classCount++;
      }

      if (
        types.includes('owl:ObjectProperty') ||
        types.includes('owl:DatatypeProperty') ||
        types.includes('rdf:Property')
      ) {
        propertyCount++;
      }

      if (types.includes('owl:NamedIndividual')) {
        individualCount++;
      }

      // Count constraints
      if (node['owl:disjointWith']) {
        constraintsByType['disjointness'] = (constraintsByType['disjointness'] || 0) + 1;
      }
      if (node['rdfs:subClassOf']) {
        constraintsByType['subsumption'] = (constraintsByType['subsumption'] || 0) + 1;
      }
      if (node['rdfs:domain']) {
        constraintsByType['property_domain'] = (constraintsByType['property_domain'] || 0) + 1;
      }
      if (node['rdfs:range']) {
        constraintsByType['property_range'] = (constraintsByType['property_range'] || 0) + 1;
      }
    }

    return {
      axiomCount: graph.length,
      classCount,
      propertyCount,
      individualCount,
      constraintsByType,
      cacheHitRate: this.fetchCount > 0 ? 0 : 1, // Placeholder
      validationTimeMs: this.lastFetchDurationMs,
      lastValidated: Date.now(),
    };
  }

  private getTypes(node: JsonLdNode): string[] {
    const type = node['@type'];
    if (!type) return [];
    return Array.isArray(type) ? type : [type];
  }

  // --- Public Getters ---

  public isConnected(): boolean {
    return this.isSubscribed && webSocketService.isSolidWebSocketConnected();
  }

  public getCacheStats(): { hits: number; age: number; valid: boolean } {
    return {
      hits: this.fetchCount,
      age: this.cacheTimestamp > 0 ? Date.now() - this.cacheTimestamp : -1,
      valid: this.isCacheValid(),
    };
  }

  public getLastFetchDuration(): number {
    return this.lastFetchDurationMs;
  }
}

// --- Export Singleton ---

export const jssOntologyService = JssOntologyService.getInstance();
export default jssOntologyService;

--------------------------------------------------------------------------------
FILE: client/src/features/analytics/store/analyticsStore.ts
PURPOSE: Analytics state (SSSP results)
--------------------------------------------------------------------------------
import { create } from 'zustand'
import { persist, createJSONStorage } from 'zustand/middleware'
import { createLogger, createErrorMetadata } from '../../../utils/loggerConfig'
import { debugState } from '../../../utils/clientDebugState'
import { produce } from 'immer'
import type { GraphNode, GraphEdge } from '../../graph/types/graphTypes'
import { unifiedApiClient } from '../../../services/api'

const logger = createLogger('AnalyticsStore')

// SSSP-specific types
export interface SSSPResult {
  sourceNodeId: string
  distances: Record<string, number>
  predecessors: Record<string, string | null>
  unreachableCount: number
  computationTime: number
  timestamp: number
  algorithm: 'dijkstra' | 'bellman-ford' | 'floyd-warshall'
}

export interface SSSPCache {
  [sourceNodeId: string]: {
    result: SSSPResult
    lastAccessed: number
    graphHash: string 
  }
}

export interface AnalyticsMetrics {
  totalComputations: number
  cacheHits: number
  cacheMisses: number
  averageComputationTime: number
  lastComputationTime: number
}

interface AnalyticsState {
  
  currentResult: SSSPResult | null
  cache: SSSPCache
  loading: boolean
  error: string | null
  
  
  metrics: AnalyticsMetrics
  
  
  lastGraphHash: string | null
  
  
  computeSSSP: (
    nodes: GraphNode[], 
    edges: GraphEdge[], 
    sourceNodeId: string,
    algorithm?: 'dijkstra' | 'bellman-ford' | 'floyd-warshall'
  ) => Promise<SSSPResult>
  
  clearResults: () => void
  clearCache: () => void
  getCachedResult: (sourceNodeId: string, graphHash: string) => SSSPResult | null
  normalizeDistances: (result: SSSPResult) => Record<string, number>
  getUnreachableNodes: (result: SSSPResult) => string[]
  
  
  invalidateCache: () => void
  cleanExpiredCache: (maxAge?: number) => void
  
  
  setError: (error: string | null) => void
  
  
  updateMetrics: (computationTime: number, fromCache: boolean) => void
  resetMetrics: () => void
}

// Hash function for graph structure
function hashGraph(nodes: GraphNode[], edges: GraphEdge[]): string {
  const nodeIds = nodes.map(n => n.id).sort().join(',')
  const edgeIds = edges.map(e => `${e.source}-${e.target}-${e.weight || 1}`).sort().join(',')
  return btoa(`${nodeIds}|${edgeIds}`)
}

// Dijkstra's algorithm implementation
function dijkstra(nodes: GraphNode[], edges: GraphEdge[], sourceNodeId: string): Omit<SSSPResult, 'timestamp' | 'computationTime' | 'algorithm'> {
  const distances: Record<string, number> = {}
  const predecessors: Record<string, string | null> = {}
  const visited = new Set<string>()
  const nodeIds = new Set(nodes.map(n => n.id))
  
  
  for (const node of nodes) {
    distances[node.id] = node.id === sourceNodeId ? 0 : Infinity
    predecessors[node.id] = null
  }
  
  
  const adjacencyList: Record<string, Array<{ nodeId: string; weight: number }>> = {}
  for (const node of nodes) {
    adjacencyList[node.id] = []
  }
  
  for (const edge of edges) {
    if (nodeIds.has(edge.source) && nodeIds.has(edge.target)) {
      const weight = edge.weight || 1
      adjacencyList[edge.source].push({ nodeId: edge.target, weight })
      
      adjacencyList[edge.target].push({ nodeId: edge.source, weight })
    }
  }
  
  
  while (visited.size < nodes.length) {
    
    let currentNode: string | null = null
    let minDistance = Infinity
    
    for (const nodeId of Object.keys(distances)) {
      if (!visited.has(nodeId) && distances[nodeId] < minDistance) {
        minDistance = distances[nodeId]
        currentNode = nodeId
      }
    }
    
    if (currentNode === null || minDistance === Infinity) break
    
    visited.add(currentNode)
    
    
    for (const neighbor of adjacencyList[currentNode] || []) {
      if (!visited.has(neighbor.nodeId)) {
        const newDistance = distances[currentNode] + neighbor.weight
        if (newDistance < distances[neighbor.nodeId]) {
          distances[neighbor.nodeId] = newDistance
          predecessors[neighbor.nodeId] = currentNode
        }
      }
    }
  }
  
  
  const unreachableCount = Object.values(distances).filter(d => d === Infinity).length
  
  return {
    sourceNodeId,
    distances,
    predecessors,
    unreachableCount
  }
}

// Bellman-Ford algorithm (handles negative weights)
function bellmanFord(nodes: GraphNode[], edges: GraphEdge[], sourceNodeId: string): Omit<SSSPResult, 'timestamp' | 'computationTime' | 'algorithm'> {
  const distances: Record<string, number> = {}
  const predecessors: Record<string, string | null> = {}
  
  
  for (const node of nodes) {
    distances[node.id] = node.id === sourceNodeId ? 0 : Infinity
    predecessors[node.id] = null
  }
  
  
  for (let i = 0; i < nodes.length - 1; i++) {
    for (const edge of edges) {
      const weight = edge.weight || 1
      if (distances[edge.source] !== Infinity) {
        const newDistance = distances[edge.source] + weight
        if (newDistance < distances[edge.target]) {
          distances[edge.target] = newDistance
          predecessors[edge.target] = edge.source
        }
      }
      
      if (distances[edge.target] !== Infinity) {
        const newDistance = distances[edge.target] + weight
        if (newDistance < distances[edge.source]) {
          distances[edge.source] = newDistance
          predecessors[edge.source] = edge.target
        }
      }
    }
  }
  
  
  for (const edge of edges) {
    const weight = edge.weight || 1
    if (distances[edge.source] !== Infinity && 
        distances[edge.source] + weight < distances[edge.target]) {
      logger.warn('Negative cycle detected in graph')
    }
  }
  
  const unreachableCount = Object.values(distances).filter(d => d === Infinity).length
  
  return {
    sourceNodeId,
    distances,
    predecessors,
    unreachableCount
  }
}

export const useAnalyticsStore = create<AnalyticsState>()(
  persist(
    (set, get) => ({
      
      currentResult: null,
      cache: {},
      loading: false,
      error: null,
      lastGraphHash: null,
      metrics: {
        totalComputations: 0,
        cacheHits: 0,
        cacheMisses: 0,
        averageComputationTime: 0,
        lastComputationTime: 0
      },

      computeSSSP: async (nodes, edges, sourceNodeId, algorithm = 'dijkstra') => {
        const startTime = performance.now()

        set({ loading: true, error: null })

        try {
          
          if (!nodes.length || !sourceNodeId) {
            throw new Error('Invalid input: nodes array is empty or sourceNodeId is missing')
          }

          const sourceNode = nodes.find(n => n.id === sourceNodeId)
          if (!sourceNode) {
            throw new Error(`Source node with id ${sourceNodeId} not found`)
          }

          
          const graphHash = hashGraph(nodes, edges)

          
          const cachedResult = get().getCachedResult(sourceNodeId, graphHash)
          if (cachedResult) {
            const computationTime = performance.now() - startTime
            get().updateMetrics(computationTime, true)

            set({
              currentResult: cachedResult,
              loading: false,
              lastGraphHash: graphHash
            })

            if (debugState.isEnabled()) {
              logger.info('SSSP result retrieved from cache', { sourceNodeId, algorithm })
            }

            return cachedResult
          }

          
          let result: SSSPResult

          
          try {
            const response = await unifiedApiClient.post('/api/analytics/shortest-path', {
              source_node_id: parseInt(sourceNodeId), 
            })

            const data = response.data

            if (!data.success) {
              throw new Error(data.error || 'SSSP computation failed on server')
            }

            
            const distances: Record<string, number> = {}
            const predecessors: Record<string, string | null> = {}

            for (const [nodeId, distance] of Object.entries(data.distances || {})) {
              distances[nodeId] = distance === null ? Infinity : distance as number
              
              predecessors[nodeId] = null
            }

            const computationTime = performance.now() - startTime

            result = {
              sourceNodeId,
              distances,
              predecessors,
              unreachableCount: data.unreachable_count || 0,
              algorithm,
              computationTime,
              timestamp: Date.now()
            }

            if (debugState.isEnabled()) {
              logger.info('SSSP computed on server', {
                sourceNodeId,
                algorithm,
                unreachableCount: result.unreachableCount,
                computationTime
              })
            }

          } catch (apiError) {
            
            logger.warn('Server SSSP failed, falling back to local computation', apiError)

            
            let baseResult: Omit<SSSPResult, 'timestamp' | 'computationTime' | 'algorithm'>

            switch (algorithm) {
              case 'bellman-ford':
                baseResult = bellmanFord(nodes, edges, sourceNodeId)
                break
              case 'dijkstra':
              default:
                baseResult = dijkstra(nodes, edges, sourceNodeId)
                break
            }

            const computationTime = performance.now() - startTime

            result = {
              ...baseResult,
              algorithm,
              computationTime,
              timestamp: Date.now()
            }
          }

          
          set(state => produce(state, draft => {
            draft.currentResult = result
            draft.loading = false
            draft.lastGraphHash = graphHash
            
            
            draft.cache[sourceNodeId] = {
              result,
              lastAccessed: Date.now(),
              graphHash
            }
            
            
            const cacheEntries = Object.entries(draft.cache)
            if (cacheEntries.length > 50) {
              
              const sortedEntries = cacheEntries.sort(([,a], [,b]) => b.lastAccessed - a.lastAccessed)
              draft.cache = Object.fromEntries(sortedEntries.slice(0, 50))
            }
          }))
          
          
          get().updateMetrics(result.computationTime, false)

          if (debugState.isEnabled()) {
            logger.info('SSSP computation completed', {
              sourceNodeId,
              algorithm,
              computationTime: `${result.computationTime.toFixed(2)}ms`,
              unreachableCount: result.unreachableCount,
              totalNodes: nodes.length
            })
          }
          
          return result
          
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : 'Unknown error during SSSP computation'
          
          logger.error('SSSP computation failed:', createErrorMetadata(error))
          
          set({ 
            loading: false, 
            error: errorMessage 
          })
          
          throw error
        }
      },

      clearResults: () => {
        set({ 
          currentResult: null, 
          error: null 
        })
        
        if (debugState.isEnabled()) {
          logger.info('SSSP results cleared')
        }
      },

      clearCache: () => {
        set({ cache: {} })
        
        if (debugState.isEnabled()) {
          logger.info('SSSP cache cleared')
        }
      },

      getCachedResult: (sourceNodeId, graphHash) => {
        const state = get()
        const cached = state.cache[sourceNodeId]
        
        if (cached && cached.graphHash === graphHash) {
          
          set(state => produce(state, draft => {
            if (draft.cache[sourceNodeId]) {
              draft.cache[sourceNodeId].lastAccessed = Date.now()
            }
          }))
          
          return cached.result
        }
        
        return null
      },

      normalizeDistances: (result) => {
        if (!result) return {}
        
        const distances = { ...result.distances }
        const finiteDistances = Object.values(distances).filter(d => isFinite(d))
        
        if (finiteDistances.length === 0) return distances
        
        const maxDistance = Math.max(...finiteDistances)
        const minDistance = Math.min(...finiteDistances)
        const range = maxDistance - minDistance
        
        if (range === 0) {
          
          Object.keys(distances).forEach(nodeId => {
            if (isFinite(distances[nodeId])) {
              distances[nodeId] = 1
            }
          })
        } else {
          
          Object.keys(distances).forEach(nodeId => {
            if (isFinite(distances[nodeId])) {
              distances[nodeId] = (distances[nodeId] - minDistance) / range
            }
          })
        }
        
        return distances
      },

      getUnreachableNodes: (result) => {
        if (!result) return []
        
        return Object.entries(result.distances)
          .filter(([, distance]) => !isFinite(distance))
          .map(([nodeId]) => nodeId)
      },

      invalidateCache: () => {
        set({ 
          cache: {},
          lastGraphHash: null 
        })
        
        if (debugState.isEnabled()) {
          logger.info('SSSP cache invalidated')
        }
      },

      cleanExpiredCache: (maxAge = 24 * 60 * 60 * 1000) => { 
        const now = Date.now()
        
        set(state => produce(state, draft => {
          Object.entries(draft.cache).forEach(([sourceNodeId, cached]) => {
            if (now - cached.lastAccessed > maxAge) {
              delete draft.cache[sourceNodeId]
            }
          })
        }))
        
        if (debugState.isEnabled()) {
          logger.info('Expired SSSP cache entries cleaned', { maxAge })
        }
      },

      setError: (error) => {
        set({ error })
      },

      updateMetrics: (computationTime, fromCache) => {
        set(state => produce(state, draft => {
          draft.metrics.totalComputations += 1
          draft.metrics.lastComputationTime = computationTime
          
          if (fromCache) {
            draft.metrics.cacheHits += 1
          } else {
            draft.metrics.cacheMisses += 1
            
            
            const totalNonCacheComputations = draft.metrics.cacheMisses
            const currentAverage = draft.metrics.averageComputationTime
            draft.metrics.averageComputationTime = 
              (currentAverage * (totalNonCacheComputations - 1) + computationTime) / totalNonCacheComputations
          }
        }))
      },

      resetMetrics: () => {
        set(state => produce(state, draft => {
          draft.metrics = {
            totalComputations: 0,
            cacheHits: 0,
            cacheMisses: 0,
            averageComputationTime: 0,
            lastComputationTime: 0
          }
        }))
        
        if (debugState.isEnabled()) {
          logger.info('SSSP metrics reset')
        }
      }
    }),
    {
      name: 'analytics-store',
      storage: createJSONStorage(() => localStorage),
      partialize: (state) => ({
        cache: state.cache,
        metrics: state.metrics
      }),
      onRehydrateStorage: () => (state) => {
        if (state && debugState.isEnabled()) {
          logger.info('Analytics store rehydrated', {
            cacheEntries: Object.keys(state.cache || {}).length,
            metrics: state.metrics
          })
        }
      }
    }
  )
)

// Utility hooks for common operations
export const useCurrentSSSPResult = () => useAnalyticsStore(state => state.currentResult)
export const useSSSPLoading = () => useAnalyticsStore(state => state.loading)
export const useSSSPError = () => useAnalyticsStore(state => state.error)
export const useSSSPMetrics = () => useAnalyticsStore(state => state.metrics)


--------------------------------------------------------------------------------
FILE: client/src/features/bots/contexts/BotsDataContext.tsx
PURPOSE: Bots data context provider
--------------------------------------------------------------------------------

import React, { createContext, useContext, useState, useEffect, useMemo } from 'react';
import type { BotsAgent, BotsEdge, BotsFullUpdateMessage } from '../types/BotsTypes';
import { botsWebSocketIntegration } from '../services/BotsWebSocketIntegration';
import { parseBinaryNodeData, isAgentNode, getActualNodeId } from '../../../types/binaryProtocol';
import { useAgentPolling } from '../hooks/useAgentPolling';
import { agentPollingService } from '../services/AgentPollingService';
import { createLogger } from '../../../utils/loggerConfig';

const logger = createLogger('BotsDataContext');

interface BotsData {
  nodeCount: number;
  edgeCount: number;
  tokenCount: number;
  mcpConnected: boolean;
  dataSource: string;
  
  agents: BotsAgent[];
  edges: BotsEdge[];  
  multiAgentMetrics?: {
    totalAgents: number;
    activeAgents: number;
    totalTasks: number;
    completedTasks: number;
    avgSuccessRate: number;
    totalTokens: number;
  };
  lastUpdate?: string;
}

interface BotsDataContextType {
  botsData: BotsData | null;
  updateBotsData: (data: BotsData) => void;
  updateFromFullUpdate: (update: BotsFullUpdateMessage) => void;
  pollingStatus?: {
    isPolling: boolean;
    activityLevel: 'active' | 'idle';
    lastUpdate: number;
    error: Error | null;
  };
  pollNow?: () => Promise<void>;
  configurePolling?: (config: any) => void;
}

const BotsDataContext = createContext<BotsDataContextType | undefined>(undefined);

export const BotsDataProvider: React.FC<{ children: React.ReactNode }> = ({ children }) => {
  
  
  const pollingData = useAgentPolling({
    enabled: true,
    config: {
      activePollingInterval: 3000,  
      idlePollingInterval: 15000,   
      enableSmartPolling: true      
    },
    onError: (error) => {
      logger.error('Polling error:', error);
    }
  });

  const [botsData, setBotsData] = useState<BotsData | null>({
    nodeCount: 0,
    edgeCount: 0,
    tokenCount: 0,
    mcpConnected: false,
    dataSource: 'live',
    agents: [],
    edges: []  
  });

  const updateBotsData = (data: BotsData) => {
    setBotsData(data);
  };

  const updateFromFullUpdate = (update: BotsFullUpdateMessage) => {
    setBotsData(prev => ({
      ...prev!,
      agents: update.agents || [],
      nodeCount: update.agents?.length || 0,
      edgeCount: 0, 
      tokenCount: update.multiAgentMetrics?.totalTokens || 0,
      mcpConnected: true,
      dataSource: 'live',
      multiAgentMetrics: update.multiAgentMetrics || {
        totalAgents: 0,
        activeAgents: 0,
        totalTasks: 0,
        completedTasks: 0,
        avgSuccessRate: 0,
        totalTokens: 0
      },
      lastUpdate: update.timestamp
    }));
  };

  
  const updateFromGraphData = (data: any) => {
    
    if (!data) {
      logger.warn('updateFromGraphData received undefined data');
      return;
    }
    
    
    const transformedAgents = (data.nodes || []).map((node: any) => {
      
      const agentType = node.metadata?.agent_type || node.type || node.node_type || node.nodeType;

      if (!agentType) {
        console.error('Missing agent type for node:', {
          nodeId: node.id,
          metadataId: node.metadataId || node.metadata_id,
          metadata: node.metadata,
          type: node.type,
          node_type: node.node_type,
          nodeType: node.nodeType
        });
      }

      
      const position = node.data?.position || {
        x: node.data?.x || 0,
        y: node.data?.y || 0,
        z: node.data?.z || 0
      };

      const velocity = node.data?.velocity || {
        x: node.data?.vx || 0,
        y: node.data?.vy || 0,
        z: node.data?.vz || 0
      };

      return {
        
        id: node.metadataId || node.metadata_id || String(node.id),
        name: node.label || node.metadata?.name || `Agent-${node.id}`,
        type: agentType,
        status: node.metadata?.status || 'active', 
        position,
        velocity,
        force: { x: 0, y: 0, z: 0 },
        
        cpuUsage: parseFloat(node.metadata?.cpu_usage || '0'),
        memoryUsage: parseFloat(node.metadata?.memory_usage || '0'),
        health: parseFloat(node.metadata?.health || '100'),
        workload: parseFloat(node.metadata?.workload || '0'),
        tokens: parseInt(node.metadata?.tokens || '0'),
        createdAt: node.metadata?.created_at || new Date().toISOString(),
        age: parseInt(node.metadata?.age || '0'),
        
        swarmId: node.metadata?.swarm_id,
        parentQueenId: node.metadata?.parent_queen_id,
        capabilities: node.metadata?.capabilities ?
          node.metadata.capabilities.split(',').map((cap: string) => cap.trim()).filter((cap: string) => cap) :
          undefined,
        connections: [],
      };
    });

    
    
    const nodeIdToAgentId = new Map();
    data.nodes?.forEach((node: any) => {
      nodeIdToAgentId.set(node.id, node.metadataId || node.metadata_id || String(node.id));
    });

    const transformedEdges = (data.edges || []).map((edge: any) => ({
      id: edge.id,
      source: nodeIdToAgentId.get(edge.source) || String(edge.source),
      target: nodeIdToAgentId.get(edge.target) || String(edge.target),
      dataVolume: edge.weight * 1000,  
      messageCount: Math.floor(edge.weight * 10),  
    }));
    
    setBotsData(prev => ({
      ...prev!,
      agents: transformedAgents,
      edges: transformedEdges,
      nodeCount: transformedAgents.length,
      edgeCount: transformedEdges.length,
      tokenCount: transformedAgents.reduce((sum: number, agent: any) => sum + (agent.tokens || 0), 0),
      mcpConnected: true,
      dataSource: 'live',
      lastUpdate: new Date().toISOString()
    }));
  };

  
  const updateFromBinaryPositions = (binaryData: ArrayBuffer) => {
    try {
      
      const nodeUpdates = parseBinaryNodeData(binaryData);

      
      const agentUpdates = nodeUpdates.filter(node => isAgentNode(node.nodeId));

      if (agentUpdates.length === 0) {
        return; 
      }

      logger.debug(`Processing ${agentUpdates.length} agent position updates from binary data`);

      setBotsData(prev => {
        if (!prev) return prev;

        
        const updatedAgents = prev.agents.map(agent => {
          
          const positionUpdate = agentUpdates.find(update => {
            const actualNodeId = getActualNodeId(update.nodeId);
            
            return String(actualNodeId) === agent.id || actualNodeId.toString() === agent.id;
          });

          if (positionUpdate) {
            
            return {
              ...agent,
              position: positionUpdate.position,
              velocity: positionUpdate.velocity,
              
              ssspDistance: positionUpdate.ssspDistance,
              ssspParent: positionUpdate.ssspParent,
              
              lastPositionUpdate: Date.now()
            };
          }

          return agent;
        });

        return {
          ...prev,
          agents: updatedAgents,
          lastUpdate: new Date().toISOString()
        };
      });
    } catch (error) {
      logger.error('Error processing binary position updates:', error);
    }
  };

  
  useEffect(() => {
    if (pollingData.agents.length > 0 || pollingData.edges.length > 0) {
      setBotsData({
        nodeCount: pollingData.agents.length,
        edgeCount: pollingData.edges.length,
        tokenCount: pollingData.metadata?.totalTokens || 0,
        mcpConnected: pollingData.isPolling,
        dataSource: 'live',
        agents: pollingData.agents,
        edges: pollingData.edges,
        multiAgentMetrics: pollingData.metadata,
        lastUpdate: new Date(pollingData.lastUpdate).toISOString()
      });
    }
  }, [pollingData]);

  
  
  useEffect(() => {
    
    const unsubscribe = botsWebSocketIntegration.on('bots-binary-position-update', (binaryData: ArrayBuffer) => {
      updateFromBinaryPositions(binaryData);
    });

    
    

    return () => {
      unsubscribe();
    };
  }, []);

  
  const contextValue = useMemo(() => ({
    botsData,
    updateBotsData,
    updateFromFullUpdate,
    
    pollingStatus: {
      isPolling: pollingData.isPolling,
      activityLevel: pollingData.activityLevel,
      lastUpdate: pollingData.lastUpdate,
      error: pollingData.error
    },
    pollNow: pollingData.pollNow,
    configurePolling: pollingData.configure
  }), [botsData, pollingData]);

  return (
    <BotsDataContext.Provider value={contextValue}>
      {children}
    </BotsDataContext.Provider>
  );
};

export const useBotsData = () => {
  const context = useContext(BotsDataContext);
  if (!context) {
    throw new Error('useBotsData must be used within a BotsDataProvider');
  }
  return context;
};
--------------------------------------------------------------------------------
FILE: client/src/features/bots/services/AgentPollingService.ts
PURPOSE: Agent polling and swarm data
--------------------------------------------------------------------------------

import { createLogger } from '../../../utils/loggerConfig';
import { unifiedApiClient } from '../../../services/api/UnifiedApiClient';
import type { BotsAgent, BotsEdge } from '../types/BotsTypes';
import { PollingPerformanceMonitor } from '../utils/pollingPerformance';

const logger = createLogger('AgentPollingService');

export interface AgentSwarmData {
  nodes: Array<{
    id: number;
    metadataId: string; 
    label: string;
    type?: string; 
    data?: {
      nodeId?: number;
      x?: number;
      y?: number;
      z?: number;
      vx?: number;
      vy?: number;
      vz?: number;
      position?: { x: number; y: number; z: number };
      velocity?: { x: number; y: number; z: number };
    };
    metadata?: {
      agent_type?: string;
      status?: string;
      health?: string;
      cpu_usage?: string;
      memory_usage?: string;
      workload?: string;
      tokens?: string;
      created_at?: string;
      age?: string;
      swarm_id?: string;
      parent_queen_id?: string;
      capabilities?: string;
    };
  }>;
  edges: Array<{
    id: string;
    source: number;
    target: number;
    weight: number;
  }>;
  metadata?: {
    total_agents: number;
    active_agents: number;
    total_tasks: number;
    completed_tasks: number;
    avg_success_rate: number;
    total_tokens: number;
  };
}

export interface PollingConfig {
  activePollingInterval: number; 
  idlePollingInterval: number;   
  enableSmartPolling: boolean;   
  maxRetries: number;
  retryDelay: number;
}

type PollingCallback = (data: AgentSwarmData) => void;
type ErrorCallback = (error: Error) => void;

export class AgentPollingService {
  private static instance: AgentPollingService;
  private pollingTimer: NodeJS.Timeout | null = null;
  private config: PollingConfig;
  private callbacks: Set<PollingCallback> = new Set();
  private errorCallbacks: Set<ErrorCallback> = new Set();
  private isPolling: boolean = false;
  private lastPollTime: number = 0;
  private lastDataHash: string = '';
  private retryCount: number = 0;
  private currentInterval: number;
  private activityLevel: 'active' | 'idle' = 'idle';
  private lastActivityCheck: number = 0;
  private performanceMonitor: PollingPerformanceMonitor;

  private constructor() {
    this.config = {
      activePollingInterval: 2000,  
      idlePollingInterval: 10000,   
      enableSmartPolling: true,
      maxRetries: 3,
      retryDelay: 2000
    };
    this.currentInterval = this.config.idlePollingInterval;
    this.performanceMonitor = new PollingPerformanceMonitor();
  }

  public static getInstance(): AgentPollingService {
    if (!AgentPollingService.instance) {
      AgentPollingService.instance = new AgentPollingService();
    }
    return AgentPollingService.instance;
  }

  
  public configure(config: Partial<PollingConfig>): void {
    this.config = { ...this.config, ...config };
    logger.debug('Polling configuration updated:', this.config);
    
    
    if (this.isPolling) {
      this.stop();
      this.start();
    }
  }

  
  public start(): void {
    if (this.isPolling) {
      logger.warn('Polling already active');
      return;
    }

    logger.debug('Starting agent swarm polling');
    this.isPolling = true;
    this.poll();
  }

  
  public stop(): void {
    if (this.pollingTimer) {
      clearTimeout(this.pollingTimer);
      this.pollingTimer = null;
    }
    this.isPolling = false;
    logger.debug('Agent swarm polling stopped');
  }

  
  public subscribe(callback: PollingCallback, errorCallback?: ErrorCallback): () => void {
    this.callbacks.add(callback);
    if (errorCallback) {
      this.errorCallbacks.add(errorCallback);
    }

    
    return () => {
      this.callbacks.delete(callback);
      if (errorCallback) {
        this.errorCallbacks.delete(errorCallback);
      }
    };
  }

  
  public async pollNow(): Promise<void> {
    if (!this.isPolling) {
      logger.warn('Cannot poll now - polling is not active');
      return;
    }
    
    
    if (this.pollingTimer) {
      clearTimeout(this.pollingTimer);
      this.pollingTimer = null;
    }
    
    await this.poll();
  }

  
  public getPerformanceMetrics() {
    return this.performanceMonitor.getMetrics();
  }

  
  public resetPerformanceMetrics(): void {
    this.performanceMonitor.reset();
  }

  
  public getStatus() {
    return {
      isPolling: this.isPolling,
      currentInterval: this.currentInterval,
      activityLevel: this.activityLevel,
      lastPollTime: this.lastPollTime,
      retryCount: this.retryCount,
      subscriberCount: this.callbacks.size,
      performance: this.performanceMonitor.getSummary()
    };
  }

  
  private async poll(): Promise<void> {
    if (!this.isPolling) return;

    try {
      const startTime = Date.now();
      
      
      const data = await unifiedApiClient.getData<AgentSwarmData>('/graph/data');
      
      const pollDuration = Date.now() - startTime;
      this.lastPollTime = Date.now();
      this.retryCount = 0; 

      
      const dataHash = this.hashData(data);
      const hasChanged = dataHash !== this.lastDataHash;
      this.lastDataHash = dataHash;
      
      
      this.performanceMonitor.recordPoll(pollDuration, hasChanged);

      
      if (this.config.enableSmartPolling) {
        this.updateActivityLevel(data, hasChanged);
      }

      
      if (hasChanged || Date.now() - this.lastActivityCheck > 10000) {
        logger.debug('Poll completed', {
          duration: pollDuration,
          hasChanged,
          activityLevel: this.activityLevel,
          nodeCount: data.nodes?.length || 0,
          activeAgents: data.metadata?.active_agents || 0
        });
        this.lastActivityCheck = Date.now();
      }

      
      if (hasChanged) {
        this.callbacks.forEach(callback => {
          try {
            callback(data);
          } catch (error) {
            logger.error('Error in polling callback:', error);
          }
        });
      }

    } catch (error) {
      this.handlePollingError(error as Error);
    }

    
    if (this.isPolling) {
      this.pollingTimer = setTimeout(() => this.poll(), this.currentInterval);
    }
  }

  
  private updateActivityLevel(data: AgentSwarmData, hasChanged: boolean): void {
    const activeAgents = data.metadata?.active_agents || 0;
    const totalAgents = data.metadata?.total_agents || 0;
    const activeRatio = totalAgents > 0 ? activeAgents / totalAgents : 0;

    
    const wasActive = this.activityLevel === 'active';
    
    
    
    
    
    if (activeRatio > 0.2 || hasChanged || (data.metadata?.total_tasks || 0) > (data.metadata?.completed_tasks || 0)) {
      this.activityLevel = 'active';
      this.currentInterval = this.config.activePollingInterval;
    } else {
      this.activityLevel = 'idle';
      this.currentInterval = this.config.idlePollingInterval;
    }

    
    if (wasActive !== (this.activityLevel === 'active')) {
      logger.info(`Activity level changed to ${this.activityLevel}, interval: ${this.currentInterval}ms`);
    }
  }

  
  private handlePollingError(error: Error): void {
    this.retryCount++;
    logger.error('Polling error:', error, { retryCount: this.retryCount });
    
    
    this.performanceMonitor.recordError();

    
    this.errorCallbacks.forEach(callback => {
      try {
        callback(error);
      } catch (err) {
        logger.error('Error in error callback:', err);
      }
    });

    if (this.retryCount >= this.config.maxRetries) {
      logger.error('Max retries reached, stopping polling');
      this.stop();
      return;
    }

    
    const retryDelay = this.config.retryDelay * Math.pow(2, this.retryCount - 1);
    logger.info(`Retrying poll in ${retryDelay}ms`);
    
    if (this.isPolling) {
      this.pollingTimer = setTimeout(() => this.poll(), retryDelay);
    }
  }

  
  private hashData(data: AgentSwarmData): string {
    const relevant = {
      nodeCount: data.nodes?.length || 0,
      edgeCount: data.edges?.length || 0,
      activeAgents: data.metadata?.active_agents || 0,
      totalTasks: data.metadata?.total_tasks || 0,
      completedTasks: data.metadata?.completed_tasks || 0,
      
      positions: data.nodes?.map(n => 
        `${n.id}:${n.data?.position?.x?.toFixed(1)},${n.data?.position?.y?.toFixed(1)},${n.data?.position?.z?.toFixed(1)}`
      ).join('|')
    };
    return JSON.stringify(relevant);
  }
}

// Export singleton instance
export const agentPollingService = AgentPollingService.getInstance();
--------------------------------------------------------------------------------
FILE: client/src/features/settings/config/settings.ts
PURPOSE: Settings definitions and paths
--------------------------------------------------------------------------------
// Type definitions for settings

export type SettingsPath = string | '';

// Node settings
export interface NodeSettings {
  baseColor: string;
  metalness: number;
  opacity: number;
  roughness: number;
  nodeSize: number; 
  quality: 'low' | 'medium' | 'high';
  enableInstancing: boolean;
  enableHologram: boolean;
  enableMetadataShape: boolean;
  enableMetadataVisualisation: boolean;
}

// Edge settings
export interface EdgeSettings {
  arrowSize: number;
  baseWidth: number;
  color: string;
  enableArrows: boolean;
  opacity: number;
  widthRange: [number, number];
  quality: 'low' | 'medium' | 'high';
  enableFlowEffect: boolean;
  flowSpeed: number;
  flowIntensity: number;
  glowStrength: number;
  distanceIntensity: number;
  useGradient: boolean;
  gradientColors: [string, string];
}

// Physics settings - using camelCase for client
export interface PhysicsSettings {
  enabled: boolean;
  
  
  springK: number;
  repelK: number;
  attractionK: number;
  gravity: number;
  
  
  dt: number;
  maxVelocity: number;
  damping: number;
  temperature: number;
  
  
  enableBounds: boolean;
  boundsSize: number;
  boundaryDamping: number;
  separationRadius: number;
  collisionRadius?: number; 
  
  
  restLength: number;
  repulsionCutoff: number;
  repulsionSofteningEpsilon: number;
  centerGravityK: number;
  gridCellSize: number;
  featureFlags: number;
  
  
  stressWeight: number;
  stressAlpha: number;
  boundaryLimit: number;
  alignmentStrength: number;
  clusterStrength: number;
  computeMode: number;
  minDistance: number;
  maxRepulsionDist: number;
  boundaryMargin: number;
  boundaryForceStrength: number;
  
  
  iterations: number;
  massScale: number;
  updateThreshold: number;
  
  
  
  boundaryExtremeMultiplier: number;
  
  boundaryExtremeForceMultiplier: number;
  
  boundaryVelocityDamping: number;
  
  maxForce: number;
  
  seed: number;
  
  iteration: number;
  
  
  warmupIterations: number;
  warmupCurve?: string; 
  zeroVelocityIterations?: number; 
  coolingRate: number;
  
  
  clusteringAlgorithm?: string;
  clusterCount?: number;
  clusteringResolution?: number;
  clusteringIterations?: number;

  // SSSP (Single Source Shortest Path) integration
  useSsspDistances?: boolean;
  ssspAlpha?: number;
}

// Rendering settings
export interface RenderingSettings {
  ambientLightIntensity: number;
  backgroundColor: string;
  directionalLightIntensity: number;
  enableAmbientOcclusion: boolean;
  enableAntialiasing: boolean;
  enableShadows: boolean;
  environmentIntensity: number;
  shadowMapSize: string;
  shadowBias: number;
  context: 'desktop' | 'ar';
}

// Animation settings
export interface AnimationSettings {
  enableMotionBlur: boolean;
  enableNodeAnimations: boolean;
  motionBlurStrength: number;
  selectionWaveEnabled: boolean;
  pulseEnabled: boolean;
  pulseSpeed: number;
  pulseStrength: number;
  waveSpeed: number;
}

// Label settings
export interface LabelSettings {
  desktopFontSize: number;
  enableLabels: boolean;
  textColor: string;
  textOutlineColor: string;
  textOutlineWidth: number;
  textResolution: number;
  textPadding: number;
  billboardMode: 'camera' | 'vertical';
  showMetadata?: boolean; 
  maxLabelWidth?: number; 
}


// Glow settings - Unified visual effects with diffuse atmospheric rendering
// This is the server-preferred interface, but client supports both
export interface GlowSettings {
  
  enabled: boolean;
  intensity: number;
  radius: number;
  threshold: number;
  
  
  diffuseStrength: number;
  atmosphericDensity: number;
  volumetricIntensity: number;
  
  
  baseColor: string;
  emissionColor: string;
  opacity: number;
  
  
  pulseSpeed: number;
  flowSpeed: number;
  
  
  nodeGlowStrength: number;
  edgeGlowStrength: number;
  environmentGlowStrength: number;
}

// Hologram settings - Enhanced with atmospheric effects
export interface HologramSettings {
  
  ringCount: number;
  ringColor: string;
  ringOpacity: number;
  sphereSizes: [number, number];
  globalRotationSpeed: number;
  
  
  enableBuckminster: boolean;
  buckminsterSize: number;
  buckminsterOpacity: number;
  enableGeodesic: boolean;
  geodesicSize: number;
  geodesicOpacity: number;
  enableTriangleSphere: boolean;
  triangleSphereSize: number;
  triangleSphereOpacity: number;
  
  
  enableQuantumField: boolean;
  quantumFieldIntensity: number;
  enablePlasmaEffects: boolean;
  plasmaIntensity: number;
  enableEnergyFlow: boolean;
  energyFlowSpeed: number;
  
  
  ringRotationSpeed: number;
  enableRingParticles: boolean;
  particleDensity: number;
}

// WebSocket settings
export interface WebSocketSettings {
  reconnectAttempts: number;
  reconnectDelay: number;
  binaryChunkSize: number;
  binaryUpdateRate?: number;
  minUpdateRate?: number;
  maxUpdateRate?: number;
  motionThreshold?: number;
  motionDamping?: number;
  binaryMessageVersion?: number;
  compressionEnabled: boolean;
  compressionThreshold: number;
  heartbeatInterval?: number;
  heartbeatTimeout?: number;
  maxConnections?: number;
  maxMessageSize?: number;
  updateRate: number;
}

// Debug settings
export interface DebugSettings {
  enabled: boolean;
  logLevel?: 'debug' | 'info' | 'warn' | 'error'; 
  logFormat?: 'json' | 'text';
  enableDataDebug: boolean;
  enableWebsocketDebug: boolean;
  logBinaryHeaders: boolean;
  logFullJson: boolean;
  enablePhysicsDebug?: boolean;
  enableNodeDebug?: boolean;
  enableShaderDebug?: boolean;
  enableMatrixDebug?: boolean;
  enablePerformanceDebug?: boolean;
}

// SpacePilot settings
export interface SpacePilotConfig {
  enabled: boolean;
  mode: 'camera' | 'object' | 'navigation';
  sensitivity: {
    translation: number;
    rotation: number;
  };
  smoothing: number;
  deadzone: number;
  buttonFunctions?: Record<number, string>;
}

// XR settings
export interface XRSettings {
  enabled: boolean;
  clientSideEnableXR?: boolean; 
  mode?: 'inline' | 'immersive-vr' | 'immersive-ar'; 
  roomScale?: number;
  spaceType?: 'local-floor' | 'bounded-floor' | 'unbounded';
  quality?: 'low' | 'medium' | 'high';
  enableHandTracking: boolean;
  handMeshEnabled?: boolean;
  handMeshColor?: string;
  handMeshOpacity?: number;
  handPointSize?: number;
  handRayEnabled?: boolean;
  handRayColor?: string;
  handRayWidth?: number;
  gestureSmoothing?: number;
  enableHaptics: boolean;
  hapticIntensity?: number;
  dragThreshold?: number;
  pinchThreshold?: number;
  rotationThreshold?: number;
  interactionRadius?: number;
  movementSpeed?: number;
  deadZone?: number;
  movementAxes?: {
    horizontal: number;
    vertical: number;
  };
  enableLightEstimation?: boolean;
  enablePlaneDetection?: boolean;
  enableSceneUnderstanding?: boolean;
  planeColor?: string;
  planeOpacity?: number;
  planeDetectionDistance?: number;
  showPlaneOverlay?: boolean;
  snapToFloor?: boolean;
  enablePassthroughPortal?: boolean;
  passthroughOpacity?: number;
  passthroughBrightness?: number;
  passthroughContrast?: number;
  portalSize?: number;
  portalEdgeColor?: string;
  portalEdgeWidth?: number;
  controllerModel?: string;
  renderScale?: number;
  interactionDistance?: number;
  locomotionMethod?: 'teleport' | 'continuous';
  teleportRayColor?: string;
  controllerRayColor?: string;
}

// Head-tracked parallax settings
export interface HeadTrackedParallaxSettings {
  enabled: boolean;
  sensitivity: number;
  cameraMode: 'offset' | 'asymmetricFrustum';
}

// Interaction settings
export interface InteractionSettings {
  headTrackedParallax: HeadTrackedParallaxSettings;
}

// Visualisation settings
export interface CameraSettings {
  fov: number;
  near: number;
  far: number;
  position: { x: number; y: number; z: number };
  lookAt?: { x: number; y: number; z: number }; 
}

// Graph-specific settings namespace
export interface GraphSettings {
  nodes: NodeSettings;
  edges: EdgeSettings;
  labels: LabelSettings;
  physics: PhysicsSettings;
}

// Multi-graph namespace structure
export interface GraphsSettings {
  logseq: GraphSettings;
  visionflow: GraphSettings;
}

export interface VisualisationSettings {

  rendering: RenderingSettings;
  animations: AnimationSettings;
  glow: GlowSettings;
  hologram: HologramSettings;
  spacePilot?: SpacePilotConfig;
  camera?: CameraSettings;
  interaction?: InteractionSettings;


  graphs: GraphsSettings;

  // Legacy alias for glow settings (bloom was renamed to glow)
  bloom?: GlowSettings;
  // Direct access shortcuts (alias to graphs.logseq.*)
  nodes?: NodeSettings;
  edges?: EdgeSettings;
  labels?: LabelSettings;
}

// System settings
export interface SystemSettings {
  websocket: WebSocketSettings;
  debug: DebugSettings;
  persistSettings: boolean; 
  customBackendUrl?: string; 
}

// RAGFlow settings
export interface RAGFlowSettings {
  apiKey?: string;
  agentId?: string;
  apiBaseUrl?: string;
  timeout?: number;
  maxRetries?: number;
  chatId?: string;
}

// Perplexity settings
export interface PerplexitySettings {
  apiKey?: string;
  model?: string;
  apiUrl?: string;
  maxTokens?: number;
  temperature?: number;
  topP?: number;
  presencePenalty?: number;
  frequencyPenalty?: number;
  timeout?: number;
  rateLimit?: number;
}

// OpenAI settings
export interface OpenAISettings {
  apiKey?: string;
  baseUrl?: string;
  timeout?: number;
  rateLimit?: number;
}

// Kokoro TTS settings
export interface KokoroSettings {
  apiUrl?: string;
  defaultVoice?: string;
  defaultFormat?: string;
  defaultSpeed?: number;
  timeout?: number;
  stream?: boolean;
  returnTimestamps?: boolean;
  sampleRate?: number;
}

// Auth settings
export interface AuthSettings {
  enabled: boolean;
  provider: 'nostr' | string; 
  required: boolean;
  nostr?: {
    connected: boolean;
    publicKey: string;
    isPowerUser?: boolean;
  };
}

// Whisper speech recognition settings
export interface WhisperSettings {
  apiUrl?: string;
  defaultModel?: string;
  defaultLanguage?: string;
  timeout?: number;
  temperature?: number;
  returnTimestamps?: boolean;
  vadFilter?: boolean;
  wordTimestamps?: boolean;
  initialPrompt?: string;
}

// Dashboard GPU status settings
export interface DashboardSettings {
  autoRefresh: boolean;
  refreshInterval: number;
  computeMode: 'Basic Force-Directed' | 'Dual Graph' | 'Constraint-Enhanced' | 'Visual Analytics';
  iterationCount: number;
  showConvergence: boolean;
  activeConstraints: number;
  clusteringActive: boolean;
}

// Analytics settings with GPU clustering
export interface AnalyticsSettings {
  updateInterval: number;
  showDegreeDistribution: boolean;
  showClusteringCoefficient: boolean;
  showCentrality: boolean;
  clustering: {
    algorithm: 'none' | 'kmeans' | 'spectral' | 'louvain';
    clusterCount: number;
    resolution: number;
    iterations: number;
    exportEnabled: boolean;
    importEnabled: boolean;
  };
}

// Performance settings with warmup controls
export interface PerformanceSettings {
  enableAdaptiveQuality: boolean;
  warmupDuration: number;
  convergenceThreshold: number;
  enableAdaptiveCooling: boolean;
}

// Developer GPU debug settings
export interface QualityGatesSettings {
  gpuAcceleration: boolean;
  ontologyPhysics: boolean;
  semanticForces: boolean;
  layoutMode: 'force-directed' | 'dag-topdown' | 'dag-radial' | 'dag-leftright' | 'type-clustering';
  showClusters: boolean;
  showAnomalies: boolean;
  showCommunities: boolean;
  ruvectorEnabled: boolean;
  gnnPhysics: boolean;
  minFpsThreshold: number;
  maxNodeCount: number;
  autoAdjust: boolean;
}

export interface DeveloperSettings {
  gpu: {
    showForceVectors: boolean;
    showConstraints: boolean;
    showBoundaryForces: boolean;
    showConvergenceGraph: boolean;
  };
  constraints: {
    active: Array<{
      id: string;
      name: string;
      enabled: boolean;
      description?: string;
      icon?: string;
    }>;
  };
}

// XR GPU optimization settings
export interface XRGPUSettings {
  enableOptimizedCompute: boolean;
  performance: {
    preset: 'Battery Saver' | 'Balanced' | 'Performance';
  };
  physics: {
    scale: number;
  };
}

// Vircadia integration settings
export interface VircadiaSettings {
  enabled: boolean;
  serverUrl: string;
  autoConnect: boolean;
}

// Node filter settings for graph visualization
export interface NodeFilterSettings {
  enabled: boolean;
  minConnections?: number;
  maxConnections?: number;
  nodeTypes?: string[];
  searchQuery?: string;
  qualityThreshold?: number;
  authorityThreshold?: number;
  filterByQuality?: boolean;
  filterByAuthority?: boolean;
  filterMode?: 'and' | 'or';
}

// Main settings interface - Single source of truth matching server AppFullSettings
export interface Settings {
  visualisation: VisualisationSettings;
  system: SystemSettings;
  xr: XRSettings & { gpu?: XRGPUSettings };
  auth: AuthSettings;
  ragflow?: RAGFlowSettings;
  perplexity?: PerplexitySettings;
  openai?: OpenAISettings;
  kokoro?: KokoroSettings;
  whisper?: WhisperSettings;
  dashboard?: DashboardSettings;
  analytics?: AnalyticsSettings;
  performance?: PerformanceSettings;
  developer?: DeveloperSettings;
  qualityGates?: QualityGatesSettings;
  vircadia?: VircadiaSettings;
  // Node filter settings for graph visualization
  nodeFilter?: NodeFilterSettings;
}

// Partial update types for settings mutations
export type DeepPartial<T> = T extends object ? {
  [P in keyof T]?: DeepPartial<T[P]>;
} : T;

export type SettingsUpdate = DeepPartial<Settings>;

================================================================================
                    SECTION 16: CLIENT HOOKS & APP
================================================================================

--------------------------------------------------------------------------------
FILE: client/src/hooks/useNostrAuth.ts
PURPOSE: Nostr authentication hook
--------------------------------------------------------------------------------
import { useState, useEffect } from 'react';
import { nostrAuth, AuthState } from '../services/nostrAuthService';
import { createLogger } from '../utils/loggerConfig';

const logger = createLogger('useNostrAuth');

export function useNostrAuth() {
  const [authState, setAuthState] = useState<AuthState>({
    authenticated: false,
    user: undefined,
    error: undefined
  });
  const [isLoading, setIsLoading] = useState(true);

  useEffect(() => {
    // Initialize auth service
    const initAuth = async () => {
      try {
        await nostrAuth.initialize();
        const currentState = nostrAuth.getCurrentAuthState();
        setAuthState(currentState);
      } catch (error) {
        logger.error('Failed to initialize auth:', error);
        setAuthState({
          authenticated: false,
          error: error instanceof Error ? error.message : 'Authentication initialization failed'
        });
      } finally {
        setIsLoading(false);
      }
    };

    initAuth();

    // Subscribe to auth state changes
    const unsubscribe = nostrAuth.onAuthStateChanged((newState) => {
      setAuthState(newState);
      setIsLoading(false);
    });

    return () => {
      unsubscribe();
    };
  }, []);

  const login = async () => {
    try {
      const newState = await nostrAuth.login();
      setAuthState(newState);
      return newState;
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Login failed';
      setAuthState({
        authenticated: false,
        error: errorMessage
      });
      throw error;
    }
  };

  const logout = async () => {
    try {
      await nostrAuth.logout();
      setAuthState({
        authenticated: false
      });
    } catch (error) {
      logger.error('Logout error:', error);
    }
  };

  const devLogin = async () => {
    try {
      const newState = await nostrAuth.devLogin();
      setAuthState(newState);
      return newState;
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Dev login failed';
      setAuthState({
        authenticated: false,
        error: errorMessage
      });
      throw error;
    }
  };

  return {
    ...authState,
    isLoading,
    login,
    logout,
    devLogin,
    hasNip07: nostrAuth.hasNip07Provider(),
    isDevLoginAvailable: nostrAuth.isDevLoginAvailable()
  };
}

--------------------------------------------------------------------------------
FILE: client/src/hooks/useSettingsWebSocket.ts
PURPOSE: WebSocket sync for settings
--------------------------------------------------------------------------------
import { useEffect, useRef, useState } from 'react';
import { useSettingsStore } from '../store/settingsStore';

// Mock toast function for notifications
const toast = (options: { title: string; description: string; duration?: number }) => {
  console.log(`[Toast] ${options.title}: ${options.description}`);
};



interface SettingsBroadcastMessage {
  type: 'SettingChanged' | 'SettingsBatchChanged' | 'SettingsReloaded' | 'PresetApplied' | 'Ping' | 'Pong';
  key?: string;
  value?: unknown;
  changes?: Array<{ key: string; value: unknown }>;
  timestamp: number;
  reason?: string;
  preset_id?: string;
  settings_count?: number;
}

interface UseSettingsWebSocketOptions {
  
  enabled?: boolean;
  
  autoReconnect?: boolean;
  
  reconnectDelay?: number;
  
  showNotifications?: boolean;
}

interface UseSettingsWebSocketReturn {
  
  connected: boolean;
  
  lastUpdate: Date | null;
  
  messageCount: number;
  
  reconnect: () => void;
  
  disconnect: () => void;
}

export const useSettingsWebSocket = (
  options: UseSettingsWebSocketOptions = {}
): UseSettingsWebSocketReturn => {
  const {
    enabled = true,
    autoReconnect = true,
    reconnectDelay = 3000,
    showNotifications = true
  } = options;

  // Use the store's set and batchUpdate methods
  const setByPath = useSettingsStore(state => state.setByPath);
  const batchUpdate = useSettingsStore(state => state.batchUpdate);

  const [connected, setConnected] = useState(false);
  const [lastUpdate, setLastUpdate] = useState<Date | null>(null);
  const [messageCount, setMessageCount] = useState(0);

  const wsRef = useRef<WebSocket | null>(null);
  const reconnectTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const reconnectAttemptsRef = useRef(0);

  const connect = () => {
    if (!enabled) return;

    
    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const host = window.location.host;
    const wsUrl = `${protocol}//${host}/ws/settings`;

    try {
      const ws = new WebSocket(wsUrl);
      wsRef.current = ws;

      ws.onopen = () => {
        console.log('[SettingsWS] Connected to settings WebSocket');
        setConnected(true);
        reconnectAttemptsRef.current = 0;

        if (showNotifications) {
          toast({
            title: 'Settings Sync',
            description: 'Real-time settings synchronization connected',
            duration: 2000,
          });
        }
      };

      ws.onmessage = (event) => {
        try {
          const message: SettingsBroadcastMessage = JSON.parse(event.data);
          handleMessage(message);
          setLastUpdate(new Date());
          setMessageCount(prev => prev + 1);
        } catch (error) {
          console.error('[SettingsWS] Failed to parse message:', error);
        }
      };

      ws.onerror = (error) => {
        console.error('[SettingsWS] WebSocket error:', error);
      };

      ws.onclose = () => {
        console.log('[SettingsWS] Connection closed');
        setConnected(false);
        wsRef.current = null;

        
        if (autoReconnect && enabled) {
          reconnectAttemptsRef.current += 1;
          const delay = Math.min(reconnectDelay * reconnectAttemptsRef.current, 30000);

          console.log(`[SettingsWS] Reconnecting in ${delay}ms (attempt ${reconnectAttemptsRef.current})`);

          reconnectTimeoutRef.current = setTimeout(() => {
            connect();
          }, delay);
        }
      };
    } catch (error) {
      console.error('[SettingsWS] Failed to connect:', error);
      setConnected(false);
    }
  };

  const handleMessage = (message: SettingsBroadcastMessage) => {
    switch (message.type) {
      case 'SettingChanged':
        if (message.key && message.value !== undefined) {
          console.log(`[SettingsWS] Setting changed: ${message.key}`);
          setByPath(message.key as any, message.value);

          if (showNotifications) {
            toast({
              title: 'Setting Updated',
              description: `${message.key} changed`,
              duration: 1500,
            });
          }
        }
        break;

      case 'SettingsBatchChanged':
        if (message.changes && message.changes.length > 0) {
          console.log(`[SettingsWS] Batch update: ${message.changes.length} settings`);

          const updates = message.changes.map(change => ({
            path: change.key as any,
            value: change.value
          }));

          batchUpdate(updates);

          if (showNotifications) {
            toast({
              title: 'Settings Updated',
              description: `${message.changes.length} settings synchronized`,
              duration: 2000,
            });
          }
        }
        break;

      case 'SettingsReloaded':
        console.log(`[SettingsWS] Settings reloaded: ${message.reason}`);

        if (showNotifications) {
          toast({
            title: 'Settings Reloaded',
            description: message.reason || 'Configuration updated',
            duration: 3000,
          });
        }

        
        window.location.reload();
        break;

      case 'PresetApplied':
        console.log(`[SettingsWS] Preset applied: ${message.preset_id}`);

        if (showNotifications) {
          toast({
            title: 'Preset Applied',
            description: `${message.preset_id} preset with ${message.settings_count} settings`,
            duration: 2000,
          });
        }
        break;

      case 'Ping':
        
        if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
          wsRef.current.send(JSON.stringify({
            type: 'Pong',
            timestamp: Date.now()
          }));
        }
        break;

      case 'Pong':
        
        break;

      default:
        console.warn('[SettingsWS] Unknown message type:', message.type);
    }
  };

  const disconnect = () => {
    if (reconnectTimeoutRef.current) {
      clearTimeout(reconnectTimeoutRef.current);
      reconnectTimeoutRef.current = null;
    }

    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }

    setConnected(false);
  };

  const reconnect = () => {
    disconnect();
    setTimeout(() => connect(), 100);
  };

  
  useEffect(() => {
    if (enabled) {
      connect();
    }

    
    return () => {
      disconnect();
    };
  }, [enabled]); 

  return {
    connected,
    lastUpdate,
    messageCount,
    reconnect,
    disconnect
  };
};

--------------------------------------------------------------------------------
FILE: client/src/hooks/useSolidPod.ts
PURPOSE: Solid pod operations hook
--------------------------------------------------------------------------------
/**
 * useSolidPod Hook
 *
 * Main hook for Solid Pod state management:
 * - Checks if user has a pod on auth
 * - Auto-provisions pod if needed
 * - Provides pod URL, WebID, loading/error states
 * - Subscribes to pod notifications via WebSocket
 * - Integrates with existing Nostr auth system
 */

import { useState, useEffect, useCallback, useRef } from 'react';
import solidPodService, {
  PodInfo,
  PodCreationResult,
  SolidNotification,
} from '../services/SolidPodService';
import { useNostrAuth } from './useNostrAuth';
import { createLogger } from '../utils/loggerConfig';

const logger = createLogger('useSolidPod');

// --- Types ---

export interface SolidPodState {
  /** URL of the user's pod */
  podUrl: string | null;
  /** User's WebID */
  webId: string | null;
  /** Whether pod check/creation is in progress */
  isLoading: boolean;
  /** Error message if any operation failed */
  error: string | null;
  /** Whether the WebSocket is connected */
  isConnected: boolean;
  /** Whether a pod exists for this user */
  hasPod: boolean;
}

export interface UseSolidPodOptions {
  /** Auto-provision pod if user doesn't have one */
  autoProvision?: boolean;
  /** Connect WebSocket for real-time notifications */
  enableWebSocket?: boolean;
  /** Custom pod name for auto-provisioning */
  defaultPodName?: string;
}

export interface UseSolidPodReturn extends SolidPodState {
  /** Manually create a pod */
  createPod: (name?: string) => Promise<PodCreationResult>;
  /** Refresh pod status */
  checkPod: () => Promise<PodInfo>;
  /** Subscribe to resource notifications */
  subscribe: (resourceUrl: string, callback: (notification: SolidNotification) => void) => () => void;
  /** Connect WebSocket manually */
  connectWebSocket: () => void;
  /** Disconnect WebSocket */
  disconnectWebSocket: () => void;
}

// --- Hook Implementation ---

export function useSolidPod(options: UseSolidPodOptions = {}): UseSolidPodReturn {
  const {
    autoProvision = false,
    enableWebSocket = true,
    defaultPodName,
  } = options;

  const { authenticated, user } = useNostrAuth();

  const [state, setState] = useState<SolidPodState>({
    podUrl: null,
    webId: null,
    isLoading: false,
    error: null,
    isConnected: false,
    hasPod: false,
  });

  const wsConnectedRef = useRef(false);
  const checkInProgressRef = useRef(false);

  // --- Pod Check ---

  const checkPod = useCallback(async (): Promise<PodInfo> => {
    if (checkInProgressRef.current) {
      return { exists: state.hasPod, podUrl: state.podUrl ?? undefined, webId: state.webId ?? undefined };
    }

    checkInProgressRef.current = true;
    setState((prev) => ({ ...prev, isLoading: true, error: null }));

    try {
      const podInfo = await solidPodService.checkPodExists();

      setState((prev) => ({
        ...prev,
        podUrl: podInfo.podUrl ?? null,
        webId: podInfo.webId ?? null,
        hasPod: podInfo.exists,
        isLoading: false,
      }));

      logger.debug('Pod check complete', { exists: podInfo.exists, podUrl: podInfo.podUrl });
      return podInfo;
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Failed to check pod';
      logger.error('Pod check failed', { error: err });

      setState((prev) => ({
        ...prev,
        isLoading: false,
        error: errorMessage,
      }));

      return { exists: false };
    } finally {
      checkInProgressRef.current = false;
    }
  }, [state.hasPod, state.podUrl, state.webId]);

  // --- Pod Creation ---

  const createPod = useCallback(async (name?: string): Promise<PodCreationResult> => {
    setState((prev) => ({ ...prev, isLoading: true, error: null }));

    try {
      const result = await solidPodService.createPod(name || defaultPodName);

      if (result.success) {
        setState((prev) => ({
          ...prev,
          podUrl: result.podUrl ?? null,
          webId: result.webId ?? null,
          hasPod: true,
          isLoading: false,
        }));

        logger.info('Pod created', { podUrl: result.podUrl });
      } else {
        setState((prev) => ({
          ...prev,
          isLoading: false,
          error: result.error ?? 'Pod creation failed',
        }));
      }

      return result;
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Pod creation failed';
      logger.error('Pod creation error', { error: err });

      setState((prev) => ({
        ...prev,
        isLoading: false,
        error: errorMessage,
      }));

      return { success: false, error: errorMessage };
    }
  }, [defaultPodName]);

  // --- WebSocket Management ---

  const connectWebSocket = useCallback(() => {
    if (wsConnectedRef.current) return;

    solidPodService.connectWebSocket();
    wsConnectedRef.current = true;
    setState((prev) => ({ ...prev, isConnected: true }));
    logger.debug('WebSocket connection initiated');
  }, []);

  const disconnectWebSocket = useCallback(() => {
    solidPodService.disconnect();
    wsConnectedRef.current = false;
    setState((prev) => ({ ...prev, isConnected: false }));
    logger.debug('WebSocket disconnected');
  }, []);

  const subscribe = useCallback(
    (resourceUrl: string, callback: (notification: SolidNotification) => void): (() => void) => {
      // Ensure WebSocket is connected
      if (!wsConnectedRef.current && enableWebSocket) {
        connectWebSocket();
      }

      return solidPodService.subscribe(resourceUrl, callback);
    },
    [connectWebSocket, enableWebSocket]
  );

  // --- Effects ---

  // Check pod on auth change
  useEffect(() => {
    if (!authenticated || !user) {
      // Reset state on logout
      setState({
        podUrl: null,
        webId: null,
        isLoading: false,
        error: null,
        isConnected: false,
        hasPod: false,
      });
      disconnectWebSocket();
      return;
    }

    const initializePod = async () => {
      const podInfo = await checkPod();

      // Auto-provision if enabled and no pod exists
      if (!podInfo.exists && autoProvision) {
        logger.info('Auto-provisioning pod');
        await createPod();
      }

      // Connect WebSocket if enabled and pod exists
      if (enableWebSocket && (podInfo.exists || autoProvision)) {
        connectWebSocket();
      }
    };

    initializePod();
  }, [authenticated, user, autoProvision, enableWebSocket, checkPod, createPod, connectWebSocket, disconnectWebSocket]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      disconnectWebSocket();
    };
  }, [disconnectWebSocket]);

  return {
    ...state,
    createPod,
    checkPod,
    subscribe,
    connectWebSocket,
    disconnectWebSocket,
  };
}

export default useSolidPod;

--------------------------------------------------------------------------------
FILE: client/src/app/App.tsx
PURPOSE: Main application component
--------------------------------------------------------------------------------
import { useEffect, useCallback, useState } from 'react'
import AppInitializer from './AppInitializer'
import { ApplicationModeProvider } from '../contexts/ApplicationModeContext';
import { useSettingsStore } from '../store/settingsStore';
import { createLogger } from '../utils/loggerConfig';
import MainLayout from './MainLayout';
import { useQuest3Integration } from '../hooks/useQuest3Integration';
import { ImmersiveApp } from '../immersive/components/ImmersiveApp';
import { BotsDataProvider } from '../features/bots/contexts/BotsDataContext';
import { CommandPalette } from '../features/command-palette/components/CommandPalette';
import { initializeCommandPalette } from '../features/command-palette/defaultCommands';
import { HelpProvider } from '../features/help/components/HelpProvider';
import { registerSettingsHelp } from '../features/help/settingsHelp';
import { OnboardingProvider } from '../features/onboarding/components/OnboardingProvider';
import { registerOnboardingCommands } from '../features/onboarding/flows/defaultFlows';
import { TooltipProvider } from '../features/design-system/components/Tooltip';
import { useBotsWebSocketIntegration } from '../features/bots/hooks/useBotsWebSocketIntegration';
import { DebugControlPanel } from '../components/DebugControlPanel';
import { ConnectionWarning } from '../components/ConnectionWarning';
import { useAutoBalanceNotifications } from '../hooks/useAutoBalanceNotifications';
import ErrorBoundary from '../components/ErrorBoundary';
import { remoteLogger } from '../services/remoteLogger';
import { VircadiaProvider } from '../contexts/VircadiaContext';
import { VircadiaBridgesProvider } from '../contexts/VircadiaBridgesContext';
import { useNostrAuth } from '../hooks/useNostrAuth';
import { NostrLoginScreen } from '../components/NostrLoginScreen';
import { LoadingScreen } from '../components/LoadingScreen';
import solidPodService from '../services/SolidPodService';

const logger = createLogger('App');

// Initialize remote logging for Quest 3 debugging
if (typeof window !== 'undefined') {
  console.log('[RemoteLogger] Initializing remote logging service...');
  remoteLogger.logXRInfo(); 
}

function App() {
  const [initializationState, setInitializationState] = useState<'loading' | 'initialized' | 'error'>('loading');
  const [initializationError, setInitializationError] = useState<Error | null>(null);
  const initialized = useSettingsStore(state => state.initialized);

  // Auth state
  const { authenticated, isLoading: isAuthLoading, user } = useNostrAuth();

  const { shouldUseQuest3Layout, isQuest3Detected, autoStartSuccessful } = useQuest3Integration({
    enableAutoStart: false
  });


  const botsConnectionStatus = useBotsWebSocketIntegration();


  useAutoBalanceNotifications();

  // Update settings store with auth state and connect Solid WebSocket
  useEffect(() => {
    if (authenticated && user) {
      const settingsStore = useSettingsStore.getState();
      settingsStore.setAuthenticated(true);
      settingsStore.setUser({
        isPowerUser: user.isPowerUser,
        pubkey: user.pubkey
      });

      // Connect Solid WebSocket for real-time pod notifications
      solidPodService.connectWebSocket();
    } else {
      const settingsStore = useSettingsStore.getState();
      settingsStore.setAuthenticated(false);
      settingsStore.setUser(null);

      // Disconnect Solid WebSocket when user logs out
      solidPodService.disconnect();
    }

    // Cleanup on unmount
    return () => {
      solidPodService.disconnect();
    };
  }, [authenticated, user]);

  
  const shouldUseImmersiveClient = () => {
    const userAgent = navigator.userAgent;
    
    const isQuest3Browser = userAgent.includes('Quest 3') ||
                            userAgent.includes('Quest3') ||
                            userAgent.includes('OculusBrowser') ||
                            (userAgent.includes('VR') && userAgent.includes('Quest')) ||
                            userAgent.toLowerCase().includes('meta quest');

    
    const forceQuest3 = window.location.search.includes('force=quest3') ||
                        window.location.search.includes('directar=true') ||
                        window.location.search.includes('immersive=true');

    return (isQuest3Browser || forceQuest3 || shouldUseQuest3Layout) && initialized;
  };

  useEffect(() => {
    
    if (initialized) {
      initializeCommandPalette();
      registerSettingsHelp();
      registerOnboardingCommands();

      const hasVisited = localStorage.getItem('hasVisited');
      if (!hasVisited) {
        localStorage.setItem('hasVisited', 'true');
        setTimeout(() => {
          window.dispatchEvent(new CustomEvent('start-onboarding', {
            detail: { flowId: 'welcome' }
          }));
        }, 1000);
      }
    }
  }, [initialized])

  const handleInitialized = useCallback(() => {
    setInitializationState('initialized');
    const settings = useSettingsStore.getState().settings;
    const debugEnabled = settings?.system?.debug?.enabled === true;
    if (debugEnabled) {
      logger.debug('Application initialized');
      logger.debug('Bots WebSocket connection status:', botsConnectionStatus);
    }
  }, [botsConnectionStatus]);

  const handleInitializationError = useCallback((error: Error) => {
    setInitializationError(error);
    setInitializationState('error');
  }, []);

  // Show loading screen while checking auth
  if (isAuthLoading) {
    return <LoadingScreen message="Checking authentication..." />;
  }

  // Show login screen if not authenticated
  if (!authenticated) {
    return <NostrLoginScreen />;
  }

  const renderContent = () => {
    switch (initializationState) {
      case 'loading':
        return <LoadingScreen message="Connecting to server..." />;
      case 'error':
        return (
          <div>
            <h2>Error Initializing Application</h2>
            <p>{initializationError?.message || 'An unknown error occurred.'}</p>
            <button onClick={() => window.location.reload()}>Retry</button>
          </div>
        );
      case 'initialized':
        return shouldUseImmersiveClient() ? (
          <BotsDataProvider>
            <VircadiaBridgesProvider enableBotsBridge={true} enableGraphBridge={true}>
              <ImmersiveApp />
            </VircadiaBridgesProvider>
          </BotsDataProvider>
        ) : (
          <BotsDataProvider>
            <VircadiaBridgesProvider enableBotsBridge={true} enableGraphBridge={false}>
              <MainLayout />
            </VircadiaBridgesProvider>
          </BotsDataProvider>
        );
    }
  };

  return (
    <VircadiaProvider autoConnect={false}>
      <TooltipProvider delayDuration={300} skipDelayDuration={100}>
        <HelpProvider>
          <OnboardingProvider>
            <ErrorBoundary>
              <ApplicationModeProvider>
                {renderContent()}
                {initializationState === 'loading' && (
                  <AppInitializer onInitialized={handleInitialized} onError={handleInitializationError} />
                )}
                {initializationState === 'initialized' && (
                  <>
                    <ConnectionWarning />
                    <CommandPalette />
                    <DebugControlPanel />
                  </>
                )}
              </ApplicationModeProvider>
            </ErrorBoundary>
          </OnboardingProvider>
        </HelpProvider>
      </TooltipProvider>
    </VircadiaProvider>
  );
}

export default App

--------------------------------------------------------------------------------
FILE: client/src/app/AppInitializer.tsx
PURPOSE: Service initialization
--------------------------------------------------------------------------------
import React, { useEffect } from 'react';
import { createLogger, createErrorMetadata } from '../utils/loggerConfig';
import { debugState } from '../utils/clientDebugState';
import { useSettingsStore } from '../store/settingsStore';
import WebSocketService from '../services/WebSocketService';
import { graphWorkerProxy } from '../features/graph/managers/graphWorkerProxy';
import { graphDataManager } from '../features/graph/managers/graphDataManager';
import { innovationManager } from '../features/graph/innovations/index';

// Load and initialize all services
const loadServices = async (): Promise<void> => {
  if (debugState.isEnabled()) {
    logger.info('Initializing services...');
  }

  try {
    
    if (debugState.isEnabled()) {
      logger.info('Using Nostr authentication system');
    }

    
    try {
      console.log('[AppInitializer] Starting Innovation Manager initialization...');
      const initPromise = innovationManager.initialize({
        enableSync: true,
        enableComparison: true,
        enableAnimations: true,
        enableAI: true,
        enableAdvancedInteractions: true,
        performanceMode: 'balanced'
      });
      
      
      const timeoutPromise = new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Innovation Manager initialization timeout')), 5000)
      );
      
      await Promise.race([initPromise, timeoutPromise]);

      console.log('[AppInitializer] Innovation Manager initialized successfully');
      if (debugState.isEnabled()) {
        logger.info('Innovation Manager initialized successfully');
        const status = innovationManager.getStatus();
        logger.debug('Innovation Manager status:', status);
      }
    } catch (innovationError) {
      console.error('[AppInitializer] Innovation Manager initialization failed:', innovationError);
      logger.error('Error initializing Innovation Manager:', createErrorMetadata(innovationError));
      
    }

  } catch (error) {
    logger.error('Error initializing services:', createErrorMetadata(error));
  }
}

const logger = createLogger('AppInitializer');

interface AppInitializerProps {
  onInitialized: () => void;
  onError: (error: Error) => void;
}

const AppInitializer: React.FC<AppInitializerProps> = ({ onInitialized, onError }) => {
  const { settings, initialize } = useSettingsStore();

  useEffect(() => {
    const initApp = async () => {
      
      await loadServices();

      if (debugState.isEnabled()) {
        logger.info('Starting application initialization...');
        }

        try {
          console.log('[AppInitializer] Step 1: Initializing graphWorkerProxy');

          await graphWorkerProxy.initialize();
          console.log('[AppInitializer] Step 1b: graphWorkerProxy initialized, ensuring graphDataManager worker connection');

          // Ensure graphDataManager is connected to the worker now that it's ready
          const workerReady = await graphDataManager.ensureWorkerReady();
          console.log(`[AppInitializer] Step 1c: graphDataManager worker ready: ${workerReady}`);

          console.log('[AppInitializer] Step 2: graphWorkerProxy initialized, calling settings initialize');
          await initialize();
          console.log('[AppInitializer] Step 3: Settings initialized');

          // Access settings from the store after initialization
          const currentSettings = useSettingsStore.getState().settings as any;
          if (currentSettings?.system?.debug) {
            try {
              const debugSettings = currentSettings.system.debug;
              debugState.enableDebug(debugSettings.enabled);
              if (debugSettings.enabled) {
                debugState.enableDataDebug(debugSettings.enableDataDebug);
                debugState.enablePerformanceDebug(debugSettings.enablePerformanceDebug);
              }
            } catch (debugError) {
              logger.warn('Error applying debug settings:', createErrorMetadata(debugError));
            }
          }

          
          if (typeof WebSocketService !== 'undefined' && typeof graphDataManager !== 'undefined') {
            try {
              
              await initializeWebSocket(settings);
              
            } catch (wsError) {
              logger.error('WebSocket initialization failed, continuing with UI only:', createErrorMetadata(wsError));
              
            }
          } else {
            logger.warn('WebSocket services not available, continuing with UI only');
          }

          
          try {
            console.log('[AppInitializer] About to fetch initial graph data via REST API');
            logger.info('Fetching initial graph data via REST API');
            const graphData = await graphDataManager.fetchInitialData();
            console.log(`[AppInitializer] Successfully fetched ${graphData.nodes.length} nodes, ${graphData.edges.length} edges`);
            if (debugState.isDataDebugEnabled()) {
              logger.debug('Initial graph data fetched successfully');
            }
          } catch (fetchError) {
            console.error('[AppInitializer] Failed to fetch initial graph data:', fetchError);
            logger.error('Failed to fetch initial graph data:', createErrorMetadata(fetchError));
            
            const emptyGraph = {
              nodes: [],
              edges: []
            };
            console.log('[AppInitializer] Initializing with empty graph due to fetch failure');
            await graphDataManager.setGraphData(emptyGraph);
          }

          console.log('[AppInitializer] About to call onInitialized');
          if (debugState.isEnabled()) {
            logger.info('Application initialized successfully');
          }

          
          onInitialized();
          console.log('[AppInitializer] onInitialized called successfully');

      } catch (error) {
          logger.error('Failed to initialize application components:', createErrorMetadata(error as Error));
          onError(error as Error);
      }
    };

    initApp();
  }, []);

  
  const initializeWebSocket = async (settings: any): Promise<void> => {
    try {
      const websocketService = WebSocketService.getInstance();

      
      websocketService.onBinaryMessage((data) => {
        if (data instanceof ArrayBuffer) {
          try {
            
            if (debugState.isDataDebugEnabled()) {
              logger.debug(`Received binary data from WebSocket: ${data.byteLength} bytes`);
            }

            
            graphDataManager.updateNodePositions(data).then(() => {
              if (debugState.isDataDebugEnabled()) {
                logger.debug(`Processed binary position update: ${data.byteLength} bytes`);
              }
            }).catch(error => {
              logger.error('Failed to process binary position update via worker:', createErrorMetadata(error));
            });
          } catch (error) {
            logger.error('Failed to process binary position update:', createErrorMetadata(error));

            
            if (debugState.isEnabled()) {
              
              logger.debug(`Binary data size: ${data.byteLength} bytes`);

              
              try {
                const view = new DataView(data);
                const hexBytes = [];
                const maxBytesToShow = Math.min(16, data.byteLength);

                for (let i = 0; i < maxBytesToShow; i++) {
                  hexBytes.push(view.getUint8(i).toString(16).padStart(2, '0'));
                }

                logger.debug(`First ${maxBytesToShow} bytes: ${hexBytes.join(' ')}`);

                
                if (data.byteLength >= 2) {
                  const firstByte = view.getUint8(0);
                  const secondByte = view.getUint8(1);
                  if (firstByte === 0x78 && (secondByte === 0x01 || secondByte === 0x9C || secondByte === 0xDA)) {
                    logger.debug('Data appears to be zlib compressed (has zlib header)');
                  }
                }
              } catch (e) {
                logger.debug('Could not display binary data preview');
              }

              
              const nodeSize = 26; 
              if (data.byteLength % nodeSize !== 0) {
                logger.debug(`Invalid data length: not a multiple of ${nodeSize} bytes per node (remainder: ${data.byteLength % nodeSize})`);
              }
            }
          }
        }
      });

      
      websocketService.onConnectionStatusChange((connected) => {
        if (debugState.isEnabled()) {
          logger.info(`WebSocket connection status changed: ${connected}`);
        }

        
        if (connected) {
          try {
            if (websocketService.isReady()) {
              
              logger.info('WebSocket is connected and fully established - enabling binary updates');
              graphDataManager.setBinaryUpdatesEnabled(true);

              
              logger.info('Sending subscribe_position_updates message to server');
              websocketService.sendMessage('subscribe_position_updates', {
                binary: true,
                interval: settings?.system?.websocket?.updateRate || 60
              });

              if (debugState.isDataDebugEnabled()) {
                logger.debug('Binary updates enabled and subscribed to position updates');
              }
            } else {
              logger.info('WebSocket connected but not fully established yet - waiting for readiness');

              
              
              graphDataManager.enableBinaryUpdates();

              
              const unsubscribe = websocketService.onMessage((message) => {
                if ((message as any).type === 'connection_established') {
                  
                  logger.info('Connection established message received, sending subscribe_position_updates');
                  websocketService.sendMessage('subscribe_position_updates', {
                    binary: true,
                    interval: settings?.system?.websocket?.updateRate || 60
                  });
                  unsubscribe(); 

                  if (debugState.isDataDebugEnabled()) {
                    logger.debug('Connection established, subscribed to position updates');
                  }
                }
              });
            }
          } catch (connectionError) {
            logger.error('Error during WebSocket status change handling:', createErrorMetadata(connectionError));
          }
        }
      });

      
      if (websocketService) {
        const wsAdapter = {
          send: (data: ArrayBuffer) => {
            websocketService.sendRawBinaryData(data);
          },
          isReady: () => websocketService.isReady()
        };
        graphDataManager.setWebSocketService(wsAdapter);
      }

      try {
        
        await websocketService.connect();
      } catch (connectError) {
        logger.error('Failed to connect to WebSocket:', createErrorMetadata(connectError));
      }
    } catch (error) {
      logger.error('Failed during WebSocket/data initialization:', createErrorMetadata(error));
      throw error;
    }
  };

  return null; 
};

export default AppInitializer;

--------------------------------------------------------------------------------
FILE: client/src/components/NostrLoginScreen.tsx
PURPOSE: Nostr login UI
--------------------------------------------------------------------------------
import React, { useState } from 'react';
import { useNostrAuth } from '../hooks/useNostrAuth';
import './NostrLoginScreen.css';

export const NostrLoginScreen: React.FC = () => {
  const { login, devLogin, hasNip07, error, isDevLoginAvailable } = useNostrAuth();
  const [isLoggingIn, setIsLoggingIn] = useState(false);
  const [isDevLoggingIn, setIsDevLoggingIn] = useState(false);
  const [loginError, setLoginError] = useState<string | null>(null);

  const handleLogin = async () => {
    setIsLoggingIn(true);
    setLoginError(null);

    try {
      await login();
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Login failed';
      setLoginError(errorMessage);
    } finally {
      setIsLoggingIn(false);
    }
  };

  const handleDevLogin = async () => {
    setIsDevLoggingIn(true);
    setLoginError(null);

    try {
      await devLogin();
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Dev login failed';
      setLoginError(errorMessage);
    } finally {
      setIsDevLoggingIn(false);
    }
  };

  return (
    <div className="nostr-login-screen">
      <div className="nostr-login-container">
        <div className="nostr-login-header">
          <h1>VisionFlow</h1>
          <p className="nostr-login-subtitle">Nostr Authentication Required</p>
        </div>

        <div className="nostr-login-content">
          {!hasNip07 ? (
            <div className="nostr-login-error">
              <div className="error-icon"></div>
              <h2>Nostr Extension Required</h2>
              <p>
                VisionFlow requires a Nostr NIP-07 compatible browser extension to authenticate.
              </p>
              <div className="extension-recommendations">
                <h3>Recommended Extensions:</h3>
                <ul>
                  <li>
                    <a href="https://getalby.com" target="_blank" rel="noopener noreferrer">
                      Alby
                    </a>
                  </li>
                  <li>
                    <a href="https://chrome.google.com/webstore/detail/nos2x" target="_blank" rel="noopener noreferrer">
                      nos2x
                    </a>
                  </li>
                </ul>
              </div>
              <button
                className="nostr-login-retry-button"
                onClick={() => window.location.reload()}
              >
                Retry After Installing Extension
              </button>

              {isDevLoginAvailable && (
                <div className="dev-login-section">
                  <div className="dev-login-divider">
                    <span>Development Mode</span>
                  </div>
                  <button
                    className="dev-login-button"
                    onClick={handleDevLogin}
                    disabled={isDevLoggingIn}
                  >
                    {isDevLoggingIn ? (
                      <>
                        <span className="spinner"></span>
                        Logging in...
                      </>
                    ) : (
                      <>
                        <span className="dev-icon"></span>
                        Dev Login (Bypass Extension)
                      </>
                    )}
                  </button>
                  <p className="dev-login-warning">
                     Development only - bypasses NIP-07 authentication
                  </p>
                </div>
              )}
            </div>
          ) : (
            <div className="nostr-login-form">
              <div className="nostr-login-icon"></div>
              <p className="nostr-login-description">
                Click the button below to authenticate with your Nostr identity.
                Your browser extension will prompt you to sign a challenge.
              </p>

              {(loginError || error) && (
                <div className="nostr-login-error-message">
                  <strong>Error:</strong> {loginError || error}
                </div>
              )}

              <button
                className="nostr-login-button"
                onClick={handleLogin}
                disabled={isLoggingIn || isDevLoggingIn}
              >
                {isLoggingIn ? (
                  <>
                    <span className="spinner"></span>
                    Authenticating...
                  </>
                ) : (
                  'Login with Nostr'
                )}
              </button>

              {isDevLoginAvailable && (
                <div className="dev-login-section">
                  <div className="dev-login-divider">
                    <span>Development Mode</span>
                  </div>
                  <button
                    className="dev-login-button"
                    onClick={handleDevLogin}
                    disabled={isLoggingIn || isDevLoggingIn}
                  >
                    {isDevLoggingIn ? (
                      <>
                        <span className="spinner"></span>
                        Logging in...
                      </>
                    ) : (
                      <>
                        <span className="dev-icon"></span>
                        Dev Login (Power User)
                      </>
                    )}
                  </button>
                  <p className="dev-login-warning">
                     Development only - bypasses NIP-07 authentication
                  </p>
                </div>
              )}

              <div className="nostr-login-info">
                <p>
                  <strong>What is Nostr?</strong>
                </p>
                <p>
                  Nostr is a decentralized protocol for social networking and identity.
                  Your identity is controlled by you via cryptographic keys.
                </p>
              </div>
            </div>
          )}
        </div>

        <div className="nostr-login-footer">
          <p>
            Need help? Visit our{' '}
            <a href="https://docs.visionflow.io/auth" target="_blank" rel="noopener noreferrer">
              documentation
            </a>
          </p>
        </div>
      </div>
    </div>
  );
};

================================================================================
                    SECTION 17: CONFIGURATION FILES
================================================================================

--------------------------------------------------------------------------------
FILE: Cargo.toml
PURPOSE: Rust project manifest with dependencies
--------------------------------------------------------------------------------
[package]
name = "webxr"
version = "0.1.0"
edition = "2021"
description = "A WebXR graph visualisation server with GPU-accelerated physics"
authors = ["Your Name <your.email@example.com>"]
license = "MIT"

[lib]
crate-type = ["cdylib", "rlib"]

[dependencies]
# Web framework and WebSocket
actix-web = { version = "4.11.0", features = ["compress-zstd", "macros"] }
actix-cors = "0.7.1"
actix-files = "0.6"
actix = "0.13"
crossbeam-channel = "0.5"
actix-web-actors = "4.3"
tungstenite = "0.21.0"
tokio-tungstenite = { version = "0.21.0" }

# Async runtime
tokio = { version = "1.47.1", features = ["full"] }
tokio-util = { version = "0.7", features = ["codec"] }
tokio-stream = "0.1"
futures = "0.3"
futures-util = "0.3"
async-trait = "0.1"

# For TCP buffered I/O and advanced socket operations
bytes = "1.10.1"
socket2 = { version = "0.5", features = ["all"] }

# Serialization
serde = { version = "1.0.219", features = ["derive"] }
serde_json = "1.0"
serde_yaml = "0.9"
validator = { version = "0.18", features = ["derive"] }

# Database - Neo4j (sole database)
neo4rs = { version = "0.9.0-rc.8", features = ["unstable-serde-packstream-format"] }

# Redis (optional distributed caching)
redis = { version = "0.27", features = ["aio", "tokio-comp", "connection-manager"], optional = true }

# TypeScript type generation
specta = { version = "2.0.0-rc.22", features = ["derive", "export"] }
specta-typescript = "0.0.9"

# Configuration
config = { version = "0.15.15", features = ["toml"] }
dotenvy = "0.15.7"
toml = "0.9.5"

# Logging and Telemetry
log = "0.4"
env_logger = "0.11.8"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["json", "chrono", "env-filter"] }
tracing-appender = "0.2"

# Error handling
thiserror = "2.0.16"
anyhow = "1.0.99"

# Graph serialization
xml = "0.8"
blake3 = "1.5"
bcrypt = "0.15"

# GPU/Compute (always enabled)
bytemuck = { version = "1.21", features = ["derive"] }
pollster = "0.4"
cudarc = { version = "0.12.1", features = ["driver", "cuda-12040"] }
cust = { version = "0.3.2" }
cust_core = { version = "0.1.1" }

# HTTP client and API
reqwest = { version = "0.12.23", features = ["json", "stream", "multipart"] }
nostr-sdk = "0.43.0"

# OpenAPI/Swagger documentation
utoipa = { version = "5", features = ["actix_extras", "chrono", "uuid"] }
utoipa-swagger-ui = { version = "9", features = ["actix-web"] }

# High-Performance Networking (QUIC/WebTransport)
quinn = "0.11"
rustls = { version = "0.23", default-features = false, features = ["ring", "std"] }
rcgen = "0.13"
fastwebsockets = { version = "0.8", features = ["upgrade"] }
postcard = { version = "1.1", features = ["alloc", "use-std"] }
http = "1.2"
hyper = { version = "1.6", features = ["http1", "http2", "server"] }
hyper-util = { version = "0.1", features = ["tokio", "server-auto"] }
http-body-util = "0.1"

# Utilities
uuid = { version = "1.18.0", features = ["v4", "serde"] }
chrono = { version = "0.4.41", features = ["serde"] }
static_assertions = "1.1"
base64 = "0.22.1"
rand = "0.8"
fastrand = "2.3"
regex = "1.11.2"
lazy_static = "1.5"
once_cell = "1.20"
sha1 = "0.10"
sha2 = "0.10"
# scopeguard = "1.2"  # Unused - removed during cleanup
url = "2.5"
flate2 = "1.0"
byteorder = "1.5"
urlencoding = "2.1"
dashmap = "6.1"
# heck = "0.5"  # Unused - removed during cleanup
lru = "0.12"
# path_abs = "0.5"  # Unused - removed during cleanup
ordered-float = "4.5.0"
notify = "6.1"  # File system watching for hot-reload

# Math/Linear Algebra (needed for GPU compute)
nalgebra = "0.34.0"

# Added from the code block
glam = "0.30.5"
sysinfo = "0.37.0"

# Parallel processing
rayon = "1.11.0"

# Hexagonal Architecture
hexser = { version = "0.4.7", features = ["full"] }

# Ontology Reasoning - using local path dependency (always enabled)
whelk = { path = "./whelk-rs" }

# Ontology dependencies (always enabled)
# Note: Using 1.2.0 for ArcStr support (thread-safe string type)
horned-owl = { version = "1.2.0", features = ["remote"] }
horned-functional = { version = "0.4.0" }
# walkdir = { version = "2.4" }  # Unused - removed during cleanup
clap = { version = "4.5", features = ["derive"] }


[dev-dependencies]
tokio-test = "0.4"
mockall = "0.13"
pretty_assertions = "1.4"
tempfile = "3.14"
actix-rt = "2.11.0"

# WASM Support for hybrid CPU-WASM/GPU SSSP
[target.'cfg(target_arch = "wasm32")'.dependencies]
wasm-bindgen = "0.2"
wasm-bindgen-futures = "0.4"
web-sys = "0.3"
js-sys = "0.3"

[build-dependencies]
tempfile = "3.14"

[features]
# GPU and ontology features for conditional compilation
# Enable by default for full system capabilities
default = ["gpu", "ontology"]
gpu = []  # GPU acceleration with CUDA kernels
ontology = []  # Ontology validation and reasoning
gpu-safe = []  # Feature for GPU-safe types
redis = ["dep:redis"]  # Enable Redis distributed caching

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
panic = "unwind"
strip = true

[profile.dev]
opt-level = 1

[package.metadata.rust-version]
min = "1.75.0"

[[bin]]
name = "generate_types"
path = "src/bin/generate_types.rs"

[[bin]]
name = "sync_local"
path = "src/bin/sync_local.rs"

# REMOVED: migrate_settings_to_neo4j binary - migration complete
# [[bin]]
# name = "migrate_settings_to_neo4j"
# path = "src/bin/migrate_settings_to_neo4j.rs"

[[example]]
name = "constraint_integration_debug"
path = "examples/constraint_integration_debug.rs"

[[example]]
name = "metadata_debug"
path = "examples/metadata_debug.rs"

[[example]]
name = "ontology_constraints_example"
path = "examples/ontology_constraints_example.rs"

[[example]]
name = "ontology_validation_example"
path = "examples/ontology_validation_example.rs"

--------------------------------------------------------------------------------
FILE: client/package.json
PURPOSE: Client Node.js manifest
--------------------------------------------------------------------------------
{
  "name": "visionflow-client",
  "private": true,
  "version": "0.1.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "npm run types:generate && vite build",
    "preview": "vite preview",
    "lint": "eslint src --ext ts,tsx --report-unused-disable-directives",
    "test": "jest",
    "test:watch": "jest --watch",
    "test:ui": "echo 'Testing disabled due to supply chain attack - see SECURITY_ALERT.md'",
    "test:coverage": "jest --coverage",
    "types:generate": "cd .. && cargo run --bin generate_types",
    "types:watch": "cd .. && cargo watch -x 'run --bin generate_types'",
    "types:clean": "rm -rf src/types/generated",
    "prebuild": "npm run types:generate",
    "preinstall": "node scripts/block-test-packages.cjs",
    "security:check": "node scripts/block-test-packages.cjs && npm audit",
    "benchmark": "ts-node scripts/run-benchmarks.ts",
    "benchmark:performance": "ts-node scripts/run-benchmarks.ts --performance",
    "benchmark:load": "ts-node scripts/run-benchmarks.ts --load",
    "benchmark:vr": "ts-node scripts/run-benchmarks.ts --vr",
    "benchmark:network": "ts-node scripts/run-benchmarks.ts --network",
    "benchmark:integration": "ts-node scripts/run-benchmarks.ts --integration",
    "benchmark:ci": "ts-node scripts/run-benchmarks.ts --all --output ./ci-results"
  },
  "dependencies": {
    "@getalby/sdk": "7.0.0",
    "@mediapipe/tasks-vision": "0.10.21",
    "@radix-ui/react-collapsible": "1.1.12",
    "@radix-ui/react-dialog": "1.1.15",
    "@radix-ui/react-dropdown-menu": "2.1.16",
    "@radix-ui/react-label": "2.1.8",
    "@radix-ui/react-radio-group": "1.3.8",
    "@radix-ui/react-select": "2.2.6",
    "@radix-ui/react-slider": "1.3.6",
    "@radix-ui/react-slot": "1.2.4",
    "@radix-ui/react-switch": "1.2.6",
    "@radix-ui/react-toast": "1.2.15",
    "@radix-ui/react-tooltip": "1.2.8",
    "@radix-ui/themes": "3.2.1",
    "@react-three/drei": "10.7.7",
    "@react-three/fiber": "9.4.2",
    "@react-three/postprocessing": "3.0.4",
    "@react-three/xr": "6.6.28",
    "@types/lodash": "4.17.21",
    "@types/react-window": "1.8.8",
    "@types/three": "0.182.0",
    "axios": "1.13.2",
    "class-variance-authority": "0.7.1",
    "clsx": "2.1.1",
    "comlink": "4.4.2",
    "framer-motion": "12.23.26",
    "hls.js": "1.6.15",
    "immer": "11.1.0",
    "lodash": "4.17.21",
    "lucide-react": "0.562.0",
    "nostr-tools": "2.19.4",
    "react": "19.2.3",
    "react-dom": "19.2.3",
    "react-markdown": "10.1.0",
    "react-resizable-panels": "4.0.15",
    "react-rnd": "10.5.2",
    "react-syntax-highlighter": "16.1.0",
    "react-window": "2.2.3",
    "remark-gfm": "4.0.1",
    "tailwind-merge": "3.2.0",
    "three": "0.182.0",
    "uuid": "13.0.0"
  },
  "devDependencies": {
    "@playwright/test": "1.57.0",
    "@tailwindcss/postcss": "4.1.7",
    "@types/jest": "29.5.14",
    "@types/node": "25.0.3",
    "@types/react": "19.2.7",
    "@types/react-dom": "19.2.3",
    "@types/ws": "8.18.1",
    "@typescript-eslint/eslint-plugin": "8.32.0",
    "@typescript-eslint/parser": "8.32.0",
    "@vitejs/plugin-react": "4.5.2",
    "autoprefixer": "10.4.21",
    "chalk": "4.1.2",
    "commander": "14.0.0",
    "jest": "29.7.0",
    "jsdom": "26.1.0",
    "postcss": "8.5.3",
    "prettier": "3.5.3",
    "tailwindcss": "4.1.7",
    "terser": "5.44.1",
    "ts-jest": "29.3.4",
    "ts-node": "10.9.2",
    "typescript": "5.8.3",
    "vite": "6.4.1",
    "ws": "8.18.2",
    "wscat": "6.1.0"
  },
  "overrides": {
    "chalk": "4.1.2",
    "ansi-regex": "6.1.0",
    "ansi-styles": "6.2.1",
    "color-name": "2.0.0",
    "color-convert": "2.0.1",
    "supports-color": "9.4.0",
    "strip-ansi": "7.1.0",
    "string-width": "7.2.0",
    "wrap-ansi": "9.0.0",
    "esbuild": "0.25.9",
    "prismjs": "1.30.0",
    "three": "0.182.0"
  }
}

--------------------------------------------------------------------------------
FILE: config.yml
PURPOSE: Cloudflare tunnel configuration
--------------------------------------------------------------------------------
tunnel: logseqXR

ingress:
  - hostname: www.visionflow.info
    service: http://webxr:3001
    originRequest:
      noTLSVerify: true
      connectTimeout: 30s
      tcpKeepAlive: 10s
      keepAliveTimeout: 10m
      idleTimeout: 10m
      websocketIdleTimeout: 10m
      keepAliveConnections: 100
      httpHostHeader: www.visionflow.info
      proxyProtocol: false
    config:
      webSockets: true
      http2Origin: true
  - service: http_status:404

# Connection settings
protocol: http2
no-autoupdate: true

# Logging settings
loglevel: debug

--------------------------------------------------------------------------------
FILE: .env.example
PURPOSE: Environment template
--------------------------------------------------------------------------------
# ===========================================
# ENVIRONMENT VARIABLES - QUICK START GUIDE
# ===========================================
# Copy this file to .env and configure with your actual values
# For detailed configuration, see:
#   - .env.development.template (development settings)
#   - .env.production.template (production settings)
# ===========================================

# Environment
NODE_ENV=development
BUILD_TARGET=development

# GPU Configuration (Optional - uncomment if using GPU)
# NVIDIA_VISIBLE_DEVICES=GPU-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
# CUDA_DEVICE=0
# CUDA_ARCH=86
# NO_GPU_COMPUTE=true

# GitHub Configuration (Required)
GITHUB_OWNER=your-github-username
GITHUB_REPO=your-repo-name
GITHUB_BRANCH=main
GITHUB_TOKEN=github_pat_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
GITHUB_BASE_PATH=mainKnowledgeGraph/pages

# RAGFlow Configuration (Required)
RAGFLOW_API_KEY=ragflow-XXXXXXXXXXXXXXXXXXXXXXXXXXXXX
RAGFLOW_API_BASE_URL=http://localhost:9380
RAGFLOW_AGENT_ID=your-agent-id

# Perplexity API (Optional)
PERPLEXITY_API_KEY=pplx-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
PERPLEXITY_MODEL=llama-3.1-sonar-small-128k-online

# OpenAI Configuration (Optional)
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

# Data Paths
DATA_ROOT=/app/data
MARKDOWN_DIR=/app/data/markdown
METADATA_DIR=/app/data/metadata

# Neo4j Graph Database (REQUIRED - sole persistence layer)
# All graph data, ontology, and settings stored in Neo4j
# CRITICAL: Backend will fail to start without Neo4j connection
# For unified docker: use bolt://neo4j:7687 (container name)
# For external Neo4j: use bolt://localhost:7687 or actual host
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=CHANGE_THIS_PASSWORD
NEO4J_DATABASE=neo4j

# Server Configuration
BIND_ADDRESS=0.0.0.0
DEBUG_ENABLED=false
RUST_LOG=info

# Network Configuration
DOMAIN=localhost

# Claude Flow MCP
CLAUDE_FLOW_HOST=localhost
MCP_TCP_PORT=9500
MANAGEMENT_API_URL=http://localhost:9090
MANAGEMENT_API_KEY=change-this-secret-key

# Security (Generate strong random secrets!)
JWT_SECRET=generate-a-strong-random-secret-here-minimum-64-chars
SESSION_SECRET=generate-another-strong-random-secret-here-minimum-64-chars
WS_AUTH_ENABLED=true

# CORS
CORS_ALLOWED_ORIGINS=http://localhost:3000

# Logging
LOG_LEVEL=info
LOG_FORMAT=json

# Performance
PERFORMANCE_MONITORING=true
TELEMETRY_ENABLED=true

# Health Check
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_PORT=9501

# ===========================================
# Quick Setup Instructions
# ===========================================
# 1. Copy this file: cp .env.example .env
# 2. Replace ALL placeholder values (XXXXX) with real credentials
# 3. Generate secure secrets for JWT_SECRET and SESSION_SECRET:
#    - Linux/Mac: openssl rand -base64 64
#    - Or use: https://passwordsgenerator.net/
# 4. Configure GitHub token: https://github.com/settings/tokens
# 5. Review and adjust paths and ports as needed
# 6. For development: see .env.development.template
# 7. For production: see .env.production.template
# ===========================================

# SECURITY REMINDERS:
# - Never commit .env files to version control
# - Use .env.local for local overrides (already in .gitignore)
# - Rotate secrets regularly (every 90 days minimum)
# - Use environment variables in CI/CD pipelines
# - Store production secrets in secure secret management systems
--------------------------------------------------------------------------------
FILE: docker-compose.yml
PURPOSE: Main Docker Compose configuration
--------------------------------------------------------------------------------
services:
  # Development configuration
  webxr:
    profiles: ["dev"]
    container_name: visionflow_container
    hostname: webxr
    build:
      context: .
      dockerfile: Dockerfile.dev
      args:
        CUDA_ARCH: ${CUDA_ARCH:-86}
    volumes:
      # Fully baked image - ALL code and config inside container
      # Only internal Docker volumes for data persistence and caching
      - visionflow-data:/app/data  # Internal volume for databases and markdown
      - ./data/pages:/app/data/pages:rw  # Mount local pages directory for persistent baseline
      - visionflow-logs:/app/logs  # Internal volume for application logs
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Docker socket for controlled access
      - npm-cache:/root/.npm
      - cargo-cache:/root/.cargo/registry
      - cargo-git-cache:/root/.cargo/git
      - cargo-target-cache:/app/target
    env_file:
      - .env
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - VITE_DEBUG=${DEBUG_ENABLED:-true}
      - NODE_ENV=development
      - VITE_DEV_SERVER_PORT=5173
      - VITE_API_PORT=4000
      - VITE_HMR_PORT=24678
      - RUST_LOG_REDIRECT=true
      - SYSTEM_NETWORK_PORT=4000
      - CLAUDE_FLOW_HOST=agentic-workstation
      - MCP_HOST=agentic-workstation
      - MCP_TCP_PORT=9500
      - MCP_TRANSPORT=tcp
      - MCP_RECONNECT_ATTEMPTS=3
      - MCP_RECONNECT_DELAY=1000
      - MCP_CONNECTION_TIMEOUT=30000
      - ORCHESTRATOR_WS_URL=ws://mcp-orchestrator:9001/ws
      - MCP_RELAY_FALLBACK_TO_MOCK=true
      - BOTS_ORCHESTRATOR_URL=ws://agentic-workstation:3002
      - MANAGEMENT_API_HOST=agentic-workstation
      - MANAGEMENT_API_PORT=9090
      - FORCE_FULL_SYNC=1
    ports:
      - "3001:3001"  # Nginx entry point for dev
      - "4000:4000"  # API port for direct access
    networks:
      docker_ragflow:
        aliases:
          - webxr
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # DISABLED: Production configuration - use dev container only for now
  # webxr-prod:
  #   profiles: ["production", "prod"]
  #   container_name: visionflow_prod_container
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.dev
  #     args:
  #       CUDA_ARCH: ${CUDA_ARCH:-86}
  #   entrypoint: ["/app/prod-entrypoint.sh"]
  #   env_file:
  #     - .env
  #   environment:
  #     - NVIDIA_VISIBLE_DEVICES=0
  #     - NVIDIA_DRIVER_CAPABILITIES=compute,utility
  #     - NODE_ENV=production
  #     - RUST_LOG=warn
  #     - SYSTEM_NETWORK_PORT=4001
  #     - CLAUDE_FLOW_HOST=agentic-workstation
  #     - MCP_HOST=agentic-workstation
  #     - MCP_TCP_PORT=9500
  #     - MCP_TRANSPORT=tcp
  #     - MCP_RECONNECT_ATTEMPTS=3
  #     - MCP_RECONNECT_DELAY=1000
  #     - MCP_CONNECTION_TIMEOUT=30000
  #     - ORCHESTRATOR_WS_URL=ws://mcp-orchestrator:9001/ws
  #     - MCP_RELAY_FALLBACK_TO_MOCK=true
  #     - BOTS_ORCHESTRATOR_URL=ws://agentic-workstation:3002
  #     - MANAGEMENT_API_HOST=agentic-workstation
  #     - MANAGEMENT_API_PORT=9090
  #   volumes:
  #     - ./client:/app/client
  #     - ./src:/app/src
  #     - ./Cargo.toml:/app/Cargo.toml
  #     - ./Cargo.lock:/app/Cargo.lock
  #     - ./data/markdown:/app/data/markdown
  #     - ./data/metadata:/app/data/metadata
  #     - ./data/user_settings:/app/user_settings
  #     - ./data/settings.yaml:/app/settings.yaml
  #     - ./nginx.production.conf:/etc/nginx/nginx.conf:ro
  #     - ./logs/nginx:/var/log/nginx
  #     - ./logs:/app/logs
  #     - ./scripts/prod-entrypoint.sh:/app/prod-entrypoint.sh:ro
  #     - ./supervisord.production.conf:/app/supervisord.production.conf:ro
  #     - cargo-target-cache:/app/target
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             capabilities: [compute,utility]
  #             device_ids: ['0']
  #   ports:
  #     - "4000:4000"  # API port for production
  #   networks:
  #     - docker_ragflow
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:4000/"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 40s

  # Cloudflare tunnel - now works with dev profile
  cloudflared:
    profiles: ["dev"]
    container_name: cloudflared-tunnel
    image: cloudflare/cloudflared:latest
    command: tunnel --no-autoupdate run
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
    volumes:
      - ./config.yml:/etc/cloudflared/config.yml:ro
    depends_on:
      webxr:
        condition: service_started
        required: false
    networks:
      - docker_ragflow
    restart: unless-stopped

networks:
  docker_ragflow:
    external: true

volumes:
  visionflow-data:  # Persistent data volume (databases, markdown, metadata, user_settings)
  visionflow-logs:  # Log files volume
  npm-cache:
  cargo-cache:
  cargo-git-cache:
  cargo-target-cache:
--------------------------------------------------------------------------------
FILE: ontology_physics.toml
PURPOSE: Physics simulation settings for ontology
--------------------------------------------------------------------------------
# Ontology Physics Configuration
# Maps OWL axioms to physics constraints

[kernel_parameters]
threads_per_block = 256
max_blocks = 1024
target_frame_time_ms = 2.0

[constraint_groups]
[constraint_groups.disjoint_classes]
enabled = true
kernel_name = "apply_disjoint_classes_kernel"
default_strength = 0.8
physics_type = "repulsion"

[constraint_groups.subclass_hierarchy]
enabled = true
kernel_name = "apply_subclass_hierarchy_kernel"
default_strength = 0.6
physics_type = "alignment"

[constraint_groups.sameas_colocate]
enabled = true
kernel_name = "apply_sameas_colocate_kernel"
default_strength = 0.9
physics_type = "attraction"

[constraint_groups.inverse_symmetry]
enabled = true
kernel_name = "apply_inverse_symmetry_kernel"
default_strength = 0.7
physics_type = "symmetry"

[constraint_groups.functional_cardinality]
enabled = true
kernel_name = "apply_functional_cardinality_kernel"
default_strength = 1.0
physics_type = "constraint"

[performance]
batch_size = 1000
memory_pool_size_mb = 512
max_concurrent_graphs = 4

================================================================================
                    END OF COMPREHENSIVE DATAFLOW DOCUMENT
================================================================================

Summary:
- Total Sections: 17
- Rust Files Included: 80+ core files
- TypeScript Files Included: 30+ core files  
- Configuration Files: 6

This document provides a complete snapshot of the VisionFlow data pipeline
for investigation with large context LLMs.

Key Data Flows:
1. GitHub/Local -> Parsers -> Enrichment -> Neo4j
2. Neo4j -> GPU Actors -> Physics Simulation -> Binary WebSocket -> Client
3. Client -> Nostr Auth -> Session -> Protected APIs
4. Client -> JSS Pods -> Solid Resources -> Real-time Notifications
5. OWL Reasoning -> Axiom Translation -> Physics Constraints -> GPU

Generated: 2026-01-01
================================================================================
