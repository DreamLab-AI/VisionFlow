//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34097967
// Cuda compilation tools, release 12.4, V12.4.131
// Based on NVVM 7.0.1
//

.version 8.4
.target sm_86
.address_size 64

	// .globl	compute_forces
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
// _ZZ14compute_forcesE16shared_positions has been demoted
// _ZZ14compute_forcesE13shared_masses has been demoted
.global .align 1 .b8 $str[59] = {78, 111, 100, 101, 32, 48, 58, 32, 100, 105, 115, 116, 61, 37, 102, 44, 32, 109, 97, 115, 115, 95, 105, 61, 37, 102, 44, 32, 109, 97, 115, 115, 95, 106, 61, 37, 102, 44, 32, 114, 101, 112, 117, 108, 115, 105, 111, 110, 95, 102, 111, 114, 99, 101, 61, 37, 102, 10};
.global .align 1 .b8 $str$1[25] = {78, 111, 100, 101, 32, 48, 58, 32, 115, 112, 114, 105, 110, 103, 95, 102, 111, 114, 99, 101, 61, 37, 102, 10};
.global .align 1 .b8 $str$2[64] = {78, 111, 100, 101, 32, 48, 58, 32, 102, 111, 114, 99, 101, 95, 109, 97, 103, 61, 37, 102, 44, 32, 102, 111, 114, 99, 101, 61, 40, 37, 102, 44, 32, 37, 102, 44, 32, 37, 102, 41, 44, 32, 110, 101, 119, 95, 118, 101, 108, 61, 40, 37, 102, 44, 32, 37, 102, 44, 32, 37, 102, 41, 10};

.visible .entry compute_forces(
	.param .u64 compute_forces_param_0,
	.param .u32 compute_forces_param_1,
	.param .f32 compute_forces_param_2,
	.param .f32 compute_forces_param_3,
	.param .f32 compute_forces_param_4,
	.param .f32 compute_forces_param_5,
	.param .f32 compute_forces_param_6
)
{
	.local .align 8 .b8 	__local_depot0[56];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<124>;
	.reg .b16 	%rs<224>;
	.reg .f32 	%f<1146>;
	.reg .b32 	%r<143>;
	.reg .f64 	%fd<17>;
	.reg .b64 	%rd<46>;
	// demoted variable
	.shared .align 16 .b8 _ZZ14compute_forcesE16shared_positions[4096];
	// demoted variable
	.shared .align 4 .b8 _ZZ14compute_forcesE13shared_masses[1024];

	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd6, [compute_forces_param_0];
	ld.param.u32 	%r46, [compute_forces_param_1];
	ld.param.f32 	%f373, [compute_forces_param_2];
	ld.param.f32 	%f374, [compute_forces_param_3];
	ld.param.f32 	%f376, [compute_forces_param_5];
	cvta.to.global.u64 	%rd1, %rd6;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r47, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	mad.lo.s32 	%r3, %r47, %r1, %r2;
	setp.ge.s32 	%p1, %r3, %r46;
	@%p1 bra 	$L__BB0_148;

	mul.wide.s32 	%rd7, %r3, 48;
	add.s64 	%rd2, %rd1, %rd7;
	.pragma "used_bytes_mask 4095";
	ld.global.v4.f32 	{%f381, %f382, %f383, %f384}, [%rd2];
	.pragma "used_bytes_mask 4095";
	ld.global.v4.f32 	{%f385, %f386, %f387, %f388}, [%rd2+16];
	ld.global.v4.u32 	{%r48, %r49, %r50, %r51}, [%rd2+32];
	mov.b32 	{%rs82, %rs83}, %r48;
	and.b16  	%rs84, %rs82, 255;
	shr.u16 	%rs1, %rs82, 8;
	cvt.rn.f32.u16 	%f389, %rs84;
	mov.f32 	%f390, 0f437F0000;
	div.approx.ftz.f32 	%f7, %f389, %f390;
	add.s32 	%r53, %r1, %r46;
	add.s32 	%r4, %r53, -1;
	setp.gt.u32 	%p2, %r1, %r4;
	add.u64 	%rd8, %SP, 0;
	add.u64 	%rd3, %SPL, 0;
	mov.f32 	%f1053, 0f00000000;
	mov.f32 	%f1054, %f1053;
	mov.f32 	%f1055, %f1053;
	@%p2 bra 	$L__BB0_136;

	shl.b32 	%r55, %r2, 4;
	mov.u32 	%r56, _ZZ14compute_forcesE16shared_positions;
	add.s32 	%r5, %r56, %r55;
	shl.b32 	%r57, %r2, 2;
	mov.u32 	%r58, _ZZ14compute_forcesE13shared_masses;
	add.s32 	%r6, %r58, %r57;
	and.b16  	%rs2, %rs1, 2;
	cvt.ftz.f64.f32 	%fd1, %f7;
	mov.u32 	%r132, 0;
	div.u32 	%r8, %r4, %r1;
	mov.f32 	%f1055, 0f00000000;
	mov.f32 	%f1054, %f1055;
	mov.f32 	%f1053, %f1055;

$L__BB0_3:
	neg.s32 	%r127, %r1;
	mul.lo.s32 	%r10, %r1, %r132;
	sub.s32 	%r59, %r10, %r46;
	max.u32 	%r11, %r59, %r127;
	neg.s32 	%r12, %r11;
	add.s32 	%r13, %r10, %r2;
	setp.ge.s32 	%p3, %r13, %r46;
	@%p3 bra 	$L__BB0_5;

	mul.wide.s32 	%rd9, %r13, 48;
	add.s64 	%rd10, %rd1, %rd9;
	.pragma "used_bytes_mask 4095";
	ld.global.v4.f32 	{%f394, %f395, %f396, %f397}, [%rd10];
	ld.global.v4.u32 	{%r60, %r61, %r62, %r63}, [%rd10+32];
	cvt.u16.u32 	%rs85, %r60;
	and.b16  	%rs86, %rs85, 255;
	st.shared.v2.f32 	[%r5], {%f394, %f395};
	st.shared.f32 	[%r5+8], %f396;
	cvt.rn.f32.u16 	%f401, %rs86;
	mov.f32 	%f402, 0f437F0000;
	div.approx.ftz.f32 	%f403, %f401, %f402;
	st.shared.f32 	[%r6], %f403;

$L__BB0_5:
	setp.eq.s32 	%p4, %r1, 0;
	bar.sync 	0;
	setp.ge.u32 	%p5, %r10, %r46;
	or.pred  	%p6, %p4, %p5;
	@%p6 bra 	$L__BB0_135;

	mul.lo.s32 	%r136, %r1, %r132;
	neg.s32 	%r130, %r1;
	sub.s32 	%r129, %r136, %r46;
	max.u32 	%r128, %r129, %r130;
	and.b32  	%r142, %r12, 7;
	setp.gt.u32 	%p7, %r128, -8;
	mov.u32 	%r137, 0;
	@%p7 bra 	$L__BB0_116;

	sub.s32 	%r135, %r12, %r142;
	mov.u32 	%r137, 0;
	mov.u32 	%r136, %r10;

$L__BB0_8:
	.pragma "nounroll";
	shl.b32 	%r67, %r137, 4;
	add.s32 	%r19, %r56, %r67;
	shl.b32 	%r69, %r137, 2;
	add.s32 	%r20, %r58, %r69;
	setp.eq.s32 	%p8, %r136, %r3;
	@%p8 bra 	$L__BB0_24;

	mul.wide.u32 	%rd11, %r136, 48;
	add.s64 	%rd12, %rd1, %rd11;
	add.s64 	%rd4, %rd12, 33;
	ld.global.u8 	%rs87, [%rd12+33];
	and.b16  	%rs88, %rs87, 1;
	setp.eq.b16 	%p9, %rs88, 1;
	mov.pred 	%p10, 0;
	xor.pred  	%p11, %p9, %p10;
	not.pred 	%p12, %p11;
	@%p12 bra 	$L__BB0_24;

	.pragma "used_bytes_mask 4095";
	ld.shared.v4.f32 	{%f406, %f407, %f408, %f409}, [%r19];
	ld.shared.f32 	%f14, [%r20];
	sub.ftz.f32 	%f15, %f381, %f406;
	sub.ftz.f32 	%f16, %f382, %f407;
	sub.ftz.f32 	%f17, %f383, %f408;
	mul.ftz.f32 	%f413, %f16, %f16;
	fma.rn.ftz.f32 	%f414, %f15, %f15, %f413;
	fma.rn.ftz.f32 	%f415, %f17, %f17, %f414;
	sqrt.approx.ftz.f32 	%f18, %f415;
	mov.f32 	%f416, 0f38D1B717;
	max.ftz.f32 	%f19, %f18, %f416;
	setp.geu.ftz.f32 	%p13, %f19, %f376;
	mov.f32 	%f1040, 0f00000000;
	@%p13 bra 	$L__BB0_13;

	mov.f32 	%f968, 0f38D1B717;
	max.ftz.f32 	%f967, %f18, %f968;
	mul.ftz.f32 	%f417, %f7, %f14;
	sqrt.approx.ftz.f32 	%f418, %f417;
	mul.ftz.f32 	%f419, %f418, %f374;
	neg.ftz.f32 	%f420, %f419;
	mul.ftz.f32 	%f421, %f967, %f967;
	div.approx.ftz.f32 	%f422, %f420, %f421;
	mov.f32 	%f423, 0fC1200000;
	max.ftz.f32 	%f1040, %f422, %f423;
	or.b32  	%r71, %r137, %r3;
	setp.ne.s32 	%p14, %r71, 0;
	@%p14 bra 	$L__BB0_13;

	mov.f32 	%f970, 0f38D1B717;
	max.ftz.f32 	%f969, %f18, %f970;
	cvt.ftz.f64.f32 	%fd2, %f969;
	st.local.f64 	[%rd3], %fd2;
	st.local.f64 	[%rd3+8], %fd1;
	cvt.ftz.f64.f32 	%fd3, %f14;
	st.local.f64 	[%rd3+16], %fd3;
	cvt.ftz.f64.f32 	%fd4, %f1040;
	st.local.f64 	[%rd3+24], %fd4;
	mov.u64 	%rd13, $str;
	cvta.global.u64 	%rd14, %rd13;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd14;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd8;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r72, [retval0+0];
	} // callseq 0

$L__BB0_13:
	setp.eq.s16 	%p15, %rs2, 0;
	@%p15 bra 	$L__BB0_20;

	ld.global.u8 	%rs89, [%rd4];
	and.b16  	%rs90, %rs89, 2;
	setp.eq.s16 	%p16, %rs90, 0;
	@%p16 bra 	$L__BB0_20;

	mov.f32 	%f963, 0f38D1B717;
	max.ftz.f32 	%f962, %f18, %f963;
	add.ftz.f32 	%f22, %f962, 0fBF800000;
	abs.ftz.f32 	%f23, %f22;
	abs.ftz.f32 	%f24, %f23;
	setp.ltu.ftz.f32 	%p17, %f24, 0f3F19999A;
	@%p17 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_16;

$L__BB0_17:
	mul.ftz.f32 	%f432, %f23, %f23;
	mov.f32 	%f433, 0fBD563CAE;
	mov.f32 	%f434, 0f3C80F082;
	fma.rn.ftz.f32 	%f435, %f434, %f432, %f433;
	mov.f32 	%f436, 0f3E085941;
	fma.rn.ftz.f32 	%f437, %f435, %f432, %f436;
	mov.f32 	%f438, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f439, %f437, %f432, %f438;
	mov.f32 	%f440, 0f00000000;
	fma.rn.ftz.f32 	%f441, %f439, %f432, %f440;
	fma.rn.ftz.f32 	%f1039, %f441, %f23, %f23;
	bra.uni 	$L__BB0_18;

$L__BB0_16:
	mul.ftz.f32 	%f424, %f24, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f425, %f424;
	add.ftz.f32 	%f426, %f425, 0f3F800000;
	mov.f32 	%f427, 0f3F800000;
	rcp.approx.ftz.f32 	%f428, %f426;
	mov.f32 	%f429, 0fC0000000;
	fma.rn.ftz.f32 	%f430, %f428, %f429, %f427;
	setp.ge.ftz.f32 	%p18, %f24, 0f41102CB4;
	selp.f32 	%f431, 0f3F800000, %f430, %p18;
	mov.b32 	%r73, %f431;
	mov.b32 	%r74, %f23;
	and.b32  	%r75, %r74, -2147483648;
	or.b32  	%r76, %r75, %r73;
	mov.b32 	%f1039, %r76;

$L__BB0_18:
	mov.f32 	%f973, 0f38D1B717;
	max.ftz.f32 	%f972, %f18, %f973;
	add.ftz.f32 	%f971, %f972, 0fBF800000;
	fma.rn.ftz.f32 	%f442, %f1039, 0f3F000000, 0f3F800000;
	mul.ftz.f32 	%f443, %f971, %f373;
	mul.ftz.f32 	%f444, %f443, %f442;
	mov.f32 	%f445, 0f41200000;
	min.ftz.f32 	%f446, %f444, %f445;
	mov.f32 	%f447, 0fC1200000;
	max.ftz.f32 	%f28, %f446, %f447;
	add.ftz.f32 	%f1040, %f1040, %f28;
	or.b32  	%r77, %r137, %r3;
	setp.ne.s32 	%p19, %r77, 0;
	@%p19 bra 	$L__BB0_20;

	cvt.ftz.f64.f32 	%fd5, %f28;
	st.local.f64 	[%rd3], %fd5;
	mov.u64 	%rd16, $str$1;
	cvta.global.u64 	%rd17, %rd16;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd17;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd8;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r78, [retval0+0];
	} // callseq 1

$L__BB0_20:
	setp.lt.ftz.f32 	%p20, %f18, 0f358637BD;
	mov.f32 	%f1041, 0f00000000;
	mov.f32 	%f1042, %f1041;
	mov.f32 	%f1043, %f1041;
	@%p20 bra 	$L__BB0_22;

	rcp.approx.ftz.f32 	%f451, %f18;
	mul.ftz.f32 	%f1043, %f17, %f451;
	mul.ftz.f32 	%f1042, %f16, %f451;
	mul.ftz.f32 	%f1041, %f15, %f451;

$L__BB0_22:
	mov.f32 	%f452, 0f41700000;
	min.ftz.f32 	%f453, %f1040, %f452;
	mov.f32 	%f454, 0fC1700000;
	max.ftz.f32 	%f455, %f453, %f454;
	fma.rn.ftz.f32 	%f1053, %f455, %f1041, %f1053;
	fma.rn.ftz.f32 	%f1054, %f455, %f1042, %f1054;
	fma.rn.ftz.f32 	%f1055, %f455, %f1043, %f1055;
	mul.ftz.f32 	%f456, %f386, %f1042;
	fma.rn.ftz.f32 	%f457, %f385, %f1041, %f456;
	fma.rn.ftz.f32 	%f43, %f387, %f1043, %f457;
	setp.leu.ftz.f32 	%p21, %f43, 0f00000000;
	@%p21 bra 	$L__BB0_24;

	sqrt.approx.ftz.f32 	%f458, %f7;
	mul.ftz.f32 	%f459, %f43, %f458;
	mul.ftz.f32 	%f460, %f459, 0fBDCCCCCD;
	mov.f32 	%f461, 0fC0A00000;
	max.ftz.f32 	%f462, %f460, %f461;
	fma.rn.ftz.f32 	%f1053, %f1041, %f462, %f1053;
	fma.rn.ftz.f32 	%f1054, %f1042, %f462, %f1054;
	fma.rn.ftz.f32 	%f1055, %f1043, %f462, %f1055;

$L__BB0_24:
	add.s32 	%r79, %r137, %r10;
	add.s32 	%r21, %r79, 1;
	setp.eq.s32 	%p22, %r21, %r3;
	@%p22 bra 	$L__BB0_37;

	mul.wide.u32 	%rd19, %r21, 48;
	add.s64 	%rd20, %rd1, %rd19;
	ld.global.u8 	%rs11, [%rd20+33];
	and.b16  	%rs103, %rs11, 1;
	setp.eq.b16 	%p23, %rs103, 1;
	mov.pred 	%p24, 0;
	xor.pred  	%p25, %p23, %p24;
	not.pred 	%p26, %p25;
	@%p26 bra 	$L__BB0_37;

	.pragma "used_bytes_mask 4095";
	ld.shared.v4.f32 	{%f464, %f465, %f466, %f467}, [%r19+16];
	sub.ftz.f32 	%f50, %f381, %f464;
	sub.ftz.f32 	%f51, %f382, %f465;
	sub.ftz.f32 	%f52, %f383, %f466;
	mul.ftz.f32 	%f471, %f51, %f51;
	fma.rn.ftz.f32 	%f472, %f50, %f50, %f471;
	fma.rn.ftz.f32 	%f473, %f52, %f52, %f472;
	sqrt.approx.ftz.f32 	%f53, %f473;
	mov.f32 	%f474, 0f38D1B717;
	max.ftz.f32 	%f54, %f53, %f474;
	setp.geu.ftz.f32 	%p27, %f54, %f376;
	mov.f32 	%f1049, 0f00000000;
	@%p27 bra 	$L__BB0_28;

	mov.f32 	%f977, 0f38D1B717;
	max.ftz.f32 	%f976, %f53, %f977;
	ld.shared.f32 	%f475, [%r20+4];
	mul.ftz.f32 	%f476, %f7, %f475;
	sqrt.approx.ftz.f32 	%f477, %f476;
	mul.ftz.f32 	%f478, %f477, %f374;
	neg.ftz.f32 	%f479, %f478;
	mul.ftz.f32 	%f480, %f976, %f976;
	div.approx.ftz.f32 	%f481, %f479, %f480;
	mov.f32 	%f482, 0fC1200000;
	max.ftz.f32 	%f1049, %f481, %f482;

$L__BB0_28:
	and.b16  	%rs104, %rs1, %rs11;
	and.b16  	%rs105, %rs104, 2;
	setp.eq.s16 	%p28, %rs105, 0;
	@%p28 bra 	$L__BB0_33;

	mov.f32 	%f975, 0f38D1B717;
	max.ftz.f32 	%f974, %f53, %f975;
	add.ftz.f32 	%f57, %f974, 0fBF800000;
	abs.ftz.f32 	%f58, %f57;
	abs.ftz.f32 	%f59, %f58;
	setp.ltu.ftz.f32 	%p29, %f59, 0f3F19999A;
	@%p29 bra 	$L__BB0_31;
	bra.uni 	$L__BB0_30;

$L__BB0_31:
	mul.ftz.f32 	%f491, %f58, %f58;
	mov.f32 	%f492, 0fBD563CAE;
	mov.f32 	%f493, 0f3C80F082;
	fma.rn.ftz.f32 	%f494, %f493, %f491, %f492;
	mov.f32 	%f495, 0f3E085941;
	fma.rn.ftz.f32 	%f496, %f494, %f491, %f495;
	mov.f32 	%f497, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f498, %f496, %f491, %f497;
	mov.f32 	%f499, 0f00000000;
	fma.rn.ftz.f32 	%f500, %f498, %f491, %f499;
	fma.rn.ftz.f32 	%f1048, %f500, %f58, %f58;
	bra.uni 	$L__BB0_32;

$L__BB0_30:
	mul.ftz.f32 	%f483, %f59, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f484, %f483;
	add.ftz.f32 	%f485, %f484, 0f3F800000;
	mov.f32 	%f486, 0f3F800000;
	rcp.approx.ftz.f32 	%f487, %f485;
	mov.f32 	%f488, 0fC0000000;
	fma.rn.ftz.f32 	%f489, %f487, %f488, %f486;
	setp.ge.ftz.f32 	%p30, %f59, 0f41102CB4;
	selp.f32 	%f490, 0f3F800000, %f489, %p30;
	mov.b32 	%r80, %f490;
	mov.b32 	%r81, %f58;
	and.b32  	%r82, %r81, -2147483648;
	or.b32  	%r83, %r82, %r80;
	mov.b32 	%f1048, %r83;

$L__BB0_32:
	mov.f32 	%f980, 0f38D1B717;
	max.ftz.f32 	%f979, %f53, %f980;
	add.ftz.f32 	%f978, %f979, 0fBF800000;
	fma.rn.ftz.f32 	%f501, %f1048, 0f3F000000, 0f3F800000;
	mul.ftz.f32 	%f502, %f978, %f373;
	mul.ftz.f32 	%f503, %f502, %f501;
	mov.f32 	%f504, 0f41200000;
	min.ftz.f32 	%f505, %f503, %f504;
	mov.f32 	%f506, 0fC1200000;
	max.ftz.f32 	%f507, %f505, %f506;
	add.ftz.f32 	%f1049, %f1049, %f507;

$L__BB0_33:
	setp.lt.ftz.f32 	%p31, %f53, 0f358637BD;
	mov.f32 	%f1050, 0f00000000;
	mov.f32 	%f1051, %f1050;
	mov.f32 	%f1052, %f1050;
	@%p31 bra 	$L__BB0_35;

	rcp.approx.ftz.f32 	%f511, %f53;
	mul.ftz.f32 	%f1052, %f52, %f511;
	mul.ftz.f32 	%f1051, %f51, %f511;
	mul.ftz.f32 	%f1050, %f50, %f511;

$L__BB0_35:
	mov.f32 	%f512, 0f41700000;
	min.ftz.f32 	%f513, %f1049, %f512;
	mov.f32 	%f514, 0fC1700000;
	max.ftz.f32 	%f515, %f513, %f514;
	fma.rn.ftz.f32 	%f1053, %f515, %f1050, %f1053;
	fma.rn.ftz.f32 	%f1054, %f515, %f1051, %f1054;
	fma.rn.ftz.f32 	%f1055, %f515, %f1052, %f1055;
	mul.ftz.f32 	%f516, %f386, %f1051;
	fma.rn.ftz.f32 	%f517, %f385, %f1050, %f516;
	fma.rn.ftz.f32 	%f77, %f387, %f1052, %f517;
	setp.leu.ftz.f32 	%p32, %f77, 0f00000000;
	@%p32 bra 	$L__BB0_37;

	sqrt.approx.ftz.f32 	%f518, %f7;
	mul.ftz.f32 	%f519, %f77, %f518;
	mul.ftz.f32 	%f520, %f519, 0fBDCCCCCD;
	mov.f32 	%f521, 0fC0A00000;
	max.ftz.f32 	%f522, %f520, %f521;
	fma.rn.ftz.f32 	%f1053, %f1050, %f522, %f1053;
	fma.rn.ftz.f32 	%f1054, %f1051, %f522, %f1054;
	fma.rn.ftz.f32 	%f1055, %f1052, %f522, %f1055;

$L__BB0_37:
	add.s32 	%r22, %r79, 2;
	setp.eq.s32 	%p33, %r22, %r3;
	@%p33 bra 	$L__BB0_50;

	mul.wide.u32 	%rd21, %r22, 48;
	add.s64 	%rd22, %rd1, %rd21;
	ld.global.u8 	%rs20, [%rd22+33];
	and.b16  	%rs118, %rs20, 1;
	setp.eq.b16 	%p34, %rs118, 1;
	mov.pred 	%p35, 0;
	xor.pred  	%p36, %p34, %p35;
	not.pred 	%p37, %p36;
	@%p37 bra 	$L__BB0_50;

	.pragma "used_bytes_mask 4095";
	ld.shared.v4.f32 	{%f524, %f525, %f526, %f527}, [%r19+32];
	sub.ftz.f32 	%f84, %f381, %f524;
	sub.ftz.f32 	%f85, %f382, %f525;
	sub.ftz.f32 	%f86, %f383, %f526;
	mul.ftz.f32 	%f531, %f85, %f85;
	fma.rn.ftz.f32 	%f532, %f84, %f84, %f531;
	fma.rn.ftz.f32 	%f533, %f86, %f86, %f532;
	sqrt.approx.ftz.f32 	%f87, %f533;
	mov.f32 	%f534, 0f38D1B717;
	max.ftz.f32 	%f88, %f87, %f534;
	setp.geu.ftz.f32 	%p38, %f88, %f376;
	mov.f32 	%f1058, 0f00000000;
	@%p38 bra 	$L__BB0_41;

	mov.f32 	%f984, 0f38D1B717;
	max.ftz.f32 	%f983, %f87, %f984;
	ld.shared.f32 	%f535, [%r20+8];
	mul.ftz.f32 	%f536, %f7, %f535;
	sqrt.approx.ftz.f32 	%f537, %f536;
	mul.ftz.f32 	%f538, %f537, %f374;
	neg.ftz.f32 	%f539, %f538;
	mul.ftz.f32 	%f540, %f983, %f983;
	div.approx.ftz.f32 	%f541, %f539, %f540;
	mov.f32 	%f542, 0fC1200000;
	max.ftz.f32 	%f1058, %f541, %f542;

$L__BB0_41:
	and.b16  	%rs119, %rs1, %rs20;
	and.b16  	%rs120, %rs119, 2;
	setp.eq.s16 	%p39, %rs120, 0;
	@%p39 bra 	$L__BB0_46;

	mov.f32 	%f982, 0f38D1B717;
	max.ftz.f32 	%f981, %f87, %f982;
	add.ftz.f32 	%f91, %f981, 0fBF800000;
	abs.ftz.f32 	%f92, %f91;
	abs.ftz.f32 	%f93, %f92;
	setp.ltu.ftz.f32 	%p40, %f93, 0f3F19999A;
	@%p40 bra 	$L__BB0_44;
	bra.uni 	$L__BB0_43;

$L__BB0_44:
	mul.ftz.f32 	%f551, %f92, %f92;
	mov.f32 	%f552, 0fBD563CAE;
	mov.f32 	%f553, 0f3C80F082;
	fma.rn.ftz.f32 	%f554, %f553, %f551, %f552;
	mov.f32 	%f555, 0f3E085941;
	fma.rn.ftz.f32 	%f556, %f554, %f551, %f555;
	mov.f32 	%f557, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f558, %f556, %f551, %f557;
	mov.f32 	%f559, 0f00000000;
	fma.rn.ftz.f32 	%f560, %f558, %f551, %f559;
	fma.rn.ftz.f32 	%f1057, %f560, %f92, %f92;
	bra.uni 	$L__BB0_45;

$L__BB0_43:
	mul.ftz.f32 	%f543, %f93, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f544, %f543;
	add.ftz.f32 	%f545, %f544, 0f3F800000;
	mov.f32 	%f546, 0f3F800000;
	rcp.approx.ftz.f32 	%f547, %f545;
	mov.f32 	%f548, 0fC0000000;
	fma.rn.ftz.f32 	%f549, %f547, %f548, %f546;
	setp.ge.ftz.f32 	%p41, %f93, 0f41102CB4;
	selp.f32 	%f550, 0f3F800000, %f549, %p41;
	mov.b32 	%r85, %f550;
	mov.b32 	%r86, %f92;
	and.b32  	%r87, %r86, -2147483648;
	or.b32  	%r88, %r87, %r85;
	mov.b32 	%f1057, %r88;

$L__BB0_45:
	mov.f32 	%f987, 0f38D1B717;
	max.ftz.f32 	%f986, %f87, %f987;
	add.ftz.f32 	%f985, %f986, 0fBF800000;
	fma.rn.ftz.f32 	%f561, %f1057, 0f3F000000, 0f3F800000;
	mul.ftz.f32 	%f562, %f985, %f373;
	mul.ftz.f32 	%f563, %f562, %f561;
	mov.f32 	%f564, 0f41200000;
	min.ftz.f32 	%f565, %f563, %f564;
	mov.f32 	%f566, 0fC1200000;
	max.ftz.f32 	%f567, %f565, %f566;
	add.ftz.f32 	%f1058, %f1058, %f567;

$L__BB0_46:
	setp.lt.ftz.f32 	%p42, %f87, 0f358637BD;
	mov.f32 	%f1059, 0f00000000;
	mov.f32 	%f1060, %f1059;
	mov.f32 	%f1061, %f1059;
	@%p42 bra 	$L__BB0_48;

	rcp.approx.ftz.f32 	%f571, %f87;
	mul.ftz.f32 	%f1061, %f86, %f571;
	mul.ftz.f32 	%f1060, %f85, %f571;
	mul.ftz.f32 	%f1059, %f84, %f571;

$L__BB0_48:
	mov.f32 	%f572, 0f41700000;
	min.ftz.f32 	%f573, %f1058, %f572;
	mov.f32 	%f574, 0fC1700000;
	max.ftz.f32 	%f575, %f573, %f574;
	fma.rn.ftz.f32 	%f1053, %f575, %f1059, %f1053;
	fma.rn.ftz.f32 	%f1054, %f575, %f1060, %f1054;
	fma.rn.ftz.f32 	%f1055, %f575, %f1061, %f1055;
	mul.ftz.f32 	%f576, %f386, %f1060;
	fma.rn.ftz.f32 	%f577, %f385, %f1059, %f576;
	fma.rn.ftz.f32 	%f111, %f387, %f1061, %f577;
	setp.leu.ftz.f32 	%p43, %f111, 0f00000000;
	@%p43 bra 	$L__BB0_50;

	sqrt.approx.ftz.f32 	%f578, %f7;
	mul.ftz.f32 	%f579, %f111, %f578;
	mul.ftz.f32 	%f580, %f579, 0fBDCCCCCD;
	mov.f32 	%f581, 0fC0A00000;
	max.ftz.f32 	%f582, %f580, %f581;
	fma.rn.ftz.f32 	%f1053, %f1059, %f582, %f1053;
	fma.rn.ftz.f32 	%f1054, %f1060, %f582, %f1054;
	fma.rn.ftz.f32 	%f1055, %f1061, %f582, %f1055;

$L__BB0_50:
	add.s32 	%r23, %r79, 3;
	setp.eq.s32 	%p44, %r23, %r3;
	@%p44 bra 	$L__BB0_63;

	mul.wide.u32 	%rd23, %r23, 48;
	add.s64 	%rd24, %rd1, %rd23;
	ld.global.u8 	%rs29, [%rd24+33];
	and.b16  	%rs133, %rs29, 1;
	setp.eq.b16 	%p45, %rs133, 1;
	mov.pred 	%p46, 0;
	xor.pred  	%p47, %p45, %p46;
	not.pred 	%p48, %p47;
	@%p48 bra 	$L__BB0_63;

	.pragma "used_bytes_mask 4095";
	ld.shared.v4.f32 	{%f584, %f585, %f586, %f587}, [%r19+48];
	sub.ftz.f32 	%f118, %f381, %f584;
	sub.ftz.f32 	%f119, %f382, %f585;
	sub.ftz.f32 	%f120, %f383, %f586;
	mul.ftz.f32 	%f591, %f119, %f119;
	fma.rn.ftz.f32 	%f592, %f118, %f118, %f591;
	fma.rn.ftz.f32 	%f593, %f120, %f120, %f592;
	sqrt.approx.ftz.f32 	%f121, %f593;
	mov.f32 	%f594, 0f38D1B717;
	max.ftz.f32 	%f122, %f121, %f594;
	setp.geu.ftz.f32 	%p49, %f122, %f376;
	mov.f32 	%f1067, 0f00000000;
	@%p49 bra 	$L__BB0_54;

	mov.f32 	%f991, 0f38D1B717;
	max.ftz.f32 	%f990, %f121, %f991;
	ld.shared.f32 	%f595, [%r20+12];
	mul.ftz.f32 	%f596, %f7, %f595;
	sqrt.approx.ftz.f32 	%f597, %f596;
	mul.ftz.f32 	%f598, %f597, %f374;
	neg.ftz.f32 	%f599, %f598;
	mul.ftz.f32 	%f600, %f990, %f990;
	div.approx.ftz.f32 	%f601, %f599, %f600;
	mov.f32 	%f602, 0fC1200000;
	max.ftz.f32 	%f1067, %f601, %f602;

$L__BB0_54:
	and.b16  	%rs134, %rs1, %rs29;
	and.b16  	%rs135, %rs134, 2;
	setp.eq.s16 	%p50, %rs135, 0;
	@%p50 bra 	$L__BB0_59;

	mov.f32 	%f989, 0f38D1B717;
	max.ftz.f32 	%f988, %f121, %f989;
	add.ftz.f32 	%f125, %f988, 0fBF800000;
	abs.ftz.f32 	%f126, %f125;
	abs.ftz.f32 	%f127, %f126;
	setp.ltu.ftz.f32 	%p51, %f127, 0f3F19999A;
	@%p51 bra 	$L__BB0_57;
	bra.uni 	$L__BB0_56;

$L__BB0_57:
	mul.ftz.f32 	%f611, %f126, %f126;
	mov.f32 	%f612, 0fBD563CAE;
	mov.f32 	%f613, 0f3C80F082;
	fma.rn.ftz.f32 	%f614, %f613, %f611, %f612;
	mov.f32 	%f615, 0f3E085941;
	fma.rn.ftz.f32 	%f616, %f614, %f611, %f615;
	mov.f32 	%f617, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f618, %f616, %f611, %f617;
	mov.f32 	%f619, 0f00000000;
	fma.rn.ftz.f32 	%f620, %f618, %f611, %f619;
	fma.rn.ftz.f32 	%f1066, %f620, %f126, %f126;
	bra.uni 	$L__BB0_58;

$L__BB0_56:
	mul.ftz.f32 	%f603, %f127, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f604, %f603;
	add.ftz.f32 	%f605, %f604, 0f3F800000;
	mov.f32 	%f606, 0f3F800000;
	rcp.approx.ftz.f32 	%f607, %f605;
	mov.f32 	%f608, 0fC0000000;
	fma.rn.ftz.f32 	%f609, %f607, %f608, %f606;
	setp.ge.ftz.f32 	%p52, %f127, 0f41102CB4;
	selp.f32 	%f610, 0f3F800000, %f609, %p52;
	mov.b32 	%r90, %f610;
	mov.b32 	%r91, %f126;
	and.b32  	%r92, %r91, -2147483648;
	or.b32  	%r93, %r92, %r90;
	mov.b32 	%f1066, %r93;

$L__BB0_58:
	mov.f32 	%f994, 0f38D1B717;
	max.ftz.f32 	%f993, %f121, %f994;
	add.ftz.f32 	%f992, %f993, 0fBF800000;
	fma.rn.ftz.f32 	%f621, %f1066, 0f3F000000, 0f3F800000;
	mul.ftz.f32 	%f622, %f992, %f373;
	mul.ftz.f32 	%f623, %f622, %f621;
	mov.f32 	%f624, 0f41200000;
	min.ftz.f32 	%f625, %f623, %f624;
	mov.f32 	%f626, 0fC1200000;
	max.ftz.f32 	%f627, %f625, %f626;
	add.ftz.f32 	%f1067, %f1067, %f627;

$L__BB0_59:
	setp.lt.ftz.f32 	%p53, %f121, 0f358637BD;
	mov.f32 	%f1068, 0f00000000;
	mov.f32 	%f1069, %f1068;
	mov.f32 	%f1070, %f1068;
	@%p53 bra 	$L__BB0_61;

	rcp.approx.ftz.f32 	%f631, %f121;
	mul.ftz.f32 	%f1070, %f120, %f631;
	mul.ftz.f32 	%f1069, %f119, %f631;
	mul.ftz.f32 	%f1068, %f118, %f631;

$L__BB0_61:
	mov.f32 	%f632, 0f41700000;
	min.ftz.f32 	%f633, %f1067, %f632;
	mov.f32 	%f634, 0fC1700000;
	max.ftz.f32 	%f635, %f633, %f634;
	fma.rn.ftz.f32 	%f1053, %f635, %f1068, %f1053;
	fma.rn.ftz.f32 	%f1054, %f635, %f1069, %f1054;
	fma.rn.ftz.f32 	%f1055, %f635, %f1070, %f1055;
	mul.ftz.f32 	%f636, %f386, %f1069;
	fma.rn.ftz.f32 	%f637, %f385, %f1068, %f636;
	fma.rn.ftz.f32 	%f145, %f387, %f1070, %f637;
	setp.leu.ftz.f32 	%p54, %f145, 0f00000000;
	@%p54 bra 	$L__BB0_63;

	sqrt.approx.ftz.f32 	%f638, %f7;
	mul.ftz.f32 	%f639, %f145, %f638;
	mul.ftz.f32 	%f640, %f639, 0fBDCCCCCD;
	mov.f32 	%f641, 0fC0A00000;
	max.ftz.f32 	%f642, %f640, %f641;
	fma.rn.ftz.f32 	%f1053, %f1068, %f642, %f1053;
	fma.rn.ftz.f32 	%f1054, %f1069, %f642, %f1054;
	fma.rn.ftz.f32 	%f1055, %f1070, %f642, %f1055;

$L__BB0_63:
	add.s32 	%r24, %r79, 4;
	setp.eq.s32 	%p55, %r24, %r3;
	@%p55 bra 	$L__BB0_76;

	mul.wide.u32 	%rd25, %r24, 48;
	add.s64 	%rd26, %rd1, %rd25;
	ld.global.u8 	%rs38, [%rd26+33];
	and.b16  	%rs148, %rs38, 1;
	setp.eq.b16 	%p56, %rs148, 1;
	mov.pred 	%p57, 0;
	xor.pred  	%p58, %p56, %p57;
	not.pred 	%p59, %p58;
	@%p59 bra 	$L__BB0_76;

	.pragma "used_bytes_mask 4095";
	ld.shared.v4.f32 	{%f644, %f645, %f646, %f647}, [%r19+64];
	sub.ftz.f32 	%f152, %f381, %f644;
	sub.ftz.f32 	%f153, %f382, %f645;
	sub.ftz.f32 	%f154, %f383, %f646;
	mul.ftz.f32 	%f651, %f153, %f153;
	fma.rn.ftz.f32 	%f652, %f152, %f152, %f651;
	fma.rn.ftz.f32 	%f653, %f154, %f154, %f652;
	sqrt.approx.ftz.f32 	%f155, %f653;
	mov.f32 	%f654, 0f38D1B717;
	max.ftz.f32 	%f156, %f155, %f654;
	setp.geu.ftz.f32 	%p60, %f156, %f376;
	mov.f32 	%f1076, 0f00000000;
	@%p60 bra 	$L__BB0_67;

	mov.f32 	%f998, 0f38D1B717;
	max.ftz.f32 	%f997, %f155, %f998;
	ld.shared.f32 	%f655, [%r20+16];
	mul.ftz.f32 	%f656, %f7, %f655;
	sqrt.approx.ftz.f32 	%f657, %f656;
	mul.ftz.f32 	%f658, %f657, %f374;
	neg.ftz.f32 	%f659, %f658;
	mul.ftz.f32 	%f660, %f997, %f997;
	div.approx.ftz.f32 	%f661, %f659, %f660;
	mov.f32 	%f662, 0fC1200000;
	max.ftz.f32 	%f1076, %f661, %f662;

$L__BB0_67:
	and.b16  	%rs149, %rs1, %rs38;
	and.b16  	%rs150, %rs149, 2;
	setp.eq.s16 	%p61, %rs150, 0;
	@%p61 bra 	$L__BB0_72;

	mov.f32 	%f996, 0f38D1B717;
	max.ftz.f32 	%f995, %f155, %f996;
	add.ftz.f32 	%f159, %f995, 0fBF800000;
	abs.ftz.f32 	%f160, %f159;
	abs.ftz.f32 	%f161, %f160;
	setp.ltu.ftz.f32 	%p62, %f161, 0f3F19999A;
	@%p62 bra 	$L__BB0_70;
	bra.uni 	$L__BB0_69;

$L__BB0_70:
	mul.ftz.f32 	%f671, %f160, %f160;
	mov.f32 	%f672, 0fBD563CAE;
	mov.f32 	%f673, 0f3C80F082;
	fma.rn.ftz.f32 	%f674, %f673, %f671, %f672;
	mov.f32 	%f675, 0f3E085941;
	fma.rn.ftz.f32 	%f676, %f674, %f671, %f675;
	mov.f32 	%f677, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f678, %f676, %f671, %f677;
	mov.f32 	%f679, 0f00000000;
	fma.rn.ftz.f32 	%f680, %f678, %f671, %f679;
	fma.rn.ftz.f32 	%f1075, %f680, %f160, %f160;
	bra.uni 	$L__BB0_71;

$L__BB0_69:
	mul.ftz.f32 	%f663, %f161, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f664, %f663;
	add.ftz.f32 	%f665, %f664, 0f3F800000;
	mov.f32 	%f666, 0f3F800000;
	rcp.approx.ftz.f32 	%f667, %f665;
	mov.f32 	%f668, 0fC0000000;
	fma.rn.ftz.f32 	%f669, %f667, %f668, %f666;
	setp.ge.ftz.f32 	%p63, %f161, 0f41102CB4;
	selp.f32 	%f670, 0f3F800000, %f669, %p63;
	mov.b32 	%r95, %f670;
	mov.b32 	%r96, %f160;
	and.b32  	%r97, %r96, -2147483648;
	or.b32  	%r98, %r97, %r95;
	mov.b32 	%f1075, %r98;

$L__BB0_71:
	mov.f32 	%f1001, 0f38D1B717;
	max.ftz.f32 	%f1000, %f155, %f1001;
	add.ftz.f32 	%f999, %f1000, 0fBF800000;
	fma.rn.ftz.f32 	%f681, %f1075, 0f3F000000, 0f3F800000;
	mul.ftz.f32 	%f682, %f999, %f373;
	mul.ftz.f32 	%f683, %f682, %f681;
	mov.f32 	%f684, 0f41200000;
	min.ftz.f32 	%f685, %f683, %f684;
	mov.f32 	%f686, 0fC1200000;
	max.ftz.f32 	%f687, %f685, %f686;
	add.ftz.f32 	%f1076, %f1076, %f687;

$L__BB0_72:
	setp.lt.ftz.f32 	%p64, %f155, 0f358637BD;
	mov.f32 	%f1077, 0f00000000;
	mov.f32 	%f1078, %f1077;
	mov.f32 	%f1079, %f1077;
	@%p64 bra 	$L__BB0_74;

	rcp.approx.ftz.f32 	%f691, %f155;
	mul.ftz.f32 	%f1079, %f154, %f691;
	mul.ftz.f32 	%f1078, %f153, %f691;
	mul.ftz.f32 	%f1077, %f152, %f691;

$L__BB0_74:
	mov.f32 	%f692, 0f41700000;
	min.ftz.f32 	%f693, %f1076, %f692;
	mov.f32 	%f694, 0fC1700000;
	max.ftz.f32 	%f695, %f693, %f694;
	fma.rn.ftz.f32 	%f1053, %f695, %f1077, %f1053;
	fma.rn.ftz.f32 	%f1054, %f695, %f1078, %f1054;
	fma.rn.ftz.f32 	%f1055, %f695, %f1079, %f1055;
	mul.ftz.f32 	%f696, %f386, %f1078;
	fma.rn.ftz.f32 	%f697, %f385, %f1077, %f696;
	fma.rn.ftz.f32 	%f179, %f387, %f1079, %f697;
	setp.leu.ftz.f32 	%p65, %f179, 0f00000000;
	@%p65 bra 	$L__BB0_76;

	sqrt.approx.ftz.f32 	%f698, %f7;
	mul.ftz.f32 	%f699, %f179, %f698;
	mul.ftz.f32 	%f700, %f699, 0fBDCCCCCD;
	mov.f32 	%f701, 0fC0A00000;
	max.ftz.f32 	%f702, %f700, %f701;
	fma.rn.ftz.f32 	%f1053, %f1077, %f702, %f1053;
	fma.rn.ftz.f32 	%f1054, %f1078, %f702, %f1054;
	fma.rn.ftz.f32 	%f1055, %f1079, %f702, %f1055;

$L__BB0_76:
	add.s32 	%r25, %r79, 5;
	setp.eq.s32 	%p66, %r25, %r3;
	@%p66 bra 	$L__BB0_89;

	mul.wide.u32 	%rd27, %r25, 48;
	add.s64 	%rd28, %rd1, %rd27;
	ld.global.u8 	%rs47, [%rd28+33];
	and.b16  	%rs163, %rs47, 1;
	setp.eq.b16 	%p67, %rs163, 1;
	mov.pred 	%p68, 0;
	xor.pred  	%p69, %p67, %p68;
	not.pred 	%p70, %p69;
	@%p70 bra 	$L__BB0_89;

	.pragma "used_bytes_mask 4095";
	ld.shared.v4.f32 	{%f704, %f705, %f706, %f707}, [%r19+80];
	sub.ftz.f32 	%f186, %f381, %f704;
	sub.ftz.f32 	%f187, %f382, %f705;
	sub.ftz.f32 	%f188, %f383, %f706;
	mul.ftz.f32 	%f711, %f187, %f187;
	fma.rn.ftz.f32 	%f712, %f186, %f186, %f711;
	fma.rn.ftz.f32 	%f713, %f188, %f188, %f712;
	sqrt.approx.ftz.f32 	%f189, %f713;
	mov.f32 	%f714, 0f38D1B717;
	max.ftz.f32 	%f190, %f189, %f714;
	setp.geu.ftz.f32 	%p71, %f190, %f376;
	mov.f32 	%f1085, 0f00000000;
	@%p71 bra 	$L__BB0_80;

	mov.f32 	%f1005, 0f38D1B717;
	max.ftz.f32 	%f1004, %f189, %f1005;
	ld.shared.f32 	%f715, [%r20+20];
	mul.ftz.f32 	%f716, %f7, %f715;
	sqrt.approx.ftz.f32 	%f717, %f716;
	mul.ftz.f32 	%f718, %f717, %f374;
	neg.ftz.f32 	%f719, %f718;
	mul.ftz.f32 	%f720, %f1004, %f1004;
	div.approx.ftz.f32 	%f721, %f719, %f720;
	mov.f32 	%f722, 0fC1200000;
	max.ftz.f32 	%f1085, %f721, %f722;

$L__BB0_80:
	and.b16  	%rs164, %rs1, %rs47;
	and.b16  	%rs165, %rs164, 2;
	setp.eq.s16 	%p72, %rs165, 0;
	@%p72 bra 	$L__BB0_85;

	mov.f32 	%f1003, 0f38D1B717;
	max.ftz.f32 	%f1002, %f189, %f1003;
	add.ftz.f32 	%f193, %f1002, 0fBF800000;
	abs.ftz.f32 	%f194, %f193;
	abs.ftz.f32 	%f195, %f194;
	setp.ltu.ftz.f32 	%p73, %f195, 0f3F19999A;
	@%p73 bra 	$L__BB0_83;
	bra.uni 	$L__BB0_82;

$L__BB0_83:
	mul.ftz.f32 	%f731, %f194, %f194;
	mov.f32 	%f732, 0fBD563CAE;
	mov.f32 	%f733, 0f3C80F082;
	fma.rn.ftz.f32 	%f734, %f733, %f731, %f732;
	mov.f32 	%f735, 0f3E085941;
	fma.rn.ftz.f32 	%f736, %f734, %f731, %f735;
	mov.f32 	%f737, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f738, %f736, %f731, %f737;
	mov.f32 	%f739, 0f00000000;
	fma.rn.ftz.f32 	%f740, %f738, %f731, %f739;
	fma.rn.ftz.f32 	%f1084, %f740, %f194, %f194;
	bra.uni 	$L__BB0_84;

$L__BB0_82:
	mul.ftz.f32 	%f723, %f195, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f724, %f723;
	add.ftz.f32 	%f725, %f724, 0f3F800000;
	mov.f32 	%f726, 0f3F800000;
	rcp.approx.ftz.f32 	%f727, %f725;
	mov.f32 	%f728, 0fC0000000;
	fma.rn.ftz.f32 	%f729, %f727, %f728, %f726;
	setp.ge.ftz.f32 	%p74, %f195, 0f41102CB4;
	selp.f32 	%f730, 0f3F800000, %f729, %p74;
	mov.b32 	%r100, %f730;
	mov.b32 	%r101, %f194;
	and.b32  	%r102, %r101, -2147483648;
	or.b32  	%r103, %r102, %r100;
	mov.b32 	%f1084, %r103;

$L__BB0_84:
	mov.f32 	%f1008, 0f38D1B717;
	max.ftz.f32 	%f1007, %f189, %f1008;
	add.ftz.f32 	%f1006, %f1007, 0fBF800000;
	fma.rn.ftz.f32 	%f741, %f1084, 0f3F000000, 0f3F800000;
	mul.ftz.f32 	%f742, %f1006, %f373;
	mul.ftz.f32 	%f743, %f742, %f741;
	mov.f32 	%f744, 0f41200000;
	min.ftz.f32 	%f745, %f743, %f744;
	mov.f32 	%f746, 0fC1200000;
	max.ftz.f32 	%f747, %f745, %f746;
	add.ftz.f32 	%f1085, %f1085, %f747;

$L__BB0_85:
	setp.lt.ftz.f32 	%p75, %f189, 0f358637BD;
	mov.f32 	%f1086, 0f00000000;
	mov.f32 	%f1087, %f1086;
	mov.f32 	%f1088, %f1086;
	@%p75 bra 	$L__BB0_87;

	rcp.approx.ftz.f32 	%f751, %f189;
	mul.ftz.f32 	%f1088, %f188, %f751;
	mul.ftz.f32 	%f1087, %f187, %f751;
	mul.ftz.f32 	%f1086, %f186, %f751;

$L__BB0_87:
	mov.f32 	%f752, 0f41700000;
	min.ftz.f32 	%f753, %f1085, %f752;
	mov.f32 	%f754, 0fC1700000;
	max.ftz.f32 	%f755, %f753, %f754;
	fma.rn.ftz.f32 	%f1053, %f755, %f1086, %f1053;
	fma.rn.ftz.f32 	%f1054, %f755, %f1087, %f1054;
	fma.rn.ftz.f32 	%f1055, %f755, %f1088, %f1055;
	mul.ftz.f32 	%f756, %f386, %f1087;
	fma.rn.ftz.f32 	%f757, %f385, %f1086, %f756;
	fma.rn.ftz.f32 	%f213, %f387, %f1088, %f757;
	setp.leu.ftz.f32 	%p76, %f213, 0f00000000;
	@%p76 bra 	$L__BB0_89;

	sqrt.approx.ftz.f32 	%f758, %f7;
	mul.ftz.f32 	%f759, %f213, %f758;
	mul.ftz.f32 	%f760, %f759, 0fBDCCCCCD;
	mov.f32 	%f761, 0fC0A00000;
	max.ftz.f32 	%f762, %f760, %f761;
	fma.rn.ftz.f32 	%f1053, %f1086, %f762, %f1053;
	fma.rn.ftz.f32 	%f1054, %f1087, %f762, %f1054;
	fma.rn.ftz.f32 	%f1055, %f1088, %f762, %f1055;

$L__BB0_89:
	add.s32 	%r26, %r79, 6;
	setp.eq.s32 	%p77, %r26, %r3;
	@%p77 bra 	$L__BB0_102;

	mul.wide.u32 	%rd29, %r26, 48;
	add.s64 	%rd30, %rd1, %rd29;
	ld.global.u8 	%rs56, [%rd30+33];
	and.b16  	%rs178, %rs56, 1;
	setp.eq.b16 	%p78, %rs178, 1;
	mov.pred 	%p79, 0;
	xor.pred  	%p80, %p78, %p79;
	not.pred 	%p81, %p80;
	@%p81 bra 	$L__BB0_102;

	.pragma "used_bytes_mask 4095";
	ld.shared.v4.f32 	{%f764, %f765, %f766, %f767}, [%r19+96];
	sub.ftz.f32 	%f220, %f381, %f764;
	sub.ftz.f32 	%f221, %f382, %f765;
	sub.ftz.f32 	%f222, %f383, %f766;
	mul.ftz.f32 	%f771, %f221, %f221;
	fma.rn.ftz.f32 	%f772, %f220, %f220, %f771;
	fma.rn.ftz.f32 	%f773, %f222, %f222, %f772;
	sqrt.approx.ftz.f32 	%f223, %f773;
	mov.f32 	%f774, 0f38D1B717;
	max.ftz.f32 	%f224, %f223, %f774;
	setp.geu.ftz.f32 	%p82, %f224, %f376;
	mov.f32 	%f1094, 0f00000000;
	@%p82 bra 	$L__BB0_93;

	mov.f32 	%f1012, 0f38D1B717;
	max.ftz.f32 	%f1011, %f223, %f1012;
	ld.shared.f32 	%f775, [%r20+24];
	mul.ftz.f32 	%f776, %f7, %f775;
	sqrt.approx.ftz.f32 	%f777, %f776;
	mul.ftz.f32 	%f778, %f777, %f374;
	neg.ftz.f32 	%f779, %f778;
	mul.ftz.f32 	%f780, %f1011, %f1011;
	div.approx.ftz.f32 	%f781, %f779, %f780;
	mov.f32 	%f782, 0fC1200000;
	max.ftz.f32 	%f1094, %f781, %f782;

$L__BB0_93:
	and.b16  	%rs179, %rs1, %rs56;
	and.b16  	%rs180, %rs179, 2;
	setp.eq.s16 	%p83, %rs180, 0;
	@%p83 bra 	$L__BB0_98;

	mov.f32 	%f1010, 0f38D1B717;
	max.ftz.f32 	%f1009, %f223, %f1010;
	add.ftz.f32 	%f227, %f1009, 0fBF800000;
	abs.ftz.f32 	%f228, %f227;
	abs.ftz.f32 	%f229, %f228;
	setp.ltu.ftz.f32 	%p84, %f229, 0f3F19999A;
	@%p84 bra 	$L__BB0_96;
	bra.uni 	$L__BB0_95;

$L__BB0_96:
	mul.ftz.f32 	%f791, %f228, %f228;
	mov.f32 	%f792, 0fBD563CAE;
	mov.f32 	%f793, 0f3C80F082;
	fma.rn.ftz.f32 	%f794, %f793, %f791, %f792;
	mov.f32 	%f795, 0f3E085941;
	fma.rn.ftz.f32 	%f796, %f794, %f791, %f795;
	mov.f32 	%f797, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f798, %f796, %f791, %f797;
	mov.f32 	%f799, 0f00000000;
	fma.rn.ftz.f32 	%f800, %f798, %f791, %f799;
	fma.rn.ftz.f32 	%f1093, %f800, %f228, %f228;
	bra.uni 	$L__BB0_97;

$L__BB0_95:
	mul.ftz.f32 	%f783, %f229, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f784, %f783;
	add.ftz.f32 	%f785, %f784, 0f3F800000;
	mov.f32 	%f786, 0f3F800000;
	rcp.approx.ftz.f32 	%f787, %f785;
	mov.f32 	%f788, 0fC0000000;
	fma.rn.ftz.f32 	%f789, %f787, %f788, %f786;
	setp.ge.ftz.f32 	%p85, %f229, 0f41102CB4;
	selp.f32 	%f790, 0f3F800000, %f789, %p85;
	mov.b32 	%r105, %f790;
	mov.b32 	%r106, %f228;
	and.b32  	%r107, %r106, -2147483648;
	or.b32  	%r108, %r107, %r105;
	mov.b32 	%f1093, %r108;

$L__BB0_97:
	mov.f32 	%f1015, 0f38D1B717;
	max.ftz.f32 	%f1014, %f223, %f1015;
	add.ftz.f32 	%f1013, %f1014, 0fBF800000;
	fma.rn.ftz.f32 	%f801, %f1093, 0f3F000000, 0f3F800000;
	mul.ftz.f32 	%f802, %f1013, %f373;
	mul.ftz.f32 	%f803, %f802, %f801;
	mov.f32 	%f804, 0f41200000;
	min.ftz.f32 	%f805, %f803, %f804;
	mov.f32 	%f806, 0fC1200000;
	max.ftz.f32 	%f807, %f805, %f806;
	add.ftz.f32 	%f1094, %f1094, %f807;

$L__BB0_98:
	setp.lt.ftz.f32 	%p86, %f223, 0f358637BD;
	mov.f32 	%f1095, 0f00000000;
	mov.f32 	%f1096, %f1095;
	mov.f32 	%f1097, %f1095;
	@%p86 bra 	$L__BB0_100;

	rcp.approx.ftz.f32 	%f811, %f223;
	mul.ftz.f32 	%f1097, %f222, %f811;
	mul.ftz.f32 	%f1096, %f221, %f811;
	mul.ftz.f32 	%f1095, %f220, %f811;

$L__BB0_100:
	mov.f32 	%f812, 0f41700000;
	min.ftz.f32 	%f813, %f1094, %f812;
	mov.f32 	%f814, 0fC1700000;
	max.ftz.f32 	%f815, %f813, %f814;
	fma.rn.ftz.f32 	%f1053, %f815, %f1095, %f1053;
	fma.rn.ftz.f32 	%f1054, %f815, %f1096, %f1054;
	fma.rn.ftz.f32 	%f1055, %f815, %f1097, %f1055;
	mul.ftz.f32 	%f816, %f386, %f1096;
	fma.rn.ftz.f32 	%f817, %f385, %f1095, %f816;
	fma.rn.ftz.f32 	%f247, %f387, %f1097, %f817;
	setp.leu.ftz.f32 	%p87, %f247, 0f00000000;
	@%p87 bra 	$L__BB0_102;

	sqrt.approx.ftz.f32 	%f818, %f7;
	mul.ftz.f32 	%f819, %f247, %f818;
	mul.ftz.f32 	%f820, %f819, 0fBDCCCCCD;
	mov.f32 	%f821, 0fC0A00000;
	max.ftz.f32 	%f822, %f820, %f821;
	fma.rn.ftz.f32 	%f1053, %f1095, %f822, %f1053;
	fma.rn.ftz.f32 	%f1054, %f1096, %f822, %f1054;
	fma.rn.ftz.f32 	%f1055, %f1097, %f822, %f1055;

$L__BB0_102:
	add.s32 	%r27, %r79, 7;
	setp.eq.s32 	%p88, %r27, %r3;
	@%p88 bra 	$L__BB0_115;

	mul.wide.u32 	%rd31, %r27, 48;
	add.s64 	%rd32, %rd1, %rd31;
	ld.global.u8 	%rs65, [%rd32+33];
	and.b16  	%rs193, %rs65, 1;
	setp.eq.b16 	%p89, %rs193, 1;
	mov.pred 	%p90, 0;
	xor.pred  	%p91, %p89, %p90;
	not.pred 	%p92, %p91;
	@%p92 bra 	$L__BB0_115;

	.pragma "used_bytes_mask 4095";
	ld.shared.v4.f32 	{%f824, %f825, %f826, %f827}, [%r19+112];
	sub.ftz.f32 	%f254, %f381, %f824;
	sub.ftz.f32 	%f255, %f382, %f825;
	sub.ftz.f32 	%f256, %f383, %f826;
	mul.ftz.f32 	%f831, %f255, %f255;
	fma.rn.ftz.f32 	%f832, %f254, %f254, %f831;
	fma.rn.ftz.f32 	%f833, %f256, %f256, %f832;
	sqrt.approx.ftz.f32 	%f257, %f833;
	mov.f32 	%f834, 0f38D1B717;
	max.ftz.f32 	%f258, %f257, %f834;
	setp.geu.ftz.f32 	%p93, %f258, %f376;
	mov.f32 	%f1103, 0f00000000;
	@%p93 bra 	$L__BB0_106;

	mov.f32 	%f1019, 0f38D1B717;
	max.ftz.f32 	%f1018, %f257, %f1019;
	ld.shared.f32 	%f835, [%r20+28];
	mul.ftz.f32 	%f836, %f7, %f835;
	sqrt.approx.ftz.f32 	%f837, %f836;
	mul.ftz.f32 	%f838, %f837, %f374;
	neg.ftz.f32 	%f839, %f838;
	mul.ftz.f32 	%f840, %f1018, %f1018;
	div.approx.ftz.f32 	%f841, %f839, %f840;
	mov.f32 	%f842, 0fC1200000;
	max.ftz.f32 	%f1103, %f841, %f842;

$L__BB0_106:
	and.b16  	%rs194, %rs1, %rs65;
	and.b16  	%rs195, %rs194, 2;
	setp.eq.s16 	%p94, %rs195, 0;
	@%p94 bra 	$L__BB0_111;

	mov.f32 	%f1017, 0f38D1B717;
	max.ftz.f32 	%f1016, %f257, %f1017;
	add.ftz.f32 	%f261, %f1016, 0fBF800000;
	abs.ftz.f32 	%f262, %f261;
	abs.ftz.f32 	%f263, %f262;
	setp.ltu.ftz.f32 	%p95, %f263, 0f3F19999A;
	@%p95 bra 	$L__BB0_109;
	bra.uni 	$L__BB0_108;

$L__BB0_109:
	mul.ftz.f32 	%f851, %f262, %f262;
	mov.f32 	%f852, 0fBD563CAE;
	mov.f32 	%f853, 0f3C80F082;
	fma.rn.ftz.f32 	%f854, %f853, %f851, %f852;
	mov.f32 	%f855, 0f3E085941;
	fma.rn.ftz.f32 	%f856, %f854, %f851, %f855;
	mov.f32 	%f857, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f858, %f856, %f851, %f857;
	mov.f32 	%f859, 0f00000000;
	fma.rn.ftz.f32 	%f860, %f858, %f851, %f859;
	fma.rn.ftz.f32 	%f1102, %f860, %f262, %f262;
	bra.uni 	$L__BB0_110;

$L__BB0_108:
	mul.ftz.f32 	%f843, %f263, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f844, %f843;
	add.ftz.f32 	%f845, %f844, 0f3F800000;
	mov.f32 	%f846, 0f3F800000;
	rcp.approx.ftz.f32 	%f847, %f845;
	mov.f32 	%f848, 0fC0000000;
	fma.rn.ftz.f32 	%f849, %f847, %f848, %f846;
	setp.ge.ftz.f32 	%p96, %f263, 0f41102CB4;
	selp.f32 	%f850, 0f3F800000, %f849, %p96;
	mov.b32 	%r110, %f850;
	mov.b32 	%r111, %f262;
	and.b32  	%r112, %r111, -2147483648;
	or.b32  	%r113, %r112, %r110;
	mov.b32 	%f1102, %r113;

$L__BB0_110:
	mov.f32 	%f1022, 0f38D1B717;
	max.ftz.f32 	%f1021, %f257, %f1022;
	add.ftz.f32 	%f1020, %f1021, 0fBF800000;
	fma.rn.ftz.f32 	%f861, %f1102, 0f3F000000, 0f3F800000;
	mul.ftz.f32 	%f862, %f1020, %f373;
	mul.ftz.f32 	%f863, %f862, %f861;
	mov.f32 	%f864, 0f41200000;
	min.ftz.f32 	%f865, %f863, %f864;
	mov.f32 	%f866, 0fC1200000;
	max.ftz.f32 	%f867, %f865, %f866;
	add.ftz.f32 	%f1103, %f1103, %f867;

$L__BB0_111:
	setp.lt.ftz.f32 	%p97, %f257, 0f358637BD;
	mov.f32 	%f1104, 0f00000000;
	mov.f32 	%f1105, %f1104;
	mov.f32 	%f1106, %f1104;
	@%p97 bra 	$L__BB0_113;

	rcp.approx.ftz.f32 	%f871, %f257;
	mul.ftz.f32 	%f1106, %f256, %f871;
	mul.ftz.f32 	%f1105, %f255, %f871;
	mul.ftz.f32 	%f1104, %f254, %f871;

$L__BB0_113:
	mov.f32 	%f872, 0f41700000;
	min.ftz.f32 	%f873, %f1103, %f872;
	mov.f32 	%f874, 0fC1700000;
	max.ftz.f32 	%f875, %f873, %f874;
	fma.rn.ftz.f32 	%f1053, %f875, %f1104, %f1053;
	fma.rn.ftz.f32 	%f1054, %f875, %f1105, %f1054;
	fma.rn.ftz.f32 	%f1055, %f875, %f1106, %f1055;
	mul.ftz.f32 	%f876, %f386, %f1105;
	fma.rn.ftz.f32 	%f877, %f385, %f1104, %f876;
	fma.rn.ftz.f32 	%f281, %f387, %f1106, %f877;
	setp.leu.ftz.f32 	%p98, %f281, 0f00000000;
	@%p98 bra 	$L__BB0_115;

	sqrt.approx.ftz.f32 	%f878, %f7;
	mul.ftz.f32 	%f879, %f281, %f878;
	mul.ftz.f32 	%f880, %f879, 0fBDCCCCCD;
	mov.f32 	%f881, 0fC0A00000;
	max.ftz.f32 	%f882, %f880, %f881;
	fma.rn.ftz.f32 	%f1053, %f1104, %f882, %f1053;
	fma.rn.ftz.f32 	%f1054, %f1105, %f882, %f1054;
	fma.rn.ftz.f32 	%f1055, %f1106, %f882, %f1055;

$L__BB0_115:
	add.s32 	%r137, %r137, 8;
	add.s32 	%r136, %r137, %r10;
	add.s32 	%r135, %r135, -8;
	setp.ne.s32 	%p99, %r135, 0;
	@%p99 bra 	$L__BB0_8;

$L__BB0_116:
	setp.eq.s32 	%p100, %r142, 0;
	@%p100 bra 	$L__BB0_135;

	shl.b32 	%r114, %r137, 2;
	add.s32 	%r139, %r58, %r114;
	shl.b32 	%r116, %r137, 4;
	add.s32 	%r138, %r56, %r116;

$L__BB0_118:
	.pragma "nounroll";
	setp.eq.s32 	%p101, %r136, %r3;
	@%p101 bra 	$L__BB0_134;

	mul.wide.u32 	%rd33, %r136, 48;
	add.s64 	%rd34, %rd1, %rd33;
	add.s64 	%rd5, %rd34, 33;
	ld.global.u8 	%rs208, [%rd34+33];
	and.b16  	%rs209, %rs208, 1;
	setp.eq.b16 	%p102, %rs209, 1;
	mov.pred 	%p103, 0;
	xor.pred  	%p104, %p102, %p103;
	not.pred 	%p105, %p104;
	@%p105 bra 	$L__BB0_134;

	.pragma "used_bytes_mask 4095";
	ld.shared.v4.f32 	{%f884, %f885, %f886, %f887}, [%r138];
	ld.shared.f32 	%f297, [%r139];
	sub.ftz.f32 	%f298, %f381, %f884;
	sub.ftz.f32 	%f299, %f382, %f885;
	sub.ftz.f32 	%f300, %f383, %f886;
	mul.ftz.f32 	%f891, %f299, %f299;
	fma.rn.ftz.f32 	%f892, %f298, %f298, %f891;
	fma.rn.ftz.f32 	%f893, %f300, %f300, %f892;
	sqrt.approx.ftz.f32 	%f301, %f893;
	mov.f32 	%f894, 0f38D1B717;
	max.ftz.f32 	%f302, %f301, %f894;
	setp.geu.ftz.f32 	%p106, %f302, %f376;
	mov.f32 	%f1121, 0f00000000;
	@%p106 bra 	$L__BB0_123;

	mov.f32 	%f1026, 0f38D1B717;
	max.ftz.f32 	%f1025, %f301, %f1026;
	mul.ftz.f32 	%f895, %f7, %f297;
	sqrt.approx.ftz.f32 	%f896, %f895;
	mul.ftz.f32 	%f897, %f896, %f374;
	neg.ftz.f32 	%f898, %f897;
	mul.ftz.f32 	%f899, %f1025, %f1025;
	div.approx.ftz.f32 	%f900, %f898, %f899;
	mov.f32 	%f901, 0fC1200000;
	max.ftz.f32 	%f1121, %f900, %f901;
	or.b32  	%r118, %r137, %r3;
	setp.ne.s32 	%p107, %r118, 0;
	@%p107 bra 	$L__BB0_123;

	mov.f32 	%f1028, 0f38D1B717;
	max.ftz.f32 	%f1027, %f301, %f1028;
	cvt.ftz.f64.f32 	%fd6, %f1027;
	st.local.f64 	[%rd3], %fd6;
	st.local.f64 	[%rd3+8], %fd1;
	cvt.ftz.f64.f32 	%fd7, %f297;
	st.local.f64 	[%rd3+16], %fd7;
	cvt.ftz.f64.f32 	%fd8, %f1121;
	st.local.f64 	[%rd3+24], %fd8;
	mov.u64 	%rd35, $str;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd36;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd8;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r119, [retval0+0];
	} // callseq 2

$L__BB0_123:
	setp.eq.s16 	%p108, %rs2, 0;
	@%p108 bra 	$L__BB0_130;

	ld.global.u8 	%rs210, [%rd5];
	and.b16  	%rs211, %rs210, 2;
	setp.eq.s16 	%p109, %rs211, 0;
	@%p109 bra 	$L__BB0_130;

	mov.f32 	%f1024, 0f38D1B717;
	max.ftz.f32 	%f1023, %f301, %f1024;
	add.ftz.f32 	%f305, %f1023, 0fBF800000;
	abs.ftz.f32 	%f306, %f305;
	abs.ftz.f32 	%f307, %f306;
	setp.ltu.ftz.f32 	%p110, %f307, 0f3F19999A;
	@%p110 bra 	$L__BB0_127;
	bra.uni 	$L__BB0_126;

$L__BB0_127:
	mul.ftz.f32 	%f910, %f306, %f306;
	mov.f32 	%f911, 0fBD563CAE;
	mov.f32 	%f912, 0f3C80F082;
	fma.rn.ftz.f32 	%f913, %f912, %f910, %f911;
	mov.f32 	%f914, 0f3E085941;
	fma.rn.ftz.f32 	%f915, %f913, %f910, %f914;
	mov.f32 	%f916, 0fBEAAA9ED;
	fma.rn.ftz.f32 	%f917, %f915, %f910, %f916;
	mov.f32 	%f918, 0f00000000;
	fma.rn.ftz.f32 	%f919, %f917, %f910, %f918;
	fma.rn.ftz.f32 	%f1120, %f919, %f306, %f306;
	bra.uni 	$L__BB0_128;

$L__BB0_126:
	mul.ftz.f32 	%f902, %f307, 0f4038AA3B;
	ex2.approx.ftz.f32 	%f903, %f902;
	add.ftz.f32 	%f904, %f903, 0f3F800000;
	mov.f32 	%f905, 0f3F800000;
	rcp.approx.ftz.f32 	%f906, %f904;
	mov.f32 	%f907, 0fC0000000;
	fma.rn.ftz.f32 	%f908, %f906, %f907, %f905;
	setp.ge.ftz.f32 	%p111, %f307, 0f41102CB4;
	selp.f32 	%f909, 0f3F800000, %f908, %p111;
	mov.b32 	%r120, %f909;
	mov.b32 	%r121, %f306;
	and.b32  	%r122, %r121, -2147483648;
	or.b32  	%r123, %r122, %r120;
	mov.b32 	%f1120, %r123;

$L__BB0_128:
	mov.f32 	%f1031, 0f38D1B717;
	max.ftz.f32 	%f1030, %f301, %f1031;
	add.ftz.f32 	%f1029, %f1030, 0fBF800000;
	fma.rn.ftz.f32 	%f920, %f1120, 0f3F000000, 0f3F800000;
	mul.ftz.f32 	%f921, %f1029, %f373;
	mul.ftz.f32 	%f922, %f921, %f920;
	mov.f32 	%f923, 0f41200000;
	min.ftz.f32 	%f924, %f922, %f923;
	mov.f32 	%f925, 0fC1200000;
	max.ftz.f32 	%f311, %f924, %f925;
	add.ftz.f32 	%f1121, %f1121, %f311;
	or.b32  	%r124, %r137, %r3;
	setp.ne.s32 	%p112, %r124, 0;
	@%p112 bra 	$L__BB0_130;

	cvt.ftz.f64.f32 	%fd9, %f311;
	st.local.f64 	[%rd3], %fd9;
	mov.u64 	%rd38, $str$1;
	cvta.global.u64 	%rd39, %rd38;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd39;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd8;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r125, [retval0+0];
	} // callseq 3

$L__BB0_130:
	setp.lt.ftz.f32 	%p113, %f301, 0f358637BD;
	mov.f32 	%f1122, 0f00000000;
	mov.f32 	%f1123, %f1122;
	mov.f32 	%f1124, %f1122;
	@%p113 bra 	$L__BB0_132;

	rcp.approx.ftz.f32 	%f929, %f301;
	mul.ftz.f32 	%f1124, %f300, %f929;
	mul.ftz.f32 	%f1123, %f299, %f929;
	mul.ftz.f32 	%f1122, %f298, %f929;

$L__BB0_132:
	mov.f32 	%f930, 0f41700000;
	min.ftz.f32 	%f931, %f1121, %f930;
	mov.f32 	%f932, 0fC1700000;
	max.ftz.f32 	%f933, %f931, %f932;
	fma.rn.ftz.f32 	%f1053, %f933, %f1122, %f1053;
	fma.rn.ftz.f32 	%f1054, %f933, %f1123, %f1054;
	fma.rn.ftz.f32 	%f1055, %f933, %f1124, %f1055;
	mul.ftz.f32 	%f934, %f386, %f1123;
	fma.rn.ftz.f32 	%f935, %f385, %f1122, %f934;
	fma.rn.ftz.f32 	%f326, %f387, %f1124, %f935;
	setp.leu.ftz.f32 	%p114, %f326, 0f00000000;
	@%p114 bra 	$L__BB0_134;

	sqrt.approx.ftz.f32 	%f936, %f7;
	mul.ftz.f32 	%f937, %f326, %f936;
	mul.ftz.f32 	%f938, %f937, 0fBDCCCCCD;
	mov.f32 	%f939, 0fC0A00000;
	max.ftz.f32 	%f940, %f938, %f939;
	fma.rn.ftz.f32 	%f1053, %f1122, %f940, %f1053;
	fma.rn.ftz.f32 	%f1054, %f1123, %f940, %f1054;
	fma.rn.ftz.f32 	%f1055, %f1124, %f940, %f1055;

$L__BB0_134:
	add.s32 	%r137, %r137, 1;
	add.s32 	%r136, %r137, %r10;
	add.s32 	%r139, %r139, 4;
	add.s32 	%r138, %r138, 16;
	add.s32 	%r142, %r142, -1;
	setp.ne.s32 	%p115, %r142, 0;
	@%p115 bra 	$L__BB0_118;

$L__BB0_135:
	bar.sync 	0;
	add.s32 	%r132, %r132, 1;
	setp.lt.u32 	%p116, %r132, %r8;
	@%p116 bra 	$L__BB0_3;

$L__BB0_136:
	mul.ftz.f32 	%f941, %f1054, %f1054;
	fma.rn.ftz.f32 	%f942, %f1053, %f1053, %f941;
	fma.rn.ftz.f32 	%f943, %f1055, %f1055, %f942;
	sqrt.approx.ftz.f32 	%f339, %f943;
	setp.leu.ftz.f32 	%p117, %f339, 0f41A00000;
	@%p117 bra 	$L__BB0_138;

	mov.f32 	%f944, 0f41A00000;
	div.approx.ftz.f32 	%f945, %f944, %f339;
	mul.ftz.f32 	%f1053, %f1053, %f945;
	mul.ftz.f32 	%f1054, %f1054, %f945;
	mul.ftz.f32 	%f1055, %f1055, %f945;

$L__BB0_138:
	ld.param.f32 	%f964, [compute_forces_param_4];
	add.ftz.f32 	%f946, %f385, %f1053;
	mul.ftz.f32 	%f1143, %f946, %f964;
	add.ftz.f32 	%f947, %f386, %f1054;
	mul.ftz.f32 	%f1144, %f947, %f964;
	add.ftz.f32 	%f948, %f387, %f1055;
	mul.ftz.f32 	%f1145, %f948, %f964;
	setp.ne.s32 	%p118, %r3, 0;
	@%p118 bra 	$L__BB0_140;

	cvt.ftz.f64.f32 	%fd10, %f339;
	st.local.f64 	[%rd3], %fd10;
	cvt.ftz.f64.f32 	%fd11, %f1053;
	st.local.f64 	[%rd3+8], %fd11;
	cvt.ftz.f64.f32 	%fd12, %f1054;
	st.local.f64 	[%rd3+16], %fd12;
	cvt.ftz.f64.f32 	%fd13, %f1055;
	st.local.f64 	[%rd3+24], %fd13;
	cvt.ftz.f64.f32 	%fd14, %f1143;
	st.local.f64 	[%rd3+32], %fd14;
	cvt.ftz.f64.f32 	%fd15, %f1144;
	st.local.f64 	[%rd3+40], %fd15;
	cvt.ftz.f64.f32 	%fd16, %f1145;
	st.local.f64 	[%rd3+48], %fd16;
	mov.u64 	%rd41, $str$2;
	cvta.global.u64 	%rd42, %rd41;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd42;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd8;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r126, [retval0+0];
	} // callseq 4

$L__BB0_140:
	add.ftz.f32 	%f949, %f7, 0f3F000000;
	mov.f32 	%f950, 0f40000000;
	div.approx.ftz.f32 	%f349, %f950, %f949;
	mul.ftz.f32 	%f951, %f1144, %f1144;
	fma.rn.ftz.f32 	%f952, %f1143, %f1143, %f951;
	fma.rn.ftz.f32 	%f953, %f1145, %f1145, %f952;
	sqrt.approx.ftz.f32 	%f350, %f953;
	setp.leu.ftz.f32 	%p119, %f350, %f349;
	@%p119 bra 	$L__BB0_142;

	div.approx.ftz.f32 	%f954, %f349, %f350;
	mul.ftz.f32 	%f1143, %f1143, %f954;
	mul.ftz.f32 	%f1144, %f1144, %f954;
	mul.ftz.f32 	%f1145, %f1145, %f954;

$L__BB0_142:
	ld.param.f32 	%f965, [compute_forces_param_6];
	add.ftz.f32 	%f1142, %f381, %f1143;
	add.ftz.f32 	%f1141, %f382, %f1144;
	add.ftz.f32 	%f1140, %f383, %f1145;
	setp.leu.ftz.f32 	%p120, %f965, 0f00000000;
	@%p120 bra 	$L__BB0_147;

	ld.param.f32 	%f966, [compute_forces_param_6];
	min.ftz.f32 	%f955, %f1142, %f966;
	neg.ftz.f32 	%f956, %f966;
	max.ftz.f32 	%f1142, %f955, %f956;
	min.ftz.f32 	%f957, %f1141, %f966;
	max.ftz.f32 	%f1141, %f957, %f956;
	min.ftz.f32 	%f958, %f1140, %f966;
	max.ftz.f32 	%f1140, %f958, %f956;
	abs.ftz.f32 	%f959, %f1142;
	mul.ftz.f32 	%f363, %f966, 0f3F666666;
	setp.gt.ftz.f32 	%p121, %f959, %f363;
	@%p121 bra 	$L__BB0_146;

	abs.ftz.f32 	%f960, %f1141;
	setp.gt.ftz.f32 	%p122, %f960, %f363;
	@%p122 bra 	$L__BB0_146;

	abs.ftz.f32 	%f961, %f1140;
	setp.leu.ftz.f32 	%p123, %f961, %f363;
	@%p123 bra 	$L__BB0_147;

$L__BB0_146:
	mul.ftz.f32 	%f1143, %f1143, 0f3F666666;
	mul.ftz.f32 	%f1144, %f1144, 0f3F666666;
	mul.ftz.f32 	%f1145, %f1145, 0f3F666666;

$L__BB0_147:
	mul.wide.s32 	%rd45, %r3, 48;
	add.s64 	%rd44, %rd1, %rd45;
	st.global.v2.f32 	[%rd44], {%f1142, %f1141};
	st.global.f32 	[%rd44+8], %f1140;
	st.global.v2.f32 	[%rd44+16], {%f1143, %f1144};
	st.global.f32 	[%rd44+24], %f1145;

$L__BB0_148:
	ret;

}

