{
  "version": "1.0.0",
  "mode": "performance",
  "description": "Intelligent model router for Agentic Flow workstation",

  "providers": {
    "gemini": {
      "enabled": true,
      "baseUrl": "https://generativelanguage.googleapis.com/v1beta",
      "apiKey": "${GOOGLE_GEMINI_API_KEY}",
      "models": {
        "default": "gemini-2.5-flash",
        "pro": "gemini-2.5-pro",
        "exp": "gemini-2.0-flash-exp"
      },
      "metrics": {
        "speed": 95,
        "quality": 85,
        "cost": 98,
        "reliability": 92
      },
      "features": {
        "streaming": true,
        "toolCalling": true,
        "contextWindow": 1000000,
        "maxTokens": 8192
      },
      "priority": 1,
      "description": "Google Gemini - Fast, cost-effective, 1M token context"
    },

    "openai": {
      "enabled": true,
      "baseUrl": "https://api.openai.com/v1",
      "apiKey": "${OPENAI_API_KEY}",
      "models": {
        "default": "gpt-4o",
        "mini": "gpt-4o-mini",
        "legacy": "gpt-4-turbo"
      },
      "metrics": {
        "speed": 85,
        "quality": 90,
        "cost": 70,
        "reliability": 95
      },
      "features": {
        "streaming": true,
        "toolCalling": true,
        "contextWindow": 128000,
        "maxTokens": 4096
      },
      "priority": 2,
      "description": "OpenAI GPT-4o - Excellent quality, strong reasoning"
    },

    "anthropic": {
      "enabled": true,
      "baseUrl": "https://api.anthropic.com/v1",
      "apiKey": "${ANTHROPIC_API_KEY}",
      "models": {
        "default": "claude-3-5-sonnet-20241022",
        "haiku": "claude-3-5-haiku-20241022",
        "opus": "claude-3-opus-20240229"
      },
      "metrics": {
        "speed": 80,
        "quality": 95,
        "cost": 40,
        "reliability": 98
      },
      "features": {
        "streaming": true,
        "toolCalling": true,
        "contextWindow": 200000,
        "maxTokens": 8192
      },
      "priority": 3,
      "useFor": [
        "code-review",
        "architecture",
        "complex-reasoning",
        "refactoring",
        "security-analysis"
      ],
      "description": "Anthropic Claude - Highest quality, best for complex tasks"
    },

    "openrouter": {
      "enabled": true,
      "baseUrl": "https://openrouter.ai/api/v1",
      "apiKey": "${OPENROUTER_API_KEY}",
      "models": {
        "default": "meta-llama/llama-3.1-8b-instruct",
        "code": "deepseek/deepseek-coder-v2",
        "chat": "deepseek/deepseek-chat",
        "reasoning": "deepseek/deepseek-r1",
        "claude": "anthropic/claude-3.5-sonnet"
      },
      "metrics": {
        "speed": 75,
        "quality": 75,
        "cost": 99,
        "reliability": 88
      },
      "features": {
        "streaming": true,
        "toolCalling": true,
        "contextWindow": 128000,
        "maxTokens": 4096
      },
      "priority": 4,
      "description": "OpenRouter - 99% cost savings, 100+ models"
    },

    "xinference": {
      "enabled": true,
      "baseUrl": "http://172.18.0.11:9997/v1",
      "apiKey": "none",
      "models": {
        "default": "auto",
        "code": "deepseek-coder",
        "chat": "qwen2.5"
      },
      "metrics": {
        "speed": 70,
        "quality": 75,
        "cost": 100,
        "reliability": 85
      },
      "features": {
        "streaming": true,
        "toolCalling": true,
        "contextWindow": 32768,
        "maxTokens": 2048,
        "localInference": true,
        "networkRequired": true
      },
      "priority": 5,
      "description": "Xinference - FREE local inference via RAGFlow network"
    },

    "onnx": {
      "enabled": true,
      "modelPath": "/home/devuser/models/phi-4.onnx",
      "executionProviders": ["cuda", "cpu"],
      "models": {
        "default": "phi-4-mini-instruct"
      },
      "metrics": {
        "speed": 60,
        "quality": 70,
        "cost": 100,
        "reliability": 90
      },
      "features": {
        "streaming": false,
        "toolCalling": false,
        "contextWindow": 4096,
        "maxTokens": 2048,
        "localInference": true,
        "offline": true,
        "gpuAccelerated": true
      },
      "priority": 6,
      "description": "ONNX Phi-4 - FREE offline GPU-accelerated inference"
    }
  },

  "routing": {
    "modes": {
      "performance": {
        "description": "Optimize for speed and quality",
        "weights": {
          "speed": 0.5,
          "quality": 0.4,
          "cost": 0.1
        },
        "defaultChain": ["gemini", "openai", "claude"],
        "fallbackChain": ["gemini", "openai", "claude", "openrouter", "xinference", "onnx"]
      },

      "cost": {
        "description": "Optimize for lowest cost",
        "weights": {
          "speed": 0.2,
          "quality": 0.3,
          "cost": 0.5
        },
        "defaultChain": ["xinference", "openrouter", "gemini"],
        "fallbackChain": ["xinference", "onnx", "openrouter", "gemini", "openai"]
      },

      "quality": {
        "description": "Optimize for highest quality",
        "weights": {
          "speed": 0.1,
          "quality": 0.7,
          "cost": 0.2
        },
        "defaultChain": ["claude", "openai", "gemini"],
        "fallbackChain": ["claude", "openai", "gemini", "openrouter"]
      },

      "balanced": {
        "description": "Balance all factors equally",
        "weights": {
          "speed": 0.33,
          "quality": 0.34,
          "cost": 0.33
        },
        "defaultChain": ["gemini", "openai", "openrouter"],
        "fallbackChain": ["gemini", "openai", "openrouter", "claude", "xinference"]
      },

      "offline": {
        "description": "Use only local inference (no internet)",
        "weights": {
          "speed": 0.5,
          "quality": 0.5,
          "cost": 0.0
        },
        "defaultChain": ["xinference", "onnx"],
        "fallbackChain": ["xinference", "onnx"]
      }
    },

    "rules": [
      {
        "condition": {
          "privacy": "high",
          "localOnly": true
        },
        "action": {
          "provider": "onnx"
        },
        "reason": "Privacy-sensitive tasks use offline ONNX local inference"
      },
      {
        "condition": {
          "task": "code-review",
          "quality": "required"
        },
        "action": {
          "provider": "claude"
        },
        "reason": "Code reviews need highest quality reasoning"
      },
      {
        "condition": {
          "task": "code-generation",
          "cost": "free"
        },
        "action": {
          "provider": "xinference",
          "model": "deepseek-coder"
        },
        "reason": "Code generation works well with free Xinference DeepSeek"
      },
      {
        "condition": {
          "task": "simple",
          "cost": "minimal"
        },
        "action": {
          "provider": "openrouter",
          "model": "meta-llama/llama-3.1-8b-instruct"
        },
        "reason": "Simple tasks use cheapest OpenRouter option"
      },
      {
        "condition": {
          "speed": "critical",
          "latency": "low"
        },
        "action": {
          "provider": "gemini",
          "model": "gemini-2.5-flash"
        },
        "reason": "Speed-critical tasks use fastest Gemini Flash"
      }
    ],

    "agentPreferences": {
      "coder": {
        "preferredProviders": ["claude", "openai", "gemini"],
        "minQuality": 85,
        "description": "Code generation needs high quality"
      },
      "reviewer": {
        "preferredProviders": ["claude", "openai"],
        "minQuality": 90,
        "description": "Code review requires highest quality reasoning"
      },
      "researcher": {
        "preferredProviders": ["gemini", "openai", "openrouter"],
        "minQuality": 70,
        "description": "Research can use cost-effective models"
      },
      "tester": {
        "preferredProviders": ["openrouter", "gemini", "xinference"],
        "minQuality": 70,
        "description": "Test generation works with budget models"
      },
      "planner": {
        "preferredProviders": ["claude", "openai", "gemini"],
        "minQuality": 85,
        "description": "Planning requires strong reasoning"
      }
    }
  },

  "costTracking": {
    "enabled": true,
    "budgetLimits": {
      "daily": 10.0,
      "weekly": 50.0,
      "monthly": 200.0
    },
    "alerts": {
      "thresholds": [0.5, 0.8, 0.95],
      "notificationMethod": "log"
    }
  },

  "performanceMonitoring": {
    "enabled": true,
    "metrics": [
      "latency",
      "tokens_per_second",
      "cost_per_request",
      "success_rate",
      "error_rate"
    ],
    "loggingLevel": "info"
  },

  "fallbackBehavior": {
    "maxRetries": 3,
    "retryDelay": 1000,
    "circuitBreaker": {
      "enabled": true,
      "failureThreshold": 5,
      "timeout": 60000
    }
  }
}
