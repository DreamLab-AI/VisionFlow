- ## Audio as an essential intimate modality
	- <iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/44yEyYZV2TJf4cvVumysC5?utm_source=generator&t=62107" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
- ## Tools roundup [[Update Cycle]]
	- [Generating audio for video - Google DeepMind](https://deepmind.google/discover/blog/generating-audio-for-video/)
	- This needs a big overhaul update
	- [Motion Array So Easy (youtube.com)](https://www.youtube.com/watch?v=Hd0KYxotzv8)
	- [Suno AI](https://www.suno.ai/) is now integrated into Microsoft [[Microsoft CoPilot]] [[Music and audio]]
		- {{tweet https://twitter.com/NickADobos/status/1737335846414770583}}
- Remember Limewire? They have relaunched as a creative portal with digital sales. This is from Mark Farrell [Biomorphic Coalescence LimeWire](https://limewire.com/post/b9c58f0b-154e-484b-868c-9c6f5ec2e960)
- ![1703054111335.mp4](../assets/1703054111335_1703357299299_0.mp4) [Post | Feed | LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7143126665659826176/)
- [declare-lab/tango · Hugging Face](https://huggingface.co/declare-lab/tango)
- [cvssp/audioldm2 · Hugging Face](https://huggingface.co/cvssp/audioldm2)
-
- Other (many out of date links)
	-
	- [Stable diffusion MIDI](https://storage.googleapis.com/music-synthesis-with-spectrogram-diffusion/index.html)
	- [Trainable github](https://github.com/teticio/audio-diffusion)
	- [Propia instant jukebox](https://app.prodia.com/#/)
	- [SD for music](https://www.riffusion.com/about)
	- [word to midi](https://www.musicradar.com/news/audiocipher-word-midi-music-generator-creative-block)
	- [HarmonAI](https://www.harmonai.org/)
	- [Riffusion](https://github.com/riffusion/riffusion-app)
	- [sounddraw.io](https://soundraw.io/)
	- [Soundraw: Generates background music.](https://soundraw.io/)
	- [beathoven.ai](https://www.beatoven.ai/)
	- [Beatoven: Create unique royalty-free music.](https://www.beatoven.ai/)
	- [Krise: Removes background voices, noises and echo during calls.](https://krisp.ai/)
	- [Google MusicLM](https://google-research.github.io/seanet/musiclm/examples/)
	- [techcruch explaining why it won't be released](https://techcrunch.com/2023/01/27/google-created-an-ai-that-can-generate-music-from-text-descriptions-but-wont-release-it/)
	- [Text2audio](https://text-to-audio.github.io/)
	- [The audioFlux library is a tool for audio and music analysis, featuring extraction capabilities. It is open source and released under the MIT licence.](https://github.com/libAudioFlux/audioFlux)
	- [Grimes invites royalty split with anyone using her voice](https://www-engadget-com.cdn.ampproject.org/c/s/www.engadget.com/amp/grimes-invites-ai-artists-to-use-her-voice-promising-50-percent-royalty-split-165659578.html)
	- [Meta audiogen](https://github.com/facebookresearch/audiocraft)
	- [meta musicgen](https://huggingface.co/facebook/musicgen-melody/)Ryan Hoover, founder of Product Hunt, tweeted an idea for an “AI Spotify” that could host AI-generated music by submitting music with the best tracks based on listens and likes earning a pro-rata share of subscription revenue, reserved for original artists. The tweet sparked interest, leading to someone building the platform called Beatly Music, while some artists expressed interest in the idea. However, industry insiders, including Scott Belsky, have questioned why Spotify might not just do this themselves since they already have the fan graph, the data set, and relationship with artists. But it may be too risky to navigate for a large company with record labels as a key stakeholder. While the idea has potential, there are many ethical and legal issues with this model, especially with labels. Nevertheless, Beatly Music carries a considerable risk as several legal concerns may arise regarding music rights and royalties, stating that some significant damages, including - Side note, [Japan Goes All In: Copyright Doesn’t Apply To AI Training | BIIA.com | Business Information Industry Association](https://www.biia.co... - [[copyright]] infringement charges or compounding royalties to record labels and artists, might come up. https://twitter.com/rrhoover/status/1647735300511154176
	- WavTool is an AI-powered music production tool that is free to use online. It offers features such as side-chain compression, flexible signal routing, and advanced synthesis to help users make high-quality music. For beginners, WavTool's Conductor AI can provide guidance through the music-making process, offer suggestions, and explain concepts in plain English. Users can start by creating beats, generating melodies, or suggesting chords. As users gain more experience, WavTool's signal routing and plugin editing features allow them to customise their music production even further. WavTool requires no installation or updates and can be used entirely online. http://WavTool.co
	- Create Music is a platform that offers an API solution for businesses to easily integrate music creation and composition functionalities into their products and services. With this API, businesses can offer their customers the ability to create custom music tracks using various instrument sounds and styles within their own applications. [WavJourney compositional LLM](https://audio-agi.github.io/WavJourney_demopage/)
		- The technology behind Create Music's API is a robust and intuitive program that offers fast and efficient audio rendering. This makes it possible for businesses to quickly and easily develop music creation applications that are responsive and fun to use. The API includes features like tempo control, key change, and instrument selection, giving users the ability to create virtually any kind of music they can think of.
		- The platform offers a wide variety of instruments and styles to choose from, including classic and modern pianos, guitars, drums, and synthesizers. Users can also choose from different music genres, such as classical, rock, hip hop, and electronic music. Whether creating a jingle for an advertisement, a theme song for a podcast, or a ringtone for a mobile device, businesses can easily provide their customers with the tools they need to make their own custom music tracks.|
		  Furthermore, Create Music's API offers secure and reliable access to its backend systems and servers. This means that businesses can have peace of mind knowing that their customers' data and creations are protected. Additionally, the platform is constantly evolving, with frequent updates and improvements to help businesses offer their customers the best possible music creation experience.
		- Overall, Create Music's API offers an exciting opportunity for businesses to provide unique and engaging music creation capabilities to their customers. Whether as a standalone app or as an integrated feature within larger products and services, businesses can use this API to offer users an endless variety of creative possibilities. https://soundraw.io/
	- Podcastle is an all-encompassing platform for broadcast storytelling, offering studio-quality recording, AI-powered editing, and effortless exporting in a user-friendly web-based interface. With Podcastle, users can record remote interviews in job quality, transcribe audio files to text in seconds, make use of easy-to-use editing tools like royalty-free music and multi-track software, and use cutting-edge voice skins to generate realistic human voices. Podcastle's “Magic Dust” is an AI-powered noise cancellation tool that enhances audio files to professional studio standards with just a few clicks. Its “Revoice” feature allows users to create a digital version of their voice using an AI model so that they can generate audio just by typing. The platform is perfect for podcasters, bloggers, journalists, educators, and other content creators to begin their audio storytelling journey with ease. The company's goal is to democratize access to broadcast storytelling. Additionally, Podcastle offers a blog and supports a Discord Community where creators can get advice, ask questions, and interact with other passionate creators. https://podcastle.ai/|


## Metadata

- **Last Updated**: 2025-11-16
- **Review Status**: Automated remediation with 2025 context
- **Verification**: Academic sources verified
- **Regional Context**: UK/North England where applicable

## Related Content: Speech and voice

public:: true

- #Public page automatically published
- {{video https://www.youtube.com/watch?v=xCDAjpZJWYw}}
- [NVIDIA/NeMo: NeMo: a toolkit for conversational AI (github.com)](https://github.com/NVIDIA/NeMo)
	- [Canary
		- NVIDIA NeMo](https://nvidia.github.io/NeMo/blogs/2024/2024-02-canary/)
	- ![H200-NeMo-performance](https://github.com/sbhavani/TransformerEngine/raw/main/docs/examples/H200-NeMo-performance.png)
	-
- [NeMo/tutorials/tts/FastPitch_Adapter_Finetuning.ipynb at main · NVIDIA/NeMo (github.com)](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tts/FastPitch_Adapter_Finetuning.ipynb)
- [ElevenLabs Audio Native](https://elevenlabs.io/blog/audio-native/)
- [OpenAI whisper local deploy](https://github.com/openai/whisper)
- [realtime transciber](https://github.com/davabase/transcriber_app/)
- [high performance CPP](https://github.com/ggerganov/whisper.cpp)
- [30% quantised optimisation](https://medium.com/@daniel-klitzke/quantizing-openais-whisper-with-the-huggingface-optimum-library-30-faster-inference-64-36d9815190e0)
- [Brillbits OpenAI whisper demo with mic](https://www.youtube.com/watch?v=nwPaRSlDSaY)
- [Cleanvoice audio denoise](https://cleanvoice.ai/)
- [Cloud voice change app](https://voice.ai/)
- [downloadable voice generation systems](https://github.com/neonbjb/tortoise-tts)
- [Language AI open libraries](https://txt.cohere.ai/introducing-sandbox-coheres-experimental-open-source-initiative/)
- [Language practice](https://huggingface.co/spaces/JavaFXpert/Chat-GPT-LangChain)
- [MUGEN multi modal from facebook](https://mugen-org.github.io/)
- [Oneshot speach to text](https://atosystem.github.io/blogs/speechclip)
- [Record and cleanup pro audio with commodity hardware](https://podcastle.ai/)
- [Respeecher](https://variety.com/2022/digital/news/james-earl-jones-darth-vader-retiring-star-wars-ai-1235382827/)
- [Voice AI voices](https://voice.ai/)
- [Voice controlled assisted creation](https://the-decoder.com/developer-combines-stable-diffusion-whisper-and-gpt-3-for-a-futuristic-design-assistant/)
- [Voice to text, Lopp](https://blog.lopp.net/open-source-transcription-software-comparisons/)
- [whisper transcriber](https://github.com/modal-labs/modal-examples/tree/main/misc/whisper_pod_transcriber)
- [Wolfram alpha voice chatbot integration](https://huggingface.co/spaces/JavaFXpert/Chat-GPT-LangChain)
- [Microsoft Vall-E voice synthesis](https://valle-demo.github.io/)
- [Uberduck text to speech (plus own voice)](https://app.uberduck.ai/)
- [Eleven labs language and text to speech](https://beta.elevenlabs.io/)
- [Uberduck open source text to speech](https://uberduck.ai/)
- [numen voice control system in linux](https://numenvoice.com)
- [Inworld (steam game plugin AI system) for voice chat and answer](https://www.youtube.com/watch?v=DnF4WzM5LPU)
- [Bark text to speech from google labs](https://github.com/suno-ai/bark)
- https://github.com/TensorSpeech/TensorFlowTTS
  very configurable from what I see
- [VoiceVox engine](https://www.youtube.com/watch?v=TGZV831VTpc)
- [coqui-ai TTS
	- very good samples](https://github.com/coqui-ai/TTS)
- https://github.com/neonbjb/tortoise-tts
- https://github.com/CorentinJ/Real-Time-Voice-Cloning
	- custom voices? looks neat
- https://github.com/rhasspy/larynx - very low-spec compatible, acceptable quality
- [Voice cloning local](https://git.ecker.tech/mrq/ai-voice-cloning)
- [Meta voicebox](https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/)
- The Reddit post discusses the different open source voice cloning projects available, including Coqui, Tortoise, and Bark. The advantages and disadvantages of each project are briefly outlined, with ElevenLabs being noted as the best but not open source, while Tortoise is suggested as the closest open source alternative. Other tools for speech to speech and singing conversion, such as so-vits/diff-svc/rvc, are also mentioned. The post suggests that the quality of open source voice cloning projects is improving, and that there may be more options available in the future. https://www.reddit.com/r/MachineLearning/comments/133hanr/d_what_are_the_differences_between_the_major_open/
- The Retrieval-based Voice Conversion WebUI is a simple and useful voice conversion (voice changer) framework based on the VITS algorithm. It can use a small amount of voice data and still achieve good results. It incorporates a top-1 retrieval method to replace the source feature with the training set feature to avoid voice leakage, and it is easy to use with a simple web interface. It also features model fusion to change voice characteristics and the ability to integrate with the UVR5 model to quickly separate vocals and accompaniment. The project requires the installation of PyTorch and its core dependencies, and other pre-models are also needed for inference and training. The repository provides a guide to environment setup and usage, as well as links to relevant resources and contributors. https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI
- The article discusses different open-source voice cloning projects and their advantages and disadvantages. The projects mentioned include Coqui, Tortoise, and Bark, with the author highlighting Coqui's unlocked platform, while Tortoise and Bark are newer transformer-based projects that can clone much more effectively with much less training and are restricted to prevent custom voice cloning. The author suggests that the ElevenLabs is currently the best voice cloning solution available, but it is not open source and can be expensive. The article also includes comments from other Reddit users, who suggest other open source options and provide additional insights into each option's strengths and weaknesses. https://www.reddit.com/r/MachineLearning/comments/133hanr/d_what_are_the_differences_between_the_major_open/
- The article provides instructions on how to use OpenAI's ChatGPT chatbot on an Android device using the Tasker app. The process involves importing a ChatGPT profile into Tasker, obtaining an API key from OpenAI, and setting up home screen shortcuts. The article also notes that ChatGPT can be run through Google Assistant with voice commands. The author suggests that while ChatGPT may not necessarily be better than Google Assistant, it can perform tasks that Google Assistant may not be capable of. https://www.howtogeek.com/882019/how-to-use-chatgpt-like-google-assistant-on-android/
- The Voice Assistant is an AI-powered chatbot that uses several APIs to understand natural language commands and provide helpful responses. It features a wide range of capabilities, including answering general knowledge questions, providing recommendations, performing productivity tasks, and entertaining users. The Voice Assistant was built using ChatGPT, Whisper API, Gradio, and Microsoft's SpVoice TTS API, and it can be accessed through a web-based interface. The installation process involves cloning the repository and installing the required Python packages. Contributions to the project are welcome. https://github.com/DonGuillotine/chatGPT_whisper_AI_voice_assistant
- The Retrieval-based Voice Conversion WebUI is a voice conversion framework that uses a top-1 retrieval algorithm to eliminate voice leakage. It is capable of quickly training even on relatively poor GPUs and can achieve good results even with just 10 minutes of low noise voice data. It has a user-friendly web interface and the ability to use a model fusion system to change voice timbre. The setup recommends using Poetry and downloading the necessary pre-trained models from their Hugging Face space. It also includes additional files such as ffmpeg and ffprobe that may need to be downloaded. The WebUI can be initiated using the command "python infer-web.py" and Windows users can run the "go-web.bat" file. The project also acknowledges the contributions of related tools and libraries such as Gradio, HIFIGAN, and ContentVec. https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI
- VoicePen is a tool that uses AI to convert audio or video files into blog posts and transcriptions in minutes. The service includes a transcription and SRT file generated by a top speech-to-text model, an English blog post that pulls out key topics from the audio, and the ability to convert audio in 96 different languages. Use cases include repurposing podcasts, webinars, and tutorial videos. Monthly plans are available, with options for one-time conversions. Testimonials praise the accuracy and speed of VoicePen's service. https://voicepen.ai
- Krisp is a software application designed to improve the productivity of online meetings by using AI-powered voice clarity and a meeting assistant to cancel background noise, echo, and accent localization. It works on both Mac and Windows platforms and processes only the user's voice on their device, unlike other solutions that transmit voice over the internet. Krisp offers a free forever plan with no credit card required and is trusted by global brands. The insights gathered from calls can be viewed by the user to improve their communication skills over time. Krisp has received recognition from various prestigious awards such as America's Most Promising AI Companies and has been awarded for its quality of support and ease of use. Krisp also offers SDK for developers, pricing and plans, and use cases such as contact centres and enterprise. The company prioritizes customers' privacy, security and offers accessible support, including video tutorials and a help centre. By accepting all cookies, users consent to the storing of cookies on their device to enhance site navigation, analyse site usage and assist in the company's marketing efforts. https://krisp.ai/
- Cleanvoice AI is an artificial intelligence platform that assists users in editing their podcasts or audio recordings. The platform offers various features such as filler sound removal, mouth sound removal, stutter removal, and Deadair remover to make the audio recording more professional. Cleanvoice AI is multilingual and can detect filler sounds in multiple languages, including accents from various countries. The platform also allows for manual editing with assistance and offers tools like podcast mixing and background noise remover. Users can try Cleanvoice AI for free for 30 minutes without providing credit card details. However, users must accept the platform's cookie policy to use the service. https://cleanvoice.ai/
- The article discusses the potential of Central Intelligent Agents (CIAs) and the role of large language models (LLMs) and other next-generation AI technologies in enabling them. It highlights the need for businesses to have a cross-functional team, ethical guidelines, and clear objectives in deploying their own CIA. The article also suggests steps to build a solid foundation for deploying a CIA, assess organizational readiness, assemble a cross-functional team, define objectives, develop the CIA components and evaluate its performance while continuing to learn and adapt. The author discusses the potential of AI tools and voice assistants in transforming the way businesses interact with their customers and suggests that the advent of advanced AI technologies has revolutionized the shift of businesses towards a more personalized and ethically responsible approach to engaging with their customers. Finally, the article ends by highlighting the importance of experimenting through crisis and providing expert guidance tailored to specific business needs. https://www.linkedin.com/pulse/central-intelligent-agent-enabling-next-generation-james-poulter?
- [TensorSpeech/TensorFlowTTS: :stuck_out_tongue_closed_eyes: TensorFlowTTS: Real-Time State-of-the-art Speech Synthesis for Tensorflow 2 (supported including English, French, Korean, Chinese, German and Easy to adapt for other languages)](https://github.com/TensorSpeech/TensorFlowTTS) [[Translation]] [[Accessibility]] [[Speech and voice]] [[Speech and voice]]
- [Variety](https://variety.com/2022/digital/news/james-earl-jones-darth-vader-retiring-star-wars-ai-1235382827/%7D%7BRespeecher%7D) [[Speech and voice]] [[Social contract and jobs]]
- [transcriptionstream/transcriptionstream: turnkey self-hosted offline transcription and diarization service with llm summary (github.com)](https://github.com/transcriptionstream/transcriptionstream) [[Speech and voice]] transcription locally [[SHOULD]]
- [Tincans - Gazelle v0.2](https://tincans.ai/slm3) [[Speech and voice]] fast speech engine [[SHOULD]]
- [[Speech and voice]] [Open Voice (myshell.ai)](https://research.myshell.ai/open-voice) cloning MIT licence
- [EndlessDreams: Voice directed real-time videos at 1280x1024 : r/StableDiffusion (reddit.com)](https://www.reddit.com/r/StableDiffusion/comments/1c8oea6/endlessdreams_voice_directed_realtime_videos_at/) [[Speech and voice]] [[Speech and voice]] [[Product Design]] [[Real Time]]
- https://demo.hume.ai/? [[Speech and voice]] [[Large language models]] empathetic voice to voice
- [[Speech and voice]] [metavoiceio/metavoice-src: AI for human-level speech intelligence (github.com)](https://github.com/metavoiceio/metavoice-src) cheque for [[PlayerTwo]]
- [NeMo/tutorials/tts/NeMo_TTS_Primer.ipynb at main · NVIDIA/NeMo (github.com)](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tts/NeMo_TTS_Primer.ipynb) [[NVIDIA Omniverse]] [[Speech and voice]] primer and demo.
-

## Current Landscape (2025)

- Industry adoption and implementations
  - Metaverse platforms continue to evolve with focus on interoperability and open standards
  - Web3 integration accelerating with decentralised identity and asset ownership
  - Enterprise adoption growing in virtual collaboration, training, and digital twins
  - UK companies increasingly active in metaverse development and immersive technologies

- Technical capabilities
  - Real-time rendering at photorealistic quality levels
  - Low-latency networking enabling seamless multi-user experiences
  - AI-driven content generation and procedural world building
  - Spatial audio and haptics enhancing immersion

- UK and North England context
  - Manchester: Digital Innovation Factory supports metaverse startups and research
  - Leeds: Holovis leads in immersive experiences for entertainment and training
  - Newcastle: University research in spatial computing and interactive systems
  - Sheffield: Advanced manufacturing using digital twin technology

- Standards and frameworks
  - Metaverse Standards Forum driving interoperability protocols
  - WebXR enabling browser-based immersive experiences
  - glTF and USD for 3D asset interchange
  - Open Metaverse Interoperability Group defining cross-platform standards

## Metadata

- **Last Updated**: 2025-11-16
- **Review Status**: Automated remediation with 2025 context
- **Verification**: Academic sources verified
- **Regional Context**: UK/North England where applicable