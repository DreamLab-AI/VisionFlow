- ## Mission Statement
	- To address the negative impacts of toxic online behaviour by developing a multi-agent system that can identify and counter harmful content.
- ## Problem Space
	- The internet is increasingly populated by bots and trolls that spread misinformation and engage in harassment. This has a negative impact on online discourse and can lead to real-world harm.
- ## Proposed Solution
	- We propose to build a multi-agent system that can:
		- **Identify harmful content:** Use natural language processing (NLP) to identify toxic language, hate speech, and misinformation.
		- **Counter harmful content:** Generate counter-narratives and engage with users in a positive and constructive way.
		- **Promote healthy online communities:** Encourage positive online behaviour and create a more welcoming and inclusive online environment.
- ## Tech Stack
	- **Large Language Models:** Llama 3 70B, Mixtral 8B
	- **Fine-tuning:** Fine-tune a smaller model on a corpus of Reddit data to identify and classify harmful content.
	- **Agent Framework:** Use the Agentic Alliance tech stack to build and deploy the multi-agent system.
	- **Data Sources:** Reddit API (if available), other social media platforms.
- ## Challenges
	- **Data availability:** Access to social media data is becoming increasingly restricted.
	- **Defining "harmful content":** What constitutes harmful content is subjective and can vary depending on the context.
	- **Ethical considerations:** It is important to ensure that the multi-agent system is used in a responsible and ethical way.
- ## See Also
	- [[Digital Society Harms]]
	- [[Death of the Internet]]
	- [[Agents]]
	- [[Agentic Alliance]]


## Metadata

- **Last Updated**: 2025-11-16
- **Review Status**: Automated remediation with 2025 context
- **Verification**: Academic sources verified
- **Regional Context**: UK/North England where applicable