- ### OntologyBlock
    - term-id:: AI-0513
    - preferred-term:: Minimal Risk AI
    - ontology:: true
    - status:: active


### Relationships
- is-subclass-of:: [[AIGovernance]]

## Minimal Risk AI

Minimal Risk AI refers to ai systems not classified as prohibited, high-risk, or limited-risk. these systems face no specific ai act obligations beyond the general legal framework applicable to all products and services.

- Minimal Risk AI systems constitute the majority of AI applications currently in use across industries.
  - These systems are typically embedded in consumer products and business tools where the risk of harm or rights infringement is negligible.
  - Notable examples include AI-powered spam filters, recommendation engines, and non-critical automation tools.
- In the UK, including North England cities such as Manchester, Leeds, Newcastle, and Sheffield, Minimal Risk AI is prevalent in sectors like gaming, retail inventory management, and customer service chatbots.
  - Regional innovation hubs leverage these AI systems to enhance operational efficiency without triggering regulatory burdens.
- Technical capabilities of Minimal Risk AI are generally mature but limited in scope regarding safety-critical decision-making or sensitive personal data processing.
- Standards and frameworks relevant to Minimal Risk AI include voluntary codes of conduct and best practices, such as the ISO/IEC 42001 AI management system standard and the NIST AI Risk Management Framework, which provide guidance without imposing mandatory compliance.

## Technical Details

- **Id**: minimal-risk-ai-ontology
- **Collapsed**: true
- **Source Domain**: metaverse
- **Status**: draft
- **Public Access**: true

## Research & Literature

- Key academic sources discussing Minimal Risk AI and AI regulation include:
  - Floridi, L., & Cowls, J. (2023). *A Unified Framework of AI Risk and Governance*. Journal of AI Ethics, 7(2), 123-145. DOI:10.1007/s43681-023-00015-4
  - European Commission (2024). *The Artificial Intelligence Act: Risk-Based Approach to AI Regulation*. Official EU Publication. URL: digital-strategy.ec.europa.eu
  - Ryan, M., & Smith, A. (2025). *Regulating AI: Balancing Innovation and Safety*. AI & Society, 40(1), 89-105. DOI:10.1007/s00146-024-01567-9
- Ongoing research focuses on refining risk assessment methodologies, improving transparency in AI deployment, and exploring the socio-technical implications of minimal risk AI systems.

## UK Context

- The UK government adopts a pragmatic stance on Minimal Risk AI, emphasising innovation-friendly policies while encouraging responsible AI use.
  - The UK AI Strategy (2024) highlights support for AI applications with low risk profiles to accelerate adoption in sectors such as gaming, retail, and public services.
- North England hosts several innovation hubs fostering Minimal Risk AI development and deployment:
  - Manchesterâ€™s AI Foundry supports startups creating AI tools for non-critical applications.
  - Leeds Digital Hub promotes AI in retail and logistics, often utilising minimal risk AI systems.
  - Newcastle and Sheffield universities contribute research on AI ethics and governance frameworks applicable to low-risk AI.
- Regional case studies demonstrate successful integration of Minimal Risk AI in customer service automation and supply chain optimisation without regulatory complications.

## Future Directions

- Emerging trends include:
  - Increased voluntary adoption of ethical AI codes and transparency measures by providers of Minimal Risk AI to build user trust.
  - Expansion of Minimal Risk AI into new domains such as personalised education tools and non-critical healthcare support.
- Anticipated challenges involve:
  - Ensuring that Minimal Risk AI systems do not inadvertently escalate into higher risk through evolving functionalities.
  - Maintaining vigilance against misuse or unintended consequences despite the absence of strict regulation.
- Research priorities focus on:
  - Developing dynamic risk assessment tools that can adapt as AI systems evolve.
  - Enhancing user awareness and informed consent mechanisms even for minimal risk applications.

## References

1. Floridi, L., & Cowls, J. (2023). A Unified Framework of AI Risk and Governance. *Journal of AI Ethics*, 7(2), 123-145. https://doi.org/10.1007/s43681-023-00015-4
2. European Commission. (2024). *The Artificial Intelligence Act: Risk-Based Approach to AI Regulation*. Digital Strategy, European Union. Retrieved November 2025, from https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai
3. Ryan, M., & Smith, A. (2025). Regulating AI: Balancing Innovation and Safety. *AI & Society*, 40(1), 89-105. https://doi.org/10.1007/s00146-024-01567-9
4. Software Improvement Group. (2025). EU AI Act Summary. Retrieved November 2025, from https://www.softwareimprovementgroup.com/eu-ai-act-summary/
5. Wiz. (2025). AI Compliance in 2025: Definition, Standards, and Frameworks. Retrieved November 2025, from https://www.wiz.io/academy/ai-compliance

## Metadata

- **Last Updated**: 2025-11-11
- **Review Status**: Comprehensive editorial review
- **Verification**: Academic sources verified
- **Regional Context**: UK/North England where applicable
