- Sdxl [[latent space]] exploration
  https://huggingface.co/blog/TimothyAlexisVass/explaining-the-sdxl-latent-space
- Real time drawing
  https://github.com/cocktailpeanut/deus
- Casino security
  https://www.biometricupdate.com/202309/face-biometrics-and-ai-prove-to-be-jackpot-for-gaming-regulators-and-casino-security
- Multi hop question mistral
  https://github.com/khaimt/qa_expert
- Pay per inference
  https://www.reddit.com/r/StableDiffusion/comments/1805v7j/after_many_allnighters_i_made_a_way_to_run/
- OpenAssistant benchmark LQ-[[LoRA DoRA etc]] is able to learn a 2.5-bit [[LLaMA]]-2 model that is competitive with a model finetuned with 4-bit Q[[LoRA DoRA etc]]. When finetuned on a language modeling calibration dataset, LQ-[[LoRA DoRA etc]] can also be used for model compression; in this setting our 2.75-bit [[LLaMA]]-2-70B model (which has 2.85 bits on average when including the low-rank components and requires 27GB of GPU memory) is competitive with the original model in full precision.
  https://arxiv.org/abs/2311.12023
- DONE sort a meeting with nick avis
- Video llava
  https://github.com/PKU-YuanGroup/Video-LLaVA