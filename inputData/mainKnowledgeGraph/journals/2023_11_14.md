# 2023_11_14
- SD promptbook from openart
  (https://openart.ai/promptbook)
- Custom GPT starter kit (replit)
  (https://replit.com/@MartinBowling/Custom-GPT-Starter-Kit#main.py)
- Florence 2 machine vision
  (https://arxiv.org/pdf/2311.06242v1.pdf)
- deepseek 34b q4 AWQ
  (https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-AWQ)
- textgenerator io self host
  (https://github.com/TextGeneratorio)
- AWQ 4 bit quants
  (https://github.com/mit-han-lab/llm-awq)
- Tinychat
  (https://github.com/mit-han-lab/llm-awq/tree/main/tinychat)
- Openshat model
  (https://github.com/imoneoi/openchat)
- Custom GPT open source semantic lock
  (https://github.com/infotrix/SSLLMs---Semantic-Secuirty-for-LLM-GPTs/blob/master/GPT_Semantic_Security_Template.txt)
- Design
- My new flex here is quorums on clusters.
- - Nvidia Jetson
- - 16k window chat with great performance
- tinychat
- awq 7b models
- openchat 3.5 16k awq
  (https://huggingface.co/TheBloke/openchat_3.5-16k-AWQ)
- - Multimodality on the [[Hardware and Edge]]
- llava 13b 4 bit
  (https://huggingface.co/TheBloke/llava-v1.5-13B-AWQ)
- - Slightly iffy json capability
- - Autogen
- - Planning semantic kernel
- - Main system
- - Deepseek 33B coding instruct 4 bit AWQ with it's own GPU
- - A gaggle of smart tuned 7B models
- Goliath 120B AWQ?
  (https://huggingface.co/TheBloke/goliath-120b-AWQ?text=Hey+my+name+is+Julien%21+How+are+you%3F)
- - Connection out to OpenAI API for the tough times
- - Claude API integration
- - Autogen, semantic kernel next
- I really need to build out some kind of priority system though and it's going to take me a minute.