- Token Classifiers
	- llamagaurd 2, rubbish, with nvidia aegis slightly better
	- llamagaurd 3 is terrible and inefficient (1 rule at a time, only 4 available)
	- shield gemma, faster but misclassification and inconsistent
	- roberta toxicity = good and fast
	- unitary toxicity = best
	- dslim's ner, are all just average, honestly Reuters tooling from 10+ years ago (open calais) was way better -
	- bert large performs best tbh,
	- distilbert isn't as accurate
- Prompt classifier [[NVIDIA]]
	- [nvidia/prompt-task-and-complexity-classifier Â· Hugging Face](https://huggingface.co/nvidia/prompt-task-and-complexity-classifier)
- [dottxt - make ai speak computer](https://dottxt.co/) [[Projects]] [[FuzzyDuck]] [[Agentic Mycelia]] [[MUST]]
	- [dottxt-ai/outlines: Structured Text Generation](https://github.com/dottxt-ai/outlines/tree/main?tab=readme-ov-file#efficient-json-generation-following-a-pydantic-model) [[json]]
	- [dottxt-ai/outlines-core: Structured generation in Rust](https://github.com/dottxt-ai/outlines-core) [[Rust]]