# 2023_04_25
- [[RGB and Client Side Validation]] is a smart contract platform that is scalable, private, and interoperable with Bitcoin and Lightning Network. It is possible to issue assets, create NFTs, and run DAOs on RGB.
  (https://rgb.tech/)
- This is a node management software for large Lightning Network nodes. It provides a way to automate workflows, manage code changes, and track work progress.
  (https://github.com/lncapital/torq)
-
- Africa leads the world in peer to peer bitcoin
  (https://twitter.com/documentingbtc/status/1646656229958361091)
- Deception, exploited workers, and cash handouts: How Worldcoin recruited its first half a million test users: The startup promises a fairly-distributed, cryptocurrency-based universal basic income. So far all it's done is build a biometric database from the bodies of the poor.
  (https://www.technologyreview.com/2022/04/06/1048981/worldcoin-cryptocurrency-biometrics-web3/)
- Cashu rust implementation
  (https://github.com/ngutech21/cashu-rs)
- Zerosync bitcoin rollup proofs
  (https://zerosync.org/)
- Mining and energy
- Bitcoin uses more energy than sweden
  (https://www.reddit.com/r/CryptoCurrency/comments/12xu714/bitcoin_has_just_surpassed_sweden_for_overall/)
- THE 'RIGHT TO MINE' #BITCOIN? IS NOW LAW IN THE STATE OF ARKANSAS!
  (https://twitter.com/satoshiactfund/status/1648445448833875969)
- Bitcoin is a more sustainable energy than EVs, and significantly less fossil fuel.
  (https://www.linkedin.com/posts/danielsbatten_like-evs-bitcoin-is-a-fully-electrified-activity-7049321186605858816-t4MB?utm_source=share&utm_medium=member_android)
- OpenOrdex is a decentralized exchange for ordinal numbers. It allows users to buy and sell ordinal numbers using a variety of methods, including Inscription, which is a process by which users can add their own numbers to the exchange.
  (https://openordex.org/)
- Smooth animation with controlnet
  (https://www.reddit.com/r/StableDiffusion/comments/125m56z/smooth_animation_with_controlnet_and_regional/)
- This code snippet sets up Reddit's Sentry error monitoring, which includes a function to check for various types of errors and report them accordingly. Additionally, it sets up a fetch() wrapper to add a header specifying that Sentry should always be used in "sticky canary" mode.
- Multi scene videos using automatic1111
  (https://www.reddit.com/r/StableDiffusion/comments/127wub7/to_make_a_video_with_multiple_scenes_using_only/)
- 1 go to Automatic1111 Deforum in interpolation mode and generate several pics regarding the prompt theme. Deforum interpolation is not good for animation, but it is good for generating lot of pics about the same subject.
  
  2 select the better images and put them in Deforum Init section. Then generate the animations in 2D or 3D. For this test I used only 10 steps, so graphics are not stellar. Repeat until you have several animations, each one on its directory.
  
  3 select the good animations. Pick the frames and put them in a directory. Then go to Deforum Output and select Pictures interpolation , put the frames here and interpolate with value 2. With this you generate the video.
  
  Note: I interpolated 693 frames. Tried bigger quantities and the interpolator did not work. So this method is pretty limited.
- Controlnet 1.1
  (https://www.reddit.com/r/StableDiffusion/comments/12o8qm3/finally_installed_the_newer_controlnet_models_a/)
- HDR landscape model
  (https://www.reddit.com/r/StableDiffusion/comments/12nzrtl/hdr_photography_style_landscapesseascapes/)
- GitHub - kpthedev/ez-text2video: Easily run text-to-video diffusion with customized video length, fps, and dimensions on 4GB video cards, as well as on CPU.: Easily run text-to-video diffusion with customized video length, fps, and dimensions on 4GB video cards, as well as on CPU. - GitHub - kpthedev/ez-text2video: Easily run text-to-video diffusion wit...
  (https://github.com/kpthedev/ez-text2video)
- This repository contains a [[ComfyUI]] Extension for Automated Text Generation. The extension provides nodes which can be used to automate the text generation process. The goal is to build a node-based Automated Text Generation AGI. This extension should ultimately combine all of the features of the existing text generation tools into one tool.
  (https://github.com/xXAdonesXx/NodeGPT)
- [R] Text-to-image Diffusion Models in Generative AI: A Survey : r/MachineLearning
  (https://www.reddit.com/r/MachineLearning/comments/12ehcez/r_texttoimage_diffusion_models_in_generative_ai_a/)
- Tutorial: Creating a Consistent Character as a Textual Inversion Embedding
  (https://github.com/BelieveDiffusion/tutorials/discussions/3)
- Segment anything webui
  (https://www.reddit.com/r/StableDiffusion/comments/12hkdy8/sd_webui_segment_everything/)
- Overriding iphone footage with SD characters using controlnet
  (https://www.reddit.com/r/StableDiffusion/comments/12lg8mn/override_more_experiments_overriding_the_original/)
- The Text2Room algorithm generates textured 3D meshes from a given text prompt by leveraging pre-trained 2D text-to-image models. The core idea is to select camera poses that will result in a seamless, textured 3D mesh. The algorithm iteratively fuses scene frames with the existing geometry to create the final mesh. Evaluation shows that the algorithm is able to generate room-scale 3D geometry with compelling textures from only text as input.
  (https://lukashoel.github.io/text-to-room/)
- The VMesh system models a scene with a triangular mesh and a sparse volume for efficient view synthesis. It is trained on multi-view images of an object to create a contiguous representation of the object's surface and volume. This representation is then used to generate a simplified triangular mesh and a sparse volume, which can be stored and rendered efficiently. The system is designed for real-time applications and can render at 2K 60FPS on common consumer devices.
  (https://bennyguo.github.io/vmesh/)
- Temporal stable automatic plugin
  (https://www.reddit.com/r/StableDiffusion/comments/12sd4bi/results_from_latest_version_of_temporal_stable/)
- We present a method for high-resolution video synthesis using latent diffusion models (LDMs). Our approach first pre-trains an LDM on images, then introduces a temporal dimension to the [[latent space]] diffusion model and fine-tunes it on encoded image sequences (i.e. videos). We focus on two real-world applications: simulation of in-the-wild driving data and creative content creation with text-to-video modeling. Our method achieves state-of-the-art performance on real driving videos of 512 x 1024 resolution. Additionally, our approach can leverage off-the-shelf pre-trained image LDMs, turning the publicly available, state-of-the-art text-to-image LDM Stable Diffusion into an efficient and expressive text-to-video model.
  (https://buff.ly/41FgQrb)
- This script allows for the automation of video stylization using StableDiffusion and ControlNet.
  (https://github.com/volotat/SD-CN-Animation)
- Really easy videos in A1111
  (https://www.reddit.com/r/StableDiffusion/comments/12otdo0/the_secret_to_really_easy_videos_in_a1111_easier/)
- Dancer 4 keyframes, low noise, controlnet approach
  (https://www.reddit.com/r/StableDiffusion/comments/12nwpdx/dancer_4_keyframes_guide_and_source_files_for/)
- Controlnet face model for SD1.5
  (https://www.reddit.com/r/StableDiffusion/comments/12dxue5/controlnet_face_model_for_sd_15/)
- The audioFlux library is a tool for audio and music analysis, featuring extraction capabilities. It is open source and released under the MIT license.
  (https://github.com/libAudioFlux/audioFlux)
- Grimes invites royalty split with anyone using her voice
  (https://www-engadget-com.cdn.ampproject.org/c/s/www.engadget.com/amp/grimes-invites-ai-artists-to-use-her-voice-promising-50-percent-royalty-split-165659578.html)
- This repository contains Stability AI's development of the StableLM series of language models. The models are designed to be more stable and robust than traditional language models, and the repository includes code and examples for training and using the models.
  (https://github.com/stability-AI/stableLM/)
- Can we improve the efficiency of these training methods, so we can still get good models in less time and for less money? We propose to do this by leveraging smaller language models that have previously been trained,
  (https://gemm.ai/learning-to-grow-machine-learning-models/)
- The text describes the Camel Chatbot, a machine learning model that has been trained using data from the AI Society and Code datasets. The chatbot is designed to improve the coding ability of users. The text includes a link to a demo of the chatbot in action.
  (https://www.linkedin.com/posts/guohao-li-9a573b136_camel-chatbot-demo-activity-7051390760327225344-8D2A?utm_source=share&utm_medium=member_android)
- Transformers are a new type of machine learning model that have been making headlines recently. They are very good at keeping track of context, which is why the text they generate makes sense. In this blog post, we will go over their architecture and how they work.
  (https://txt.cohere.ai/what-are-transformer-models/)
- NexusGPT is a freelancer platform that uses AI to help businesses find the right freelancers for their needs. The platform offers a variety of features to help businesses find the perfect freelancer for their project, including a searchable database of freelancers, a rating system, and a feature that allows businesses to post their project and receive bids from freelancers.
  (https://nexus.snikpic.io)
- aomni: Aomni is an information retrieval AI agent that is able to find, extract, and process any data for you on the internet.
  (https://www.aomni.com/)
- AutoGPT twitter thread
  (https://mobile.twitter.com/SullyOmarr/status/1645482778677452805)
- Godmode.space automatic 3.5 task website
  (https://godmode.space/)
- Experiments in 1 and 2 million token inputs
  (https://arxiv.org/abs/2304.11062)
- github
  (https://github.com/booydar/t5-experiments)
- Chat with any github repository
  (https://www.reddit.com/r/MachineLearning/comments/12oh07a/p_chat_with_any_github_repo_code_understanding/)
- Best way to train an LLM on company data
  (https://www.reddit.com/r/MachineLearning/comments/125qztx/d_the_best_way_to_train_an_llm_on_company_data/)
- The text describes the process of integrating ChatGPT, a chatbot, with an internal knowledge base and question-answer platform. The goal is to improve the chatbot's ability to provide accurate and relevant information. The process involves training the chatbot on a variety of data sources, including the internal knowledge base.
  (https://medium.com/singapore-gds/integrating-chatgpt-with-internal-knowledge-base-and-question-answer-platform-36a3283d6334)
- Peak LLM: Prompt injection might be just the beginning
  (https://ihavemanythoughts.substack.com/p/peak-llm)
- Language models as inductive reasoners paper
  (https://sentic.net/language-models-as-inductive-reasoners.pdf)
- This repository contains a collection of papers and resources on Reasoning in [[Large Language Models]]. The papers survey the state of the art in this area, and discuss how [[large language models]] can be used to obtain emergent abilities.
  (https://github.com/jeffhj/LM-reasoning)
- Full trainingset used by bloombergAI
  (https://mobile.twitter.com/omarsar0/status/1641788196550856704)
- Zain Kahn on LinkedIn reports that over 1,000 AI tools were released in March. He states that ChatGPT is just the tip of the iceberg, and that there are 20 AI tools that will transform productivity forever.
  (https://www.linkedin.com/posts/zainkahn_1000-ai-tools-were-released-in-march-activity-7048285306101358592-4wAA?utm_source=share&utm_medium=member_android)
- Language driven shell for OS (ooft)
  (https://www.reddit.com/r/MachineLearning/comments/129wzdk/p_engshell_a_gpt4_driven_englishlanguage_shell/)
- The text contains information on the release of guidelines by the DPA for the use of AI, as well as on similar efforts by other organizations. It also provides links to resources on the topic.
  (https://www.linkedin.com/posts/ezra-eeman-8a5ba64_dpa-just-released-its-guidelines-for-the-activity-7048985893910519808-921y?utm_source=share&utm_medium=member_android)
- This repository is a collection of links to various courses and resources about Artificial Intelligence (AI).
  (https://github.com/SkalskiP/courses)
-
- The Web LLM project has created a browser-based version of the vicuna-7b Large Language Model, which is impressively accurate and fast. The model is able to handle complex prompts and provide accurate responses, although it does sometimes make mistakes.
  (https://simonwillison.net/2023/Apr/16/web-llm/)
- MultimodalC4 is a multimodal extension of c4 that interleaves millions of images with text. The corpus contains over a billion images, and the text is interleaved with the images to provide context.
  (https://github.com/allenai/mmc4)
- The text provides instructions on how to train your own [[large language models]] using Replit. It explains that you will need to first create a Replit account and then follow the instructions on the website.
  (https://blog.replit.com/llm-training)
- Futurepedia is the largest AI tools directory, with over 700 tools in various categories. It is updated daily, and features search and filter options to help you find the right tool for your needs.
  (http://Futurepedia.io)
- GitHub - gitnomad24601/ShogScript: ShogScript: The GitHub repository "ShogScript" contains a proof-of-concept pseudocode for GPT-4 AI interactions, ideal for storytelling & communication. The code is released under the MIT license.
  (https://github.com/gitnomad24601/ShogScript)
- Understanding [[Large Language Models]]: A Cross-Section of the Most Relevant Literature To Get Up to Speed
  (https://magazine.sebastianraschka.com/p/understanding-large-language-models)
- The text describes a change to support the GPTQ triton commit c90adef. This change allows for the disabling of quant attention.
  (https://github.com/oobabooga/text-generation-webui/pull/1229)
- Prompt model tips for learning
- 1. Improve your writing by getting feedback.
- Use this prompt:
- [paste your writing]
- "Proofread my writing above. Fix grammar and spelling mistakes. And make suggestions that will improve the clarity of my writing"
- 2. Use the 80/20 principle to learn faster than ever.
- "I want to learn about [insert topic]. Identify and share the most important 20% of learnings from this topic that will help me understand 80% of it."
- 3. Learn and develop any new skill.
- "I want to learn / get better at [insert desired skill]. I am a complete beginner. Create a 30 day learning plan that will help a beginner like me learn and improve this skill."
- 4. Get short and insight-packed book summaries.
- "Summarize the book [insert book] by the author [insert author] and give me a list of the most important learnings and insights."
- 5. Get feedback from history's greatest minds.
- "Assume you are [insert famous person e.g. Steve Jobs]. Read my argument below and give me feedback as if you were [insert person again]"
- [insert your argument]
- 6. Enhance your problem solving skills.
- "Your role is that of a problem solver. Give me a step-by-step guide to solving [insert your problem]."
- 7. Generate new ideas and overcome writers block:
- "I am writing a blog post about [insert topic]. Give me an outline for this blog post with 10 bullet points. Also give me 5 options for a catchy headline."
- You can adapt this prompt for whatever you're writing.
- 8. Summarize long texts and accelerate your learning:
- "Summarize the text below into 500 words or less. Create sections for each important point with a brief summary of that point."
- 9. Use stories and metaphors to aid your memory.
- "I am currently learning about [insert topic]. Convert the key lessons from this topic into engaging stories and metaphors to aid my memorization."
- 10. Strengthen your learning by testing yourself.
- "I am currently learning about [insert topic]. Ask me a series of questions that will test my knowledge. Identify knowledge gaps in my answers and give me better answers to fill those gaps."
- Prompt injection: what s the worst that can happen?
  (https://simonwillison.net/2023/Apr/14/worst-that-can-happen/)
- To jailbreak ChatGPT, you need to get it to really do what you want. This can be done by editing the source code or by using a third-party tool.
  (https://www.digitaltrends.com/computing/how-to-jailbreak-chatgpt/)
- [[Large Language Models]] are Human-Level Prompt Engineers: We propose an algorithm for automatic instruction generation and selection for [[large language models]] with human level performance.
  (https://openreview.net/forum?id=92gvk82DE-)
- The text provides a guide on how to make your own Loras, which are easy and free to create. The process is described in detail, and the text includes instructions on how to create and customize your own Loras.
  (https://civitai.com/models/22530)
- A Cookbook of Self-Supervised Learning
  (https://arxiv.org/abs/2304.12210)
- Goldman Sachs Predicts 300 Million Jobs Will Be Lost Or Degraded By Artificial Intelligence: Goldman Sachs maintains that if generative AI lives up to its hype, the workforce in the United States and Europe will be upended. The bank estimates 300 million jobs could be lost or diminished due to this fast-growing technology.
  (https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/?sh=3af7314e782b)
- Chatbots must disclose sources or face ban
  (https://www.artisana.ai/articles/eus-ai-act-stricter-rules-for-chatbots-on-the-horizon)
- Specialist model use cases
- Medical
- Financial / tax
- Compliance
- Companionship
- Travel
- Law
- Programming
- Copywriting
- Editorial
- Segment Anything, which can "cut out" any object in any image or video with a single click. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks.
  (https://www.linkedin.com/posts/eric-vyacheslav-156273169_big-news-meta-just-released-segment-anything-activity-7049409700370554880-tStk?utm_source=share&utm_medium=member_android)
- This repository contains code for the Painter and SegGPT models from the BAAI Vision Foundation. These models are designed for in-context visual learning, and can be used to segment images and generate descriptions of them.
  (http://github.com/baaivision/Painter)
- The text presents SegGPT, a generalist model for segmenting everything in context. The model is trained to unify various segmentation tasks into a generalist in-context learning framework, and is evaluated on a broad range of tasks, including few-shot semantic segmentation, video object segmentation, semantic segmentation, and panoptic segmentation. Results show strong capabilities in segmenting in-domain and out-of-domain targets, either qualitatively or quantitatively.
  (https://buff.ly/3KD0Zns)
- Podcast on the law
  (https://www.reply.com/en/metaminutes-s3-e5-legal-challenges-and-regulation-for-the-[[Metaverse and Telecollaboration]])
- The article discusses how the internet has ruined the [[Metaverse and Telecollaboration]], and how it can still be saved. It argues that the internet has made the [[Metaverse and Telecollaboration]] less accessible and more difficult to navigate, and that this has had a negative impact on its potential. The article suggests that the [[Metaverse and Telecollaboration]] can still be saved if we take steps to improve its accessibility and make it easier to use.
  (https://www.wired.com/story/[[Metaverse and Telecollaboration]]-ethics/)
- Exploring Why the [[Metaverse and Telecollaboration]] Hasn't Taken Off as Expected: The [[Metaverse and Telecollaboration]] has quickly turned from a profitable utopia into a cash-guzzling dystopia.The text provides an overview of the [[Metaverse and Telecollaboration]], a virtual world that has not yet taken off as expected. The text describes the potential reasons for this, including the lack of a clear business model and the difficulty of creating an immersive experience.
  (https://www.bbntimes.com/technology/exploring-why-the-[[Metaverse and Telecollaboration]]-hasn-t-taken-off-as-expected)
- The text describes the benefits of using the FinOps and MLOps open source platforms. These platforms allow for better management of financial operations and machine learning operations, respectively.
  (http://hystax.com)
- RFdiffusion is a codebase for running diffusion simulations. It is designed to work with the SE3-transformer library and to be used in conjunction with the PPI scaffold examples. Basic execution of the diffusion script is straightforward, and the inpaint_seq flag can be used to control the output. Partial diffusion is also possible, and the binder design can be used to constrain the diffusion.
  (https://github.com/RosettaCommons/RFdiffusion)
- Daily Study Group: The Wolfram Plugin for ChatGPT: Learn about the Wolfram ChatGPT plugin for access to powerful computation, curated knowledge, real-time data, visualization and even code generation. 
  (https://wolfr.am/1cCK87Nms)
- Inferno is a distributed operating system which uses a file-like name hierarchy to represent services and resources, including devices, network and protocol interfaces, dynamic data sources, and services.Applications are written in a concurrent programming language, Limbo.
  (https://github.com/inferno-os/inferno-os)
-
- Arible Avatars & Virtual Studio: Professional Photography Without Photographers Or The Camera: Unlimited Realistic or Artistic photos of yourself and others monthly
  (https://www.arible.co/prompts)