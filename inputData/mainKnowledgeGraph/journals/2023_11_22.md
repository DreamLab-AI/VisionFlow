- DONE [Ai Adoption Toolkit - Digital Catapult (digicatapult.org.uk)](https://apps.digicatapult.org.uk/ai-adoption-toolkit/#section-2)
  :LOGBOOK:
  CLOCK: [2023-11-22 Wed 18:48:17]--[2023-11-22 Wed 18:48:18] =>  00:00:01
  CLOCK: [2023-11-22 Wed 18:55:46]--[2023-11-22 Wed 18:55:49] =>  00:00:03
  CLOCK: [2023-11-22 Wed 18:55:50]--[2023-11-22 Wed 18:55:50] =>  00:00:00
  CLOCK: [2023-11-22 Wed 18:56:00]--[2023-11-22 Wed 18:56:01] =>  00:00:01
  CLOCK: [2023-11-22 Wed 18:57:10]--[2023-11-22 Wed 18:57:11] =>  00:00:01
  CLOCK: [2023-11-22 Wed 20:48:24]--[2023-11-22 Wed 20:48:25] =>  00:00:01
  :END:
- [[empty?]]
	- DONE Look up: [Christian Gutterman](https://www.linkedin.com/in/guttmann/) at intelligent ultrasound
	- This is a very useful place to start researching optimising ultrasound training [Global-Health-Labs/US-DCGAN (github.com)](https://github.com/Global-Health-Labs/US-DCGAN)
		- The text discusses a study on optimizing ultrasound training using a generative adversarial network (GAN) model. The study used quantitative metrics to measure the distance between real and synthetic image distributions, which helped select the best generative models and assess their performance. Different image representations and metrics, such as pixel space, convolutional layers, logit layers, and softmax output, were analyzed to evaluate the GAN model's success. Empirical convergence metrics, including kernel maximum mean discrepancy (kMMD) and 1-Nearest Neighbor (1NN) accuracy, indicated that the GAN model converged after around 60 epochs. Additionally, Principal Component Analysis (PCA) visualization was used to compare synthetic and real images, demonstrating significant overlap and indicating the successful capture of the real data distribution by the generator model. The comprehensive assessment of the GAN's ability to generate realistic images suggests that the training process was successful.
- A comparison of [[Apple]] which adds some interesting context
  https://eclecticlight.co/2023/11/22/what-has-changed-in-cpu-cores-in-m3-chips/
- [[Finnish church project]]
	- SDXL [[Lora]] for stained glass [Stained Glass Style - SDXL - v1_SDXL | Stable Diffusion [[LoRA DoRA etc]] | Civitai](https://civitai.com/models/122283/stained-glass-style-sdxl)
	- #[[Real Time]] #drawing input to LCM model [cocktailpeanut/deus (github.com)](https://github.com/cocktailpeanut/deus)
- [[Courses and Training]] Free course series released from Amazon
	- "After completing this course, you will be able to build ML models to support proofs of concept (POCs). You will also be able to assist data scientists with potential ML model candidates to solve business problems." The link is https://explore.skillbuilder.aws/learn/course/external/view/elearning/17515/low-code-machine-learning-on-aws
- [[Immersive]] job offer
	- DONE Check back on slack
	  :LOGBOOK:
	  CLOCK: [2023-11-22 Wed 21:59:53]--[2023-11-22 Wed 21:59:54] =>  00:00:01
	  :END:
- [[Knowledge Graphing]] turns out to be Turing complete [(1) Bas Grolleman on X: "So, with 0.8.15 you can run an http api server, from Logseq and then just use JSON api calls to change things. Here I'm just experimenting a bit using wget. But I could hook it up to Make, just need to setup something like an nginx proxy. https://t.co/RrFnwV9L9B" / X (twitter.com)](https://twitter.com/ToolsonTech/status/1608862709554249728)
	- [Turing machine visualization](https://turingmachine.io/)
	- ```
	  curl -X POST http://127.0.0.1:12315/api \
	  -H "Authorization: Bearer {replace with your-token-value-here}" \
	  -H "Content-Type: application/json" \
	  -d '{"method": "logseq.Editor.insertBlock", "args": ["Test page", "This is a new block", {"isPageBlock": true}]}'
	  ```
-